{
  "count" : 566,
  "summaries" : [ {
    "issueDTO" : {
      "id" : 3224577759,
      "title" : "????????????????????????",
      "url" : "https://github.com/ModelEngine-Group/app-platform/issues/320",
      "repositoryName" : "ModelEngine-Group/app-platform",
      "description" : "### ???????????? / Issue Summary\n\n????????????????????????\n\n### ???????????? / Version Information\n\n?????? (??????????????????) / Other (please specify below)\n\n### ????????? / Browser\n\nChrome\n\n### ???????????? / Operating System\n\nWindows 10\n\n### ??????????????????/ What happened?\n\n<img width=\"959\" height=\"331\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/86d71002-3ab9-4760-95aa-20e7d21d9b9a\" />\n\n### ??????????????? / Expected Behavior\n\n????????????????????????\n\n### ???????????? / Steps to Reproduce\n\n1. ?????????https://github.com/ModelEngine-Group/app-platform/tree/main\n\n### ???????????? / Relevant Logs\n\n```shell\n\n```\n\n### ???????????? / Additional Context\n\n_No response_\n\n### ???????????? / Confirmations\n\n- [x] ???????????????????????????issues??????????????????????????????\nI have searched existing issues and confirmed this is not a duplicate\n\n- [x] ????????????????????????????????? FAQ\nI have read the project documentation and FAQ  \n\n- [x] ??????????????????????????????\nThe information I provided is accurate and complete\n\n- [x] ????????????????????????????????? (??????)\nI'm willing to help test the bug fix (optional)\n",
      "updatedAt" : 1752281273.000000000,
      "user" : "loveTsong",
      "userHtmlUrl" : "https://github.com/loveTsong",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16813322?v=4",
      "labels" : [ "type: bug", "status: waiting-for-triage", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "AppPlatform ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? AI ???????????????",
        "homepage" : "http://modelengine-ai.net",
        "name" : "app-platform",
        "fullName" : "ModelEngine-Group/app-platform",
        "htmlUrl" : "https://github.com/ModelEngine-Group/app-platform",
        "gitUrl" : "git://github.com/ModelEngine-Group/app-platform.git",
        "sshUrl" : "git@github.com:ModelEngine-Group/app-platform.git",
        "cloneUrl" : "https://github.com/ModelEngine-Group/app-platform.git",
        "owner" : {
          "login" : "ModelEngine-Group",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 184,
        "stargazersCount" : 1002,
        "watchersCount" : 1002,
        "size" : 23878,
        "openIssuesCount" : 77,
        "subscribersCount" : 133,
        "pushedAt" : "2025-07-11T08:35:50Z",
        "languages" : {
          "TypeScript" : 1362806,
          "Java" : 7293926,
          "Dockerfile" : 564,
          "Shell" : 11750,
          "CSS" : 1937,
          "SCSS" : 184852,
          "PLpgSQL" : 23547,
          "JavaScript" : 36730,
          "HTML" : 1303
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to troubleshoot why images are not displaying on the homepage",
      "validationOrRequirement" : "Please specify the version information",
      "attemptedFixes" : "No fixes attempted or blockers encountered",
      "otherNotes" : "No additional context provided",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282675
  }, {
    "issueDTO" : {
      "id" : 3205824618,
      "title" : "Recommended to add TG commands: /profit long and /profit short",
      "url" : "https://github.com/freqtrade/freqtrade/issues/11958",
      "repositoryName" : "freqtrade/freqtrade",
      "description" : "<!-- \nNote: this section will not show up in the issue.\nHave you search for this feature before requesting it? It's highly likely that a similar request was already filed.\n-->\n\n## Describe your environment\n(if applicable)\n\n* Operating system: Ubuntu 24.04.2\n* Python Version: 3.12.3\n* CCXT version: 4.4.77\n* Freqtrade Version: 2025.4\n\n\n## Describe the enhancement\n\nRecommended to add TG commands: `/profit long` and `/profit short`\n\n*Explain the enhancement you would like*\n\nCurrently, the TG command `/profit` can be used to view the overall trading report. \n\nHowever, during trading, we sometimes need to check the long and short reports separately to understand which direction the market is currently favoring.\n\nCould you provide the `/profit long` and `/profit short` commands for this purpose?\n\nThank you!",
      "updatedAt" : 1752281101.000000000,
      "user" : "WinPoss",
      "userHtmlUrl" : "https://github.com/WinPoss",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1667248?v=4",
      "labels" : [ "RPC", "Good first issue", "Enhancement" ],
      "state" : "OPEN",
      "comments" : [ "doesn't `/entries` , `/exits` - or `/mix_tags` (obviously assuming the tags in the strategy are set properly) provide you with this information already.\n\nAlso - the `/profit` command already has an argument (days) - overloading the same property with assumptions may not be a good idea (from a UX perspective).\n\nWhat \"could\" work is having a  `/profit_long` and `/profit_short` command (separate - with the same argument as above) - though i don't really see a necessity for this if i'm honest.\n\nIf you think you require this - would you be open to create a Pull Request adding this functionality?", "Hi, I'm working on this. I will be submitting a pull request soon." ],
      "repository" : {
        "description" : "Free, open source crypto trading bot",
        "homepage" : "https://www.freqtrade.io",
        "name" : "freqtrade",
        "fullName" : "freqtrade/freqtrade",
        "htmlUrl" : "https://github.com/freqtrade/freqtrade",
        "gitUrl" : "git://github.com/freqtrade/freqtrade.git",
        "sshUrl" : "git@github.com:freqtrade/freqtrade.git",
        "cloneUrl" : "https://github.com/freqtrade/freqtrade.git",
        "owner" : {
          "login" : "freqtrade",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 8059,
        "stargazersCount" : 40366,
        "watchersCount" : 40366,
        "size" : 599687,
        "openIssuesCount" : 37,
        "subscribersCount" : 710,
        "pushedAt" : "2025-07-10T05:08:41Z",
        "languages" : {
          "PowerShell" : 15818,
          "Dockerfile" : 1686,
          "Jinja" : 38569,
          "Shell" : 19277,
          "HTML" : 753,
          "Gnuplot" : 221,
          "Jupyter Notebook" : 14363,
          "Python" : 4681123
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add TG commands: /profit long and /profit short to view long and short trading reports separately",
      "validationOrRequirement" : "UX perspective, having separate /profit_long and /profit_short commands could work, but it's not necessary.",
      "attemptedFixes" : "The author is working on a pull request and will submit it soon.",
      "otherNotes" : "The /entries, /exits, or /mix_tags commands already provide the necessary information. The /profit command already has an argument (days) and overloading it with assumptions may not be good UX. Having separate /profit_long and /profit_short commands could work.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282679
  }, {
    "issueDTO" : {
      "id" : 557808600,
      "title" : "Tests fail with System.BadImageFormatException",
      "url" : "https://github.com/dotnet/runtime/issues/4852",
      "repositoryName" : "dotnet/runtime",
      "description" : "The following tests fail with a mesage like this on a debug win64 test job:\r\n\r\n```\r\nUnhandled Exception: System.BadImageFormatException: \r\nCould not load file or assembly '<testname>.exe' or one of its dependencies.\r\nAn attempt was made to load a program with an incorrect format.\r\n```\r\n\r\nThe failing tests are:\r\n\r\n```\r\nJIT\\Directed\\tls\\mutualrecurthd-tls\\mutualrecurthd-tls.cmd\r\nJIT\\Directed\\tls\\test-tls\\test-tls.cmd\r\nJIT\\Regression\\CLR-x86-EJIT\\v1-m10\\b07847\\b07847\\b07847.cmd\r\nJIT\\Regression\\CLR-x86-JIT\\V1.2-M01\\b03689\\b03689\\b03689.cmd\r\n```\r\n\r\ncategory:correctness\r\ntheme:testing\r\nskill-level:beginner\r\ncost:medium\r\nimpact:small",
      "updatedAt" : 1752281069.000000000,
      "user" : "richardlford",
      "userHtmlUrl" : "https://github.com/richardlford",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6829071?v=4",
      "labels" : [ "in-pr", "help wanted", "area-CodeGen-coreclr", "test-bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Please check whether TLS statics are supported by CoreCLR.\n", "@richardlford \nThe .data tls FieldData = XXXXXX construct is not supported on non-Windows platforms. It is really OS specific and there is no anything like that available on the non Windows platforms.\nThese tests are expected to fail on non-Windows platforms. Please move them to the tests/testsUnsupportedOutsideWindows.txt file and  close the issue.\n", "TLS statics not supported by .NET Core.  BadImageFormatException is expected on all platforms.  We should replace these tests with a single test that verifies the exception is raised.\n", "@RussKeldorph Do we need to keep this issue open?", "@BruceForstall If my last comment is no longer actionable or relevant, sure, close it.  Otherwise, I'd rather keep it open to track the gap in testing.", "These files no longer exist so can this issue be closed?", "These tests still all exist in the test tree (but the tests are not built).", "Given this is old enough, I am pushing it to Future. " ],
      "repository" : {
        "description" : ".NET is a cross-platform runtime for cloud, mobile, desktop, and IoT apps.",
        "homepage" : "https://docs.microsoft.com/dotnet/core/",
        "name" : "runtime",
        "fullName" : "dotnet/runtime",
        "htmlUrl" : "https://github.com/dotnet/runtime",
        "gitUrl" : "git://github.com/dotnet/runtime.git",
        "sshUrl" : "git@github.com:dotnet/runtime.git",
        "cloneUrl" : "https://github.com/dotnet/runtime.git",
        "owner" : {
          "login" : "dotnet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5082,
        "stargazersCount" : 16622,
        "watchersCount" : 16622,
        "size" : 961858,
        "openIssuesCount" : 8688,
        "subscribersCount" : 460,
        "pushedAt" : "2025-07-12T00:46:27Z",
        "languages" : {
          "C#" : 422854789,
          "C" : 39606717,
          "CMake" : 741500,
          "Makefile" : 32653,
          "HTML" : 52294,
          "TypeScript" : 1040949,
          "Shell" : 796890,
          "JavaScript" : 113268,
          "Objective-C" : 114621,
          "PHP" : 1690,
          "Visual Basic .NET" : 2139933,
          "F#" : 71631,
          "Assembly" : 1765695,
          "Python" : 953775,
          "PowerShell" : 241899,
          "Yacc" : 157337,
          "Java" : 17612,
          "C++" : 52375402,
          "CSS" : 29,
          "Objective-C++" : 733,
          "XSLT" : 453872,
          "Perl" : 31646,
          "BitBake" : 1467,
          "OpenEdge ABL" : 137573,
          "Dockerfile" : 19220,
          "Batchfile" : 153589,
          "ASP.NET" : 739,
          "Swift" : 217142,
          "Roff" : 740588,
          "DTrace" : 2861
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "tests fail with System.BadImageFormatException due to unsupported TLS statics and OS specific construct on non-Windows platforms",
      "validationOrRequirement" : "tests are expected to fail on non-Windows platforms, TLS statics not supported by .NET Core, BadImageFormatException is expected on all platforms",
      "attemptedFixes" : "tests were expected to fail on non-Windows platforms, suggested moving tests to tests/testsUnsupportedOutsideWindows.txt file",
      "otherNotes" : "TLS statics not supported by .NET Core, .data tls FieldData = XXXXXX construct is not supported on non-Windows platforms, tests are expected to fail on non-Windows platforms",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282684
  }, {
    "issueDTO" : {
      "id" : 2050170275,
      "title" : "[Intermediate][Test Case] Design a test case for the delete command.",
      "url" : "https://github.com/OpenTenBase/OpenTenBase/issues/12",
      "repositoryName" : "OpenTenBase/OpenTenBase",
      "description" : "Design a test case for the delete command, including the case of associated deletion.\r\n\r\n????????????delete??????????????????????????????????????????????????????",
      "updatedAt" : 1752280916.000000000,
      "user" : "bartdong",
      "userHtmlUrl" : "https://github.com/bartdong",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/27182433?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "??????????????????issue", "??????????????????issue", "PR?????????", "??????????????????issue" ],
      "repository" : {
        "description" : "OpenTenBase is an enterprise-level distributed HTAP open source database. ",
        "homepage" : "https://opentenbase.org",
        "name" : "OpenTenBase",
        "fullName" : "OpenTenBase/OpenTenBase",
        "htmlUrl" : "https://github.com/OpenTenBase/OpenTenBase",
        "gitUrl" : "git://github.com/OpenTenBase/OpenTenBase.git",
        "sshUrl" : "git@github.com:OpenTenBase/OpenTenBase.git",
        "cloneUrl" : "https://github.com/OpenTenBase/OpenTenBase.git",
        "owner" : {
          "login" : "OpenTenBase",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 109,
        "stargazersCount" : 159,
        "watchersCount" : 159,
        "size" : 29019,
        "openIssuesCount" : 101,
        "subscribersCount" : 8,
        "pushedAt" : "2024-12-31T08:25:00Z",
        "languages" : {
          "Smarty" : 2837,
          "Yacc" : 639767,
          "C" : 52308919,
          "PLpgSQL" : 2194887,
          "Makefile" : 332260,
          "M4" : 93402,
          "Perl" : 860316,
          "Dockerfile" : 5769,
          "Shell" : 195723,
          "sed" : 1231,
          "Batchfile" : 10341,
          "PLSQL" : 79435,
          "Roff" : 30385,
          "XS" : 6988,
          "Ruby" : 224834,
          "Lex" : 201427,
          "Assembly" : 3265,
          "Python" : 16241,
          "Emacs Lisp" : 3488,
          "DTrace" : 3435
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Design a test case for the delete command",
      "validationOrRequirement" : "Good first issue",
      "attemptedFixes" : "PR has been submitted",
      "otherNotes" : "The issue is about designing a test case for the delete command, including the case of associated deletion.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282686
  }, {
    "issueDTO" : {
      "id" : 3224573856,
      "title" : "Better error when mixing up `include` and `extend`",
      "url" : "https://github.com/sorbet/sorbet/issues/9062",
      "repositoryName" : "sorbet/sorbet",
      "description" : "\n#### Input\n\n[??? View on sorbet.run](https://sorbet.run/#%23%20typed%3A%20true%0A%0Amodule%20Foo%0A%20%20def%20foo%0A%20%20end%0Aend%0A%0Aclass%20A%0A%20%20include%20Foo%0Aend%0A%0AA.foo%0A%0A)\n\n```ruby\n# typed: true\n\nmodule Foo\n  def foo\n  end\nend\n\nclass A\n  include Foo\nend\n\nA.foo\n\n\n```\n\n#### Observed output\n\n```\neditor.rb:12: Method foo does not exist on T.class_of(A) https://srb.help/7003\n    12 |A.foo\n          ^^^\n  Got T.class_of(A) originating from:\n    editor.rb:12:\n    12 |A.foo\n        ^\nErrors: 1\n```\n\n<!-- TODO: For issues where `srb tc` differs from the behavior of `sorbet-runtime`, please include the observed runtime output. -->\n\n#### Expected behavior\n\n<!-- TODO: Briefly explain what the expected behavior should be on this example. -->\n\nMisuse of `include` and `extend` is a common Ruby beginner bug. It would be nice if Sorbet could\n\n1. notice that `foo` does not exist as a singleton class method\n2. notice that it exists as an instance method\n3. notice that it comes not from `A` but an ancestor of `A` called `Foo`\n4. suggest changing `include Foo` to `extend Foo`\n\nThis cannot be an autocorrect, because there's no telling who else might be depending on that instance method existing. But having the additional context would be nice, especially if we have no other advice to give.\n\n- - -\n\n<!-- TODO: If there is any additional information you'd like to include, include it here. -->\n\nNote that we already sort of do something similar. If you define an instance method in `A` and attempt to call it as a singleton class method, Sorbet suggests converting it to a `def self.foo` method.\n\n\n[??? View on sorbet.run](https://sorbet.run/#%23%20typed%3A%20true%0A%0Amodule%20Foo%0Aend%0A%0Aclass%20A%0A%20%20include%20Foo%0A%20%20def%20foo%0A%20%20end%0Aend%0A%0AA.foo)\n\n```ruby\n# typed: true\n\nmodule Foo\nend\n\nclass A\n  include Foo\n  def foo\n  end\nend\n\nA.foo\n```\n\n```\neditor.rb:12: Method foo does not exist on T.class_of(A) https://srb.help/7003\n    12 |A.foo\n          ^^^\n  Got T.class_of(A) originating from:\n    editor.rb:12:\n    12 |A.foo\n        ^\n  Note:\n    Did you mean to define foo as a singleton class method?\n  Autocorrect: Use -a to autocorrect\n    editor.rb:8: Insert self.\n     8 |  def foo\n              ^\nErrors: 1\n```\n\nFor the case where it's directly a member of the attached class that's safe, because regardless whether it's a class or module, the `self.` trick will work.\n\nBut for the original problem of `include Foo`, defining the method as `def self.foo` will not help, because module singleton classes are final and are not put in the ancestor chain when `include` is used. So the only way to get access to `Foo#foo` would be to `extend Foo`.",
      "updatedAt" : 1752280850.000000000,
      "user" : "jez",
      "userHtmlUrl" : "https://github.com/jez",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5544532?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A fast, powerful type checker designed for Ruby",
        "homepage" : "https://sorbet.org",
        "name" : "sorbet",
        "fullName" : "sorbet/sorbet",
        "htmlUrl" : "https://github.com/sorbet/sorbet",
        "gitUrl" : "git://github.com/sorbet/sorbet.git",
        "sshUrl" : "git@github.com:sorbet/sorbet.git",
        "cloneUrl" : "https://github.com/sorbet/sorbet.git",
        "owner" : {
          "login" : "sorbet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 567,
        "stargazersCount" : 3703,
        "watchersCount" : 3703,
        "size" : 203086,
        "openIssuesCount" : 885,
        "subscribersCount" : 36,
        "pushedAt" : "2025-07-12T00:31:33Z",
        "languages" : {
          "TypeScript" : 151074,
          "C++" : 5113416,
          "Shell" : 179871,
          "CSS" : 7529,
          "Starlark" : 89189,
          "C" : 7273,
          "JavaScript" : 34356,
          "Lua" : 1613,
          "HTML" : 5068,
          "Ruby" : 5791170,
          "Ragel" : 89517,
          "Python" : 7887
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Provide better error when mixing up `include` and `extend`",
      "validationOrRequirement" : "Sorbet should notice that `foo` does not exist as a singleton class method, notice that it exists as an instance method, notice that it comes not from `A` but an ancestor of `A` called `Foo`, suggest changing `include Foo` to `extend Foo`.",
      "attemptedFixes" : "Note that we already sort of do something similar. If you define an instance method in `A` and attempt to call it as a singleton class method, Sorbet suggests converting it to a `def self.foo` method.",
      "otherNotes" : "Misuse of `include` and `extend` is a common Ruby beginner bug. It would be nice if Sorbet could notice that `foo` does not exist as a singleton class method, notice that it exists as an instance method, notice that it comes not from `A` but an ancestor of `A` called `Foo`, suggest changing `include Foo` to `extend Foo`. This cannot be an autocorrect, because there's no telling who else might be depending on that instance method existing. But having the additional context would be nice, especially if we have no other advice to give.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282695
  }, {
    "issueDTO" : {
      "id" : 3012106769,
      "title" : "Match within string when autocompleting cell type",
      "url" : "https://github.com/ToposInstitute/CatColab/issues/480",
      "repositoryName" : "ToposInstitute/CatColab",
      "description" : "In the cell type selector menu you can type to autocomplete, but the match is only on the initial segment. So for instance \"pos\" does not match \"delayed positive link.\" It should probably be substring match, not initial substring.",
      "updatedAt" : 1752280749.000000000,
      "user" : "KevinDCarlson",
      "userHtmlUrl" : "https://github.com/KevinDCarlson",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29418533?v=4",
      "labels" : [ "enhancement", "good first issue", "ui/ux" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A collaborative environment for formal, interoperable, conceptual modeling",
        "homepage" : "https://catcolab.org",
        "name" : "CatColab",
        "fullName" : "ToposInstitute/CatColab",
        "htmlUrl" : "https://github.com/ToposInstitute/CatColab",
        "gitUrl" : "git://github.com/ToposInstitute/CatColab.git",
        "sshUrl" : "git@github.com:ToposInstitute/CatColab.git",
        "cloneUrl" : "https://github.com/ToposInstitute/CatColab.git",
        "owner" : {
          "login" : "ToposInstitute",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 24,
        "stargazersCount" : 88,
        "watchersCount" : 88,
        "size" : 55616,
        "openIssuesCount" : 141,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-12T00:37:46Z",
        "languages" : {
          "TypeScript" : 403439,
          "Julia" : 40045,
          "MDX" : 17661,
          "Dockerfile" : 1018,
          "CSS" : 32369,
          "Shell" : 13508,
          "Rust" : 566080,
          "JavaScript" : 2753,
          "XSLT" : 20981,
          "HTML" : 367,
          "Nix" : 583477
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve the autocomplete functionality in the cell type selector menu to match within the entire string instead of just the initial segment.",
      "validationOrRequirement" : "The match should be a substring match, not an initial substring match.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the cell type selector menu and the autocomplete functionality, where the match is only on the initial segment of the string.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282698
  }, {
    "issueDTO" : {
      "id" : 2759751004,
      "title" : "[Demos-Collection] Collecting Use Case Demos for Apache SeaTunnel",
      "url" : "https://github.com/apache/seatunnel/issues/8388",
      "repositoryName" : "apache/seatunnel",
      "description" : "# \uD83C\uDFAF Collecting Use Case Demos for Apache SeaTunnel\r\n\r\nDear Apache SeaTunnel community members,\r\n\r\nWe are initiating a community effort to collect **real-world use case demos** to enrich our documentation and help more users quickly get started and solve their problems with Apache SeaTunnel! \uD83D\uDE80\r\n\r\n## Why are these demos important?\r\n\r\nMany users encounter unique scenarios while using SeaTunnel. By collecting and maintaining these demos, we can:\r\n- **Help newcomers**: Showcase the broad range of use cases supported by SeaTunnel.\r\n- **Provide quick-start solutions**: Offer ready-made templates to reduce troubleshooting time.\r\n- **Foster community collaboration**: Enable others to build and improve upon these examples.\r\n\r\n## What can you contribute?\r\n\r\n### 1. Share your specific use case:\r\n- **Scenario Description**: What problem did you solve?\r\n- **SeaTunnel Version**: The version you were using.\r\n- **Configuration or Code Snippet**: Key configuration or scripts.\r\n- **Outcome**: A brief description of the result.\r\n\r\n### 2. Submit a complete demo:\r\n- Organize your configuration files, sample datasets, and documentation into a complete demo.\r\n- Submit a PR to the `demos/` directory in the SeaTunnel repository.\r\n\r\n### 3. Share ideas even without a demo:\r\n- If you don't have a complete demo, feel free to share your ideas here. We will help organize and improve them.\r\n\r\n## Example:\r\n\r\n- **Scenario**: Batch Single Table Synchronization from MySQL to MySQL\r\n- **SeaTunnel Version**: 2.3.8\r\n- **Configuration**:\r\n```\r\nenv {\r\n    job.name = \"mysql_to_elasticsearch\"\r\n    job.mode = \"BATCH\"\r\n    parallelism = 6\r\n}\r\n\r\nsource {\r\n    Jdbc {\r\n        url = \"jdbc:mysql://xxx:3306/source_db\"\r\n        driver = \"com.mysql.cj.jdbc.Driver\"\r\n        user = \"test_user\"\r\n        password = \"test_pwd\"\r\n\r\n        table_list = [\r\n            {\r\n                query = \"select * from source_db.t1\"\r\n                table_path = \"source_db.t1\"\r\n            }\r\n        ]\r\n        result_table_name = \"my-source-1\"\r\n    }\r\n}\r\n\r\nsink {\r\n    Jdbc {\r\n        source_table_name = \"my-source-1\"\r\n        url = \"jdbc:mysql://localhost:3306/sink_db\"\r\n        driver = \"com.mysql.cj.jdbc.Driver\"\r\n        user = \"test_user\"\r\n        password = \"test_pwd\"\r\n\r\n        database = \"sink_db\"\r\n        table = \"${table_name}_copy\"\r\n        generate_sink_sql = true\r\n        batch_size = 1000\r\n\r\n        schema_save_mode = \"RECREATE_SCHEMA\"\r\n        data_save_mode = \"KEEP_SCHEMA_DROP_DATA\"\r\n    }\r\n}\r\n```\r\n\r\n\r\n### \uD83C\uDFAF Calling All Users!\r\nWe???re collecting amazing demos for the project to showcase features and improve the experience! \uD83C\uDF89  \r\n\r\n### \uD83D\uDCCC Why Your Contribution Matters!\r\n- Why contribute?Your demo could become part of the official examples, helping more developers get started quickly!  \r\n- How to contribute? Submit your demo in the comment section???the more detailed, the better!  \r\n\r\n\r\n\uD83D\uDD25 Show off your skills and join us in building a thriving community! \uD83D\uDE80  \r\n\r\n",
      "updatedAt" : 1752280694.000000000,
      "user" : "davidzollo",
      "userHtmlUrl" : "https://github.com/davidzollo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15833811?v=4",
      "labels" : [ "stale", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "??????????????????????????????\nI am willing to participate in this proposal \n??????????????????Oracle-CDC???????????????\n```haconf\nenv {\n  parallelism = 2\n  job.mode = \"STREAMING\"\n  checkpoint.interval = 60000\n}\n\nsource {\n  Oracle-CDC {\n    base-url = \"jdbc:oracle:thin:BI_ETL/xxxxxx@ip:1521:ars\"\n    username = \"BI_ETL\"\n    password = \"xxxxxx\"\n    source.reader.close.timeout = 120000\n    \n    database-names = [\"ARS\"]\n    schema-names = [\"BI_ETL\"]\n    table-names = [\"ARS.BI_ETL.TEST_DIM_C\"]\n    \n    result_table_name = \"TEST_DIM_C\"\n\n  }\n}\n\nsink {\n  Console {\n  }\n}\n```", "Using the MySQL CDC Connector to Read Historical Full Data and CDC Incremental Data from Multiple Tables in a MySQL Database to Doris\n---\n?????? MySQL CDC Connector ??? MySQL ???????????????????????????????????? cdc ??????????????? Doris\n\n```\nenv {\n  job.mode = \"STREAMING\"\n  parallelism = 3\n}\nsource {\n  MySQL-CDC {\n    base-url = \"jdbc:mysql://datasource01:3306/qa_source\"\n    username = \"root\"\n    password = \"root@123\"\n    \n    table-names = [\"qa_source.batch_mysql_to_doris\", \"qa_source.batch_mysql_to_doris_offline_incremental_where\"]\n    startup.mode = \"latest\"\n  \n  }\n}\n\nsink {\n    Doris {\n        fenodes = \"datasource01:8034\"\n        query-port = 9034\n        username = root\n        password = \"root@123\"\n        schema_save_mode = \"RECREATE_SCHEMA\"\n        database = \"e2e_sink\"\n        table = \"${table_name}_from_mysql\"\n        sink.enable-2pc = \"true\"\n        sink.enable-delete = \"true\"\n        sink.label-prefix = \"test_json\"\n        doris.config = {\n            format=\"json\"\n            read_json_by_line=\"true\"\n        }\n    }\n}\n```", "Batch task from MySQL to Doris\n \n```\nenv {\n  parallelism = 4\n  job.mode = \"BATCH\"\n}\n\nsource {\n  Jdbc {\n    result_table_name = \"tab1\"\n    url = \"jdbc:mysql://x.x.x.x:9999/test?useSSL=false&serverTimezone=GMT%2b8\"\n    driver = \"com.mysql.cj.jdbc.Driver\"\n    connection_check_timeout_sec = 100\n    user = \"u\"\n    password = \"p\"\n    query = \"select id,'2025-02-11' as pt_dt, name, task_type, task_execute_type, task_code, task_definition_version, process_instance_id, state, submit_time, start_time, end_time, host, execute_path, log_path, alert_flag, retry_times, pid, app_link, task_params, flag, retry_interval, max_retry_times, task_instance_priority, worker_group, environment_code, environment_config, executor_id, first_submit_time, delay_time, var_pool, task_group_id, dry_run, cpu_quota, memory_max, test_flag, is_cache, cache_key, process_instance_name, project_code, executor_name,'2025-02-11 14:38:18' as backup_time from ql\"\n    partition_column = \"id\"\n    partition_num = 4\n    fetch_size = 2000\n  }\n}\n\nsink {\n  Doris {\n    fenodes = \"x.x.x.x:9999\"\n    username = \"u\"\n    password = \"p\"\n    database = \"bd_seb_test\"\n    table = \"t_ds_task_instance_backup\"\n    sink.label-prefix = \"mysql_to_doris\" \n    sink.enable-2pc = \"false\"\n    doris.batch.size = 500000\n    sink.buffer-size = 104857600\n    sink.max-retries = 5\n    doris.config = {\n      format = \"json\"                             \n      read_json_by_line = \"true\"         \n    }\n  }\n}\n```", "Streaming task from Kafka to Doris\n\n```\nenv {\n  parallelism = 4 # It is recommended to adjust according to the number of Kafka partitions, keeping it consistent with the partition count\n  job.mode = \"STREAMING\"\n  checkpoint.interval = 30000\n  checkpoint.timeout = 600000\n  # Your current rate limits seem high but reasonable, ~700MB/s\n  read_limit.bytes_per_second=700000000\n  read_limit.rows_per_second=40000\n}\n\nsource {\n  \n    Kafka {\n      result_table_name = \"kafka_log\"\n      #Kafka server address\n      bootstrap.servers = \"xxxxx\"\n      topic = \"xxxx\"\n      consumer.group = \"kafka2table\"\n      start_mode = \"earliest\"\n      kafka.config = {\n            \"fetch.min.bytes\" = \"1048576\" # 1MB, increase the minimum batch fetch size\n            \"fetch.max.wait.ms\" = \"500\"    # Wait time when data is insufficient\n            \"max.partition.fetch.bytes\" = \"5242880\" # 5MB, maximum data fetch per partition\n            \"max.poll.records\" = \"5000\"     # Maximum number of records per poll\n            \"isolation.level\" = \"read_committed\" # Ensure data consistency\n      }\n      format = json\n      schema={\n        fields={\n            ev=STRING\n            pg=STRING\n            uuid=STRING\n            userId=bigint\n            fromDevice=STRING\n            ip=STRING\n            source=STRING\n            np=STRING\n            lp=STRING\n            tg=STRING\n            ch=STRING\n            v=STRING\n            nt=STRING\n            wifi=STRING\n            dbd=STRING\n            dmd=STRING\n            bs=STRING\n            browser_version=STRING\n            ext=STRING\n            sid=STRING\n            timestamp=bigint\n            reporttime=bigint\n        }\n      }\n  }\n}\n\ntransform {\n  Sql {\n    source_table_name = \"kafka_log\"\n    result_table_name = \"log\"\n    query = \"select ev as event,pg as page,uuid,userId as userid,fromDevice as platform,ip,source,np as nextpage,lp as lastpage,tg as target,ch as channel,v as version,nt as network,wifi,dbd as device_brand,dmd as device_model,bs as browser,browser_version,ext as extra,sid as sessionid,timestamp,reporttime,CURRENT_DATE as dt from kafka_log\"\n  }\n}\n\nsink {\n  \n  Doris {\n    source_table_name = \"log\"\n    \n    fenodes = \"dxxx\"\n    username = xxx\n    password = \"xxxx\"\n    table.identifier = \"ods.ods_log\"\n    sink.label-prefix = \"log\"\n\n    sink.enable-2pc = \"false\"\n    doris.batch.size = 500000\n    sink.buffer-size = 104857600\n    sink.max-retries = 5\n\n    doris.config {\n        format=\"json\"\n        read_json_by_line=\"true\"\n    }\n  }\n}\n\n\n```", "MySQL multiple table cdc to S3 \n\n---------------\n```\nenv {\n  job.name=\"SeaTunnel_job\"\n  job.mode=\"STREAMING\"\n  parallelism = 4\n}\nsource {\n  MySQL-CDC {\n      database-names=[\n          \"wls_t1\"\n      ]\n      table-names=[\n          \"wls_t1.mysqlcdc_to_s3_t3\",\n          \"wls_t1.mysqlcdc_to_s3_t4\",\n          \"wls_t1.mysqlcdc_to_s3_t5\",\n          \"wls_t1.mysqlcdc_to_s3_t1\",\n          \"wls_t1.mysqlcdc_to_s3_t2\"\n      ]\n      password=\"xxxxxx\"\n      username=\"xxxxxxxxxxxxx\"\n      base-url=\"jdbc:mysql://localhost:3306/qa_source\"\n  }\n}\n\ntransform {\n}\n\nsink {\n  S3File {\n    bucket = \"s3a://seatunnel-test\"\n    tmp_path = \"/tmp/seatunnel/${table_name}\"\n    path=\"/test/${table_name}\"\n    fs.s3a.endpoint=\"s3.cn-north-1.amazonaws.com.cn\"\n    fs.s3a.aws.credentials.provider=\"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\"\n    access_key = \"xxxxxxxxxxxxxxxxx\"\n    secret_key = \"xxxxxxxxxxxxxxxxx\"\n    file_format_type = \"orc\"\n    schema_save_mode = \"CREATE_SCHEMA_WHEN_NOT_EXIST\"\n    data_save_mode=\"APPEND_DATA\"\n  }\n}\n```", "MySQL cdc to PostgreSQL\n--------------------\n\n```\nenv {\n  job.mode = \"STREAMING\"\n  job.name = \"DEMO\"\n  parallelism = 3\n  checkpoint.interval = 60000\n  checkpoint.timeout = 180000\n  \n  job.retry.times = 3 \n  job.retry.interval.seconds = 3 # 3s\n}\n\nsource {\n  MySQL-CDC {\n    base-url = \"jdbc:mysql://192.168.8.101:3306/test?serverTimezone=Asia/Shanghai\"\n    username = \"test\"\n    password = \"123456\"\n    \n    database-names = [\"test\"]\n    # table-names = [\"test.test_001\",\"test.test_002\"]\n    table-pattern = \"test\\\\.test_.*\"  # The first dot is a normal string and needs to be escaped; the second dot matches any single character\n    table-names-config = [\n        {\"table\":\"test.test_002\",\"primaryKeys\":[\"id\"]}\n        ]\n    \n    startup.mode = \"initial\" # First perform a full historical sync, then incremental sync\n    snapshot.split.size = \"8096\" \n    snapshot.fetch.size = \"1024\"\n    server-id = \"6500-8500\"\n    connect.timeout.ms = 30000\n    connect.max-retries = 3\n    connection.pool.size = 20\n    # For data analysis scenarios, disable exactly-once consistency, allowing some duplication and loss to improve performance\n    exactly_once = false   \n     # Enable schema evolution to avoid frequent modifications of table fields, but may affect downstream tasks. Supports add, rename, and drop operations.\n    schema-changes.enabled = true \n  }\n}\n\nsink {\n  jdbc {\n        url = \"jdbc:postgresql://192.168.8.101:5432/test\"\n        driver = \"org.postgresql.Driver\"\n        user = \"postgres\"\n        password = \"123456\"\n        \n        generate_sink_sql = true\n        database = \"test\"\n        table = \"public.${table_name}\"\n        schema_save_mode = \"CREATE_SCHEMA_WHEN_NOT_EXIST\"\n        data_save_mode = \"APPEND_DATA\"\n        # enable_upsert = false\n    }\n}\n```\n\n-------------------------------\n\n```\nenv {\n  job.mode = \"STREAMING\"\n  job.name = \"DEMO\"\n  parallelism = 3\n  checkpoint.interval = 30000 # 30s\n  checkpoint.timeout = 30000 # 30s\n  \n  job.retry.times = 3 \n  job.retry.interval.seconds = 3 # 3s\n}\n\nsource {\n  MySQL-CDC {\n    base-url = \"jdbc:mysql://192.168.8.101:3306/test?serverTimezone=Asia/Shanghai\"\n    username = \"test\"\n    password = \"123456\"\n    \n    database-names = [\"test\"]\n    # table-names = [\"test.test_001\",\"test.test_002\"]\n    # ???????????????????????????????????????????????? ????????????????????????1???????????????\n    table-pattern = \"test\\\\.test_.*\"  \n    table-names-config = [\n        {\"table\":\"test.test_002\",\"primaryKeys\":[\"id\"]}\n        ]\n    \n    startup.mode = \"initial\" # ?????????????????????????????????\n    snapshot.split.size = \"8096\" \n    snapshot.fetch.size = \"1024\"\n    server-id = \"6500-8500\"\n    connect.timeout.ms = 30000\n    connect.max-retries = 3\n    connection.pool.size = 20\n     # ???????????????????????????????????????????????????????????????????????? ????????????\n    exactly_once = false  \n    # ???????????? ??????  ???????????????????????????,??????????????????????????????add rename drop \n    schema-changes.enabled = true\n  }\n}\n\nsink {\n  jdbc {\n        url = \"jdbc:postgresql://192.168.8.101:5432/test\"\n        driver = \"org.postgresql.Driver\"\n        user = \"postgres\"\n        password = \"123456\"\n        \n        generate_sink_sql = true\n        database = \"test\"\n        table = \"public.${table_name}\"\n        schema_save_mode = \"CREATE_SCHEMA_WHEN_NOT_EXIST\"\n        data_save_mode = \"APPEND_DATA\"\n        # enable_upsert = false\n    }\n}\n\n```", "Maxcompute batch to PostgreSQL\n---\n```\nenv {\n job.name=\"maxcompute-starrocks\"\n job.mode=\"BATCH\"\n parallelism = 3\n}\nsource {\n  Maxcompute {\n    accessId=\"xxx\"\n    accesskey=\"xxx\"\n    endpoint=\"https://xxx.maxcompute.aliyun.com/api\"\n    project=\"release_v26\"\n    partition_spec=\"year=2025\"\n    table_name=\"fm_mysql_all_type\"\n    schema {\n        fields {\n            \"tinyint_col\" = tinyint\n            \"smallint_col\" = smallint\n            \"int_col\" = int\n            \"year\" = int\n        }\n    }\n  }\n}\nsink {\n StarRocks {\n     updateFieldType=null\n     batch_max_rows=\"102400\"\n     batch_max_bytes=\"524288000\"\n     max_retries=3\n     enable_upsert_delete=\"false\"\n     schema_save_mode=\"RECREATE_SCHEMA\"\n     data_save_mode=\"APPEND_DATA\"\n     http_socket_timeout_ms=180000\n     multi_table_sink_replica=1\n     table=\"fm_mysql_tsz\"\n     database=\"lyc_test\"\n     nodeUrls=[\n         \"datasource01:8050\"\n     ]\n     password=\"xxx\"\n     username=\"xxx\"\n     base-url=\"jdbc:mysql://datasource01:9030/lyc_test\"\n }\n}\n```", "MySQL cdc to Starrocks\n---\n```\nenv {\n  # You can set engine configuration here\n  #parallelism = 4\n  job.mode = \"STREAMING\"\n  checkpoint.interval = 60000\n  checkpoint.timeout=1800000\n  #read_limit.bytes_per_second=7000000\n  #read_limit.rows_per_second=100000\n  job.name = \"mysql_to_starrocks_test\"\n  #job.retry.times=3\n  #job.retry.interval.seconds=30\n}\n\nsource {\n  MySQL-CDC {\n    schema-changes.enabled = true\n    username = \"****\"\n    password = \"****\"\n    base-url = \"jdbc:mysql://****?useUnicode=true&characterEncoding=UTF-8&serverTimezone=GMT%2B8&autoReconnect=true&zeroDateTimeBehavior=convertToNull&useSSL=false\"\n    startup.mode = \"earliest\"\n    server-id = 6671\n    #startup.specific-offset.file = \"mysql-bin.020789\" \n    #startup.specific-offset.pos = \"4\"\n    table-names = [\n       \"test.admin\"\n    ]\n  }\n}\n\ntransform {\n}\n\n\nsink {\n  StarRocks {\n    nodeUrls = [\"*****:8030\"]\n    username = \"****\"\n    password = \"****\"\n    database = \"test\"\n    table = \"ts_${table_name}\"\n    base-url = \"jdbc:mysql://*****:9030/test\"\n    max_retries = 3\n    enable_upsert_delete = true\n    \"schema_save_mode\"=\"RECREATE_SCHEMA\"\n    \"data_save_mode\"=\"DROP_DATA\"\n    save_mode_create_template = \"\"\"\n    CREATE TABLE IF NOT EXISTS test.`${table_name}` (\n        ${rowtype_primary_key},\n        ${rowtype_fields}\n        ) ENGINE=OLAP\n        PRIMARY KEY (${rowtype_primary_key})\n        DISTRIBUTED BY HASH (${rowtype_primary_key})\n        PROPERTIES (\n                \"replication_num\" = \"3\",\n                \"in_memory\" = \"false\",\n                \"enable_persistent_index\" = \"true\",\n                \"replicated_storage\" = \"true\",\n                \"compression\" = \"LZ4\"\n          )\n    \"\"\"\n  }\n\n}\n```", "MySQL cdc to HDFS ????????????????????????????????????????????????", "@wuzhaoyu Can you describe your business requirement much clearly?I can't understand the scenario.\n\n", "PostgreSQL batch to FTP\n\n---\n\n```\nenv { \n  \"job.mode\" = \"BATCH\"\n   parallelism = 4\n} \n\nsource { \n  Jdbc { \n      driver = \"org.postgresql.Driver\" \n      url = \"jdbc:postgresql://xxxx:5432/demo\" \n      user = \"xxxx\" \n      password = \"xxxx\" \n      query = \"select * from demo.\\\"test_read\\\".\\\"order_job_20250101\\\"\" \n      table_path = \"demo.test_read.job_20250101\" \n      result_table_name = \"table0\" \n  } \n}  \n\ntransform { \n  Sql { \n      source_table_name  = \"table0\" \n      result_table_name  = \"table1\" \n      table_transform  =[ \n        { \n          tablePath = \"demo.test_read.job_20250101\" \n          query = \"select * from table0\" \n        }  \n      ]  \n  } \n}  \n\nsink { \n  FtpFile  { \n      host = \"xxxx\" \n      port = \"21\" \n      user = \"xxxx\" \n      password = \"xxxx\" \n      tmp_path  = \"/data/tmp\"\n      path  = \"/data/20250101\"\n      source_table_name = \"table1\" \n      file_format_type = \"text\" \n      custom_filename = true \n      file_name_expression = \"order_job_20250101\" \n      data_save_mode = \"APPEND_DATA\" \n      field_delimiter   = \",\" \n      encoding    = \"UTF-8\" \n      connection_mode = \"PASSIVE_LOCAL_DATA_CONNECTION_MODE\" \n      is_enable_transaction = false \n      compress_codec = \"NONE\" \n      single_file_mode = true \n      create_empty_file_when_no_data = true \n  } \n}  \n```", " MySQL-CDC to S3File\n-------\n```\nenv{\n  parallelism = 1\n  job.mode = \"STREAMING\"\n  checkpoint.interval = 60000\n}\n\nsource {\n  MySQL-CDC {\n   base-url=\"jdbc:mysql://192.168.1.100:3306/wubx\"\n   username=\"wubx\"\n   password=\"wubxwubx\"\n   table-names=[\"wubx.t01\"]\n   startup.mode=\"initial\"\n  }\n}\n\nsink {\n  S3File {\n    bucket = \"s3a://mystage\"\n    tmp_path = \"/tmp/SeaTunnel/${table_name}\"\n    path=\"/mysql/${table_name}\"\n    fs.s3a.endpoint=\"http://192.168.1.100:9900\"\n    fs.s3a.aws.credentials.provider=\"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\"\n    access_key = \"minioadmin\"\n    secret_key = \"minioadmin\"\n    file_format_type=\"json\"\n    schema_save_mode = \"CREATE_SCHEMA_WHEN_NOT_EXIST\"\n    data_save_mode=\"APPEND_DATA\"\n  }\n}\n```", "\nLocalFile batch to PostgreSQL\n\n---\n\n```\nenv {\n    \"job.name\"=\"localfiletopg\"\n    \"job.mode\"=\"BATCH\"\n}\nsource {\n    LocalFile {\n            file_filter_pattern = \"BDC_ceshi1298.csv\" \n            file_format_type = \"CSV\" \n            data_save_mode  = \"CSV\" \n            delimiter   = \",\"\n            read_columns  = [\"n1_b_ak\", \"n2_bak\", \"amm_bak\", \"remarks\"] \n            schema {\n                columns=[\n                    {\n                        name=\"n1_b_ak\"\n                        type=string\n                        \"nullable\"=false\n                    },\n                    {\n                        name=\"n2_bak\"\n                        type=string\n                        \"nullable\"=false\n                    },\n                    {\n                        name=\"amm_bak\"\n                        type=string\n                        \"nullable\"=false\n                    },\n                    {\n                        name=remarks\n                        type=string\n                        \"nullable\"=false\n                    }\n                    ]\n                }\n            path=\"/data/whale_ops/flie/\"\n            \"skip_header_row_number\"=\"1\"\n            encoding= \"UTF-8\" \n    }\n}\nsink { \n  Jdbc { \n      driver = \"org.postgresql.Driver\" \n      url = \"jdbc:postgresql://xxx:5432/qa_sink\" \n      user = \"postgres\" \n      password = \"postgres\" \n      generate_sink_sql = \"true\" \n      enable_upsert  = \"true\" \n      is_primary_key_updated  = \"false\" \n      schema_save_mode  = \"CREATE_SCHEMA_WHEN_NOT_EXIST\" \n      database  = \"qa_sink\" \n      table=\"public.csvtable\" \n      data_save_mode = \"APPEND_DATA\" \n  } \n}\n```\n\n\n[BDC_ceshi1298.csv](https://github.com/user-attachments/files/20104868/BDC_ceshi1298.csv)", "This issue has been automatically marked as stale because it has not had recent activity for 30 days. It will be closed in next 7 days if no further activity occurs." ],
      "repository" : {
        "description" : "SeaTunnel is a next-generation super high-performance, distributed, massive data integration tool.",
        "homepage" : "https://seatunnel.apache.org/",
        "name" : "seatunnel",
        "fullName" : "apache/seatunnel",
        "htmlUrl" : "https://github.com/apache/seatunnel",
        "gitUrl" : "git://github.com/apache/seatunnel.git",
        "sshUrl" : "git@github.com:apache/seatunnel.git",
        "cloneUrl" : "https://github.com/apache/seatunnel.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2019,
        "stargazersCount" : 8638,
        "watchersCount" : 8638,
        "size" : 45875,
        "openIssuesCount" : 709,
        "subscribersCount" : 173,
        "pushedAt" : "2025-07-11T01:39:38Z",
        "languages" : {
          "TypeScript" : 107575,
          "Smarty" : 2206,
          "Java" : 21310081,
          "Dockerfile" : 848,
          "Shell" : 40758,
          "Batchfile" : 24358,
          "SCSS" : 7232,
          "JavaScript" : 12629,
          "HTML" : 1128,
          "Python" : 17770
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to collect and maintain demos of various use cases for Apache SeaTunnel, including MySQL CDC to PostgreSQL, MySQL CDC to Starrocks, MySQL CDC to S3, MySQL CDC to FTP, MySQL CDC to HDFS, MySQL CDC to S3File, LocalFile batch to PostgreSQL, and others, to enrich documentation and help users get started and solve problems.",
      "validationOrRequirement" : "The validation or requirement for this issue is to collect and maintain demos of various use cases, including MySQL CDC to PostgreSQL, MySQL CDC to Starrocks, MySQL CDC to S3, MySQL CDC to FTP, MySQL CDC to HDFS, MySQL CDC to S3File, LocalFile batch to PostgreSQL, and others, to enrich documentation and help users get started and solve problems.",
      "attemptedFixes" : "Several attempts were made to collect and maintain demos, including providing configuration examples for various use cases, sharing Oracle-CDC connection configurations, and explaining how to configure multiple table CDC to S3 and MySQL CDC to Starrocks.",
      "otherNotes" : "This issue is about collecting real-world use case demos for Apache SeaTunnel to enrich documentation and help users get started and solve problems. It involves collecting and maintaining demos of various use cases, including MySQL CDC to PostgreSQL, MySQL CDC to Starrocks, MySQL CDC to S3, MySQL CDC to FTP, MySQL CDC to HDFS, MySQL CDC to S3File, LocalFile batch to PostgreSQL, and others.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282709
  }, {
    "issueDTO" : {
      "id" : 3224530475,
      "title" : "Fix JavaScript lint errors",
      "url" : "https://github.com/stdlib-js/stdlib/issues/7625",
      "repositoryName" : "stdlib-js/stdlib",
      "description" : "  ## JavaScript Linting Failures\n\n  Linting failures were detected in the automated JavaScript lint workflow run.\n\n  ### Workflow Details\n\n  - Run: https://github.com/stdlib-js/stdlib/actions/runs/16231941293\n  - Type: JavaScript Linting\n  - Date: 2025-07-12 00:09:27 UTC\n\n  ### Error Details\n  ```\n  make[1]: Entering directory '/home/runner/work/stdlib/stdlib'\n\nLinting file: lib/node_modules/@stdlib/_tools/eslint/rules/jsdoc-list-item-spacing/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/string/to-well-formed/lib/main.js\n\n/home/runner/work/stdlib/stdlib/lib/node_modules/@stdlib/string/to-well-formed/lib/main.js\n  62:1  warning  This line has a length of 100. Maximum allowed is 80  max-len\n\n??? 1 problem (0 errors, 1 warning)\n\n\nLinting file: lib/node_modules/@stdlib/stats/base/dists/weibull/mean/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/ndarray/base/count-falsy/lib/8d_blocked_accessors.js\n\nLinting file: lib/node_modules/@stdlib/random/base/discrete-uniform/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/datasets/pace-boston-house-prices/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/number/uint32/base/add/lib/main.js\n\nLinting file: lib/node_modules/@stdlib/datasets/fivethirtyeight-ffq/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/ndarray/base/unary-reduce-subarray/lib/7d_blocked.js\n\nLinting file: lib/node_modules/@stdlib/stats/strided/smeanli/lib/ndarray.native.js\n\nLinting file: lib/node_modules/@stdlib/blas/base/dswap/lib/ndarray.native.js\n\nLinting file: lib/node_modules/@stdlib/plot/ctor/lib/props/x-num-ticks/set.js\n\nLinting file: lib/node_modules/@stdlib/math/base/special/cphasef/lib/main.js\n\nLinting file: lib/node_modules/@stdlib/plot/sparklines/unicode/column/lib/props/y-max/set.js\n\nLinting file: lib/node_modules/@stdlib/blas/ext/base/dsapxsum/lib/native.js\n\nLinting file: lib/node_modules/@stdlib/ndarray/base/every/lib/2d_blocked_complex.js\n\nLinting file: lib/node_modules/@stdlib/stats/base/dists/pareto-type1/mean/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/plot/hist/lib/render/svg/sync.js\nmake[1]: Leaving directory '/home/runner/work/stdlib/stdlib'\n  ```\n\n  ### Pull Request Instructions\n\n  -   Please use the following PR title format:\n  \"chore: fix JavaScript lint errors (issue #<ISSUE_NUMBER>)\".\n  -   Reference this issue in the \"Related Issues\" section of the PR body as \"resolves #<ISSUE_NUMBER>\".\n",
      "updatedAt" : 1752278978.000000000,
      "user" : "stdlib-bot",
      "userHtmlUrl" : "https://github.com/stdlib-bot",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82920195?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "# :wave: Important: PLEASE READ :wave:\n\nThis issue has been labeled as a **good first issue** and is available for anyone to work on.\n\nIf this is your first time contributing to an open source project, some aspects of the development process may seem unusual, arcane, or some combination of both.\n\n1.  **You cannot \"claim\" issues.** People new to open source often want to \"claim\" or be assigned an issue before beginning work. The typical rationale is that people want to avoid wasted work in the event that someone else ends up working the issue. However, this practice is not effective in open source, as it often leads to \"issue squatting\", in which an individual asks to be assigned, is granted their request, and then never ends up working on the issue. Accordingly, you are encouraged to communicate your intent to address this issue, ideally by providing a rough outline as to how you plan to address the issue or asking clarifying questions, but, at the end of the day, we will take running code and rough consensus in order to move forward quickly.\n2.  **We have a very high bar for contributions.** We have very high standards for contributions and expect all contributions???whether new features, tests, or documentation???to be rigorous, thorough, and complete. Once a pull request is merged into stdlib, that contribution immediately becomes the collective responsibility of all maintainers of stdlib. When we merge code into stdlib, we are saying that we, the maintainers, commit to reviewing subsequent changes and making bugfixes to the code. Hence, in order to ensure future maintainability, this naturally leads to a higher standard of contribution.\n\nBefore working on this issue and opening a pull request, please read the project's [contributing guidelines](https://github.com/stdlib-js/stdlib/blob/develop/CONTRIBUTING.md). These guidelines and the associated [development guide](https://github.com/stdlib-js/stdlib/blob/develop/docs/contributing/development.md) provide important information, including links to stdlib's [Code of Conduct](https://github.com/stdlib-js/stdlib/blob/develop/CODE_OF_CONDUCT.md), license policy, and steps for setting up your local development environment.\n\nTo reiterate, we **strongly** encourage you to refer to our contributing guides **before** beginning work on this issue. Failure to follow our guidelines significantly decreases the likelihood that you'll successfully contribute to stdlib and may result in automatic closure of a pull request without review.\n\nSetting up your local development environment is a critical first step, as doing so ensures that automated development processes for linting, license verification, and unit testing can run prior to authoring commits and pushing changes. If you would prefer to avoid manual setup, we provide pre-configured [development containers](https://github.com/stdlib-js/stdlib/tree/develop/.devcontainer) for use locally or in GitHub Codespaces.\n\nWe place a high value on consistency throughout the stdlib codebase. We encourage you to closely examine other packages in stdlib and attempt to emulate the practices and conventions found therein.\n\n-   If you are attempting to contribute a new package, sometimes the best approach is to simply copy the contents of an existing package and then modify the minimum amount necessary to implement the feature (e.g., changing descriptions, parameter names, and implementation).\n-   If you are contributing tests, find a package implementing a similar feature and emulate the tests of that package.\n-   If you are updating documentation, examine several similar packages and emulate the content, style, and prose of those packages.\n\nIn short, the more effort you put in to ensure that your contribution looks and feels like stdlib???including variables names, bracket spacing, line breaks, etc???the more likely that your contribution will be reviewed and ultimately accepted. We encourage you to closely study the codebase **before** beginning work on this issue.\n\n:sparkles: Thank you again for your interest in stdlib, and we look forward to reviewing your future contributions. :sparkles:\n" ],
      "repository" : {
        "description" : "??? Standard library for JavaScript and Node.js. ???",
        "homepage" : "https://stdlib.io",
        "name" : "stdlib",
        "fullName" : "stdlib-js/stdlib",
        "htmlUrl" : "https://github.com/stdlib-js/stdlib",
        "gitUrl" : "git://github.com/stdlib-js/stdlib.git",
        "sshUrl" : "git@github.com:stdlib-js/stdlib.git",
        "cloneUrl" : "https://github.com/stdlib-js/stdlib.git",
        "owner" : {
          "login" : "stdlib-js",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 843,
        "stargazersCount" : 5263,
        "watchersCount" : 5263,
        "size" : 2119351,
        "openIssuesCount" : 833,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-11T22:10:54Z",
        "languages" : {
          "C++" : 322679,
          "CSS" : 50680,
          "C" : 44265210,
          "WebAssembly" : 205765,
          "HTML" : 55717,
          "Fortran" : 365806,
          "TypeScript" : 31139318,
          "Julia" : 5682,
          "Shell" : 213507,
          "R" : 5700,
          "Awk" : 3608,
          "JavaScript" : 135406211,
          "Python" : 8521226
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix JavaScript lint errors in the automated JavaScript lint workflow run.",
      "validationOrRequirement" : "Please use the following PR title format: chore: fix JavaScript lint errors (issue #<ISSUE_NUMBER>). Reference this issue in the Related Issues section of the PR body as resolves #<ISSUE_NUMBER>.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description.",
      "otherNotes" : "This issue has been labeled as a good first issue and is available for anyone to work on. Please refer to the contributing guidelines and development guide before beginning work on this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282714
  }, {
    "issueDTO" : {
      "id" : 3224527354,
      "title" : "Address commit comments (commit `e6823fe`)",
      "url" : "https://github.com/stdlib-js/stdlib/issues/7624",
      "repositoryName" : "stdlib-js/stdlib",
      "description" : "This commit has **1** comment(s) from core contributors that require attention.\n\n**Commit:** [e6823fe95a468d4c981dffb05dbc04149e15083d](https://github.com/stdlib-js/stdlib/commit/e6823fe95a468d4c981dffb05dbc04149e15083d)\n\n**Comments:**\n\n-   https://github.com/stdlib-js/stdlib/commit/e6823fe95a468d4c981dffb05dbc04149e15083d#r161979382\n\n    > @stdlib-bot Should be `bench( pkg+'::native', opts, function benchmark( b ) {`\n\n    https://github.com/stdlib-js/stdlib/blob/e6823fe95a468d4c981dffb05dbc04149e15083d/lib/node_modules/@stdlib/stats/base/dists/signrank/pdf/benchmark/benchmark.native.js#L-3-L3\n\nInterested in helping improve the project? If you are, the comment linked to above has **1** comment(s) from core contributors that could use your attention.\n\nWhat do you need to do?\n\n1.  Open the above linked comments mentioning @stdlib-bot.\n2.  Review the suggested changes or follow-up tasks (e.g., formatting improvements, small refactorings, or clean-up).\n3.  If you are a first-time contributor, follow the [contributing](https://github.com/stdlib-js/stdlib/blob/develop/CONTRIBUTING.md) and [development](https://github.com/stdlib-js/stdlib/blob/develop/docs/contributing/development.md) guides to setup your local environment for contributing to stdlib. If you are already a seasoned stdlib contributor, create a new branch on your local fork for making the changes.\n4.  Make all the desired changes and commit those changes to a local branch.\n5.  Push the changes to GitHub and open a new pull request against the `develop` branch of the main stdlib development [repository](https://github.com/stdlib-js/stdlib).\n\nOnce you've opened a pull request, a stdlib maintainer will review your work and suggest any follow-up changes.\n\nAnd that's it!\n\nThank you for your help in reducing the project backlog and in improving the quality of stdlib. \uD83D\uDE4C\n\n* * *\n\n## Notes\n\n-  When creating your pull request, please use the following format for the PR title:\n\n   ```\n   chore: address commit comments for commit `e6823fe` (issue #NNNN)\n   ```\n\n   where `NNNN` is the issue number assigned to this issue.\n\n-  For older commits, there is a chance that comments will have been already been addressed due to other refactorings. If you find that to be true, don't worry! Just move on to addressing the next comment, and, when opening your pull request and describing your proposed changes, be sure to link to the comment and mention that it has been addressed. This will help reviewers when reviewing your code!\n\n* * *\n\nThis issue was created automatically to address commit comments tagging @stdlib-bot.",
      "updatedAt" : 1752278849.000000000,
      "user" : "stdlib-bot",
      "userHtmlUrl" : "https://github.com/stdlib-bot",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82920195?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "# :wave: Important: PLEASE READ :wave:\n\nThis issue has been labeled as a **good first issue** and is available for anyone to work on.\n\nIf this is your first time contributing to an open source project, some aspects of the development process may seem unusual, arcane, or some combination of both.\n\n1.  **You cannot \"claim\" issues.** People new to open source often want to \"claim\" or be assigned an issue before beginning work. The typical rationale is that people want to avoid wasted work in the event that someone else ends up working the issue. However, this practice is not effective in open source, as it often leads to \"issue squatting\", in which an individual asks to be assigned, is granted their request, and then never ends up working on the issue. Accordingly, you are encouraged to communicate your intent to address this issue, ideally by providing a rough outline as to how you plan to address the issue or asking clarifying questions, but, at the end of the day, we will take running code and rough consensus in order to move forward quickly.\n2.  **We have a very high bar for contributions.** We have very high standards for contributions and expect all contributions???whether new features, tests, or documentation???to be rigorous, thorough, and complete. Once a pull request is merged into stdlib, that contribution immediately becomes the collective responsibility of all maintainers of stdlib. When we merge code into stdlib, we are saying that we, the maintainers, commit to reviewing subsequent changes and making bugfixes to the code. Hence, in order to ensure future maintainability, this naturally leads to a higher standard of contribution.\n\nBefore working on this issue and opening a pull request, please read the project's [contributing guidelines](https://github.com/stdlib-js/stdlib/blob/develop/CONTRIBUTING.md). These guidelines and the associated [development guide](https://github.com/stdlib-js/stdlib/blob/develop/docs/contributing/development.md) provide important information, including links to stdlib's [Code of Conduct](https://github.com/stdlib-js/stdlib/blob/develop/CODE_OF_CONDUCT.md), license policy, and steps for setting up your local development environment.\n\nTo reiterate, we **strongly** encourage you to refer to our contributing guides **before** beginning work on this issue. Failure to follow our guidelines significantly decreases the likelihood that you'll successfully contribute to stdlib and may result in automatic closure of a pull request without review.\n\nSetting up your local development environment is a critical first step, as doing so ensures that automated development processes for linting, license verification, and unit testing can run prior to authoring commits and pushing changes. If you would prefer to avoid manual setup, we provide pre-configured [development containers](https://github.com/stdlib-js/stdlib/tree/develop/.devcontainer) for use locally or in GitHub Codespaces.\n\nWe place a high value on consistency throughout the stdlib codebase. We encourage you to closely examine other packages in stdlib and attempt to emulate the practices and conventions found therein.\n\n-   If you are attempting to contribute a new package, sometimes the best approach is to simply copy the contents of an existing package and then modify the minimum amount necessary to implement the feature (e.g., changing descriptions, parameter names, and implementation).\n-   If you are contributing tests, find a package implementing a similar feature and emulate the tests of that package.\n-   If you are updating documentation, examine several similar packages and emulate the content, style, and prose of those packages.\n\nIn short, the more effort you put in to ensure that your contribution looks and feels like stdlib???including variables names, bracket spacing, line breaks, etc???the more likely that your contribution will be reviewed and ultimately accepted. We encourage you to closely study the codebase **before** beginning work on this issue.\n\n:sparkles: Thank you again for your interest in stdlib, and we look forward to reviewing your future contributions. :sparkles:\n" ],
      "repository" : {
        "description" : "??? Standard library for JavaScript and Node.js. ???",
        "homepage" : "https://stdlib.io",
        "name" : "stdlib",
        "fullName" : "stdlib-js/stdlib",
        "htmlUrl" : "https://github.com/stdlib-js/stdlib",
        "gitUrl" : "git://github.com/stdlib-js/stdlib.git",
        "sshUrl" : "git@github.com:stdlib-js/stdlib.git",
        "cloneUrl" : "https://github.com/stdlib-js/stdlib.git",
        "owner" : {
          "login" : "stdlib-js",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 843,
        "stargazersCount" : 5263,
        "watchersCount" : 5263,
        "size" : 2119351,
        "openIssuesCount" : 833,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-11T22:10:54Z",
        "languages" : {
          "C++" : 322679,
          "CSS" : 50680,
          "C" : 44265210,
          "WebAssembly" : 205765,
          "HTML" : 55717,
          "Fortran" : 365806,
          "TypeScript" : 31139318,
          "Julia" : 5682,
          "Shell" : 213507,
          "R" : 5700,
          "Awk" : 3608,
          "JavaScript" : 135406211,
          "Python" : 8521226
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Address commit comments from core contributors for commit `e6823fe` by reviewing the suggested changes or follow-up tasks, and opening a new pull request against the `develop` branch of the main stdlib development repository.",
      "validationOrRequirement" : "The validation is that the changes should be rigorous, thorough, and complete, and the contributor should follow the project's contributing guidelines and development guide.",
      "attemptedFixes" : "The issue is about addressing commit comments from core contributors, and it requires reviewing the suggested changes or follow-up tasks.",
      "otherNotes" : "When creating your pull request, please use the following format for the PR title: chore: address commit comments for commit `e6823fe` (issue #NNNN).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282719
  }, {
    "issueDTO" : {
      "id" : 3224521823,
      "title" : "Fix EditorConfig lint errors",
      "url" : "https://github.com/stdlib-js/stdlib/issues/7623",
      "repositoryName" : "stdlib-js/stdlib",
      "description" : "## EditorConfig Linting Failures\n\nLinting failures were detected in the automated EditorConfig lint workflow run.\n\n### Workflow Details\n\n- Run: https://github.com/stdlib-js/stdlib/actions/runs/16231941293\n- Type: EditorConfig Linting\n- Date: 2025-07-12 00:04:19 UTC\n\n### Error Details\n\n```\nLinting files for basic formatting errors...\nDownloading v3.3.0\nlib/node_modules/@stdlib/math/strided/special/dmskramp/manifest.json:\n\t2-74: Wrong indent style found (tabs instead of spaces)\n\n1 errors found\nmake: *** [/home/runner/work/stdlib/stdlib/tools/make/lib/lint/editorconfig.mk:90: lint-editorconfig-files] Error 1\n```\n\n### Pull Request Instructions\n\n-   Please use the following PR title format:\n\"chore: fix EditorConfig lint errors (issue #<ISSUE_NUMBER>)\".\n-   Reference this issue in the \"Related Issues\" section of the PR body as \"resolves #<ISSUE_NUMBER>\".\n",
      "updatedAt" : 1752278675.000000000,
      "user" : "stdlib-bot",
      "userHtmlUrl" : "https://github.com/stdlib-bot",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82920195?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "# :wave: Important: PLEASE READ :wave:\n\nThis issue has been labeled as a **good first issue** and is available for anyone to work on.\n\nIf this is your first time contributing to an open source project, some aspects of the development process may seem unusual, arcane, or some combination of both.\n\n1.  **You cannot \"claim\" issues.** People new to open source often want to \"claim\" or be assigned an issue before beginning work. The typical rationale is that people want to avoid wasted work in the event that someone else ends up working the issue. However, this practice is not effective in open source, as it often leads to \"issue squatting\", in which an individual asks to be assigned, is granted their request, and then never ends up working on the issue. Accordingly, you are encouraged to communicate your intent to address this issue, ideally by providing a rough outline as to how you plan to address the issue or asking clarifying questions, but, at the end of the day, we will take running code and rough consensus in order to move forward quickly.\n2.  **We have a very high bar for contributions.** We have very high standards for contributions and expect all contributions???whether new features, tests, or documentation???to be rigorous, thorough, and complete. Once a pull request is merged into stdlib, that contribution immediately becomes the collective responsibility of all maintainers of stdlib. When we merge code into stdlib, we are saying that we, the maintainers, commit to reviewing subsequent changes and making bugfixes to the code. Hence, in order to ensure future maintainability, this naturally leads to a higher standard of contribution.\n\nBefore working on this issue and opening a pull request, please read the project's [contributing guidelines](https://github.com/stdlib-js/stdlib/blob/develop/CONTRIBUTING.md). These guidelines and the associated [development guide](https://github.com/stdlib-js/stdlib/blob/develop/docs/contributing/development.md) provide important information, including links to stdlib's [Code of Conduct](https://github.com/stdlib-js/stdlib/blob/develop/CODE_OF_CONDUCT.md), license policy, and steps for setting up your local development environment.\n\nTo reiterate, we **strongly** encourage you to refer to our contributing guides **before** beginning work on this issue. Failure to follow our guidelines significantly decreases the likelihood that you'll successfully contribute to stdlib and may result in automatic closure of a pull request without review.\n\nSetting up your local development environment is a critical first step, as doing so ensures that automated development processes for linting, license verification, and unit testing can run prior to authoring commits and pushing changes. If you would prefer to avoid manual setup, we provide pre-configured [development containers](https://github.com/stdlib-js/stdlib/tree/develop/.devcontainer) for use locally or in GitHub Codespaces.\n\nWe place a high value on consistency throughout the stdlib codebase. We encourage you to closely examine other packages in stdlib and attempt to emulate the practices and conventions found therein.\n\n-   If you are attempting to contribute a new package, sometimes the best approach is to simply copy the contents of an existing package and then modify the minimum amount necessary to implement the feature (e.g., changing descriptions, parameter names, and implementation).\n-   If you are contributing tests, find a package implementing a similar feature and emulate the tests of that package.\n-   If you are updating documentation, examine several similar packages and emulate the content, style, and prose of those packages.\n\nIn short, the more effort you put in to ensure that your contribution looks and feels like stdlib???including variables names, bracket spacing, line breaks, etc???the more likely that your contribution will be reviewed and ultimately accepted. We encourage you to closely study the codebase **before** beginning work on this issue.\n\n:sparkles: Thank you again for your interest in stdlib, and we look forward to reviewing your future contributions. :sparkles:\n" ],
      "repository" : {
        "description" : "??? Standard library for JavaScript and Node.js. ???",
        "homepage" : "https://stdlib.io",
        "name" : "stdlib",
        "fullName" : "stdlib-js/stdlib",
        "htmlUrl" : "https://github.com/stdlib-js/stdlib",
        "gitUrl" : "git://github.com/stdlib-js/stdlib.git",
        "sshUrl" : "git@github.com:stdlib-js/stdlib.git",
        "cloneUrl" : "https://github.com/stdlib-js/stdlib.git",
        "owner" : {
          "login" : "stdlib-js",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 843,
        "stargazersCount" : 5263,
        "watchersCount" : 5263,
        "size" : 2119351,
        "openIssuesCount" : 833,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-11T22:10:54Z",
        "languages" : {
          "C++" : 322679,
          "CSS" : 50680,
          "C" : 44265210,
          "WebAssembly" : 205765,
          "HTML" : 55717,
          "Fortran" : 365806,
          "TypeScript" : 31139318,
          "Julia" : 5682,
          "Shell" : 213507,
          "R" : 5700,
          "Awk" : 3608,
          "JavaScript" : 135406211,
          "Python" : 8521226
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix EditorConfig lint errors by addressing the wrong indent style found in the manifest.json file",
      "validationOrRequirement" : "The issue requires contributors to use a specific PR title format and reference this issue in the 'Related Issues' section of the PR body.",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "This issue has been labeled as a good first issue and is available for anyone to work on. The issue has specific instructions for contributors, including a high bar for contributions, a requirement to read contributing guidelines, and a need to emulate stdlib's practices and conventions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282723
  }, {
    "issueDTO" : {
      "id" : 3213742841,
      "title" : "Support `SET` in string context",
      "url" : "https://github.com/dolthub/dolt/issues/9469",
      "repositoryName" : "dolthub/dolt",
      "description" : "Similar to this [issue](https://github.com/dolthub/dolt/issues/9426) with `ENUM`s, `SET` types also do not properly convert to strings.\n\nSkipped tests: https://github.com/dolthub/go-mysql-server/pull/3077",
      "updatedAt" : 1752277959.000000000,
      "user" : "jycor",
      "userHtmlUrl" : "https://github.com/jycor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30810879?v=4",
      "labels" : [ "correctness", "good repro", "good first issue", "sql" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Dolt ??? Git for Data",
        "homepage" : "https://www.dolthub.com",
        "name" : "dolt",
        "fullName" : "dolthub/dolt",
        "htmlUrl" : "https://github.com/dolthub/dolt",
        "gitUrl" : "git://github.com/dolthub/dolt.git",
        "sshUrl" : "git@github.com:dolthub/dolt.git",
        "cloneUrl" : "https://github.com/dolthub/dolt.git",
        "owner" : {
          "login" : "dolthub",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 568,
        "stargazersCount" : 18870,
        "watchersCount" : 18870,
        "size" : 155830,
        "openIssuesCount" : 429,
        "subscribersCount" : 116,
        "pushedAt" : "2025-07-11T23:37:55Z",
        "languages" : {
          "C#" : 8841,
          "Java" : 12609,
          "C++" : 2745,
          "C" : 4925,
          "Rust" : 1991,
          "CMake" : 591,
          "Makefile" : 3258,
          "Go" : 15461516,
          "Perl" : 3555,
          "TypeScript" : 2938,
          "Dockerfile" : 578,
          "Shell" : 2668304,
          "R" : 4965,
          "Batchfile" : 521,
          "JavaScript" : 46932,
          "PHP" : 2434,
          "Tcl" : 1569,
          "Ruby" : 2603,
          "Elixir" : 2236,
          "Python" : 11991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support `SET` in string context",
      "validationOrRequirement" : "good repro, good first issue, sql",
      "attemptedFixes" : "Skipped tests: https://github.com/dolthub/go-mysql-server/pull/3077",
      "otherNotes" : "Similar to issue #9426 with ENUMs, SET types do not properly convert to strings.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282726
  }, {
    "issueDTO" : {
      "id" : 3224111167,
      "title" : "Bug: Light Mode - buttons aren't accessible",
      "url" : "https://github.com/pyOpenSci/python-package-guide/issues/533",
      "repositoryName" : "pyOpenSci/python-package-guide",
      "description" : "The css in light mode needs to be fixed for buttons - [see this page](https://www.pyopensci.org/python-package-guide/#a-community-created-guidebook)\n\n\n<img width=\"603\" height=\"298\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/63264185-5810-453b-81a6-9a75493bcc33\" />",
      "updatedAt" : 1752277523.000000000,
      "user" : "lwasser",
      "userHtmlUrl" : "https://github.com/lwasser",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7649194?v=4",
      "labels" : [ "sprintable", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Python packaging made simple. Recommendations & guidance curated by the pyOpenSci community",
        "homepage" : "https://www.pyopensci.org/python-package-guide/",
        "name" : "python-package-guide",
        "fullName" : "pyOpenSci/python-package-guide",
        "htmlUrl" : "https://github.com/pyOpenSci/python-package-guide",
        "gitUrl" : "git://github.com/pyOpenSci/python-package-guide.git",
        "sshUrl" : "git@github.com:pyOpenSci/python-package-guide.git",
        "cloneUrl" : "https://github.com/pyOpenSci/python-package-guide.git",
        "owner" : {
          "login" : "pyOpenSci",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 62,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 150945,
        "openIssuesCount" : 69,
        "subscribersCount" : 14,
        "pushedAt" : "2025-07-11T21:07:22Z",
        "languages" : {
          "CSS" : 10374,
          "TeX" : 1454,
          "JavaScript" : 998,
          "HTML" : 1014,
          "Python" : 31584
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the accessibility of buttons in light mode",
      "validationOrRequirement" : "CSS needs to be fixed for buttons in light mode",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the CSS in light mode for buttons and a link to a specific page is provided for reference.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282729
  }, {
    "issueDTO" : {
      "id" : 577386488,
      "title" : "Dependency Dashboard",
      "url" : "https://github.com/uPortal-Project/uPortal-start/issues/440",
      "repositoryName" : "uPortal-Project/uPortal-start",
      "description" : "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/uPortal-Project/uPortal-start).\n\n## Config Migration Needed\n\n - [ ] <!-- create-config-migration-pr --> Select this checkbox to let Renovate create an automated Config Migration PR.\n\n## Pending Approval\n\nThese branches will be created by Renovate only once you click their checkbox below.\n\n - [ ] <!-- approve-branch=renovate/eslint-plugin-playwright-2.x -->chore(deps): update dependency eslint-plugin-playwright to v2\n - [ ] <!-- approve-branch=renovate/eslint-plugin-sonarjs-3.x -->chore(deps): update dependency eslint-plugin-sonarjs to v3\n - [ ] <!-- approve-branch=renovate/eslint-plugin-unicorn-59.x -->chore(deps): update dependency eslint-plugin-unicorn to v59\n - [ ] <!-- approve-branch=renovate/gradle-8.x -->chore(deps): update dependency gradle to v8\n - [ ] <!-- approve-branch=renovate/major-casserverversion -->fix(deps): update casserverversion to v4 (major) (`org.jasig.cas:cas-server-core`, `org.jasig.cas:cas-server-extension-clearpass`, `org.jasig.cas:cas-server-webapp`)\n - [ ] <!-- approve-branch=renovate/com.sun.xml.bind-jaxb-impl-4.x -->fix(deps): update dependency com.sun.xml.bind:jaxb-impl to v4\n - [ ] <!-- approve-branch=renovate/javax.servlet-javax.servlet-api-4.x -->fix(deps): update dependency javax.servlet:javax.servlet-api to v4\n - [ ] <!-- approve-branch=renovate/major-person-directory -->fix(deps): update dependency org.apereo.service.persondir:person-directory-api to v3\n - [ ] <!-- approve-branch=renovate/major-slf4j-monorepo -->fix(deps): update dependency org.slf4j:slf4j-api to v2\n - [ ] <!-- approve-branch=renovate/major-spring-core -->fix(deps): update dependency org.springframework:spring-jdbc to v6\n - [ ] <!-- approve-branch=renovate/major-vue-monorepo -->fix(deps): update dependency org.webjars.npm:vue to v3\n - [ ] <!-- approve-branch=renovate/major-plutoversion -->fix(deps): update plutoversion to v3 (major) (`org.apache.portals.pluto:pluto-testsuite`, `org.apache.portals.pluto:pluto-util`, `org.apache.portals.pluto:pluto-taglib`, `org.apache.portals.pluto:pluto-container-driver-api`, `org.apache.portals.pluto:pluto-container-api`)\n - [ ] <!-- approve-all-pending-prs -->\uD83D\uDD10 **Create all pending approval PRs at once** \uD83D\uDD10\n\n## Rate-Limited\n\nThese updates are currently rate-limited. Click on a checkbox below to force their creation now.\n\n - [ ] <!-- unlimit-branch=renovate/newsreaderportletversion -->fix(deps): update dependency org.jasig.portlet:newsreaderportlet to v5.1.1\n - [ ] <!-- unlimit-branch=renovate/eslint-monorepo -->chore(deps): update dependency eslint to ~9.31.0\n - [ ] <!-- unlimit-branch=renovate/eslint-plugin-no-jquery-3.x -->chore(deps): update dependency eslint-plugin-no-jquery to ~3.1.0\n - [ ] <!-- unlimit-branch=renovate/eslint-plugin-playwright-1.x -->chore(deps): update dependency eslint-plugin-playwright to ~1.8.0\n - [ ] <!-- unlimit-branch=renovate/prettier-3.x -->chore(deps): update dependency prettier to ~3.6.0\n - [ ] <!-- unlimit-branch=renovate/typescript-5.x -->chore(deps): update dependency typescript to ~5.8.0\n - [ ] <!-- unlimit-branch=renovate/com.github.node-gradle.node-7.x -->chore(deps): update plugin com.github.node-gradle.node to v7.1.0\n - [ ] <!-- unlimit-branch=renovate/typescript-eslint-monorepo -->chore(deps): update typescript-eslint monorepo to ~8.36.0 (`@typescript-eslint/eslint-plugin`, `@typescript-eslint/parser`)\n - [ ] <!-- unlimit-branch=renovate/cascommonscodecversion -->fix(deps): update dependency commons-codec:commons-codec to v1.18.0\n - [ ] <!-- unlimit-branch=renovate/org.easymock-easymock-5.x -->fix(deps): update dependency org.easymock:easymock to v5.6.0\n - [ ] <!-- create-all-rate-limited-prs -->\uD83D\uDD10 **Create all rate-limited PRs at once** \uD83D\uDD10\n\n\n---\n\n> [!WARNING]\n> Renovate failed to look up the following dependencies: `Failed to look up maven package javax.ccpp:ccpp`.\n> \n> Files affected: `gradle.properties`\n\n---\n\n\n## Open\n\nThese updates have all been created already. Click a checkbox below to force a retry/rebase of any.\n\n - [ ] <!-- rebase-branch=renovate/com.sun.xml.bind-jaxb-impl-2.x -->[fix(deps): update dependency com.sun.xml.bind:jaxb-impl to v2.3.9](../pull/637)\n - [ ] <!-- rebase-branch=renovate/org.aspectj-aspectjrt-1.x -->[fix(deps): update dependency org.aspectj:aspectjrt to v1.9.24](../pull/639)\n - [ ] <!-- rebase-branch=renovate/org.aspectj-aspectjweaver-1.x -->[fix(deps): update dependency org.aspectj:aspectjweaver to v1.9.24](../pull/640)\n - [ ] <!-- rebase-branch=renovate/casxercesimplversion -->[fix(deps): update dependency xerces:xercesimpl to v2.12.2](../pull/559)\n - [ ] <!-- rebase-branch=renovate/uportal-web-components -->[fix(deps): update uportal web components to v1.40.2](../pull/657) (`org.webjars.npm:uportal__waffle-menu`, `org.webjars.npm:uportal__esco-content-menu`, `org.webjars.npm:uportal__content-carousel`)\n - [ ] <!-- rebase-branch=renovate/playwright-monorepo -->[chore(deps): update dependency @playwright/test to ~1.54.0](../pull/577)\n - [ ] <!-- rebase-branch=renovate/javax.servlet-javax.servlet-api-3.x -->[fix(deps): update dependency javax.servlet:javax.servlet-api to v3.1.0](../pull/494)\n - [ ] <!-- rebase-branch=renovate/resource-server -->[fix(deps): update dependency org.jasig.resourceserver:resource-server-webapp to v1.5.0](../pull/542)\n - [ ] <!-- rebase-branch=renovate/hsqldbversion -->[fix(deps): update hsqldbversion to v2.7.4](../pull/537) (`org.hsqldb:sqltool`, `org.hsqldb:hsqldb`)\n - [ ] <!-- rebase-branch=renovate/adoptopenjdk-11.x -->[chore(deps): update adoptopenjdk docker tag to v11](../pull/614)\n - [ ] <!-- rebase-branch=renovate/less-4.x -->[chore(deps): update dependency less to v4](../pull/673)\n - [ ] <!-- rebase-branch=renovate/major-gradledockerpluginversion -->[fix(deps): update dependency com.bmuschko:gradle-docker-plugin to v6](../pull/548)\n - [ ] <!-- rebase-branch=renovate/major-tomcatversion -->[fix(deps): update dependency org.apache.tomcat:tomcat to v11](../pull/547)\n - [ ] <!-- rebase-all-open-prs -->**Click on this checkbox to rebase all open PRs at once**\n\n## Detected dependencies\n\n<details><summary>dockerfile</summary>\n<blockquote>\n\n<details><summary>docker/Dockerfile</summary>\n\n - `adoptopenjdk 8-jdk-hotspot`\n\n</details>\n\n<details><summary>docker/Dockerfile-cli</summary>\n\n - `gradle 6.9.1-jdk8-hotspot`\n\n</details>\n\n<details><summary>docker/Dockerfile-demo</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>github-actions</summary>\n<blockquote>\n\n<details><summary>.github/workflows/CI.yml</summary>\n\n - `actions/checkout v4`\n - `actions/setup-java v4`\n - `gradle/actions v4`\n - `gradle/actions v4`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>gradle</summary>\n<blockquote>\n\n<details><summary>gradle.properties</summary>\n\n - `javax.servlet:javax.servlet-api 3.0.1`\n - `org.apache.portals:portlet-api_2.1.0_spec 1.0`\n - `org.hsqldb:hsqldb 2.5.1`\n - `org.hsqldb:sqltool 2.5.1`\n - `org.apache.tomcat:tomcat 8.5.100`\n - `javax.ccpp:ccpp 1.0`\n - `org.apache.portals.pluto:pluto-container-api 2.1.0-M3`\n - `org.apache.portals.pluto:pluto-container-driver-api 2.1.0-M3`\n - `org.apache.portals.pluto:pluto-taglib 2.1.0-M3`\n - `org.apereo.service.persondir:person-directory-api 1.8.16`\n - `com.bmuschko:gradle-docker-plugin 3.2.4`\n - `org.jasypt:jasypt 1.9.3`\n - `org.apache.portals.pluto:pluto-util 2.1.0-M3`\n - `org.jasig.portal:uPortal-tools 5.17.1`\n - `org.jasig.portal:uPortal-groups-filesystem 5.17.1`\n - `org.jasig.portal:uPortal-groups-grouper 5.17.1`\n - `org.jasig.portal:uPortal-groups-ldap 5.17.1`\n - `org.jasig.portal:uPortal-groups-local 5.17.1`\n - `org.jasig.portal:uPortal-groups-smartldap 5.17.1`\n - `org.jasig.portal:uPortal-portlets 5.17.1`\n - `org.jasig.portal:uPortal-security-authn 5.17.1`\n - `org.jasig.portal:uPortal-security-xslt 5.17.1`\n - `org.jasig.portal:uPortal-soffit-connector 5.17.1`\n - `org.jasig.portal:uPortal-utils-jmx 5.17.1`\n - `org.jasig.portlet:Announcements 2.5.0`\n - `org.jasig.portal:uPortal-hibernate3-dialects 5.17.1`\n - `org.jasig.portlet:BookmarksPortlet 1.3.0`\n - `org.jasig.portlet:CalendarPortlet 2.7.0`\n - `org.jasig.portlet:FeedbackPortlet 1.3.0`\n - `org.jasig.portlet:FunctionalTestsPortlet 1.1.4`\n - `org.jasig.portlet:NewsReaderPortlet 5.1.0`\n - `org.jasig.portlet.notification:notification-portlet-webapp 4.8.0`\n - `org.jasig.resourceserver:resource-server-webapp 1.0.48`\n - `org.jasig.portlet.simplecontent:SimpleContentPortlet 3.4.0`\n - `org.jasig.portal:uPortal-hibernate4-dialects 5.17.1`\n - `org.jasig.portlet.proxy:WebProxyPortlet 2.4.0`\n - `org.jasig.portlet:basiclti-portlet 1.5.0`\n - `commons-dbcp:commons-dbcp 1.4`\n - `net.sf.ehcache:ehcache-core 2.6.11`\n - `org.jasig.cas:cas-server-webapp 3.6.0`\n - `org.jasig.cas:cas-server-extension-clearpass 3.6.0`\n - `xerces:xercesImpl 2.12.1`\n - `commons-codec:commons-codec 1.17.1`\n - `commons-collections:commons-collections 3.2.2`\n - `org.slf4j:slf4j-api 1.7.36`\n - `org.jasig.cas:cas-server-core 3.6.0`\n - `org.springframework:spring-jdbc 3.2.18.RELEASE`\n - `org.jasig.portlet:cas-proxy-test-portlet 1.0.2`\n - `org.esupportail.portlet.filemanager:esup-filemanager 4.0.0`\n - `org.jasig.portlet:jasig-widget-portlets 2.4.0`\n - `org.apache.portals.pluto:pluto-testsuite 2.1.0-M3`\n - `org.jasig.resourceserver:resource-server-webapp 1.5.0`\n - `org.webjars.npm:vue 2.7.16`\n - `org.webjars.npm:uportal__api-template-vue 1.40.1`\n - `org.webjars.npm:uportal__content-carousel 1.40.1`\n - `org.webjars.npm:uportal__esco-content-menu 1.40.1`\n - `org.webjars.npm:uportal__waffle-menu 1.40.1`\n - `org.webjars.npm:uportal__notification-banner 1.0.4`\n - `org.webjars.npm:uportal__notification-icon 1.0.4`\n - `org.webjars.npm:uportal__notification-list 1.0.4`\n - `org.webjars.npm:uportal__notification-modal 1.0.4`\n - `org.jasig.portal:uPortal-webapp 5.17.1`\n\n</details>\n\n<details><summary>settings.gradle</summary>\n\n\n</details>\n\n<details><summary>build.gradle</summary>\n\n - `net.foragerr.jmeter 1.1.0-4.0`\n - `com.github.node-gradle.node 7.0.2`\n\n</details>\n\n<details><summary>buildSrc/build.gradle</summary>\n\n\n</details>\n\n<details><summary>gradle/tasks/docker.gradle</summary>\n\n\n</details>\n\n<details><summary>gradle/tasks/hsql.gradle</summary>\n\n\n</details>\n\n<details><summary>gradle/tasks/perf.gradle</summary>\n\n\n</details>\n\n<details><summary>gradle/tasks/playwright.gradle</summary>\n\n\n</details>\n\n<details><summary>gradle/tasks/portal.gradle</summary>\n\n\n</details>\n\n<details><summary>gradle/tasks/portlet.gradle</summary>\n\n\n</details>\n\n<details><summary>gradle/tasks/properties.gradle</summary>\n\n\n</details>\n\n<details><summary>gradle/tasks/tomcat.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/Announcements/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/BookmarksPortlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/CalendarPortlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/FeedbackPortlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/FunctionalTestsPortlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/NewsReaderPortlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/NotificationPortlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/ResourceServingWebapp/build.gradle</summary>\n\n - `javax.xml.bind:jaxb-api 2.3.1`\n - `com.sun.xml.bind:jaxb-impl 2.3.3`\n\n</details>\n\n<details><summary>overlays/SimpleContentPortlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/WebProxyPortlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/basiclti-portlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/cas/build.gradle</summary>\n\n - `org.aspectj:aspectjrt 1.9.7`\n - `org.aspectj:aspectjweaver 1.9.7`\n - `junit:junit 4.13.2`\n - `org.easymock:easymock 5.3.0`\n\n</details>\n\n<details><summary>overlays/cas-proxy-test-portlet/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/esup-filemanager/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/jasig-widget-portlets/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/pluto-testsuite/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/resource-server/build.gradle</summary>\n\n\n</details>\n\n<details><summary>overlays/uPortal/build.gradle</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>gradle-wrapper</summary>\n<blockquote>\n\n<details><summary>gradle/wrapper/gradle-wrapper.properties</summary>\n\n - `gradle 6.9.4`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>npm</summary>\n<blockquote>\n\n<details><summary>overlays/uPortal/package.json</summary>\n\n - `less ^3.13.0`\n\n</details>\n\n<details><summary>package.json</summary>\n\n - `@playwright/test ~1.23.0`\n - `@typescript-eslint/eslint-plugin ~8.6.0`\n - `@typescript-eslint/parser ~8.6.0`\n - `eslint ~9.10.0`\n - `eslint-plugin-no-jquery ~3.0.0`\n - `eslint-plugin-playwright ~1.6.0`\n - `eslint-plugin-sonarjs ~2.0.0`\n - `eslint-plugin-unicorn ~55.0.0`\n - `prettier ~3.3.0`\n - `type-coverage ~2.29.0`\n - `typescript ~5.6.0`\n\n</details>\n\n</blockquote>\n</details>\n\n---\n\n- [ ] <!-- manual job -->Check this box to trigger a request for Renovate to run again on this repository\n\n",
      "updatedAt" : 1752277376.000000000,
      "user" : "renovate[bot]",
      "userHtmlUrl" : "https://github.com/apps/renovate",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/2740?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "CLI tools for implementing uPortal, beginning with version 5.0.0",
        "homepage" : "",
        "name" : "uPortal-start",
        "fullName" : "uPortal-Project/uPortal-start",
        "htmlUrl" : "https://github.com/uPortal-Project/uPortal-start",
        "gitUrl" : "git://github.com/uPortal-Project/uPortal-start.git",
        "sshUrl" : "git@github.com:uPortal-Project/uPortal-start.git",
        "cloneUrl" : "https://github.com/uPortal-Project/uPortal-start.git",
        "owner" : {
          "login" : "uPortal-Project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 53,
        "stargazersCount" : 19,
        "watchersCount" : 19,
        "size" : 131445,
        "openIssuesCount" : 53,
        "subscribersCount" : 26,
        "pushedAt" : "2025-07-10T12:49:45Z",
        "languages" : {
          "TypeScript" : 38425,
          "Java" : 34777,
          "Dockerfile" : 941,
          "CSS" : 7053,
          "Shell" : 1930,
          "Batchfile" : 2150,
          "JavaScript" : 1341,
          "Groovy" : 17847,
          "Less" : 12006
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to manage dependencies and updates in the uPortal-Project/uPortal-start repository using Renovate.",
      "validationOrRequirement" : "The issue requires the creation of automated Config Migration PRs, approval of pending branches, and creation of rate-limited PRs. It also mentions the need to rebase open PRs.",
      "attemptedFixes" : "The issue mentions that Renovate failed to look up the following dependencies: `Failed to look up maven package javax.ccpp:ccpp`. It also includes various configurations, rate-limited updates, and open updates.",
      "otherNotes" : "This issue is about Dependency Dashboard, which lists Renovate updates and detected dependencies. It includes various configurations, rate-limited updates, and open updates. The issue also mentions failed lookups for dependencies and provides information about the detected dependencies.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282735
  }, {
    "issueDTO" : {
      "id" : 3223415981,
      "title" : "[FEAT] Implement retry mechanism for Telegram flood limits",
      "url" : "https://github.com/EverythingSuckz/TG-FileStreamBot/issues/174",
      "repositoryName" : "EverythingSuckz/TG-FileStreamBot",
      "description" : "English\n\nHello developer, I found some problems during my use, I hope you can take a look and see if it can be solved. When sending or forwarding a media group (eight photos or videos), only one or two files can be properly converted to a link, while the rest will report an error of [ Error - rpcDoRequst: rpc error code: 420: Flood_Wait (2)]I am using version 3.1.0 of the Go language, thank you for your hard work, please check if it can be resolved.\n\n---\n\n??????\n\n????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????Error - rpcDoRequest: rpc error code 420: FLOOD_WAIT (2)??????????????????GO????????????3.1.0??????????????????????????????????????????????????????",
      "updatedAt" : 1752277303.000000000,
      "user" : "yanjie233",
      "userHtmlUrl" : "https://github.com/yanjie233",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/130467849?v=4",
      "labels" : [ "inspecting", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "![Screenshot_2025-07-11-23-49-50-030_org.telegram.messenger-edit.jpg](https://github.com/user-attachments/assets/f8c75e28-64a1-4bf4-9897-9d44d444bdeb)\n\nThis is a screenshot of the problem. I hope it can help you reproduce the problem and try to fix it.\n\nMy Telegram bot ID is [@TGfile_888_BOT](https://t.me/TGfile_888_BOT)", "Hey @yanjie233, thanks for reporting.\n\nThat error is from Telegram and isn???t something caused by the bot itself. Basically, they rate-limit bots if too many requests happen too quickly. The rpc error code: `420: FLOOD_WAIT` just means Telegram blocked further requests for a short time.\n\nNothing much I can do about it. Telegram kinda messes around with these limits randomly too, sometimes it works fine, sometimes it doesn???t.\n\nSo yeah, basically it's not fixable from my side, Sorry. You???ll just have to wait a bit before trying again.\n\n---\nFeel free to close this issue if you think it's helpful.", "Indeed, I also found that the problem is from the telegram. This problem did not occur when using the early version of the Python branch. Is it that the delay mechanism was added early? In fact, you can try adding a delay mechanism to counter this error. What do you think?\n\nThank you for replying to my question, regardless of whether the problem can be solved or not!??????", "> Indeed, I also found that the problem is from the telegram. This problem did not occur when using the early version of the Python branch. Is it that the delay mechanism was added early? In fact, you can try adding a delay mechanism to counter this error. What do you think?\n> \n> Thank you for replying to my question, regardless of whether the problem can be solved or not!??????\n\nYeah, I get what you mean. I actually thought about adding something like that. It???s just that I???ve been busy with my IRL job lately. There are a bunch of other feature requests too, but I???ll try to work on this when I get some free time.", "Thank you, actually I want to try to fix it myself, but I'm not very good at Go language, so I need to rely on AI to do it.\n\nThank you for patiently reading my opinion and adopting it, thank you, and I wish you happiness every day~???" ],
      "repository" : {
        "description" : "A telegram bot that will give instant stream links for telegram files without the need of waiting till the download completes.",
        "homepage" : "",
        "name" : "TG-FileStreamBot",
        "fullName" : "EverythingSuckz/TG-FileStreamBot",
        "htmlUrl" : "https://github.com/EverythingSuckz/TG-FileStreamBot",
        "gitUrl" : "git://github.com/EverythingSuckz/TG-FileStreamBot.git",
        "sshUrl" : "git@github.com:EverythingSuckz/TG-FileStreamBot.git",
        "cloneUrl" : "https://github.com/EverythingSuckz/TG-FileStreamBot.git",
        "owner" : {
          "login" : "EverythingSuckz",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1436,
        "stargazersCount" : 1550,
        "watchersCount" : 1550,
        "size" : 406,
        "openIssuesCount" : 32,
        "subscribersCount" : 23,
        "pushedAt" : "2025-04-28T20:46:47Z",
        "languages" : {
          "Dockerfile" : 308,
          "Procfile" : 12,
          "Go" : 46591
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a retry mechanism for Telegram flood limits to allow the bot to properly convert media groups into links.",
      "validationOrRequirement" : "The issue requires a retry mechanism that can handle Telegram's flood limits and rate-limits. The author suggests that the delay mechanism was added early in the Python branch.",
      "attemptedFixes" : "The author and the commenter have discussed adding a delay mechanism to fix the issue, but it's been put on hold due to the author's busy schedule.",
      "otherNotes" : "The issue is related to Telegram flood limits and the bot's retry mechanism. The author suggests adding a delay mechanism to counter the error.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282740
  }, {
    "issueDTO" : {
      "id" : 1526611020,
      "title" : "Add: overview about .citation.cff files on GitHub",
      "url" : "https://github.com/pyOpenSci/python-package-guide/issues/34",
      "repositoryName" : "pyOpenSci/python-package-guide",
      "description" : "This issue involves writing new text about this file in our guidebook. It is beginner friendly in that you could complete this totally on the github GUI or even in a hackmd document and we can help you with the PR if you aren't a github user! \n\nAdd information about the citation.cff file to the [license page](https://www.pyopensci.org/python-package-guide/documentation/repository-files/license-files.html):\n\n- [ ] how .cff files work - what they add to the repo\n- [ ] how dates are tracked in this file\n- [ ] how they integrate into / with zenodo",
      "updatedAt" : 1752276601.000000000,
      "user" : "lwasser",
      "userHtmlUrl" : "https://github.com/lwasser",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7649194?v=4",
      "labels" : [ "sprintable", "new-content", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "What is a CITATION.cff file?\nA CITATION.cff file is a simple, human- and machine-readable file (written in YAML format) that you add to the root of your repository. Its main purpose is to tell others how to cite your software correctly. When you include a CITATION.cff file, GitHub will automatically show a ???Cite this repository??? button, making it easy for users to find the citation information.\n\nWhat does a CITATION.cff file add to your repository?\nCitation Instructions: It provides clear instructions on how to cite your work.\nMetadata: It contains important metadata about your project, such as authors, title, version, and more.\nMachine Readability: Citation tools and services (like GitHub and Zenodo) can read this file to generate standardized citation formats automatically.\nHow are dates tracked in CITATION.cff?\nThe CITATION.cff file can include fields such as date-released (and optionally, date-created and date-modified). These dates help others know when your code was published, and they are included in citations generated from the file.\n\nExample:\n\nYAML\ndate-released: \"2024-06-01\"\nHow does CITATION.cff integrate with Zenodo?\nZenodo is a popular service for archiving research outputs and assigning DOIs (Digital Object Identifiers). When you connect your GitHub repository to Zenodo, Zenodo reads the CITATION.cff file (if present) and uses the metadata to create accurate citations for each version it archives. This ensures consistency and saves you time, as you only need to maintain your citation info in one place.\n\nIn summary:\nAdding a CITATION.cff file to your repository helps others cite your work properly, tracks important dates, and ensures your citations are up-to-date and consistent across platforms like GitHub and Zenodo.", "@all-contributors please add @SanketKumarKar for code", "@lwasser \n\nI've put up [a pull request](https://github.com/pyOpenSci/python-package-guide/pull/516) to add @SanketKumarKar! :tada:", "hey there @SanketKumarKar this looks like a great start to this issue. Are you open to submitting a pull request for it? We can then have folks in our community review.\n\nI also don't recall if you wanted to be invited to our slack community. If you do, I can invite you (i just need an email) and we can discuss the pr further there if you'd like some support in submitting it. Please let me know! ", "The next steps in this issue is to evaluate / review the text above. We likely want to edit/enhance it to match the tone of our guide. Then we can add it to the guide as a formal pull request. \n\nI think we also want to add some context around the file and link to an example of it. ", "We can then add a citation.cff file to our package example repo [here](https://github.com/pyOpenSci/pyospackage) and link to it as an example from the guide. (i'll make a separate issue in the pyospackage repo)" ],
      "repository" : {
        "description" : "Python packaging made simple. Recommendations & guidance curated by the pyOpenSci community",
        "homepage" : "https://www.pyopensci.org/python-package-guide/",
        "name" : "python-package-guide",
        "fullName" : "pyOpenSci/python-package-guide",
        "htmlUrl" : "https://github.com/pyOpenSci/python-package-guide",
        "gitUrl" : "git://github.com/pyOpenSci/python-package-guide.git",
        "sshUrl" : "git@github.com:pyOpenSci/python-package-guide.git",
        "cloneUrl" : "https://github.com/pyOpenSci/python-package-guide.git",
        "owner" : {
          "login" : "pyOpenSci",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 62,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 150945,
        "openIssuesCount" : 69,
        "subscribersCount" : 14,
        "pushedAt" : "2025-07-11T21:07:22Z",
        "languages" : {
          "CSS" : 10374,
          "TeX" : 1454,
          "JavaScript" : 998,
          "HTML" : 1014,
          "Python" : 31584
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add an overview about .citation.cff files on GitHub, specifically adding information about how they work, how dates are tracked, and how they integrate with Zenodo, and adding a pull request for the text.",
      "validationOrRequirement" : "The issue requires adding information about the citation.cff file to the license page, specifically covering how .cff files work, how dates are tracked, and how they integrate with Zenodo.",
      "attemptedFixes" : "The author has put up a pull request to add the contributor @SanketKumarKar. The next steps involve evaluating and reviewing the text, editing/enhancing it to match the tone of the guide, and adding it to the guide as a formal pull request.",
      "otherNotes" : "The issue involves adding new text about the .citation.cff file in the guidebook, specifically about how .cff files work, how dates are tracked, and how they integrate with Zenodo. The issue also mentions adding a pull request for the text and inviting the contributor to the slack community.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282747
  }, {
    "issueDTO" : {
      "id" : 770516959,
      "title" : "Refactor: Extract component resources into <component>/resources.ts",
      "url" : "https://github.com/Esri/calcite-design-system/issues/1419",
      "repositoryName" : "Esri/calcite-design-system",
      "description" : "## Summary <!-- pain point -->\n\nFor reusability between tests and components, CSS, SLOTS, ~TEXT~ (no longer applicable after [built-in localization was introduced](https://github.com/Esri/calcite-design-system/issues/4961)), and additional resources should be extracted into a supporting `<calcite-component>/resources.ts` file.\n\n### Notes\n\n* deprecated components should be skipped\n* defining `ICON` const is optional\n\n## Measure of Success <!-- desired outcome -->\n\n- [ ] extract applicable entries (CSS, slots, ~text~, ~values [if applicable]~) to component resources file\n- [ ] Share resources between wherever applicable (component, tests, stories)\n- [ ] ~Rename existing `resources.ts` to `<component-name>.resources.ts`~ ???  dropped in favor of conciseness in imports. Unlike other `<component-name>.<type>.<extension>` files, resource files are imported in one or multiple files.\n- [ ] Update [conventions file](https://github.com/Esri/calcite-design-system/blob/main/packages/calcite-components/conventions/README.md)\n\n### Which Component\n\n- [x] `accordion` \n- [x] `accordion-item` \n- [x] `action`\n- [x] `action-bar`\n- [x] `action-group`\n- [x] `action-menu` \n- [x] `action-pad`\n- [x] `alert`\n- [x] `avatar`\n- [x] `block`\n- [x] `block-section`\n- [x] `button`\n- [ ] `card`\n- [ ] `card-group`\n- [x] `checkbox`\n- [x] `chip`\n- [ ] `chip-group`\n- [x] `color-picker`\n- [x] `color-picker-hex-input`\n- [x] `color-picker-swatch`\n- [ ] `combobox`\n- [x] `combobox-item`\n- [x] `combobox-item-group`\n- [x] `date-picker`\n- [ ] `date-picker-day`\n- [x] `date-picker-month-header`\n- [x] `date-picker-month`\n- [ ] `dropdown`\n- [x] `dropdown-group`\n- [x] `dropdown-item`\n- [x] `fab`\n- [x] `filter`\n- [x] `flow`\n- [x] `flow-item`\n- [x] functional\n    - [x] ExpandToggle\n    - [x] FloatingArrow\n    - [x] Heading\n    - [x] XButton\n- [x] `graph` \n- [x] `handle`\n- [x] `icon`\n- [x] `inline-editable`\n- [x] `input`\n- [x] `input-date-picker`\n- [ ] `input-message`\n- [x] `input-number`\n- [x] `input-text`\n- [x] `input-time-picker`\n- [x] `input-time-zone`\n- [x] `label`\n- [ ] `link`\n- [x] `list`\n- [x] `list-item`\n- [x] `list-item-group`\n- [x] `loader`\n- [x] `menu`\n- [ ] `menu-item` (`SLOTS` object only)\n- [x] `meter`\n- [x] `modal` (deprecated)\n- [x] `navigation`\n- [x] `navigation-logo`\n- [x] `navigation-user`\n- [x] `notice`\n- [x] `option`\n- [x] `option-group`\n- [x] `pagination`\n- [x] `panel`\n- [x] `popover` \n- [ ] `progress`\n- [x] `radio-button`\n- [x] `radio-group`\n- [x] `radio-group-item`\n- [ ] `rating` \n- [x] `scrim` \n- [x] `segmented-control`\n- [x] `segmented-control-item`\n- [x] `select`\n- [x] `sheet` \n- [x] `shell` \n- [x] `shell-center-row` \n- [x] `shell-panel`\n- [x] `slider`\n- [x] `split-button`\n- [x] `stack`\n- [x] `stepper`\n- [ ] `stepper-item`\n- [x] `switch`\n- [x] `tab`\n- [x] `tab-nav`\n- [x] `tab-title`\n- [x] `table`\n- [x] `table-header`\n- [x] `table-row`\n- [x] `table-cell`\n- [x] `tabs`\n- [x] `text-area`\n- [x] `tile`\n- [x] `tile-group`\n- [x] `tile-select` (deprecated)\n- [x] `tile-select-group` (deprecated)\n- [x] `time-picker`\n- [x] `tip` (deprecated)\n- [x] `tip-group` (deprecated)\n- [x] `tip-manager` (deprecated)\n- [x] `tooltip`\n- [x] `tree`\n- [x] `tree-item`\n\n\n### Resources <!--(e.g. links to libraries or code snippets)-->\n\nExamples: \n\n* tests: https://github.com/Esri/calcite-components/blob/master/src/components/calcite-color/calcite-color.e2e.ts#L635-L637\n* between components: https://github.com/Esri/calcite-components/blob/master/src/components/calcite-value-list-item/calcite-value-list-item.tsx#L15",
      "updatedAt" : 1752276507.000000000,
      "user" : "jcfranco",
      "userHtmlUrl" : "https://github.com/jcfranco",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/197440?v=4",
      "labels" : [ "estimate - 3", "3 - installed", "spike complete", "epic", "good first issue", "refactor", "p - low" ],
      "state" : "OPEN",
      "comments" : [ "This one valid?", "Will revisit this once https://github.com/Esri/calcite-components/issues/2913 lands.", "Split up the effort by individual components to determine effort needed across the components.\r\n\r\nOnce the individual breakdown is setup, could be a `good first issue` and with a lower effort, likely an `estimate-2`.", "I assume these are divided on a per-component basis, even within nested parent-child relationship trees? We won't be consolidating resources for those, right? \r\n\r\nEg. `tab, tabs, tab-nav, tab-title` could all share `.content` or `.container` if we opt to combine their resources. \r\n\r\nI think these should either have individual resources or share one common file, or else we'll end up importing 2 files, which seems messy.\r\n\r\n@geospatialem How should I approach the task of dividing these into individual components to assess the required effort across each component? Should I be transforming this issue into an epic? ", "> How should I approach the task of dividing these into individual components to assess the required effort across each component? Should I be transforming this issue into an epic?\r\n\r\nSummarizing our Teams discussion. Will approach this issue as a means to organize the component audit, and was it needed across the design system. Updated the issue summary above to include a list of all components, including functional components, for inclusion of the audit, targeted for January.\r\n\r\ncc: @Elijbet \r\n\r\n\r\n\r\n", "Spike to confirm across components which need to be addressed, and which are already following the expected/anticipated pattern.", "Updated list with remaining components. \r\n\r\n**Findings**\r\n\r\n* Remaining components are mostly to introduce `CSS` and `SLOTS` (1 occurrence) lookup objects\r\n* ?????? should be used to update components and E2E tests (stories no longer need to be updated as we have dedicated test stories that use static HTML scenarios)\r\n* We no longer need to worry about `TEXT` after adding built-in translation support. ", "cc  @geospatialem, @brittneytewks", "Installed and assigned for verification.", "@jcfranco Any input/guidance on how to go about verifying these changes? \n\nAlso, @Amretasre002762670 are the components that are not checked off meant to be excluded from the changes or is the list just not updated? For example in the [PR]([refactor: extract component resources into resources.ts #12442](https://github.com/Esri/calcite-design-system/pull/12442)) I see changes for `card-group` but not `card` and neither of them are check off the list. ", "> [@jcfranco](https://github.com/jcfranco) Any input/guidance on how to go about verifying these changes?\n> \n> Also, [@Amretasre002762670](https://github.com/Amretasre002762670) are the components that are not checked off meant to be excluded from the changes or is the list just not updated? For example in the [PR]([refactor: extract component resources into resources.ts #12442](https://github.com/Esri/calcite-design-system/pull/12442)) I see changes for `card-group` but not `card` and neither of them are check off the list.\n\nThe list was not updated, so I focused on components that are not deprecated. I also ignored the functional components." ],
      "repository" : {
        "description" : "A monorepo containing the packages for Esri's Calcite Design System",
        "homepage" : "https://developers.arcgis.com/calcite-design-system/",
        "name" : "calcite-design-system",
        "fullName" : "Esri/calcite-design-system",
        "htmlUrl" : "https://github.com/Esri/calcite-design-system",
        "gitUrl" : "git://github.com/Esri/calcite-design-system.git",
        "sshUrl" : "git@github.com:Esri/calcite-design-system.git",
        "cloneUrl" : "https://github.com/Esri/calcite-design-system.git",
        "owner" : {
          "login" : "Esri",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 79,
        "stargazersCount" : 324,
        "watchersCount" : 324,
        "size" : 353570,
        "openIssuesCount" : 797,
        "subscribersCount" : 248,
        "pushedAt" : "2025-07-11T23:43:00Z",
        "languages" : {
          "TypeScript" : 5777880,
          "MDX" : 3481,
          "Shell" : 5608,
          "CSS" : 3562,
          "SCSS" : 499290,
          "JavaScript" : 45742,
          "HTML" : 5951657
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor: Extract component resources into <component>/resources.ts file for reusability between tests and components, CSS, SLOTS, and additional resources.",
      "validationOrRequirement" : "Components to be audited include functional components. Non-deprecated components should be included, and functional components should be ignored.",
      "attemptedFixes" : "Spike to confirm across components which need to be addressed, and which are already following the expected/anticipated pattern.",
      "otherNotes" : "Components to be audited include functional components. The task involves dividing the effort by individual components to determine the effort needed across the components. The list was not updated, so the focus was on non-deprecated components and ignoring functional components.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282752
  }, {
    "issueDTO" : {
      "id" : 2559137924,
      "title" : "Inconsistent handling of dates before 01.01.1900",
      "url" : "https://github.com/abap2xlsx/abap2xlsx/issues/1275",
      "repositoryName" : "abap2xlsx/abap2xlsx",
      "description" : "Hi,\r\n\r\ncurrently absp2xlsx handles ???invalid??? Excel dates (dates before 01.01.1900) different on the import and on the export side. \r\nI want to convert an ALV to a CSV file using abap2xlsx. If the data contains such a date, converting the ALV to Excel works without problem. But exporting it to CSV fails. \r\nIn my opinion, this is inconsistent. What do you think? \r\n\r\nBest regards,\r\nOliver\r\n\r\n```abap\r\nPARAMETERS p_path TYPE string LOWER CASE.\r\n\r\nINITIALIZATION.\r\n  cl_gui_frontend_services=>get_sapgui_workdir( CHANGING sapworkdir = p_path ).\r\n  cl_gui_cfw=>flush( ).\r\n\r\nSTART-OF-SELECTION.\r\n  TYPES tt_sflight TYPE STANDARD TABLE OF sflight WITH EMPTY KEY.\r\n\r\n  DATA(gt_sflight) = VALUE tt_sflight(\r\n      ( carrid = 'AA' connid = 1 fldate = '20000101'  )\r\n      ( carrid = 'AA' connid = 1 fldate = '18000101'  ) ).\r\n  cl_salv_table=>factory( IMPORTING r_salv_table = DATA(lo_salv)\r\n                          CHANGING  t_table      = gt_sflight ).\r\n  cl_salv_bs_runtime_info=>set( display  = abap_false\r\n                                metadata = abap_false\r\n                                data     = abap_false ).\r\n  lo_salv->display( ).\r\n\r\n  DATA(lo_converter) = NEW zcl_excel_converter( ).\r\n  DATA(lo_excel) = NEW zcl_excel( ).\r\n  lo_converter->convert( EXPORTING io_alv       = lo_salv\r\n                                   it_table     = gt_sflight\r\n                         CHANGING  co_excel     = lo_excel ).\r\n\r\n  DATA(lo_excel_writer) = CAST zif_excel_writer( NEW zcl_excel_writer_csv( ) ).\r\n  DATA(lv_file) = lo_excel_writer->write_file( lo_excel ).\r\n\r\n  DATA(lt_file_tab) = cl_bcs_convert=>xstring_to_solix( lv_file ).\r\n  cl_gui_frontend_services=>gui_download( EXPORTING bin_filesize = xstrlen( lv_file )\r\n                                                    filename     = p_path && '\\Sheet1.csv'\r\n                                                    filetype     = 'BIN'\r\n                                          CHANGING  data_tab     = lt_file_tab ).\r\n``` ",
      "updatedAt" : 1752276393.000000000,
      "user" : "oliver-huetkoeper",
      "userHtmlUrl" : "https://github.com/oliver-huetkoeper",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8492855?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Do you have a screenshot with the differences?", "> Do you have a screenshot with the differences?\r\n\r\nThe converter creates negative numbers from such a date. The CSV writer raises an exception if the number is negative.\r\nMethod date_to_excel_string vs. excel_string_to_date in class zcl_excel_common.", "Result of the program above ([Sheet1.csv](https://github.com/user-attachments/files/17210480/Sheet1.csv)):\r\n![image](https://github.com/user-attachments/assets/273c1dcc-16c4-413a-a48e-0677367857fe)\r\n\r\n(36526 is the Excel date number representing the YYYYMMDD date `20000101`, -36523 is for `18000101`)", "Obviously, a bug to be fixed. It must have been here for a long time; my 2 cents that it originates from ancient modifications of `zcl_excel_worksheet=>set_cell` concerning \"data type\" and \"value type\" notions (which I never clearly understood). In the program above, `zcl_excel_writer_csv` receives an empty data type for date and number fields, but the class expects \"D\" for date fields (there's also a crazy logic which tests the field names to determine the data type).", "It looks like the texts of domain XUDATFM changed in newer systems:\r\nNW 7.40: DD.MM.YYYY\r\nNW 7.52: DD.MM.YYYY (Gregorian Date).\r\n\r\nThis breaks the crazy date identification logic.\r\nI implemented a fix, which is part of https://github.com/abap2xlsx/abap2xlsx/pull/1268\r\n\r\nNow the demo program also dumps in newer systems ;)\r\nSo what is your opinion on the invalid date handling on import/export side?", "1) I think @oliver-huetkoeper was using 'E' as system-language and @sandraros did not.\r\nThat is why @oliver-huetkoeper got an exception and @sandraros got a result with negative values.\r\n\r\nThere is the following code in method create_csv\r\n```abap\r\n* --- Retrieve SAP date format\r\n  CLEAR ls_format.\r\n  SELECT ddtext INTO ls_format-attvalue FROM dd07t WHERE domname    = 'XUDATFM'\r\n                                                     AND ddlanguage = sy-langu.     \"THIS IS WRONG\r\n    ls_format-cmpname = 'DATE'.\r\n    CONDENSE ls_format-attvalue.\r\n    CONCATENATE '''' ls_format-attvalue '''' INTO ls_format-attvalue.\r\n    APPEND ls_format TO lt_format.\r\n  ENDSELECT.\r\n```\r\n\r\nPlease refer to method zcl_excel_worksheet->GET_DEFAULT_EXCEL_DATE_FORMAT:\r\nThere you find the following code:\r\n```abap\r\n      cl_abap_datfm=>get_date_format_des( EXPORTING im_langu = c_lang_e\r\n                                          IMPORTING ex_dateformat = default_excel_date_format ).\r\n```\r\n\r\nThe date formats like 'DD.MM.YYYY' and similar corresponds to english language only and should be read in english above, too.\r\n\r\n2) After this fix we get always the exception. With issue #703 some code was added in zcl_excel_common->EXCEL_STRING_TO_DATE. Of course this is correct for normal excel output. But perhaps we should add a flag IP_PERMIT_NEGATIVE to be used from method create_csv only. Then the lower boundary to check is -693596 (01.01.0000)", "@darnoc312 you are right regarding the language bug. I also discovered it and there is a fix for this in my pull request as well. \r\nI was not sure if English is always correct. Therefore I SELECT now with sy-langu and with E.", "In my opinion only language 'E' makes sense, because excel itself can not deal with 'JJJJ' or 'AAAA' as synonym for year in the format code. But you could argue to permit sy-langu because of backwards compatibility for csv only. So far the local date format was detected as date for csv although it does not work for excel. But if you like the possibility to switch the writer in your application program this may be another hidden problem. May @sandraros decide.", "> 1. I think @oliver-huetkoeper was using 'E' as system-language and @sandraros did not.\r\n>    That is why @oliver-huetkoeper got an exception and @sandraros got a result with negative values.\r\n> \r\n> There is the following code in method create_csv\r\n> \r\n> ```abap\r\n> * --- Retrieve SAP date format\r\n>   CLEAR ls_format.\r\n>   SELECT ddtext INTO ls_format-attvalue FROM dd07t WHERE domname    = 'XUDATFM'\r\n>                                                      AND ddlanguage = sy-langu.     \"THIS IS WRONG\r\n>     ls_format-cmpname = 'DATE'.\r\n>     CONDENSE ls_format-attvalue.\r\n>     CONCATENATE '''' ls_format-attvalue '''' INTO ls_format-attvalue.\r\n>     APPEND ls_format TO lt_format.\r\n>   ENDSELECT.\r\n> ```\r\n> \r\n> Please refer to method zcl_excel_worksheet->GET_DEFAULT_EXCEL_DATE_FORMAT: There you find the following code:\r\n> \r\n> ```abap\r\n>       cl_abap_datfm=>get_date_format_des( EXPORTING im_langu = c_lang_e\r\n>                                           IMPORTING ex_dateformat = default_excel_date_format ).\r\n> ```\r\n> \r\n> The date formats like 'DD.MM.YYYY' and similar corresponds to english language only and should be read in english above, too.\r\n> \r\n> 2. After this fix we get always the exception. With issue [zcl_excel_common=>excel_string_to_date returns wrong value when cell was empty??#703](https://github.com/abap2xlsx/abap2xlsx/issues/703) some code was added in zcl_excel_common->EXCEL_STRING_TO_DATE. Of course this is correct for normal excel output. But perhaps we should add a flag IP_PERMIT_NEGATIVE to be used from method create_csv only. Then the lower boundary to check is -693596 (01.01.0000)\r\n\r\nLooking at the code introduced with https://github.com/abap2xlsx/abap2xlsx/issues/703 it is basically the check statement at the beginning that solved the issue back then. \r\nTherefore I would propose to simply extend the valid value range and do not introduce a new parameter. Or do you see any need to restrict this to only valid Excel dates?", "The `date_to_excel_string` method correctly handles dates before 1900 by producing negative numbers (like -36523 for 18000101), but `excel_string_to_date` has validation that rejects negative values `zcl_excel_common.clas.abap:895-897` .\n\n### CSV Writer Issue\nThe CSV writer calls `excel_string_to_date` when processing date cells `zcl_excel_writer_csv.clas.abap:275` , which throws an exception for the negative values that represent pre-1900 dates.\n\n### Proposed Solutions\nBased on the discussion in the issue, there are two main approaches:\n\n### Option 1: Add a Parameter to Allow Negative Values\nAdd an `ip_permit_negative` parameter to `excel_string_to_date` that the CSV writer can use to bypass the validation for negative values. The lower boundary would be -693596 (representing 01.01.0000).\n\n### Option 2: Extend the Valid Range (Recommended)\nSimply extend the valid value range in `excel_string_to_date` to accept negative values without requiring a new parameter. This would make the behavior consistent across all writers.\n\n### Implementation\nThe fix should modify the validation in `excel_string_to_date` to accept a wider range of values. \nCurrently it checks:\n`IF lv_date_int NOT BETWEEN 1 AND 2958465.`\n\nThis should be changed to allow negative values down to approximately -693596 (representing year 0000).\n\nCan anyone confirm if this is correct? " ],
      "repository" : {
        "description" : "Generate your professional Excel spreadsheet from ABAP",
        "homepage" : "https://abap2xlsx.github.io/abap2xlsx/",
        "name" : "abap2xlsx",
        "fullName" : "abap2xlsx/abap2xlsx",
        "htmlUrl" : "https://github.com/abap2xlsx/abap2xlsx",
        "gitUrl" : "git://github.com/abap2xlsx/abap2xlsx.git",
        "sshUrl" : "git@github.com:abap2xlsx/abap2xlsx.git",
        "cloneUrl" : "https://github.com/abap2xlsx/abap2xlsx.git",
        "owner" : {
          "login" : "abap2xlsx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 301,
        "stargazersCount" : 786,
        "watchersCount" : 786,
        "size" : 26314,
        "openIssuesCount" : 129,
        "subscribersCount" : 72,
        "pushedAt" : "2025-07-06T09:22:44Z",
        "languages" : {
          "JavaScript" : 312,
          "ABAP" : 1723539
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Inconsistent handling of dates before 01.01.1900. The converter creates negative numbers from such a date. The CSV writer raises an exception if the number is negative.",
      "validationOrRequirement" : "The CSV writer calls `excel_string_to_date` when processing date cells, which throws an exception for the negative values that represent pre-1900 dates., There is the following code in method create_csv, The date formats like 'DD.MM.YYYY' and similar corresponds to english language only and should be read in english above, too., Add an `ip_permit_negative` parameter to `excel_string_to_date` that the CSV writer can use to bypass the validation for negative values, or simply extend the valid value range in `excel_string_to_date` to accept negative values without requiring a new parameter.",
      "attemptedFixes" : "A fix was implemented which is part of https://github.com/abap2xlsx/abap2xlsx/pull/1268, There is the following code in method create_csv, The date formats like 'DD.MM.YYYY' and similar corresponds to english language only and should be read in english above, too., The `date_to_excel_string` method correctly handles dates before 1900 by producing negative numbers (like -36523 for 18000101), but `excel_string_to_date` has validation that rejects negative values.",
      "otherNotes" : "The converter creates negative numbers from such a date. The CSV writer raises an exception if the number is negative. Method date_to_excel_string vs. excel_string_to_date in class zcl_excel_common., The date formats like 'DD.MM.YYYY' and similar corresponds to english language only and should be read in english above, too.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282764
  }, {
    "issueDTO" : {
      "id" : 3206142489,
      "title" : "[CHORE]: Achieve 100% doctest coverage and add Makefile and CI/CD targets for doctest and coverage",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/249",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "### \uD83E\uDDED Chore Summary\n\nImplement **comprehensive doctest coverage** across the entire codebase: `make doctest` and drive coverage to **100%** while keeping *all* tests green and ensuring every public function/method/class has executable documentation examples.\n\n---\n\n### \uD83E\uDDF1 Areas Affected\n\n* [x] Pre-commit hooks / linters\n* [x] Build system / Make targets (`make doctest`, `make doctest-verbose`, `make doctest-coverage`, `make pre-commit`)\n* [x] GitHub Actions / CI pipeline\n* [x] Runtime codebase (docstrings, examples, edge cases, error handling)\n* [x] Documentation generation (Sphinx integration)\n\n---\n\n### ?????? Context / Rationale\n\nDoctest ensures that **documentation stays synchronized with code**. Every example in docstrings becomes an executable test, catching API changes, parameter mismatches, and stale documentation *before* they confuse users. This creates living documentation that's always accurate and serves as both usage examples and regression tests.\n\n**What is Doctest?**\nDoctest searches for text that looks like interactive Python sessions in docstrings, then executes those sessions to verify that they work exactly as shown.\n\n**Simple Example:**\n```python\ndef add_numbers(a, b):\n    \"\"\"Add two numbers together.\n    \n    >>> add_numbers(2, 3)\n    5\n    >>> add_numbers(-1, 1)\n    0\n    >>> add_numbers(0, 0)\n    0\n    \"\"\"\n    return a + b\n```\n\n**More Complex Example with Error Handling:**\n```python\ndef divide_safely(numerator, denominator):\n    \"\"\"Divide two numbers with proper error handling.\n    \n    Basic division:\n    >>> divide_safely(10, 2)\n    5.0\n    >>> divide_safely(7, 3)\n    2.3333333333333335\n    \n    Edge cases:\n    >>> divide_safely(0, 5)\n    0.0\n    >>> divide_safely(5, 0)\n    Traceback (most recent call last):\n        ...\n    ValueError: Cannot divide by zero\n    \n    Type validation:\n    >>> divide_safely(\"10\", 2)\n    Traceback (most recent call last):\n        ...\n    TypeError: Numerator must be a number\n    \"\"\"\n    if not isinstance(numerator, (int, float)):\n        raise TypeError(\"Numerator must be a number\")\n    if not isinstance(denominator, (int, float)):\n        raise TypeError(\"Denominator must be a number\")\n    if denominator == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return float(numerator) / float(denominator)\n```\n\n**Advanced Example with State and Objects:**\n```python\nclass BankAccount:\n    \"\"\"A simple bank account with deposits and withdrawals.\n    \n    Create account:\n    >>> account = BankAccount(\"Alice\", 100)\n    >>> account.owner\n    'Alice'\n    >>> account.balance\n    100\n    \n    Deposit money:\n    >>> account.deposit(50)\n    >>> account.balance\n    150\n    \n    Withdraw money:\n    >>> account.withdraw(30)\n    >>> account.balance\n    120\n    \n    Overdraft protection:\n    >>> account.withdraw(200)\n    Traceback (most recent call last):\n        ...\n    ValueError: Insufficient funds\n    \n    Transaction history:\n    >>> len(account.transactions)\n    3\n    >>> account.transactions[0]\n    'Deposit: +50'\n    \"\"\"\n    def __init__(self, owner, initial_balance=0):\n        self.owner = owner\n        self.balance = initial_balance\n        self.transactions = []\n    \n    def deposit(self, amount):\n        self.balance += amount\n        self.transactions.append(f\"Deposit: +{amount}\")\n    \n    def withdraw(self, amount):\n        if amount > self.balance:\n            raise ValueError(\"Insufficient funds\")\n        self.balance -= amount\n        self.transactions.append(f\"Withdrawal: -{amount}\")\n```\n\n**MCP Gateway Specific Examples:**\n\n```python\nclass MCPConnection:\n    \"\"\"Manages connection state to an MCP server.\n    \n    Initialize connection:\n    >>> conn = MCPConnection(\"ws://localhost:8080\", timeout=30)\n    >>> conn.url\n    'ws://localhost:8080'\n    >>> conn.timeout\n    30\n    >>> conn.is_connected\n    False\n    \n    Connection lifecycle:\n    >>> conn.connect()  # doctest: +SKIP\n    >>> conn.is_connected  # doctest: +SKIP\n    True\n    >>> conn.ping()  # doctest: +SKIP\n    'pong'\n    \n    Error handling:\n    >>> conn = MCPConnection(\"invalid-url\")\n    >>> conn.validate_url()\n    Traceback (most recent call last):\n        ...\n    ValueError: Invalid WebSocket URL format\n    \n    Connection metrics:\n    >>> conn.get_stats()\n    {'messages_sent': 0, 'messages_received': 0, 'uptime': 0}\n    \"\"\"\n    def __init__(self, url, timeout=10):\n        self.url = url\n        self.timeout = timeout\n        self.is_connected = False\n        self._stats = {'messages_sent': 0, 'messages_received': 0, 'uptime': 0}\n    \n    def validate_url(self):\n        if not self.url.startswith(('ws://', 'wss://')):\n            raise ValueError(\"Invalid WebSocket URL format\")\n    \n    def get_stats(self):\n        return self._stats.copy()\n\nclass RequestRouter:\n    \"\"\"Routes requests to appropriate MCP servers based on patterns.\n    \n    Setup router:\n    >>> router = RequestRouter()\n    >>> router.add_route(\"/api/v1/*\", \"server1\")\n    >>> router.add_route(\"/tools/*\", \"server2\") \n    >>> len(router.routes)\n    2\n    \n    Route matching:\n    >>> router.match_route(\"/api/v1/users\")\n    'server1'\n    >>> router.match_route(\"/tools/calculator\")\n    'server2'\n    >>> router.match_route(\"/unknown/path\")\n    \n    Route conflicts:\n    >>> router.add_route(\"/api/v1/*\", \"server3\")\n    Traceback (most recent call last):\n        ...\n    ValueError: Route pattern '/api/v1/*' already exists\n    \n    Pattern validation:\n    >>> router.add_route(\"invalid-pattern\", \"server4\")\n    Traceback (most recent call last):\n        ...\n    ValueError: Route pattern must start with '/'\n    \"\"\"\n    def __init__(self):\n        self.routes = {}\n    \n    def add_route(self, pattern, server_id):\n        if not pattern.startswith('/'):\n            raise ValueError(\"Route pattern must start with '/'\")\n        if pattern in self.routes:\n            raise ValueError(f\"Route pattern '{pattern}' already exists\")\n        self.routes[pattern] = server_id\n    \n    def match_route(self, path):\n        for pattern, server_id in self.routes.items():\n            if self._matches_pattern(path, pattern):\n                return server_id\n        return None\n    \n    def _matches_pattern(self, path, pattern):\n        if pattern.endswith('*'):\n            return path.startswith(pattern[:-1])\n        return path == pattern\n```\n\n---\n\n### \uD83D\uDCE6 Related Make Targets\n\n| Target                     | Purpose                                                              |\n| -------------------------- | -------------------------------------------------------------------- |\n| **`make doctest`**         | Run doctest on all modules with summary report                      |\n| **`make doctest-verbose`** | Run doctest with detailed output (`-v` flag)                        |\n| **`make doctest-coverage`**| Generate coverage report for doctest examples                       |\n| **`make doctest-check`**   | Check doctest coverage percentage (fail if < 100%)                  |\n| **`make pre-commit`**      | Execute all hooks locally (includes doctest validation)             |\n| `make docs-build`          | Build documentation with doctest examples                           |\n| `make docs-test`           | Test all documentation examples                                      |\n| `make lint`                | Meta-target (includes doctest + type checks + style)                |\n| `make test`                | Unit / integration tests                                             |\n| `make smoketest`           | Minimal E2E sanity check                                             |\n\n**Bold** targets are **mandatory**; CI must fail if doctest coverage is below 100% or any doctest fails.\n\n---\n\n### \uD83D\uDCCB Acceptance Criteria\n\n* [ ] `make doctest` exits **0** with **0 failures** across all modules.\n* [ ] `make doctest-coverage` reports **100% coverage** for all public functions/methods/classes.\n* [ ] `make doctest-check` passes coverage threshold validation.\n* [ ] `make pre-commit` includes doctest validation without modifying working tree.\n* [ ] `make test` and `make smoketest` pass with doctest integration.\n* [ ] GitHub Actions enforces doctest requirements in CI pipeline.\n* [ ] All public APIs have meaningful, executable examples in their docstrings.\n* [ ] Error cases and edge conditions are documented with doctest examples.\n* [ ] Changelog entry under **\"Documentation\"** or **\"Maintenance\"**.\n\n---\n\n### \uD83D\uDEE0??? Task List (suggested flow)\n\n1. **Baseline assessment**\n\n   ```bash\n   python -m doctest mcpgateway/**/*.py > /tmp/doctest-report.txt\n   find mcpgateway -name \"*.py\" -exec python -c \"import doctest, sys; doctest.testmod(__import__(sys.argv[1].replace('/', '.').replace('.py', '')))\" {} \\;\n   ```\n\n   Identify modules without doctest coverage and catalog missing examples.\n\n2. **Makefile integration**\n\n   ```makefile\n   .PHONY: doctest doctest-verbose doctest-coverage doctest-check\n   \n   doctest:\n   \tpython -m pytest --doctest-modules mcpgateway/\n   \n   doctest-verbose:\n   \tpython -m pytest --doctest-modules mcpgateway/ -v\n   \n   doctest-coverage:\n   \tpython -m doctest_coverage mcpgateway/ --threshold=100\n   \n   doctest-check:\n   \tpython -c \"import doctest_coverage; doctest_coverage.check_coverage('mcpgateway/', 100)\"\n   ```\n\n3. **Start with simple functions**\n\n   * Add basic input/output examples to utility functions\n   * Cover happy path scenarios first\n   * Run `make doctest` frequently to catch syntax errors\n\n4. **Expand to complex scenarios**\n\n   * Document error cases with `Traceback` examples\n   * Show state changes in classes and methods\n   * Include edge cases and boundary conditions\n\n5. **Error handling patterns**\n\n   ```python\n   def validate_email(email):\n       \"\"\"Validate email address format.\n       \n       Valid emails:\n       >>> validate_email(\"user@example.com\")\n       True\n       >>> validate_email(\"test.email+tag@domain.co.uk\")\n       True\n       \n       Invalid emails:\n       >>> validate_email(\"invalid-email\")\n       False\n       >>> validate_email(\"@missing-local.com\")\n       False\n       >>> validate_email(\"missing-at-sign.com\")\n       False\n       \n       Type errors:\n       >>> validate_email(None)\n       Traceback (most recent call last):\n           ...\n       TypeError: Email must be a string\n       \"\"\"\n   \n   def validate_mcp_message(message):\n       \"\"\"Validate MCP protocol message structure.\n       \n       Valid message:\n       >>> msg = {\"jsonrpc\": \"2.0\", \"method\": \"ping\", \"id\": 1}\n       >>> validate_mcp_message(msg)\n       True\n       \n       Missing required fields:\n       >>> validate_mcp_message({\"method\": \"ping\"})\n       Traceback (most recent call last):\n           ...\n       ValueError: Missing required field: jsonrpc\n       \n       Invalid JSON-RPC version:\n       >>> validate_mcp_message({\"jsonrpc\": \"1.0\", \"method\": \"ping\", \"id\": 1})\n       Traceback (most recent call last):\n           ...\n       ValueError: Invalid JSON-RPC version, must be '2.0'\n       \n       Invalid method name:\n       >>> validate_mcp_message({\"jsonrpc\": \"2.0\", \"method\": \"\", \"id\": 1})\n       Traceback (most recent call last):\n           ...\n       ValueError: Method name cannot be empty\n       \"\"\"\n   ```\n\n6. **CI integration**\n\n   Add to the lint matrix in the existing GitHub Actions workflow:\n\n   ```yaml\n   # Add to the existing lint matrix\n   - id: doctest\n     setup: pip install pytest doctest-coverage\n     cmd: |\n       python -m pytest --doctest-modules mcpgateway/\n       python -m doctest_coverage mcpgateway/ --threshold=100\n\n   - id: doctest-verbose  \n     setup: pip install pytest\n     cmd: python -m pytest --doctest-modules mcpgateway/ -v\n   ```\n\n   Or create a dedicated doctest job following the existing pattern:\n\n   ```yaml\n   name: Documentation Tests\n   \n   on:\n     push:\n       branches: [\"main\"]\n     pull_request:\n       branches: [\"main\"]\n   \n   jobs:\n     doctest:\n       name: doctest\n       runs-on: ubuntu-latest\n       steps:\n         - name: ??????  Checkout source\n           uses: actions/checkout@v4\n           with:\n             fetch-depth: 1\n   \n         - name: \uD83D\uDC0D  Set up Python\n           uses: actions/setup-python@v5\n           with:\n             python-version: \"3.12\"\n             cache: pip\n   \n         - name: \uD83D\uDCE6  Install project (editable mode)\n           run: |\n             python -m pip install --upgrade pip\n             pip install -e .[dev]\n   \n         - name: \uD83D\uDD27  Install doctest tools\n           run: pip install pytest doctest-coverage\n   \n         - name: \uD83D\uDD0D  Run doctest\n           run: |\n             python -m pytest --doctest-modules mcpgateway/\n             python -m doctest_coverage mcpgateway/ --threshold=100\n   ```\n\n7. **Coverage measurement**\n\n   * Install `doctest-coverage` or similar tool\n   * Set up automated reporting for missing doctest examples\n   * Integrate with existing coverage tools\n\n8. **Advanced doctest features**\n\n   ```python\n   # Ellipsis for variable output\n   >>> import uuid; str(uuid.uuid4())  # doctest: +ELLIPSIS\n   '...-...-...-...-...'\n   \n   # Normalize whitespace\n   >>> print(\"hello\\n\\nworld\")  # doctest: +NORMALIZE_WHITESPACE\n   hello\n   world\n   \n   # Skip platform-specific tests\n   >>> import sys\n   >>> sys.platform  # doctest: +SKIP\n   'linux'\n   ```\n\n9. **Documentation integration**\n\n   * Configure MkDocs to include doctest examples in documentation\n   * Set up `mkdocs.yml` with appropriate plugins for code execution\n   * Update documentation in `docs/docs/testing/` to reference doctest examples\n   * Ensure examples render properly in generated MkDocs site\n\n   Example `mkdocs.yml` configuration:\n   ```yaml\n   plugins:\n     - mkdocstrings:\n         handlers:\n           python:\n             options:\n               show_source: true\n               show_docstring_examples: true\n   ```\n\n10. **Final validation**\n\n    ```bash\n    make doctest doctest-coverage doctest-check\n    make test smoketest\n    make docs-build docs-test\n    ```\n\n---\n\n### \uD83D\uDCD6 References\n\n* **Python doctest module** ??? Built-in testing via documentation ?? [https://docs.python.org/3/library/doctest.html](https://docs.python.org/3/library/doctest.html)\n* **pytest doctest integration** ??? Running doctests with pytest ?? [https://docs.pytest.org/en/stable/how.html#doctest](https://docs.pytest.org/en/stable/how.html#doctest)\n* **doctest-coverage** ??? Measure doctest coverage ?? [https://pypi.org/project/doctest-coverage/](https://pypi.org/project/doctest-coverage/)\n* **MkDocs Material** ??? Documentation framework ?? [https://squidfunk.github.io/mkdocs-material/](https://squidfunk.github.io/mkdocs-material/)\n* **mkdocstrings** ??? Automatic API docs from docstrings ?? [https://mkdocstrings.github.io/](https://mkdocstrings.github.io/)\n\n---\n\n### \uD83E\uDDE9 Additional Notes\n\n* **Start simple**: Begin with pure functions that have clear inputs/outputs before tackling stateful objects.\n* **Test the examples**: Every doctest example should be copy-pastable into a Python REPL and work exactly as shown.\n* **Cover error cases**: Don't just show happy path - demonstrate how functions handle invalid inputs.\n* **Keep examples realistic**: Use domain-appropriate data rather than contrived `foo`/`bar` examples.\n* **Maintain consistency**: Establish conventions for example formatting, variable names, and output representation.\n* **Performance considerations**: Doctest examples run during import - keep them fast and avoid expensive operations.\n* **Mock external dependencies**: Use `doctest.testmod()` options or `# doctest: +SKIP` for examples requiring external services.\n\n**Doctest Best Practices:**\n- Each public function/method/class should have at least one example\n- Show typical usage patterns, not just minimal cases  \n- Include examples that demonstrate the function's purpose and value\n- Use meaningful variable names and realistic data\n- Test both success and failure scenarios where appropriate",
      "updatedAt" : 1752276354.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "devops", "testing", "help wanted", "cicd", "chore", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ "Working on infrastructure setup (Makefile, CI, tooling)\n" ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to implement comprehensive doctest coverage across the entire codebase, ensuring all tests are green and every public function/method/class has executable documentation examples.",
      "validationOrRequirement" : "The issue requires 100% doctest coverage, passing doctest requirements in CI pipeline, and ensuring all public APIs have meaningful, executable examples in their docstrings. It also requires documenting error cases and edge conditions with doctest examples.",
      "attemptedFixes" : "The issue mentions setting up baseline assessment, integrating Makefile, and creating a dedicated doctest job in CI. It also suggests installing doctest tools, running doctest, and integrating with existing coverage tools.",
      "otherNotes" : "The issue aims to achieve 100% doctest coverage across the entire codebase, ensuring all tests are green and every public function/method/class has executable documentation examples. It involves implementing comprehensive doctest coverage, adding Makefile and CI/CD targets for doctest and coverage, and integrating doctest with existing documentation generation. The issue also requires setting up doctest for specific examples, handling error cases and edge conditions, and integrating doctest with CI pipeline.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282772
  }, {
    "issueDTO" : {
      "id" : 2954157180,
      "title" : "issue with wifi off",
      "url" : "https://github.com/gradio-app/fastrtc/issues/217",
      "repositoryName" : "gradio-app/fastrtc",
      "description" : "Newbie here, I'm trying to use this cool repo:\n\nhttps://github.com/PkmX/orpheus-chat-webui \n\nthat uses fastrtc.  I'm on a Mac M1 Max.  It works fine when I have a wifi connection but fails immediately when wifi is off.  Looking at the logs I see entries like this:\n\nCouldn't bind socket to address IP4:0.0.0.0:53312/UDP\n\nICE-STREAM(PC:{964aa2d2-61ac-4cb7-9700-7ca3db848167} 1743097440730886 (id=12884901889 url=http://127.0.0.1:7860/) transport-id=transport_1 - 512b74c8:f946abcbbde404470f44eb8b4566293b): couldn't create socket for address IP4:0.0.0.0:53312/UDP\n\n/builds/worker/checkouts/gecko/dom/media/webrtc/transport/third_party/nICEr/src/net/nr_socket_multi_tcp.c:639 function nr_socket_multi_tcp_listen failed with error 3\n\n-----------\nany ideas would be greatly appreciated.",
      "updatedAt" : 1752276253.000000000,
      "user" : "scalar27",
      "userHtmlUrl" : "https://github.com/scalar27",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/159171897?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Yea i think internet is needed to mediate the inotial webrtc connection even if running locally. is this a blocker for you?", "It also stops working if I start the code with wifi on and then turn it off.  Also, the dev says running w/o internet works fine for him.  Could it be a Mac thing?  (He's not on Mac but I am)", "It might be \uD83E\uDD14 I have not tried running without internet tbh", "Is this something I could make a PR for?", "Yes please do @scalar27 !", "Um, I just tried and it turns out I'm not competent to do that ;)   Let's just call it a request for you to consider. Thanks.", "Curious if there has been any progress on this issue to enable offline use?" ],
      "repository" : {
        "description" : "The python library for real-time communication",
        "homepage" : "https://fastrtc.org/",
        "name" : "fastrtc",
        "fullName" : "gradio-app/fastrtc",
        "htmlUrl" : "https://github.com/gradio-app/fastrtc",
        "gitUrl" : "git://github.com/gradio-app/fastrtc.git",
        "sshUrl" : "git@github.com:gradio-app/fastrtc.git",
        "cloneUrl" : "https://github.com/gradio-app/fastrtc.git",
        "owner" : {
          "login" : "gradio-app",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 371,
        "stargazersCount" : 4116,
        "watchersCount" : 4116,
        "size" : 6471,
        "openIssuesCount" : 47,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-07T08:56:18Z",
        "languages" : {
          "TypeScript" : 10617,
          "JavaScript" : 4037990,
          "HTML" : 3758,
          "Svelte" : 66144,
          "Python" : 240710,
          "Just" : 2300
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to enable offline use of the repository, which currently fails when WiFi is off.",
      "validationOrRequirement" : "The issue requires the ability to use the repository offline, and possibly a Mac-specific fix.",
      "attemptedFixes" : "The author tried running the code with WiFi on and then off, and also tried running without internet, but didn't make any progress.",
      "otherNotes" : "The issue occurs when WiFi is off, and the logs show errors like 'Couldn't bind socket to address IP4:0.0.0.0:53312/UDP' and 'nr_socket_multi_tcp_listen failed with error 3'. The author is unsure if it's a Mac-specific issue, and the dev hasn't experienced it.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282778
  }, {
    "issueDTO" : {
      "id" : 2370854787,
      "title" : "Azure Datalake Storage V2 ObjectStoragePath connection issues",
      "url" : "https://github.com/apache/airflow/issues/40410",
      "repositoryName" : "apache/airflow",
      "description" : "### Apache Airflow version\r\n\r\n2.9.2\r\n\r\n### If \"Other Airflow 2 version\" selected, which one?\r\n\r\n_No response_\r\n\r\n### What happened?\r\n\r\nConnection parsing seems buggy with the Azure implementation for ObjectStoragePath - requiring specific extras in specific places that don't really make sense. This is also inconsistent with the `AzureDataLakeStorageV2Hook` connection parsing\r\n\r\nAdditionally - there is no documentation at all about an Azure implementation for ObjectStoragePath - so we should make sure to have a doc associated with the provider. \r\n\r\nFurthermore, this is a Microsoft problem - but why there are [three solutions for the same thing, each with different terminology](https://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-best-practices#understand-the-terms-used-in-documentation), in varying degrees of supported or deprecated - is wicked confusing. \r\n\r\n### What you think should happen instead?\r\n\r\n_No response_\r\n\r\n### How to reproduce\r\n\r\n1) ???  `extras.connection_string` - works for both the Hook and Object Storage, without issue:\r\n```\r\nimport os\r\nos.environ[\"AIRFLOW_CONN_ADLS\"] = '{\"conn_type\": \"adls\", \"extra\": {\"connection_string\": \"...\"}}'\r\n\r\nfrom airflow.providers.microsoft.azure.fs.adls import get_fs\r\nfrom airflow.providers.microsoft.azure.hooks.data_lake import AzureDataLakeStorageV2Hook\r\n\r\n# Hook\r\nprint(list(AzureDataLakeStorageV2Hook(adls_conn_id=\"ADLS\").get_conn().list_file_systems()))\r\n# Object Storage\r\nget_fs(\"ADLS\")\r\n```\r\n\r\n2) ???  `host`+`login`+`password`+`extras.tenant_id` - ??? works for the Hook, ??? DOES NOT WORK for Object Storage:\r\n```\r\nimport os\r\nos.environ[\"AIRFLOW_CONN_ADLS\"] = '{\"conn_type\": \"adls\", \"host\": \"myfilesystem\", \"login\": \"...\", \"password\": \"...\", \"extra\": {\"tenant_id\": \"...\"}}'\r\n\r\nfrom airflow.providers.microsoft.azure.fs.adls import get_fs\r\nfrom airflow.providers.microsoft.azure.hooks.data_lake import AzureDataLakeStorageV2Hook\r\n\r\n# Hook\r\nprint(list(AzureDataLakeStorageV2Hook(adls_conn_id=\"ADLS\").get_conn().list_file_systems()))\r\n# Object Storage\r\nget_fs(\"ADLS\")\r\n# ValueError: unable to connect to account for Must provide either a connection_string or account_name with credentials!!\r\n```\r\nError from `adlfs.spec@do_connect`\r\n\r\n3) ??? `host`+`login`+`password`+`extras.tenant_id`+`extras.account_name` (not [documented](https://airflow.apache.org/docs/apache-airflow-providers-microsoft-azure/stable/connections/adls_v2.html)). ~~Works for both~~\r\n```\r\nimport os\r\nos.environ[\"AIRFLOW_CONN_ADLS\"] = '{\"conn_type\": \"adls\", \"host\": \"myfilesystem\", \"login\": \"...\", \"password\": \"...\", \"extra\": {\"tenant_id\": \"...\", \"account_name\": \"myfilesystem\"}}'\r\n\r\nfrom airflow.providers.microsoft.azure.fs.adls import get_fs\r\nfrom airflow.providers.microsoft.azure.hooks.data_lake import AzureDataLakeStorageV2Hook\r\n\r\n# Hook\r\nprint(list(AzureDataLakeStorageV2Hook(adls_conn_id=\"ADLS\").get_conn().list_file_systems()))\r\n# Object Storage\r\nget_fs(\"ADLS\")\r\n\r\n# test #2\r\nget_fs(\"ADLS\").ls(\"/\")\r\n# ClientAuthenticationError: Server failed to authenticate the request. Please refer to the information in the ww-authentication header.\r\n# 'WWW-Authenticate': 'Bearer authorization_uri=https://login.microsoftonline.com/.../oauth2/authorize resource_id=https://storage.azure.com\"\r\n```\r\n(edit: I initially thought this was working, as `get_fs` returns successfully, but as soon as I attempt to use it it fails. I've tried a number of other combinations, such as including `account_url` and `client_secret_auth_config` in `extra` - none are working)\r\n\r\n### Operating System\r\n\r\nAstronomer/Docker\r\n\r\n### Versions of Apache Airflow Providers\r\n\r\n_No response_\r\n\r\n### Deployment\r\n\r\nAstronomer\r\n\r\n### Deployment details\r\n\r\n_No response_\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)\r\n",
      "updatedAt" : 1752276244.000000000,
      "user" : "fritz-astronomer",
      "userHtmlUrl" : "https://github.com/fritz-astronomer",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/80706212?v=4",
      "labels" : [ "kind:bug", "provider:microsoft-azure", "area:providers", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I can get this working with the client directly - the problem is 100% in the `get_fs` method\r\n\r\n```\r\nfrom azure.identity.aio import ClientSecretCredential\r\nfrom adlfs import AzureBlobFileSystem\r\n\r\nprint(AzureBlobFileSystem(\r\n  account_name=\"...\",\r\n  credential=ClientSecretCredential(\r\n    tenant_id=\"...\",\r\n    client_id=\"...\",\r\n    client_secret=\"...\",\r\n).ls('/'))\r\n```", "Will try to look into it next week", "Hi,\n\nCould you please assign this ticket to me?\n\nI would like to contribute on Airflow \uD83D\uDE04", "Hello @fernandocast , I am just wondering if you have got a chance to work on this PR yet? I ran into the same issue as well. Thanks." ],
      "repository" : {
        "description" : "Apache Airflow - A platform to programmatically author, schedule, and monitor workflows",
        "homepage" : "https://airflow.apache.org/",
        "name" : "airflow",
        "fullName" : "apache/airflow",
        "htmlUrl" : "https://github.com/apache/airflow",
        "gitUrl" : "git://github.com/apache/airflow.git",
        "sshUrl" : "git@github.com:apache/airflow.git",
        "cloneUrl" : "https://github.com/apache/airflow.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15301,
        "stargazersCount" : 40971,
        "watchersCount" : 40971,
        "size" : 416042,
        "openIssuesCount" : 1526,
        "subscribersCount" : 763,
        "pushedAt" : "2025-07-11T23:51:39Z",
        "languages" : {
          "Java" : 1443,
          "Jinja" : 76192,
          "CSS" : 15733,
          "Go" : 63158,
          "HTML" : 42905,
          "Jupyter Notebook" : 7288,
          "TypeScript" : 2124349,
          "HCL" : 3786,
          "Dockerfile" : 119790,
          "Shell" : 230742,
          "JavaScript" : 328117,
          "Mako" : 2684,
          "Python" : 42415969
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the connection parsing issue with Azure implementation for ObjectStoragePath in Airflow, and to create a doc associated with the provider.",
      "validationOrRequirement" : "The issue requires specific extras in specific places that don't really make sense, and the documentation is inconsistent and confusing.",
      "attemptedFixes" : "The problem is in the `get_fs` method, and a possible fix is to use the client directly with `AzureBlobFileSystem`.",
      "otherNotes" : "The issue is related to Azure Datalake Storage V2 ObjectStoragePath connection issues, with inconsistent and confusing documentation. There are three solutions for the same thing, each with different terminology, and no documentation for Azure implementation for ObjectStoragePath.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282783
  }, {
    "issueDTO" : {
      "id" : 3224444243,
      "title" : "Add a lint checker for OSB 2.X terms",
      "url" : "https://github.com/opensearch-project/opensearch-benchmark/issues/892",
      "repositoryName" : "opensearch-project/opensearch-benchmark",
      "description" : "### Is your feature request related to a problem? Please describe\n\nOpposite of #841 . A lint checker to check OSB 1.X branches for 2.X terms could be helpful in maintaining backwards compatibility. \n\n### Describe the solution you'd like\n\nThe same solution as #888 , except for the following terms:\n`cluster-configs` instead of `provision-configs`/`provision-config-instances`\n`reporting` instead of `results-publishing`\n`worker-hosts` instead of `load-worker-coordinator-hosts`, `node-ip`, `coordinator-ip`\n`run-test`/`test-run` instead of `execute-test`\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752275643.000000000,
      "user" : "OVI3D0",
      "userHtmlUrl" : "https://github.com/OVI3D0",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/57258816?v=4",
      "labels" : [ "2.0.0", "Low Priority", "enhancement", "good first issue", "untriaged" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OpenSearch Benchmark - a community driven, open source project to run performance tests for OpenSearch",
        "homepage" : "https://opensearch.org/docs/latest/benchmark/",
        "name" : "opensearch-benchmark",
        "fullName" : "opensearch-project/opensearch-benchmark",
        "htmlUrl" : "https://github.com/opensearch-project/opensearch-benchmark",
        "gitUrl" : "git://github.com/opensearch-project/opensearch-benchmark.git",
        "sshUrl" : "git@github.com:opensearch-project/opensearch-benchmark.git",
        "cloneUrl" : "https://github.com/opensearch-project/opensearch-benchmark.git",
        "owner" : {
          "login" : "opensearch-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 102,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 9059,
        "openIssuesCount" : 172,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-10T19:27:53Z",
        "languages" : {
          "Dockerfile" : 2014,
          "Shell" : 15349,
          "Jinja" : 7783,
          "Makefile" : 4014,
          "Python" : 2833501
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a lint checker for OSB 2.X terms to maintain backwards compatibility",
      "validationOrRequirement" : "The same solution as #888, except for the following terms: cluster-configs, reporting, worker-hosts, run-test/test-run",
      "attemptedFixes" : "No response on alternatives considered",
      "otherNotes" : "The issue is related to a problem and aims to maintain backwards compatibility by adding a lint checker for OSB 2.X terms, with alternatives considered for specific terms.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282787
  }, {
    "issueDTO" : {
      "id" : 3220542853,
      "title" : "Convert Images into Meshery Design.",
      "url" : "https://github.com/layer5io/docs/issues/646",
      "repositoryName" : "layer5io/docs",
      "description" : "#### Current Behavior\nHey Everyone,\nGood First Issue Alert! :tada:\nWe???re adding a new course to the Layer5 learning path, and we need help designing embedded visuals for the course content.\nHere???s what you need to do:\nA few issues have already been created, each with an image attached.\nYour task is to redesign the image into a Meshery design.\nOnce done, share your design as a comment under the respective issue.\nThis will count as your first contribution to Meshery and you???ll also earn your first design badge! :sports_medal:\nFor reference:\nImage: \n<img width=\"2792\" height=\"1334\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/15ece83c-8bbb-417b-a9ae-6fdfca7184fc\" />\n\nDesign:\n<img width=\"720\" height=\"504\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a24bb537-7797-47e4-b63f-e86a76667258\" />\n\n#### Desired Behavior\n<!-- A brief description of the enhancement. -->\n\n#### Implementation\n<!-- [Optional] Specifics on the approach to fulfilling the feature request. -->\n\n#### Acceptance Tests\n<!-- [Optional] Stipulations of functional behavior or non-functional items that must be in-place in order for the issue to be closed. -->\n\n#### Mockups\n<!-- [Optional] Any visual diagrams of the desired user interface. -->\n\n---\n\n#### Contributor Guide and Resources\n- \uD83D\uDCDA [Instructions for contributing to documentation](https://github.com/layer5io/docs/blob/master/CONTRIBUTING.md)\n   - Layer5 documentation [site](https://docs.layer5.io) and [source](https://github.com/layer5io/docs/)\n- \uD83C\uDFA8 Wireframes and [designs for Layer5 site](https://www.figma.com/file/5ZwEkSJwUPitURD59YHMEN/Layer5-Designs) in Figma [(open invite)](https://www.figma.com/team_invite/redeem/qJy1c95qirjgWQODApilR9)\n- \uD83D\uDE4B\uD83C\uDFFE\uD83D\uDE4B\uD83C\uDFFC Questions: [Layer5 Discussion Forum](https://discuss.layer5.io) and [Layer5 Community Slack](http://slack.layer5.io)\n",
      "updatedAt" : 1752275335.000000000,
      "user" : "vr-varad",
      "userHtmlUrl" : "https://github.com/vr-varad",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/114755221?v=4",
      "labels" : [ "framework/hugo", "language/javascript", "language/html", "kind/enhancement", "help wanted", "language/css", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I would like to take up #647 #648 #649 as they are all similar.", "I'd like to work on [#650](https://github.com/layer5io/docs/issues/646?issue=layer5io%7Cdocs%7C650), [#654](https://github.com/layer5io/docs/issues/646?issue=layer5io%7Cdocs%7C654),[ #655](https://github.com/layer5io/docs/issues/646?issue=layer5io%7Cdocs%7C655).", "@vr-varad I'd like to work on #656  #657 #658", "@vr-varad I'd like to work on #660 #661 #662 " ],
      "repository" : {
        "description" : "Documentation and Developer resources for Layer5 products",
        "homepage" : "https://docs.layer5.io",
        "name" : "docs",
        "fullName" : "layer5io/docs",
        "htmlUrl" : "https://github.com/layer5io/docs",
        "gitUrl" : "git://github.com/layer5io/docs.git",
        "sshUrl" : "git@github.com:layer5io/docs.git",
        "cloneUrl" : "https://github.com/layer5io/docs.git",
        "owner" : {
          "login" : "layer5io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 121,
        "stargazersCount" : 60,
        "watchersCount" : 60,
        "size" : 329333,
        "openIssuesCount" : 74,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-11T17:07:59Z",
        "languages" : {
          "Dockerfile" : 2365,
          "SCSS" : 85700,
          "Makefile" : 1397,
          "JavaScript" : 12196497,
          "HTML" : 93998
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert Images into Meshery Design, redesign images into Meshery design for new course content",
      "validationOrRequirement" : "redesign images into Meshery design, specific design requirements not mentioned",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "Good First Issue Alert, redesigning images into Meshery design, earn design badge, reference images provided, contributor guide and resources provided",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282790
  }, {
    "issueDTO" : {
      "id" : 3198376770,
      "title" : "[Term Entry] NumPy Random Module: .geometric()",
      "url" : "https://github.com/Codecademy/docs/issues/7217",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `.geometric()` under `random-module` in NumPy. The entry should be in `content/numpy/concepts/random-module/terms/geometric/geometric.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that show an example of the current entry.\n- An ## Codebyte section that have a compilable code inside it showing the current entry in use. Use ```codebyte/python to add compilable code.\n\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752274924.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "numpy", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@codecademy-docs  I would like to work on this issue .", "Hey @AtulDeshpande09, you have already submitted 3 PRs. Once they are merged, we can then assign more issues to you.\n", "I would like to contribute to this issue, please." ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new entry for the .geometric() method in the NumPy Random Module, including description, syntax, example, and codebyte sections.",
      "validationOrRequirement" : "New term entry for existing concept entry. Syntax, example, and codebyte sections are required. Refer to term entry template, content standards, and markdown style guide.",
      "attemptedFixes" : "None",
      "otherNotes" : "Term entry template, content standards, and markdown style guide are to be referred to when working on the PR. Code of Conduct is agreed upon. Labels: new entry, numpy, good first issue. Multiple comments from authors and maintainers.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282794
  }, {
    "issueDTO" : {
      "id" : 3204234197,
      "title" : "[Component] Slider",
      "url" : "https://github.com/zard-ui/zardui/issues/101",
      "repositoryName" : "zard-ui/zardui",
      "description" : "## \uD83D\uDE80 New Component: Slider\n\n### \uD83D\uDCD6 Description\nAn Slider component who will recieve a min value and a max value and the idea is the user select a value based on this range, the component will recieve a default value too and this default value cant be less than min and higher than max.\n\n### \uD83C\uDFA8 References\n- shadcn/ui: [Link](https://ui.shadcn.com/docs/components/slider)\n\n<img width=\"760\" height=\"716\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/35e0da2a-1a12-40a5-b9e5-387359fb3e83\" />\n\n### \uD83D\uDCE6 Expected API\n\n#### **Inputs (Props)**\n\n<!-- List all the inputs (props) that the component should accept. -->\n\n| Name    | Type                                | Required | Description              |\n| ------- | ----------------------------------- | -------- | ------------------------ |\n| `zMin` | `number` | Yes       | Defines the Slider min value |\n| `zMax` | `number` | Yes       | Defines the Slider max value |\n| `zDefault` | `number` | No | Defines the Slider default value (this value need cant be less than min and higher than max) |\n| `zValue` | `number` | No   | Return the slider current value |\n| `zDisable` | `boolean` | No   | Disable the Slider usage |\n\n#### **Outputs (Events)**\n\n<!-- List all the outputs (events) that the component should emit. -->\n\n| Name      | Type                 | Description                        |\n| --------- | -------------------- | ---------------------------------- |\n| `onSlide` | `EventEmitter<number>` | Emit the current value |\n\n### ??? Acceptance Criteria\n\n- [ ] Matches the references\n- [ ] Includes unit tests\n- [ ] Responsive and accessible (a11y)\n- [ ] Supports dark mode\n",
      "updatedAt" : 1752274592.000000000,
      "user" : "Luizgomess",
      "userHtmlUrl" : "https://github.com/Luizgomess",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/62315802?v=4",
      "labels" : [ "ready", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A collection of beautiful and accessible components for Angular based in Shadcn/ui and Ng-zorro. Fully open source and free ??????",
        "homepage" : "https://www.zardui.com",
        "name" : "zardui",
        "fullName" : "zard-ui/zardui",
        "htmlUrl" : "https://github.com/zard-ui/zardui",
        "gitUrl" : "git://github.com/zard-ui/zardui.git",
        "sshUrl" : "git@github.com:zard-ui/zardui.git",
        "cloneUrl" : "https://github.com/zard-ui/zardui.git",
        "owner" : {
          "login" : "zard-ui",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 22,
        "stargazersCount" : 116,
        "watchersCount" : 116,
        "size" : 2385,
        "openIssuesCount" : 17,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-08T23:14:17Z",
        "languages" : {
          "TypeScript" : 333662,
          "CSS" : 13700,
          "SCSS" : 1363,
          "JavaScript" : 11740,
          "HTML" : 21396
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new Slider component that allows users to select a value within a range, with a default value that cannot be less than the minimum and higher than the maximum value.",
      "validationOrRequirement" : "The component should accept the following inputs (props): `zMin` (number, required), `zMax` (number, required), `zDefault` (number, optional), `zValue` (number, optional), and `zDisable` (boolean, optional). The component should also emit the current value through the `onSlide` event.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about creating a new component called Slider, which will receive min and max values, and a default value that cannot be less than min and higher than max. The component will also receive a current value and emit it when the user interacts with it. The acceptance criteria include matching references, including unit tests, being responsive and accessible, and supporting dark mode.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282801
  }, {
    "issueDTO" : {
      "id" : 3224392192,
      "title" : "[COMPONENTS] Modify Add to Calendar PRO components per app developer request",
      "url" : "https://github.com/PipedreamHQ/pipedream/issues/17588",
      "repositoryName" : "PipedreamHQ/pipedream",
      "description" : "**Is there a specific app this action is for?**\nAdd to Calendar PRO\n\n**Please provide a link to the relevant API docs for the specific service / operation.**\nhttps://docs.add-to-calendar-pro.com/api/introduction\n\n**Request from app developer**\n### General Stuff at the add_to_calendar_pro.app.mjs:\n\nrecurrence -> description should be: An RRULE. Use in combination with \"Simplified Recurrence\" being set to false.\nrecurrenceSimpleType -> description should be: Use in combination with \"Simplified Recurrence\" being set to true.\nmetaRobotsOverride -> type needs to be boolean\nstyleId -> type needs to be integer\nlandingPageTemplateId -> type needs to be integer\nrsvpTemplateId -> type needs to be integer\nctaTemplateId -> type needs to be integer\ncustomDomainId -> type needs to be integer\nemailTemplateId -> type needs to be integer\n\n### Action: get-ics-data:\n\nAdd query ?responseType=object, so the response includes the name and download address of the ics files (alongside with the raw ics content data)\n\n\nRather minor things:\n\n### Action: update-event:\n\nname and startDate at Dates are not required for the update/patch case. They only are for creation\n\n### Trigger: new-rsvp-answer-instant: Test Data:\n\nEmail should have a value as it will always be set. Let???s go for [john.doe@email.com](mailto:john.doe@email.com)\n\n### Trigger: new-rsvp-answer-updated-instant: Test Data:\n\nEmail should have a value as it will always be set. Let???s go for [john.doe@email.com](mailto:john.doe@email.com)",
      "updatedAt" : 1752273930.000000000,
      "user" : "sergio-eliot-rodriguez",
      "userHtmlUrl" : "https://github.com/sergio-eliot-rodriguez",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/101526248?v=4",
      "labels" : [ "help wanted", "action", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Connect APIs, remarkably fast.  Free for developers.",
        "homepage" : "https://pipedream.com",
        "name" : "pipedream",
        "fullName" : "PipedreamHQ/pipedream",
        "htmlUrl" : "https://github.com/PipedreamHQ/pipedream",
        "gitUrl" : "git://github.com/PipedreamHQ/pipedream.git",
        "sshUrl" : "git@github.com:PipedreamHQ/pipedream.git",
        "cloneUrl" : "https://github.com/PipedreamHQ/pipedream.git",
        "owner" : {
          "login" : "PipedreamHQ",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5402,
        "stargazersCount" : 10157,
        "watchersCount" : 10157,
        "size" : 601491,
        "openIssuesCount" : 4073,
        "subscribersCount" : 277,
        "pushedAt" : "2025-07-11T19:30:29Z",
        "languages" : {
          "TypeScript" : 1305958,
          "MDX" : 1185411,
          "Dockerfile" : 295,
          "CSS" : 4596,
          "Shell" : 2688,
          "Makefile" : 270,
          "JavaScript" : 25109889,
          "HTML" : 568,
          "Jupyter Notebook" : 22765
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Modify Add to Calendar PRO components per app developer request",
      "validationOrRequirement" : "Types need to be specific: recurrence -> description should be: An RRULE, recurrenceSimpleType -> description should be: Use in combination with 'Simplified Recurrence' being set to true, metaRobotsOverride -> type needs to be boolean, styleId -> type needs to be integer, landingPageTemplateId -> type needs to be integer, rsvpTemplateId -> type needs to be integer, ctaTemplateId -> type needs to be integer, customDomainId -> type needs to be integer, emailTemplateId -> type needs to be integer, and ?responseType=object query for get-ics-data action.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is related to modifying Add to Calendar PRO components per app developer request. The request includes changes to the recurrence, recurrenceSimpleType, metaRobotsOverride, styleId, landingPageTemplateId, rsvpTemplateId, ctaTemplateId, customDomainId, and emailTemplateId types. Additionally, the get-ics-data action should include the ?responseType=object query, and the name and startDate fields are not required for the update/patch case in the update-event action. The new-rsvp-answer-instant and new-rsvp-answer-updated-instant triggers should include an email value.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282810
  }, {
    "issueDTO" : {
      "id" : 2271485296,
      "title" : "Add ESLint rule to prevent usage of the order CSS property",
      "url" : "https://github.com/WordPress/gutenberg/issues/61247",
      "repositoryName" : "WordPress/gutenberg",
      "description" : "### Description\r\n\r\nSee https://github.com/WordPress/gutenberg/issues/61241\r\n\r\nSome components come with CSS in JS. \r\n\r\nhttps://github.com/WordPress/gutenberg/issues/61241 and https://github.com/WordPress/gutenberg/pull/61243 aim to introduce a `stylelint` rule to prevent usage of the `order` CSS property, which is impactful for accessibility.\r\n\r\nIn the same way, it would be nice to add an ESLint rule to prevent usage of the `order` CSS property in any *.js file.\r\n\r\nUnfortunately this isn't exactly my area of expertise so that I'd appreciate some guidance. I did see a similar rule added in https://github.com/WordPress/gutenberg/pull/58130\r\n\r\n### Step-by-step reproduction instructions\r\n\r\n- Add an `order` CSS property e.g. `order: 1;` to any CSS-in-JS for example in [this file](https://github.com/WordPress/gutenberg/blob/db5e39180b3aadfb965941545c22593fe055e494/packages/components/src/palette-edit/styles.ts)..\r\n-  Run `npm run lint:js`.\r\n- Observe the linter does not report any error.\r\n\r\n### Screenshots, screen recording, code snippet\r\n\r\n_No response_\r\n\r\n### Environment info\r\n\r\n_No response_\r\n\r\n### Please confirm that you have searched existing issues in the repo.\r\n\r\nYes\r\n\r\n### Please confirm that you have tested with all plugins deactivated except Gutenberg.\r\n\r\nYes",
      "updatedAt" : 1752273930.000000000,
      "user" : "afercia",
      "userHtmlUrl" : "https://github.com/afercia",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1682452?v=4",
      "labels" : [ "Good First Issue", "[Type] Code Quality", "[Status] In Progress", "[Focus] Accessibility (a11y)" ],
      "state" : "OPEN",
      "comments" : [ "I guess the patterns to catch would be, at least, the following ones. With and without leading spaces or tab characters:\r\n\r\n```\r\norder: 123;\r\n    order: 123;\r\n\r\norder: 123,\r\n    order: 123,\r\n\r\norder: '123',\r\n    order: '123',\r\n\r\n\r\n'order: 123;'\r\n    'order: 123;'\r\n```", "Hey,  I'm fairly new to open-source and web development, but I would love to give it a try", "@ghostp13409 welcome. Sure, please do feel free to work on a Pull Request.\r\n\r\nI did try to follow a previous example that added another ESLint rule, see https://github.com/WordPress/gutenberg/pull/59022. But I'm not good at regular expressions. Also, I have no idea how that works. I did try to go through the ESLint [custom rules docs](https://eslint.org/docs/latest/extend/custom-rules) and [the docs for selectors](https://eslint.org/docs/latest/extend/selectors) but this isn't really my area of expertise. Wondering if there's any simpler way to detect the `order` CSS property in JS. @mirka any help would be appreciated, when you have a chance \uD83D\uDE47\uD83C\uDFFD????????? \r\n\r\nIt gets complicated because of the several ways CSS can be coded in JS. It could be a key/value pair within an object, or a string, or a concatenated string... etc.\r\n\r\nNote the JS linter can be run in the terminal with this command: `npm run lint:js -- --quiet`", "CSS-in-JS can either be done with strings or objects. The string case can be caught similar to #59022 without much downside, but the object case will be trickier because `{ order: 3 }` is something that could validly appear in code unrelated to styling.\r\n\r\nI wouldn't say this rule is particularly necessary at the moment, given that: \r\n\r\n- We currently have zero violations in `@wordpress/components` code, and we generally have more rigorous reviews on CSS that gets merged in the package. (CSS-in-JS is only used in `@wordpress/components`)\r\n- There will be increasingly fewer usages of CSS-in-JS as we migrate off of Emotion.\r\n\r\nMight be fine to revisit once we actually encounter an `order` slipping through.", "Hey @afercia , I think i can solve this issue....Can i make a pull request?\n", "@Gannu456 thanks for looking into this. Given @mirka's previous comment, I'm not sure it is worth it.", "Hi @afercia . It's been a while since last comment in this issue. and I can't find any PR related to it.\nI've checked it carefully, and seems to be a little bit tricky if we want to implement it properly and not to trigger 'false positives' in the linting.\nI'm taking it over if you don't mind. cc @ghostp13409 , @Gannu456 \n\nAs a comment, your test example proposals \n```\norder: 123;\n    order: 123;\n\norder: 123,\n    order: 123,\n\norder: '123',\n    order: '123',\n\n\n'order: 123;'\n    'order: 123;'\n```\n\ndon't look quite precise to me. I've been digging in the packages codebase, and there are cases where the property 'order' is correctly used in a different context than CSS in JS, therefore we need to ensure that we don't trigger the error in those legit cases.\n\nI'll be pulling a PR today and tomorrow for dicussion, if that's ok with you\n\n\n", "There it goes @afercia , PR ready for reviewing. Since it is my first PR, It would be good if you could check it in a quick look\nhttps://github.com/WordPress/gutenberg/pull/70699 , to see if it looks something similar to what you had in mind.\n\nIt was tricky to determine if a developer is actually using the property `order` as a CSS-in-JS, or as anything else. I had to develop some context detection to consider it as styled CSS in JS. \nThere were cases like this \n[packages/block-editor/src/store/selectors.js\n](https://github.com/WordPress/gutenberg/blob/trunk/packages/block-editor/src/store/selectors.js#L738)\nwhere I had to be careful not to trigger a false error.\n\nIt uses regular expressions also to detect `order` and not `border` , for example.\n\nI have tested it carefully, confirming that it doesnt trigger false positives, and that it triggers the errors for real cases of `order` CSS injections. The unit test is quite exhaustive, and I also included the documentation about this rule into the 'md' in the same way as the other ones.\n\nThe code might look a little overkilling, so I'd appreciate if you could give me a feedback about it." ],
      "repository" : {
        "description" : "The Block Editor project for WordPress and beyond. Plugin is available from the official repository.",
        "homepage" : "https://wordpress.org/gutenberg/",
        "name" : "gutenberg",
        "fullName" : "WordPress/gutenberg",
        "htmlUrl" : "https://github.com/WordPress/gutenberg",
        "gitUrl" : "git://github.com/WordPress/gutenberg.git",
        "sshUrl" : "git@github.com:WordPress/gutenberg.git",
        "cloneUrl" : "https://github.com/WordPress/gutenberg.git",
        "owner" : {
          "login" : "WordPress",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4443,
        "stargazersCount" : 11295,
        "watchersCount" : 11295,
        "size" : 887358,
        "openIssuesCount" : 7589,
        "subscribersCount" : 344,
        "pushedAt" : "2025-07-11T14:52:29Z",
        "languages" : {
          "MDX" : 28545,
          "Java" : 211238,
          "CSS" : 20859,
          "Mustache" : 30576,
          "HTML" : 791962,
          "Kotlin" : 42181,
          "TypeScript" : 4149952,
          "Shell" : 24077,
          "Starlark" : 152,
          "PEG.js" : 8241,
          "SCSS" : 782835,
          "JavaScript" : 13488780,
          "PHP" : 2004273,
          "Objective-C" : 7609,
          "Swift" : 126502,
          "Ruby" : 6854
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Introduce an ESLint rule to prevent usage of the `order` CSS property in any *.js file, ensuring that it doesn't trigger false positives and can detect the `order` CSS property in both string and object cases.",
      "validationOrRequirement" : "The ESLint rule should prevent usage of the `order` CSS property in any *.js file. The contributor is looking for a way to detect the `order` CSS property in JS without triggering false positives, as it could be used in different contexts. The rule should be able to catch the `order` CSS property in both string and object cases.",
      "attemptedFixes" : "The contributor tried to follow a previous example that added another ESLint rule, but they're not good at regular expressions. They also tried to go through the ESLint custom rules docs and selectors docs but didn't find a simpler way to detect the `order` CSS property in JS. @mirka offered help, and the contributor is looking for guidance.",
      "otherNotes" : "The issue aims to introduce an ESLint rule to prevent usage of the `order` CSS property in any *.js file. It's a Good First Issue, and the contributor is fairly new to open-source and web development. The issue is related to accessibility and code quality, and it's already in progress.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282819
  }, {
    "issueDTO" : {
      "id" : 3147568901,
      "title" : "Enable 3DGUT",
      "url" : "https://github.com/MrNeRF/gaussian-splatting-cuda/issues/112",
      "repositoryName" : "MrNeRF/gaussian-splatting-cuda",
      "description" : "The 3dgut kernels are here in this repo and the mcmc strategy is implemented. We need to connect it to the trainer. ",
      "updatedAt" : 1752273901.000000000,
      "user" : "MrNeRF",
      "userHtmlUrl" : "https://github.com/MrNeRF",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/33876434?v=4",
      "labels" : [ "intermediate", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "https://github.com/MrNeRF/gaussian-splatting-cuda/issues/45 Is prerequisite.", "Implement wip: https://github.com/calvin-laurenson/gaussian-splatting-cuda/tree/3dgut" ],
      "repository" : {
        "description" : "3D Gaussian Splatting, reimagined: Unleashing unmatched speed with C++ and CUDA from the ground up!",
        "homepage" : "",
        "name" : "gaussian-splatting-cuda",
        "fullName" : "MrNeRF/gaussian-splatting-cuda",
        "htmlUrl" : "https://github.com/MrNeRF/gaussian-splatting-cuda",
        "gitUrl" : "git://github.com/MrNeRF/gaussian-splatting-cuda.git",
        "sshUrl" : "git@github.com:MrNeRF/gaussian-splatting-cuda.git",
        "cloneUrl" : "https://github.com/MrNeRF/gaussian-splatting-cuda.git",
        "owner" : {
          "login" : "MrNeRF",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 118,
        "stargazersCount" : 1179,
        "watchersCount" : 1179,
        "size" : 56892,
        "openIssuesCount" : 23,
        "subscribersCount" : 33,
        "pushedAt" : "2025-07-09T21:42:06Z",
        "languages" : {
          "Dockerfile" : 4292,
          "C++" : 568130,
          "Shell" : 7167,
          "C" : 731,
          "CMake" : 17413,
          "Cuda" : 314400,
          "GLSL" : 385
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Enable 3DGUT",
      "validationOrRequirement" : "Connect the 3dgut kernels to the trainer.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description.",
      "otherNotes" : "The 3dgut kernels are already implemented in the repo, and the MCMC strategy is implemented as well. A prerequisite is the issue at https://github.com/MrNeRF/gaussian-splatting-cuda/issues/45, and there is a WIP branch at https://github.com/calvin-laurenson/gaussian-splatting-cuda/tree/3dgut.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282823
  }, {
    "issueDTO" : {
      "id" : 3222339458,
      "title" : "Bug: Message sending process should be awaiting instead of allowing multiple sends",
      "url" : "https://github.com/K-Kluster/Kasia/issues/150",
      "repositoryName" : "K-Kluster/Kasia",
      "description" : "> Whenever I send a message to my friends, it doesn???t get delivered the first time. I have to tap send again, and suddenly, the same message gets sent twice. This happens quite often, and it becomes confusing because they receive duplicate messages from me even though I only typed it once.\n\n[source](https://discord.com/channels/1359255794675089558/1359255795648172245/1393170391941382246)\n\nProposed solution:\n> adding a loading state to the send button, and disallow logic to be executed if a message is in the process of being sent (simple workaround, later on we'll add better handling of this)\n",
      "updatedAt" : 1752273619.000000000,
      "user" : "IzioDev",
      "userHtmlUrl" : "https://github.com/IzioDev",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9900846?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\"It doesn't get delivered\", is interesting, as in they don't see it in chat (this is not delivery, this is local storage) or the receiver doesn't see it?\nIdeally we _dont_ block the message send. A very small timeout is probably ok, but I'd rather work on a robust queuing system. \nOn iMessage (in times of bad connection) the message propagates to the chat but you don't get the 'delivered' stamp.\nSignal also has a status icon thing.\n\nEDIT: Just saw 'simple workaround' proposed first.\n", "If one is interested into implementing the end-goal straight away, i'm all in" ],
      "repository" : {
        "description" : "Encrypted, Decentralized and Fast P2P Messaging Protocol & Application built on top of Kaspa.",
        "homepage" : "https://kasia.fyi",
        "name" : "Kasia",
        "fullName" : "K-Kluster/Kasia",
        "htmlUrl" : "https://github.com/K-Kluster/Kasia",
        "gitUrl" : "git://github.com/K-Kluster/Kasia.git",
        "sshUrl" : "git@github.com:K-Kluster/Kasia.git",
        "cloneUrl" : "https://github.com/K-Kluster/Kasia.git",
        "owner" : {
          "login" : "K-Kluster",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 34,
        "watchersCount" : 34,
        "size" : 3087,
        "openIssuesCount" : 29,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-12T00:46:12Z",
        "languages" : {
          "TypeScript" : 466378,
          "CSS" : 7020,
          "C++" : 82,
          "Rust" : 12597,
          "Objective-C++" : 100,
          "JavaScript" : 1506,
          "HTML" : 2588,
          "Ruby" : 628,
          "Kotlin" : 5031
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to make the message sending process awaiting instead of allowing multiple sends, to prevent duplicate messages being sent.",
      "validationOrRequirement" : "The issue should not block the message send, a small timeout is probably okay, but a robust queuing system would be ideal.",
      "attemptedFixes" : "Proposed solution: adding a loading state to the send button, disallowing logic to be executed if a message is in the process of being sent.",
      "otherNotes" : "The issue is about message sending process, where the message doesn't get delivered the first time and the user has to tap send again to send the message, resulting in duplicate messages being sent.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282828
  }, {
    "issueDTO" : {
      "id" : 2458699425,
      "title" : "[Color Picker] Add ability to hide the color field",
      "url" : "https://github.com/Esri/calcite-design-system/issues/10031",
      "repositoryName" : "Esri/calcite-design-system",
      "description" : "### Check existing issues\n\n- [X] I have [checked for existing issues](https://github.com/Esri/calcite-design-system/issues) to avoid duplicates\n\n### Description\n\nAdd a property to hide the \"color graph\" from the Color Picker - many use cases do not need to offer this and the other input methods the component provides are sufficient.\n\nThis is consistent with our other configurable properties for this component - like `alpha-disabled`, `hex-disabled`, etc.\n\n### Acceptance Criteria\n\nA new property is added that allows the hiding of the color graph.\n\n### Relevant Info\n\n<img width=\"761\" alt=\"Screenshot 2024-08-09 at 2 39 08???PM\" src=\"https://github.com/user-attachments/assets/dc1f3e7c-b8a6-4ed1-8a02-db02485283e9\">\n\n\n### Which Component\n\nColor Picker\n\n### Example Use Case\n\n_No response_\n\n### Priority impact\n\nimpact - p2 - want for an upcoming milestone\n\n### Calcite package\n\n- [X] @esri/calcite-components\n- [ ] @esri/calcite-components-angular\n- [ ] @esri/calcite-components-react\n- [ ] @esri/calcite-design-tokens\n- [ ] @esri/eslint-plugin-calcite-components\n\n### Esri team\n\nCalcite (design)\n\n**monday.com sync:** #9365384691",
      "updatedAt" : 1752273597.000000000,
      "user" : "macandcheese",
      "userHtmlUrl" : "https://github.com/macandcheese",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4733155?v=4",
      "labels" : [ "estimate - 3", "ready for dev", "3 - installed", "p - medium", "design", "enhancement", "monday.com sync", "good first issue", "calcite-components" ],
      "state" : "OPEN",
      "comments" : [ "Naming-wise, color-field or something along those lines would be closer to the terminology used in the component's implementation.", "Maybe `field-disabled` could work? Keeps it brief. \r\n\r\nSince this one is just about naming, I'm going to mark this as `ready for dev` so we can match the final name in Figma when it gets merge in.", "cc  @geospatialem, @brittneytewks", "Installed and assigned for verification." ],
      "repository" : {
        "description" : "A monorepo containing the packages for Esri's Calcite Design System",
        "homepage" : "https://developers.arcgis.com/calcite-design-system/",
        "name" : "calcite-design-system",
        "fullName" : "Esri/calcite-design-system",
        "htmlUrl" : "https://github.com/Esri/calcite-design-system",
        "gitUrl" : "git://github.com/Esri/calcite-design-system.git",
        "sshUrl" : "git@github.com:Esri/calcite-design-system.git",
        "cloneUrl" : "https://github.com/Esri/calcite-design-system.git",
        "owner" : {
          "login" : "Esri",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 79,
        "stargazersCount" : 324,
        "watchersCount" : 324,
        "size" : 353570,
        "openIssuesCount" : 797,
        "subscribersCount" : 248,
        "pushedAt" : "2025-07-11T23:43:00Z",
        "languages" : {
          "TypeScript" : 5777880,
          "MDX" : 3481,
          "Shell" : 5608,
          "CSS" : 3562,
          "SCSS" : 499290,
          "JavaScript" : 45742,
          "HTML" : 5951657
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a property to hide the 'color graph' from the Color Picker component, consistent with other configurable properties for this component.",
      "validationOrRequirement" : "The issue requires a new property to be added to the Color Picker component, and the property should allow hiding the color graph.",
      "attemptedFixes" : "The issue is marked as ready for dev, and the author suggests naming options such as 'color-field' or 'field-disabled'.",
      "otherNotes" : "The issue is related to the Color Picker component, and the description includes a screenshot. The acceptance criteria is to add a new property to hide the color graph. The priority impact is p2, and the Calcite package affected is @esri/calcite-components.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282833
  }, {
    "issueDTO" : {
      "id" : 2391307568,
      "title" : "`useFetch` and `useAsyncData` type inference incorrect for generic parameter",
      "url" : "https://github.com/nuxt/nuxt/issues/28030",
      "repositoryName" : "nuxt/nuxt",
      "description" : "### Environment\n\n```\r\n------------------------------\r\n- Operating System: Linux\r\n- Node Version:     v18.20.3\r\n- Nuxt Version:     3.12.3\r\n- CLI Version:      3.12.0\r\n- Nitro Version:    2.9.7\r\n- Package Manager:  npm@10.2.3\r\n- Builder:          -\r\n- User Config:      devtools\r\n- Runtime Modules:  -\r\n- Build Modules:    -\r\n------------------------------\r\n```\n\n### Reproduction\n\nhttps://stackblitz.com/edit/github-8k6key?file=composables%2FuseCustomData.ts\n\n### Describe the bug\n\nWhen you use a generic parameter (e.g. the `T` in `<T>(...)`) to type the returned data of `useFetch` or `useAsyncData`, the functions end up inferring the returned data's type to be something with no fields in it (even if `T` was guaranteed to have certain fields via `extends`).\r\n\r\nOther functions don't seem to have this problem (e.g. `$fetch` as demonstrated in the reproduction), so this behavior is unlikely to be caused by TypeScript itself (I think it might have something to do with how the `pick` option affects the type inference process).\r\n\n\n### Additional context\n\n_No response_\n\n### Logs\n\n_No response_",
      "updatedAt" : 1752273237.000000000,
      "user" : "miosenpai",
      "userHtmlUrl" : "https://github.com/miosenpai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5713101?v=4",
      "labels" : [ "\uD83C\uDF70 p2-nice-to-have", "types", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<a href='https://stackblitz.com/~/github.com/nuxt/nuxt/issues/28030?repros=github-8k6key'><img src='https://developer.stackblitz.com/img/fix_this_issue_small.svg' alt='Fix this issue in StackBlitz Codeflow' align='left' width='117' height='20'></a> _Start a new pull request in [StackBlitz Codeflow](https://stackblitz.com/~/github.com/nuxt/nuxt/issues/28030?repros=github-8k6key)._\n\n- [**github-8k6key** (Open reproduction)](https://stackblitz.com/edit/github-8k6key?issueRepo=nuxt/nuxt&issueNumber=28030)\n", "Yes, this is caused by the fact that it's not possible to know the keys of a type that extends another type.\n\nWe deliberately try to identify all possible keys (https://github.com/nuxt/framework/pull/9061), when passed a union (e.g. `{ title: string } | { description: string }`) not just the keys that are common to all possible types.\n\nYou can see a minimal example here:\n\nhttps://www.typescriptlang.org/play/?#code/GYVwdgxgLglg9mABAUwB5WWAJgHgCoB8iAFAJQBciACjBANb4A0ieK6mWAzi4gPyJ1kATzjAelMMgBuyAE5EA3gChEqxLORQQspAoC+iAIbdDYIUr1LjQyInxsM2bgsQBbIQGlhlTlFkwwAHNEPQIyRABeRRU1CARfRCxDKENIhw58MNIAbhjVJJSAOncvcz1soA\n\nIt would be nice to have this just work in Nuxt but I think it's enough of an edge case that the best solution is for you resolve it yourself in the types of your custom composable." ],
      "repository" : {
        "description" : "The Intuitive Vue Framework.",
        "homepage" : "https://nuxt.com",
        "name" : "nuxt",
        "fullName" : "nuxt/nuxt",
        "htmlUrl" : "https://github.com/nuxt/nuxt",
        "gitUrl" : "git://github.com/nuxt/nuxt.git",
        "sshUrl" : "git@github.com:nuxt/nuxt.git",
        "cloneUrl" : "https://github.com/nuxt/nuxt.git",
        "owner" : {
          "login" : "nuxt",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5296,
        "stargazersCount" : 57572,
        "watchersCount" : 57572,
        "size" : 123938,
        "openIssuesCount" : 823,
        "subscribersCount" : 789,
        "pushedAt" : "2025-07-11T22:43:06Z",
        "languages" : {
          "TypeScript" : 1575711,
          "Dockerfile" : 468,
          "Shell" : 2931,
          "JavaScript" : 30115,
          "Vue" : 15799,
          "HTML" : 27177
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the incorrect type inference for generic parameters in `useFetch` and `useAsyncData` when using a generic parameter (e.g. the `T` in `<T>(...)`) to type the returned data.",
      "validationOrRequirement" : "The issue is with type inference for generic parameters in `useFetch` and `useAsyncData`.",
      "attemptedFixes" : "The author suggests resolving the issue by identifying all possible keys when passed a union (e.g. `{ title: string } | { description: string }`), not just the keys that are common to all possible types.",
      "otherNotes" : "The issue is caused by the fact that it's not possible to know the keys of a type that extends another type. The `pick` option affects the type inference process.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282839
  }, {
    "issueDTO" : {
      "id" : 1824595229,
      "title" : "How to setup contour as level 2 proxy",
      "url" : "https://github.com/projectcontour/contour/issues/5598",
      "repositoryName" : "projectcontour/contour",
      "description" : "**What question do you have?:**\r\nHow to setup contour as level 2 proxy\r\n\r\n**Anything else you would like to add:**\r\nAs described here, envoy needs some more configuration when running as level 2 proxy. -https://www.envoyproxy.io/docs/envoy/latest/configuration/best_practices/level_two\r\n\r\n\r\n\r\n\r\n**Environment:**\r\n\r\n- Contour version:  v1.25.1\r\n- Kubernetes version: (use `kubectl version`):\r\n- Kubernetes installer & version:\r\n- Cloud provider or hardware configuration:\r\n- OS (e.g. from `/etc/os-release`):\r\n",
      "updatedAt" : 1752273116.000000000,
      "user" : "deveshk0",
      "userHtmlUrl" : "https://github.com/deveshk0",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20398273?v=4",
      "labels" : [ "help wanted", "kind/feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Sounds reasonable to offer the configurability of this field to allow users to run their Envoy's in line with Envoy's \"L2\" guidelines: https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/network/http_connection_manager/v3/http_connection_manager.proto#envoy-v3-api-field-extensions-filters-network-http-connection-manager-v3-httpconnectionmanager-stream-error-on-invalid-http-message\r\n\r\nThis would have to be a new feature, a global configuration that can be applied by an operator who knows how Contour is deployed so they can enable it correctly, probably should go here: https://projectcontour.io/docs/1.25/configuration/#listener-configuration\r\n\r\nLet us know if you would be able to work on this @deveshk0, we can help guide your contribution and get you credit for this change!", "@sunjayBhatia  I will take this up", "that sounds great @deveshk0, I'll assign this issue to you, feel free to reach out for any help you need \uD83D\uDC4D\uD83C\uDFFD ", "Hi @sunjayBhatia ??? I???ve opened this [PR](https://github.com/projectcontour/contour/pull/7126) to address this issue. Let me know if anything needs to be changed! \uD83D\uDE04 " ],
      "repository" : {
        "description" : "Contour is a Kubernetes ingress controller using Envoy proxy.",
        "homepage" : "https://projectcontour.io",
        "name" : "contour",
        "fullName" : "projectcontour/contour",
        "htmlUrl" : "https://github.com/projectcontour/contour",
        "gitUrl" : "git://github.com/projectcontour/contour.git",
        "sshUrl" : "git@github.com:projectcontour/contour.git",
        "cloneUrl" : "https://github.com/projectcontour/contour.git",
        "owner" : {
          "login" : "projectcontour",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 696,
        "stargazersCount" : 3820,
        "watchersCount" : 3820,
        "size" : 37171,
        "openIssuesCount" : 126,
        "subscribersCount" : 70,
        "pushedAt" : "2025-07-08T14:01:07Z",
        "languages" : {
          "Smarty" : 3855,
          "Dockerfile" : 1206,
          "Shell" : 45861,
          "SCSS" : 33371,
          "Makefile" : 14689,
          "JavaScript" : 566,
          "Go" : 5111466,
          "HTML" : 5214968
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To setup contour as level 2 proxy, configure Envoy according to Envoy's 'L2' guidelines and add a global configuration option in Contour for operators to enable it correctly.",
      "validationOrRequirement" : "The Envoy version should be v1.25.1, and the Kubernetes version should be compatible with Contour.",
      "attemptedFixes" : "A PR (https://github.com/projectcontour/contour/pull/7126) has been opened to address this issue.",
      "otherNotes" : "The issue is related to Envoy's 'L2' guidelines and requires a new feature for global configuration in Contour.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282843
  }, {
    "issueDTO" : {
      "id" : 3211320010,
      "title" : "no space left on device",
      "url" : "https://github.com/ovn-kubernetes/ovn-kubernetes/issues/5357",
      "repositoryName" : "ovn-kubernetes/ovn-kubernetes",
      "description" : "### Which jobs are flaking?\n\nall\n\n### Which tests are flaking?\n\nhttps://github.com/ovn-kubernetes/ovn-kubernetes/actions/runs/15731165151/job/44334488100?pr=5298\nhttps://github.com/ovn-kubernetes/ovn-kubernetes/actions/runs/16001857006/job/45376421708?pr=5202\n\n### Since when has it been flaking?\n\n-\n\n### Reason for failure (if possible)\n\n_No response_\n\n### Anything else we need to know?\n\n_No response_",
      "updatedAt" : 1752273064.000000000,
      "user" : "npinaeva",
      "userHtmlUrl" : "https://github.com/npinaeva",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15113699?v=4",
      "labels" : [ "kind/ci-flake", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "++ seen it too. do any research on increasing instance disk size?", "this was raised in upstream community meeting and we are searching for volunteers to pick this up\ncc @martinkennelly / @jluhrsen \n\nbased on what we find, we had plans to proactively cleanup/create disk space or open ticket with github to understand why we are getting runners with full disk space", "- https://github.com/ovn-kubernetes/ovn-kubernetes/actions/runs/16154034033/job/45594089391?pr=5140\n- https://github.com/ovn-kubernetes/ovn-kubernetes/actions/runs/16154034033/job/45594089355?pr=5140", "If anyone wants to work on this please assign yourself to the issue so that we can know if its been worked on or not", "Hi! @tssurya I???m new to this project and would like to work on this issue. ", "thanks @sachinparihar ! I think you can start by looking at the above linked jobs to see how to improve things", "@tssurya , @sachinparihar , if we get [this PR](https://github.com/ovn-kubernetes/ovn-kubernetes/pull/5366) in it may help. This was a miss by me back when I added the 'Runner Diagnostics\" step to help such debugging.\n\nStill you may have info to look at right now that could help. the disk usage is collected in that step before and after the tests run. maybe check some passing jobs and see if anything stands out as a big disk hog." ],
      "repository" : {
        "description" : "A robust Kubernetes networking platform",
        "homepage" : "https://ovn-kubernetes.io/",
        "name" : "ovn-kubernetes",
        "fullName" : "ovn-kubernetes/ovn-kubernetes",
        "htmlUrl" : "https://github.com/ovn-kubernetes/ovn-kubernetes",
        "gitUrl" : "git://github.com/ovn-kubernetes/ovn-kubernetes.git",
        "sshUrl" : "git@github.com:ovn-kubernetes/ovn-kubernetes.git",
        "cloneUrl" : "https://github.com/ovn-kubernetes/ovn-kubernetes.git",
        "owner" : {
          "login" : "ovn-kubernetes",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 385,
        "stargazersCount" : 933,
        "watchersCount" : 933,
        "size" : 70552,
        "openIssuesCount" : 247,
        "subscribersCount" : 58,
        "pushedAt" : "2025-07-11T16:17:55Z",
        "languages" : {
          "Smarty" : 2483,
          "Shell" : 166696,
          "Jinja" : 1995,
          "Makefile" : 6293,
          "Go" : 11310777
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to identify and fix the cause of flaking jobs in CI due to no space left on device.",
      "validationOrRequirement" : "No specific validation or requirement mentioned, but the issue requires volunteers to pick it up and work on it.",
      "attemptedFixes" : "No specific fixes mentioned, but the author suggests looking at disk usage in passing jobs to identify big disk hogs and potentially checking the PR 5366.",
      "otherNotes" : "This issue is about flaking jobs in CI due to no space left on device. The issue is tracked through two links to GitHub Actions runs. The community meeting raised this issue and volunteers are needed to pick it up. The author suggests checking disk usage in passing jobs to identify big disk hogs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282848
  }, {
    "issueDTO" : {
      "id" : 2921640134,
      "title" : "Update doc to recommend to use PrimitiveBuilder or PrimitiveArray::from()",
      "url" : "https://github.com/apache/arrow-rs/issues/7297",
      "repositoryName" : "apache/arrow-rs",
      "description" : "**Is your feature request related to a problem or challenge? Please describe what you are trying to do.**\n<!--\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...] \n(This section helps Arrow developers understand the context and *why* for this feature, in addition to  the *what*)\n-->\n\nThere are 2 ways to create PrimitiveArray,\n\n1. PrimitiveBuilder like Int64Builder\n2. PrimitiveArray::from(vec![])\n\n\nI remember that option 2 is faster than option 1 in some cases, but I'm not sure if this is always true. It would be great to run some benchmarks to determine which option is preferable in different scenarios and document it so downstream user can easily follow which one to use.\n\n\n**Describe the solution you'd like**\n<!--\nA clear and concise description of what you want to happen.\n-->\n\n**Describe alternatives you've considered**\n<!--\nA clear and concise description of any alternative solutions or features you've considered.\n-->\n\nProvide a unify API for downstream so we can always create PrimitiveArray optimally.\n\n\n**Additional context**\n<!--\nAdd any other context or screenshots about the feature request here.\n-->\n\nThis idea also applies to other kind of Array",
      "updatedAt" : 1752272904.000000000,
      "user" : "jayzhan211",
      "userHtmlUrl" : "https://github.com/jayzhan211",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15869383?v=4",
      "labels" : [ "documentation", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "take", "@jayzhan211 I am interested in working on this (if @ajita-asthana you are not) but can you explain more what types of things should be benchmarked here? Are you seeing that doing a for loop over a `Vec<i64>` and adding each value to the builder may be faster than using `PrimitiveArray::from(Vec<i64>)` What are the **some cases** you are referring to?", "I added some benches in the above PR. using `::from` is faster for these cases. \n\n```\nprimitive_array_into_no_null          time:   [10.052 ??s 10.181 ??s 10.423 ??s]\nbuilder_no_null                       time:   [310.80 ??s 311.41 ??s 312.16 ??s]\nprimitive_array_into                  time:   [290.83 ??s 291.67 ??s 292.61 ??s]\nbuilder                               time:   [601.88 ??s 608.93 ??s 618.89 ??s]\n```\n\nWhat other cases can be tried?" ],
      "repository" : {
        "description" : "Official Rust implementation of Apache Arrow",
        "homepage" : "https://arrow.apache.org/",
        "name" : "arrow-rs",
        "fullName" : "apache/arrow-rs",
        "htmlUrl" : "https://github.com/apache/arrow-rs",
        "gitUrl" : "git://github.com/apache/arrow-rs.git",
        "sshUrl" : "git@github.com:apache/arrow-rs.git",
        "cloneUrl" : "https://github.com/apache/arrow-rs.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 969,
        "stargazersCount" : 3020,
        "watchersCount" : 3020,
        "size" : 46383,
        "openIssuesCount" : 494,
        "subscribersCount" : 53,
        "pushedAt" : "2025-07-11T19:47:53Z",
        "languages" : {
          "Shell" : 31792,
          "Rust" : 10964765,
          "Python" : 32170
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the documentation to recommend the use of PrimitiveBuilder or PrimitiveArray::from() for creating PrimitiveArray, with a focus on optimal creation and providing benchmarks to support the recommendation.",
      "validationOrRequirement" : "The issue requires the creation of a unified API for downstream users to create PrimitiveArray optimally.",
      "attemptedFixes" : "Some benches have been added to the PR, showing that using PrimitiveArray::from() is faster in some cases.",
      "otherNotes" : "The issue is related to PrimitiveArray creation, specifically recommending the use of PrimitiveBuilder or PrimitiveArray::from() for optimal creation. The author suggests running benchmarks to determine the preferable option in different scenarios and documenting the results.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282853
  }, {
    "issueDTO" : {
      "id" : 3219066369,
      "title" : "Remove `SECONDS_PER_SLOT` const and use `network_spec().seconds_per_slot` instead",
      "url" : "https://github.com/ReamLabs/ream/issues/637",
      "repositoryName" : "ReamLabs/ream",
      "description" : "### Describe the feature\n\nRemove `SECONDS_PER_SLOT` const and use `network_spec().seconds_per_slot` instead\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752272900.000000000,
      "user" : "KolbyML",
      "userHtmlUrl" : "https://github.com/KolbyML",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/31669092?v=4",
      "labels" : [ "help wanted", "good first issue", "Consensus" ],
      "state" : "OPEN",
      "comments" : [ "Hi, would love to take this, can I get assigned?", "@Dyslex7c assigned \uD83E\uDEE1 ", "@KolbyML just had one small query, adding the `ream-network-spec` package in the consensus engine creates some kind of a cyclic dependency so what should I do?", "> [@KolbyML](https://github.com/KolbyML) just had one small query, adding the `ream-network-spec` package in the consensus engine creates some kind of a cyclic dependency so what should I do?\n\nsplit the consensus crate into multiple internal crates would work well" ],
      "repository" : {
        "description" : "ream: an Ethereum Beam client written in Rust",
        "homepage" : "https://ream.rs",
        "name" : "ream",
        "fullName" : "ReamLabs/ream",
        "htmlUrl" : "https://github.com/ReamLabs/ream",
        "gitUrl" : "git://github.com/ReamLabs/ream.git",
        "sshUrl" : "git@github.com:ReamLabs/ream.git",
        "cloneUrl" : "https://github.com/ReamLabs/ream.git",
        "owner" : {
          "login" : "ReamLabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 49,
        "stargazersCount" : 102,
        "watchersCount" : 102,
        "size" : 1619,
        "openIssuesCount" : 92,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-08T08:18:09Z",
        "languages" : {
          "Dockerfile" : 1543,
          "Shell" : 320,
          "Rust" : 872611,
          "Makefile" : 3079
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace the `SECONDS_PER_SLOT` constant with the `network_spec().seconds_per_slot` value",
      "validationOrRequirement" : "Use `network_spec().seconds_per_slot` instead of the `SECONDS_PER_SLOT` const",
      "attemptedFixes" : "The comment suggests that splitting the consensus crate into multiple internal crates could be a solution to the cyclic dependency issue.",
      "otherNotes" : "Adding the `ream-network-spec` package in the consensus engine creates a cyclic dependency, a possible solution is to split the consensus crate into multiple internal crates.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282857
  }, {
    "issueDTO" : {
      "id" : 3224354622,
      "title" : "Optimize `reviewDoc.ts` to correctly handle removed lines when only reviewing changed chunks",
      "url" : "https://github.com/aymericzip/intlayer/issues/153",
      "repositoryName" : "aymericzip/intlayer",
      "description" : "## Background\n\nThe `@intlayer/cli` package provides two commands for translation workflows that are based on LLM translations :\n\n1. **Generate translations**\n\n   ```bash\n   npx intlayer doc translate --doc-pattern ./myFile.md\n   ```\n\n   This creates a translated version of your source file.\n\n2. **Review translations** (with optimization)\n\n   ```bash\n   npx intlayer doc review --doc-pattern ./myFile.md\n   ```\n\n   Intended to only re-review (and possibly re-translate) the chunks that have changed, saving API costs by skipping unchanged sections.\n\n---\n\n## The Problem\n\nAn optimization branch of code (around line 275 in [reviewDoc.ts](https://github.com/aymericzip/intlayer/blob/fba8b2d899ac0a89262ec8e17ac7804a0ccc812e/packages/%40intlayer/cli/src/reviewDoc.ts#L275) has been commented out. Re-enabling it:\n\n* ??? Works perfectly when the ???base translation??? file and the ???to-be-reviewed??? file have the **same number of lines**.\n* ??? Fails (produces bad formatting) when the **base file translated** is longer than the file under review (i.e. when lines have been removed in the source).\n\nIn other words, the current diff-based chunking logic doesn???t correctly handle cases where lines were deleted in the updated file, causing mis-aligned chunks and garbled output.\n\n---\n\n## Steps to Reproduce\n\n1. Prepare `original.md` and produce its translation:\n\n   ```bash\n   npx intlayer doc translate --doc-pattern original.md\n   ```\n2. Edit `original.md` to **remove** or **reorder** some lines.\n3. Run review:\n\n   ```bash\n   npx intlayer doc review --doc-pattern original.md\n   ```\n4. Observe that the translated output is misformatted or chunks are skipped incorrectly.\n\n---\n\n## Expected Behavior\n\n* **Only** the modified chunks (including those affected by line deletions) should be passed to the review/LLM step.\n* Unchanged chunks should remain exactly as in the existing translated file, preserving formatting.\n* The script should gracefully handle:\n\n  * Inserted lines\n  * Deleted lines\n  * Moved blocks\n\n---\n\n## Actual Behavior\n\n* When lines are deleted in the source, the diff-based chunk slicing falls out of sync.\n* Unchanged sections are sometimes reprocessed???or worse, dropped or mangled???resulting in formatting issues.",
      "updatedAt" : 1752272257.000000000,
      "user" : "aymericzip",
      "userHtmlUrl" : "https://github.com/aymericzip",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/62554073?v=4",
      "labels" : [ "onlydust-wave", "bug", "good first issue", "javascript" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Internationalisation solution for JS application focusing on scalability. Make your JavaScript / TypeScript application multilingue.",
        "homepage" : "https://intlayer.org",
        "name" : "intlayer",
        "fullName" : "aymericzip/intlayer",
        "htmlUrl" : "https://github.com/aymericzip/intlayer",
        "gitUrl" : "git://github.com/aymericzip/intlayer.git",
        "sshUrl" : "git@github.com:aymericzip/intlayer.git",
        "cloneUrl" : "https://github.com/aymericzip/intlayer.git",
        "owner" : {
          "login" : "aymericzip",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 23,
        "stargazersCount" : 189,
        "watchersCount" : 189,
        "size" : 227576,
        "openIssuesCount" : 26,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T22:54:35Z",
        "languages" : {
          "TypeScript" : 3497840,
          "Dockerfile" : 7710,
          "CSS" : 9638,
          "Rust" : 20334,
          "JavaScript" : 56707,
          "Vue" : 6700,
          "HTML" : 364
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Optimize `reviewDoc.ts` to correctly handle removed lines when only reviewing changed chunks",
      "validationOrRequirement" : "The requirement is to correctly handle cases where lines were deleted in the updated file, causing mis-aligned chunks and garbled output. The expected behavior is that only the modified chunks (including those affected by line deletions) should be passed to the review/LLM step.",
      "attemptedFixes" : "The issue is about re-enabling an optimization branch of code around line 275 in `reviewDoc.ts` which has been commented out.",
      "otherNotes" : "The issue is about optimizing the `reviewDoc.ts` file to correctly handle removed lines when only reviewing changed chunks. It's a bug in the existing code that causes formatting issues and chunk skipping when lines are deleted in the source file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282863
  }, {
    "issueDTO" : {
      "id" : 3224008597,
      "title" : "[ENHANCEMENT] OEP-0004: PVC Storage Support for BaseModel and ClusterBaseModel",
      "url" : "https://github.com/sgl-project/ome/issues/160",
      "repositoryName" : "sgl-project/ome",
      "description" : "# OEP-0004: PVC Storage Support for BaseModel and ClusterBaseModel\n\n<!-- toc -->\n- [Summary](#summary)\n- [Motivation](#motivation)\n  - [Goals](#goals)\n  - [Non-Goals](#non-goals)\n- [Proposal](#proposal)\n  - [User Stories](#user-stories)\n    - [Story 1: Using Models from Existing PVCs](#story-1-using-models-from-existing-pvcs)\n    - [Story 2: Shared Model Repository via NFS](#story-2-shared-model-repository-via-nfs)\n    - [Story 3: Block Storage Models](#story-3-block-storage-models)\n  - [Notes/Constraints/Caveats](#notesconstraintscaveats)\n  - [Risks and Mitigations](#risks-and-mitigations)\n- [Design Details](#design-details)\n  - [Architecture Overview](#architecture-overview)\n  - [Component Changes](#component-changes)\n    - [Model Agent Changes](#model-agent-changes)\n    - [BaseModel Controller Changes](#basemodel-controller-changes)\n    - [Metadata Extraction Job](#metadata-extraction-job)\n    - [InferenceService Controller Changes](#inferenceservice-controller-changes)\n  - [API Changes](#api-changes)\n  - [Test Plan](#test-plan)\n    - [Unit Tests](#unit-tests)\n    - [Integration Tests](#integration-tests)\n  - [Graduation Criteria](#graduation-criteria)\n- [Implementation History](#implementation-history)\n- [Drawbacks](#drawbacks)\n- [Alternatives](#alternatives)\n<!-- /toc -->\n\n## Summary\n\nThis OEP proposes adding PVC (Persistent Volume Claim) storage support to the OME model management system, allowing BaseModel and ClusterBaseModel resources to reference models stored in Kubernetes PVCs. The implementation uses a controller-based approach where the BaseModel controller validates PVC existence and creates Jobs for metadata extraction, while the model agent completely skips PVC storage types. This design enables users to leverage existing models in PVCs without requiring download to host paths, supporting both ReadWriteMany (RWX) and ReadWriteOnce (RWO) access modes.\n\n## Motivation\n\nCurrently, OME supports multiple storage backends (OCI Object Storage, HuggingFace, S3, etc.) but requires models to be downloaded to host paths before use. Many organizations already have models stored in PVCs backed by various storage systems (NFS, block storage, CSI drivers). Requiring these models to be re-uploaded to object storage or downloaded to every node creates unnecessary data duplication and operational overhead.\n\n### Goals\n\n1. Enable BaseModel/ClusterBaseModel to reference models stored in PVCs using URI format:\n   - BaseModel: `pvc://{pvc-name}/{sub-path}` (PVC in same namespace)\n   - ClusterBaseModel: `pvc://{namespace}/{pvc-name}/{sub-path}` (PVC in specified namespace)\n2. Support both ReadWriteMany (RWX) and ReadWriteOnce (RWO) access modes appropriately\n3. Automatically extract and populate model metadata (architecture, parameters, capabilities) from PVC-stored models\n4. Maintain compatibility with existing InferenceService scheduling and deployment mechanisms\n5. Provide clear error messages for PVC-related issues (not found, not bound, access conflicts)\n\n### Non-Goals\n\n1. Creating or managing PVCs - users must pre-create PVCs with models\n2. Model upload/download to PVCs - this OEP only covers reading existing models\n3. PVC provisioning or storage class configuration\n4. Cross-namespace PVC access for BaseModel - BaseModel can only access PVCs in its own namespace\n5. Supporting PVC storage for model downloads/caching by model agent\n\n## Proposal\n\nAdd PVC as a supported storage type with a streamlined approach:\n\n1. **Model Agent**: Skip PVC storage types entirely - no processing required\n2. **BaseModel Controller**: Validate PVC existence, create metadata extraction jobs, manage status\n3. **Metadata Extraction Job**: Mount PVC, extract metadata, update BaseModel CR\n4. **InferenceService Controller**: Mount PVC volumes directly without node selection requirements\n\n### User Stories\n\n#### Story 1: Using Models from Existing PVCs\n\nAs a platform engineer, I have large language models already stored in PVCs backed by high-performance storage. I want to create BaseModel resources that reference these PVCs directly without copying the models to object storage, reducing storage costs and eliminating redundant data transfer.\n\n#### Story 2: Shared Model Repository via NFS\n\nAs an ML team lead, we maintain a shared model repository on an NFS server exposed as ReadWriteMany PVCs. I want multiple InferenceService pods across different nodes to access the same model simultaneously, enabling efficient resource utilization without model duplication.\n\n#### Story 3: Block Storage Models\n\nAs a data scientist, I have models stored on high-performance block storage exposed as ReadWriteOnce PVCs. I want to deploy single-replica inference services that can exclusively mount and use these models with optimal I/O performance.\n\n### Notes/Constraints/Caveats\n\n1. **Model Agent Bypass**: \n   - Model agent ignores PVC storage types completely\n   - No node labeling by model agent for PVC storage\n   - Scheduling handled by Kubernetes based on PVC accessibility\n\n2. **Controller Responsibilities**:\n   - PVC validation happens in BaseModel controller\n   - Job creation and monitoring by controller\n   - Status updates based on job completion\n\n3. **PVC Access Modes**: \n   - RWX PVCs can be mounted by multiple pods simultaneously\n   - RWO PVCs can only be mounted by one pod at a time\n   - Kubernetes scheduler handles placement constraints automatically\n\n4. **Metadata Extraction**:\n   - Requires creating temporary Jobs to mount PVCs and read config.json\n   - Jobs run in the same namespace as the BaseModel\n   - Metadata extraction happens once per model\n\n5. **Namespace Handling**:\n   - **BaseModel**: PVC must be in the same namespace, URI format: `pvc://{pvc-name}/{sub-path}`\n   - **ClusterBaseModel**: PVC namespace must be specified in URI: `pvc://{namespace}/{pvc-name}/{sub-path}`\n   - For ClusterBaseModel, metadata extraction jobs are created in the PVC's namespace\n   - InferenceService pods will be scheduled in the PVC's namespace for ClusterBaseModel\n\n### Risks and Mitigations\n\n| Risk | Mitigation |\n|------|------------|\n| **Security**: Jobs mounting PVCs could access sensitive data | Jobs run with minimal RBAC permissions, only read access to specific PVC |\n| **Performance**: Metadata extraction jobs add latency | Jobs are created only once per model, results are cached in BaseModel CR |\n| **Resource Usage**: Additional jobs consume cluster resources | Jobs are ephemeral with resource limits, cleaned up after completion |\n| **PVC Availability**: PVC might be deleted while BaseModel exists | Controller continuously verifies PVC existence, updates status accordingly |\n| **Access Conflicts**: RWO PVCs could cause pod scheduling failures | Clear documentation on access modes, appropriate error messages |\n| **Model Agent Confusion**: Users expect model agent to handle all storage types | Clear documentation that PVC is handled differently |\n\n## Design Details\n\n### Architecture Overview\n\nThe architecture is designed to minimize complexity by having the model agent skip PVC storage entirely, while the BaseModel controller handles all PVC-related operations:\n\n```mermaid\nflowchart TD\n    BM[BaseModel<br/>PVC Storage] --> BMC[BaseModel<br/>Controller]\n    \n    BMC --> |Creates| MJ[Metadata Job]\n    \n    MA[Model Agent<br/>DaemonSet]\n    \n    MJ --> |Updates| BMU[BaseModel<br/>Updated CR]\n    BMU --> ISC[InferenceService<br/>Controller]\n    ISC --> |Creates| ISP[InferenceService<br/>Pods]\n    \n    %% Component details\n    BMC -.- BMCD[- Detect PVC URI<br/>- Validate PVC<br/>- Create Job<br/>- Monitor Job<br/>- Update Status]\n    MA -.- MAD[- Skip PVC types<br/>- Handle other<br/>storage types]\n    MJ -.- MJD[- Mount PVC<br/>- Read config<br/>- Update CR<br/>- Exit]\n    BMU -.- BMUD[- Model metadata<br/>- Status: Ready<br/>- Architecture<br/>- Parameters]\n    ISC -.- ISCD[- Read BaseModel<br/>- Create pods with<br/>PVC volumes<br/>- No node selector]\n    ISP -.- ISPD[- Mount PVC<br/>- Serve model]\n```\n\n**Key Design Decisions:**\n\n1. **Model Agent Skips PVC**: The model agent (DaemonSet) doesn't process PVC storage because:\n   - DaemonSet pods cannot effectively mount PVCs (especially RWO)\n   - PVC models don't need to be downloaded or verified on nodes\n   - Node labeling is irrelevant for PVC storage\n\n2. **Controller Owns Flow**: The BaseModel controller handles everything:\n   - Validates PVC exists and is bound\n   - Creates metadata extraction jobs\n   - Monitors job completion\n   - Updates BaseModel status directly\n\n3. **No Node Labeling**: Unlike downloaded models, PVC models don't need node labels because:\n   - Kubernetes scheduler already understands PVC constraints\n   - PVCs aren't tied to specific nodes\n   - InferenceService pods can run wherever the PVC is accessible\n\n### Component Changes\n\n#### Model Agent Changes\n\nIn `pkg/modelagent/gopher.go`, simply skip PVC storage:\n\n```go\nfunc (s *Gopher) downloadModel(ctx context.Context, task *GopherTask, modelInfo *ModelInfo) error {\n    // ... existing code ...\n    \n    storageType, err := storage.GetStorageType(*baseModelSpec.Storage.StorageUri)\n    if err != nil {\n        return fmt.Errorf(\"failed to determine storage type: %w\", err)\n    }\n    \n    switch storageType {\n    case storage.StorageTypePVC:\n        // Skip PVC storage - handled by controller\n        s.logger.Infof(\"Skipping PVC storage type for model %s (handled by BaseModel controller)\", modelInfo)\n        return nil\n        \n    case storage.StorageTypeOCI:\n        // ... existing OCI handling ...\n    \n    // ... other storage types ...\n    }\n}\n```\n\n#### BaseModel Controller Changes\n\nIn `pkg/controller/v1beta1/basemodel/controller.go`, add complete PVC handling:\n\n```go\nfunc (r *BaseModelReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\n    // ... existing code ...\n    \n    // Check if this is a PVC storage model\n    if r.isPVCStorage(baseModel) {\n        return r.reconcilePVCStorage(ctx, baseModel, log)\n    }\n    \n    // For non-PVC storage, use existing ConfigMap-based logic\n    if err := r.updateModelStatus(ctx, baseModel); err != nil {\n        log.Error(err, \"Failed to update BaseModel status\")\n        return ctrl.Result{RequeueAfter: time.Minute}, err\n    }\n    \n    return ctrl.Result{}, nil\n}\n\nfunc (r *BaseModelReconciler) reconcilePVCStorage(ctx context.Context, baseModel *v1beta1.BaseModel, log logr.Logger) (ctrl.Result, error) {\n    // Parse PVC URI\n    pvcComponents, err := storage.ParsePVCStorageURI(*baseModel.Spec.Storage.StorageUri)\n    if err != nil {\n        return r.updateFailedStatus(ctx, baseModel, fmt.Sprintf(\"Invalid PVC URI: %v\", err))\n    }\n    \n    // Determine namespace for PVC\n    pvcNamespace := baseModel.Namespace\n    if isClusterScoped(baseModel) && pvcComponents.Namespace != \"\" {\n        pvcNamespace = pvcComponents.Namespace\n    }\n    \n    // Validate PVC exists and is bound\n    pvc := &corev1.PersistentVolumeClaim{}\n    err = r.Get(ctx, types.NamespacedName{\n        Namespace: pvcNamespace,\n        Name:     pvcComponents.PVCName,\n    }, pvc)\n    \n    if err != nil {\n        if errors.IsNotFound(err) {\n            return r.updateFailedStatus(ctx, baseModel, fmt.Sprintf(\"PVC %s not found\", pvcComponents.PVCName))\n        }\n        return ctrl.Result{}, err\n    }\n    \n    if pvc.Status.Phase != corev1.ClaimBound {\n        return r.updateFailedStatus(ctx, baseModel, fmt.Sprintf(\"PVC %s not bound (phase: %s)\", pvcComponents.PVCName, pvc.Status.Phase))\n    }\n    \n    // Check if metadata already extracted\n    if r.isMetadataComplete(baseModel) {\n        return r.updateReadyStatus(ctx, baseModel)\n    }\n    \n    // Create metadata extraction job if needed\n    return r.ensureMetadataJob(ctx, baseModel, pvcComponents, pvc, log)\n}\n```\n\n#### Metadata Extraction Job\n\nCreate `cmd/ome-agent/model_metadata_agent.go`:\n\n```go\ntype ModelMetadataAgent struct {\n    k8sClient client.Client\n    logger    *zap.Logger\n}\n\nfunc (m *ModelMetadataAgent) Start() error {\n    modelPath := m.viper.GetString(\"model-path\")\n    baseModelName := m.viper.GetString(\"basemodel-name\")\n    baseModelNamespace := m.viper.GetString(\"basemodel-namespace\")\n    \n    // Extract model configuration\n    config, err := m.extractModelConfig(modelPath)\n    if err != nil {\n        return fmt.Errorf(\"failed to extract model config: %w\", err)\n    }\n    \n    // Update BaseModel CR with metadata\n    ctx := context.Background()\n    return m.updateBaseModel(ctx, baseModelNamespace, baseModelName, config)\n}\n```\n\n#### InferenceService Controller Changes\n\nIn `pkg/controller/v1beta1/inferenceservice/components/base.go`:\n\n```go\n// UpdatePodSpecVolumes - handle PVC storage type\nfunc UpdatePodSpecVolumes(b *BaseComponentFields, isvc *v1beta1.InferenceService, podSpec *corev1.PodSpec, objectMeta *metav1.ObjectMeta) {\n    if b.BaseModel != nil && b.BaseModel.Storage != nil {\n        storageType, _ := storage.GetStorageType(*b.BaseModel.Storage.StorageUri)\n        \n        if storageType == storage.StorageTypePVC {\n            pvcComponents, _ := storage.ParsePVCStorageURI(*b.BaseModel.Storage.StorageUri)\n            \n            modelVolume := corev1.Volume{\n                Name: b.BaseModelMeta.Name,\n                VolumeSource: corev1.VolumeSource{\n                    PersistentVolumeClaim: &corev1.PersistentVolumeClaimVolumeSource{\n                        ClaimName: pvcComponents.PVCName,\n                        ReadOnly:  true,\n                    },\n                },\n            }\n            podSpec.Volumes = append(podSpec.Volumes, modelVolume)\n            \n            // Set model path for volume mounts\n            modelPath := constants.ModelDefaultMountPath\n            b.BaseModel.Storage.Path = &modelPath\n        } else if b.BaseModel.Storage.Path != nil {\n            // Existing host path logic for downloaded models\n            // ...\n        }\n    }\n}\n\n// UpdatePodSpecNodeSelector - skip node selector for PVC storage\nfunc UpdatePodSpecNodeSelector(b *BaseComponentFields, isvc *v1beta1.InferenceService, podSpec *corev1.PodSpec) {\n    if b.BaseModel == nil || b.BaseModelMeta == nil {\n        return\n    }\n    \n    // Check storage type\n    if b.BaseModel.Storage != nil && b.BaseModel.Storage.StorageUri != nil {\n        storageType, _ := storage.GetStorageType(*b.BaseModel.Storage.StorageUri)\n        \n        if storageType == storage.StorageTypePVC {\n            // Skip node selector for PVC storage\n            b.Log.Info(\"Using PVC storage, skipping node selector\",\n                \"inferenceService\", isvc.Name, \n                \"storageUri\", *b.BaseModel.Storage.StorageUri)\n            return\n        }\n    }\n    \n    // Existing node selector logic for downloaded models\n    // ...\n}\n```\n\n### API Changes\n\nNo changes to the BaseModel/ClusterBaseModel API. The existing `storage.storageUri` field supports the new PVC URI formats:\n\n**BaseModel Example (PVC in same namespace):**\n```yaml\napiVersion: ome.io/v1beta1\nkind: BaseModel\nmetadata:\n  name: llama2-7b-pvc\n  namespace: models\nspec:\n  storage:\n    storageUri: \"pvc://model-storage-pvc/models/llama2-7b\"\n  modelFormat:\n    name: llama\n```\n\n**ClusterBaseModel Example (PVC in specified namespace):**\n```yaml\napiVersion: ome.io/v1beta1\nkind: ClusterBaseModel\nmetadata:\n  name: llama2-7b-shared\nspec:\n  storage:\n    storageUri: \"pvc://model-storage/model-storage-pvc/models/llama2-7b\"\n    # Format: pvc://{namespace}/{pvc-name}/{sub-path}\n  modelFormat:\n    name: llama\n```\n\n### Test Plan\n\n#### Unit Tests\n\n- `pkg/utils/storage/storage_test.go`: Test PVC URI parsing and validation\n- `pkg/modelagent/gopher_test.go`: Test PVC storage type skipping\n- `pkg/controller/v1beta1/basemodel/controller_test.go`: Test PVC validation and job creation\n- `cmd/ome-agent/model_metadata_agent_test.go`: Test metadata extraction logic\n\n#### Integration Tests\n\n1. **PVC Storage Flow**: Create BaseModel with PVC storage, verify controller creates job and updates status\n2. **Metadata Extraction**: Verify job creation and successful metadata population\n3. **InferenceService Deployment**: Deploy inference service with PVC model, verify pod scheduling\n4. **Access Mode Handling**: Test both RWX and RWO PVC scenarios\n5. **Error Cases**: Test with non-existent PVC, unbound PVC, invalid paths\n\n### Graduation Criteria\n\n**Alpha**:\n- Basic PVC storage support implemented\n- Controller validates PVC and creates jobs\n- Manual metadata specification supported\n\n**Beta**:\n- Automatic metadata extraction via jobs\n- Comprehensive error handling\n- Documentation and examples\n\n**Stable**:\n- Production usage validation\n- Performance optimization\n- Multi-namespace support consideration\n\n## Implementation History\n\n- 2024-12-XX: Initial OEP proposal\n- TBD: Implementation started\n- TBD: Alpha release\n- TBD: Beta release\n- TBD: GA release\n\n## Drawbacks\n\n1. **Different Flow**: PVC storage has a completely different flow than other storage types\n2. **Controller Complexity**: More logic in the BaseModel controller\n3. **Job Management**: Need to handle job lifecycle and cleanup\n4. **Debugging Complexity**: More components involved in the model lifecycle\n\n## Alternatives\n\n1. **Model Agent Handles Everything**: \n   - Rejected: DaemonSet can't effectively mount PVCs, especially RWO\n   - Would require complex coordination between model agents\n\n2. **Init Container Approach**: Use init containers in InferenceService pods to extract metadata\n   - Rejected: Would run for every pod, not just once per model\n\n3. **Require Pre-populated Metadata**: Make users specify all metadata manually\n   - Rejected: Poor user experience, error-prone\n\n4. **Separate Metadata Service**: Dedicated service for metadata extraction\n   - Rejected: Over-engineered for this use case\n\n5. **Webhook-based Validation**: Validate PVC in admission webhook\n   - Rejected: Doesn't solve metadata extraction problem\n\naddressing #159 ",
      "updatedAt" : 1752272252.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "design", "enhancement", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this OEP is to add PVC storage support to the OME model management system, allowing BaseModel and ClusterBaseModel resources to reference models stored in Kubernetes PVCs.",
      "validationOrRequirement" : "The proposal includes the following validation or requirements: 1. PVC URI format: pvc://{pvc-name}/{sub-path} (PVC in same namespace) or pvc://{namespace}/{pvc-name}/{sub-path} (PVC in specified namespace). 2. Model agent skips PVC storage types. 3. Controller validates PVC existence and creates jobs for metadata extraction.",
      "attemptedFixes" : "The proposal suggests the following attempts to solve the issue: 1. Model Agent Skips PVC - the model agent (DaemonSet) doesn't process PVC storage because DaemonSet pods cannot effectively mount PVCs (especially RWO), PVC models don't need to be downloaded or verified on nodes, and node labeling is irrelevant for PVC storage. 2. Controller Owns Flow - the BaseModel controller handles everything: validates PVC exists and is bound, creates metadata extraction jobs, monitors job completion, and updates BaseModel status directly.",
      "otherNotes" : "This OEP proposes adding PVC (Persistent Volume Claim) storage support to the OME model management system, allowing BaseModel and ClusterBaseModel resources to reference models stored in Kubernetes PVCs. The implementation uses a controller-based approach where the BaseModel controller validates PVC existence and creates Jobs for metadata extraction, while the model agent completely skips PVC storage types.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282873
  }, {
    "issueDTO" : {
      "id" : 196134493,
      "title" : "Add join/leave notifications for private channels",
      "url" : "https://github.com/zulip/zulip/issues/2746",
      "repositoryName" : "zulip/zulip",
      "description" : "I generally think IRC \"User joined/left\" notifications are pretty spammy and usually not useful in public channels/streams, but I think it could be a really useful feature for private streams.\r\n\r\nWe can have them be sent by the Zulip Notification bot like our new stream announcements, but sent to the stream in question.\r\n\r\n---\r\n\r\nUpdate by @alya (2024-12):\r\n\r\nNotification messages should be sent to the \"channel events\" topic, and should say:\r\n\r\n- `@_**user1** added @_**user2** to this channel.`\r\n- `@_**user** left this channel.`",
      "updatedAt" : 1752272122.000000000,
      "user" : "timabbott",
      "userHtmlUrl" : "https://github.com/timabbott",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2746074?v=4",
      "labels" : [ "help wanted", "area: channel settings", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'm taking this up @timabbott ", "For join/leave notification should I add the ```internal_send_message```  from notification bot to  ```do_reactivate_user```, ```do_deactivate_user``` methods  or create new method?", "@sinwar no, those are for user creation/deactivation; you should be modifying `bulk_add_subscription` and similar removal method.  ", "ok thanks @timabbott ", "@zulipbot claim.", "Hello @sinwar, you have been unassigned from this issue because you have not updated this issue or any referenced pull requests for over 14 days.\n\nYou can reclaim this issue or claim any other issue by commenting `@zulipbot claim` on that issue.\n\nThanks for your contributions, and hope to see you again soon!", "I would like to work on this if nobody is working on it?", "@zulipbot claim\r\n", "Welcome to Zulip, @vbomdica3! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n* Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n* Sign the [Dropbox Contributor License Agreement](https://opensource.dropbox.com/cla/), so that Zulip can use your code.\n* [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!", "Hi, I've started to work on this, and could anybody suggest which files/which areas in specific files I should focus my efforts on.", "Hello @vbomdica3, you have been unassigned from this issue because you have not updated this issue or any referenced pull requests for over 14 days.\n\nYou can reclaim this issue or claim any other issue by commenting `@zulipbot claim` on that issue.\n\nThanks for your contributions, and hope to see you again soon!", "@zulipbot claim", "Welcome to Zulip, @blevenson! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n* Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n* [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!", "Submitted a fix in PR #13488", "Hello @blevenson, you have been unassigned from this issue because you have not updated this issue or any referenced pull requests for over 14 days.\n\nYou can reclaim this issue or claim any other issue by commenting `@zulipbot claim` on that issue.\n\nThanks for your contributions, and hope to see you again soon!", "@zulipbot claim", "@s-bose7 You have been unassigned from this issue because you have not made any updates for over 14 days. Please feel free to reclaim the issue if you decide to pick up again. Thanks!\n", "@zulipbot claim", "Hello @hamatilo, it looks like you've currently claimed 1 issue in this repository. We encourage new contributors to focus their efforts on at most 1 issue at a time, so please complete your work on your other claimed issues before trying to claim this issue again.\n\nWe look forward to your valuable contributions!", "@zulipbot claim", "@zulipbot claim", "@zulipbot claim\r\n", "Submitted a PR for this in #18255", "@zulipbot claim", "Hello @arenton, it looks like you've currently claimed 1 issue in this repository. We encourage new contributors to focus their efforts on at most 1 issue at a time, so please complete your work on your other claimed issues before trying to claim this issue again.\n\nWe look forward to your valuable contributions!\n", "can i work on this issue", "@zulipbot claim", "Hello @s-bose7, it looks like you've currently claimed 1 issue in this repository. We encourage new contributors to focus their efforts on at most 1 issue at a time, so please complete your work on your other claimed issues before trying to claim this issue again.\n\nWe look forward to your valuable contributions!\n", "@zulipbot claim", "@zulipbot claim", "Welcome to Zulip, @notasandwichman! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n\n- Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n- [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!\n", "@alya  may I ask what do you mean by \"notification should be sent to stream events topic\"", "Exactly that. We currently send notifications about changes to a stream (e.g., renaming) to a topic called \"stream events\".", "If anyone working on this issue, please go through [my PR](https://github.com/zulip/zulip/pull/27231). You can modify that to solve the issue. Most of the work has been done. Stuck because of a failed API test case.  ", "I've taken it up.", "@zulipbot claim", "@shresth20 This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "@shresth20 are you working on this?\r\n", "> @shresth20 are you working on this?\n> \n\nNo", "@zulipbot claim", "@aarohim24 This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "@zulipbot claim", "@bciereszynski This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "@zulipbot claim\r\n", "@Md-Murthaza This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "@zulipbot claim", "@zulipbot claim", "@zulipbot claim", "Welcome to Zulip, @Rishi00786! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n\n- Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n- [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!\n", "@zulipbot unclaim", "@zulipbot claim", "Welcome to Zulip, @Sanchay117! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n\n- Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n- [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!\n", "@zulipbot claim", "@aadith247 This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "@zulipbot claim\r\n", "@Ritesh051 This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "@zulipbot claim\r\n", "Welcome to Zulip, @sushabhan878! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n\n- Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n- [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!\n", "@zulipbot claim", "@vasu962 This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "Pinging for others, I will be working on this one.\nThank you.", "Reassigned due to lack of activity, thanks.", "Can I work on this?\n", "Yes, you can\r\n\r\nOn Fri, 31 Jan 2025, 23:26 shashank pant, ***@***.***> wrote:\r\n\r\n> Can I work on this?\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/zulip/zulip/issues/2746#issuecomment-2627987370>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AVUOOFZZCLCPMGVMONH6OPL2NO2L7AVCNFSM4CZ6BG2KU5DIOJSWCZC7NNSXTN2JONZXKZKDN5WW2ZLOOQ5TENRSG44TQNZTG4YA>\r\n> .\r\n> You are receiving this because you were assigned.Message ID:\r\n> ***@***.***>\r\n>\r\n", "@shashank0470, I am still working on this one. Please find any other issues with label \"help wanted\".\nThank you.", "@zulipbot claim\n", "@EXCALIBUR-cmd This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "@zulipbot can i work on this issue?", "How do I do this issue?", "@zulipbot can i work on this issue?", "@zulipbot claim", "@danyasahib This issue cannot be claimed, as someone else is already working on it. Please see our [contributor guide](https://zulip.readthedocs.io/en/latest/overview/contributing.html#your-first-codebase-contribution) for advice on finding an issue to work on. Thanks!\n", "@zulipbot abandon\n", "Hello. Can I help with this project?", "@zulipbot claim", "Hey i would love to work on this \n", "@zulipbot  abandon", "**ERROR:** You have not claimed this issue to work on yet.", "Welcome to Zulip, @dexterhere04! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n\n- Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n- [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!\n", "abandoning because of updated in another issue \n@zulipbot abandon", "@zulipbot claim\n\nI'd like to work on this. I notice there have been previous attempts to work on this issue, but it's currently unassigned. I plan to help implement this if that's fine.", "Welcome to Zulip, @lztong1029! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n\n- Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n- [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!\n", "@zulipbot abandon", "@zulipbot  claim", "Welcome to Zulip, @sanskar-502! We just sent you an invite to collaborate on this repository at https://github.com/zulip/zulip/invitations. Please accept this invite in order to claim this issue and begin a fun, rewarding experience contributing to Zulip!\n\nHere's some tips to get you off to a good start:\n\n- Join me on the [Zulip developers' server](https://chat.zulip.org), to get help, chat about this issue, and meet the other developers.\n- [Unwatch this repository](https://help.github.com/articles/unwatching-repositories/), so that you don't get 100 emails a day.\n\nAs you work on this issue, you'll also want to refer to the [Zulip code contribution guide](https://zulip.readthedocs.io/en/latest/contributing/index.html), as well as the rest of the developer documentation on that site.\n\nSee you on the other side (that is, the pull request side)!\n", "@zulipbot abandon\n" ],
      "repository" : {
        "description" : "Zulip server and web application. Open-source team chat that helps teams stay productive and focused.",
        "homepage" : "https://zulip.com",
        "name" : "zulip",
        "fullName" : "zulip/zulip",
        "htmlUrl" : "https://github.com/zulip/zulip",
        "gitUrl" : "git://github.com/zulip/zulip.git",
        "sshUrl" : "git@github.com:zulip/zulip.git",
        "cloneUrl" : "https://github.com/zulip/zulip.git",
        "owner" : {
          "login" : "zulip",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 8550,
        "stargazersCount" : 23117,
        "watchersCount" : 23117,
        "size" : 537936,
        "openIssuesCount" : 2385,
        "subscribersCount" : 374,
        "pushedAt" : "2025-07-11T23:00:11Z",
        "languages" : {
          "CSS" : 1012873,
          "Handlebars" : 678469,
          "HTML" : 979426,
          "Perl" : 10353,
          "TypeScript" : 4594453,
          "Dockerfile" : 4219,
          "Shell" : 166395,
          "Astro" : 15770,
          "JavaScript" : 2510493,
          "Puppet" : 135184,
          "Ruby" : 3794,
          "Python" : 15412998,
          "Emacs Lisp" : 157
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add join/leave notifications for private channels in Zulip. This feature would be useful for users who want to be notified when someone joins or leaves a private channel.",
      "validationOrRequirement" : "The issue requires a good understanding of Zulip's codebase and notification system. The author, @alya, suggested sending the notifications to the 'channel events' topic, but it is unclear how this should be implemented.",
      "attemptedFixes" : "Several attempts have been made to work on this issue, but none have been successful. There is a PR #13488 that was submitted, but it was not completed. Another PR #18255 was submitted, but it was also not completed. There are also comments suggesting modifications to the `bulk_add_subscription` and similar removal method.",
      "otherNotes" : "The issue is about adding join/leave notifications for private channels. The author, @alya, suggested sending these notifications to the 'channel events' topic. There have been several attempts to work on this issue, but it is currently unassigned. The issue has been reassigned several times due to lack of activity. The issue has been abandoned multiple times, but there is still interest in working on it.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282883
  }, {
    "issueDTO" : {
      "id" : 2093880266,
      "title" : "\"Origin checking failed\" not fixable by CSRF_TRUSTED_ORIGINS?",
      "url" : "https://github.com/cvat-ai/cvat/issues/7382",
      "repositoryName" : "cvat-ai/cvat",
      "description" : "### Actions before raising this issue\n\n- [X] I searched the existing issues and did not find anything similar.\n- [X] I read/searched [the docs](https://github.com/cvat-ai/cvat/tree/master#documentation)\n\n### Steps to Reproduce\n\n1) Install CVAT 2.10.1 docker based, cloned from git, following  \"Quick installation guide\" (https://opencv.github.io/cvat/docs/administration/basics/installation/#quick-installation-guide) minutely\r\n2) Specify CVAT_HOST to the external IP on the LAN\r\n3) Log in to application succeeds\r\n4) Access to admin page and entering user properties succeeds\r\n5) Submitting via \"SAVE\" throws \r\na) \"Forbidden (403) CSRF verification failed. Request aborted. More information is available with DEBUG=True.\" in UI, and  \r\nb) \"DEBG 'uvicorn-1' stderr output: WARNING django.security.csrf: Forbidden (Origin checking failed - https://10.20.0.10 does not match any trusted origins.): /admin/auth/user/add/\" in log file\n\n### Expected Behavior\n\n1) Since access to the application and admin interface already succeed and work perfectly fine throughout the entire UI, POST interactions on the /admin page should not make a difference?\r\n2) If crosssite access is rightfully blocked by django's origin checking, because the accessing IP/FQDN is not yet in the list of \"trusted origins\", adding it via CSRF_TRUSTED_ORIGINS/SMOKESCREEN_OPTS should be possible and allow POST from /admin?\n\n### Possible Solution\n\nAccording to:\r\nhttps://github.com/opencv/cvat/issues/6516\r\nhttps://github.com/opencv/cvat/issues/6760 \r\nhttps://github.com/opencv/cvat/pull/6362\r\nhttps://github.com/opencv/cvat/issues/6760 \r\nhttps://github.com/doccano/doccano/issues/1820\r\n\r\nCSRF_TRUSTED_ORIGINS = [ 'https://10.20.0.10' ].\r\nand/or\r\nSMOKESCREEN_OPTS: \"trusted_origins=https://10.20.0.10\"\r\nShouldn't setting \"CSRF_TRUSTED_ORIGINS\" allow to add trusted domains/IPs to the origin checking whitelist?\n\n### Context\n\n1) The application has to run behind a reverse proxy:\r\n[ 0.0.0.0:8080 => 10.10.0.100:443 (Host)] => 10.20.0.100:443 (LAN)\r\nThe reverse proxy is terminating SSL, using an institutional certificate\r\n2) I tried to set \"CSRF_TRUSTED_ORIGINS\" and/or \"SMOKESCREEN_OPTS\" in docker-compose.yml and/or base.py, in several syntax variants, for just cvat_server and/or cvat_ui and/or globally\r\nbut it looks like this configuration gets never effective?\n\n### Environment\n\n```Markdown\nCVAT 2.10.1 cloned from Git and implemented exxactly following \"Quick installation guide\" (https://opencv.github.io/cvat/docs/administration/basics/installation/#quick-installation-guide), except for specifying CHAT_HOST=10.20.0.10.\r\nUnfortunately we need to host the application on our inhouse infrastructure due to inhouse policies.\n```\n",
      "updatedAt" : 1752271963.000000000,
      "user" : "kelbstf",
      "userHtmlUrl" : "https://github.com/kelbstf",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68855468?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@nmanovic can i work on this issue", "https://github.com/miroai/cvat/commit/1c97a44f849687f2551db6e1912b05cfe125bcfc\r\nAdding the base URL helped me. I ran into this issue trying to run it behind a reverse proxy some time ago, give it a try :)", "> [miroai@1c97a44](https://github.com/miroai/cvat/commit/1c97a44f849687f2551db6e1912b05cfe125bcfc) Adding the base URL helped me. I ran into this issue trying to run it behind a reverse proxy some time ago, give it a try :)\r\n\r\nI tried this issue, still I see the error: \"CSRF Failed: Origin checking failed - https://my domain url does not match any trusted origins.", "Error message I see after following all the steps and adding my doamin url in the relevant fields\r\nCSRF Failed: Origin checking failed - https://domainurl does not match any trusted origins.", "### Problem with CSRF\r\nError message I see after following all the steps and adding my doamin url in the relevant fields\r\nAlso set ALLOWED_HOSTS: '*'\r\nadded even CVAT_HOST: to docker-compose.yml\r\ncvat_server  | [2024-12-29 15:41:35,080] WARNING django.security.csrf: Forbidden (Origin checking failed - https://my does not match any trusted origins.): /admin/auth/user/add/\r\nAlso have this errors in grafana:\r\n```\r\n{\"basename\":\"events\",\"action\":\"create\",\"request\":{\"url\":\"/api/events?org=\",\"query_params\":{\"org\":\"\"},\"content_type\":\"application/json\",\"method\":\"POST\",\"id\":\"ec14b6b4-3595-4846-8403-13e85755babf\"},\"message\":\"rest_framework.exceptions.PermissionDenied: CSRF Failed: Origin checking failed - https://my does not match any trusted origins.\",\"stack\":\"Traceback (most recent call last):\\n  File \\\"/opt/venv/lib/python3.10/site-packages/rest_framework/views.py\\\", line 497, in dispatch\\n    self.initial(request, *args, **kwargs)\\n  File \\\"/opt/venv/lib/python3.10/site-packages/rest_framework/views.py\\\", line 414, in initial\\n    self.perform_authentication(request)\\n  File \\\"/opt/venv/lib/python3.10/site-packages/rest_framework/views.py\\\", line 324, in perform_authentication\\n    request.user\\n  File \\\"/opt/venv/lib/python3.10/site-packages/rest_framework/request.py\\\", line 231, in user\\n    self._authenticate()\\n  File \\\"/opt/venv/lib/python3.10/site-packages/rest_framework/request.py\\\", line 384, in _authenticate\\n    user_auth_tuple = authenticator.authenticate(self)\\n  File \\\"/opt/venv/lib/python3.10/site-packages/rest_framework/authentication.py\\\", line 130, in authenticate\\n    self.enforce_csrf(request)\\n  File \\\"/opt/venv/lib/python3.10/site-packages/rest_framework/authentication.py\\\", line 148, in enforce_csrf\\n    raise exceptions.PermissionDenied('CSRF Failed: %s' % reason)\\nrest_framework.exceptions.PermissionDenied: CSRF Failed: Origin checking failed - https://my does not match any trusted origins.\\n\",\"status_code\":403}\r\n```\r\n### Solution\r\nFixed with mounting to container `production.py` to `/home/django/cvat/setting/production.py` with \r\n```\r\nCSRF_TRUSTED_ORIGINS = [\r\n    'https://my',\r\n]\r\n```\r\nor in docker-compose.yml for `cvat_server`:\r\n```\r\n  volumes:\r\n      - <path>/production.py:/home/django/cvat/settings/production.py\r\n```", "This was pretty frustrating, same issue was raised here https://github.com/cvat-ai/cvat/issues/6321 and had an attached PR which was closed \r\n\r\nI followed this workaround: https://github.com/cvat-ai/cvat/pull/6322#issuecomment-2257131513 as overriding `production.py` caused some issues for me. ", "I fixed the issue by copying base.py from /home/django/cvat/settings/base.py inside the cvat_server service to my local machine. Then, I added CSRF_TRUSTED_ORIGINS to the file and mounted it as a volume. After that, everything worked.", "@thekavikumar Any updates on this issue? " ],
      "repository" : {
        "description" : "Annotate better with CVAT, the industry-leading data engine for machine learning. Used and trusted by teams at any scale, for data of any scale.",
        "homepage" : "https://cvat.ai",
        "name" : "cvat",
        "fullName" : "cvat-ai/cvat",
        "htmlUrl" : "https://github.com/cvat-ai/cvat",
        "gitUrl" : "git://github.com/cvat-ai/cvat.git",
        "sshUrl" : "git@github.com:cvat-ai/cvat.git",
        "cloneUrl" : "https://github.com/cvat-ai/cvat.git",
        "owner" : {
          "login" : "cvat-ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3281,
        "stargazersCount" : 14037,
        "watchersCount" : 14037,
        "size" : 343102,
        "openIssuesCount" : 584,
        "subscribersCount" : 180,
        "pushedAt" : "2025-07-11T17:58:38Z",
        "languages" : {
          "TypeScript" : 3768932,
          "Smarty" : 4928,
          "Dockerfile" : 11080,
          "Shell" : 10529,
          "Jinja" : 138,
          "SCSS" : 150336,
          "Open Policy Agent" : 84204,
          "JavaScript" : 1011491,
          "Mustache" : 206890,
          "HTML" : 29323,
          "Python" : 4228189
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the 'Origin checking failed' error when running CVAT behind a reverse proxy, which is preventing POST interactions on the /admin page.",
      "validationOrRequirement" : "The issue requires the trusted origin to be added to the CSRF_TRUSTED_ORIGINS setting, either in production.py or in docker-compose.yml.",
      "attemptedFixes" : "The author tried setting CSRF_TRUSTED_ORIGINS in docker-compose.yml and/or base.py, but it didn't work. They also tried overriding production.py, but it caused issues. The solution was to copy base.py, add CSRF_TRUSTED_ORIGINS, and mount it as a volume.",
      "otherNotes" : "The issue is related to running CVAT behind a reverse proxy and CSRF origin checking. The solution is to add the trusted origin to the CSRF_TRUSTED_ORIGINS setting, either in the production.py file or in the docker-compose.yml file for the cvat_server service.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282889
  }, {
    "issueDTO" : {
      "id" : 3223632637,
      "title" : "Warn user when adaptor field is empty on save",
      "url" : "https://github.com/transformerlab/transformerlab-app/issues/642",
      "repositoryName" : "transformerlab/transformerlab-app",
      "description" : "When trying to save the training template, it wouldn???t save ??? but there was no error shown. The issue was that the adaptor field was empty. It would be helpful to show a warning to the user explaining the problem.\n\n\nhttps://github.com/user-attachments/assets/66ae9313-a99f-4120-b693-b7d9dc884a62",
      "updatedAt" : 1752271389.000000000,
      "user" : "mina-parham",
      "userHtmlUrl" : "https://github.com/mina-parham",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/36207068?v=4",
      "labels" : [ "bug", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Maybe we use NotificationSystem to show any missing required fields here?" ],
      "repository" : {
        "description" : "Open Source Application for Advanced LLM + Diffusion Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.",
        "homepage" : "https://transformerlab.ai/",
        "name" : "transformerlab-app",
        "fullName" : "transformerlab/transformerlab-app",
        "htmlUrl" : "https://github.com/transformerlab/transformerlab-app",
        "gitUrl" : "git://github.com/transformerlab/transformerlab-app.git",
        "sshUrl" : "git@github.com:transformerlab/transformerlab-app.git",
        "cloneUrl" : "https://github.com/transformerlab/transformerlab-app.git",
        "owner" : {
          "login" : "transformerlab",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 306,
        "stargazersCount" : 3561,
        "watchersCount" : 3561,
        "size" : 11043,
        "openIssuesCount" : 66,
        "subscribersCount" : 30,
        "pushedAt" : "2025-07-11T22:08:59Z",
        "languages" : {
          "TypeScript" : 1424378,
          "CSS" : 8317,
          "Shell" : 580,
          "JavaScript" : 41863,
          "EJS" : 464
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Warn user when adaptor field is empty on save",
      "validationOrRequirement" : "Adaptor field should not be empty",
      "attemptedFixes" : "",
      "otherNotes" : "Maybe we use NotificationSystem to show any missing required fields here?",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282891
  }, {
    "issueDTO" : {
      "id" : 3157513477,
      "title" : "docs: document list calls to deprecated apis in audit docs",
      "url" : "https://github.com/open-policy-agent/gatekeeper/issues/4014",
      "repositoryName" : "open-policy-agent/gatekeeper",
      "description" : "document https://github.com/open-policy-agent/gatekeeper/issues/3923#issuecomment-2984909753 in audit docs",
      "updatedAt" : 1752270985.000000000,
      "user" : "sozercan",
      "userHtmlUrl" : "https://github.com/sozercan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/852750?v=4",
      "labels" : [ "docs", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@sozercan can I work on this issue ", "@blazethunderstorm assigning this to you\n" ],
      "repository" : {
        "description" : "\uD83D\uDC0A Gatekeeper - Policy Controller for Kubernetes",
        "homepage" : "https://open-policy-agent.github.io/gatekeeper/",
        "name" : "gatekeeper",
        "fullName" : "open-policy-agent/gatekeeper",
        "htmlUrl" : "https://github.com/open-policy-agent/gatekeeper",
        "gitUrl" : "git://github.com/open-policy-agent/gatekeeper.git",
        "sshUrl" : "git@github.com:open-policy-agent/gatekeeper.git",
        "cloneUrl" : "https://github.com/open-policy-agent/gatekeeper.git",
        "owner" : {
          "login" : "open-policy-agent",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 804,
        "stargazersCount" : 3935,
        "watchersCount" : 3935,
        "size" : 181759,
        "openIssuesCount" : 150,
        "subscribersCount" : 70,
        "pushedAt" : "2025-07-08T18:30:17Z",
        "languages" : {
          "Smarty" : 11784,
          "Dockerfile" : 6088,
          "Shell" : 59057,
          "CSS" : 4796,
          "Makefile" : 23208,
          "Open Policy Agent" : 9016,
          "JavaScript" : 11879,
          "Go" : 2253284,
          "Python" : 3915
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document list calls to deprecated APIs in audit docs.",
      "validationOrRequirement" : "Documenting list calls to deprecated APIs in audit docs, referencing a specific comment on GitHub.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is about documenting list calls to deprecated APIs in audit docs, referencing a specific comment on GitHub.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282894
  }, {
    "issueDTO" : {
      "id" : 2476216778,
      "title" : "When discovering iOS devices: `ProcessException: Resource temporarily unavailable`",
      "url" : "https://github.com/flutter/flutter/issues/153776",
      "repositoryName" : "flutter/flutter",
      "description" : "As of today (8/20), on 3.24.0: 221 reports from 102 unique clients (top 20ish crasher)\r\n\r\nFrom flutter commands (looking at first 20 reports): `flutter daemon`\r\n\r\n```\r\nProcessException: Resource temporarily unavailable  Command: /usr/bin/xcrun simctl list devices booted iOS --json\r\nat _ProcessImpl._start(process_patch.dart:402)\r\nat Process.start(process_patch.dart:38)\r\nat _runNonInteractiveProcess(process_patch.dart:579)\r\nat Process.run(process_patch.dart:49)\r\nat LocalProcessManager.run(local_process_manager.dart:72)\r\nat ErrorHandlingProcessManager.run.<anonymous closure>(error_handling_io.dart:669)\r\nat _run(error_handling_io.dart:564)\r\nat ErrorHandlingProcessManager.run(error_handling_io.dart:668)\r\nat _DefaultProcessUtils.run(process.dart:312)\r\nat SimControl._listBootedDevices(simulators.dart:162)\r\nat SimControl.getConnectedDevices(simulators.dart:187)\r\nat IOSSimulatorUtils.getAttachedDevices(simulators.dart:75)\r\nat IOSSimulators.pollingGetDevices(simulators.dart:49)\r\nat PollingDeviceDiscovery._initTimer.<anonymous closure>(device.dart:498)\r\nat _rootRun(zone.dart:1391)\r\nat _CustomZone.run(zone.dart:1301)\r\nat _CustomZone.runGuarded(zone.dart:1209)\r\nat _CustomZone.bindCallbackGuarded.<anonymous closure>(zone.dart:1249)\r\nat _rootRun(zone.dart:1399)\r\nat _CustomZone.run(zone.dart:1301)\r\nat _CustomZone.bindCallback.<anonymous closure>(zone.dart:1233)\r\nat Timer._createTimer.<anonymous closure>(timer_patch.dart:18)\r\nat _Timer._runTimers(timer_impl.dart:398)\r\nat _Timer._handleMessage(timer_impl.dart:429)\r\nat _RawReceivePort._handleMessage(isolate_patch.dart:184)\r\n```",
      "updatedAt" : 1752270906.000000000,
      "user" : "andrewkolos",
      "userHtmlUrl" : "https://github.com/andrewkolos",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9027551?v=4",
      "labels" : [ "tool-still-valid", "P2", "triaged-tool", "good first issue", "team-tool", "c: crash" ],
      "state" : "OPEN",
      "comments" : [ "`ErrorHandlingProcessManager` could handle this error code more generically and suggest the command be run again?", "> `ErrorHandlingProcessManager` could handle this error code more generically and suggest the command be run again?\r\n\r\nDoing some research around what `Resource temporarily unavailable` actually means, I think this is a good suggestion.", "I actually don't see this crash on 3.24.1? I might need to find a way to search the internal tool by GitHub issue ID\r\n\r\nedit: nevermind, it still exists, just at a lower rate (15 reports)", "https://github.com/flutter/flutter/pull/154306 seems like a fine change, though I don't think it's the right fix for this.  I think when devices are being discovered, if there's an error when getting the simulators (even a \"temp\" error) then the right thing would be to skip the simulators, not tool exit.\r\n\r\nIt looks like there may just be a missing check to see if the simulator command line is working:\r\nhttps://github.com/flutter/flutter/blob/55af75d57bc702d2cbd43ceaf2d5fd71c8f85d74/packages/flutter_tools/lib/src/ios/simulators.dart#L186-L187\r\n```diff\r\n+   if (!_xcode.isSimctlInstalled) {\r\n+     return <BootedSimDevice>[];\r\n+   }\r\n    final Map<String, Object?> devicesSection = await _listBootedDevices();\r\n```\r\n`isSimctlInstalled` will catch process errors:\r\nhttps://github.com/flutter/flutter/blob/55af75d57bc702d2cbd43ceaf2d5fd71c8f85d74/packages/flutter_tools/lib/src/macos/xcode.dart#L189-L191", "> #154306 seems like a fine change, though I don't think it's the right fix for this. I think when devices are being discovered, if there's an error when getting the simulators (even a \"temp\" error) then the right thing would be to skip the simulators, not tool exit.\r\n\r\nMakes sense. However, if we skip a discovery step for any reason, we should tell the user. Every now and then, users file issues in the class of \"flutter won't discover my device\", and these are very difficult to troubleshoot (many things can go wrong, high likelihood of user error, etc.)." ],
      "repository" : {
        "description" : "Flutter makes it easy and fast to build beautiful apps for mobile and beyond",
        "homepage" : "https://flutter.dev",
        "name" : "flutter",
        "fullName" : "flutter/flutter",
        "htmlUrl" : "https://github.com/flutter/flutter",
        "gitUrl" : "git://github.com/flutter/flutter.git",
        "sshUrl" : "git@github.com:flutter/flutter.git",
        "cloneUrl" : "https://github.com/flutter/flutter.git",
        "owner" : {
          "login" : "flutter",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28842,
        "stargazersCount" : 171336,
        "watchersCount" : 171336,
        "size" : 395594,
        "openIssuesCount" : 12122,
        "subscribersCount" : 3502,
        "pushedAt" : "2025-07-12T00:32:46Z",
        "languages" : {
          "PowerShell" : 12057,
          "Java" : 2850308,
          "C++" : 17160615,
          "CSS" : 6019,
          "C" : 628665,
          "Objective-C++" : 2834064,
          "CMake" : 100149,
          "HTML" : 34304,
          "Kotlin" : 342834,
          "Shell" : 159110,
          "Batchfile" : 27058,
          "JavaScript" : 78130,
          "Objective-C" : 662487,
          "Swift" : 65260,
          "Roff" : 55608,
          "HLSL" : 898,
          "Ruby" : 46804,
          "Lex" : 2069,
          "Dart" : 78320789,
          "Python" : 504541,
          "GLSL" : 210145
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "When discovering iOS devices, `ProcessException: Resource temporarily unavailable` is thrown, and it's causing crashes in the flutter daemon.",
      "validationOrRequirement" : "Any validations or specific requirements are not mentioned in the issue description.",
      "attemptedFixes" : "ErrorHandlingProcessManager could handle this error code more generically and suggest the command be run again. Also, #154306 seems like a fine change, though I don't think it's the right fix for this.",
      "otherNotes" : "There are 221 reports from 102 unique clients, top 20ish crasher, from flutter commands, `flutter daemon`. It seems like there may just be a missing check to see if the simulator command line is working. The author suggests that when devices are being discovered, if there's an error when getting the simulators (even a \"temp\" error) then the right thing would be to skip the simulators, not tool exit. Also, if we skip a discovery step for any reason, we should tell the user.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282901
  }, {
    "issueDTO" : {
      "id" : 3223128320,
      "title" : "Use `pytest.importorskip` to DRY tests with optional dependencies",
      "url" : "https://github.com/falconry/falcon/issues/2480",
      "repositoryName" : "falconry/falcon",
      "description" : "Suggested by @CaselIT: https://docs.pytest.org/en/7.1.x/how-to/skipping.html#skipping-on-a-missing-import-dependency.\n\nSo instead of writing\n```python\ntry:\n    import gunicorn  # noqa: F401\nexcept ImportError:\n    pytest.skip('gunicorn not installed')\n```\n...we can use the more succinct form:\n```python\ngunicorn = pytest.importorskip('gunicorn')  # No need for linter overrides either!\n```\n\nAlso see a more concrete snippet by @webknjaz how to DRY ASGI/WSGI server fixtures: https://github.com/falconry/falcon/pull/2479#discussion_r2200863676.",
      "updatedAt" : 1752270683.000000000,
      "user" : "vytas7",
      "userHtmlUrl" : "https://github.com/vytas7",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3430939?v=4",
      "labels" : [ "enhancement", "good first issue", "maintenance" ],
      "state" : "OPEN",
      "comments" : [ "@x612skm wanna give this a try?", "@webknjaz Hey! Yeah sure, I can take this! Thanks!" ],
      "repository" : {
        "description" : "The no-magic web API and microservices framework for Python developers, with an emphasis on reliability and performance at scale.",
        "homepage" : "https://falcon.readthedocs.io",
        "name" : "falcon",
        "fullName" : "falconry/falcon",
        "htmlUrl" : "https://github.com/falconry/falcon",
        "gitUrl" : "git://github.com/falconry/falcon.git",
        "sshUrl" : "git@github.com:falconry/falcon.git",
        "cloneUrl" : "https://github.com/falconry/falcon.git",
        "owner" : {
          "login" : "falconry",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 958,
        "stargazersCount" : 9689,
        "watchersCount" : 9689,
        "size" : 8152,
        "openIssuesCount" : 159,
        "subscribersCount" : 255,
        "pushedAt" : "2025-07-11T16:27:09Z",
        "languages" : {
          "Dockerfile" : 759,
          "Shell" : 2020,
          "CSS" : 1167,
          "Makefile" : 835,
          "JavaScript" : 2542,
          "HTML" : 2222,
          "Cython" : 27674,
          "Python" : 1946882
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Use pytest.importorskip to make tests more DRY and avoid writing boilerplate code for optional dependencies",
      "validationOrRequirement" : "None mentioned in the issue description or comments",
      "attemptedFixes" : "None mentioned in the issue description or comments",
      "otherNotes" : "The issue suggests using pytest.importorskip to make tests more DRY and avoid writing boilerplate code for optional dependencies. It also provides examples and references to other related issues.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282904
  }, {
    "issueDTO" : {
      "id" : 3224296814,
      "title" : "Add support for https://github.com/fosrl/pangolin",
      "url" : "https://github.com/amantus-ai/vibetunnel/issues/315",
      "repositoryName" : "amantus-ai/vibetunnel",
      "description" : "We already support ngrok, Tailscale, CF, so https://github.com/fosrl/pangolin would be a nice addition.\n\nThis is mostly UI work in the Mac app.",
      "updatedAt" : 1752270127.000000000,
      "user" : "steipete",
      "userHtmlUrl" : "https://github.com/steipete",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/58493?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Turn any browser into your terminal & command your agents on the go.",
        "homepage" : "https://vibetunnel.sh",
        "name" : "vibetunnel",
        "fullName" : "amantus-ai/vibetunnel",
        "htmlUrl" : "https://github.com/amantus-ai/vibetunnel",
        "gitUrl" : "git://github.com/amantus-ai/vibetunnel.git",
        "sshUrl" : "git@github.com:amantus-ai/vibetunnel.git",
        "cloneUrl" : "https://github.com/amantus-ai/vibetunnel.git",
        "owner" : {
          "login" : "amantus-ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 78,
        "stargazersCount" : 1098,
        "watchersCount" : 1098,
        "size" : 1017276,
        "openIssuesCount" : 47,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-11T23:42:43Z",
        "languages" : {
          "TypeScript" : 2760076,
          "Shell" : 318037,
          "C++" : 56337,
          "CSS" : 46325,
          "Rust" : 697976,
          "C" : 1727,
          "JavaScript" : 79869,
          "Swift" : 2132984,
          "HTML" : 59478,
          "Python" : 1412
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for https://github.com/fosrl/pangolin to the Mac app",
      "validationOrRequirement" : "Add support for https://github.com/fosrl/pangolin, similar to ngrok, Tailscale, CF",
      "attemptedFixes" : "",
      "otherNotes" : "This is mostly UI work in the Mac app.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282907
  }, {
    "issueDTO" : {
      "id" : 3197851366,
      "title" : "[BUG] The Backup YAML example in the Longhorn doc does not work",
      "url" : "https://github.com/longhorn/longhorn/issues/11216",
      "repositoryName" : "longhorn/longhorn",
      "description" : "### Describe the Bug\n\nThe Backup YAML example in [our doc website](https://longhorn.io/docs/1.9.0/snapshots-and-backups/backup-and-restore/create-a-backup) does not work. Because Longhorn mutator webhook requires providing [the correct `metadata.labels`](https://github.com/longhorn/longhorn-manager/blob/16f796214eb359cdb9f9efbe577a2de68144081b/webhook/resources/backup/mutator.go#L63-L67) while the doc does not mention that.\n\nThere are 2 solutions for this:\n- Simply updating the doc by adding `metadata.labels` for the example YAMLs\n- The mutator should figure out and set up the labels automatically based on the input `spec.snapshotName`\n\nNow I may prefer the latter one since this solution can both\n- provide a better user experience\n- and forcibly ask the mutator to check the volume and snapshot existence before backup creation\n\n### To Reproduce\n\n1. Create and attach a volume\n2. Create a random snapshot\n3. Apply the following backup YAML provided by the doc:\n```\napiVersion: longhorn.io/v1beta2\nkind: Backup\nmetadata:\n  name: backup-example\n  namespace: longhorn-system\nspec:\n  backupMode: full\n  snapshotName: <volume snapshot name>\n  labels:\n    app: test\n```\n\n### Expected Behavior\n\nThe backup should be created correctly\n\n### Support Bundle for Troubleshooting\n\n```\nubuntu:~$ kubectl apply -f backup.yaml\nError from server (InternalError): error when creating \"backup.yaml\": Internal error occurred: failed calling webhook \"mutator.longhorn.io\": failed to call webhook: post \"https://longhorn-admission-webhock.longhorn-system.svc:9502/v1/webhook/mutation?timeout=10s\": EOF\n```\n\n### Environment\n\n- Longhorn version: master-head (07/02/2025)\n\n### Additional context\n\nThis issue was found by community contributor @nzhan126  when she tried to test a backup-related fix. \n\n### Workaround and Mitigation\n\nSet up `matadata.labels` for the backup YAML. For example:\n```\napiVersion: longhorn.io/v1beta2\nkind: Backup\nmetadata:\n  name: backup-example\n  namespace: longhorn-system\n  labels:\n    backup-volume: <volume name>\nspec:\n  backupMode: full\n  snapshotName: <volume snapshot name>\n  labels:\n    app: test\n```\n",
      "updatedAt" : 1752270123.000000000,
      "user" : "shuo-wu",
      "userHtmlUrl" : "https://github.com/shuo-wu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47542419?v=4",
      "labels" : [ "kind/bug", "require/backport", "kind/doc", "priority/0", "area/admission-webhook", "component/longhorn-manager", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hi can I try to work on this one? Thanks! = ) @mantissahz ", "> hi can I try to work on this one? Thanks! = ) [@mantissahz](https://github.com/mantissahz)\n\nGo ahead. Thank you @nzhan126 ", ">hi can I try to work on this one? Thanks! = ) @mantissahz \n\nSurely. No problem. Thanks for contributing.", "Hi @nzhan126,\nDo we have any updates on this issue? ", "> Hi [@nzhan126](https://github.com/nzhan126), Do we have any updates on this issue?\n\n@mantissahz \nHi after a discussion with @shuo-wu we think further checks should be implemented for backup creation:\n1. check if  `Spec.SnapshotName` exists, if not, return error.\n2. check if `backup.Labels[types.LonghornLabelBackupVolume]` exists, if not infer volume name based on snapshot name\n3. check if `backup.Labels[types.LonghornLabelBackupVolume]` matches inferred volume name, if not, return error.\n4. check if `volume.Spec.BackupTargetName` matches `Labels[types.LonghornLabelBackupTarget]`, if not, return error.\n\nI am currently working on the implemetation and should be done by next Monday!\nThanks!\n" ],
      "repository" : {
        "description" : "Cloud-Native distributed storage built on and for Kubernetes",
        "homepage" : "https://longhorn.io",
        "name" : "longhorn",
        "fullName" : "longhorn/longhorn",
        "htmlUrl" : "https://github.com/longhorn/longhorn",
        "gitUrl" : "git://github.com/longhorn/longhorn.git",
        "sshUrl" : "git@github.com:longhorn/longhorn.git",
        "cloneUrl" : "https://github.com/longhorn/longhorn.git",
        "owner" : {
          "login" : "longhorn",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 645,
        "stargazersCount" : 6838,
        "watchersCount" : 6838,
        "size" : 17099,
        "openIssuesCount" : 1532,
        "subscribersCount" : 98,
        "pushedAt" : "2025-07-11T11:35:26Z",
        "languages" : {
          "Shell" : 42715,
          "Mustache" : 1972,
          "Python" : 6508
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Backup YAML example in the Longhorn doc does not work because Longhorn mutator webhook requires providing the correct `metadata.labels` while the doc does not mention that.",
      "validationOrRequirement" : "The Longhorn mutator webhook requires providing the correct `metadata.labels` while the doc does not mention that.",
      "attemptedFixes" : "The author @shuo-wu is currently working on implementing further checks for backup creation: 1. check if `Spec.SnapshotName` exists, if not, return error. 2. check if `backup.Labels[types.LonghornLabelBackupVolume]` exists, if not infer volume name based on snapshot name 3. check if `backup.Labels[types.LonghornLabelBackupVolume]` matches inferred volume name, if not, return error. 4. check if `volume.Spec.BackupTargetName` matches `Labels[types.LonghornLabelBackupTarget]`, if not, return error.",
      "otherNotes" : "The issue was found by community contributor @nzhan126 when she tried to test a backup-related fix. The workaround is to set up `matadata.labels` for the backup YAML. There are 2 solutions: updating the doc by adding `metadata.labels` for the example YAMLs, or the mutator should figure out and set up the labels automatically based on the input `spec.snapshotName`.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282916
  }, {
    "issueDTO" : {
      "id" : 1373663726,
      "title" : "[ENH] ensure that all estimators have two test parameter sets",
      "url" : "https://github.com/sktime/sktime/issues/3429",
      "repositoryName" : "sktime/sktime",
      "description" : "We should ensure that all estimators (that have parameters) possess at least two test parameter sets.\r\n\r\nThe two (or more) parameter sets should:\r\n\r\n* be fast to run together - `fit` is the bottleneck (so we should not overdo it with too many parameter sets)\r\n* cover substantially different settings for all the important parameters, i.e., substantially different typical cases and/or important edge cases\r\n\r\nRecipe:\r\n\r\n1. search for estimators which have parameters but only a single test parameter set. These are estimators with no `get_test_params` implemented, or `get_test_params` returning only a single dictionary instead of a list of two (or more) dictionaries.\r\n2. post here in this issue which estimator you picked (to avoid duplication of work)\r\n3. come up with a parameter set satisfying the above constraints and add it to the return (should be list of two or more dictionaries)\r\n4. make a PR, this should add the parameter set in `get_test_params`, and remove the estimator from `EXCLUDED_TESTS_BY_TEST` in `sktime.tests._config`\r\n\r\nAn example PR that adds second parameter sets for some estimators can be found here: https://github.com/alan-turing-institute/sktime/pull/3428\r\n\r\nFinding some estimators that have only one parameter set can be done quickly by checking the variable `EXCLUDED_TESTS_BY_TEST` in `sktime.tests._config`, estimators which do not comply with the \"number of test parameter sets\" requirements are skipping `\"test_get_test_params_coverage\"`.\r\n\r\nAlternatively, locally running code which does this:\r\n```python\r\nfrom sktime.registry import all_estimators\r\n\r\nall_ests = all_estimators()\r\n[x[0] for x in all_ests if (len(x[1].get_test_params())<2 or isinstance(x[1].get_test_params(), dict)) and len(x[1].get_param_names())>0]\r\n```\r\n\r\nCurrent output:\r\n- [x] `Aggregator`\r\n- [x] `BaggingForecaster`\r\n- [x] `CNNNetwork`\r\n- [ ] `ClaSPTransformer`\r\n- [ ] `ColumnEnsembleClassifier`\r\n- [ ] `ColumnTransformer`\r\n- [ ] `ColumnwiseTransformer`\r\n- [x] `ComposableTimeSeriesForestRegressor`\r\n- [x] `ConstraintViolation`\r\n- [x] `CutoffSplitter`\r\n- [ ] `DOBIN`\r\n- [ ] `DWTTransformer`\r\n- [ ] `DistFromAligner`\r\n- [ ] `DistanceFeatures`\r\n- [ ] `DontUpdate`\r\n- [ ] `DummyRegressor`\r\n- [x] `EmpiricalCoverage`\r\n- [x] `ExpandingWindowSplitter`\r\n- [x] `FCNNetwork`\r\n- [ ] `FeatureSelection`\r\n- [x] `Filter`\r\n- [x] `FinancialHolidaysTransformer`\r\n- [x] `FittedParamExtractor`\r\n- [ ] `GeometricMeanAbsoluteError`\r\n- [ ] `GeometricMeanRelativeAbsoluteError`\r\n- [ ] `GreedyGaussianSegmentation`\r\n- [x] `HCrystalBallAdapter`\r\n- [ ] `HOG1DTransformer`\r\n- [x] `HampelFilter`\r\n- [ ] `HolidayFeatures`\r\n- [ ] `InceptionTimeNetwork`\r\n- [ ] `IndividualBOSS`\r\n- [ ] `IndividualTDE`\r\n- [x] `KNeighborsTimeSeriesRegressor`\r\n- [x] `KalmanFilterTransformerFP`\r\n- [x] `KalmanFilterTransformerPK`\r\n- [x] `LSTMFCNNetwork`\r\n- [ ] `LogTransformer`\r\n- [ ] `MACNNNetwork`\r\n- [ ] `MCDCNNClassifier`\r\n- [ ] `MCDCNNNetwork`\r\n- [ ] `MCDCNNRegressor`\r\n- [ ] `MLPNetwork`\r\n- [ ] `MatrixProfile`\r\n- [ ] `MatrixProfileClassifier`\r\n- [ ] `MatrixProfileTransformer`\r\n- [ ] `MeanAbsoluteError`\r\n- [ ] `MeanRelativeAbsoluteError`\r\n- [ ] `MedianAbsoluteError`\r\n- [ ] `MedianRelativeAbsoluteError`\r\n- [ ] `MiniRocket`\r\n- [ ] `MiniRocketMultivariate`\r\n- [ ] `MiniRocketMultivariateVariable`\r\n- [ ] `MultiRocket`\r\n- [ ] `MultiRocketMultivariate`\r\n- [ ] `OnlineEnsembleForecaster`\r\n- [ ] `PAA`\r\n- [ ] `PCATransformer`\r\n- [ ] `PaddingTransformer`\r\n- [x] `ParamFitterPipeline`\r\n- [ ] `PlateauFinder`\r\n- [x] `PluginParamsForecaster`\r\n- [x] `PoissonHMM`\r\n- [x] `PyODAnnotator`\r\n- [x] `RNNNetwork`\r\n- [ ] `RandomIntervalFeatureExtractor`\r\n- [ ] `RandomIntervalSegmenter`\r\n- [ ] `RandomIntervals`\r\n- [ ] `RandomSamplesAugmenter`\r\n- [ ] `ReducerTransform`\r\n- [x] `ResNetNetwork`\r\n- [ ] `Rocket`\r\n- [x] `RocketClassifier`\r\n- [x] `RocketRegressor`\r\n- [x] `STRAY`\r\n- [x] `ShapeDTW`\r\n- [ ] `ShapeletTransform`\r\n- [x] `SingleWindowSplitter`\r\n- [ ] `SlidingWindowSegmenter`\r\n- [x] `SlidingWindowSplitter`\r\n- [ ] `SlopeTransformer`\r\n- [ ] `StackingForecaster`\r\n- [ ] `SupervisedTimeSeriesForest`\r\n- [x] `TSInterpolator`\r\n- [ ] `TapNetNetwork`\r\n- [x] `TestPlusTrainSplitter`\r\n- [x] `ThetaLinesTransformer`\r\n- [x] `ThetaModularForecaster`\r\n- [ ] `TimeBinner`\r\n- [ ] `TimeSeriesForestClassifier`\r\n- [ ] `TimeSeriesForestRegressor`\r\n- [x] `TimeSeriesKMeansTslearn`\r\n- [x] `TimeSeriesLloyds`\r\n- [ ] `TruncationTransformer`\r\n- [ ] `UnobservedComponents`\r\n- [ ] `WhiteNoiseAugmenter`\r\n- [x] `YtoX`",
      "updatedAt" : 1752269898.000000000,
      "user" : "fkiraly",
      "userHtmlUrl" : "https://github.com/fkiraly",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7985502?v=4",
      "labels" : [ "module:tests", "enhancement", "good first issue", "maintenance" ],
      "state" : "OPEN",
      "comments" : [ "Hi @fkiraly \r\n\r\nI???d like to to tackle this if it???s ok for you. ", "sure, @Abelarm - pick an estimator!", "I am picking SARIMAX.", "which estimators are still left?", "@julia-kraus, the failures in this diagnostic PR https://github.com/sktime/sktime/pull/2862 correspond to the ones that do have only one - it might not be 100% up to date, I'll restart it so it is:", "I would like to add the test params for the `HampelFilter`, that sounds interesting.", "I have worked on Rocket regression #6134", "Hi , can I take up this issue for the estimator:  \"TimeSeriesForestClassier\"\r\n@fkiraly ", "@namita0210, absolutely! All yours!", "Hi, I will try to tackle the MatrixProfileClassifier. @fkiraly ", "great, thanks, @MMTrooper!", "Hi @fkiraly,\r\n\r\nI'm currently working on adding new test parameter sets for the estimators identified in the issue. I'll be focusing on ``TimeSeriesKMeansTslearn``.\r\nI'll create a pull request once I've completed the changes and tests. In the meantime, please let me know if you have any suggestions.\r\n\r\nThanks!", "Hello @fkiraly , I will try to work on the estimator:- LogTransformer", "Hi @fkiraly , I will try to work on `KNeighborsTimeSeriesRegressor`.", "Hello @fkiraly,\r\nCould I please work on the `LSTMFCNNetwork`? \r\n\r\nThank you!!", "do you mean, you would like to work on `LSTMFCNNetwork`, or are you asking me to?", "@fkiraly, Oh I'm sorry about that! I meant if **I** could work on this! I wrote that while traveling, so sorry again!", "Sure! No worries, and thanks for contributing!\r\n\r\nFor this estimator, kindly be aware of:\r\n\r\n* failures reported in https://github.com/sktime/sktime/issues/6153 which you might encounter\r\n* the requirement to remove the test skip after fixing, as described in #6153 (or tests will not run)", "@fkiraly, Thank you so much for letting me help out!\r\nI'll keep my eye on the possible failures and I'll remove the test skips as well :)", "Hello @fkiraly,\r\n\r\nI hope that you're having a good start to your week! I wanted to let you know that I added 2 test parameters for the `LSTMFCNNetwork` [here](https://github.com/shlok191/sktime/blob/lstm_fcnn_networks/sktime/networks/lstmfcn.py). I also checked `tests/_config.py` to make sure that this estimator is included in CI tests. ?????? \r\n\r\nI am really excited to test out the test parameters and getting your feedback! I can try to test out the changes locally first if that is the preferred protocol. I learned a lot about LSTMs in the context of time series from this. I would really love to possibly contribute more after this estimator's parameters are completed if that is okay.\r\n\r\nThank you so much again!", "Great, @shlok191!\r\n\r\nI recommend you open a pull request, where core developers can discuss your contribution further and possiby merge it!", "@fkiraly, I just added a PR. Thanks a lot again for letting me contribute! \uD83D\uDE03 ", "`sktime` is an open project, so everyone can contribute!\r\n\r\nThanks for your contribution!", "Hey @fkiraly, I am working on `ColumnTransformer` for this issue.", "Hi @fkiraly, I have worked on `STRAY` and added a PR #7420  for it. I am really looking forward to getting your feedback and hopefully having this PR merged! ", "Hey @fkiraly,I am working on `BaggingForecaster` for this issue", "> Finding some estimators that have only one parameter set can be done quickly by checking the variable EXCLUDED_TESTS_BY_TEST in sktime.tests._config, estimators which do not comply with the \"number of test parameter sets\" requirements are skipping \"test_get_test_params_coverage\"\r\n\r\n@fkiraly the estimators in the above list and the ones generated by running the code mentioned in the issue do not match, is it because the list has not been updated yet or is there something I am missing? Thanks!\r\n\r\nUpdate: Checked the commits made above and a lot of them do not consist of updates to sktime.tests._config, may I know why?", "Copying my answer from discord:\r\n\r\nWe have probably forgotten in some instances to update the `EXCLUDED_TESTS_BY_TEST` variable! It might be a good idea to add a test that would ensure they are up to date.\r\n\r\nHowever, there is a caveat, as there is another edge case to take care of: if the estimator has no parameters except those in the tag `reserved_params`, then it is fine to have an empty `get_test_params`, this is not covered by the code.\r\n\r\nThe actual condition should have `len(x[1].get_param_names()) - len(x[1].get_tag(\"reserved_params\") ) > 0]` (and coerce `None` to an empty list)", "Hey @fkiraly, I am working on `DummyRegressor` for this issue", "Hey @fkiraly , I have created a PR on `TimeBinner` related to this issue", "Hi @fkiraly, I would like to contibute to this issue as a new contributor to open source", "@anoodsha, welcome to sktime!\n\nPick an estimator to work on (see list above)", "@fkiraly Hi, thank you , i would like to work on the following estimators from the list above (A-C): \nAggregator\n\nBaggingForecaster\n\nCNNNetwork\n\nClaSPTransformer\n\nColumnEnsembleClassifier\n\nColumnTransformer\n\nColumnwiseTransformer\n\nComposableTimeSeriesForestRegressor\n\nConstraintViolation\n\nCutoffSplitter\n\nHowever, I noticed the list of estimators when running the same code provided above from sktime.registry looks different from the estimators provided above. thank you ", "> However, I noticed the list of estimators when running the same code provided above from sktime.registry looks different from the estimators provided above. thank you\n\nThanks - we should update the list, maybe it is outdated.", "Hello @fkiraly \n\nI want to take:-\n\nLTSFDLinearForecaster\nLTSFLinearForecaster\nLTSFNLinearForecaster\n\nWhile these are not present in the list you posted with this PR, they are present in the list generated by the code you posted above.", "great, thanks!" ],
      "repository" : {
        "description" : "A unified framework for machine learning with time series",
        "homepage" : "https://www.sktime.net",
        "name" : "sktime",
        "fullName" : "sktime/sktime",
        "htmlUrl" : "https://github.com/sktime/sktime",
        "gitUrl" : "git://github.com/sktime/sktime.git",
        "sshUrl" : "git@github.com:sktime/sktime.git",
        "cloneUrl" : "https://github.com/sktime/sktime.git",
        "owner" : {
          "login" : "sktime",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1659,
        "stargazersCount" : 9149,
        "watchersCount" : 9149,
        "size" : 83131,
        "openIssuesCount" : 1527,
        "subscribersCount" : 112,
        "pushedAt" : "2025-07-11T08:53:14Z",
        "languages" : {
          "Dockerfile" : 1942,
          "CSS" : 8789,
          "Shell" : 1823,
          "Makefile" : 3358,
          "Jupyter Notebook" : 22524,
          "MATLAB" : 4442,
          "Python" : 11501863
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "ensure that all estimators have two test parameter sets, by identifying estimators that have only one parameter set and adding new test parameter sets for them.",
      "validationOrRequirement" : "estimators should have at least two test parameter sets, which should be fast to run together and cover substantially different settings for all the important parameters.",
      "attemptedFixes" : "some contributors are working on adding test parameter sets for various estimators, others are trying to identify and fix the issues with the code provided above.",
      "otherNotes" : "estimators that have only one parameter set can be done quickly by checking the variable `EXCLUDED_TESTS_BY_TEST` in `sktime.tests._config`, estimators which do not comply with the \"number of test parameter sets\" requirements are skipping \"test_get_test_params_coverage\". Additionally, there is an issue with the code provided above, as the actual condition should have `len(x[1].get_param_names()) - len(x[1].get_tag(\"reserved_params\") ) > 0]` (and coerce `None` to an empty list).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282924
  }, {
    "issueDTO" : {
      "id" : 3075232822,
      "title" : "Segfault in Einsum shape inference",
      "url" : "https://github.com/onnx/onnx/issues/6981",
      "repositoryName" : "onnx/onnx",
      "description" : "# Bug Report\n\n### Is the issue related to model conversion?\nThe attached model invokes Einsum shape inference. The input 0 shape comes in as a scalar which is not correctly handled.\n\n### Describe the bug\nThe shape is empty, however, it is being indexed which results in protobuf assert and exception in ONNXRuntime.\nHowever, onnx model checker simply kills the process. Apparently built with protobuf asserts disabled.\n\nThe code in question is introduced by https://github.com/onnx/onnx/pull/6010\n\n### System information\nAppears to be generic. If the onnx.checker line is commented out ONNXRuntime issues the following error in debug build which originates in ONNX code, see attached screenshots.\n\nonnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node () Op (Einsum) CHECK failed: (index) < (current_size_): \n\n### Reproduction instructions\n```\nimport onnx\nimport onnxruntime\n            \ndef main():\n    onnx_model = onnx.load(\"a397.onnx\")\n    onnx.checker.check_model(onnx_model, full_check=True)\n    \n    ort_session = onnxruntime.InferenceSession(\n            onnx_model.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n        )\n    \nif __name__ == \"__main__\":\n    \n    main()\n...\n```\nAdditionally, ONNX issues disallow attachments of type .onnx which I find amusing, since the bug report template asks for it.\n\n![Image](https://github.com/user-attachments/assets/5d321438-eaf8-45b0-97b9-589a1131b7c3)\n\n### Expected behavior\n<!-- A clear and concise description of what you expected to happen. -->\n\n### Notes\n<!-- Any additional information -->\n",
      "updatedAt" : 1752269868.000000000,
      "user" : "yuslepukhin",
      "userHtmlUrl" : "https://github.com/yuslepukhin",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11303988?v=4",
      "labels" : [ "bug", "contributions welcome", "good first issue", "module: shape inference" ],
      "state" : "OPEN",
      "comments" : [ "![Image](https://github.com/user-attachments/assets/5c34a9ac-4a78-414e-a40a-61b3df637662)", "Indexing an empty shape.\n<img width=\"548\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/23729c1a-3a6a-4d39-a169-1025727624e4\" />", "```textproto\nir_version: 10\nproducer_name: \"onnx-example\"\ngraph {\n  node {\n    input: \"input\"\n    output: \"maxpool_output\"\n    op_type: \"MaxPool\"\n    attribute {\n      name: \"auto_pad\"\n      s: \"VALID\"\n      type: STRING\n    }\n    attribute {\n      name: \"kernel_shape\"\n      ints: 2\n      ints: 2\n      type: INTS\n    }\n    attribute {\n      name: \"strides\"\n      ints: 2\n      ints: 2\n      type: INTS\n    }\n  }\n  node {\n    input: \"maxpool_output\"\n    output: \"reducemax_output\"\n    op_type: \"ReduceMax\"\n    attribute {\n      name: \"keepdims\"\n      i: 0\n      type: INT\n    }\n  }\n  node {\n    input: \"reducemax_output\"\n    input: \"greater_constant\"\n    output: \"greater_output\"\n    op_type: \"Greater\"\n  }\n  node {\n    input: \"reducemax_output\"\n    input: \"einsum_constant\"\n    output: \"einsum_output\"\n    op_type: \"Einsum\"\n    attribute {\n      name: \"equation\"\n      s: \"ij,ij->i\"\n      type: STRING\n    }\n  }\n  node {\n    input: \"einsum_output\"\n    output: \"reducemean_output\"\n    op_type: \"ReduceMean\"\n    attribute {\n      name: \"keepdims\"\n      i: 0\n      type: INT\n    }\n  }\n  name: \"ComplexModel\"\n  initializer {\n    dims: 1\n    data_type: 1\n    name: \"greater_constant\"\n    raw_data: \"\\000\\000\\200?\"\n  }\n  initializer {\n    dims: 1\n    dims: 3\n    data_type: 1\n    name: \"einsum_constant\"\n    raw_data: \"\\000\\000\\200?\\000\\000\\000@\\000\\000@@\"\n  }\n  input {\n    name: \"input\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 3\n          }\n          dim {\n            dim_value: 32\n          }\n          dim {\n            dim_value: 32\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"reducemean_output\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n        }\n      }\n    }\n  }\n}\nopset_import {\n  version: 22\n}\n```", "> ONNX issues disallow attachments of type .onnx which I find amusing, since the bug report template asks for it.\n\nyou may update the file as a zip in the future :)", "Potentially as 1.18.1?", "1.18.1 => why not\n\n( https://github.com/onnx/onnx/blob/main/RELEASE-MANAGEMENT.md#release-cadence But if we wait too long, 1.19 could also be something... I am not saying that one excludes the other )\n" ],
      "repository" : {
        "description" : "Open standard for machine learning interoperability",
        "homepage" : "https://onnx.ai/",
        "name" : "onnx",
        "fullName" : "onnx/onnx",
        "htmlUrl" : "https://github.com/onnx/onnx",
        "gitUrl" : "git://github.com/onnx/onnx.git",
        "sshUrl" : "git@github.com:onnx/onnx.git",
        "cloneUrl" : "https://github.com/onnx/onnx.git",
        "owner" : {
          "login" : "onnx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3763,
        "stargazersCount" : 19230,
        "watchersCount" : 19230,
        "size" : 39918,
        "openIssuesCount" : 312,
        "subscribersCount" : 437,
        "pushedAt" : "2025-07-12T00:15:30Z",
        "languages" : {
          "PowerShell" : 1371,
          "C++" : 2714343,
          "Shell" : 2433,
          "C" : 1905,
          "Batchfile" : 424,
          "CMake" : 27043,
          "PureBasic" : 2297160,
          "Python" : 3161188
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The shape is empty, however, it is being indexed which results in protobuf assert and exception in ONNXRuntime",
      "validationOrRequirement" : "The input 0 shape comes in as a scalar which is not correctly handled, protobuf assert and exception in ONNXRuntime",
      "attemptedFixes" : "ONNXRuntime issues the following error in debug build which originates in ONNX code, see attached screenshots",
      "otherNotes" : "The code in question is introduced by https://github.com/onnx/onnx/pull/6010, ONNX issues disallow attachments of type .onnx, potentially update the file as a zip in the future",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282929
  }, {
    "issueDTO" : {
      "id" : 3221722759,
      "title" : "[ONNX] Elu operator should support input tensor with any shape rather than only 1D",
      "url" : "https://github.com/onnx/onnx/issues/7119",
      "repositoryName" : "onnx/onnx",
      "description" : "According to https://onnx.ai/onnx/operators/onnx__Elu.html , Elu can only accept 1D input tensor.\nWhile as discussed here https://chromium-review.googlesource.com/c/chromium/src/+/6701350/comment/1a0925cc_0b168219/, it should support any shape.\n\n@fdwr ",
      "updatedAt" : 1752269852.000000000,
      "user" : "mingmingtasd",
      "userHtmlUrl" : "https://github.com/mingmingtasd",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/52519066?v=4",
      "labels" : [ "module: schema", "topic: operator", "contributions welcome", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This entire family of elementwise activation operators take any input shape...\n\n| Operator | Rank |\n|-----------|-------|\n| Relu | ND |\n| LeakyRelu | ND |\n| ThresholdedRelu | ND |\n| PRelu | ND |\n| Elu | 1D \uD83D\uDE43 |\n| Selu | ND |\n| Celu | ND |\n| Gelu | ND |\n\n...except that one oddball. Surely this is a typo?\n\nNote that all of [Elu](https://onnx.ai/onnx/operators/onnx__Elu.html)'s decompositions (where `f(x) = if x < 0 then alpha * (exp(x) - 1.) else f(x)`) accept any input shape and rank: `Constant`, `CastLike`, `Less`, `Exp`, `Sub`, `Mul`, `Where`.\n\n## Library References\n\n- ??? [ONNX](https://onnx.ai/onnx/operators/onnx__Elu.html) Elu\n- ??? [PyTorch](https://docs.pytorch.org/docs/stable/generated/torch.nn.ELU.html) supports ND Elu\n- ??? [WebNN](https://www.w3.org/TR/webnn/#api-mlgraphbuilder-elu) supports ND Elu\n- ??? [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/activations/elu) supports ND Elu\n\n```python\n####################\n# pip freeze torch==1.11.0+cpu\ninput = torch.tensor([[0.0, 1.1], [2.2, 3.3], [4.4, 5.5]])\nn = torch.nn.ELU()\noutput = n(input)\nprint(output)\n\n# tensor([[0.0000, 1.1000],\n#         [2.2000, 3.3000],\n#         [4.4000, 5.5000]])\n\n####################\n# pip freeze tensorflow==2.11.0\nimport tensorflow as tf\n\ninput  = tf.constant([[1.1,2.2],[3.3,4.4]])\noutput = tf.keras.activations.elu(input, alpha=1.0)\n\nprint(\"value:\", output)\nprint(\"shape:\", output.shape)\n\n# value: tf.Tensor(\n# [[1.1 2.2]\n#  [3.3 4.4]], shape=(2, 2), dtype=float32)\n# shape: (2, 2)\n```", "Has to be a typo. Would you like to create a PR to update the opset?" ],
      "repository" : {
        "description" : "Open standard for machine learning interoperability",
        "homepage" : "https://onnx.ai/",
        "name" : "onnx",
        "fullName" : "onnx/onnx",
        "htmlUrl" : "https://github.com/onnx/onnx",
        "gitUrl" : "git://github.com/onnx/onnx.git",
        "sshUrl" : "git@github.com:onnx/onnx.git",
        "cloneUrl" : "https://github.com/onnx/onnx.git",
        "owner" : {
          "login" : "onnx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3763,
        "stargazersCount" : 19230,
        "watchersCount" : 19230,
        "size" : 39918,
        "openIssuesCount" : 312,
        "subscribersCount" : 437,
        "pushedAt" : "2025-07-12T00:15:30Z",
        "languages" : {
          "PowerShell" : 1371,
          "C++" : 2714343,
          "Shell" : 2433,
          "C" : 1905,
          "Batchfile" : 424,
          "CMake" : 27043,
          "PureBasic" : 2297160,
          "Python" : 3161188
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to update the ONNX Elu operator to support input tensor with any shape rather than only 1D.",
      "validationOrRequirement" : "The requirement is to support input tensor with any shape rather than only 1D for the Elu operator, as per the documentation of ONNX and other libraries.",
      "attemptedFixes" : "None mentioned in the issue description.",
      "otherNotes" : "The issue is about supporting input tensor with any shape rather than only 1D for the Elu operator. This is based on the documentation of ONNX and other libraries such as PyTorch, WebNN, and TensorFlow which all support ND Elu.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282933
  }, {
    "issueDTO" : {
      "id" : 3224255393,
      "title" : "Don't repeat already visible status text in tooltip",
      "url" : "https://github.com/zulip/zulip/issues/35238",
      "repositoryName" : "zulip/zulip",
      "description" : "<!-- Issue description -->\n\nIn the right sidebar user tooltips, we should show the status text only if one of the following is true:\n\n1. The user list is displayed in the \"Compact\" style (i.e., the status text is hidden).\n2. The status text is too long to fit and is abbreviated in the right sidebar.\n\n<!-- Link to a message in the chat.zulip.org discussion. Message links will still work even if the topic is renamed or resolved. Link back to this issue from the chat.zulip.org thread. -->\n\nCZO thread: [#feedback > buddy list click targets are unclear @ \uD83D\uDCAC](https://chat.zulip.org/#narrow/channel/137-feedback/topic/buddy.20list.20click.20targets.20are.20unclear/near/2219185)\n",
      "updatedAt" : 1752269819.000000000,
      "user" : "alya",
      "userHtmlUrl" : "https://github.com/alya",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2090066?v=4",
      "labels" : [ "area: right-sidebar", "help wanted", "area: popovers", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello @zulip/server-sidebars members, this issue was labeled with the \"area: right-sidebar\" label, so you may want to check it out!\n\n<!-- areaLabelAddition -->\n", "Hi @alya, @zulipbot, I'd like to claim this issue. Could you please assign it to me?" ],
      "repository" : {
        "description" : "Zulip server and web application. Open-source team chat that helps teams stay productive and focused.",
        "homepage" : "https://zulip.com",
        "name" : "zulip",
        "fullName" : "zulip/zulip",
        "htmlUrl" : "https://github.com/zulip/zulip",
        "gitUrl" : "git://github.com/zulip/zulip.git",
        "sshUrl" : "git@github.com:zulip/zulip.git",
        "cloneUrl" : "https://github.com/zulip/zulip.git",
        "owner" : {
          "login" : "zulip",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 8550,
        "stargazersCount" : 23117,
        "watchersCount" : 23117,
        "size" : 537936,
        "openIssuesCount" : 2385,
        "subscribersCount" : 374,
        "pushedAt" : "2025-07-11T23:00:11Z",
        "languages" : {
          "CSS" : 1012873,
          "Handlebars" : 678469,
          "HTML" : 979426,
          "Perl" : 10353,
          "TypeScript" : 4594453,
          "Dockerfile" : 4219,
          "Shell" : 166395,
          "Astro" : 15770,
          "JavaScript" : 2510493,
          "Puppet" : 135184,
          "Ruby" : 3794,
          "Python" : 15412998,
          "Emacs Lisp" : 157
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "In the right sidebar user tooltips, show the status text only if it's not already visible",
      "validationOrRequirement" : "The status text should only be shown if one of the following is true: 1. The user list is displayed in the 'Compact' style, 2. The status text is too long to fit and is abbreviated in the right sidebar",
      "attemptedFixes" : "",
      "otherNotes" : "Link to a message in the chat.zulip.org discussion, CZO thread, areaLabelAddition",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282937
  }, {
    "issueDTO" : {
      "id" : 3223164654,
      "title" : "bug: check_pre_req.sh does not work for kflex 0.9.0",
      "url" : "https://github.com/kubestellar/kubestellar/issues/3078",
      "repositoryName" : "kubestellar/kubestellar",
      "description" : "### Describe the bug\n\nThere is a bug in `scripts/check_pre_req.sh`.\n\nIt works fine for kflex version < 0.9.0:\n\n```shell\n$ kflex version\nKubeflex version: v0.8.2.5fd5f9c 2025-03-10T14:58:02Z\nKubernetes version: v1.32.2\n\n$ scripts/check_pre_req.sh \n...\n??? KubeFlex (Kubeflex version: v0.8.2.5fd5f9c 2025-03-10T14:58:02Z)\n...\n```\n\nbut not for 0.9.0:\n\n```shell\n$ kflex version\nWARNING: current kflex version introduces BREAKING CHANGES related to kflex and your kubeconfig file which may interrupt kflex to function properly.\nSee https://github.com/kubestellar/kubeflex/blob/main/docs/users.md\nKubeflex version: v0.9.0.a2f9eab 2025-07-08T17:11:47Z\nKubernetes version: v1.32.2\n\n$ scripts/check_pre_req.sh \n...\n??? KubeFlex (WARNING: current kflex version introduces BREAKING CHANGES related to kflex and your kubeconfig file which may interrupt kflex to function properly.)\n...\n```\n\n### Output from KubeStellar-Snapshot.sh\n\nNot needed here\n\n### Steps To Reproduce\n\nSee above\n\n### Expected Behavior\n\nFor kflex 0.9.0, `check_pre_req.sh` should report the correct value of 0.9.0\n\n### Want to contribute?\n\n- [ ] I would like to work on this issue.\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752269766.000000000,
      "user" : "francostellari",
      "userHtmlUrl" : "https://github.com/francostellari",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/50019234?v=4",
      "labels" : [ "kind/bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/assign", "@francostellari is it open to work", "@blazethunderstorm go ahead, thank you!", "@francostellari thanks" ],
      "repository" : {
        "description" : "KubeStellar - a flexible solution for multi-cluster configuration management for edge, multi-cloud, and hybrid cloud",
        "homepage" : "https://kubestellar.io",
        "name" : "kubestellar",
        "fullName" : "kubestellar/kubestellar",
        "htmlUrl" : "https://github.com/kubestellar/kubestellar",
        "gitUrl" : "git://github.com/kubestellar/kubestellar.git",
        "sshUrl" : "git@github.com:kubestellar/kubestellar.git",
        "cloneUrl" : "https://github.com/kubestellar/kubestellar.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 152,
        "stargazersCount" : 430,
        "watchersCount" : 430,
        "size" : 209203,
        "openIssuesCount" : 195,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-11T17:08:49Z",
        "languages" : {
          "Smarty" : 2184,
          "Dockerfile" : 1303,
          "Shell" : 191983,
          "Makefile" : 14208,
          "Go" : 642085,
          "Python" : 30022
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "check_pre_req.sh does not work for kflex 0.9.0 and should report the correct value of 0.9.0",
      "validationOrRequirement" : "Report correct value of 0.9.0 for kflex 0.9.0",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "No response",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282940
  }, {
    "issueDTO" : {
      "id" : 3224271351,
      "title" : "release failure issue failing to be opened",
      "url" : "https://github.com/semantic-release/github/issues/1065",
      "repositoryName" : "semantic-release/github",
      "description" : "while working through semantic-release/npm#958, i had several situations where my configuration was not yet working, so semantic-release attempted to open the issue in the repo to report the release failure. an example failure can be found in https://github.com/travi-test/npm-oidc-test/actions/runs/16186374845/job/45692725649#step:5:106\n\nit appears that the way we are creating the issue is failing some sort of validation of labels on the github api side. unfortunately, the error gets collapsed to prevent the error from being obvious, so i havent dug deeper to understand the issue further: https://github.com/travi-test/npm-oidc-test/actions/runs/16186374845/job/45692725649#step:5:188\n\nthe issue gets created with `octokit.request` and i dont see anything obvious when comparing to the [rest api doc](https://docs.github.com/en/rest/issues/issues?apiVersion=2022-11-28#create-an-issue): https://github.com/semantic-release/github/blob/ecde3a8a58a7cda1ddb8d405d049f56d223afe23/lib/fail.js#L100",
      "updatedAt" : 1752269415.000000000,
      "user" : "travi",
      "userHtmlUrl" : "https://github.com/travi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/126441?v=4",
      "labels" : [ "bug", "Good first issue", "help wanted" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : ":octocat:  semantic-release plugin to publish a GitHub release and comment on released Pull Requests/Issues",
        "homepage" : "https://www.npmjs.com/package/@semantic-release/github",
        "name" : "github",
        "fullName" : "semantic-release/github",
        "htmlUrl" : "https://github.com/semantic-release/github",
        "gitUrl" : "git://github.com/semantic-release/github.git",
        "sshUrl" : "git@github.com:semantic-release/github.git",
        "cloneUrl" : "https://github.com/semantic-release/github.git",
        "owner" : {
          "login" : "semantic-release",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 139,
        "stargazersCount" : 464,
        "watchersCount" : 464,
        "size" : 3848,
        "openIssuesCount" : 67,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-11T20:37:42Z",
        "languages" : {
          "JavaScript" : 366849
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "release failure issue failing to be opened",
      "validationOrRequirement" : "some sort of validation of labels on the github api side",
      "attemptedFixes" : "haven't dug deeper to understand the issue further",
      "otherNotes" : "the issue gets created with octokit.request and i dont see anything obvious when comparing to the rest api doc",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282943
  }, {
    "issueDTO" : {
      "id" : 3194178442,
      "title" : "scxtop: add \"missing scheduler\" message",
      "url" : "https://github.com/sched-ext/scx/issues/2310",
      "repositoryName" : "sched-ext/scx",
      "description" : "If the scheduler is unloaded and one selects the scheduler view, it would be nice to get a message that tells you why the screen is empty instead of a bunch of empty panes. See #2309 for a bit of context.",
      "updatedAt" : 1752269389.000000000,
      "user" : "yaakov-stein",
      "userHtmlUrl" : "https://github.com/yaakov-stein",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/99366270?v=4",
      "labels" : [ "scxtop", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "As mentioned in #2379, it would also be nice to have a banner or pane message appear if one of the events fails to attach." ],
      "repository" : {
        "description" : "sched_ext schedulers and tools",
        "homepage" : "https://discord.gg/b2J8DrWa7t",
        "name" : "scx",
        "fullName" : "sched-ext/scx",
        "htmlUrl" : "https://github.com/sched-ext/scx",
        "gitUrl" : "git://github.com/sched-ext/scx.git",
        "sshUrl" : "git@github.com:sched-ext/scx.git",
        "cloneUrl" : "https://github.com/sched-ext/scx.git",
        "owner" : {
          "login" : "sched-ext",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 160,
        "stargazersCount" : 1343,
        "watchersCount" : 1343,
        "size" : 19116,
        "openIssuesCount" : 77,
        "subscribersCount" : 30,
        "pushedAt" : "2025-07-12T00:05:47Z",
        "languages" : {
          "Shell" : 22553,
          "C++" : 3659,
          "C" : 19248975,
          "Rust" : 1262478,
          "Meson" : 23315,
          "Python" : 33199
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "add a message to indicate why the screen is empty when scheduler is unloaded and scheduler view is selected",
      "validationOrRequirement" : "add a message when scheduler is unloaded and scheduler view is selected",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "See #2309 for a bit of context, also mentioned in #2379",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282945
  }, {
    "issueDTO" : {
      "id" : 3102475238,
      "title" : "[Feature]: AWS Bedrock as a provider",
      "url" : "https://github.com/nanobrowser/nanobrowser/issues/132",
      "repositoryName" : "nanobrowser/nanobrowser",
      "description" : "### What problem does this solve?\n\nTo be able to run models on the managed service bedrock in aws\n\n### Proposed solution\n\nTo get aws bedrock support and the models available there (or a set of them)\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752269248.000000000,
      "user" : "lezgin-bakircioglu-qred",
      "userHtmlUrl" : "https://github.com/lezgin-bakircioglu-qred",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/108487870?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "this is a good issue for ppl to work on if interested. currently dev has low priority on supporting extra model providers due to limited bandwidth. ", "I'd be happy to contribute on this, @Casslin!", "> I'd be happy to contribute on this, [@Casslin](https://github.com/Casslin)!\n\nthanks! assigned! ", "@AbdullahAdeebx were you able to finish this?", "No @mabblydev \n\nI don't have the bandwidth at the moment because of exams \uD83D\uDE2D\n\nAssign it to someone else if possible @Casslin \n", "> No [@mabblydev](https://github.com/mabblydev)\n> \n> I don't have the bandwidth at the moment because of exams \uD83D\uDE2D\n> \n> Assign it to someone else if possible [@Casslin](https://github.com/Casslin)\n\nok removed ur assignment. good luck w/ ur exams!", "ty @Casslin \n\nalso #130 pls unassign if possible \uD83D\uDE4F", "From Grok4 - if i get time later, ill play with it, but might lead someone in the right direction:\n\nTo add Amazon Bedrock support to Nanobrowser as a new LLM provider, the implementation leverages LangChain's `@langchain/aws` package for seamless integration with the existing architecture. This uses the `ChatBedrockConverse` class, which wraps the Bedrock Converse API for a unified chat interface across models (e.g., Claude, Llama, Mistral). This ensures compatibility with Nanobrowser's multi-agent system (e.g., Navigator, Planner, Validator agents), where each agent can be assigned a Bedrock model via the `createChatModel` function.\n\nNanobrowser's codebase already uses LangChain (`@langchain/core` v0.3.57 and provider-specific packages), so this aligns perfectly without custom API wrappers. The Converse API supports non-streaming and streaming responses; while Nanobrowser's agents currently use synchronous calls (e.g., via `model.invoke`), streaming can be added optionally for future real-time UI updates in the side panel.\n\nBased on the provided files (e.g., `package.json` for dependencies, `index.ts` for model creation via `createChatModel`, Vite config for builds, and storage for providers), the following changes are needed. These are verified against the LangChain Bedrock docs (e.g., constructor options for credentials, region, model ID, temperature) and GitHub examples (e.g., from langchain-ai/langchainjs repos using TypeScript with `@langchain/aws`).\n\n1. **Add dependency**: Update `package.json` to include the LangChain AWS package. Run `pnpm add @langchain/aws` (matches the existing pnpm workflow).\n\n```json\n{\n  // ... existing content ...\n  \"dependencies\": {\n    // ... existing dependencies ...\n    \"@langchain/aws\": \"^0.0.15\"  // Latest compatible with @langchain/core 0.3.57; supports Bedrock Converse API\n  }\n}\n```\n\n2. **Update `createChatModel` in `background/agent/helper.ts`** (assuming this file exists based on the import in `index.ts`; if not, create it or place in an appropriate helper module). Add a case for the 'bedrock' provider type. This function already handles other providers (e.g., OpenAI, Anthropic) by instantiating `BaseChatModel` subclasses. The Bedrock integration maps messages to the Converse format and handles authentication.\n\n```typescript\n// background/agent/helper.ts (add or update this file)\nimport { BaseChatModel } from '@langchain/core/language_models/chat_models';\n// Existing imports for other providers, e.g.:\nimport { ChatAnthropic } from '@langchain/anthropic';\nimport { ChatOpenAI } from '@langchain/openai';\n// ... other imports ...\n\n// New import for Bedrock\nimport { ChatBedrockConverse } from '@langchain/aws';\n\nimport type { LLMProviderConfig, AgentModel } from '../types';  // Adjust based on actual types\n\nexport function createChatModel(config: LLMProviderConfig, model: AgentModel): BaseChatModel {\n  switch (config.type) {\n    // Existing cases, e.g.:\n    case 'openai':\n      return new ChatOpenAI({\n        model: model.model,\n        apiKey: config.apiKey,\n        temperature: model.temperature ?? 0.5,\n        // ... other OpenAI options ...\n      });\n    case 'anthropic':\n      return new ChatAnthropic({\n        model: model.model,\n        apiKey: config.apiKey,\n        temperature: model.temperature ?? 0.5,\n        // ... other Anthropic options ...\n      });\n    // ... other existing providers ...\n\n    // New case for Bedrock\n    case 'bedrock':\n      return new ChatBedrockConverse({\n        model: model.model,  // e.g., 'anthropic.claude-3-sonnet-20240229-v1:0'\n        region: config.region ?? 'us-east-1',\n        credentials: {\n          accessKeyId: config.accessKeyId,\n          secretAccessKey: config.secretAccessKey,\n        },\n        temperature: model.temperature ?? 0.5,\n        topK: model.topK ?? 200,  // Passed via additionalInferenceParameters\n        maxTokens: model.maxTokens ?? 4096,\n        // Additional options for Bedrock Converse\n        additionalInferenceParameters: {\n          topK: model.topK ?? 200,\n          // Add more if needed, e.g., guardrails\n        },\n        // Enable streaming if Nanobrowser adds support (e.g., for side-panel real-time updates)\n        streaming: false,  // Set to true for streaming; requires agent updates to use model.stream()\n      });\n\n    default:\n      throw new Error(`Unsupported provider: ${config.type}`);\n  }\n}\n```\n\n3. **Update provider storage and types**: In `@extension/storage` (e.g., `llmProviderStore.ts`), add 'bedrock' as a valid provider type. Extend the `LLMProviderConfig` interface to include Bedrock-specific fields.\n\n```typescript\n// @extension/storage/types.ts (or similar)\nexport interface LLMProviderConfig {\n  type: 'openai' | 'anthropic' | /* ... existing */ | 'bedrock';\n  // Existing fields ...\n  // New for Bedrock\n  accessKeyId?: string;  // Required for Bedrock\n  secretAccessKey?: string;  // Required for Bedrock\n  region?: string;  // e.g., 'us-east-1'\n}\n\n// In llmProviderStore.ts, ensure getAllProviders() handles Bedrock configs\n```\n\n4. **Update settings UI for Bedrock configuration**: In `pages/options/src/Options.tsx` (React component for model settings), add 'bedrock' to the provider dropdown and render input fields for AWS credentials, region, and model options. This matches the pattern for other providers (e.g., API key inputs). Use state to handle values and save to `llmProviderStore`.\n\n```tsx\n// pages/options/src/Options.tsx\nimport { useState } from 'react';\n// ... existing imports ...\n\nconst providerTypes = [\n  // ... existing options ...\n  { value: 'bedrock', label: 'AWS Bedrock' },\n];\n\n// In the form rendering (e.g., inside a switch or conditional based on selectedProvider)\nif (selectedProvider === 'bedrock') {\n  const [accessKeyId, setAccessKeyId] = useState('');\n  const [secretAccessKey, setSecretAccessKey] = useState('');\n  const [region, setRegion] = useState('us-east-1');\n  const [model, setModel] = useState('anthropic.claude-3-sonnet-20240229-v1:0');\n  const [temperature, setTemperature] = useState(0.5);\n  const [topK, setTopK] = useState(200);\n\n  // On save, store via llmProviderStore.addProvider({ type: 'bedrock', accessKeyId, ... })\n\n  return (\n    <div>\n      <input type=\"text\" placeholder=\"AWS Access Key ID\" value={accessKeyId} onChange={(e) => setAccessKeyId(e.target.value)} />\n      <input type=\"password\" placeholder=\"AWS Secret Access Key\" value={secretAccessKey} onChange={(e) => setSecretAccessKey(e.target.value)} />\n      <input type=\"text\" placeholder=\"AWS Region (e.g., us-east-1)\" value={region} onChange={(e) => setRegion(e.target.value)} />\n      <input type=\"text\" placeholder=\"Model ID (e.g., anthropic.claude-3-sonnet-20240229-v1:0)\" value={model} onChange={(e) => setModel(e.target.value)} />\n      <input type=\"number\" placeholder=\"Temperature (0-1)\" value={temperature} step={0.1} onChange={(e) => setTemperature(parseFloat(e.target.value))} />\n      <input type=\"number\" placeholder=\"Top K\" value={topK} onChange={(e) => setTopK(parseInt(e.target.value))} />\n    </div>\n  );\n}\n```\n\n5. **Update agent assignment UI**: In the agent config section (likely in `Options.tsx` or a sub-component), allow selecting 'bedrock' as the provider for each agent (Navigator, Planner, Validator). Pass the config to `agentModelStore` for storage, ensuring `createChatModel` uses it in `index.ts`.\n\n6. **Handle streaming (optional enhancement)**: If adding real-time responses (e.g., in side-panel via port messages), update agent calls (e.g., in `Executor`) to use `model.stream()` instead of `invoke()`. For Bedrock:\n\n```typescript\n// In agent logic, e.g., for chat completion\nasync function* streamResponse(model: BaseChatModel, messages: AIMessage[]) {\n  const stream = await model.stream(messages);\n  for await (const chunk of stream) {\n    yield chunk.content;  // Send to port.postMessage for UI updates\n  }\n}\n```\n\n7. **Build and test updates**: Run `pnpm build` (uses Vite config). Test by configuring Bedrock in options, assigning to an agent, and running a task like \"Navigate to amazon.com and find the top deal.\" Ensure AWS IAM permissions include `bedrock:InvokeModel`. Handle errors in `createLogger` (e.g., auth failures). For vision (if enabled in settings), note Bedrock models like Claude support multimodal but require image handling updates.\n\nThis integration is complete, LangChain-aligned, and improves on the custom provider by reusing existing abstractions. Submit as a PR following CONTRIBUTING.md." ],
      "repository" : {
        "description" : "Open-Source Chrome extension for AI-powered web automation. Run multi-agent workflows using your own LLM API key. Alternative to OpenAI Operator.",
        "homepage" : "",
        "name" : "nanobrowser",
        "fullName" : "nanobrowser/nanobrowser",
        "htmlUrl" : "https://github.com/nanobrowser/nanobrowser",
        "gitUrl" : "git://github.com/nanobrowser/nanobrowser.git",
        "sshUrl" : "git@github.com:nanobrowser/nanobrowser.git",
        "cloneUrl" : "https://github.com/nanobrowser/nanobrowser.git",
        "owner" : {
          "login" : "nanobrowser",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 779,
        "stargazersCount" : 7807,
        "watchersCount" : 7807,
        "size" : 838,
        "openIssuesCount" : 27,
        "subscribersCount" : 46,
        "pushedAt" : "2025-07-08T02:59:22Z",
        "languages" : {
          "TypeScript" : 569341,
          "CSS" : 4368,
          "Shell" : 515,
          "JavaScript" : 66453,
          "HTML" : 2594
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add Amazon Bedrock as a new LLM provider to Nanobrowser, allowing users to run models on the managed service Bedrock in AWS.",
      "validationOrRequirement" : "Add dependency: Update package.json to include the LangChain AWS package. Update createChatModel in background/agent/helper.ts to include a case for the 'bedrock' provider type. Update provider storage and types in @extension/storage. Update settings UI for Bedrock configuration in pages/options/src/Options.tsx. Update agent assignment UI to allow selecting 'bedrock' as the provider for each agent. Handle streaming (optional enhancement). Build and test updates.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "This issue aims to add Amazon Bedrock as a new LLM provider to Nanobrowser, leveraging LangChain's @langchain/aws package for seamless integration with the existing architecture. The implementation involves updating package.json to include the LangChain AWS package, adding a case for the 'bedrock' provider type in createChatModel, updating provider storage and types, updating settings UI for Bedrock configuration, updating agent assignment UI, handling streaming (optional enhancement), and building and testing updates.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282954
  }, {
    "issueDTO" : {
      "id" : 3217911793,
      "title" : "[Term Entry] JavaScript Arrays: .entries()",
      "url" : "https://github.com/Codecademy/docs/issues/7309",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `.entries()` under arrays in JavaScript. The entry should be in `content/javascript/concepts/arrays/terms/entries/entries.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that show an example of the current entry.\n- An ## Codebyte section that have a compilable code inside it showing the current entry in use. Use ```codebyte/javascript to add compilable code.\n\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752268789.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "good first issue", "javascript" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I would like to work on this issue. " ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new term entry for `.entries()` under arrays in JavaScript, including description, syntax, example, and codebyte section with compilable code.",
      "validationOrRequirement" : "The entry should include a description of the term, syntax, example, and codebyte section with compilable code.",
      "attemptedFixes" : "",
      "otherNotes" : "Please refer to the term entry template, content standards, and markdown style guide when working on the PR for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282957
  }, {
    "issueDTO" : {
      "id" : 2338522331,
      "title" : "Add ANSI support for Multiply",
      "url" : "https://github.com/apache/datafusion-comet/issues/534",
      "repositoryName" : "apache/datafusion-comet",
      "description" : "### What is the problem the feature request solves?\n\nSpark has specific handling of overflows when ANSI mode is enabled and we need to add the same in Comet.\n\n### Describe the potential solution\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752268666.000000000,
      "user" : "andygrove",
      "userHtmlUrl" : "https://github.com/andygrove",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/934084?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\r\nHello @andygrove I would like to work on this issue. Can you please assign it to me\r\n\r\n", "Thank you @jatin510 . Assigned to you now.", "I am planning to implement my solution based on  https://github.com/apache/datafusion-comet/pull/616 . Will resume once the PR is merged" ],
      "repository" : {
        "description" : "Apache DataFusion Comet Spark Accelerator",
        "homepage" : "https://datafusion.apache.org/comet",
        "name" : "datafusion-comet",
        "fullName" : "apache/datafusion-comet",
        "htmlUrl" : "https://github.com/apache/datafusion-comet",
        "gitUrl" : "git://github.com/apache/datafusion-comet.git",
        "sshUrl" : "git@github.com:apache/datafusion-comet.git",
        "cloneUrl" : "https://github.com/apache/datafusion-comet.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 222,
        "stargazersCount" : 989,
        "watchersCount" : 989,
        "size" : 19074,
        "openIssuesCount" : 249,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-11T21:47:57Z",
        "languages" : {
          "Java" : 477078,
          "Dockerfile" : 6894,
          "Shell" : 29303,
          "Rust" : 1894706,
          "Scala" : 1652880,
          "Makefile" : 5518,
          "Python" : 8374
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add ANSI support for Multiply in Comet, enabling similar handling of overflows as in Spark when ANSI mode is enabled.",
      "validationOrRequirement" : "Add ANSI support for Multiply, specific handling of overflows when ANSI mode is enabled, similar to Spark's handling.",
      "attemptedFixes" : "No attempted fixes mentioned in the comments, but the author plans to implement a solution based on a PR (https://github.com/apache/datafusion-comet/pull/616) and will resume once it's merged.",
      "otherNotes" : "No potential solution described, but the issue is labeled as good first issue and enhancement, suggesting it's a beginner-friendly task.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282961
  }, {
    "issueDTO" : {
      "id" : 2338520973,
      "title" : "Add ANSI support for Divide and IntegralDivide",
      "url" : "https://github.com/apache/datafusion-comet/issues/533",
      "repositoryName" : "apache/datafusion-comet",
      "description" : "### What is the problem the feature request solves?\n\nSpark has specific handling of overflows when ANSI mode is enabled and we need to add the same in Comet.\n\n### Describe the potential solution\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752268122.000000000,
      "user" : "andygrove",
      "userHtmlUrl" : "https://github.com/andygrove",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/934084?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I want to take this one!", "Thanks @hycsam " ],
      "repository" : {
        "description" : "Apache DataFusion Comet Spark Accelerator",
        "homepage" : "https://datafusion.apache.org/comet",
        "name" : "datafusion-comet",
        "fullName" : "apache/datafusion-comet",
        "htmlUrl" : "https://github.com/apache/datafusion-comet",
        "gitUrl" : "git://github.com/apache/datafusion-comet.git",
        "sshUrl" : "git@github.com:apache/datafusion-comet.git",
        "cloneUrl" : "https://github.com/apache/datafusion-comet.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 222,
        "stargazersCount" : 989,
        "watchersCount" : 989,
        "size" : 19074,
        "openIssuesCount" : 249,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-11T21:47:57Z",
        "languages" : {
          "Java" : 477078,
          "Dockerfile" : 6894,
          "Shell" : 29303,
          "Rust" : 1894706,
          "Scala" : 1652880,
          "Makefile" : 5518,
          "Python" : 8374
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add ANSI support for Divide and IntegralDivide in Comet to handle overflows when ANSI mode is enabled.",
      "validationOrRequirement" : "Add ANSI support for Divide and IntegralDivide in Comet, specifically for handling overflows when ANSI mode is enabled.",
      "attemptedFixes" : "No potential solution or additional context provided in the description.",
      "otherNotes" : "The issue is about adding ANSI support for Divide and IntegralDivide in Comet, specifically for handling overflows when ANSI mode is enabled.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282965
  }, {
    "issueDTO" : {
      "id" : 3224206054,
      "title" : "Eventbrite: Remove order_by from API Request and Consider any Other Tweaks",
      "url" : "https://github.com/hackgvl/hackgreenville-com/issues/589",
      "repositoryName" : "hackgvl/hackgreenville-com",
      "description" : "This email was from May 27.   The changes haven't, not surprisingly, changed things for us.\n\nThough, I thought we might still want to remove the obsolete field and see if their note about _start_date.range_start_ would have us do anything.\n\n> Hey Eventbrite Customer,\n> \n> We're contacting you as a user of Eventbrite's API, which you may be using to display upcoming events on your website.\n> \n> We???re implementing performance improvements to our API on Thursday, May 29, which will require action on your part to ensure your integration continues to run smoothly.\n> \n> The following information is intended for people who are familiar with administrating APIs:\n> \n> We are making changes to the API endpoint : /v3/organizers/{organizer_id}/events\n> \n> What???s changing\n> \n> Sorting will no longer be supported: The order_by parameter will be accepted but will have no effect. This change improves performance and simplifies data retrieval.\n> \n> Default date filtering will change: If start_date.range_start is not specified, the endpoint will return events starting from 24 hours before the current time (to include current and upcoming events by default).\n> \n> What will no longer work\n> \n> Any sorting logic that relied on the order_by parameter will no longer influence the order of results.\n> \n> If you expect to retrieve past events but don???t set a start date, those past events will no longer be returned by default.\n> \n> What you should do now\n> \n> If you rely on a specific event order: Retrieve all paginated results and implement sorting on your side, after collecting the full dataset.\n> \n> If you need past events: Use the start_date.range_start parameter to define your desired time window. \n> \n> Example: ?start_date.range_start=2025-10-19T11:00:00&start_date.range_end=2026-02-16T11:00:00\n> \n> These changes are part of our ongoing effort to improve API performance and reliability at scale.\n> \n> If you have any questions or need assistance adjusting your implementation, please don???t hesitate to reach out through our [Help Center](https://link.eventbrite.com/f/a/7ZkX1C6-SHtGRwVVXCk49g~~/AAQRxRA~/NEx5zQjMIYet6BbW0LuLxLzOfBgRbLExkYurXnFxQmMOHFRlI4RpH9yS6VOOshqMIVeWzYjKbrIsLa-YTiEFUlWLakl2bG8OJBaIdkNXsecES6YtIPiH348zXRvcWNa-uUAMtb4XpVCtQQCX5t2DxgG-y-cYaX_t2TrhsGg85MU~)???we???re here to help.\n> \n> Sincerely,\n> Eventbrite",
      "updatedAt" : 1752267896.000000000,
      "user" : "allella",
      "userHtmlUrl" : "https://github.com/allella",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1777776?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "These fields are being referenced in \n\n- app-modules/event-importer/tests/Feature/EventBriteTest.php\n- app-modules/event-importer/src/Services/EventBriteHandler.php" ],
      "repository" : {
        "description" : "HackGreenville's Website",
        "homepage" : "https://hackgreenville.com",
        "name" : "hackgreenville-com",
        "fullName" : "hackgvl/hackgreenville-com",
        "htmlUrl" : "https://github.com/hackgvl/hackgreenville-com",
        "gitUrl" : "git://github.com/hackgvl/hackgreenville-com.git",
        "sshUrl" : "git@github.com:hackgvl/hackgreenville-com.git",
        "cloneUrl" : "https://github.com/hackgvl/hackgreenville-com.git",
        "owner" : {
          "login" : "hackgvl",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 20,
        "watchersCount" : 20,
        "size" : 13779,
        "openIssuesCount" : 15,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-11T13:49:39Z",
        "languages" : {
          "Dockerfile" : 932,
          "Shell" : 1178,
          "PHP" : 323704,
          "HTML" : 54,
          "Blade" : 117548
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove the obsolete order_by from API request and consider any other tweaks",
      "validationOrRequirement" : "The order_by parameter will be accepted but will have no effect. Default date filtering will change: If start_date.range_start is not specified, the endpoint will return events starting from 24 hours before the current time.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The changes are part of Eventbrite's ongoing effort to improve API performance and reliability at scale.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282969
  }, {
    "issueDTO" : {
      "id" : 3213757901,
      "title" : "Foreign Key constraints over `SET` columns beahvior differs from MySQL",
      "url" : "https://github.com/dolthub/dolt/issues/9472",
      "repositoryName" : "dolthub/dolt",
      "description" : "Skipped tests: https://github.com/dolthub/go-mysql-server/pull/3077",
      "updatedAt" : 1752267663.000000000,
      "user" : "jycor",
      "userHtmlUrl" : "https://github.com/jycor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30810879?v=4",
      "labels" : [ "correctness", "good repro", "good first issue", "sql" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Dolt ??? Git for Data",
        "homepage" : "https://www.dolthub.com",
        "name" : "dolt",
        "fullName" : "dolthub/dolt",
        "htmlUrl" : "https://github.com/dolthub/dolt",
        "gitUrl" : "git://github.com/dolthub/dolt.git",
        "sshUrl" : "git@github.com:dolthub/dolt.git",
        "cloneUrl" : "https://github.com/dolthub/dolt.git",
        "owner" : {
          "login" : "dolthub",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 568,
        "stargazersCount" : 18870,
        "watchersCount" : 18870,
        "size" : 155830,
        "openIssuesCount" : 429,
        "subscribersCount" : 116,
        "pushedAt" : "2025-07-11T23:37:55Z",
        "languages" : {
          "C#" : 8841,
          "Java" : 12609,
          "C++" : 2745,
          "C" : 4925,
          "Rust" : 1991,
          "CMake" : 591,
          "Makefile" : 3258,
          "Go" : 15461516,
          "Perl" : 3555,
          "TypeScript" : 2938,
          "Dockerfile" : 578,
          "Shell" : 2668304,
          "R" : 4965,
          "Batchfile" : 521,
          "JavaScript" : 46932,
          "PHP" : 2434,
          "Tcl" : 1569,
          "Ruby" : 2603,
          "Elixir" : 2236,
          "Python" : 11991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document and potentially fix the difference in behavior between MySQL and Dolt when it comes to Foreign Key constraints over `SET` columns",
      "validationOrRequirement" : "Foreign Key constraints over `SET` columns behavior differs from MySQL",
      "attemptedFixes" : "",
      "otherNotes" : "Skipped tests: https://github.com/dolthub/go-mysql-server/pull/3077",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282971
  }, {
    "issueDTO" : {
      "id" : 3154440517,
      "title" : "Rename `executorch` cmake target to `prim_ops_lib`",
      "url" : "https://github.com/pytorch/executorch/issues/11761",
      "repositoryName" : "pytorch/executorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nAs titled. The cmake target `executorch` is confusing, it only contains `executorch_core` and `register_prim_ops.cpp`. It would be good if we can change the name to `prim_ops_lib`, following the pattern of `portable_ops_lib` and `optimized_ops_lib`.\n\nAfter the renaming, it would be good to change `executorch-config.cmake` to add `target_link_options_shared_lib(prim_ops_lib)` there. Then we can get rid of code like: \n\nhttps://github.com/pytorch/executorch/blob/main/examples/models/llama/CMakeLists.txt#L82-L83\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### RFC (Optional)\n\n_No response_",
      "updatedAt" : 1752267578.000000000,
      "user" : "larryliu0820",
      "userHtmlUrl" : "https://github.com/larryliu0820",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8188269?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I'd love to work on this issue as my first contribution. Could you please assign it to me or let me know if it's okay to proceed?\n\n", "This is also nice because it frees up executorch as a target name for an \"everything I configured\" target, which I've wanted to add. It does technically break BC to rename this, but to be honest, I think it's worth doing and calling out in release notes.", "> Hi! I'd love to work on this issue as my first contribution. Could you please assign it to me or let me know if it's okay to proceed?\n\nSure, thanks. I've assigned the issue to you.", "@JawadKhan65 Just wanted to ping on this. Is this still something you're interested in working on? If not, no worries. Feel free to reach out if you're blocked or have any questions.", "I merged code, but requires to be reviewed by code owners (names listed below)\n[larryliu0820]: (https://github.com/larryliu0820)\n\n[kirklandsign]: (https://github.com/kirklandsign)'s avatar image\n", "@JawadKhan65 Sorry, I didn't see the PR. Thanks for putting that up. I'll make sure it gets reviewed.", "I left a few comments. Thanks for putting this up." ],
      "repository" : {
        "description" : "On-device AI across mobile, embedded and edge for PyTorch",
        "homepage" : "https://pytorch.org/executorch/",
        "name" : "executorch",
        "fullName" : "pytorch/executorch",
        "htmlUrl" : "https://github.com/pytorch/executorch",
        "gitUrl" : "git://github.com/pytorch/executorch.git",
        "sshUrl" : "git@github.com:pytorch/executorch.git",
        "cloneUrl" : "https://github.com/pytorch/executorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 613,
        "stargazersCount" : 3029,
        "watchersCount" : 3029,
        "size" : 238670,
        "openIssuesCount" : 1225,
        "subscribersCount" : 70,
        "pushedAt" : "2025-07-12T00:52:56Z",
        "languages" : {
          "Java" : 91154,
          "C++" : 7468950,
          "Jinja" : 11160,
          "C" : 92510,
          "Objective-C++" : 585572,
          "CMake" : 253562,
          "Kotlin" : 47365,
          "Dockerfile" : 2690,
          "Shell" : 234857,
          "Starlark" : 485277,
          "Batchfile" : 339,
          "Objective-C" : 192295,
          "Swift" : 90538,
          "Python" : 9370932,
          "GLSL" : 313850
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rename the cmake target `executorch` to `prim_ops_lib` to make it more descriptive and follow the naming pattern.",
      "validationOrRequirement" : "Rename the cmake target `executorch` to `prim_ops_lib` following the pattern of `portable_ops_lib` and `optimized_ops_lib`. Add `target_link_options_shared_lib(prim_ops_lib)` to `executorch-config.cmake`.",
      "attemptedFixes" : "Code was merged, but requires review by code owners.",
      "otherNotes" : "The renaming would break BC, but it's worth doing and calling out in release notes. The issue is assigned to JawadKhan65, and the code requires review by larryliu0820 and kirklandsign.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282976
  }, {
    "issueDTO" : {
      "id" : 3155602142,
      "title" : "Wrong RemovedInAirflow3Warning in access_control",
      "url" : "https://github.com/apache/airflow/issues/51869",
      "repositoryName" : "apache/airflow",
      "description" : "### Apache Airflow version\n\nOther Airflow 2 version (please specify below)\n\n### If \"Other Airflow 2 version\" selected, which one?\n\n2.10.5\n\n### What happened?\n\nI define access_control\n```\nACCESS_CONTROL = {\n    'myrole': {\n        \"DAGs\": {\"can_edit\", \"can_read\", \"can_delete\"},\n        \"DAG Runs\": {\"can_create\", \"can_read\", \"menu_access\"}\n    }\n}\n```\n\nBut when running it announced \n```\n/airflow/airflow-jobs/migrate_placement_dag.py:108 RemovedInAirflow3Warning: The 'can_dag_read' and 'can_dag_edit' permissions are deprecated. Please use 'can_read' and 'can_edit', respectively.\n```\n\n### What you think should happen instead?\n\nNo RemovedInAirflow3Warning\n\n### How to reproduce\n\nAdd access_control in DAGs\n```\nACCESS_CONTROL = {\n    'myrole': {\n        \"DAGs\": {\"can_edit\", \"can_read\", \"can_delete\"},\n        \"DAG Runs\": {\"can_create\", \"can_read\", \"menu_access\"}\n    }\n}\n```\n\n### Operating System\n\nmacOS Sequoia 15.5\n\n### Versions of Apache Airflow Providers\n\n_No response_\n\n### Deployment\n\nOfficial Apache Airflow Helm Chart\n\n### Deployment details\n\n_No response_\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [x] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)\n",
      "updatedAt" : 1752267485.000000000,
      "user" : "vumdao",
      "userHtmlUrl" : "https://github.com/vumdao",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/37215642?v=4",
      "labels" : [ "kind:bug", "affected_version:2.11", "area:core", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Apache Airflow - A platform to programmatically author, schedule, and monitor workflows",
        "homepage" : "https://airflow.apache.org/",
        "name" : "airflow",
        "fullName" : "apache/airflow",
        "htmlUrl" : "https://github.com/apache/airflow",
        "gitUrl" : "git://github.com/apache/airflow.git",
        "sshUrl" : "git@github.com:apache/airflow.git",
        "cloneUrl" : "https://github.com/apache/airflow.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15301,
        "stargazersCount" : 40971,
        "watchersCount" : 40971,
        "size" : 416042,
        "openIssuesCount" : 1526,
        "subscribersCount" : 763,
        "pushedAt" : "2025-07-11T23:51:39Z",
        "languages" : {
          "Java" : 1443,
          "Jinja" : 76192,
          "CSS" : 15733,
          "Go" : 63158,
          "HTML" : 42905,
          "Jupyter Notebook" : 7288,
          "TypeScript" : 2124349,
          "HCL" : 3786,
          "Dockerfile" : 119790,
          "Shell" : 230742,
          "JavaScript" : 328117,
          "Mako" : 2684,
          "Python" : 42415969
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to resolve the RemovedInAirflow3Warning when defining access_control in Airflow 2.11.",
      "validationOrRequirement" : "Airflow 2.11 version and access_control configuration.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description.",
      "otherNotes" : "The issue is related to access_control and RemovedInAirflow3Warning in Airflow 2.11, and the user is not willing to submit a PR.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282980
  }, {
    "issueDTO" : {
      "id" : 3204664228,
      "title" : "Let the GUI colors be choosen via hex values",
      "url" : "https://github.com/flameshot-org/flameshot/issues/4058",
      "repositoryName" : "flameshot-org/flameshot",
      "description" : "### Feature Description\n\nChoosing the colors for the colorwheel can be done graphically and via hex. It would be nice if the color of the GUI could be choosen via hex too. That way I can make flameshot look like built in. ",
      "updatedAt" : 1752267040.000000000,
      "user" : "funnym0nk3y",
      "userHtmlUrl" : "https://github.com/funnym0nk3y",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/41870754?v=4",
      "labels" : [ "Good first issue", "Enhancement" ],
      "state" : "OPEN",
      "comments" : [ "Can you explain more? Do you want to define the colors in the right-click color wheel, or are you looking for a way to define the active color for the tools (e.g., arrow) through hexadecimal?", "I'm sorry if my description was unclear. \nIn this view I can not set the color in e.g. hex...\n\n<img width=\"749\" height=\"1163\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0ffee842-6bf6-48d5-a3d8-69c1764ddace\" />\n\ncompared to this view, where I can set it in hex:\n\n<img width=\"756\" height=\"1134\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d66fd036-338c-4821-9abe-a3758c6495bd\" />\n\nIn Windows I can set a accent color, and it would be nice if I can set the same color in flameshot too via hex (or RGB, HSV, whatever)", "@funnym0nk3y thanks for the explanation. You actually can set the hex value in the flameshot.ini file, but as you said not through the graphical config window.\n\nI think this is a simple thing to add. I'm interested to know @borgmanJeremy opinion on this." ],
      "repository" : {
        "description" : "Powerful yet simple to use screenshot software :desktop_computer: :camera_flash:",
        "homepage" : "https://flameshot.org",
        "name" : "flameshot",
        "fullName" : "flameshot-org/flameshot",
        "htmlUrl" : "https://github.com/flameshot-org/flameshot",
        "gitUrl" : "git://github.com/flameshot-org/flameshot.git",
        "sshUrl" : "git@github.com:flameshot-org/flameshot.git",
        "cloneUrl" : "https://github.com/flameshot-org/flameshot.git",
        "owner" : {
          "login" : "flameshot-org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1724,
        "stargazersCount" : 27138,
        "watchersCount" : 27138,
        "size" : 24927,
        "openIssuesCount" : 693,
        "subscribersCount" : 209,
        "pushedAt" : "2025-07-11T19:12:19Z",
        "languages" : {
          "C++" : 672346,
          "Shell" : 20849,
          "C" : 1158,
          "CMake" : 46569,
          "Makefile" : 843,
          "Roff" : 8652,
          "Nix" : 209
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow users to choose GUI colors via hex values, similar to the colorwheel, for a more customized appearance",
      "validationOrRequirement" : "Define colors in the right-click color wheel or define active color for tools (e.g., arrow) through hexadecimal",
      "attemptedFixes" : "Setting hex value in flameshot.ini file, but not through graphical config window",
      "otherNotes" : "The issue is about choosing GUI colors via hex values, with comparison of graphical and hex color selection, and also mentions setting accent color in Windows and Flameshot.ini file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282984
  }, {
    "issueDTO" : {
      "id" : 3223617751,
      "title" : "Manual install networkx issue",
      "url" : "https://github.com/MODSetter/SurfSense/issues/187",
      "repositoryName" : "MODSetter/SurfSense",
      "description" : "```\n**error: Failed to install: networkx-3.5-py3-none-any.whl (networkx==3.5)\n  Caused by: The wheel is invalid: Metadata field Name not found**\n```\n\nLooked at the files url and they look correct along with the hash not sure why the install is failing, below is the content from the uv files\n\n`\n[[package]]\nname = \"networkx\"\nversion = \"3.5\"\nsource = { registry = \"https://pypi.org/simple\" }\nsdist = { url = \"https://files.pythonhosted.org/packages/6c/4f/ccdb8ad3a38e583f214547fd2f7ff1fc160c43a75af88e6aec213404b96a/networkx-3.5.tar.gz\", hash = \"sha256:d4c6f9cf81f52d69230866796b82afbccdec3db7ae4fbd1b65ea750feed50037\", size = 2471065 }\nwheels = [\n    { url = \"https://files.pythonhosted.org/packages/eb/8d/776adee7bbf76365fdd7f2552710282c79a4ead5d2a46408c9043a2b70ba/networkx-3.5-py3-none-any.whl\", hash = \"sha256:0030d386a9a06dee3565298b4a734b68589749a544acbb6c412dc9e2489ec6ec\", size = 2034406 },\n]`",
      "updatedAt" : 1752266890.000000000,
      "user" : "cheatmaster5",
      "userHtmlUrl" : "https://github.com/cheatmaster5",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/96499822?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@cheatmaster5 Can you first remove uv.lock and then try uv sync again. I think lock file was recently changed so could be that issue." ],
      "repository" : {
        "description" : "Open Source Alternative to NotebookLM / Perplexity / Glean, connected to external sources such as search engines (Tavily, Linkup), Slack, Linear, Notion, YouTube, GitHub, Discord and more.",
        "homepage" : "https://www.surfsense.net",
        "name" : "SurfSense",
        "fullName" : "MODSetter/SurfSense",
        "htmlUrl" : "https://github.com/MODSetter/SurfSense",
        "gitUrl" : "git://github.com/MODSetter/SurfSense.git",
        "sshUrl" : "git@github.com:MODSetter/SurfSense.git",
        "cloneUrl" : "https://github.com/MODSetter/SurfSense.git",
        "owner" : {
          "login" : "MODSetter",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 432,
        "stargazersCount" : 5897,
        "watchersCount" : 5897,
        "size" : 3786,
        "openIssuesCount" : 35,
        "subscribersCount" : 42,
        "pushedAt" : "2025-07-11T08:20:50Z",
        "languages" : {
          "TypeScript" : 866509,
          "MDX" : 34543,
          "Dockerfile" : 1413,
          "CSS" : 7461,
          "JavaScript" : 5503,
          "Mako" : 689,
          "Python" : 568636
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "to resolve the manual install issue for networkx-3.5",
      "validationOrRequirement" : "check the files url and hash",
      "attemptedFixes" : "remove uv.lock and try uv sync again",
      "otherNotes" : "The wheel is invalid: Metadata field Name not found",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282986
  }, {
    "issueDTO" : {
      "id" : 3219723459,
      "title" : "[lambda-events] Make sure that we have Default implemented for all event types",
      "url" : "https://github.com/awslabs/aws-lambda-rust-runtime/issues/1009",
      "repositoryName" : "awslabs/aws-lambda-rust-runtime",
      "description" : "In https://github.com/awslabs/aws-lambda-rust-runtime/pull/1008, a contributor noticed that our kinesis event was missing its `#[derive(Default)]` and implemented that.\n\nWe should double check that no other events are missing Default impl as well. It's irritating to write unit tests without it.",
      "updatedAt" : 1752266342.000000000,
      "user" : "jlizen",
      "userHtmlUrl" : "https://github.com/jlizen",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/44884346?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "To provide additional context here, `cargo lambda init` allows a user to select the type of event that will invoke their Lambda. All of the events in `lambda_events` are options. After completing the `init` flow, code is autogenerated in `event_handler.rs` that is specific to the event selected.\n\nFor example, for the KinesisEvent, the following test is generated in `event_handler.rs`:\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use lambda_runtime::{Context, LambdaEvent};\n\n    #[tokio::test]\n    async fn test_event_handler() {\n        let event = LambdaEvent::new(KinesisEvent::default(), Context::default());\n        let response = function_handler(event).await.unwrap();\n        assert_eq!((), response);\n    }\n}\n```\n\nPrior to https://github.com/awslabs/aws-lambda-rust-runtime/pull/1008, this code failed to compile, because `Default` was not implemented on `KinesisEvent`.\n\nA similar issue has been opened previously: https://github.com/awslabs/aws-lambda-rust-runtime/issues/725." ],
      "repository" : {
        "description" : "A Rust runtime for AWS Lambda",
        "homepage" : "",
        "name" : "aws-lambda-rust-runtime",
        "fullName" : "awslabs/aws-lambda-rust-runtime",
        "htmlUrl" : "https://github.com/awslabs/aws-lambda-rust-runtime",
        "gitUrl" : "git://github.com/awslabs/aws-lambda-rust-runtime.git",
        "sshUrl" : "git@github.com:awslabs/aws-lambda-rust-runtime.git",
        "cloneUrl" : "https://github.com/awslabs/aws-lambda-rust-runtime.git",
        "owner" : {
          "login" : "awslabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 360,
        "stargazersCount" : 3492,
        "watchersCount" : 3492,
        "size" : 10040,
        "openIssuesCount" : 22,
        "subscribersCount" : 47,
        "pushedAt" : "2025-07-11T21:45:25Z",
        "languages" : {
          "Rust" : 688439,
          "Makefile" : 6208
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Ensure that Default is implemented for all event types, to avoid compilation errors and make unit testing easier.",
      "validationOrRequirement" : "Implement Default for all event types, specifically for code generation in event_handler.rs.",
      "attemptedFixes" : "The contributor noticed that KinesisEvent was missing Default implementation, and implemented it in https://github.com/awslabs/aws-lambda-rust-runtime/pull/1008.",
      "otherNotes" : "The issue was previously opened in #725, and a similar issue was noticed in https://github.com/awslabs/aws-lambda-rust-runtime/pull/1008, where a contributor implemented Default for KinesisEvent. The issue is related to code generation in event_handler.rs and the need for Default implementation for all event types.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282991
  }, {
    "issueDTO" : {
      "id" : 225204157,
      "title" : "Gtk+ related code cleanup",
      "url" : "https://github.com/exaile/exaile/issues/347",
      "repositoryName" : "exaile/exaile",
      "description" : "Gtk+ changes and keeps deprecating code, which requires changes in Exaile. When using newer APIs, make sure to meet the requirement on Gtk+ for Exaile, which is currently 3.14. This issue is very low priority, but often easy to work on.\r\n- [x] Do not create any `Gtk.Window` or any class inherting from it (most notably `Gtk.Dialog`) without a parent.\r\n- [x] `Gdk.Color` is deprecated. (#358, #360, #364, #366, #367)\r\n- [ ] `Gtk.Stock` is deprecated, including `Gtk.StockItem` (#368, ???)\r\n  - [ ] Remove all the stock actions in dialogs, maybe replace them by a new class in xlgui/widgets?\r\n  - [ ] `xlgui/widgets/menu.py:simple_menu_item()` and all its uses all over the tree\r\n- [x] `Themeable Stock Images` API is deprecated.\r\n  * `Gtk.IconSize` enum is not affected\r\n  * `Gtk.IconSource`, `Gtk.IconFactory`, `Gtk.IconSet` uses should be replaced by `Gtk.IconTheme`\r\n  * `Gtk.IconInfo` is partially affected but not being used\r\n- [ ] `Gtk.Window.resize()` is not deprecated, but its use is discouraged and will result in ever-shrinking or ever-growing windows. Use `Gtk.Window.set_default_size()` instead.\r\n- [ ] [Make use of the `popup-menu` signal and other popup-related fixes](https://developer.gnome.org/gtk3/stable/gtk-migrating-checklist.html#checklist-popup-menu)\r\n  - [ ] `Gtk.Widget.popup()` requires the popup to be associated to a `Gtk.Widget` with `menu.attach_to_widget()`.\r\n  - [ ] replace most usages of `button-press-event`, `key-press-event` by `popup-menu`\r\n  - [x] check for `Gdk.Event.triggers_context_menu()` instead of `Gdk.BUTTON_SECONDARY` in `button-press-event` handler (#432)\r\n- [ ] Use modern signals API:\r\n  * This will also improve touch screen support a little. Make sure to use touch events too!\r\n  - [ ] `button-release-event` should be replaced by `activated`, `popup-menu` (see above) or `drag-` signals (partially done)\r\n  - [ ] Make sure all signal handlers correctly return a boolean value if required by Gtk+. Maybe write a script to automate this.\r\n- [ ] [Test for modifier keys correctly](https://developer.gnome.org/gtk3/stable/checklist-modifiers.html)\r\n- [ ] Make use of `Gtk.Stack` where applicable instead of replacing widgets\r\n\r\n## Hope/wait for proper replacements\r\nThese widgets are deprecated, but there is no proper replacement yet. Maybe there will be a replacement until Exaile is being ported to Gtk+ 4.\r\n- [x] `Gtk.StatusIcon`: Gtk+ developers intend to provide no replacement. With the `mpris2` and `notify` plugins in good state, this should not be an issue.\r\n- [ ] `Gtk.ImageMenuItem`: [Tepl's Amtk](https://developer.gnome.org/tepl/stable/) might be useful here.\r\n- [ ] `Gtk.Arrow` is deprecated, use `Gtk.Image` with an icon instead. This looks quite ugly and wrong for now.\r\n\r\n## Newer Gtk+\r\nOnce Exaile requires at least Gtk+ 3.22, these changes should be done:\r\n- [ ] `Gtk.Widget.popup()` is deprecated. Use `Gtk.Widget.popup_at_[???]()` instead. 3.22 or later.\r\n- [ ] Make use of `Gtk.Popover` where applicable. Available in 3.12, but not so nice until 3.22 or later.\r\n\r\n## Cleanup\r\n- [x] Don't create `Gtk.Window`s all the time and throw them away. Glade is able to use widgets created outside of windows.\r\n  - [x] all the `panel` code ~is~ was based on this (#405)\r\n\r\n## GtkApplication/GApplication\r\nmaybe port Exaile to using GApplication / GtkApplication. In this case, we could get rid of all the dbus activation code. Also, we could get rid of the libnotify dependency because we can use GNotification instead.",
      "updatedAt" : 1752266022.000000000,
      "user" : "genodeftest",
      "userHtmlUrl" : "https://github.com/genodeftest",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/934401?v=4",
      "labels" : [ "Type: enhancement", "Good first issue", "GTK3/GST1.x" ],
      "state" : "OPEN",
      "comments" : [ "The `popup_at_*` APIs are introduced in GTK 3.22. We'll wait a little while before using them, otherwise we require 3.22... which, I'm not sure what we actually require, but it's older than that.", "> The `popup_at_*` APIs are introduced in GTK 3.22. We'll wait a little while before using them, otherwise we require 3.22... which, I'm not sure what we actually require, but it's older than that.\r\n\r\nThanks, I've updated the description for that.", "> Gtk.ImageMenuItem\r\n\r\nDoes it even still work? On Win32 (msys2) I already don't have any menu icons.\r\n\r\n\\<rant>I don't get how removing icons is supposed to improve usability. Now I have to read every menu item to find what I want; same with dialog button icons.\\</rant>\r\n\r\n> Gtk.StatusIcon\r\n\r\nThis is still a very useful feature on many (non-GNOME) environments. I don't mind if it moves to a plugin but keep it somewhere. GTK+ 3 should be on maintenance mode so they won't remove the class until at least GTK+ 4; by that time hopefully there will have been a suitable replacement library.", "> > Gtk.ImageMenuItem\r\n>\r\n> Does it even still work? On Win32 (msys2) I already don't have any menu icons.\r\n\r\nI can see icons on Linux, but only on Wayland, not on X11, which seems like a bug in Gtk+. But I'd rather not tell them ;). Maybe you can get them back by adding\r\n```\r\ngtk-menu-images=1\r\ngtk-button-images=1\r\n```\r\nto your Gtk+ 3 `settings.ini` file, at least that's what I did.\r\n\r\n> <rant>[???]</rant>\r\n\r\n+1 on that.\r\n\r\n> > Gtk.StatusIcon\r\n>\r\n> [???]\r\n\r\nAdded to the list above." ],
      "repository" : {
        "description" : "\uD83C\uDFB6 Cross-platform music player",
        "homepage" : "https://www.exaile.org",
        "name" : "exaile",
        "fullName" : "exaile/exaile",
        "htmlUrl" : "https://github.com/exaile/exaile",
        "gitUrl" : "git://github.com/exaile/exaile.git",
        "sshUrl" : "git@github.com:exaile/exaile.git",
        "cloneUrl" : "https://github.com/exaile/exaile.git",
        "owner" : {
          "login" : "exaile",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 85,
        "stargazersCount" : 375,
        "watchersCount" : 375,
        "size" : 94982,
        "openIssuesCount" : 103,
        "subscribersCount" : 28,
        "pushedAt" : "2025-07-05T17:06:31Z",
        "languages" : {
          "Shell" : 5746,
          "Batchfile" : 2372,
          "Makefile" : 15010,
          "HTML" : 16641,
          "NSIS" : 7573,
          "Python" : 2262306
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to clean up the Gtk+ related code in Exaile, specifically to remove deprecated widgets and APIs, and to make sure the code meets the requirements for Exaile.",
      "validationOrRequirement" : "Exaile requires at least Gtk+ 3.14. There are some specific requirements for `Gtk.Window` and `Gtk.Stock` to be replaced with newer APIs. The issue also mentions the need to use modern signals API and test for modifier keys correctly.",
      "attemptedFixes" : "The issue mentions some attempts and blockers, such as replacing `Gtk.Window` and `Gtk.Stock` with newer APIs, removing `Gdk.Color` and `Themeable Stock Images` API, using modern signals API, and testing for modifier keys correctly. There are also some notes about `Gtk.StatusIcon` and `Gtk.ImageMenuItem` being deprecated but no proper replacement yet.",
      "otherNotes" : "The issue is very low priority but often easy to work on. Exaile requires at least Gtk+ 3.14. There are some deprecated widgets and APIs that need to be replaced. The issue also mentions porting Exaile to using GApplication/GtkApplication.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752282999
  }, {
    "issueDTO" : {
      "id" : 1384397945,
      "title" : "Add weights for the pearson, spearman, and r2_score",
      "url" : "https://github.com/Lightning-AI/torchmetrics/issues/1235",
      "repositoryName" : "Lightning-AI/torchmetrics",
      "description" : "## \uD83D\uDE80 Feature\r\n\r\nWe can provide a weight Tensor to the regression coefficients, such as pearson, spearman, and r2_score\r\n\r\n### Motivation\r\n\r\nIt should be relatively simple to add weights to these computations. And it can be useful in many contexts, including masking by providing 0-weights, or adding more weights to the relevant sample/target pairs.\r\n\r\n### Pitch\r\n\r\nAdding `weights` parameter in `pearson`, `spearman`, and `r2_score`. The parameter `weights` should be either `None`, 1D ,or 2D.\r\n\r\n### Alternatives\r\n\r\nNone\r\n\r\n### Additional context\r\n\r\nSee [weighted pearsonr](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#Weighted_correlation_coefficient). For the spearmanr, it should be identical, since spearman is the correlation of the rank.\r\n\r\nFor the r2_score, there exist some implementations for example in [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html), but it would be better to provide either a 1D or 2D matrix, and it would be broadcasted to the same shape as preds / target. instead of forcing `sample_weight` to be 1D.\r\n",
      "updatedAt" : 1752265962.000000000,
      "user" : "DomInvivo",
      "userHtmlUrl" : "https://github.com/DomInvivo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47570400?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Sounds good to me, @DomInvivo would you interested in implementing it?\r\ncc: @SkafteNicki ", "@Borda It's no longer a priority for me, I found a way to achieve what I needed since I only needed weights of 1 and 0. Unfortunately, I do not have time at the moment but could consider it later.", "@Borda is this still available? I would be interested in working on it.", "@matsumotosan Yes  it is. Feel free to gibe it a shot and we would appreciate a contribution. If you're getting stuck somewhere let us know. Also open a draft PR as early as possible so that we can review early on :)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n", "Hey! Wanted to see if this issue is still open. #1759 was meant to close this but not sure if that was merged. Happy to contribute :)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n" ],
      "repository" : {
        "description" : "Machine learning metrics for distributed, scalable PyTorch applications.",
        "homepage" : "https://lightning.ai/docs/torchmetrics/",
        "name" : "torchmetrics",
        "fullName" : "Lightning-AI/torchmetrics",
        "htmlUrl" : "https://github.com/Lightning-AI/torchmetrics",
        "gitUrl" : "git://github.com/Lightning-AI/torchmetrics.git",
        "sshUrl" : "git@github.com:Lightning-AI/torchmetrics.git",
        "cloneUrl" : "https://github.com/Lightning-AI/torchmetrics.git",
        "owner" : {
          "login" : "Lightning-AI",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 445,
        "stargazersCount" : 2309,
        "watchersCount" : 2309,
        "size" : 13396,
        "openIssuesCount" : 80,
        "subscribersCount" : 33,
        "pushedAt" : "2025-07-11T15:25:43Z",
        "languages" : {
          "Dockerfile" : 5397,
          "Makefile" : 1564,
          "Python" : 5094220
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add weights for the pearson, spearman, and r2_score regression coefficients, with the weights being either None, 1D, or 2D.",
      "validationOrRequirement" : "The weights should be either None, 1D, or 2D. The parameter 'weights' should be added in 'pearson', 'spearman', and 'r2_score'.",
      "attemptedFixes" : "The issue has been mentioned in the comments, but no specific fixes have been attempted. However, the author (@DomInvivo) has mentioned that they found a way to achieve what they needed since they only needed weights of 1 and 0.",
      "otherNotes" : "The issue is about adding weights for pearson, spearman, and r2_score regression coefficients. The weights should be either None, 1D, or 2D. The motivation is to provide a way to mask or add more weights to relevant sample/target pairs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283006
  }, {
    "issueDTO" : {
      "id" : 3224138984,
      "title" : "fix(coordinator): add additional tests",
      "url" : "https://github.com/privacy-scaling-explorations/maci/issues/2639",
      "repositoryName" : "privacy-scaling-explorations/maci",
      "description" : "- [ ] merge should throw error if end date is not there\n- [ ] generate should throw error if state is not merged yet\n- [ ] merge, generate and submit should throw error if poll is not found",
      "updatedAt" : 1752265868.000000000,
      "user" : "NicoSerranoP",
      "userHtmlUrl" : "https://github.com/NicoSerranoP",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/38594836?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Minimal Anti-Collusion Infrastructure (MACI)",
        "homepage" : "https://maci.pse.dev/",
        "name" : "maci",
        "fullName" : "privacy-scaling-explorations/maci",
        "htmlUrl" : "https://github.com/privacy-scaling-explorations/maci",
        "gitUrl" : "git://github.com/privacy-scaling-explorations/maci.git",
        "sshUrl" : "git@github.com:privacy-scaling-explorations/maci.git",
        "cloneUrl" : "https://github.com/privacy-scaling-explorations/maci.git",
        "owner" : {
          "login" : "privacy-scaling-explorations",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 179,
        "stargazersCount" : 570,
        "watchersCount" : 570,
        "size" : 284971,
        "openIssuesCount" : 38,
        "subscribersCount" : 20,
        "pushedAt" : "2025-07-12T00:20:57Z",
        "languages" : {
          "TypeScript" : 1671719,
          "Dockerfile" : 2057,
          "CSS" : 12546,
          "Shell" : 2562,
          "Circom" : 148658,
          "Solidity" : 146907,
          "JavaScript" : 67391
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add additional tests for coordinator with error handling for merge, generate, and submit.",
      "validationOrRequirement" : "Tests should be added for merge, generate, and submit, with specific error handling for end date, state, and poll.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description.",
      "otherNotes" : "Additional tests for merge, generate, and submit should be added, with specific error handling for end date, state, and poll.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283009
  }, {
    "issueDTO" : {
      "id" : 3064341683,
      "title" : "[Bug] Dev Containers extension incompatibility with Void",
      "url" : "https://github.com/voideditor/void/issues/589",
      "repositoryName" : "voideditor/void",
      "description" : "**Version**\n\nVSCode Version: 1.99.30031 (system setup)\nVoid Version: 1.3.7\nCommit: 4b86bfa184b176c26649d77fbbe30026de0c3e81\nDate: 2025-05-13T03:21:14.422Z\nElectron: 34.3.2\nElectronBuildId: undefined\nChromium: 132.0.6834.210\nNode.js: 20.18.3\nV8: 13.2.152.41-electron.0\nOS: Windows_NT x64 10.0.26100\n\n**Issue**\nIs there a way to get working dev containers in WSL ?\n\nI got the following message\n\n![Image](https://github.com/user-attachments/assets/ccd39d6b-152e-413b-ac4a-78dafdc6d494)\n",
      "updatedAt" : 1752265860.000000000,
      "user" : "jovazxc",
      "userHtmlUrl" : "https://github.com/jovazxc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/60413260?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "There is likely an open source devcontainers extension that we simply need to drop into the `extensions/` folder (and add a link to `reh`, which I can help with). ", "any updates of this ? @andrewpareles ", "I'm keen to know any updates on this as well.", "Hi @andrewpareles,\nAre there any updates on this? It???s a bit of a blocker ??? without support for Dev Containers, I might have to consider switching to another editor. Would really appreciate any insight or plans regarding this.\n\nThanks!", "Please update, devcontainers are quite central to how I code for different stacks ", "FWIW, Dev Containers do work in Cursor.", "Yes works in original VS Code and Windsurf as well. This is the error I get for Void (I'm on Mac M1 and not WSL):\n\n<img width=\"572\" height=\"634\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/df9647d5-66bc-4cfe-a628-993fdf73c7ed\" />\n\nVoid is more or less unusable for me without support for [Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers). While it's nice to bring-your-own-key (BYOK) for all the LLM providers (Windsurf only lets you BYOK for Anthropic), the lack of container support is a big issue - basically a non-starter to using this Editor.", "Thanks for sharing, I would have thought the built-in would work (after uninstalling any extra devcontainer extensions)... Apologies for this, working on it" ],
      "repository" : {
        "description" : null,
        "homepage" : "https://voideditor.com",
        "name" : "void",
        "fullName" : "voideditor/void",
        "htmlUrl" : "https://github.com/voideditor/void",
        "gitUrl" : "git://github.com/voideditor/void.git",
        "sshUrl" : "git@github.com:voideditor/void.git",
        "cloneUrl" : "https://github.com/voideditor/void.git",
        "owner" : {
          "login" : "voideditor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1764,
        "stargazersCount" : 25836,
        "watchersCount" : 25836,
        "size" : 49104,
        "openIssuesCount" : 243,
        "subscribersCount" : 151,
        "pushedAt" : "2025-07-05T08:01:10Z",
        "languages" : {
          "C#" : 864,
          "C" : 818,
          "Makefile" : 2307,
          "Handlebars" : 1064,
          "ShaderLab" : 330,
          "Go" : 652,
          "Inno Setup" : 309957,
          "HTML" : 393822,
          "Groovy" : 3928,
          "Jupyter Notebook" : 929,
          "TypeScript" : 69634571,
          "Shell" : 113209,
          "R" : 362,
          "SCSS" : 6732,
          "JavaScript" : 856583,
          "Objective-C" : 1387,
          "PHP" : 998,
          "Lua" : 252,
          "Visual Basic .NET" : 893,
          "Ruby" : 1703,
          "Less" : 1029,
          "F#" : 634,
          "Python" : 2171,
          "Clojure" : 1206,
          "Raku" : 761,
          "PowerShell" : 15796,
          "Java" : 599,
          "CSS" : 1026130,
          "C++" : 2745,
          "Rust" : 500641,
          "Pug" : 654,
          "Hack" : 16,
          "Objective-C++" : 1387,
          "TeX" : 1602,
          "Tree-sitter Query" : 12860,
          "Perl" : 1922,
          "Cuda" : 3634,
          "Julia" : 940,
          "Dockerfile" : 960,
          "Scilab" : 202892,
          "CoffeeScript" : 590,
          "Batchfile" : 18993,
          "Swift" : 284,
          "Roff" : 351,
          "Nix" : 1560,
          "HLSL" : 184,
          "Dart" : 324
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to get working dev containers in WSL, as the user is unable to use Void without this feature.",
      "validationOrRequirement" : "The issue requires support for Dev Containers in Void, which is a blocker for the user without it.",
      "attemptedFixes" : "The commenter suggested trying to drop the devcontainers extension into the `extensions/` folder and adding a link to `reh`, which was offered to help with.",
      "otherNotes" : "Dev Containers do work in Cursor, original VS Code, and Windsurf, but not in Void, with the error shown in the image.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283013
  }, {
    "issueDTO" : {
      "id" : 3224090020,
      "title" : "Move httpbin app to testdefaults package",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11656",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "Tracker for the https://github.com/kgateway-dev/kgateway/pull/11596#discussion_r2190573853 review comment. Related to #11057.",
      "updatedAt" : 1752265545.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "/assign" ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 537,
        "stargazersCount" : 4626,
        "watchersCount" : 4626,
        "size" : 210688,
        "openIssuesCount" : 577,
        "subscribersCount" : 102,
        "pushedAt" : "2025-07-11T22:49:24Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16652,
          "Rust" : 20712,
          "Makefile" : 30384,
          "JavaScript" : 435,
          "Go" : 4010698,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Move the httpbin app to the testdefaults package.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description.",
      "otherNotes" : "Related to #11057, Tracker for the https://github.com/kgateway-dev/kgateway/pull/11596#discussion_r2190573853 review comment.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283016
  }, {
    "issueDTO" : {
      "id" : 2520578721,
      "title" : "[DOC] Add yml highlight and copy button to pipeline docs and fix config navigation for Data Prepper",
      "url" : "https://github.com/opensearch-project/documentation-website/issues/8223",
      "repositoryName" : "opensearch-project/documentation-website",
      "description" : "**What do you want to do?**\r\n \r\n- [X] Request a change to existing documentation\r\n- [ ] Add new documentation\r\n- [ ] Report a technical problem with the documentation\r\n- [ ] Other \r\n\r\n**Tell us about your request.** Provide a summary of the request.\r\n\r\n- Looking at the Data Prepper section, none of the yaml snippets have the yaml highlighter or copy button added.\r\n- The configuration directory seems unnecessary. Just want to flag this for a future fix. This just makes the link longer (and shorter links are preferable for SEO). We can fix that by removing the configuration folder and adding redirects from the old link to the new link in all files under the pipelines directory.\r\n- \r\n\r\n***Version:** List the OpenSearch version to which this issue applies, e.g. 2.14, 2.12--2.14, or all.\r\n\r\nCurrent version\r\n \r\n**What other resources are available?** Provide links to related issues, POCs, steps for testing, etc.\r\n\r\n",
      "updatedAt" : 1752265506.000000000,
      "user" : "vagimeli",
      "userHtmlUrl" : "https://github.com/vagimeli",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/105296784?v=4",
      "labels" : [ "help wanted", "Backlog", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The documentation for OpenSearch, OpenSearch Dashboards, and their associated plugins.",
        "homepage" : "https://opensearch.org/docs",
        "name" : "documentation-website",
        "fullName" : "opensearch-project/documentation-website",
        "htmlUrl" : "https://github.com/opensearch-project/documentation-website",
        "gitUrl" : "git://github.com/opensearch-project/documentation-website.git",
        "sshUrl" : "git@github.com:opensearch-project/documentation-website.git",
        "cloneUrl" : "https://github.com/opensearch-project/documentation-website.git",
        "owner" : {
          "login" : "opensearch-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 577,
        "stargazersCount" : 83,
        "watchersCount" : 83,
        "size" : 301174,
        "openIssuesCount" : 327,
        "subscribersCount" : 14,
        "pushedAt" : "2025-07-11T21:06:50Z",
        "languages" : {
          "Smarty" : 716,
          "CSS" : 36764,
          "Shell" : 8456,
          "SCSS" : 102927,
          "JavaScript" : 81097,
          "Mustache" : 2920,
          "HTML" : 298932,
          "Ruby" : 61637
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add yaml highlighter and copy button to pipeline docs and fix config navigation for Data Prepper",
      "validationOrRequirement" : "Add yaml highlighter and copy button to pipeline docs and fix config navigation for Data Prepper",
      "attemptedFixes" : "",
      "otherNotes" : "The configuration directory seems unnecessary and can be fixed by removing it and adding redirects from the old link to the new link in all files under the pipelines directory.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283019
  }, {
    "issueDTO" : {
      "id" : 3221018461,
      "title" : "`DECIMAL`s with foreign key behavior differs from MySQL",
      "url" : "https://github.com/dolthub/dolt/issues/9496",
      "repositoryName" : "dolthub/dolt",
      "description" : "MySQL allows decimals with different scale and precision values to be referenced in foreign keys, but dolt does not.\nDue to zero padding however, pretty much only decimals with the same precision/scale can have inserts.\n\nskipped tests here: https://github.com/dolthub/go-mysql-server/pull/3089",
      "updatedAt" : 1752265466.000000000,
      "user" : "jycor",
      "userHtmlUrl" : "https://github.com/jycor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30810879?v=4",
      "labels" : [ "correctness", "good repro", "good first issue", "sql" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Dolt ??? Git for Data",
        "homepage" : "https://www.dolthub.com",
        "name" : "dolt",
        "fullName" : "dolthub/dolt",
        "htmlUrl" : "https://github.com/dolthub/dolt",
        "gitUrl" : "git://github.com/dolthub/dolt.git",
        "sshUrl" : "git@github.com:dolthub/dolt.git",
        "cloneUrl" : "https://github.com/dolthub/dolt.git",
        "owner" : {
          "login" : "dolthub",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 568,
        "stargazersCount" : 18870,
        "watchersCount" : 18870,
        "size" : 155830,
        "openIssuesCount" : 429,
        "subscribersCount" : 116,
        "pushedAt" : "2025-07-11T23:37:55Z",
        "languages" : {
          "C#" : 8841,
          "Java" : 12609,
          "C++" : 2745,
          "C" : 4925,
          "Rust" : 1991,
          "CMake" : 591,
          "Makefile" : 3258,
          "Go" : 15461516,
          "Perl" : 3555,
          "TypeScript" : 2938,
          "Dockerfile" : 578,
          "Shell" : 2668304,
          "R" : 4965,
          "Batchfile" : 521,
          "JavaScript" : 46932,
          "PHP" : 2434,
          "Tcl" : 1569,
          "Ruby" : 2603,
          "Elixir" : 2236,
          "Python" : 11991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "MySQL allows decimals with different scale and precision values to be referenced in foreign keys, but dolt does not",
      "validationOrRequirement" : "DECIMALs with foreign key behavior differs from MySQL, requires same precision/scale for inserts",
      "attemptedFixes" : "No attempts or blockers mentioned in the description",
      "otherNotes" : "The issue is related to a pull request #3089",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283023
  }, {
    "issueDTO" : {
      "id" : 2945843731,
      "title" : "Should Throw Error When Adding Projects with the Same Name but Different Paths to Solution Folder",
      "url" : "https://github.com/dotnet/sdk/issues/47859",
      "repositoryName" : "dotnet/sdk",
      "description" : "### Describe the bug\nThe current behavior allows these projects to be added to the same solution folder, which can lead to naming conflicts and management confusion.\n\n**Current Behavior???When attempting to add projects with the same name but different paths to a solution folder, this operation is allowed and does not throw an error.  This causes the test [WhenNestedDuplicateProjectIsAddedToASolutionFolder ](https://github.com/dotnet/sdk/blob/main/test/dotnet-sln.Tests/GivenDotnetSlnAdd.cs#L298)to fail.**\n\n### Expected Behavior\nAn error should be thrown in this scenario, indicating a naming conflict and preventing the addition.  This will ensure the correctness and consistency of the project.\n",
      "updatedAt" : 1752265369.000000000,
      "user" : "v-wuzhai",
      "userHtmlUrl" : "https://github.com/v-wuzhai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/46013274?v=4",
      "labels" : [ "cli-ux", "Test Debt", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I couldn't figure out the best area label to add to this issue. If you have write-permissions please help me learn by adding exactly one area label.", "I couldn't figure out the best area label to add to this issue. If you have write-permissions please help me learn by adding exactly one area label.", "@MiYanni, @joeloff, is the current behavior acceptable? When we insert the project into the solution file via dotnet commands, no error occurs, but when we execute the build command or open the project via Visual Sdutio, an error or warning occurs. Should we tweak the test cases for testing purposes?\n\n![Image](https://github.com/user-attachments/assets/73ad789d-7805-4dba-9449-7f35848ed498)\n\n![Image](https://github.com/user-attachments/assets/b2b07141-1343-4c11-b17e-de0977d38394)", "@SimonZhao888 Unfortunately, the person working on this functionality most recently was affected by recent layoffs. I'm going to mark this as \"Good First Issue\" and see if we can have someone else address it." ],
      "repository" : {
        "description" : "Core functionality needed to create .NET Core projects, that is shared between Visual Studio and CLI",
        "homepage" : "https://dot.net/core",
        "name" : "sdk",
        "fullName" : "dotnet/sdk",
        "htmlUrl" : "https://github.com/dotnet/sdk",
        "gitUrl" : "git://github.com/dotnet/sdk.git",
        "sshUrl" : "git@github.com:dotnet/sdk.git",
        "cloneUrl" : "https://github.com/dotnet/sdk.git",
        "owner" : {
          "login" : "dotnet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1133,
        "stargazersCount" : 2931,
        "watchersCount" : 2931,
        "size" : 269338,
        "openIssuesCount" : 2877,
        "subscribersCount" : 219,
        "pushedAt" : "2025-07-11T22:47:46Z",
        "languages" : {
          "C#" : 15987347,
          "PowerShell" : 378288,
          "CSS" : 21277,
          "C++" : 3999,
          "C" : 124,
          "CMake" : 14853,
          "HTML" : 139503,
          "XSLT" : 916,
          "TypeScript" : 473,
          "Dockerfile" : 76,
          "Shell" : 392919,
          "Forth" : 450,
          "Smalltalk" : 139,
          "Batchfile" : 5847,
          "JavaScript" : 19346,
          "Visual Basic .NET" : 10164,
          "Haml" : 181,
          "Nushell" : 622,
          "F#" : 6697,
          "Python" : 13176
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Throw an error when adding projects with the same name but different paths to a solution folder",
      "validationOrRequirement" : "An error should be thrown in this scenario, indicating a naming conflict and preventing the addition.",
      "attemptedFixes" : "Tweak test cases for testing purposes",
      "otherNotes" : "The current behavior allows projects with the same name but different paths to be added to the same solution folder, leading to naming conflicts and management confusion.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283026
  }, {
    "issueDTO" : {
      "id" : 3034436227,
      "title" : "[Documentation Change Request]: Publish an icon guide",
      "url" : "https://github.com/meshtastic/meshtastic/issues/1831",
      "repositoryName" : "meshtastic/meshtastic",
      "description" : "### Request Details\n\nIcons are great; they pack a lot of information into the space of a single character or the minimum of space in a graphic.\n\nMany icons are intutive to the developer; they may not be so to the user.\n\nMany icons have a common usage across domains: the gear wheel is almot universally the symbol for Settings.\n\nI suggest that Meshtastic publish a guide to icons for those of us for whom they are not all intuitive.\n\nFor example the nodes on a map are cubes of vaious colors.  Are the colors significant?\n\nDoes cloud with check mark mean \"message sent\",  or \"received by another node\" or \"received by adressee\"?\n\nOn the Android, inbound messages have a happy face.  When would an inbound message not have a happy face?\n\nOn Android, outbound messages have a cloud with check. On the web it is a cirle with a check.  Is it the same?  What it the difference between a cirle with ellipsis and cirlce with exclamation point?\n\n \n\n### Code of Conduct\n\n- [x] I agree to follow this project's Code of Conduct",
      "updatedAt" : 1752265179.000000000,
      "user" : "roberthadow",
      "userHtmlUrl" : "https://github.com/roberthadow",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13628518?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "One might want to point out that  a head-and-shoulders with checkmark is a DM. A cloud with the checkmark is a successful broadcast (^all)..", "In the web UI, there are three symbols: circle with check, circle with exclamation point, and cirlcle with ellipsis.  As time permits, it would make sense to standardize the symbols between web UI and Android and other user interfaces." ],
      "repository" : {
        "description" : "Meshtastic project website and documentation",
        "homepage" : "https://meshtastic.org",
        "name" : "meshtastic",
        "fullName" : "meshtastic/meshtastic",
        "htmlUrl" : "https://github.com/meshtastic/meshtastic",
        "gitUrl" : "git://github.com/meshtastic/meshtastic.git",
        "sshUrl" : "git@github.com:meshtastic/meshtastic.git",
        "cloneUrl" : "https://github.com/meshtastic/meshtastic.git",
        "owner" : {
          "login" : "meshtastic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 634,
        "stargazersCount" : 1107,
        "watchersCount" : 1107,
        "size" : 317815,
        "openIssuesCount" : 33,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-10T23:28:09Z",
        "languages" : {
          "MDX" : 95219,
          "TypeScript" : 47718,
          "CSS" : 7257,
          "JavaScript" : 6322
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Publish a guide to icons to help developers understand their meanings and usage across domains.",
      "validationOrRequirement" : "None mentioned in the description or comments.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The guide will cover the significance of icon colors, the meaning of cloud with check mark, happy face for inbound messages, and differences between circle with check, circle with ellipsis, and circle with exclamation point.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283029
  }, {
    "issueDTO" : {
      "id" : 3142687596,
      "title" : "[Task 1.2.7] Syllabus & Project structure",
      "url" : "https://github.com/Saumy1905/PYQFort/issues/29",
      "repositoryName" : "Saumy1905/PYQFort",
      "description" : "# Task 1.2.7 (Syllabus & Project Structure)\n\n## Earning: 30 pts. for this task\n\n> - Create a new folder inside your cloned repository (after following the necessary steps in `Readme.md`).\n> - Add 3 branch (like: CE, ME, ECE) syllabus in the format as given below\n\n### Contributing Rules:\n\n- The first person to comment will be assigned this issue.\n- Please ensure your comment is relevant to the task described.\n---\n\n### Note:\n\n- This is an **extended version of [Task 1.2]**, designed to help everyone begin contributing to this centralized collection of open-source PYQs (Previous Year Questions) by adding their institutes.\n- Projects will be assigned starting **June 14, 2025** as points will be tracked by the team from this date.\n- Make sure to install the VS Code extension as per the email sent by the team.\n\n![Image](https://github.com/user-attachments/assets/f080a483-6c75-43b8-9c1b-1407b9570c3c)",
      "updatedAt" : 1752265168.000000000,
      "user" : "Saumy1905",
      "userHtmlUrl" : "https://github.com/Saumy1905",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/161037206?v=4",
      "labels" : [ "SSOC S4", "Intermediate", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I would like to work on this issue. Please assign me.\n", "This task is open to all", "assign me \n", "This issue is assigned to @Pixel20coder " ],
      "repository" : {
        "description" : "This repository aims to create a centralized collection of PYQs for all B.Tech. students in India. Star, fork, clone and follow the instructions as given in README.md to help students",
        "homepage" : "",
        "name" : "PYQFort",
        "fullName" : "Saumy1905/PYQFort",
        "htmlUrl" : "https://github.com/Saumy1905/PYQFort",
        "gitUrl" : "git://github.com/Saumy1905/PYQFort.git",
        "sshUrl" : "git@github.com:Saumy1905/PYQFort.git",
        "cloneUrl" : "https://github.com/Saumy1905/PYQFort.git",
        "owner" : {
          "login" : "Saumy1905",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 88,
        "stargazersCount" : 87,
        "watchersCount" : 87,
        "size" : 3735031,
        "openIssuesCount" : 47,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-11T20:27:43Z",
        "languages" : { },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new folder in the cloned repository and add 3 branch syllabus in the given format for Task 1.2.7.",
      "validationOrRequirement" : "Create a new folder inside your cloned repository, add 3 branch syllabus in the format given, and ensure the comment is relevant to the task.",
      "attemptedFixes" : "No fixes attempted, but the issue is assigned to @Pixel20coder.",
      "otherNotes" : "This is an extended version of [Task 1.2], designed to help everyone begin contributing to this centralized collection of open-source PYQs by adding their institutes. Projects will be assigned starting June 14, 2025, as points will be tracked by the team from this date. Make sure to install the VS Code extension as per the email sent by the team.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283034
  }, {
    "issueDTO" : {
      "id" : 3224114944,
      "title" : "\uD83D\uDC1EBug report",
      "url" : "https://github.com/code-charity/youtube/issues/3035",
      "repositoryName" : "code-charity/youtube",
      "description" : "### Concise Description\n\n<img width=\"342\" height=\"354\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6184a995-7ef7-47f6-8190-c2c0320bc01f\" />\n\n### Browser/s\n\n_No response_\n\n### Other Browser:\n\n_No response_\n\n### 'Steps to reproduce' - Which of our features is required for the bug to happen?\n\n\"Loop\" still activated in context menu each time \n\n### Since when?\n\nI don't know , honestly\n\n### Does the bug still happen when you log out of YouTube?\n\nNone\n\n### ..No? Then please paste your yt.config_.EXPERIMENT_FLAGS. Twice (With the error & Without)\n\n_No response_\n\n### Are any errors or related log-messages shown in the Browser-Console? (F12)\n\n_No response_\n\n### Tested as the only active extension? (incognito mode or another browser users):\n\nNone\n\n### Expected preferred behavior:\n\n_No response_\n\n### ImprovedTube Version\n\n_No response_\n\n### Your Settings (From the Extension's `???`-Hamburger menu > Settings > Backup & reset > Export settings)\n\nThe Hamburger menu doesn't work \n\n### Your YouTube-Document\n\n_No response_\n\n### OS / Device:\n\n_No response_",
      "updatedAt" : 1752265151.000000000,
      "user" : "EnkephalosLog",
      "userHtmlUrl" : "https://github.com/EnkephalosLog",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/61691980?v=4",
      "labels" : [ "Bug", "help wanted", "good first issue", "up-for-grabs" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Open YouTube & Video browser-extension [top~1] Enrich your experience&choice!\uD83E\uDDF0200+options; clever features\uD83D\uDCCCset&forget\uD83D\uDCCCLongest-standing. Join\uD83E\uDDE9us?\uD83D\uDC68???\uD83D\uDC69???\uD83D\uDC67???\uD83D\uDC67  ??? {playback|content discovery|player|extra buttons|distractions|related videos|shorts|ads|quality|codec|full tab|full screen}",
        "homepage" : "http://improvedtube.com",
        "name" : "youtube",
        "fullName" : "code-charity/youtube",
        "htmlUrl" : "https://github.com/code-charity/youtube",
        "gitUrl" : "git://github.com/code-charity/youtube.git",
        "sshUrl" : "git@github.com:code-charity/youtube.git",
        "cloneUrl" : "https://github.com/code-charity/youtube.git",
        "owner" : {
          "login" : "code-charity",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 645,
        "stargazersCount" : 3834,
        "watchersCount" : 3834,
        "size" : 11908,
        "openIssuesCount" : 907,
        "subscribersCount" : 274,
        "pushedAt" : "2025-07-05T20:55:21Z",
        "languages" : {
          "CSS" : 282481,
          "JavaScript" : 535751,
          "HTML" : 4280,
          "Python" : 11326
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Report a bug where 'Loop' is still activated in the context menu each time",
      "validationOrRequirement" : "No specific validations or requirements mentioned",
      "attemptedFixes" : "None mentioned in the issue description",
      "otherNotes" : "The issue is about a bug report with a missing concise description, and the author is unsure when the bug started. The author also mentions that the Hamburger menu doesn't work.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283037
  }, {
    "issueDTO" : {
      "id" : 3052491082,
      "title" : "c2pa.metadata Assertion support",
      "url" : "https://github.com/contentauth/c2pa-rs/issues/1070",
      "repositoryName" : "contentauth/c2pa-rs",
      "description" : "2.2 moves the EXIF and IPTC assertions into the [c2pa.metadata assertion](https://spec.c2pa.org/specifications/specifications/2.2/specs/C2PA_Specification.html#_metadata). We need to create test cases for these data types and then update our other tools to look for metadata in this assertion.\n\n There's a [section](https://spec.c2pa.org/specifications/specifications/2.2/specs/C2PA_Specification.html#metadata_annex) that details all the data that is valid for a Metadata assertion. In theory we need to validate that only those fields are present. \n\nI'd set the highest priority on making sure we know how to generate a subset of this data and read it back in a valid form.\n\nFirst we need to create test cases and then we need to do the proper validations.\n\n2.2 requires validation of c2pa.metdata assertions.  This task is to support those validations \n\nSomewhere down the road we may want to test this by automatically moving metadata from XMP into one of these assertions. But we would need to be very selective, so I'm not sure about that.",
      "updatedAt" : 1752264960.000000000,
      "user" : "mauricefisher64",
      "userHtmlUrl" : "https://github.com/mauricefisher64",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/92736594?v=4",
      "labels" : [ "feature", "accepted", "status:triaged", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This also needs to be validated and exposed at the top level API.", ":white_check_mark: Jira issue https://jira.corp.adobe.com/browse/CAI-8974 is successfully created for this GitHub issue." ],
      "repository" : {
        "description" : "Rust SDK for the core C2PA (Coalition for Content Provenance and Authenticity) specification",
        "homepage" : "",
        "name" : "c2pa-rs",
        "fullName" : "contentauth/c2pa-rs",
        "htmlUrl" : "https://github.com/contentauth/c2pa-rs",
        "gitUrl" : "git://github.com/contentauth/c2pa-rs.git",
        "sshUrl" : "git@github.com:contentauth/c2pa-rs.git",
        "cloneUrl" : "https://github.com/contentauth/c2pa-rs.git",
        "owner" : {
          "login" : "contentauth",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 88,
        "stargazersCount" : 202,
        "watchersCount" : 202,
        "size" : 85403,
        "openIssuesCount" : 105,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-11T21:31:39Z",
        "languages" : {
          "PowerShell" : 10894,
          "Rust" : 3084080,
          "Makefile" : 12961
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support 2.2 c2pa.metadata assertion by creating test cases and validating the data types.",
      "validationOrRequirement" : "Validation of c2pa.metdata assertions as per 2.2 specification. Only those fields mentioned in the metadata annex section should be present.",
      "attemptedFixes" : "Not mentioned in the issue description",
      "otherNotes" : "This task is to support validations required in c2pa.metadata assertions in 2.2. It also requires creating test cases and doing proper validations. There's a possibility of testing this by automatically moving metadata from XMP into one of these assertions in the future.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283042
  }, {
    "issueDTO" : {
      "id" : 3130396370,
      "title" : "`rosbag2_performance_benchmarking` deb install empty",
      "url" : "https://github.com/ros2/rosbag2/issues/2037",
      "repositoryName" : "ros2/rosbag2",
      "description" : "## Description\nWhen installing `rosbag2_performance_benchmarking` via apt: `sudo apt install ros-humble-rosbag2-performance-benchmarking` I get a empty package and therefore when I try to call `benchmark_launch.py` I get an error:\n\n```\nros2 launch rosbag2_performance_benchmarking benchmark_launch.py benchmark:=`ros2 pkg prefix rosbag2_performance_benchmarking`/share/rosbag2_performance_benchmarking/config/benchmarks/test.yaml producers:=`ros2 pkg prefix rosbag2_performance_benchmarking`/share/rosbag2_performance_benchmarking/config/producers/mixed_110Mbs.yaml\nfile 'benchmark_launch.py' was not found in the share directory of package 'rosbag2_performance_benchmarking' which is at '/opt/ros/humble/share/rosbag2_performance_ben\n```\nThis is probably due to the missing `DBUILD_ROSBAG2_BENCHMARKS=1` that is required when building as mentioned in https://github.com/ros2/rosbag2/tree/rolling/rosbag2_performance/rosbag2_performance_benchmarking#building\n\n### Expected Behavior\n\n`apt` install should work build the package similar to when running `colcon build --packages-select rosbag2_performance_benchmarking --cmake-args -DBUILD_ROSBAG2_BENCHMARKS=1` for source install.\n\n## To Reproduce\n1. `sudo apt install ros-humble-rosbag2-performance-benchmarking`\n2. `ros2 launch rosbag2_performance_benchmarking benchmark_launch.py benchmark:=`ros2 pkg prefix rosbag2_performance_benchmarking`/share/rosbag2_performance_benchmarking/config/benchmarks/test.yaml producers:=`ros2 pkg prefix rosbag2_performance_benchmarking`/share/rosbag2_performance_benchmarking/config/producers/mixed_110Mbs.yaml`\n\n## System\n - OS: Ubuntu 22.04\n - ROS 2 Distro: Humble\n - Install Method: APT\n - Version: Humble",
      "updatedAt" : 1752264917.000000000,
      "user" : "TannerGilbert",
      "userHtmlUrl" : "https://github.com/TannerGilbert",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/36239763?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Just wanted to echo that I ran into the exact same error this evening.\n\nIn case anyone else is looking for a way to get this working in the meantime, I wrote out what I did to build rosbag2 from source:\n\n<details>\n<summary>Instructions</summary>\n\n1. Used [rocker](https://github.com/osrf/rocker) to bring up a `humble-ros-core` container:\n  ```\n  rocker --user --name rosbag2_benchmarking --volume <ws_on_your_drive>:/ws -- ros:humble-ros-core\n  ```\n2. Installed `ros-dev-tools`\n```\nsudo apt update && sudo apt install -y ros-dev-tools\n```\n3. Made a workspace and cloned rosbag2 for humble:\n```\nmkdir -p /ws/src && cd /ws/src && git clone git@github.com:ros2/rosbag2.git --branch humble\n```\n4. Setup rosdep and install all dependencies for rosbag2:\n```\nsudo rosdep init && rosdep update && rosdep install --from-paths src -y --ignore-src\n```\n5. Build the workspace with the CMAKE flags specified in the [performance benchmarking README](https://github.com/ros2/rosbag2/tree/humble/rosbag2_performance/rosbag2_performance_benchmarking#building) mentioned above (but using `--packages-up-to` instead of `--packages-select`\n```\ncolcon build --packages-up-to rosbag2_performance_benchmarking --cmake-args -DBUILD_ROSBAG2_BENCHMARKS=1\n```\n6. _I also ran into another tiny issue where, when building from source, the `rosbag2_compression_zstd` was not built--which appears to be because it is [not listed in its `package.xml`](https://github.com/ros2/rosbag2/blob/4d4ffd36990f2661fab78cd1edca829a5bbfd4d0/rosbag2_performance/rosbag2_performance_benchmarking/package.xml#L12-L25). Easy enough to just build it on its own, but thought that was worth mentioning._\n6. Sourced the workspace\n```\nsource install/local_setup.bash\n```\n7. Ran the benchmark with the provided example config:\n```\nros2 launch rosbag2_performance_benchmarking benchmark_launch.py benchmark:=`ros2 pkg prefix rosbag2_performance_benchmarking`/share/rosbag2_performance_benchmarking/config/benchmarks/test.yaml producers:=`ros2 pkg prefix rosbag2_performance_benchmarking`/share/rosbag2_performance_benchmarking/config/producers/mixed_110Mbs.yaml\n```\n\nNote: make sure you mount a directory on the actual drive you want to test this on.\n\nApologies if this kind of issue is not the place for instructions like that, just figured I'd write out what I did in case someone else was trying to run this \uD83D\uDE42 \n\n</details>", "This package appears definitely broken.  Only a changelog+copyright getting installed.\n\n```\nme@robot:~/workspace_ws/$ dpkg-query -L  ros-jazzy-rosbag2-performance-benchmarking\n/.\n/usr\n/usr/share\n/usr/share/doc\n/usr/share/doc/ros-jazzy-rosbag2-performance-benchmarking\n/usr/share/doc/ros-jazzy-rosbag2-performance-benchmarking/changelog.Debian.gz\n/usr/share/doc/ros-jazzy-rosbag2-performance-benchmarking/copyright\n\n```", "- We didn't compile it for a reason. Since this is a performance benchmarking package with high load tests we don't want it to be running on CI.\n- Need to reconsider the approach and make it build by default, but disable tests by default.", "@yassine-cherni, Please consider handling this issue.", "Fair enough.  As a clarification-- what's the reasoning we don't want to be running it on CI?  Combination of \"lots of resources/$$\" and \"benchmarking your CI server doesn't help my robot\"?  Maybe other reasons?\n\nEdit: just wondering if there's some config steps to optimize for my system that I'm missing.  While trying to prompt great answers a future \"help wanted\" applicant can crib from.", "The reasoning behind not running on CI is that there is no consistent outcome. Such performance tests need a dedicated machine to avoid interference with other tasks (CI jobs) running in parallel." ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "rosbag2",
        "fullName" : "ros2/rosbag2",
        "htmlUrl" : "https://github.com/ros2/rosbag2",
        "gitUrl" : "git://github.com/ros2/rosbag2.git",
        "sshUrl" : "git@github.com:ros2/rosbag2.git",
        "cloneUrl" : "https://github.com/ros2/rosbag2.git",
        "owner" : {
          "login" : "ros2",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 279,
        "stargazersCount" : 340,
        "watchersCount" : 340,
        "size" : 7838,
        "openIssuesCount" : 94,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T22:19:33Z",
        "languages" : {
          "C++" : 1994900,
          "CMake" : 88916,
          "Python" : 251538
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the installation of the `rosbag2_performance_benchmarking` package via apt, which is currently empty and does not include the `benchmark_launch.py` file.",
      "validationOrRequirement" : "The `DBUILD_ROSBAG2_BENCHMARKS=1` flag is required during building to include the `benchmark_launch.py` file. The package installation via apt should work similar to when running `colcon build --packages-select rosbag2_performance_benchmarking --cmake-args -DBUILD_ROSBAG2_BENCHMARKS=1` for source install.",
      "attemptedFixes" : "The author attempted to build the package from source, but the `rosbag2_compression_zstd` package was not built due to its missing `package.xml` listing. The author also mentioned that the package appears broken, with only a changelog and copyright being installed.",
      "otherNotes" : "The issue is related to the `rosbag2_performance_benchmarking` package installation via apt, where the package is empty, and the `benchmark_launch.py` file is not found. This is due to the missing `DBUILD_ROSBAG2_BENCHMARKS=1` flag during building. The expected behavior is to build the package similar to when running `colcon build --packages-select rosbag2_performance_benchmarking --cmake-args -DBUILD_ROSBAG2_BENCHMARKS=1` for source install.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283052
  }, {
    "issueDTO" : {
      "id" : 3052522313,
      "title" : "Support LinkHeader for remote manifest fetch",
      "url" : "https://github.com/contentauth/c2pa-rs/issues/1078",
      "repositoryName" : "contentauth/c2pa-rs",
      "description" : "Support link header to automatically retrieve remote manifests",
      "updatedAt" : 1752264887.000000000,
      "user" : "mauricefisher64",
      "userHtmlUrl" : "https://github.com/mauricefisher64",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/92736594?v=4",
      "labels" : [ "feature", "accepted", "status:triaged", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'm not exactly sure where this belongs or how it shows up in our sdk, but we definitely want to support it.", ":white_check_mark: Jira issue https://jira.corp.adobe.com/browse/CAI-8982 is successfully created for this GitHub issue." ],
      "repository" : {
        "description" : "Rust SDK for the core C2PA (Coalition for Content Provenance and Authenticity) specification",
        "homepage" : "",
        "name" : "c2pa-rs",
        "fullName" : "contentauth/c2pa-rs",
        "htmlUrl" : "https://github.com/contentauth/c2pa-rs",
        "gitUrl" : "git://github.com/contentauth/c2pa-rs.git",
        "sshUrl" : "git@github.com:contentauth/c2pa-rs.git",
        "cloneUrl" : "https://github.com/contentauth/c2pa-rs.git",
        "owner" : {
          "login" : "contentauth",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 88,
        "stargazersCount" : 202,
        "watchersCount" : 202,
        "size" : 85403,
        "openIssuesCount" : 105,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-11T21:31:39Z",
        "languages" : {
          "PowerShell" : 10894,
          "Rust" : 3084080,
          "Makefile" : 12961
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support LinkHeader for remote manifest fetch",
      "validationOrRequirement" : "support link header to automatically retrieve remote manifests",
      "attemptedFixes" : "no attempted fixes mentioned",
      "otherNotes" : "Jira issue https://jira.corp.adobe.com/browse/CAI-8982 is successfully created for this GitHub issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283054
  }, {
    "issueDTO" : {
      "id" : 2990556756,
      "title" : "Handle license for GBFS feeds",
      "url" : "https://github.com/public-transport/transitous/issues/1060",
      "repositoryName" : "public-transport/transitous",
      "description" : "License info can be available in `system_information.json` of GBFS feeds. It would be great to handle this, so a link to the license can be displayed at https://transitous.org/sources/.",
      "updatedAt" : 1752264856.000000000,
      "user" : "Altonss",
      "userHtmlUrl" : "https://github.com/Altonss",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/66519591?v=4",
      "labels" : [ "import", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "A note that we share the GBFS license URL in the Mobility Database API if there's interest in using it: https://mobilitydata.github.io/mobility-feed-api/SwaggerUI/index.html#/feeds/getGbfsFeed\n\nMore about this here: https://github.com/public-transport/transitous/issues/903#issuecomment-2936961466", "> A note that we share the GBFS license URL in the Mobility Database API if there's interest in using it: https://mobilitydata.github.io/mobility-feed-api/SwaggerUI/index.html#/feeds/getGbfsFeed\n\nThat would be great to use. I just had a look and currently we download the CSV file from https://files.mobilitydatabase.org/feeds_v2.csv, which does not contain the gbfs feeds, while the systems.csv does not contain the license information.\n\n" ],
      "repository" : {
        "description" : "Free and open public transport routing.",
        "homepage" : "https://transitous.org",
        "name" : "transitous",
        "fullName" : "public-transport/transitous",
        "htmlUrl" : "https://github.com/public-transport/transitous",
        "gitUrl" : "git://github.com/public-transport/transitous.git",
        "sshUrl" : "git@github.com:public-transport/transitous.git",
        "cloneUrl" : "https://github.com/public-transport/transitous.git",
        "owner" : {
          "login" : "public-transport",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 97,
        "stargazersCount" : 402,
        "watchersCount" : 402,
        "size" : 6910,
        "openIssuesCount" : 103,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-11T11:03:26Z",
        "languages" : {
          "Dockerfile" : 886,
          "Jinja" : 7383,
          "Shell" : 1386,
          "CSS" : 1081,
          "PureScript" : 9081,
          "Dhall" : 1217,
          "HTML" : 13200,
          "Python" : 73951
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Handle license for GBFS feeds",
      "validationOrRequirement" : "The license info should be handled so a link to the license can be displayed at https://transitous.org/sources.",
      "attemptedFixes" : "Currently, the CSV file from https://files.mobilitydatabase.org/feeds_v2.csv is downloaded, which does not contain the gbfs feeds, while the systems.csv does not contain the license information.",
      "otherNotes" : "The license info can be available in `system_information.json` of GBFS feeds. A link to the license can be displayed at https://transitous.org/sources.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283058
  }, {
    "issueDTO" : {
      "id" : 3216011679,
      "title" : "YouTube Shorts do not respect the Forced Playback Speed setting (Or: Automatically swap /shorts URL to /watch URL)",
      "url" : "https://github.com/code-charity/youtube/issues/3033",
      "repositoryName" : "code-charity/youtube",
      "description" : "<!--\n(Click PREVIEW to undestand this template) \n               OPTIONALLY fill the table if each point fits in the same line: \n-->\n\n??? _PROBLEM_: \n<!-- (Does your IDEA / feature request relate to a Problem? Which problem is? \n           Ex. I'm always frustrated when [...] )-->\nYouTube Shorts do not respect the Forced Playback Speed setting. There is no way to modify the speed on a YouTube short.\n\n??? _SOLUTION_:    \n<!-- (Describe what you'd like \n          (A clear and concise description of what you want to happen). \n           Please consider screenshots or sketches if it makes sense)-->\n\nA new option that will automatically swap a /shorts url to a /watch URL. A /watch URL does respect the forced playback speed option. This would be the most convenient for me personally as I don't scroll through multiple shorts.\n\nAs an example, here is a shorts url: https://www.youtube.com/shorts/tyovphLN_Kg\n\nNote that you can not perform any speed controls, at least not in the browser.\n\nHere is that same url and all I've done is replaced the word \"shorts\" with \"watch\":\n\nhttps://www.youtube.com/watch/tyovphLN_Kg\n\nWhich resolves to https://www.youtube.com/watch?v=tyovphLN_Kg and works like any other YouTube video.\n\n ??? _ALTERNATIVES_: \n<!-- (Describe what you've considered: \n      Alternative solutions or features, you'd consider as equal or inferior). -->\n\nPerhaps there is also a way behind the scenes to speed up Shorts in the Shorts interface.\n\n ??? _RELEVANCE / SCOPE_: \n<!-- (Would this be good by for everybody by default? (hypothetically). \n          Estimate how many percent of our users (or all youtube users) should/would use your idea? ) -->\n\nI believe this would be useful for anyone who uses Forced Playback Speed. I do not know if that is a popular feature or not, it is my most important feature.\n\n??? _\"SIDE EFFECTS\"_:   \n<!-- (Is there any conflict with any other feature? \n           Who might NOT want this?(How many percent of users could be bothered by it even filling space in our menu?)--> \n\nNo, either solution would be configurable.\n\n Thank  you!\n\nSHORT Table | (Summary)     \n------------ | -------------   \n*Problem*     |  YouTube shorts do not respect the Forced Playback Speed option                                 \n*Solution*     |   Add a toggle to automatically convert the shorts url to a watch url                                                         <!-- TYPE HERE, 1 line each) -->         \n*Alternatives*|   Perhaps something behind the scenes can speed up a short      \n*Scope*         |   Anyone who uses the forced playback speed option        \n*Side effects*|   None, as everything should be toggleable by the user     \n",
      "updatedAt" : 1752264334.000000000,
      "user" : "cjshrader",
      "userHtmlUrl" : "https://github.com/cjshrader",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2818173?v=4",
      "labels" : [ "Feature request", "help wanted", "good first issue", "up-for-grabs" ],
      "state" : "OPEN",
      "comments" : [ "assign me i'll try", "@NikhilBisht2 this is my first time submitting an issue with this system. You are asking for an admin to assign you, not me, right?\n\nAnd thank you for taking a look.", "@ImprovedTube whats you thought about this ??" ],
      "repository" : {
        "description" : "Open YouTube & Video browser-extension [top~1] Enrich your experience&choice!\uD83E\uDDF0200+options; clever features\uD83D\uDCCCset&forget\uD83D\uDCCCLongest-standing. Join\uD83E\uDDE9us?\uD83D\uDC68???\uD83D\uDC69???\uD83D\uDC67???\uD83D\uDC67  ??? {playback|content discovery|player|extra buttons|distractions|related videos|shorts|ads|quality|codec|full tab|full screen}",
        "homepage" : "http://improvedtube.com",
        "name" : "youtube",
        "fullName" : "code-charity/youtube",
        "htmlUrl" : "https://github.com/code-charity/youtube",
        "gitUrl" : "git://github.com/code-charity/youtube.git",
        "sshUrl" : "git@github.com:code-charity/youtube.git",
        "cloneUrl" : "https://github.com/code-charity/youtube.git",
        "owner" : {
          "login" : "code-charity",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 645,
        "stargazersCount" : 3834,
        "watchersCount" : 3834,
        "size" : 11908,
        "openIssuesCount" : 907,
        "subscribersCount" : 274,
        "pushedAt" : "2025-07-05T20:55:21Z",
        "languages" : {
          "CSS" : 282481,
          "JavaScript" : 535751,
          "HTML" : 4280,
          "Python" : 11326
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a feature that automatically converts YouTube Shorts URLs to watch URLs, allowing users to modify playback speed.",
      "validationOrRequirement" : "The solution should be configurable and not conflict with any other feature.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is related to YouTube Shorts not respecting the Forced Playback Speed setting, and the proposed solution is to add a toggle to automatically convert the shorts URL to a watch URL.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283062
  }, {
    "issueDTO" : {
      "id" : 3224015306,
      "title" : "Task 8: Documentation",
      "url" : "https://github.com/sgl-project/ome/issues/168",
      "repositoryName" : "sgl-project/ome",
      "description" : "# Task 8: Documentation\n\n## Overview\nCreate comprehensive documentation for PVC storage support, including user guides, API documentation, troubleshooting guides, and architecture diagrams.\n\n## Scope\n- User documentation for PVC storage usage\n- Developer documentation for implementation details\n- Troubleshooting guide for common issues\n- Architecture diagrams\n- Migration guide from other storage types\n\n## Files to Create/Modify\n- `docs/user-guide/storage/pvc-storage.md` - User guide\n- `docs/api/storage-types.md` - API documentation update\n- `docs/troubleshooting/pvc-storage.md` - Troubleshooting guide\n- `docs/architecture/pvc-storage-flow.md` - Architecture documentation\n- `README.md` - Update main README with PVC storage mention\n\n## Documentation Content\n\n### User Guide: `docs/user-guide/storage/pvc-storage.md`\n```markdown\n# PVC Storage for Models\n\nOME supports using Kubernetes Persistent Volume Claims (PVCs) as storage for machine learning models. This allows you to leverage existing models stored in PVCs without copying them to object storage.\n\n## Overview\n\nPVC storage is ideal when you:\n- Have models already stored in PVCs backed by NFS, block storage, or other CSI drivers\n- Want to avoid duplicating large models across multiple storage systems\n- Need to use enterprise storage systems exposed through Kubernetes PVCs\n- Require specific storage performance characteristics\n\n## Prerequisites\n\n1. A Kubernetes cluster with PVC support\n2. Pre-existing PVCs containing model files\n3. Models must include a `config.json` file for automatic metadata extraction\n\n## PVC URI Format\n\n```\npvc://{pvc-name}/{sub-path}\n```\n\nExamples:\n- `pvc://model-storage/llama2-7b`\n- `pvc://shared-models/foundation/nlp/bert-large`\n\n## Creating a BaseModel with PVC Storage\n\n### Basic Example\n\n```yaml\napiVersion: ome.io/v1beta1\nkind: BaseModel\nmetadata:\n  name: llama2-7b-pvc\n  namespace: default\nspec:\n  storage:\n    storageUri: \"pvc://llama2-model-pvc/models/llama2-7b\"\n  modelFormat:\n    name: \"safetensors\"\n```\n\nThe model metadata (type, architecture, parameters) will be automatically extracted from the model's `config.json` file.\n\n### Manual Metadata Specification\n\nIf automatic extraction is not possible or desired, you can specify metadata manually:\n\n```yaml\napiVersion: ome.io/v1beta1\nkind: BaseModel\nmetadata:\n  name: llama2-7b-pvc\n  namespace: default\nspec:\n  storage:\n    storageUri: \"pvc://llama2-model-pvc/models/llama2-7b\"\n  modelFormat:\n    name: \"safetensors\"\n  modelType: \"llama\"\n  modelArchitecture: \"LlamaForCausalLM\"\n  modelParameterSize: \"7B\"\n  modelCapabilities:\n  - \"text-generation\"\n  - \"chat\"\n  maxTokens: 4096\n```\n\n## PVC Access Modes\n\nOME handles different PVC access modes appropriately:\n\n### ReadWriteMany (RWX)\n- Multiple pods can mount the PVC simultaneously\n- Ideal for shared model repositories\n- InferenceService pods can run on any node\n\n### ReadWriteOnce (RWO)\n- Only one pod can mount the PVC at a time\n- Suitable for high-performance block storage\n- InferenceService scheduling is handled by Kubernetes\n\n### ReadOnlyMany (ROX)\n- Multiple pods can mount the PVC read-only\n- Good for immutable model storage\n- Similar behavior to RWX for model serving\n\n## Using PVC Models in InferenceService\n\n```yaml\napiVersion: ome.io/v1beta1\nkind: InferenceService\nmetadata:\n  name: llama2-serving\nspec:\n  model:\n    name: llama2-7b-pvc\n    runtime: vllm-runtime\n  predictor:\n    containers:\n    - name: predictor\n      args:\n      - \"--model\"\n      - \"$(MODEL_PATH)\"\n      resources:\n        limits:\n          nvidia.com/gpu: \"1\"\n```\n\nThe InferenceService will automatically mount the PVC and set the `MODEL_PATH` environment variable.\n\n## ClusterBaseModel with PVC\n\nFor cluster-wide models, the PVC must exist in the configured cluster model namespace (typically `ome-system`):\n\n```yaml\napiVersion: ome.io/v1beta1\nkind: ClusterBaseModel\nmetadata:\n  name: shared-llama2-7b\nspec:\n  storage:\n    storageUri: \"pvc://cluster-models-pvc/foundation/llama2-7b\"\n  modelFormat:\n    name: \"safetensors\"\n```\n\n## Preparing PVCs for Model Storage\n\n### Model Directory Structure\n\nYour PVC should contain models with this structure:\n```\n/models/\n????????? llama2-7b/\n???   ????????? config.json          # Required for metadata extraction\n???   ????????? model.safetensors    # Model weights\n???   ????????? tokenizer.json       # Tokenizer configuration\n???   ????????? tokenizer_config.json\n????????? bert-large/\n    ????????? config.json\n    ????????? pytorch_model.bin\n    ????????? vocab.txt\n```\n\n### Example: Populating a PVC\n\n```yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: download-model-to-pvc\nspec:\n  template:\n    spec:\n      containers:\n      - name: downloader\n        image: huggingface/transformers-cli:latest\n        command:\n        - sh\n        - -c\n        - |\n          # Download model from HuggingFace to PVC\n          cd /models\n          git lfs install\n          git clone https://huggingface.co/meta-llama/Llama-2-7b-hf llama2-7b\n      volumeMounts:\n      - name: model-storage\n        mountPath: /models\n      volumes:\n      - name: model-storage\n        persistentVolumeClaim:\n          claimName: model-storage-pvc\n      restartPolicy: OnFailure\n```\n\n## Monitoring PVC Model Status\n\nCheck BaseModel status:\n```bash\nkubectl get basemodel llama2-7b-pvc -o yaml\n```\n\nLook for:\n- `status.state`: Should be \"Ready\" when model is verified\n- `status.nodesReady`: Nodes where model is available (for RWX PVCs)\n- `spec.modelType`, `spec.modelArchitecture`: Auto-populated metadata\n\n## Best Practices\n\n1. **Use RWX PVCs for shared models** that multiple services will use\n2. **Pre-validate model files** ensure config.json exists before creating BaseModel\n3. **Set resource limits** on metadata extraction jobs if using large PVCs\n4. **Use subpaths** to organize multiple models in a single PVC\n5. **Monitor PVC usage** to ensure sufficient storage capacity\n\n## Limitations\n\n1. PVCs must be in the same namespace as BaseModel (or cluster namespace for ClusterBaseModel)\n2. Cross-namespace PVC access is not supported\n3. Model files must be readable by the OME service accounts\n4. Metadata extraction requires `config.json` in standard format\n\n## Migration from Other Storage Types\n\nTo migrate existing models to PVC storage:\n\n1. Copy model files to PVC maintaining directory structure\n2. Ensure config.json is present\n3. Update BaseModel storageUri to use `pvc://` format\n4. Delete old model files from nodes if using host storage\n```\n\n### Troubleshooting Guide: `docs/troubleshooting/pvc-storage.md`\n\nThe troubleshooting guide should include:\n\n**Common Issues**:\n\n1. **Model Status Stuck in \"MetadataPending\"**\n   - Symptoms and possible causes\n   - Diagnostic commands\n   - Solutions for each cause\n\n2. **InferenceService Pod Fails to Start**\n   - PVC mounting issues\n   - Access mode conflicts\n   - Node affinity problems\n\n3. **\"PVC Not Found\" Errors**\n   - Namespace mismatches\n   - RBAC permission issues\n   - URI typos\n\n4. **Metadata Extraction Job Failures**\n   - Missing config.json\n   - JSON parsing errors\n   - File permission issues\n\n5. **Performance Issues**\n   - Storage latency\n   - I/O bottlenecks\n   - Optimization strategies\n\n**Debugging Tools**:\n- kubectl commands for diagnostics\n- Log analysis techniques\n- Test pod creation for verification\n- Job monitoring commands\n\n**Error Reference Table**:\n- Common error messages\n- Root causes\n- Quick solutions\n\n**Advanced Debugging**:\n- Creating debug pods\n- Accessing PVC contents\n- Verifying file permissions\n- RBAC troubleshooting\n\n### Architecture Documentation: `docs/architecture/pvc-storage-flow.md`\n\nThe architecture documentation should include:\n\n**Overview**:\n- Purpose of PVC storage support\n- High-level architecture description\n- Benefits over existing storage methods\n\n**Architecture Diagram**:\n- Sequence diagram showing the complete flow\n- Component interactions\n- Data flow between components\n\n**Component Details**:\n\n1. **Model Agent**:\n   - Role in PVC verification\n   - Why it doesn't mount PVCs\n   - Status updates it performs\n\n2. **BaseModel Controller**:\n   - PVC-specific reconciliation logic\n   - Job creation and monitoring\n   - Status management\n\n3. **Metadata Extraction Job**:\n   - Purpose and lifecycle\n   - Security context\n   - Resource limits and timeouts\n\n4. **InferenceService Controller**:\n   - PVC volume handling\n   - Scheduling considerations\n   - Subpath support\n\n**Design Decisions**:\n- Why jobs for metadata extraction\n- Why no PVC mounting in model agent\n- Node selector implications\n- Security boundaries\n\n**Storage Type Comparison**:\n- Table comparing all storage types\n- Trade-offs and use cases\n- Performance characteristics\n\n**Security Model**:\n- RBAC permissions required\n- PVC access patterns\n- Isolation boundaries\n\n**Performance Analysis**:\n- One-time vs recurring costs\n- Caching behavior\n- Scaling considerations\n\n**Future Enhancements**:\n- Cross-namespace support\n- Metadata caching\n- Dynamic provisioning\n- Advanced scheduling\n\n### README Update\n\nUpdate the main README.md to include:\n\n**In Supported Storage Types section**:\n- Add PVC to the list of supported storage backends\n- Brief description of PVC storage benefits\n- Link to detailed documentation\n\n**PVC Storage Summary**:\n- Key features and benefits\n- Simple example showing BaseModel with PVC URI\n- Reference to the user guide\n- Version information (when feature was added)\n\n## Documentation Standards\n\n1. **Clear Examples**: Every concept should have a working example\n2. **Troubleshooting**: Common errors and solutions\n3. **Diagrams**: Visual representation of complex flows\n4. **Cross-references**: Link between related topics\n5. **Version Notes**: Indicate when features were added\n\n## Acceptance Criteria\n- [ ] User guide covers all PVC storage scenarios\n- [ ] Troubleshooting guide addresses common issues\n- [ ] Architecture documentation explains design decisions\n- [ ] API documentation is updated\n- [ ] Examples are tested and working\n- [ ] Documentation is reviewed by team\n\n## Dependencies\n- Implementation tasks completed\n- E2E tests for validating examples\n\n## Estimated Effort\n4-5 hours",
      "updatedAt" : 1752264258.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "documentation", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to create comprehensive documentation for PVC storage support, including user guides, API documentation, troubleshooting guides, and architecture diagrams.",
      "validationOrRequirement" : "The issue does not specify any specific requirements or validations, but it mentions that the documentation should cover various aspects such as user documentation for PVC storage usage, developer documentation for implementation details, troubleshooting guide for common issues, architecture diagrams, and migration guide from other storage types.",
      "attemptedFixes" : "The issue does not specify any attempted fixes, but it mentions that the documentation should include troubleshooting guides for common issues.",
      "otherNotes" : "The issue is about creating comprehensive documentation for PVC storage support, including user guides, API documentation, troubleshooting guides, and architecture diagrams. The documentation should cover various aspects such as user documentation for PVC storage usage, developer documentation for implementation details, troubleshooting guide for common issues, architecture diagrams, and migration guide from other storage types.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283069
  }, {
    "issueDTO" : {
      "id" : 3224013982,
      "title" : "Task 5: InferenceService PVC Volume Support",
      "url" : "https://github.com/sgl-project/ome/issues/165",
      "repositoryName" : "sgl-project/ome",
      "description" : "# Task 5: InferenceService PVC Volume Support\n\n## Overview\nUpdate the InferenceService controller components to properly handle PVC volumes instead of host paths when BaseModel uses PVC storage.\n\n## Scope\n- Modify volume creation logic in base.go\n- Update volume mount handling for PVC subpaths\n- Adjust node selector logic for PVC-based models\n- Handle RWO vs RWX access mode differences\n\n## Files to Modify\n- `pkg/controller/v1beta1/inferenceservice/components/base.go`\n- `pkg/controller/v1beta1/inferenceservice/utils/utils.go` (if needed)\n- Related component files that use base.go functions\n\n## Implementation Details\n\n### Key Functions to Update\n\n1. **UpdatePodSpecVolumes**\n   - Detect PVC storage type from BaseModel\n   - Create PVC volume source instead of hostPath\n   - Set appropriate mount path\n   - Handle error cases gracefully\n\n2. **UpdateVolumeMounts**\n   - Add volume mounts with subpath support\n   - Ensure read-only mounting for model volumes\n   - Check if volume mount is necessary based on annotations\n\n3. **UpdatePodSpecNodeSelector**\n   - Skip node selector for PVC-based models\n   - Let Kubernetes scheduler handle PVC accessibility\n   - Consider future pod affinity enhancements for RWO PVCs\n   - Maintain existing behavior for downloaded models\n\n4. **ProcessBaseAnnotations**\n   - Add storage type annotation for PVC models\n   - Include PVC name and subpath in annotations\n   - Useful for debugging and observability\n\n### Design Considerations\n\n**Volume Creation**:\n- PVC volumes should reference the PVC name from the parsed URI\n- Always mount as read-only for model data integrity\n- Handle both presence and absence of subpaths\n\n**Node Scheduling**:\n- PVC models don't need node selectors (unlike downloaded models)\n- Kubernetes scheduler handles PVC accessibility constraints\n- RWO PVCs will naturally limit pod placement\n- RWX PVCs allow flexible scheduling\n\n**Backward Compatibility**:\n- Preserve existing hostPath behavior for non-PVC models\n- Ensure fine-tuned serving logic remains intact\n- Don't break existing InferenceService deployments\n\n## Test Cases\n\n1. **PVC Volume Creation**:\n   - PVC volume created correctly with claim name\n   - Host path volume created for non-PVC storage\n   - Error handling for invalid PVC URI\n\n2. **Volume Mount Handling**:\n   - Correct mount path with subpath for PVC\n   - Mount without subpath when not needed\n   - Read-only mounts enforced\n\n3. **Node Selector Logic**:\n   - No node selector for PVC storage\n   - Node selector present for downloaded models\n   - Fine-tuned serving cases handled correctly\n\n4. **Annotation Processing**:\n   - Storage type annotation added\n   - PVC details in annotations\n   - Backward compatibility maintained\n\n## Constants to Add\n\nNew constants needed in `pkg/constants/constants.go`:\n- `StorageTypeAnnotationKey`: Track storage type in pod annotations\n- `PVCNameAnnotationKey`: Record PVC name for debugging\n- `PVCSubPathAnnotationKey`: Record subpath for debugging\n\n## Acceptance Criteria\n- [ ] InferenceService pods mount PVC volumes correctly\n- [ ] Subpath handling works for nested model directories\n- [ ] Node selector logic adapted for PVC storage\n- [ ] Annotations include PVC information\n- [ ] Backward compatibility maintained for existing storage types\n- [ ] Unit tests cover all PVC scenarios\n- [ ] Integration tests verify pod creation with PVC volumes\n\n## Dependencies\n- Task 1: Storage URI Parsing\n- Task 4: BaseModel Controller (for PVC validation)\n\n## Estimated Effort\n3-4 hours",
      "updatedAt" : 1752264250.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the InferenceService controller components to properly handle PVC volumes instead of host paths when BaseModel uses PVC storage",
      "validationOrRequirement" : "Modify volume creation logic in base.go; Update volume mount handling for PVC subpaths; Adjust node selector logic for PVC-based models; Handle RWO vs RWX access mode differences; Add storage type annotation for PVC models; Include PVC name and subpath in annotations; Ensure read-only mounting for model volumes; Check if volume mount is necessary based on annotations",
      "attemptedFixes" : "Modify volume creation logic in base.go; Update volume mount handling for PVC subpaths; Adjust node selector logic for PVC-based models; Handle RWO vs RWX access mode differences; Add storage type annotation for PVC models; Include PVC name and subpath in annotations",
      "otherNotes" : "Task 5: InferenceService PVC Volume Support; Update the InferenceService controller components to properly handle PVC volumes instead of host paths when BaseModel uses PVC storage; Add storage type annotation for PVC models; Include PVC name and subpath in annotations; Useful for debugging and observability",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283076
  }, {
    "issueDTO" : {
      "id" : 3224013571,
      "title" : "Task 4: BaseModel Controller PVC Handling",
      "url" : "https://github.com/sgl-project/ome/issues/164",
      "repositoryName" : "sgl-project/ome",
      "description" : "# Task 4: BaseModel Controller PVC Handling\n\n## Overview\nUpdate the BaseModel controller to handle the complete PVC storage flow: validation, job creation, and status management. This replaces the original design where model agent was involved.\n\n## Scope\n- Add PVC validation logic to controller reconciliation\n- Create metadata extraction jobs for PVC models\n- Monitor job status and update BaseModel accordingly\n- Handle all PVC-related errors and edge cases\n\n## Files to Modify\n- `pkg/controller/v1beta1/basemodel/controller.go` - Main implementation\n- `config/rbac/role.yaml` - Add PVC and Job permissions\n- `pkg/controller/v1beta1/basemodel/controller_test.go` - Tests\n\n## Implementation Details\n\n### Key Functions to Add\n\n1. **PVC Detection in Reconcile Loop**\n   - Check if BaseModel uses PVC storage URI\n   - Route to PVC-specific reconciliation logic\n   - Maintain existing behavior for non-PVC models\n\n2. **PVC Validation**\n   - Parse PVC URI to extract components\n   - Verify PVC exists in the same namespace\n   - Check PVC binding status\n   - Update BaseModel status with validation results\n\n3. **Metadata Extraction Job Management**\n   - Create Kubernetes Job for metadata extraction\n   - Job should mount PVC read-only\n   - Monitor job status (running, succeeded, failed)\n   - Handle job lifecycle (creation, monitoring, cleanup)\n\n4. **Status Updates**\n   - Update BaseModel status based on PVC and job states\n   - Store PVC information in status annotations\n   - Clear node-related status fields (not applicable for PVC)\n   - Handle error messages and failure reasons\n\n### Job Specification Requirements\n\nThe metadata extraction job should:\n- Use the ome-agent image with `model-metadata` command\n- Mount the PVC at a specific path with subpath support\n- Run with appropriate resource limits\n- Have a reasonable timeout (e.g., 5 minutes)\n- Include TTL for automatic cleanup\n- Use dedicated ServiceAccount with minimal permissions\n\n### Controller Watch Configuration\n\nUpdate the controller to:\n- Watch owned Jobs for status updates\n- Filter ConfigMap watches to exclude PVC models\n- Add appropriate event handlers\n\n## Test Cases\n\n1. **Valid PVC Flow**:\n   - PVC exists and is bound\n   - Job created successfully\n   - Metadata extracted and updated\n   - Status becomes Ready\n\n2. **PVC Validation**:\n   - PVC not found\n   - PVC not bound\n   - Invalid PVC URI\n\n3. **Job Management**:\n   - Job creation\n   - Job success handling\n   - Job failure handling\n   - Job already exists\n\n4. **Edge Cases**:\n   - Metadata already populated\n   - Job timeout\n   - Controller restart during job\n\n## Acceptance Criteria\n- [ ] Controller validates PVC existence and binding\n- [ ] Creates metadata extraction job with correct spec\n- [ ] Monitors job status and updates BaseModel accordingly\n- [ ] Handles all error cases gracefully\n- [ ] Status reflects PVC storage accurately\n- [ ] No interference with non-PVC models\n- [ ] Comprehensive test coverage\n\n## Dependencies\n- Task 1: Storage URI Parsing\n- Task 3: Model Metadata Agent\n\n## Estimated Effort\n5-6 hours (increased due to complete flow ownership)",
      "updatedAt" : 1752264249.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the BaseModel controller to handle the complete PVC storage flow: validation, job creation, and status management, replacing the original design where model agent was involved.",
      "validationOrRequirement" : "Add PVC validation logic to controller reconciliation, create metadata extraction jobs for PVC models, monitor job status and update BaseModel accordingly, handle all PVC-related errors and edge cases, and ensure the metadata extraction job meets the specified requirements.",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "This issue is about updating the BaseModel controller to handle PVC storage flow, including validation, job creation, and status management. It involves adding PVC validation logic, creating metadata extraction jobs, monitoring job status, and handling errors. The issue also includes test cases and acceptance criteria.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283081
  }, {
    "issueDTO" : {
      "id" : 3224013157,
      "title" : "Task 3: Create Model Metadata Agent",
      "url" : "https://github.com/sgl-project/ome/issues/163",
      "repositoryName" : "sgl-project/ome",
      "description" : "# Task 3: Create Model Metadata Agent\n\n## Overview\nCreate a new agent in the ome-agent framework that can mount PVCs and extract model metadata. This agent will be run as a Kubernetes Job by the BaseModel controller.\n\n## Scope\n- Create new model_metadata_agent.go in cmd/ome-agent\n- Implement metadata extraction logic\n- Update ome-agent main.go to register the new agent\n- Add unit tests\n\n## Files to Create/Modify\n- `cmd/ome-agent/model_metadata_agent.go` - New file\n- `cmd/ome-agent/main.go` - Register new agent\n- `cmd/ome-agent/model_metadata_agent_test.go` - New test file\n\n## Implementation Requirements\n\n### Agent Structure\n- Implement AgentModule interface\n- Name: \"model-metadata\"\n- Accept command line arguments:\n  - `--model-path`: Path to the model directory\n  - `--basemodel-name`: Name of the BaseModel CR\n  - `--basemodel-namespace`: Namespace of the BaseModel CR\n  - `--cluster-scoped`: Boolean flag for ClusterBaseModel\n\n### Core Functionality\n1. **Model Config Extraction**:\n   - Read config.json from the specified model path\n   - Handle alternative config file locations (model_config.json, configuration.json)\n   - Parse JSON to extract model metadata\n\n2. **BaseModel Update**:\n   - Create Kubernetes client\n   - Fetch the BaseModel/ClusterBaseModel CR\n   - Update spec with extracted metadata (only if fields are not already set)\n   - Use the existing updateSpecWithConfig utility function from basemodel controller\n\n3. **Error Handling**:\n   - Clear error messages for missing config files\n   - Handle malformed JSON gracefully\n   - Retry logic for Kubernetes API failures\n\n### Dependencies\n- Reuse existing model config parser from modelagent package\n- Use controller-runtime client for Kubernetes operations\n- Follow existing ome-agent patterns (fx dependency injection, zap logging)\n\n## Test Cases\n\n1. Valid config.json extraction\n2. Missing config.json handling\n3. Alternative config file locations\n4. Invalid JSON format\n5. BaseModel update success\n6. ClusterBaseModel update success\n7. Kubernetes API failure scenarios\n\n## Acceptance Criteria\n- [ ] Agent can be invoked via `ome-agent model-metadata`\n- [ ] Successfully extracts metadata from standard model config files\n- [ ] Updates BaseModel CR with extracted metadata\n- [ ] Handles ClusterBaseModel when --cluster-scoped flag is set\n- [ ] Provides clear error messages for common failure scenarios\n- [ ] Unit tests cover main functionality\n- [ ] Follows existing ome-agent patterns and conventions\n\n## Dependencies\n- ome-agent framework exists\n- Model config parser is available in modelagent package\n- Kubernetes client libraries\n\n## Estimated Effort\n4-5 hours",
      "updatedAt" : 1752264249.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new agent in the ome-agent framework that can mount PVCs and extract model metadata.",
      "validationOrRequirement" : "The issue requires implementing AgentModule interface, accepting command line arguments, reading config.json, handling alternative config file locations, parsing JSON, creating Kubernetes client, fetching BaseModel/ClusterBaseModel CR, updating spec with extracted metadata, and following existing ome-agent patterns.",
      "attemptedFixes" : "No attempted fixes are mentioned in the issue description.",
      "otherNotes" : "The issue is about creating a new agent in the ome-agent framework that can mount PVCs and extract model metadata. The agent will be run as a Kubernetes Job by the BaseModel controller. It involves creating new files, implementing metadata extraction logic, registering the new agent, and adding unit tests.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283087
  }, {
    "issueDTO" : {
      "id" : 3224012354,
      "title" : "Task 2: Model Agent Skip PVC Storage",
      "url" : "https://github.com/sgl-project/ome/issues/162",
      "repositoryName" : "sgl-project/ome",
      "description" : "# Task 2: Model Agent Skip PVC Storage\n\n## Overview\nUpdate the model agent to completely skip PVC storage types, as they will be handled entirely by the BaseModel controller.\n\n## Scope\n- Add logic to detect and skip PVC storage type\n- Remove any PVC-related processing from model agent\n- Ensure clean handoff to controller-based flow\n\n## Files to Modify\n- `pkg/modelagent/gopher.go` - Add skip logic for PVC storage\n- `pkg/modelagent/scout.go` - Ensure PVC models aren't queued for download\n\n## Implementation Details\n\n### 1. Update downloadModel in gopher.go\n- Add storage type detection using `storage.GetStorageType()`\n- Add switch case for `storage.StorageTypePVC`\n- When PVC storage is detected:\n  - Log informational message that PVC is handled by controller\n  - Return nil immediately (success) without any processing\n  - Skip all status updates, ConfigMap updates, and node labeling\n- Ensure existing storage types (OCI, HuggingFace, Vendor) continue to work\n\n### 2. Update Scout to Skip PVC Models (Optional)\n- In `shouldDownloadModel` method, check storage type before queuing\n- If storage type is PVC, return false to skip queuing\n- Add debug logging to indicate PVC models are skipped\n\n### 3. Ensure No ConfigMap Updates for PVC\n- In any status update methods, check storage type first\n- Skip all ConfigMap operations for PVC storage\n- This prevents model agent from interfering with controller flow\n\n### 4. Logging Strategy\n- Info level: \"Skipping PVC storage type for model X (handled by BaseModel controller)\"\n- Debug level: Additional context about why PVC is skipped\n- Ensure logs clearly indicate the handoff to controller\n\n## Test Cases\n\n1. **PVC Storage Skip**:\n   - Model with PVC storage type is not processed\n   - No status updates in ConfigMap\n   - No node labels added\n   - Task completes successfully\n\n2. **Other Storage Types**:\n   - OCI, HuggingFace, Vendor storage work as before\n   - No regression in existing functionality\n\n3. **Error Handling**:\n   - Invalid storage URI handled gracefully\n   - Clear log messages for skipped PVC models\n\n\n## Acceptance Criteria\n- [ ] Model agent detects PVC storage type correctly\n- [ ] PVC models are skipped without errors\n- [ ] No ConfigMap updates for PVC models\n- [ ] No node labels added for PVC models\n- [ ] Clear log messages indicate PVC models are skipped\n- [ ] Other storage types continue to work normally\n- [ ] Unit tests verify skip behavior\n\n## Dependencies\n- Task 1: Storage URI Parsing (for GetStorageType function)\n\n## Estimated Effort\n1-2 hours (simplified from original 3-4 hours)\n\n## Benefits of This Approach\n1. **Simplicity**: Model agent doesn't need to understand PVC semantics\n2. **Clear Separation**: Each component has a single responsibility\n3. **No DaemonSet Issues**: Avoids problems with PVC access from DaemonSet\n4. **Easier Testing**: Simpler logic to test",
      "updatedAt" : 1752264248.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the model agent to completely skip PVC storage types, as they will be handled entirely by the BaseModel controller",
      "validationOrRequirement" : "Add logic to detect and skip PVC storage type, Remove any PVC-related processing from model agent, Ensure clean handoff to controller-based flow",
      "attemptedFixes" : "Add storage type detection using `storage.GetStorageType()`, Add switch case for `storage.StorageTypePVC`, When PVC storage is detected: Log informational message that PVC is handled by controller, Return nil immediately (success) without any processing, Skip all status updates, ConfigMap updates, and node labeling",
      "otherNotes" : "Task 2: Model Agent Skip PVC Storage, Update model agent to completely skip PVC storage types, as they will be handled entirely by the BaseModel controller, Add logic to detect and skip PVC storage type, Remove any PVC-related processing from model agent, Ensure clean handoff to controller-based flow",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283093
  }, {
    "issueDTO" : {
      "id" : 3224011948,
      "title" : "Task 1: Implement PVC Storage URI Parsing",
      "url" : "https://github.com/sgl-project/ome/issues/161",
      "repositoryName" : "sgl-project/ome",
      "description" : "# Task 1: Implement PVC Storage URI Parsing\n\n## Overview\nAdd PVC storage URI parsing functionality to the storage utility package. This is the foundation for all PVC storage support.\n\n## Scope\n- Add PVC URI format validation\n- Implement URI parsing to extract PVC name and subpath\n- Add unit tests for parsing logic\n\n## Files to Modify\n- `pkg/utils/storage/storage.go` - Already has the parsing logic implemented\n- `pkg/utils/storage/storage_test.go` - Add comprehensive tests\n\n## Implementation Details\n\n### Current State\nThe PVC URI parsing is already implemented in `storage.go`:\n```go\n// ParsePVCStorageURI parses a PVC storage URI and returns its components\n// Format: pvc://{pvc-name}/{sub-path}\nfunc ParsePVCStorageURI(uri string) (*PVCStorageComponents, error) {\n    // ... existing implementation\n}\n```\n\n### Required Work\n1. Add validation tests for edge cases:\n   - Empty PVC name\n   - Missing subpath\n   - Invalid characters in PVC name\n   - Very long paths\n   - Special characters in subpath\n\n2. Add integration with GetStorageType function (already exists)\n\n## Test Cases\n```go\nfunc TestParsePVCStorageURI(t *testing.T) {\n    tests := []struct {\n        name    string\n        uri     string\n        want    *PVCStorageComponents\n        wantErr bool\n    }{\n        {\n            name: \"valid PVC URI\",\n            uri:  \"pvc://my-model-pvc/models/llama2-7b\",\n            want: &PVCStorageComponents{\n                PVCName: \"my-model-pvc\",\n                SubPath: \"models/llama2-7b\",\n            },\n        },\n        {\n            name:    \"missing subpath\",\n            uri:     \"pvc://my-model-pvc\",\n            wantErr: true,\n        },\n        {\n            name:    \"empty PVC name\",\n            uri:     \"pvc:///models/llama2-7b\",\n            wantErr: true,\n        },\n        // Add more test cases\n    }\n}\n```\n\n## Acceptance Criteria\n- [ ] All existing storage type tests pass\n- [ ] PVC URI parsing handles all valid formats correctly\n- [ ] Clear error messages for invalid URIs\n- [ ] 100% test coverage for PVC parsing functions\n\n## Dependencies\nNone - this is the foundational task\n\n## Estimated Effort\n1-2 hours (mostly testing since implementation exists)",
      "updatedAt" : 1752264247.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement PVC storage URI parsing functionality to the storage utility package.",
      "validationOrRequirement" : "PVC URI format validation, edge cases (empty PVC name, missing subpath, invalid characters, very long paths, special characters in subpath), and integration with GetStorageType function.",
      "attemptedFixes" : "Implementation details provided, including existing implementation in storage.go, required work, test cases, and acceptance criteria.",
      "otherNotes" : "PVC URI parsing functionality needs to be added to the storage utility package, including URI format validation, parsing to extract PVC name and subpath, and comprehensive unit tests.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283098
  }, {
    "issueDTO" : {
      "id" : 3224014920,
      "title" : "Task 7: Integration Tests",
      "url" : "https://github.com/sgl-project/ome/issues/167",
      "repositoryName" : "sgl-project/ome",
      "description" : "# Task 7: Integration Tests\n\n## Overview\nCreate comprehensive integration tests to validate the end-to-end PVC storage support functionality.\n\n## Scope\n- Unit tests for individual components\n- Integration tests for the complete flow\n- E2E tests for real cluster validation\n- Performance and stress tests\n\n## Files to Create/Modify\n- `pkg/utils/storage/storage_test.go` - Enhance existing tests\n- `pkg/modelagent/gopher_test.go` - Add PVC test cases\n- `pkg/controller/v1beta1/basemodel/controller_test.go` - Job creation tests\n- `test/e2e/pvc_storage_test.go` - New E2E test file\n- `cmd/ome-agent/model_metadata_agent_test.go` - Agent unit tests\n\n## Test Implementation\n\n### Unit Tests for Storage Package\nEnhance `pkg/utils/storage/storage_test.go` with test cases for:\n- Valid PVC URI parsing with various subpath formats\n- Invalid URI formats and error handling\n- Storage type detection for PVC URIs\n- Edge cases like empty URIs, missing components, trailing slashes\n\n### Model Agent Tests\nAdd to `pkg/modelagent/gopher_test.go` test cases for:\n- PVC exists and is bound scenario\n- PVC not found error handling\n- PVC not bound (pending) status\n- Invalid PVC URI format\n- Proper status updates (MetadataPending, Failed)\n- Mock Kubernetes client interactions\n\n### BaseModel Controller Tests\nAdd to `pkg/controller/v1beta1/basemodel/controller_test.go` test cases for:\n- Metadata job creation when BaseModel has PVC storage\n- Job spec validation (correct image, args, volumes)\n- Job monitoring and status updates\n- Handling job success and failure scenarios\n- PVC validation before job creation\n- Idempotency (job already exists)\n- Controller reconciliation loops\n\n### E2E Tests\nCreate `test/e2e/pvc_storage_test.go` with comprehensive end-to-end tests:\n\n**TestPVCStorageEndToEnd**:\n- Create PVC and wait for it to be bound\n- Populate PVC with model files (including config.json)\n- Create BaseModel with PVC storage URI\n- Verify metadata extraction job runs successfully\n- Verify BaseModel metadata is populated\n- Create InferenceService using the PVC model\n- Verify pod has PVC mounted correctly\n- Check volume mounts and subpaths\n\n**TestPVCStorageAccessModes**:\n- Test ReadWriteOnce (RWO) PVC behavior\n- Test ReadWriteMany (RWX) PVC behavior\n- Verify scheduling constraints are handled correctly\n\n**TestPVCStorageErrorCases**:\n- Test non-existent PVC handling\n- Test unbound PVC behavior\n- Test invalid subpath scenarios\n- Test permission errors and RBAC issues\n\n### Model Metadata Agent Tests\nCreate `cmd/ome-agent/model_metadata_agent_test.go` with tests for:\n- Successful config.json extraction from model directory\n- Handling missing config.json files\n- Parsing various config.json formats (HuggingFace, custom)\n- Metadata field mapping and validation\n- BaseModel update via Kubernetes API\n- Error handling for malformed JSON\n- Permission errors when reading files\n\n## Test Matrix\n\n| Component | Test Type | Coverage Target |\n|-----------|-----------|-----------------|\n| Storage Package | Unit | 100% |\n| Model Agent | Unit | PVC handling paths |\n| BaseModel Controller | Unit | Job creation logic |\n| Model Metadata Agent | Unit | Config extraction |\n| End-to-End | Integration | Complete flow |\n| Performance | Load | 100 concurrent PVCs |\n\n## Performance Tests\n\n**BenchmarkPVCVerification**:\n- Benchmark PVC verification speed\n- Measure URI parsing performance\n- Test concurrent PVC checks\n\n**TestPVCStorageScale**:\n- Test with 100+ BaseModels using PVCs\n- Verify no resource leaks\n- Check job cleanup and TTL\n- Monitor controller performance under load\n\n## Acceptance Criteria\n- [ ] Unit test coverage > 80% for new code\n- [ ] All integration tests pass in CI\n- [ ] E2E tests validate complete flow\n- [ ] Performance tests show no regression\n- [ ] Error cases properly handled and tested\n- [ ] Tests are maintainable and well-documented\n\n## Test Environment Setup\n- Kind cluster with CSI driver for PVC tests\n- Pre-populated PVCs with sample models\n- Mock model files with valid config.json\n\n## Dependencies\n- All implementation tasks completed\n- Test infrastructure available\n- Sample model files prepared\n\n## Estimated Effort\n5-6 hours",
      "updatedAt" : 1752264228.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create comprehensive integration tests to validate the end-to-end PVC storage support functionality",
      "validationOrRequirement" : "test coverage > 80% for new code, all integration tests pass in CI, E2E tests validate complete flow, performance tests show no regression, error cases properly handled and tested, tests are maintainable and well-documented",
      "attemptedFixes" : "test cases for various scenarios, edge cases, and error handling, test matrix for coverage and performance, acceptance criteria for new code, integration tests, and performance tests",
      "otherNotes" : "Task 7: Integration Tests, comprehensive integration tests to validate end-to-end PVC storage support functionality, includes unit tests for individual components, integration tests for complete flow, E2E tests for real cluster validation, performance and stress tests",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283103
  }, {
    "issueDTO" : {
      "id" : 3224014373,
      "title" : "Task 6: RBAC and Kubernetes Manifests",
      "url" : "https://github.com/sgl-project/ome/issues/166",
      "repositoryName" : "sgl-project/ome",
      "description" : "# Task 6: RBAC and Kubernetes Manifests\n\n## Overview\nCreate and update Kubernetes manifests for RBAC permissions, ServiceAccounts, and other resources needed for PVC storage support.\n\n## Scope\n- Create ServiceAccount for metadata extraction jobs\n- Define RBAC roles and bindings\n- Update existing controller RBAC for job management\n- Create example PVC and BaseModel manifests\n\n## Files to Create/Modify\n- `config/rbac/model_metadata_extractor_role.yaml` - New file\n- `config/rbac/model_metadata_extractor_binding.yaml` - New file  \n- `config/rbac/model_metadata_service_account.yaml` - New file\n- `config/rbac/role.yaml` - Update existing controller permissions\n- `examples/pvc-storage/` - New directory with examples\n\n## Implementation Details\n\n### ServiceAccount for Metadata Extractor\nCreate `config/rbac/model_metadata_service_account.yaml`:\n- ServiceAccount named `ome-model-metadata-extractor`\n- Deploy in `ome-system` namespace\n- Add appropriate labels for identification\n\n### RBAC Role for Metadata Extractor\nCreate `config/rbac/model_metadata_extractor_role.yaml` with permissions to:\n- Read BaseModel and ClusterBaseModel resources\n- Update BaseModel and ClusterBaseModel (for metadata updates)\n- Read PVCs to verify they exist\n- Create events for auditing\n\n### RBAC RoleBinding\nCreate `config/rbac/model_metadata_extractor_binding.yaml`:\n- Bind the metadata extractor role to the service account\n- Use ClusterRoleBinding for cross-namespace access\n\n### Update Controller RBAC\nUpdate `config/rbac/role.yaml` to add permissions for:\n- Creating and managing Kubernetes Jobs\n- Reading PVCs to verify storage\n- Watching job status changes\n\n### Example Manifests\n\n#### Example PVC with Model\nCreate `examples/pvc-storage/model-pvc.yaml`:\n- PersistentVolumeClaim for storing model files\n- Appropriate access modes (RWX for shared models, RWO for single-node)\n- Sufficient storage capacity for model files\n- Optional job example showing how to populate the PVC\n\n#### Example BaseModel with PVC Storage\nCreate `examples/pvc-storage/basemodel-pvc.yaml`:\n- BaseModel using `pvc://` storage URI format\n- Shows both auto-populated and manual metadata options\n- Includes proper model format specification\n\n#### Example InferenceService using PVC Model\nCreate `examples/pvc-storage/inferenceservice-pvc.yaml`:\n- InferenceService referencing a PVC-based BaseModel\n- Appropriate runtime configuration\n- Resource requirements for model serving\n\n#### Example ClusterBaseModel with PVC\nCreate `examples/pvc-storage/clusterbasemodel-pvc.yaml`:\n- ClusterBaseModel using PVC in cluster namespace\n- Note about namespace requirements\n- Shared model configuration\n\n### Kustomization Updates\nUpdate `config/rbac/kustomization.yaml` to include:\n- New ServiceAccount resource\n- Metadata extractor role and binding\n- Ensure proper resource ordering\n\n## Test Scenarios\n\n1. **RBAC Validation**:\n   - Metadata extractor can read BaseModel/ClusterBaseModel\n   - Metadata extractor can update BaseModel/ClusterBaseModel\n   - Metadata extractor cannot delete resources\n   - Controller can create/manage jobs\n\n2. **Example Validation**:\n   - Examples deploy successfully\n   - PVC gets mounted correctly\n   - Metadata extraction works\n\n## Acceptance Criteria\n- [ ] ServiceAccount created for metadata extractor\n- [ ] RBAC permissions are minimal but sufficient\n- [ ] Controller can create and manage jobs\n- [ ] Example manifests are clear and working\n- [ ] Documentation includes usage instructions\n- [ ] Kustomization files updated\n\n## Security Considerations\n- Metadata extractor has minimal permissions\n- Read-only access to PVCs\n- No cross-namespace access\n- Jobs run with non-root user (configure in container)\n\n## Dependencies\n- All previous tasks (for testing the complete flow)\n\n## Estimated Effort\n2-3 hours",
      "updatedAt" : 1752264227.000000000,
      "user" : "slin1237",
      "userHtmlUrl" : "https://github.com/slin1237",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25425177?v=4",
      "labels" : [ "feature", "good first issue", "high-priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)",
        "homepage" : "http://docs.sglang.ai/ome/",
        "name" : "ome",
        "fullName" : "sgl-project/ome",
        "htmlUrl" : "https://github.com/sgl-project/ome",
        "gitUrl" : "git://github.com/sgl-project/ome.git",
        "sshUrl" : "git@github.com:sgl-project/ome.git",
        "cloneUrl" : "https://github.com/sgl-project/ome.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 163,
        "watchersCount" : 163,
        "size" : 11299,
        "openIssuesCount" : 26,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:43:01Z",
        "languages" : {
          "Smarty" : 3020,
          "Dockerfile" : 9230,
          "Shell" : 41775,
          "Makefile" : 34695,
          "SCSS" : 10984,
          "JavaScript" : 279,
          "Go" : 3308216,
          "HTML" : 45930
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create and update Kubernetes manifests for RBAC permissions, ServiceAccounts, and other resources needed for PVC storage support, including creating multiple files, updating existing controller RBAC, and creating example PVC and BaseModel manifests.",
      "validationOrRequirement" : "Create ServiceAccount for metadata extraction jobs, Define RBAC roles and bindings, Update existing controller RBAC for job management, Create example PVC and BaseModel manifests, Ensure proper resource ordering, Minimal permissions for metadata extractor, Read-only access to PVCs, No cross-namespace access, Jobs run with non-root user.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description.",
      "otherNotes" : "This task aims to create and update Kubernetes manifests for RBAC permissions, ServiceAccounts, and other resources needed for PVC storage support. It involves creating multiple files, updating existing controller RBAC, and creating example PVC and BaseModel manifests.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283109
  }, {
    "issueDTO" : {
      "id" : 3224079008,
      "title" : "Add the rest of the core concept names to MathCAT",
      "url" : "https://github.com/NSoiffer/MathCAT/issues/381",
      "repositoryName" : "NSoiffer/MathCAT",
      "description" : "The [core concepts names](https://w3c.github.io/mathml-docs/intent-core-concepts/#functions-and-inverses) is in a nearly final state. \n\nFor each language, there is a definitions file that (should) specify how to speak that intent.  For example, in `Rules/Languages\\en\\definitions.yaml` there is the `IntentMappings` variable. For any intent that fits a simple generic pattern, the intent should be listed for that variable. For example,\n```\n    \"absolute-value\": \"function= ; absolute value: the absolute value: the absolute value; end absolute value\",\n```\nSome of the translations don't yet have this variable in the file.\n\nSome concepts have special cases (e.g., fractions, powers), and so they need an actual rule.\n\nThe values in 'en' and some other directories were added as a test and are probably only ~20% of the concept names. The rest need to be added, and for non-English files, eventually translated.\n\nFor those concepts that don't fit within what `IntentMappings` allows, a note should be made that a rule needs to be added.\n\nFor translations, \"t:\" and \"T:\" indicates whether something is translated. That doesn't work here. Probably the only thing to do is to add a comment\n```\n# NEEDS TRANSLATION\n```\nto the end of the line.",
      "updatedAt" : 1752264197.000000000,
      "user" : "NSoiffer",
      "userHtmlUrl" : "https://github.com/NSoiffer",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1545836?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "MathCAT: Math Capable Assistive Technology for generating speech, braille, and navigation.",
        "homepage" : "",
        "name" : "MathCAT",
        "fullName" : "NSoiffer/MathCAT",
        "htmlUrl" : "https://github.com/NSoiffer/MathCAT",
        "gitUrl" : "git://github.com/NSoiffer/MathCAT.git",
        "sshUrl" : "git@github.com:NSoiffer/MathCAT.git",
        "cloneUrl" : "https://github.com/NSoiffer/MathCAT.git",
        "owner" : {
          "login" : "NSoiffer",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 39,
        "stargazersCount" : 76,
        "watchersCount" : 76,
        "size" : 16387,
        "openIssuesCount" : 82,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-09T19:04:32Z",
        "languages" : {
          "Rust" : 2653044,
          "HTML" : 1650539,
          "Python" : 166621
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add the rest of the core concept names to MathCAT, including IntentMappings variable in definitions.yaml, and special cases needing actual rules.",
      "validationOrRequirement" : "Add the rest of the core concept names to MathCAT, with IntentMappings variable in definitions.yaml, and special cases needing actual rules. Add translation for non-English files.",
      "attemptedFixes" : "",
      "otherNotes" : "The core concept names are in a nearly final state, with definitions files for each language, and a variable IntentMappings in definitions.yaml. Some translations are missing, and special cases need actual rules. Values in 'en' and some other directories were added as a test, and the rest need to be added, along with translation for non-English files.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283114
  }, {
    "issueDTO" : {
      "id" : 3215113788,
      "title" : "[APM] Dependencies table infinite loading when no data exists",
      "url" : "https://github.com/elastic/kibana/issues/227184",
      "repositoryName" : "elastic/kibana",
      "description" : "**Kibana version:**\n8.18.3\n\n**Elasticsearch version:**\n\n**Server OS version:**\n\n**Browser version:**\n\n**Browser OS version:**\n\n**Original install method (e.g. download page, yum, from source, etc.):**\n\n**Describe the bug:**\nThe Dependencies table in the APM UI experiences infinite loading even when there is no data available.\n\n**Steps to reproduce:**\n1. Navigate to the APM application in Kibana.\n2. Go to the Dependencies table view.\n3. Ensure there is NO data available for dependencies.\n4. Observe that the table continues to load indefinitely and no data is displayed.\n\n**Expected behavior:**\nThe Dependencies table should properly render and display an empty page when no data is available, rather than displaying infinite loading.\n\n**Screenshots (if relevant):**\n\n**Errors in browser console (if relevant):**\n\n**Provide logs and/or server output (if relevant):**\n\n**Any additional context:**\n### Acceptance Criteria:\n- [ ] If there is NO data, an empty page should be shown rather than infinite loading.\n- [ ] Add a test to prevent this regression from happening again.\n\nhttps://github.com/user-attachments/assets/b4c1f953-82fe-45c7-a9fc-2b9954d54559\n",
      "updatedAt" : 1752264135.000000000,
      "user" : "kpatticha",
      "userHtmlUrl" : "https://github.com/kpatticha",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3369346?v=4",
      "labels" : [ "bug", "regression", "Team:obs-ux-infra_services", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Pinging @elastic/obs-ux-infra_services-team (Team:obs-ux-infra_services)", "I would love to work on it if its not assigned to anyone :) Could you assign it to me? @kpatticha ", "@itsagrox I added you as an assignee. Please let us know if you have any questions.", "> [@itsagrox](https://github.com/itsagrox) I added you as an assignee. Please let us know if you have any questions.\n\nI am setting up the environment, only this should be time consuming, issue itself is pretty straight forward. :)" ],
      "repository" : {
        "description" : "Your window into the Elastic Stack",
        "homepage" : "https://www.elastic.co/products/kibana",
        "name" : "kibana",
        "fullName" : "elastic/kibana",
        "htmlUrl" : "https://github.com/elastic/kibana",
        "gitUrl" : "git://github.com/elastic/kibana.git",
        "sshUrl" : "git@github.com:elastic/kibana.git",
        "cloneUrl" : "https://github.com/elastic/kibana.git",
        "owner" : {
          "login" : "elastic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 8393,
        "stargazersCount" : 20574,
        "watchersCount" : 20574,
        "size" : 10549670,
        "openIssuesCount" : 13302,
        "subscribersCount" : 845,
        "pushedAt" : "2025-07-12T00:03:43Z",
        "languages" : {
          "MDX" : 2692507,
          "CSS" : 205865,
          "Standard ML" : 3033,
          "Handlebars" : 36535,
          "Makefile" : 5205,
          "HTML" : 19095,
          "Perl" : 12381,
          "Nunjucks" : 118640,
          "EJS" : 12706,
          "TypeScript" : 255927723,
          "Dockerfile" : 15257,
          "Shell" : 432108,
          "Starlark" : 40163,
          "PEG.js" : 20672,
          "Batchfile" : 5169,
          "ANTLR" : 41968,
          "SCSS" : 127063,
          "JavaScript" : 8674841,
          "Python" : 7624
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Dependencies table in the APM UI experiences infinite loading even when there is no data available, and the expected behavior is to display an empty page instead.",
      "validationOrRequirement" : "The issue should be assigned to someone, and the assignee should let others know if they have any questions.",
      "attemptedFixes" : "No attempted fixes are mentioned in the description or comments.",
      "otherNotes" : "The issue is considered a good first issue and has been assigned to the author. The author is setting up the environment, which might take some time.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283118
  }, {
    "issueDTO" : {
      "id" : 3223187769,
      "title" : "Add the `in` operator",
      "url" : "https://github.com/SynaLinks/synalinks/issues/14",
      "repositoryName" : "SynaLinks/synalinks",
      "description" : "We already have the code to check if a schema contains another one, that would be nice to have an operator for that.\n\nThe goal is to be able to write things like:\n\n```python\nclass Foo(synalinks.DataModel):\n    foo: str\n\nclass FooBar(synalinks.DataModel):\n   foo: str\n   bar: str\n\nFoo in FooBar\n>>> True\n```",
      "updatedAt" : 1752264061.000000000,
      "user" : "YoanSallami",
      "userHtmlUrl" : "https://github.com/YoanSallami",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18442328?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I'd like to work on this issue, if it's still available. Could you please assign it to me?", "## Error when implementing the feature: `TypeError: argument of type 'MetaDataModel' is not iterable`\n\nThe error:\n```TypeError: argument of type 'MetaDataModel' is not iterable```\n\n\nhappens because Python does not support using the `in` operator directly between classes or metaclasses.\n\nWhen writing `Foo in FooBar`, Python internally tries to call `FooBar.__contains__(Foo)`. However, for classes and metaclasses, `__contains__` is not defined by default, and Python does not look for it on the metaclass in a way that works. This causes the `TypeError`.\n\nEven if we invert the operands (`FooBar in Foo`), the same issue arises because Python expects the right operand to be iterable or implement `__contains__`, which metaclasses do not.\n\n## Summary\n\n- The `in` operator requires the right-hand operand to be iterable or implement `__contains__`.\n- Classes and metaclasses are not iterable and do not properly support `__contains__` for this use case.\n- Therefore, expressions like `Foo in FooBar` or `FooBar in Foo` raise `TypeError`.\n\n## Recommended Solution\n\nInstead of using the `in` operator with classes/metaclasses, create a helper function for schema containment checks, for example:\n\n```python\ndef schema_in(sub_cls, sup_cls):\n    if not inspect.isclass(sub_cls) or not inspect.isclass(sup_cls):\n        return False\n    return contains_schema(sup_cls.get_schema(), sub_cls.get_schema())\n```\n\nThen use ```schema_in(Foo, FooBar)``` to check schema compatibility safely and clearly." ],
      "repository" : {
        "description" : "\uD83E\uDDE0\uD83D\uDD17 From idea to production in just few lines: Graph-Based Programmable Neuro-Symbolic LM Framework - a production-first LM framework built with decade old Deep Learning best practices",
        "homepage" : "https://www.synalinks.com/",
        "name" : "synalinks",
        "fullName" : "SynaLinks/synalinks",
        "htmlUrl" : "https://github.com/SynaLinks/synalinks",
        "gitUrl" : "git://github.com/SynaLinks/synalinks.git",
        "sshUrl" : "git@github.com:SynaLinks/synalinks.git",
        "cloneUrl" : "https://github.com/SynaLinks/synalinks.git",
        "owner" : {
          "login" : "SynaLinks",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 271,
        "watchersCount" : 271,
        "size" : 16314,
        "openIssuesCount" : 6,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T17:15:14Z",
        "languages" : {
          "Shell" : 1784,
          "Python" : 1400570
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add the `in` operator to check if a schema contains another one, allowing for expressions like `Foo in FooBar` or `FooBar in Foo`.",
      "validationOrRequirement" : "The `in` operator requires the right-hand operand to be iterable or implement `__contains__`. Classes and metaclasses are not iterable and do not properly support `__contains__` for this use case.",
      "attemptedFixes" : "## Error when implementing the feature: `TypeError: argument of type 'MetaDataModel' is not iterable`",
      "otherNotes" : "The error happens because Python does not support using the `in` operator directly between classes or metaclasses. The recommended solution is to create a helper function for schema containment checks.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283123
  }, {
    "issueDTO" : {
      "id" : 3214272969,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/briefcase-android-gradle-template/issues/102",
      "repositoryName" : "beeware/briefcase-android-gradle-template",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752264046.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I would like to take this task. Can you please assign it to me?", "BeeWare doesn't use issue assignments. Commenting here that you're working on it is sufficient. Thanks!" ],
      "repository" : {
        "description" : "A template for generating Android Gradle projects with Briefcase",
        "homepage" : "",
        "name" : "briefcase-android-gradle-template",
        "fullName" : "beeware/briefcase-android-gradle-template",
        "htmlUrl" : "https://github.com/beeware/briefcase-android-gradle-template",
        "gitUrl" : "git://github.com/beeware/briefcase-android-gradle-template.git",
        "sshUrl" : "git@github.com:beeware/briefcase-android-gradle-template.git",
        "cloneUrl" : "https://github.com/beeware/briefcase-android-gradle-template.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 31,
        "stargazersCount" : 25,
        "watchersCount" : 25,
        "size" : 3742,
        "openIssuesCount" : 3,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-10T07:03:40Z",
        "languages" : {
          "Java" : 8786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert README.rst from reStructuredText to GitHub-flavored Markdown, then delete the README.rst file before submitting a PR.",
      "validationOrRequirement" : "Verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.",
      "attemptedFixes" : "None mentioned in the description.",
      "otherNotes" : "One possible conversion option is pandoc. Pandoc installation instructions can be found here.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283126
  }, {
    "issueDTO" : {
      "id" : 3223372160,
      "title" : "The `TMT_SSH_*` options have no effect",
      "url" : "https://github.com/teemtee/tmt/issues/3872",
      "repositoryName" : "teemtee/tmt",
      "description" : "Currently the ssh options provided as `TMT_SSH_*` environment variables are appended to the list if default options:\n\nhttps://github.com/teemtee/tmt/blob/32ca248bd0e14ef8b9fe00f3d0235dfc3c0c2e2e/tmt/steps/provision/__init__.py#L155-L159\n\nAn example command line:\n\n    TMT_SSH_SERVER_ALIVE_INTERVAL=3 TMT_SSH_SERVER_ALIVE_COUNT_MAX=3 tmt run -vvv\n\nResults into this:\n\n    > /home/psss/git/tmt/tmt/steps/provision/__init__.py(160)<module>()\n    (Pdb) pp BASE_SSH_OPTIONS\n    ['-oForwardX11=no',\n    '-oStrictHostKeyChecking=no',\n    '-oUserKnownHostsFile=/dev/null',\n    '-oConnectionAttempts=5',\n    '-oConnectTimeout=60',\n    '-oServerAliveInterval=5',\n    '-oServerAliveCountMax=60',\n    '-oServerAliveCountMax=3',\n    '-oServerAliveInterval=3']\n\nIt seems that `ssh` respects the first one provided so the values from the environment variables are ignored. We should drop the duplicate names from the list to make it actualy working.\n\nThere are some options though, which can be provided multiple times and should be preserved, for example:\n\n    ssh -o \"IdentityFile=~/.ssh/key_one\" -o \"IdentityFile=~/.ssh/key_two\"",
      "updatedAt" : 1752263856.000000000,
      "user" : "psss",
      "userHtmlUrl" : "https://github.com/psss",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2803150?v=4",
      "labels" : [ "bug", "good first issue", "area | environment", "step | provision" ],
      "state" : "OPEN",
      "comments" : [ "> Currently the ssh options provided as `TMT_SSH_*` environment variables are appended to the list if default options:\n> \n> [tmt/tmt/steps/provision/__init__.py](https://github.com/teemtee/tmt/blob/32ca248bd0e14ef8b9fe00f3d0235dfc3c0c2e2e/tmt/steps/provision/__init__.py#L155-L159)\n> \n> Lines 155 to 159 in [32ca248](/teemtee/tmt/commit/32ca248bd0e14ef8b9fe00f3d0235dfc3c0c2e2e)\n> \n>  #: Base SSH options. \n>  #: This is the base set of SSH options tmt would use for all SSH \n>  #: connections. It is a combination of the default SSH options and those \n>  #: provided by environment variables. \n>  BASE_SSH_OPTIONS: tmt.utils.RawCommand = DEFAULT_SSH_OPTIONS + configure_ssh_options() \n> An example command line:\n> \n> ```\n> TMT_SSH_SERVER_ALIVE_INTERVAL=3 TMT_SSH_SERVER_ALIVE_COUNT_MAX=3 tmt run -vvv\n> ```\n> \n> Results into this:\n> \n> ```\n> > /home/psss/git/tmt/tmt/steps/provision/__init__.py(160)<module>()\n> (Pdb) pp BASE_SSH_OPTIONS\n> ['-oForwardX11=no',\n> '-oStrictHostKeyChecking=no',\n> '-oUserKnownHostsFile=/dev/null',\n> '-oConnectionAttempts=5',\n> '-oConnectTimeout=60',\n> '-oServerAliveInterval=5',\n> '-oServerAliveCountMax=60',\n> '-oServerAliveCountMax=3',\n> '-oServerAliveInterval=3']\n> ```\n> \n> It seems that `ssh` respects the first one provided so the values from the environment variables are ignored. We should drop the duplicate names from the list to make it actualy working.\n>\n> There are some options though, which can be provided multiple times and should be preserved...\n\nWouldn't we need to keep a list of options that need to be pruned? What if we prepend options from envvars, instead of adding them at the end of base options? That way the envvars ones would be the first ones seen by `ssh`, and those that can be repeated would still propagated." ],
      "repository" : {
        "description" : "Test Management Tool",
        "homepage" : "",
        "name" : "tmt",
        "fullName" : "teemtee/tmt",
        "htmlUrl" : "https://github.com/teemtee/tmt",
        "gitUrl" : "git://github.com/teemtee/tmt.git",
        "sshUrl" : "git@github.com:teemtee/tmt.git",
        "cloneUrl" : "https://github.com/teemtee/tmt.git",
        "owner" : {
          "login" : "teemtee",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 155,
        "stargazersCount" : 139,
        "watchersCount" : 139,
        "size" : 8857,
        "openIssuesCount" : 661,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-11T16:44:07Z",
        "languages" : {
          "Dockerfile" : 4409,
          "Shell" : 625594,
          "Jinja" : 26118,
          "Makefile" : 22399,
          "Python" : 2236053
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The `TMT_SSH_*` options have no effect because ssh respects the first option provided, so the values from environment variables are ignored.",
      "validationOrRequirement" : "The issue requires the validation that the environment variables are correctly handled and the ssh options are not duplicated.",
      "attemptedFixes" : "Prepending options from envvars instead of adding them at the end of base options was suggested as a potential solution.",
      "otherNotes" : "The issue seems to be related to the way ssh options are handled, specifically how environment variables are appended to the default options. The problem is that ssh respects the first option provided, so the values from environment variables are ignored. It's suggested to drop duplicate names from the list to make it work.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283131
  }, {
    "issueDTO" : {
      "id" : 3210399646,
      "title" : "Soft Binding Assertion",
      "url" : "https://github.com/contentauth/c2pa-rs/issues/1211",
      "repositoryName" : "contentauth/c2pa-rs",
      "description" : "The spec defines an updated concept of a Soft Binding Assertion for enclosing information about things like watermarks. The full definition of this assertion is fairly complicated with many components identifying the kind of  binding scope and regions of interest. We need to assure that we can read and write these assertions. A stretch goal would be full validation of the fields, but that isn't required.\n\nThere is a [standard list of valid algorithms](https://github.com/c2pa-org/softbinding-algorithm-list/blob/main/softbinding-algorithm-list.json) associated with this definition.\n[standard list of valid algorithms](https://github.com/c2pa-org/softbinding-algorithm-list/blob/main/softbinding-algorithm-list.json)\n\nThere is a [Soft Binding Resolution API ](https://spec.c2pa.org/specifications/specifications/2.2/specs/C2PA_Specification.html#_soft_binding_resolution_api)that we will need to support at least on a client basis. But that, should be a separate issue.\n\nWhen a soft binding is found, there is a section on [Validating Soft Binding Matches](https://spec.c2pa.org/specifications/specifications/2.2/specs/C2PA_Specification.html#_validating_soft_binding_matches) that will need to be supported.\n\n\n",
      "updatedAt" : 1752263667.000000000,
      "user" : "gpeacock",
      "userHtmlUrl" : "https://github.com/gpeacock",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1124693?v=4",
      "labels" : [ "feature", "accepted", "status:triaged", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ":white_check_mark: Jira issue https://jira.corp.adobe.com/browse/CAI-8976 is successfully created for this GitHub issue." ],
      "repository" : {
        "description" : "Rust SDK for the core C2PA (Coalition for Content Provenance and Authenticity) specification",
        "homepage" : "",
        "name" : "c2pa-rs",
        "fullName" : "contentauth/c2pa-rs",
        "htmlUrl" : "https://github.com/contentauth/c2pa-rs",
        "gitUrl" : "git://github.com/contentauth/c2pa-rs.git",
        "sshUrl" : "git@github.com:contentauth/c2pa-rs.git",
        "cloneUrl" : "https://github.com/contentauth/c2pa-rs.git",
        "owner" : {
          "login" : "contentauth",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 88,
        "stargazersCount" : 202,
        "watchersCount" : 202,
        "size" : 85403,
        "openIssuesCount" : 105,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-11T21:31:39Z",
        "languages" : {
          "PowerShell" : 10894,
          "Rust" : 3084080,
          "Makefile" : 12961
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement support for Soft Binding Assertions, including reading and writing, with optional full validation of fields",
      "validationOrRequirement" : "Support reading and writing Soft Binding Assertions, with a stretch goal of full validation of fields",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is related to a Soft Binding Assertion, with a linked standard list of valid algorithms and a Soft Binding Resolution API that needs to be supported on a client basis.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283134
  }, {
    "issueDTO" : {
      "id" : 3046359404,
      "title" : "New Metadata Variable Requested (define_variable_codelist_coded_codes) for Rule blocked: CORERULES-38 - 483 - 9716 ??? 9762",
      "url" : "https://github.com/cdisc-org/cdisc-rules-engine/issues/1171",
      "repositoryName" : "cdisc-org/cdisc-rules-engine",
      "description" : "Test data: https://cdisc.sharepoint.com/:f:/r/sites/CORERules/Shared%20Documents/unitTesting/SDTMIG/[CG0001](https://cdisc.sharepoint.com/:f:/r/sites/CORERules/Shared%20Documents/unitTesting/SDTMIG/CG0001?csf=1&web=1&e=LBMM90)?csf=1&web=1&e=LBMM90\n\n**Links to related JIRA Tickets**\n- https://jira.cdisc.org/browse/CORERULES-38    CG0001\n- https://jira.cdisc.org/browse/CORERULES-483  SEND16\n- https://jira.cdisc.org/browse/CORERULES-9716 TIG0090\n- https://jira.cdisc.org/browse/CORERULES-9716  TIG0289\n\nCondition: Not   custom domain \nRule: DOMAIN   = valid Domain Code published by CDISC\n\nTo program this rule, we need a new metadata variable that is similar to: \n**define_variable_codelist_coded_values**\nItemGroupDef.ItemDef.CodeList.[CodeListItem/EnumeratedItem].CodedValue\n\nthis should be:\n**define_variable_codelist_coded_codes**\nItemGroupDef.ItemDef.CodeList.[CodeListItem/EnumeratedItem].Alias.Name\n\n\n![Image](https://github.com/user-attachments/assets/15898a71-8039-4541-879b-cb02e326480c)",
      "updatedAt" : 1752263523.000000000,
      "user" : "eljanssens",
      "userHtmlUrl" : "https://github.com/eljanssens",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/117269125?v=4",
      "labels" : [ "Define-XML cross check", "SDTM", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Open source offering of the cdisc rules engine",
        "homepage" : null,
        "name" : "cdisc-rules-engine",
        "fullName" : "cdisc-org/cdisc-rules-engine",
        "htmlUrl" : "https://github.com/cdisc-org/cdisc-rules-engine",
        "gitUrl" : "git://github.com/cdisc-org/cdisc-rules-engine.git",
        "sshUrl" : "git@github.com:cdisc-org/cdisc-rules-engine.git",
        "cloneUrl" : "https://github.com/cdisc-org/cdisc-rules-engine.git",
        "owner" : {
          "login" : "cdisc-org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15,
        "stargazersCount" : 63,
        "watchersCount" : 63,
        "size" : 118182,
        "openIssuesCount" : 214,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-11T19:45:44Z",
        "languages" : {
          "AGS Script" : 807,
          "Python" : 1665299
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Request for a new metadata variable define_variable_codelist_coded_codes to be used in the SDTM rules engine.",
      "validationOrRequirement" : "The rule is to validate a Domain Code published by CDISC, and a new metadata variable is required to achieve this.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to JIRA tickets CORERULES-38, CORERULES-483, CORERULES-9716, and CORERULES-9762. The condition is that the domain is not custom and the rule is to validate a Domain Code published by CDISC. A new metadata variable is needed, similar to define_variable_codelist_coded_values, but for codes instead of values.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283140
  }, {
    "issueDTO" : {
      "id" : 3223661372,
      "title" : "Return a properly formatted DataFrame when no features are detected",
      "url" : "https://github.com/tobac-project/tobac/issues/510",
      "repositoryName" : "tobac-project/tobac",
      "description" : "* [x] Have you searched the issue tracker for the same problem?\n* [x] Have you checked if you're using the latest version? If not, which version are you using?\n* [x] Have you mentioned the steps to reproduce the issue?\n* [x] Have you, if applicable, included error messages?\n\nRight now, if you detect no features, `None` is returned. Instead, we should return an empty (but properly formatted) dataframe. ",
      "updatedAt" : 1752263507.000000000,
      "user" : "freemansw1",
      "userHtmlUrl" : "https://github.com/freemansw1",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7192020?v=4",
      "labels" : [ "bug", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Tracking and object-based analysis of clouds",
        "homepage" : "",
        "name" : "tobac",
        "fullName" : "tobac-project/tobac",
        "htmlUrl" : "https://github.com/tobac-project/tobac",
        "gitUrl" : "git://github.com/tobac-project/tobac.git",
        "sshUrl" : "git@github.com:tobac-project/tobac.git",
        "cloneUrl" : "https://github.com/tobac-project/tobac.git",
        "owner" : {
          "login" : "tobac-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 59,
        "stargazersCount" : 120,
        "watchersCount" : 120,
        "size" : 100830,
        "openIssuesCount" : 68,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-09T18:17:21Z",
        "languages" : {
          "Dockerfile" : 280,
          "Shell" : 322,
          "Python" : 759398
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Return an empty but properly formatted DataFrame when no features are detected instead of returning None",
      "validationOrRequirement" : "Return a properly formatted DataFrame when no features are detected",
      "attemptedFixes" : "",
      "otherNotes" : "The issue tracker has been searched, the latest version is being used, steps to reproduce the issue are included, and error messages are mentioned.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283143
  }, {
    "issueDTO" : {
      "id" : 2639226494,
      "title" : "Default logger and events logger use different timestamp formats",
      "url" : "https://github.com/elastic/elastic-agent/issues/5962",
      "repositoryName" : "elastic/elastic-agent",
      "description" : "This was tested with the latest `main` from Elastic-Agent and Beats\n\nThe default logger (user configurable) and the events logger are using different formats for the timestamp:\n\nDefault logger (RFC3339):\n`\"@timestamp\":\"2024-11-06T21:01:18.537Z\"`\nEvent logger (ISO8601):\n`\"@timestamp\":\"2024-11-06T16:01:03.105-0500\"`\n\nThere is a chance this has been like that since the events logger was introduced by https://github.com/elastic/elastic-agent/pull/4549.\n\nStandalone Beats might be affected by this as well.",
      "updatedAt" : 1752263411.000000000,
      "user" : "belimawr",
      "userHtmlUrl" : "https://github.com/belimawr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/333577?v=4",
      "labels" : [ "Team:Elastic-Agent", "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Pinging @elastic/elastic-agent (Team:Elastic-Agent)", "hi @belimawr if its ok can i work on this?", "We are going to get rid of the event log files in Elastic Agent, so it probably isn't worth fixing this right now. https://github.com/elastic/elastic-agent/issues/8845" ],
      "repository" : {
        "description" : "Elastic Agent - single, unified way to add monitoring for logs, metrics, and other types of data to a host.",
        "homepage" : "",
        "name" : "elastic-agent",
        "fullName" : "elastic/elastic-agent",
        "htmlUrl" : "https://github.com/elastic/elastic-agent",
        "gitUrl" : "git://github.com/elastic/elastic-agent.git",
        "sshUrl" : "git@github.com:elastic/elastic-agent.git",
        "cloneUrl" : "https://github.com/elastic/elastic-agent.git",
        "owner" : {
          "login" : "elastic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 175,
        "stargazersCount" : 185,
        "watchersCount" : 185,
        "size" : 392884,
        "openIssuesCount" : 608,
        "subscribersCount" : 234,
        "pushedAt" : "2025-07-11T21:35:59Z",
        "languages" : {
          "Smarty" : 70655,
          "HCL" : 21793,
          "PowerShell" : 13651,
          "Dockerfile" : 302,
          "Shell" : 70790,
          "C" : 6722,
          "ANTLR" : 1704,
          "Makefile" : 13019,
          "Go" : 5735246,
          "Mustache" : 5353,
          "Python" : 4898
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The default logger and events logger are using different timestamp formats, with the default logger using RFC3339 and the events logger using ISO8601.",
      "validationOrRequirement" : "No specific requirements mentioned, but it's a good first issue and a bug.",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments.",
      "otherNotes" : "This issue was tested with the latest main from Elastic-Agent and Beats. It's possible this has been like that since the events logger was introduced by https://github.com/elastic/elastic-agent/pull/4549. Standalone Beats might be affected as well.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283147
  }, {
    "issueDTO" : {
      "id" : 3210588510,
      "title" : "AllActionsIncluded default to true",
      "url" : "https://github.com/contentauth/c2pa-rs/issues/1215",
      "repositoryName" : "contentauth/c2pa-rs",
      "description" : "The spec did a flip/flop on this and now requires every actions to state explicitly that it includes all actions or else it will be assumed that it does not (and a warning would be displayed). Since this was never required before in our SDK, I think the only safe way to handle this is to default this field to true, and let users set it to false if they know or suspect that actions are missing. \nI'd suggest that we have a setting that would define if the claim generator wants this to default to true or false.\n\nThis could be part of a larger effort to set default values for any action.",
      "updatedAt" : 1752263273.000000000,
      "user" : "gpeacock",
      "userHtmlUrl" : "https://github.com/gpeacock",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1124693?v=4",
      "labels" : [ "feature", "accepted", "status:triaged", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ":white_check_mark: Jira issue https://jira.corp.adobe.com/browse/CAI-8978 is successfully created for this GitHub issue." ],
      "repository" : {
        "description" : "Rust SDK for the core C2PA (Coalition for Content Provenance and Authenticity) specification",
        "homepage" : "",
        "name" : "c2pa-rs",
        "fullName" : "contentauth/c2pa-rs",
        "htmlUrl" : "https://github.com/contentauth/c2pa-rs",
        "gitUrl" : "git://github.com/contentauth/c2pa-rs.git",
        "sshUrl" : "git@github.com:contentauth/c2pa-rs.git",
        "cloneUrl" : "https://github.com/contentauth/c2pa-rs.git",
        "owner" : {
          "login" : "contentauth",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 88,
        "stargazersCount" : 202,
        "watchersCount" : 202,
        "size" : 85403,
        "openIssuesCount" : 105,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-11T21:31:39Z",
        "languages" : {
          "PowerShell" : 10894,
          "Rust" : 3084080,
          "Makefile" : 12961
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The spec did a flip/flop on this and now requires every actions to state explicitly that it includes all actions or else it will be assumed that it does not, and default the AllActionsIncluded field to true",
      "validationOrRequirement" : "every actions to state explicitly that it includes all actions or else it will be assumed that it does not (and a warning would be displayed)",
      "attemptedFixes" : "default this field to true, and let users set it to false if they know or suspect that actions are missing",
      "otherNotes" : "Jira issue https://jira.corp.adobe.com/browse/CAI-8978 is successfully created for this GitHub issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283151
  }, {
    "issueDTO" : {
      "id" : 3222949532,
      "title" : "Puck breaks with strict CSP",
      "url" : "https://github.com/puckeditor/puck/issues/1157",
      "repositoryName" : "puckeditor/puck",
      "description" : "## Description\n\nHey, Our current environment has a strict CSP (Content Security Policy) in place. We noticed that the stylesheet is importing an external font:\nhttps://github.com/puckeditor/puck/blob/7bb4823fafd73c9c3eb507f1999b153a373c5c2d/packages/core/styles.css#L1\n\nUnfortunately, we cannot simply update our CSP policy to allow this, and it is also preventing Puck from loading.\n\nWould you be open to including the font within the library to avoid the external import? If so, we would be happy to work on the PR.\n\n## Environment\n\n- Puck version: 0.19.1\n\n<!--\n  Detail the environment where the bug is occurring.\n-->\n\n## Steps to reproduce\n\nThis is happening  when `https://rsms.me/inter/inter.css\"` is not part of the `Content-Security-Policy header.\n\n<img width=\"1192\" height=\"421\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/748b308a-d77d-439b-b8a2-3dfe710b85ab\" />\n\n\n## What I expect to happen\n\nIdeally, all resources should be imported from the library itself.\n",
      "updatedAt" : 1752263256.000000000,
      "user" : "fkhadra",
      "userHtmlUrl" : "https://github.com/fkhadra",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5574267?v=4",
      "labels" : [ "type: bug \uD83D\uDC1B", "ready", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This is valid. We can look to inline the font file.", "@chrisvxd  Hi! I???d like to work on this issue if it???s still available.\n", "Yes no problem, go ahead!" ],
      "repository" : {
        "description" : "The visual editor for React",
        "homepage" : "https://puckeditor.com",
        "name" : "puck",
        "fullName" : "puckeditor/puck",
        "htmlUrl" : "https://github.com/puckeditor/puck",
        "gitUrl" : "git://github.com/puckeditor/puck.git",
        "sshUrl" : "git@github.com:puckeditor/puck.git",
        "cloneUrl" : "https://github.com/puckeditor/puck.git",
        "owner" : {
          "login" : "puckeditor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 467,
        "stargazersCount" : 6977,
        "watchersCount" : 6977,
        "size" : 4223,
        "openIssuesCount" : 199,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T10:56:40Z",
        "languages" : {
          "TypeScript" : 624768,
          "MDX" : 243067,
          "CSS" : 62695,
          "Shell" : 452,
          "Handlebars" : 2758,
          "JavaScript" : 23811
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to include the font within the library to avoid the external import, and make all resources import from the library itself.",
      "validationOrRequirement" : "The environment has a strict CSP policy, and the font should be included within the library to avoid the external import.",
      "attemptedFixes" : "The comment suggests to inline the font file.",
      "otherNotes" : "The issue is occurring in a strict CSP environment, the stylesheet is importing an external font, and the environment details are not provided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283155
  }, {
    "issueDTO" : {
      "id" : 3210905052,
      "title" : "Investigate build size reductions by selective feature compilation",
      "url" : "https://github.com/contentauth/c2pa-rs/issues/1219",
      "repositoryName" : "contentauth/c2pa-rs",
      "description" : "Determine is size reduction is possible or appropriate by conditional compilation of features.",
      "updatedAt" : 1752263163.000000000,
      "user" : "gpeacock",
      "userHtmlUrl" : "https://github.com/gpeacock",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1124693?v=4",
      "labels" : [ "task", "accepted", "status:triaged", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ":white_check_mark: Jira issue https://jira.corp.adobe.com/browse/CAI-9020 is successfully created for this GitHub issue." ],
      "repository" : {
        "description" : "Rust SDK for the core C2PA (Coalition for Content Provenance and Authenticity) specification",
        "homepage" : "",
        "name" : "c2pa-rs",
        "fullName" : "contentauth/c2pa-rs",
        "htmlUrl" : "https://github.com/contentauth/c2pa-rs",
        "gitUrl" : "git://github.com/contentauth/c2pa-rs.git",
        "sshUrl" : "git@github.com:contentauth/c2pa-rs.git",
        "cloneUrl" : "https://github.com/contentauth/c2pa-rs.git",
        "owner" : {
          "login" : "contentauth",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 88,
        "stargazersCount" : 202,
        "watchersCount" : 202,
        "size" : 85403,
        "openIssuesCount" : 105,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-11T21:31:39Z",
        "languages" : {
          "PowerShell" : 10894,
          "Rust" : 3084080,
          "Makefile" : 12961
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Investigate build size reductions by selective feature compilation",
      "validationOrRequirement" : "determine if size reduction is possible or appropriate by conditional compilation of features",
      "attemptedFixes" : "",
      "otherNotes" : "Jira issue https://jira.corp.adobe.com/browse/CAI-9020 is successfully created for this GitHub issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283158
  }, {
    "issueDTO" : {
      "id" : 2510227302,
      "title" : "Stop using deprecated grpc connection establishment functions",
      "url" : "https://github.com/elastic/elastic-agent/issues/5453",
      "repositoryName" : "elastic/elastic-agent",
      "description" : "Our control protocol clients use the deprecated [`grpc.DialContext` ](https://pkg.go.dev/google.golang.org/grpc#DialContext) for connection establishment. The package suggests using [`grpc.NewClient`](https://pkg.go.dev/google.golang.org/grpc#NewClient) instead, but this isn't semantically equivalent. More specifically, it cannot be made to block, whereas we specifically want to block when we establish these connections. If we want to migrate, we'll have to write our own wrapper which is equivalent to what [`grpc.DialContext`](https://pkg.go.dev/google.golang.org/grpc#DialContext) does.\n\nThe deprecated methods will remain supported throughout `v1.x` of `grpc`, so this isn't urgent. For now, I've added `nolint` directives and comments in #5442.",
      "updatedAt" : 1752263085.000000000,
      "user" : "swiatekm",
      "userHtmlUrl" : "https://github.com/swiatekm",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/93588780?v=4",
      "labels" : [ "good first issue", "Cleanup" ],
      "state" : "OPEN",
      "comments" : [ "hi @swiatekm can i work on this if its ok?" ],
      "repository" : {
        "description" : "Elastic Agent - single, unified way to add monitoring for logs, metrics, and other types of data to a host.",
        "homepage" : "",
        "name" : "elastic-agent",
        "fullName" : "elastic/elastic-agent",
        "htmlUrl" : "https://github.com/elastic/elastic-agent",
        "gitUrl" : "git://github.com/elastic/elastic-agent.git",
        "sshUrl" : "git@github.com:elastic/elastic-agent.git",
        "cloneUrl" : "https://github.com/elastic/elastic-agent.git",
        "owner" : {
          "login" : "elastic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 175,
        "stargazersCount" : 185,
        "watchersCount" : 185,
        "size" : 392884,
        "openIssuesCount" : 608,
        "subscribersCount" : 234,
        "pushedAt" : "2025-07-11T21:35:59Z",
        "languages" : {
          "Smarty" : 70655,
          "HCL" : 21793,
          "PowerShell" : 13651,
          "Dockerfile" : 302,
          "Shell" : 70790,
          "C" : 6722,
          "ANTLR" : 1704,
          "Makefile" : 13019,
          "Go" : 5735246,
          "Mustache" : 5353,
          "Python" : 4898
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "stop using deprecated grpc connection establishment functions and migrate to grpc.NewClient",
      "validationOrRequirement" : "semantically equivalent to grpc.NewClient, cannot be made to block, need to write own wrapper",
      "attemptedFixes" : "nolint directives and comments added in #5442",
      "otherNotes" : "nolint directives and comments added in #5442, deprecated methods will remain supported throughout v1.x of grpc",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283161
  }, {
    "issueDTO" : {
      "id" : 3223137877,
      "title" : "dagProcessor in helm chart doesn't have a labels section",
      "url" : "https://github.com/apache/airflow/issues/53190",
      "repositoryName" : "apache/airflow",
      "description" : "### Description\n\nAll other parts of the helm chart have a labels section specific to the workload except for the dagProcessor. Can one be added please?\n\n### Use case/motivation\n\nI'd like the dagProcessor to have labels\n\n### Related issues\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [x] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)\n",
      "updatedAt" : 1752263071.000000000,
      "user" : "jabbera",
      "userHtmlUrl" : "https://github.com/jabbera",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/301208?v=4",
      "labels" : [ "good first issue", "kind:feature", "area:helm-chart" ],
      "state" : "OPEN",
      "comments" : [ "Feel free to add it ", "Otherwise it will wait for someone to pick it up and do it - I marked it as \"good first issue\" so hopefully someone will soon. But if you can make PR, that's the fastest way.", "values.yaml has labels section which gets injected into all deployments. Does that help in any regard?", "I can take this!" ],
      "repository" : {
        "description" : "Apache Airflow - A platform to programmatically author, schedule, and monitor workflows",
        "homepage" : "https://airflow.apache.org/",
        "name" : "airflow",
        "fullName" : "apache/airflow",
        "htmlUrl" : "https://github.com/apache/airflow",
        "gitUrl" : "git://github.com/apache/airflow.git",
        "sshUrl" : "git@github.com:apache/airflow.git",
        "cloneUrl" : "https://github.com/apache/airflow.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15301,
        "stargazersCount" : 40971,
        "watchersCount" : 40971,
        "size" : 416042,
        "openIssuesCount" : 1526,
        "subscribersCount" : 763,
        "pushedAt" : "2025-07-11T23:51:39Z",
        "languages" : {
          "Java" : 1443,
          "Jinja" : 76192,
          "CSS" : 15733,
          "Go" : 63158,
          "HTML" : 42905,
          "Jupyter Notebook" : 7288,
          "TypeScript" : 2124349,
          "HCL" : 3786,
          "Dockerfile" : 119790,
          "Shell" : 230742,
          "JavaScript" : 328117,
          "Mako" : 2684,
          "Python" : 42415969
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a labels section to the dagProcessor in the helm chart",
      "validationOrRequirement" : "None",
      "attemptedFixes" : "None",
      "otherNotes" : "values.yaml has labels section which gets injected into all deployments. Does that help in any regard?",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283163
  }, {
    "issueDTO" : {
      "id" : 3146323660,
      "title" : "Kali Linux 2025.2 Release (Kali Menu Refresh, BloodHound CE & CARsenal)",
      "url" : "https://github.com/e-m-b-a/emba/issues/1609",
      "repositoryName" : "e-m-b-a/emba",
      "description" : "New Kali Linux is out: https://www.kali.org/blog/kali-linux-2025-2-release/\n\nWe need to test EMBA on it\n\n**Testcases:**\n\nTestfirmware: [DLink DIR300](https://ftp.dlink.de/dir/dir-300/archive/driver_software/DIR-300_fw_revb_214b01_ALL_de_20130206.zip)\n\n- [x] Default/docker installation working with current docker image\n  - [x] `./installer.sh -d` finished without errors\n  - [x] dependency check (`./emba -d 1`)\n  - [x] EMBA run with profile quick-scan\n  - [x] EMBA run with profile default-scan in strict mode (-S)\n  - [x] EMBA run with profile default-scan-emulation in strict mode (-S)\n  - [x] EMBA run with profile full-scan in strict mode (-S)\n- [ ] Docker base image build\n  - [x] `DOCKER_BUILDKIT=1 sudo -E docker compose build --progress=plain --no-cache --pull` finished without errors\n  - [x] dependency check (`./emba -d 2`)\n  - [ ] EMBA run with profile quick-scan\n  - [ ] EMBA run with profile default-scan in strict mode (-S)\n  - [ ] EMBA run with profile default-scan-emulation in strict mode (-S)\n  - [ ] EMBA run with profile full-scan in strict mode (-S)\n- [ ] Optional full installation working on Kali Linux\n  - [ ] `./installer.sh -F` finished without errors\n  - [ ] dependency check (`./emba -d 1`)\n  - [ ] EMBA run in dev mode with options -s -z -S -D -E -t -W -Q\n  - [ ] EMBA run in dev mode with options -s -z -S -D, -c, -E, -t, -W -Q\n\n**Priority issue**\nYES\n",
      "updatedAt" : 1752263053.000000000,
      "user" : "m-1-k-3",
      "userHtmlUrl" : "https://github.com/m-1-k-3",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/497520?v=4",
      "labels" : [ "in progress", "EMBA", "issue in 3rd party component", "help wanted", "Research", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi,\n\nI am doing the first section today.", "Installation was OK.\n\nDependency check shows this:\n\n![Image](https://github.com/user-attachments/assets/5ea3725e-9cf9-462d-b084-8a94b85aad02)\n\n1.5.2d was downloaded during the install. All other dependeny are OK. 1st test is running.", "Basically all the tests were OK. I got a \"No such object\" error at the end but the reports are error free.\n\nQuick-scan:\n\n![Image](https://github.com/user-attachments/assets/3ed08847-bb09-4db0-aa60-d8556b16ab9c)\n\nDefault-scan:\n\n![Image](https://github.com/user-attachments/assets/ce5dfbe9-5978-4c8a-8bfa-d0d193d0f807)\n\nDefault-scan-emulation:\n\n![Image](https://github.com/user-attachments/assets/2b0918fc-dfdc-49f8-8381-e9af4d688888)\n\nFull-scan:\n\n![Image](https://github.com/user-attachments/assets/753bbba2-c067-4c0b-9f17-89a66f36cd66)", "A quick note on this issue ... The docker build is currently failing.", "Should work again ... someone interested in testing the full install and the docker build?\n", "\n**Update on latest Kali Docker install / re-emulation behavior:**\n\nI tested the **Kali 2025.2 release** using the `run.sh` script and confirmed that while the emulation triggers correctly, it fails due to missing emulation dependencies **outside** the Docker container???namely `uml-utilities` and `qemu-system-mips` aren't present in the host environment, causing the re-emulation step to abort.\n\n![Image](https://github.com/user-attachments/assets/3b3126cd-72c7-406d-bf23-f4a9051c4a7b)\n\n![Image](https://github.com/user-attachments/assets/ab5f278e-c07e-4118-93fe-37681a60bc82)\n\n---\n\n**Proposed next steps:**\n\n* Modify the `run.sh` logic to detect and install required host tools (`uml???utilities`, `qemu???system???mips`)  before starting the re-emulation.\n* Alternatively, clarify in the README/docs that these dependencies are required on the host for proper operation outside containerized execution.\n\nAlso, as mentioned in the last comment, I???m happy to test the full install and docker build.\n", "> **Update on latest Kali Docker install / re-emulation behavior:**\n> \n> I tested the **Kali 2025.2 release** using the `run.sh` script and confirmed that while the emulation triggers correctly, it fails due to missing emulation dependencies **outside** the Docker container???namely `uml-utilities` and `qemu-system-mips` aren't present in the host environment, causing the re-emulation step to abort.\n\nYes, that is the expectected behaviour. The installer does not install all these dependencies on the host. If you are using system emulation and you would like to use the re-run feature on the host you need to install it manually. On the other hand you could also use the docker base image for the re-run.", "Thanks for the explanation, makes sense to me. ", "Did section 2 tonight, everything seemed to go fine other than the previously mentioned \n`Error: No such object: 1057f73a5e8d4157dde52776d5ab6ca3b8ca27ea4988174e3e9418747df03f30`\n\nDocker build\n\n![Image](https://github.com/user-attachments/assets/dab0cf4f-3d27-41fd-b6a7-3ab453969e9d)\n\ndependency check:\n\n![Image](https://github.com/user-attachments/assets/1f3644da-7596-488b-ab7b-65350f86cc4a)\n\n![Image](https://github.com/user-attachments/assets/642c51fb-ba72-4a64-96af-9f62cac22e42)\n\nEMBA run with profile quick-scan:\n\n![Image](https://github.com/user-attachments/assets/aa27ca31-eadb-4923-bb1f-30a38e1a616c)\n\nEMBA run with profile default-scan in strict mode (-S):\n\n![Image](https://github.com/user-attachments/assets/a0f14282-931b-4526-93be-020bef06a759)\n\nEMBA run with profile default-scan-emulation in strict mode (-S):\n\n![Image](https://github.com/user-attachments/assets/e737526f-5d58-4d5e-a916-b94df9a5201e)\n\nEMBA run with profile full-scan in strict mode (-S):\n\n![Image](https://github.com/user-attachments/assets/b060b216-6b8c-4e3a-abc1-a3f131326221)" ],
      "repository" : {
        "description" : "EMBA - The firmware security analyzer",
        "homepage" : "https://www.securefirmware.de",
        "name" : "emba",
        "fullName" : "e-m-b-a/emba",
        "htmlUrl" : "https://github.com/e-m-b-a/emba",
        "gitUrl" : "git://github.com/e-m-b-a/emba.git",
        "sshUrl" : "git@github.com:e-m-b-a/emba.git",
        "cloneUrl" : "https://github.com/e-m-b-a/emba.git",
        "owner" : {
          "login" : "e-m-b-a",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 265,
        "stargazersCount" : 3043,
        "watchersCount" : 3043,
        "size" : 24474,
        "openIssuesCount" : 8,
        "subscribersCount" : 43,
        "pushedAt" : "2025-07-07T08:29:10Z",
        "languages" : {
          "Dockerfile" : 422,
          "Shell" : 2033397,
          "CSS" : 6771,
          "HTML" : 9560
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Test EMBA on Kali Linux 2025.2 release, including testing of EMBA run with different profiles and dependency checks",
      "validationOrRequirement" : "Test EMBA on Kali Linux 2025.2 release, testcases include: Default/docker installation working with current docker image, Docker base image build, Optional full installation working on Kali Linux",
      "attemptedFixes" : "Modify `run.sh` logic to detect and install required host tools (`uml-utilities`, `qemu-system-mips`) before starting re-emulation. Alternatively, clarify in README/docs that these dependencies are required on the host for proper operation outside containerized execution.",
      "otherNotes" : "The installer does not install all dependencies on the host. Manual installation is required for system emulation re-run feature. Docker base image can be used for re-run.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283169
  }, {
    "issueDTO" : {
      "id" : 2149329220,
      "title" : "Add __builtin_stack_address to clang to increase compatibility to gcc",
      "url" : "https://github.com/llvm/llvm-project/issues/82632",
      "repositoryName" : "llvm/llvm-project",
      "description" : "I want to get the stack address and gcc has the function [__builtin_stack_address](https://gcc.gnu.org/onlinedocs/gcc/Return-Address.html). It would be good, to also have this builtin in clang, it would on top increase compatibility to gcc.",
      "updatedAt" : 1752263013.000000000,
      "user" : "Febbe",
      "userHtmlUrl" : "https://github.com/Febbe",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2228627?v=4",
      "labels" : [ "clang:headers", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "We can reuse `@llvm.sponentry` https://llvm.org/docs/LangRef.html#llvm-sponentry-intrinsic. However it is only available on AArch64 and ARM.\r\n\r\nAnother way to implement this is using `@llvm.read_register`. It is implemented on ARM, AArch64, PowerPC and x86_64.\r\n", "\nHi!\n\nThis issue may be a good introductory issue for people new to working on LLVM. If you would like to work on this issue, your first steps are:\n\n1. In the comments of the issue, request for it to be assigned to you.\n2. Fix the issue locally.\n3. [Run the test suite](https://llvm.org/docs/TestingGuide.html#unit-and-regression-tests) locally. Remember that the subdirectories under `test/` create fine-grained testing targets, so you can e.g. use `make check-clang-ast` to only run Clang's AST tests.\n4. Create a Git commit.\n5. Run [`git clang-format HEAD~1`](https://clang.llvm.org/docs/ClangFormat.html#git-integration) to format your changes.\n6. Open a [pull request](https://github.com/llvm/llvm-project/pulls) to the [upstream repository](https://github.com/llvm/llvm-project) on GitHub. Detailed instructions can be found [in GitHub's documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request).\n\nIf you have any further questions about this issue, don't hesitate to ask via a comment in the thread below.\n\n", "\n@llvm/issue-subscribers-good-first-issue\n\nAuthor: Fabian Ke??ler (Febbe)\n\n<details>\nI want to get the stack address and gcc has the function [__builtin_stack_address](https://gcc.gnu.org/onlinedocs/gcc/Return-Address.html). It would be god, to also have this builtin in clang, it would on top increase compatibility to gcc.\n</details>\n", "Could I be assigned this one please?", "@dtcxzyw Would you prefer there be an LLVM IR intrinsic `llvm.stackaddress` and then lower it in LLVM, or to just emit the appropriate `llvm.read_register` call in clang's CGBuiltins.cpp (and an error otherwise if on an unsupported architecture)? It seems that the first approach is taken for `__builtin_frame_address` etc., but those require complicated logic compared to getting the stack address.\r\n\r\nRelatedly, it seems like `llvm.frameaddress` leads to a crash in ISel DAG->DAG for m68k: https://gcc.godbolt.org/z/rcnfEbPvY (I guess it's unimplemented), but all other targets on Godbolt seem to work.", "I am not a member of LLVM, but I think adding the intrinsic to LLVM would be cleaner, since it is more general.", "@anematode are you still working on this?\r\n", "@komalverma04 Ack, sorry. I think if the preferred solution is adding a new LLVM intrinsic it's probably not a good task for a newbie like myself. Could I be unassigned please?", "@anematode I am also newbie. I would like to try it once. If you have worked on it, maybe we can do it together.", "FWIW, there's this patch from ages ago: https://lists.llvm.org/pipermail/llvm-dev/2013-October/066294.html", "I see that @anematode is not working on this anymore. Could I be assigned this issue?", "> Could I be assigned this issue?\n\nThanks!\n\nSo the implementation (#121332)  is using the `@llvm.read_register.*` intrinsic to read the stack pointer register and return it as an `Int8PtrTy`. Currently the implementation only supports x86[_64]. I can add other architectures in future patches.\n\nQQ: Is there someone working on adding support  for `@llvm.read_register` to other architectures and/or registers. I [see](https://llvm.org/docs/LangRef.html#llvm-read-register-llvm-read-volatile-register-and-llvm-write-register-intrinsics) that you can only read the stack pointer register and only on certain architectures.", "Closing as @aalhwc seems to have added this builtin here: https://github.com/aalhwc/llvm-project/commit/f247c1ab9fa89ca09476ed0a398a4c4385e75193", "This patch is still under review.", "> This patch is still under review.\n\nI see, can you link the review for us?  It doesn't seem linked ot this issue. (And github didnt make it clear that the 'fix' was in a branch, not in llvm, *sigh*, sorry about that).", "That was my bad. My apologies.", "> That was my bad. My apologies.\n\nOn top, the linked PR only implements this for amd64/x86. \nBut honestly, I was interested in this feature on riscv32-unknown-unknown.\nI would propose to close this, when all major platforms are supported.", "> On top, the linked PR only implements this for amd64/x86.\n\nThe last 2 commits add support for risc32/64 and arm32/64. I updated the PR description accordingly.", "I unfortunately can't work on this anymore, please feel free to assign this issue to someone else.", "Can I be assigned this issue? I have a [PR](https://github.com/llvm/llvm-project/pull/148281) up already. Feedback is appreciated!" ],
      "repository" : {
        "description" : "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.",
        "homepage" : "http://llvm.org",
        "name" : "llvm-project",
        "fullName" : "llvm/llvm-project",
        "htmlUrl" : "https://github.com/llvm/llvm-project",
        "gitUrl" : "git://github.com/llvm/llvm-project.git",
        "sshUrl" : "git@github.com:llvm/llvm-project.git",
        "cloneUrl" : "https://github.com/llvm/llvm-project.git",
        "owner" : {
          "login" : "llvm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14443,
        "stargazersCount" : 33450,
        "watchersCount" : 33450,
        "size" : 2519038,
        "openIssuesCount" : 30765,
        "subscribersCount" : 577,
        "pushedAt" : "2025-07-12T01:01:34Z",
        "languages" : {
          "GDB" : 8473,
          "CMake" : 4075997,
          "Mustache" : 16482,
          "HTML" : 1956247,
          "Pawn" : 10154,
          "MATLAB" : 4946,
          "Fortran" : 11610249,
          "LLVM" : 631719945,
          "OCaml" : 335815,
          "Assembly" : 150737335,
          "Python" : 12915167,
          "Rust" : 4903,
          "Objective-C++" : 1173632,
          "SWIG" : 287770,
          "Tree-sitter Query" : 6195,
          "Perl" : 183797,
          "MLIR" : 21179643,
          "Cuda" : 1243342,
          "Scilab" : 160404,
          "Starlark" : 1177382,
          "Batchfile" : 52122,
          "AMPL" : 1662,
          "Swift" : 271,
          "DTrace" : 334,
          "C" : 202129658,
          "RPC" : 28,
          "Makefile" : 114902,
          "Cool" : 5401,
          "Jupyter Notebook" : 72939,
          "M" : 9785,
          "TypeScript" : 69121,
          "Shell" : 263950,
          "Awk" : 127345,
          "JavaScript" : 161607,
          "Mathematica" : 1118,
          "Objective-C" : 4269109,
          "Lua" : 12033,
          "PHP" : 64,
          "Limbo" : 303,
          "POV-Ray SDL" : 861,
          "Emacs Lisp" : 69003,
          "C++" : 488688394,
          "CSS" : 63859,
          "FIRRTL" : 4298018,
          "TeX" : 2141,
          "AppleScript" : 1429,
          "NASL" : 35217,
          "HIP" : 856703,
          "Julia" : 49676,
          "Dockerfile" : 23252,
          "Linker Script" : 903,
          "Roff" : 60700,
          "HLSL" : 1475332,
          "Mercury" : 14,
          "Vim Script" : 29186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add __builtin_stack_address to clang to increase compatibility to gcc.",
      "validationOrRequirement" : "The issue requires the implementation of __builtin_stack_address in clang to increase compatibility to gcc. The implementation should support different architectures, including riscv32-unknown-unknown.",
      "attemptedFixes" : "The issue has been attempted to be fixed by implementing the __builtin_stack_address using @llvm.sponentry or @llvm.read_register. There is also a patch that was submitted but it is still under review. The patch adds support for different architectures, including riscv32-unknown-unknown, but it only implements this for amd64/x86.",
      "otherNotes" : "The issue is about adding __builtin_stack_address to clang to increase compatibility to gcc. It would be good to also have this builtin in clang, it would on top increase compatibility to gcc. There are different ways to implement this, such as using @llvm.sponentry or @llvm.read_register. The issue is labeled as a good first issue, and the author is looking for someone to work on it. The issue has been assigned to different people and unassigned as well. There is also a patch that was submitted but it is still under review. The patch adds support for different architectures, including riscv32-unknown-unknown, but it only implements this for amd64/x86.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283178
  }, {
    "issueDTO" : {
      "id" : 3103767078,
      "title" : "Use sha2 implementation from datafusion-spark crate",
      "url" : "https://github.com/apache/datafusion-comet/issues/1820",
      "repositoryName" : "apache/datafusion-comet",
      "description" : "### What is the problem the feature request solves?\n\nThe `datafusion-spark` crate now provides a sha2 implementation (https://github.com/apache/datafusion/pull/16168), so we should be able to use that and remove the current implementation from Comet.\n\n### Describe the potential solution\n\nSee https://github.com/apache/datafusion-comet/pull/1711 for an example of using an expression from `datafusion-spark`.\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752262449.000000000,
      "user" : "andygrove",
      "userHtmlUrl" : "https://github.com/andygrove",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/934084?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@andygrove I can work on this.", "Thanks @rishvin. I assigned the issue to you. Let me know if you have any questions.", "Hi @andygrove, I tried the following approach and looks like there is some discrepancy in the Datafusion's `SparkSha2` output with Spark.\n\n**This is what I attempted**\n\nRemoved the existing ssh(224|256|384|512) and other related codes from [comet_scalar_funcs.rs](https://github.com/rishvin/datafusion-comet/blob/1b1d6185ede9175887de1e9ec7f48422c2a64a10/native/spark-expr/src/comet_scalar_funcs.rs#L120)\n\nRegistered the `SparkSha2` UDF [here](https://github.com/rishvin/datafusion-comet/blob/1b1d6185ede9175887de1e9ec7f48422c2a64a10/native/core/src/execution/planner.rs#L160).\n\nModified the serialization logic at Spark to roughly like so,\n```\ncase Sha2(left, numBits) =>\n    if (!numBits.foldable) {\n          withInfo(expr, \"non literal numBits is not supported\")\n          return None\n    }\n    val childExpr = exprToProtoInternal(left, inputs, binding)\n    val bitsExpr = exprToProtoInternal(numBits, inputs, binding)\n    scalarFunctionExprToProtoWithReturnType(\"sha2\", StringType, childExpr, bitsExpr)\n```\n\n\nWith these changes we hit the following exception - `Unsupported argument types for sha2 function`. \nThis is because the `SparkSha2` pattern matching supports `numBits` type to be UInt32 but we are sending type Int32 type from spark (Ref: [here](https://github.com/apache/datafusion/blob/1daa5ed5cc51546904d45e23cc148601d973942a/datafusion/spark/src/function/hash/sha2.rs#L141)). I checked the supported types for Spark which we define [here](https://github.com/rishvin/datafusion-comet/blob/1b1d6185ede9175887de1e9ec7f48422c2a64a10/spark/src/main/scala/org/apache/comet/serde/QueryPlanSerde.scala#L90), but looks like Spark doesn't support UInt32. \n\nTo test things further, I duplicated the `SparkSha2` into Comet and added Int32 into the pattern matching. This time the output response was successfully returned but the results did not match with the expected spark result. The hash returned by the `SparkSha2` is in uppercase, however, Spark returns SHA2 in lowercase. Here is an example of the two,\nComet returned - `2C83E9E8A39D60F7FCD3CFEC29C154260AA069F91CD40C972756F9354C64594E` \nSpark returned - `2c83e9e8a39d60f7fcd3cfec29c154260aa069f91cd40c972756f9354c64594e`.\n\nThis happened because the [hex_encode](https://github.com/apache/datafusion/blob/1daa5ed5cc51546904d45e23cc148601d973942a/datafusion/spark/src/function/math/hex.rs#L163) method used by the `SparkSha2` sets the lowercase=false (second parameter). However in the existing Comet implementation lowercase is set to true, [here](https://github.com/rishvin/datafusion-comet/blob/1b1d6185ede9175887de1e9ec7f48422c2a64a10/native/spark-expr/src/math_funcs/hex.rs#L56). Hence, we are getting the matching results from comet.\n\nTo make it work we might have to do following changes to the Datafusion's `SparkSha2`,\n- Add support for pattern matching Int32 type.\n- Add support to return hashes in lowercase.\n\nAlternatively, if are not suppose to make these change in Datafusion, we might have to create some wrappers over `SparkSha2` in Comet.\n\nLet me know your thoughts on this or I'm missing anything.", "Thanks for working on this @rishvin.\n\nYou are correct that Spark doesn't support UInt32 because it is JVM-based. JVM only has signed ints. The upper-case output seems to be a bug.\n\nI suggest filing a bug report in DataFusion, linking to this issue. Perhaps you would be interested in creating a PR in DataFusion to resolve these issues?\n\ncc @shehabgamin\n\n\n\n", "I should be able to resume working on this later this week. I might have to file another ticket to first upgrade the datafusion dependency before making Comet changes.", "@andygrove can I backport [SHA2-fix](https://github.com/apache/datafusion/pull/16350) to branch-48 of datafusion ? I tried updating with datafusion-main branch until my commit, however, looks like there are many changes in between and they are causing different test failures in Comet.", "> [@andygrove](https://github.com/andygrove) can I backport [SHA2-fix](https://github.com/apache/datafusion/pull/16350) to branch-48 of datafusion ? I tried updating with datafusion-main branch until my commit, however, looks like there are many changes in between and they are causing different test failures in Comet.\n\n\nLooks like the test-cases are failing in Comet after updating the Datafusion dependency with main-branch  due to this [commit](https://github.com/apache/datafusion/commit/0c3037404929fc3a3c4fbf6b9b7325d422ce10bd). This commit was revert in the branch-48 [here](https://github.com/apache/datafusion/commit/c76c1f076cca6f1922de8ba86b98c05b6a27e7ac), however it wasn't in the main branch. And the failures that I encountered were also related to Window functions tests,\n\nFor eg, I ran this: `./mvnw test -Dtest=None -Dsuites=\"org.apache.comet.exec.CometExecSuite Windows support\"`\nand it failed with subraction underflow,\n```\n Windows support *** FAILED *** (7 seconds, 210 milliseconds)\n  org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 17) (pop-os executor driver): org.apache.comet.CometNativeException: attempt to subtract with overflow\n        at comet::errors::init::{{closure}}(/home/rishabjoshi/Projects/datafusion-comet/native/core/src/errors.rs:151)\n        at <alloc::boxed::Box<F,A> as core::ops::function::Fn<Args>>::call(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/alloc/src/boxed.rs:2007)\n        at std::panicking::rust_panic_with_hook(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/panicking.rs:836)\n        at std::panicking::begin_panic_handler::{{closure}}(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/panicking.rs:694)\n        at std::sys::backtrace::__rust_end_short_backtrace(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/sys/backtrace.rs:168)\n        at rust_begin_unwind(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/panicking.rs:692)\n        at core::panicking::panic_fmt(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/core/src/panicking.rs:75)\n        at core::panicking::panic_const::panic_const_sub_overflow(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/core/src/panicking.rs:178)\n        at datafusion_expr::window_state::WindowAggState::update(/home/rishabjoshi/Projects/datafusion/datafusion/expr/src/window_state.rs:95)\n        at datafusion_physical_expr::window::window_expr::AggregateWindowExpr::aggregate_evaluate_stateful(/home/rishabjoshi/Projects/datafusion/datafusion/physical-expr/src/window/window_expr.rs:260)\n        at <datafusion_physical_expr::window::aggregate::PlainAggregateWindowExpr as datafusion_physical_expr::window::window_expr::WindowExpr>::evaluate_stateful(/home/rishabjoshi/Projects/datafusion/datafusion/physical-expr/src/window/aggregate.rs:148)\n        at datafusion_physical_plan::windows::bounded_window_agg_exec::BoundedWindowAggStream::compute_aggregates(/home/rishabjoshi/Projects/datafusion/datafusion/physical-plan/src/windows/bounded_window_agg_exec.rs:983)\n        at datafusion_physical_plan::windows::bounded_window_agg_exec::BoundedWindowAggStream::poll_next_inner(/home/rishabjoshi/Projects/datafusion/datafusion/physical-plan/src/windows/bounded_window_agg_exec.rs:1033)\n        at <datafusion_physical_plan::windows::bounded_window_agg_exec::BoundedWindowAggStream as futures_core::stream::Stream>::poll_next(/home/rishabjoshi/Projects/datafusion/datafusion/physical-plan/src/windows/bounded_window_agg_exec.rs:949)\n```\nAfter applying the revert I see the test case passing in main also.\n\n@andygrove would you prefer if I apply this revert in the main also? Looks like applying the revert in main is no longer clean because there were many conflicting patches in between now. However, if you prefer, rather than revert I might disable that pieces of code within some property/feature-flag that will be remain turned off. \nI can do this piece of work as part of this ticket itself.", "> > [@andygrove](https://github.com/andygrove) can I backport [SHA2-fix](https://github.com/apache/datafusion/pull/16350) to branch-48 of datafusion ? I tried updating with datafusion-main branch until my commit, however, looks like there are many changes in between and they are causing different test failures in Comet.\n> \n> Looks like the test-cases are failing in Comet after updating the Datafusion dependency with main-branch due to this [commit](https://github.com/apache/datafusion/commit/0c3037404929fc3a3c4fbf6b9b7325d422ce10bd). This commit was revert in the branch-48 [here](https://github.com/apache/datafusion/commit/c76c1f076cca6f1922de8ba86b98c05b6a27e7ac), however it wasn't in the main branch. And the failures that I encountered were also related to Window functions tests,\n> \n> For eg, I ran this: `./mvnw test -Dtest=None -Dsuites=\"org.apache.comet.exec.CometExecSuite Windows support\"` and it failed with subraction underflow,\n> \n> ```\n>  Windows support *** FAILED *** (7 seconds, 210 milliseconds)\n>   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 17) (pop-os executor driver): org.apache.comet.CometNativeException: attempt to subtract with overflow\n>         at comet::errors::init::{{closure}}(/home/rishabjoshi/Projects/datafusion-comet/native/core/src/errors.rs:151)\n>         at <alloc::boxed::Box<F,A> as core::ops::function::Fn<Args>>::call(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/alloc/src/boxed.rs:2007)\n>         at std::panicking::rust_panic_with_hook(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/panicking.rs:836)\n>         at std::panicking::begin_panic_handler::{{closure}}(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/panicking.rs:694)\n>         at std::sys::backtrace::__rust_end_short_backtrace(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/sys/backtrace.rs:168)\n>         at rust_begin_unwind(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/panicking.rs:692)\n>         at core::panicking::panic_fmt(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/core/src/panicking.rs:75)\n>         at core::panicking::panic_const::panic_const_sub_overflow(/rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/core/src/panicking.rs:178)\n>         at datafusion_expr::window_state::WindowAggState::update(/home/rishabjoshi/Projects/datafusion/datafusion/expr/src/window_state.rs:95)\n>         at datafusion_physical_expr::window::window_expr::AggregateWindowExpr::aggregate_evaluate_stateful(/home/rishabjoshi/Projects/datafusion/datafusion/physical-expr/src/window/window_expr.rs:260)\n>         at <datafusion_physical_expr::window::aggregate::PlainAggregateWindowExpr as datafusion_physical_expr::window::window_expr::WindowExpr>::evaluate_stateful(/home/rishabjoshi/Projects/datafusion/datafusion/physical-expr/src/window/aggregate.rs:148)\n>         at datafusion_physical_plan::windows::bounded_window_agg_exec::BoundedWindowAggStream::compute_aggregates(/home/rishabjoshi/Projects/datafusion/datafusion/physical-plan/src/windows/bounded_window_agg_exec.rs:983)\n>         at datafusion_physical_plan::windows::bounded_window_agg_exec::BoundedWindowAggStream::poll_next_inner(/home/rishabjoshi/Projects/datafusion/datafusion/physical-plan/src/windows/bounded_window_agg_exec.rs:1033)\n>         at <datafusion_physical_plan::windows::bounded_window_agg_exec::BoundedWindowAggStream as futures_core::stream::Stream>::poll_next(/home/rishabjoshi/Projects/datafusion/datafusion/physical-plan/src/windows/bounded_window_agg_exec.rs:949)\n> ```\n> \n> After applying the revert I see the test case passing in main also.\n> \n> [@andygrove](https://github.com/andygrove) would you prefer if I apply this revert in the main also? Looks like applying the revert in main is no longer clean because there were many conflicting patches in between now. However, if you prefer, rather than revert I might disable that pieces of code within some property/feature-flag that will be remain turned off. I can do this piece of work as part of this ticket itself.\n\nOk, this issue is fixed here: https://github.com/apache/datafusion/pull/16430 ", "> [@andygrove](https://github.com/andygrove) can I backport [SHA2-fix](https://github.com/apache/datafusion/pull/16350) to branch-48 of datafusion ? I tried updating with datafusion-main branch until my commit, however, looks like there are many changes in between and they are causing different test failures in Comet.\n\nWe plan on releasing Comet 0.9.0 in the next few days, hopefully, and then we can have Comet main branch start using a pinned dependency on DataFusion and start making updated for the changes that have happened in DF since 48 was released.", "Should be able to open Comet's PR after https://github.com/apache/datafusion-comet/issues/1993 is closed." ],
      "repository" : {
        "description" : "Apache DataFusion Comet Spark Accelerator",
        "homepage" : "https://datafusion.apache.org/comet",
        "name" : "datafusion-comet",
        "fullName" : "apache/datafusion-comet",
        "htmlUrl" : "https://github.com/apache/datafusion-comet",
        "gitUrl" : "git://github.com/apache/datafusion-comet.git",
        "sshUrl" : "git@github.com:apache/datafusion-comet.git",
        "cloneUrl" : "https://github.com/apache/datafusion-comet.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 222,
        "stargazersCount" : 989,
        "watchersCount" : 989,
        "size" : 19074,
        "openIssuesCount" : 249,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-11T21:47:57Z",
        "languages" : {
          "Java" : 477078,
          "Dockerfile" : 6894,
          "Shell" : 29303,
          "Rust" : 1894706,
          "Scala" : 1652880,
          "Makefile" : 5518,
          "Python" : 8374
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to use the sha2 implementation from datafusion-spark crate in Comet and remove the current implementation from Comet.",
      "validationOrRequirement" : "The issue requires the sha2 implementation from datafusion-spark crate to be used in Comet. The author needs to backport a fix from DataFusion to branch-48.",
      "attemptedFixes" : "The author tried to use an expression from datafusion-spark but encountered some discrepancies in the output. The author also tried to duplicate the SparkSha2 into Comet and add Int32 into the pattern matching. However, this attempt was unsuccessful. The author also tried to file a bug report in DataFusion and create a PR to resolve the issues.",
      "otherNotes" : "The issue aims to use the sha2 implementation from datafusion-spark crate and remove the current implementation from Comet. The author tried to use an expression from datafusion-spark but encountered some discrepancies in the output. The issue also involves backporting a fix from DataFusion to branch-48. There are some test failures in Comet after updating the Datafusion dependency with main-branch due to a commit that was reverted in branch-48. The issue is fixed in https://github.com/apache/datafusion/pull/16430.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283187
  }, {
    "issueDTO" : {
      "id" : 2582785065,
      "title" : "Dependency Dashboard",
      "url" : "https://github.com/tuono-labs/tuono/issues/34",
      "repositoryName" : "tuono-labs/tuono",
      "description" : "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/tuono-labs/tuono).\n\n## Rate-Limited\n\nThese updates are currently rate-limited. Click on a checkbox below to force their creation now.\n\n - [ ] <!-- unlimit-branch=renovate/playwright-monorepo -->chore(deps): update dependency @playwright/test to v1.54.1\n - [ ] <!-- unlimit-branch=renovate/vitest-eslint-plugin-1.x -->chore(deps): update dependency @vitest/eslint-plugin to v1.3.4\n - [ ] <!-- unlimit-branch=renovate/oxlint-monorepo -->chore(deps): update dependency oxc-transform to v0.76.0\n - [ ] <!-- unlimit-branch=renovate/prettier-3.x -->chore(deps): update dependency prettier to v3.6.2\n - [ ] <!-- unlimit-branch=renovate/unplugin-isolated-decl-0.x -->chore(deps): update dependency unplugin-isolated-decl to v0.14.5\n - [ ] <!-- unlimit-branch=renovate/vite-6.x -->chore(deps): update dependency vite to v6.3.5\n - [ ] <!-- unlimit-branch=renovate/vitest-monorepo -->chore(deps): update dependency vitest to v3.2.4\n - [ ] <!-- unlimit-branch=renovate/devdependencies-(eslint) -->chore(deps): update devdependencies (eslint) (`@eslint/js`, `eslint`, `eslint-import-resolver-typescript`, `eslint-plugin-import`, `typescript-eslint`)\n - [ ] <!-- unlimit-branch=renovate/node-22.x -->chore(deps): update node.js to v22.17.0 (`node`, `@types/node`)\n - [ ] <!-- unlimit-branch=renovate/pnpm-10.x -->chore(deps): update pnpm to v10.13.1\n - [ ] <!-- unlimit-branch=renovate/rust-1.x -->chore(deps): update rust docker tag to v1.88\n - [ ] <!-- unlimit-branch=renovate/babel-monorepo -->fix(deps): update babel monorepo (`@babel/core`, `@babel/plugin-syntax-jsx`, `@babel/plugin-syntax-typescript`, `@babel/types`)\n - [ ] <!-- unlimit-branch=renovate/vitejs-plugin-react-swc-3.x-lockfile -->fix(deps): update dependency @vitejs/plugin-react-swc to v3.10.2\n - [ ] <!-- unlimit-branch=renovate/prettier-3.x-lockfile -->fix(deps): update dependency prettier to v3.6.2\n - [ ] <!-- unlimit-branch=renovate/vite-6.x-lockfile -->fix(deps): update dependency vite to v6.3.5\n - [ ] <!-- unlimit-branch=renovate/console-0.x -->fix(deps): update rust crate console to 0.16.0\n - [ ] <!-- unlimit-branch=renovate/tokio-tungstenite-0.x -->fix(deps): update rust crate tokio-tungstenite to 0.27.0\n - [ ] <!-- unlimit-branch=renovate/tungstenite-0.x -->fix(deps): update rust crate tungstenite to 0.27.0\n - [ ] <!-- unlimit-branch=renovate/major-happy-dom-monorepo -->chore(deps): update dependency happy-dom to v18\n - [ ] <!-- unlimit-branch=renovate/vite-7.x -->fix(deps): update dependency vite to v7\n - [ ] <!-- unlimit-branch=renovate/colored-3.x -->fix(deps): update rust crate colored to v3\n - [ ] <!-- unlimit-branch=renovate/watchexec-8.x -->fix(deps): update rust crate watchexec to v8\n - [ ] <!-- unlimit-branch=renovate/watchexec-events-6.x -->fix(deps): update rust crate watchexec-events to v6\n - [ ] <!-- unlimit-branch=renovate/watchexec-signals-5.x -->fix(deps): update rust crate watchexec-signals to v5\n - [ ] <!-- unlimit-branch=renovate/watchexec-supervisor-5.x -->fix(deps): update rust crate watchexec-supervisor to v5\n - [ ] <!-- create-all-rate-limited-prs -->\uD83D\uDD10 **Create all rate-limited PRs at once** \uD83D\uDD10\n\n## Open\n\nThese updates have all been created already. Click a checkbox below to force a retry/rebase of any.\n\n - [ ] <!-- rebase-branch=renovate/vitejs-plugin-react-swc-3.x -->[chore(deps): update dependency @vitejs/plugin-react-swc to v3.10.2](../pull/797)\n - [ ] <!-- rebase-branch=renovate/happy-dom-monorepo -->[chore(deps): update dependency happy-dom to v17.6.3](../pull/792)\n - [ ] <!-- rebase-branch=renovate/react-monorepo -->[chore(deps): update react monorepo](../pull/794) (`@types/react`, `@types/react-dom`)\n - [ ] <!-- rebase-branch=renovate/typescript-5.x-lockfile -->[chore(deps): update dependency typescript to v5.8.3](../pull/795)\n - [ ] <!-- rebase-branch=renovate/typescript-5.x -->[chore(deps): update dependency typescript to v5.8.3](../pull/796)\n - [ ] <!-- rebase-all-open-prs -->**Click on this checkbox to rebase all open PRs at once**\n\n## Ignored or Blocked\n\nThese are blocked by an existing closed PR and will not be recreated unless you click a checkbox below.\n\n - [ ] <!-- recreate-branch=renovate/web-streams-polyfill-4.x-lockfile -->[fix(deps): update dependency web-streams-polyfill to v4.1.0](../pull/322)\n\n## Detected dependencies\n\n<details><summary>cargo</summary>\n<blockquote>\n\n<details><summary>crates/tuono/Cargo.toml</summary>\n\n - `clap 4.5.4`\n - `syn 2.0.100`\n - `tracing 0.1.41`\n - `tracing-subscriber 0.3.19`\n - `miette 7.2.0`\n - `colored 2.1.0`\n - `once_cell 1.19.0`\n - `watchexec 5.0.0`\n - `watchexec-signals 4.0.0`\n - `watchexec-events 4.0.0`\n - `watchexec-supervisor 3.0.0`\n - `tokio 1`\n - `serde 1.0.202`\n - `glob 0.3.1`\n - `regex 1.10.4`\n - `reqwest 0.12.4`\n - `serde_json 1.0`\n - `fs_extra 1.3.0`\n - `http 1.1.0`\n - `spinners 4.1.1`\n - `console 0.15.10`\n - `convert_case 0.8.0`\n - `wiremock 0.6.2`\n - `tempfile 3.14.0`\n - `assert_cmd 2.0.16`\n - `serial_test 3.0.0`\n\n</details>\n\n<details><summary>crates/tuono_internal/Cargo.toml</summary>\n\n - `serde 1.0`\n - `serde_json 1.0.137`\n - `fs_extra 1.3.0`\n - `tempfile 3.14.0`\n - `assert_cmd 2.0.16`\n - `serial_test 3.0.0`\n\n</details>\n\n<details><summary>crates/tuono_lib/Cargo.toml</summary>\n\n - `ssr_rs 0.8.3`\n - `axum 0.8.1`\n - `axum-extra 0.10.0`\n - `tokio 1.37.0`\n - `serde 1.0.202`\n - `erased-serde 0.4.5`\n - `serde_json 1.0`\n - `serde_urlencoded 0.7.1`\n - `reqwest 0.12.4`\n - `once_cell 1.19.0`\n - `regex 1.10.5`\n - `either 1.13.0`\n - `tower-http 0.6.0`\n - `colored 3.0.0`\n - `tokio-tungstenite 0.26.0`\n - `futures-util 0.3`\n - `tungstenite 0.26.0`\n - `http 1.1.0`\n - `pin-project 1.1.7`\n - `tower 0.5.1`\n - `fs_extra 1.3.0`\n - `tempfile 3.14.0`\n - `serial_test 3.0.0`\n\n</details>\n\n<details><summary>crates/tuono_lib_macros/Cargo.toml</summary>\n\n - `syn 2.0.0`\n - `quote 1.0`\n\n</details>\n\n<details><summary>e2e/fixtures/base/Cargo.toml</summary>\n\n - `serde 1.0.202`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>docker-compose</summary>\n<blockquote>\n\n<details><summary>docker/compose.yml</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>dockerfile</summary>\n<blockquote>\n\n<details><summary>docker/Dockerfile</summary>\n\n - `rust 1.83-bookworm`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>github-actions</summary>\n<blockquote>\n\n<details><summary>.github/actions/install-node-dependencies/action.yml</summary>\n\n - `pnpm/action-setup v4`\n - `actions/setup-node v4`\n - `actions/setup-node v4`\n\n</details>\n\n<details><summary>.github/workflows/docker-ci.yml</summary>\n\n - `actions/checkout v4`\n\n</details>\n\n<details><summary>.github/workflows/e2e-ci.yml</summary>\n\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n\n</details>\n\n<details><summary>.github/workflows/examples-ci.yml</summary>\n\n - `actions/checkout v4`\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n\n</details>\n\n<details><summary>.github/workflows/pr-labeler.yml</summary>\n\n - `actions/checkout v4`\n - `actions/labeler v5`\n\n</details>\n\n<details><summary>.github/workflows/pr-title-checker.yml</summary>\n\n\n</details>\n\n<details><summary>.github/workflows/release.yml</summary>\n\n - `actions/checkout v4`\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n - `katyo/publish-crates v2`\n - `actions/checkout v4`\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n - `katyo/publish-crates v2`\n\n</details>\n\n<details><summary>.github/workflows/repo-root-ci.yml</summary>\n\n - `actions/checkout v4`\n\n</details>\n\n<details><summary>.github/workflows/rust-ci.yml</summary>\n\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n\n</details>\n\n<details><summary>.github/workflows/spell-checking.yml</summary>\n\n - `actions/checkout v4`\n - `reviewdog/action-languagetool v1`\n\n</details>\n\n<details><summary>.github/workflows/typescript-ci.yml</summary>\n\n - `actions/checkout v4`\n - `actions/checkout v4`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>npm</summary>\n<blockquote>\n\n<details><summary>devtools/vite-config/package.json</summary>\n\n - `oxc-transform 0.72.2`\n - `rollup-plugin-preserve-directives 0.4.0`\n - `unplugin-isolated-decl 0.13.6`\n - `vite 6.1.3`\n - `vite-plugin-externalize-deps 0.9.0`\n\n</details>\n\n<details><summary>e2e/fixtures/base/package.json</summary>\n\n - `react ^19.0.0`\n - `react-dom ^19.0.0`\n - `@types/react ^19.0.2`\n - `@types/react-dom ^19.0.2`\n - `typescript ^5.6.3`\n\n</details>\n\n<details><summary>package.json</summary>\n\n - `@eslint/js 9.24.0`\n - `@playwright/test 1.52.0`\n - `@types/node 22.14.1`\n - `@vitest/eslint-plugin 1.2.1`\n - `eslint 9.24.0`\n - `eslint-import-resolver-typescript 4.3.2`\n - `eslint-plugin-import 2.31.0`\n - `eslint-plugin-react 7.37.5`\n - `eslint-plugin-react-hooks 5.2.0`\n - `prettier 3.5.3`\n - `turbo 2.5.4`\n - `typescript 5.7.3`\n - `typescript-eslint 8.29.1`\n - `pnpm 10.7.1+sha512.2d92c86b7928dc8284f53494fb4201f983da65f0fb4f0d40baafa5cf628fa31dae3e5968f12466f17df7e97310e30f343a648baea1b9b350685dafafffdf5808`\n\n</details>\n\n<details><summary>packages/tuono-react-vite-plugin/package.json</summary>\n\n - `@babel/core ^7.24.4`\n - `@babel/types ^7.24.0`\n - `prettier ^3.2.4`\n - `vite ^6.1.1`\n - `@types/babel__core 7.20.5`\n - `vitest 3.1.4`\n\n</details>\n\n<details><summary>packages/tuono-router/package.json</summary>\n\n - `react-intersection-observer ^9.13.0`\n - `@testing-library/react 16.3.0`\n - `@types/react 19.1.3`\n - `@vitejs/plugin-react-swc 3.10.1`\n - `happy-dom 17.6.1`\n - `react 19.1.0`\n - `vite 6.1.3`\n - `vitest 3.1.4`\n - `react >=19.0.0`\n\n</details>\n\n<details><summary>packages/tuono/package.json</summary>\n\n - `@babel/core ^7.24.4`\n - `@babel/plugin-syntax-jsx ^7.24.1`\n - `@babel/plugin-syntax-typescript ^7.24.1`\n - `@rollup/plugin-inject ^5.0.5`\n - `@vitejs/plugin-react-swc ^3.8.0`\n - `fast-text-encoding ^1.0.6`\n - `url-search-params-polyfill ^8.2.5`\n - `vite ^6.1.1`\n - `web-streams-polyfill ^4.0.0`\n - `@types/babel__core 7.20.5`\n - `@types/babel__traverse 7.20.7`\n - `@types/node 22.14.1`\n - `@types/react 19.1.3`\n - `@types/react-dom 19.1.3`\n - `react 19.1.0`\n - `react-dom 19.1.0`\n - `vitest 3.1.4`\n - `react >=19.0.0`\n - `react-dom >=19.0.0`\n\n</details>\n\n<details><summary>pnpm-workspace.yaml</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>nvm</summary>\n<blockquote>\n\n<details><summary>.nvmrc</summary>\n\n - `node 22.14.0`\n\n</details>\n\n</blockquote>\n</details>\n\n---\n\n- [ ] <!-- manual job -->Check this box to trigger a request for Renovate to run again on this repository\n\n",
      "updatedAt" : 1752262372.000000000,
      "user" : "renovate[bot]",
      "userHtmlUrl" : "https://github.com/apps/renovate",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/2740?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "??? Modern fullstack web framework based on Rust and React",
        "homepage" : "https://tuono.dev",
        "name" : "tuono",
        "fullName" : "tuono-labs/tuono",
        "htmlUrl" : "https://github.com/tuono-labs/tuono",
        "gitUrl" : "git://github.com/tuono-labs/tuono.git",
        "sshUrl" : "git@github.com:tuono-labs/tuono.git",
        "cloneUrl" : "https://github.com/tuono-labs/tuono.git",
        "owner" : {
          "login" : "tuono-labs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 47,
        "stargazersCount" : 872,
        "watchersCount" : 872,
        "size" : 2985,
        "openIssuesCount" : 36,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-07T03:00:19Z",
        "languages" : {
          "TypeScript" : 132475,
          "Dockerfile" : 1436,
          "Rust" : 200006
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to update dependencies and create pull requests.",
      "validationOrRequirement" : "The issue does not have any specific validations or requirements mentioned.",
      "attemptedFixes" : "The issue does not have any attempted fixes or blockers mentioned.",
      "otherNotes" : "The issue lists Renovate updates and detected dependencies. There are rate-limited updates, open updates, and ignored or blocked updates. The dependencies include cargo, docker-compose, dockerfile, github-actions, npm, and nvm.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283191
  }, {
    "issueDTO" : {
      "id" : 3223371810,
      "title" : "[Handbook] Code of Conduct page content lacks proper section title",
      "url" : "https://github.com/layer5io/layer5/issues/6627",
      "repositoryName" : "layer5io/layer5",
      "description" : "### Description\n<!-- A brief description with a link to the page on the site where you found the issue. -->\nThe content should have a proper section title/heading similar to other handbook pages (e.g., \"About Layer5\" on the About page).\n\n**Comparison**\nOther pages in the handbook follow a consistent pattern:\n- **About page:** Has \"About Layer5\" as a section title\n- **Code of Conduct page:** Missing section title (starts with body text)\n\n**Location**\n- **Page:** Community Handbook - Code of Conduct\n- **URL:** `/community/handbook/code-of-conduct`\n- **Component:** Main content area\n\n\n### Screenshots\n<!-- Add screenshots, if applicable, to help explain your problem. -->\n\n<img width=\"1562\" height=\"780\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ed825432-6f0f-4d18-b44c-9232831023e3\" />\n\n### Environment:\n- Host OS:\n- Browser:\n\n---\n<img src=\"https://raw.githubusercontent.com/layer5io/layer5/master/.github/assets/images/layer5/5-light-small.svg\" width=\"24px\" align=\"left\" /><h2>Contributor Resources and <a href=\"https://layer5.io/community/handbook\">Handbook</a></h2>\n\nThe layer5.io website uses Gatsby, React, and GitHub Pages. Site content is found under the [`master` branch](https://github.com/layer5io/layer5/tree/master).\n- \uD83D\uDCDA See [contributing instructions](https://github.com/layer5io/layer5/blob/master/CONTRIBUTING.md).\n- \uD83C\uDFA8 Wireframes and [designs for Layer5 site](https://www.figma.com/file/5ZwEkSJwUPitURD59YHMEN/Layer5-Designs) in Figma [(open invite)](https://www.figma.com/team_invite/redeem/qJy1c95qirjgWQODApilR9)\n- \uD83D\uDE4B\uD83C\uDFFE\uD83D\uDE4B\uD83C\uDFFC Questions: [Discussion Forum](https://discuss.layer5.io) and [Community Slack](https://slack.layer5.io).\n\n<img src=\"https://raw.githubusercontent.com/layer5io/layer5/master/.github/assets/images/buttons/community.webp\" height=\"22px\" align=\"left\" />Join the Layer5 Community by submitting your [community member form](https://layer5.io/newcomer).\n",
      "updatedAt" : 1752262228.000000000,
      "user" : "Vincamine",
      "userHtmlUrl" : "https://github.com/Vincamine",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/149436095?v=4",
      "labels" : [ "kind/bug", "framework/gatsby", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@Vincamine Can i work on this issue ??", "Mind finishing your other pr @Ayushmore1214 then you can jump to this issue:)", "Hi! I'd like to contribute. It will be my first contribution on GitHub, so it might take me the weekend to finish. Would that be a problem?\n\nI noticed there's a missing h2 on src/sections/Community/Handbook/conduct.js, it should be reasonably simply to implement." ],
      "repository" : {
        "description" : "Layer5, expect more from your infrastructure",
        "homepage" : "https://layer5.io",
        "name" : "layer5",
        "fullName" : "layer5io/layer5",
        "htmlUrl" : "https://github.com/layer5io/layer5",
        "gitUrl" : "git://github.com/layer5io/layer5.git",
        "sshUrl" : "git@github.com:layer5io/layer5.git",
        "cloneUrl" : "https://github.com/layer5io/layer5.git",
        "owner" : {
          "login" : "layer5io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1357,
        "stargazersCount" : 932,
        "watchersCount" : 932,
        "size" : 11567452,
        "openIssuesCount" : 145,
        "subscribersCount" : 24,
        "pushedAt" : "2025-07-11T17:45:40Z",
        "languages" : {
          "MDX" : 3508972,
          "Dockerfile" : 679,
          "CSS" : 19435,
          "Shell" : 167,
          "Makefile" : 1647,
          "JavaScript" : 13709104,
          "HTML" : 345971
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a proper section title/heading to the Code of Conduct page in the Community Handbook.",
      "validationOrRequirement" : "The requirement is to have a proper section title/heading similar to other handbook pages.",
      "attemptedFixes" : "No specific attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The issue is about missing section title/heading on the Code of Conduct page in the Community Handbook, and it should be similar to other handbook pages.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283195
  }, {
    "issueDTO" : {
      "id" : 3214238264,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/beeware/issues/539",
      "repositoryName" : "beeware/beeware",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752261744.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A meta-package simplifying the installation of the BeeWare suite of tools",
        "homepage" : "https://docs.beeware.org",
        "name" : "beeware",
        "fullName" : "beeware/beeware",
        "htmlUrl" : "https://github.com/beeware/beeware",
        "gitUrl" : "git://github.com/beeware/beeware.git",
        "sshUrl" : "git@github.com:beeware/beeware.git",
        "cloneUrl" : "https://github.com/beeware/beeware.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 174,
        "stargazersCount" : 921,
        "watchersCount" : 921,
        "size" : 13291,
        "openIssuesCount" : 6,
        "subscribersCount" : 27,
        "pushedAt" : "2025-07-08T19:04:56Z",
        "languages" : { },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown.",
      "validationOrRequirement" : "Verify that the two files (README.rst and README.md) are rendering the same after conversion.",
      "attemptedFixes" : "None mentioned in the description.",
      "otherNotes" : "The README file for the beeware/beeware repository is currently formatted using reStructuredText. Pandoc installation instructions can be found at https://pandoc.org/installing.html. The conversion command is pandoc -s README.rst -t gfm -o README.md.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283199
  }, {
    "issueDTO" : {
      "id" : 3214240555,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/Python-Apple-support/issues/304",
      "repositoryName" : "beeware/Python-Apple-support",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752261737.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A meta-package for building a version of Python that can be embedded into a macOS, iOS, tvOS or watchOS project.",
        "homepage" : "",
        "name" : "Python-Apple-support",
        "fullName" : "beeware/Python-Apple-support",
        "htmlUrl" : "https://github.com/beeware/Python-Apple-support",
        "gitUrl" : "git://github.com/beeware/Python-Apple-support.git",
        "sshUrl" : "git@github.com:beeware/Python-Apple-support.git",
        "cloneUrl" : "https://github.com/beeware/Python-Apple-support.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 184,
        "stargazersCount" : 1230,
        "watchersCount" : 1230,
        "size" : 7136,
        "openIssuesCount" : 7,
        "subscribersCount" : 36,
        "pushedAt" : "2025-07-08T18:15:18Z",
        "languages" : {
          "Shell" : 1049,
          "Makefile" : 35437,
          "Python" : 9431
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README file from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "Verify that the two files are rendering the same, especially around headers and code syntax, and ensure the title is formatted as '# Title'.",
      "attemptedFixes" : "None",
      "otherNotes" : "The README file is currently formatted using reStructuredText, and the goal is to convert it to GitHub-flavored Markdown. Pandoc installation instructions are available, and the conversion command is provided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283203
  }, {
    "issueDTO" : {
      "id" : 3214244023,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/briefcase/issues/2378",
      "repositoryName" : "beeware/briefcase",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.\n",
      "updatedAt" : 1752261716.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Tools to support converting a Python project into a standalone native application.",
        "homepage" : "https://briefcase.readthedocs.io/",
        "name" : "briefcase",
        "fullName" : "beeware/briefcase",
        "htmlUrl" : "https://github.com/beeware/briefcase",
        "gitUrl" : "git://github.com/beeware/briefcase.git",
        "sshUrl" : "git@github.com:beeware/briefcase.git",
        "cloneUrl" : "https://github.com/beeware/briefcase.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 424,
        "stargazersCount" : 2978,
        "watchersCount" : 2978,
        "size" : 12676,
        "openIssuesCount" : 181,
        "subscribersCount" : 48,
        "pushedAt" : "2025-07-12T00:58:14Z",
        "languages" : {
          "Python" : 3066398
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "Verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax. Delete the README.rst file before submitting a PR.",
      "attemptedFixes" : "None",
      "otherNotes" : "One possible conversion option is pandoc. Pandoc installation instructions can be found here. To use pandoc to convert the README.rst file from rST to GitHub-flavored Markdown, run the following command from the same directory as the README.rst file: pandoc -s README.rst -t gfm -o README.md. This command may result in an incorrect formatting of the title; the title should be formatted as # Title. Ensure you are verifying that the results you are getting are what you expect.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283208
  }, {
    "issueDTO" : {
      "id" : 3214249764,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/toga-chart/issues/246",
      "repositoryName" : "beeware/toga-chart",
      "description" : "### What is the problem or limitation you are having?\n\nThe README files for this repository is currently formatted using reStructuredText.\n\nThere is the main `README.rst`, as well as the second `examples/README.rst`.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752261707.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A matplotlib charting widget for Toga.",
        "homepage" : "",
        "name" : "toga-chart",
        "fullName" : "beeware/toga-chart",
        "htmlUrl" : "https://github.com/beeware/toga-chart",
        "gitUrl" : "git://github.com/beeware/toga-chart.git",
        "sshUrl" : "git@github.com:beeware/toga-chart.git",
        "cloneUrl" : "https://github.com/beeware/toga-chart.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15,
        "stargazersCount" : 29,
        "watchersCount" : 29,
        "size" : 564,
        "openIssuesCount" : 7,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-10T02:55:30Z",
        "languages" : {
          "Python" : 9027
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert README.rst from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "The README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. Once conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.",
      "attemptedFixes" : "Delete the README.rst file before submitting a PR.",
      "otherNotes" : "One possible conversion option is pandoc. Pandoc installation instructions can be found here. To use pandoc to convert the README.rst file from rST to GitHub-flavored Markdown, run the following command from the same directory as the README.rst file: pandoc -s README.rst -t gfm -o README.md. This command may result in an incorrect formatting of the title; the title should be formatted as # Title. Ensure you are verifying that the results you are getting are what you expect.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283215
  }, {
    "issueDTO" : {
      "id" : 3214252301,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/rubicon-objc/issues/609",
      "repositoryName" : "beeware/rubicon-objc",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752261699.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A bridge interface between Python and Objective-C.",
        "homepage" : "https://rubicon-objc.readthedocs.io",
        "name" : "rubicon-objc",
        "fullName" : "beeware/rubicon-objc",
        "htmlUrl" : "https://github.com/beeware/rubicon-objc",
        "gitUrl" : "git://github.com/beeware/rubicon-objc.git",
        "sshUrl" : "git@github.com:beeware/rubicon-objc.git",
        "cloneUrl" : "https://github.com/beeware/rubicon-objc.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 57,
        "stargazersCount" : 276,
        "watchersCount" : 276,
        "size" : 2471,
        "openIssuesCount" : 25,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-09T04:14:13Z",
        "languages" : {
          "Makefile" : 593,
          "Objective-C" : 15538,
          "Python" : 368498
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README file from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "The README should be converted to GitHub-flavored Markdown from rST, and the two files should render the same, with cleanup around headers and code syntax.",
      "attemptedFixes" : "None mentioned in the description.",
      "otherNotes" : "The README file is currently formatted using reStructuredText and should be converted to GitHub-flavored Markdown using multiple methods such as pandoc. Verification of the two files is required, especially around headers and code syntax, and the README.rst file should be deleted before submitting a PR.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283219
  }, {
    "issueDTO" : {
      "id" : 3214256158,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/colosseum/issues/141",
      "repositoryName" : "beeware/colosseum",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\nThere is the primary `README.rst`, as well as a second at `utils/README.rst`.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.\n",
      "updatedAt" : 1752261691.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An implementation of the CSS layout algorithm.",
        "homepage" : "",
        "name" : "colosseum",
        "fullName" : "beeware/colosseum",
        "htmlUrl" : "https://github.com/beeware/colosseum",
        "gitUrl" : "git://github.com/beeware/colosseum.git",
        "sshUrl" : "git@github.com:beeware/colosseum.git",
        "cloneUrl" : "https://github.com/beeware/colosseum.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 137,
        "stargazersCount" : 130,
        "watchersCount" : 130,
        "size" : 10452,
        "openIssuesCount" : 13,
        "subscribersCount" : 16,
        "pushedAt" : "2025-06-29T20:58:47Z",
        "languages" : {
          "Shell" : 4469,
          "JavaScript" : 21588,
          "Python" : 449272
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown, and verify the formatting of the title",
      "validationOrRequirement" : "Verify that the two files (README.rst and README.md) are rendering the same after conversion, and delete the README.rst file before submitting a PR.",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "Conversion method options include pandoc, and the command to use is pandoc -s README.rst -t gfm -o README.md. Also, note that the title formatting may need to be adjusted to # Title.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283223
  }, {
    "issueDTO" : {
      "id" : 3214257909,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/briefcase-macOS-Xcode-template/issues/84",
      "repositoryName" : "beeware/briefcase-macOS-Xcode-template",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.\n",
      "updatedAt" : 1752261683.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A template for generating an Xcode project for a macOS app using Briefcase",
        "homepage" : null,
        "name" : "briefcase-macOS-Xcode-template",
        "fullName" : "beeware/briefcase-macOS-Xcode-template",
        "htmlUrl" : "https://github.com/beeware/briefcase-macOS-Xcode-template",
        "gitUrl" : "git://github.com/beeware/briefcase-macOS-Xcode-template.git",
        "sshUrl" : "git@github.com:beeware/briefcase-macOS-Xcode-template.git",
        "cloneUrl" : "https://github.com/beeware/briefcase-macOS-Xcode-template.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 17,
        "watchersCount" : 17,
        "size" : 874,
        "openIssuesCount" : 4,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-10T07:03:57Z",
        "languages" : {
          "Shell" : 410,
          "Objective-C" : 21054,
          "HTML" : 379
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert README.rst from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "Verify that the two files are rendering the same, especially around headers and code syntax, and delete the README.rst file before submitting a PR.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The README file is currently in reStructuredText and needs to be converted to GitHub-flavored Markdown. Pandoc installation instructions can be found here: https://pandoc.org/installing.html. The conversion command is: pandoc -s README.rst -t gfm -o README.md. Verification of the two files rendering the same is required, especially around headers and code syntax.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283228
  }, {
    "issueDTO" : {
      "id" : 3214262933,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/mobile-forge/issues/103",
      "repositoryName" : "beeware/mobile-forge",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.\n",
      "updatedAt" : 1752261666.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A tool to manage building cross-platform binary wheels for mobile devices",
        "homepage" : null,
        "name" : "mobile-forge",
        "fullName" : "beeware/mobile-forge",
        "htmlUrl" : "https://github.com/beeware/mobile-forge",
        "gitUrl" : "git://github.com/beeware/mobile-forge.git",
        "sshUrl" : "git@github.com:beeware/mobile-forge.git",
        "cloneUrl" : "https://github.com/beeware/mobile-forge.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 21,
        "stargazersCount" : 36,
        "watchersCount" : 36,
        "size" : 474,
        "openIssuesCount" : 11,
        "subscribersCount" : 7,
        "pushedAt" : "2025-06-23T00:11:20Z",
        "languages" : {
          "Shell" : 9115,
          "Python" : 63480
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README file from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "Verify that the two files (README.rst and README.md) are rendering the same after conversion",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "The README file is currently formatted using reStructuredText and needs to be converted to GitHub-flavored Markdown using multiple methods, with pandoc being one option. The conversion may require cleanup, especially around headers and code syntax. The title may need to be formatted as # Title.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283232
  }, {
    "issueDTO" : {
      "id" : 3214266998,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/briefcase-template/issues/199",
      "repositoryName" : "beeware/briefcase-template",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\nThere is a `README.rst` in the cookiecutter template directory; this can also be converted, but should be done manually.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.\n",
      "updatedAt" : 1752261659.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A cookiecutter template for a starter Briefcase project.",
        "homepage" : "",
        "name" : "briefcase-template",
        "fullName" : "beeware/briefcase-template",
        "htmlUrl" : "https://github.com/beeware/briefcase-template",
        "gitUrl" : "git://github.com/beeware/briefcase-template.git",
        "sshUrl" : "git@github.com:beeware/briefcase-template.git",
        "cloneUrl" : "https://github.com/beeware/briefcase-template.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 48,
        "stargazersCount" : 49,
        "watchersCount" : 49,
        "size" : 1011,
        "openIssuesCount" : 2,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-10T07:03:59Z",
        "languages" : {
          "Python" : 14154
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "Conversion to GitHub-flavored Markdown, manual deletion of README.rst file before PR submission, verification of file rendering",
      "attemptedFixes" : "None",
      "otherNotes" : "Conversion from reStructuredText to GitHub-flavored Markdown, manual conversion of README.rst, cleanup around headers and code syntax, pandoc installation instructions provided, verification of file rendering",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283235
  }, {
    "issueDTO" : {
      "id" : 3214270967,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/briefcase-macOS-app-template/issues/83",
      "repositoryName" : "beeware/briefcase-macOS-app-template",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752261643.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A template for generating macOS app projects with Briefcase",
        "homepage" : "",
        "name" : "briefcase-macOS-app-template",
        "fullName" : "beeware/briefcase-macOS-app-template",
        "htmlUrl" : "https://github.com/beeware/briefcase-macOS-app-template",
        "gitUrl" : "git://github.com/beeware/briefcase-macOS-app-template.git",
        "sshUrl" : "git@github.com:beeware/briefcase-macOS-app-template.git",
        "cloneUrl" : "https://github.com/beeware/briefcase-macOS-app-template.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 28,
        "watchersCount" : 28,
        "size" : 193216,
        "openIssuesCount" : 2,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-10T07:03:55Z",
        "languages" : {
          "Shell" : 410,
          "HTML" : 379,
          "Python" : 764
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown using a method such as pandoc, and verify the resulting README.md file is correctly formatted.",
      "validationOrRequirement" : "Verify that the two files (README.rst and README.md) are rendering the same after conversion, and delete the README.rst file before submitting a PR.",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The README file is currently formatted using reStructuredText, and there are multiple methods to convert rST to Markdown, including using pandoc. The conversion process may require some cleanup, especially around headers and code syntax.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283240
  }, {
    "issueDTO" : {
      "id" : 3214274374,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/briefcase-iOS-Xcode-template/issues/52",
      "repositoryName" : "beeware/briefcase-iOS-Xcode-template",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.\n",
      "updatedAt" : 1752261628.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A template for generating iOS Xcode projects with Briefcase",
        "homepage" : "",
        "name" : "briefcase-iOS-Xcode-template",
        "fullName" : "beeware/briefcase-iOS-Xcode-template",
        "htmlUrl" : "https://github.com/beeware/briefcase-iOS-Xcode-template",
        "gitUrl" : "git://github.com/beeware/briefcase-iOS-Xcode-template.git",
        "sshUrl" : "git@github.com:beeware/briefcase-iOS-Xcode-template.git",
        "cloneUrl" : "https://github.com/beeware/briefcase-iOS-Xcode-template.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 27,
        "watchersCount" : 27,
        "size" : 3385,
        "openIssuesCount" : 1,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-10T07:03:43Z",
        "languages" : {
          "Objective-C" : 17420
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README file from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "The README file should be converted to GitHub-flavored Markdown and verified to render the same as the original reStructuredText file. The title should be formatted as '# Title'.",
      "attemptedFixes" : "None",
      "otherNotes" : "The README file is currently formatted using reStructuredText and needs to be converted to GitHub-flavored Markdown. The conversion process may require cleanup, especially around headers and code syntax. Pandoc installation instructions are available and the command to convert the file is provided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283244
  }, {
    "issueDTO" : {
      "id" : 3214282879,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/briefcase-linux-appimage-template/issues/58",
      "repositoryName" : "beeware/briefcase-linux-appimage-template",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.\n",
      "updatedAt" : 1752261592.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A template for generating Linux AppImage projects with Briefcase",
        "homepage" : "",
        "name" : "briefcase-linux-appimage-template",
        "fullName" : "beeware/briefcase-linux-appimage-template",
        "htmlUrl" : "https://github.com/beeware/briefcase-linux-appimage-template",
        "gitUrl" : "git://github.com/beeware/briefcase-linux-appimage-template.git",
        "sshUrl" : "git@github.com:beeware/briefcase-linux-appimage-template.git",
        "cloneUrl" : "https://github.com/beeware/briefcase-linux-appimage-template.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 21,
        "watchersCount" : 21,
        "size" : 781,
        "openIssuesCount" : 2,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-10T07:03:45Z",
        "languages" : {
          "Dockerfile" : 1884,
          "Shell" : 527
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown and verify the conversion.",
      "validationOrRequirement" : "Verify that the converted README file renders the same as the original and delete the README.rst file before submitting a PR.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The README file is currently in reStructuredText and needs to be converted to GitHub-flavored Markdown. The conversion should be verified by comparing the two files and ensuring they render the same. Pandoc is one possible conversion option.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283247
  }, {
    "issueDTO" : {
      "id" : 3214293560,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/cricket/issues/98",
      "repositoryName" : "beeware/cricket",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.\n",
      "updatedAt" : 1752261579.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A GUI tool for running Python test suites.",
        "homepage" : "",
        "name" : "cricket",
        "fullName" : "beeware/cricket",
        "htmlUrl" : "https://github.com/beeware/cricket",
        "gitUrl" : "git://github.com/beeware/cricket.git",
        "sshUrl" : "git@github.com:beeware/cricket.git",
        "cloneUrl" : "https://github.com/beeware/cricket.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 217,
        "watchersCount" : 217,
        "size" : 985,
        "openIssuesCount" : 24,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-10T03:05:21Z",
        "languages" : {
          "Python" : 161698
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "Verify that the two files (README.rst and README.md) render the same after conversion, and ensure cleanup of headers and code syntax.",
      "attemptedFixes" : "None",
      "otherNotes" : "The README file is currently formatted using reStructuredText, and the goal is to convert it to GitHub-flavored Markdown. The conversion method is not specified, but pandoc is mentioned as an option. The title formatting may need to be adjusted.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283252
  }, {
    "issueDTO" : {
      "id" : 3214294765,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/bugjar/issues/33",
      "repositoryName" : "beeware/bugjar",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752261571.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A interactive graphical debugger for Python code.",
        "homepage" : "",
        "name" : "bugjar",
        "fullName" : "beeware/bugjar",
        "htmlUrl" : "https://github.com/beeware/bugjar",
        "gitUrl" : "git://github.com/beeware/bugjar.git",
        "sshUrl" : "git@github.com:beeware/bugjar.git",
        "cloneUrl" : "https://github.com/beeware/bugjar.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 33,
        "stargazersCount" : 250,
        "watchersCount" : 250,
        "size" : 82,
        "openIssuesCount" : 11,
        "subscribersCount" : 19,
        "pushedAt" : "2023-03-23T02:30:38Z",
        "languages" : {
          "Python" : 72604
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "Verify that the two files are rendering the same, especially around headers and code syntax, and delete the `README.rst` file before submitting a PR.",
      "attemptedFixes" : "None",
      "otherNotes" : "The README file is currently formatted using reStructuredText and needs to be converted to GitHub-flavored Markdown. Pandoc installation instructions are available. The conversion command is `pandoc -s README.rst -t gfm -o README.md`.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283256
  }, {
    "issueDTO" : {
      "id" : 3214296292,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/duvet/issues/17",
      "repositoryName" : "beeware/duvet",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752261562.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A GUI tool for visualizing coverage data.",
        "homepage" : "",
        "name" : "duvet",
        "fullName" : "beeware/duvet",
        "htmlUrl" : "https://github.com/beeware/duvet",
        "gitUrl" : "git://github.com/beeware/duvet.git",
        "sshUrl" : "git@github.com:beeware/duvet.git",
        "cloneUrl" : "https://github.com/beeware/duvet.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 55,
        "watchersCount" : 55,
        "size" : 52,
        "openIssuesCount" : 2,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-10T03:03:19Z",
        "languages" : {
          "Python" : 31447
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "Verify that the two files are rendering the same, especially around headers and code syntax. Delete the README.rst file before submitting a PR.",
      "attemptedFixes" : "None",
      "otherNotes" : "The README file for this repository is currently formatted using reStructuredText. Pandoc installation instructions can be found at https://pandoc.org/installing.html. The conversion command is pandoc -s README.rst -t gfm -o README.md. Ensure the title is formatted as # Title and verify the results are what you expect.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283260
  }, {
    "issueDTO" : {
      "id" : 3223969024,
      "title" : "Encounting pointer keys other than local ones in tests",
      "url" : "https://github.com/wala/ML/issues/284",
      "repositoryName" : "wala/ML",
      "description" : "Is this bad when it happens? What other pointer keys do we encounter during the tests? Should we be handling them?\n\nhttps://github.com/wala/ML/blob/53d2f0a82446e4913682249af7de1b270addb32a/com.ibm.wala.cast.python.ml.test/source/com/ibm/wala/cast/python/ml/test/TestTensorflow2Model.java#L3473",
      "updatedAt" : 1752261555.000000000,
      "user" : "khatchad",
      "userHtmlUrl" : "https://github.com/khatchad",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2048831?v=4",
      "labels" : [ "question", "testing", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "ML",
        "fullName" : "wala/ML",
        "htmlUrl" : "https://github.com/wala/ML",
        "gitUrl" : "git://github.com/wala/ML.git",
        "sshUrl" : "git@github.com:wala/ML.git",
        "cloneUrl" : "https://github.com/wala/ML.git",
        "owner" : {
          "login" : "wala",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 26,
        "watchersCount" : 26,
        "size" : 158156,
        "openIssuesCount" : 50,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-11T14:16:23Z",
        "languages" : {
          "Java" : 915457,
          "Shell" : 293,
          "HTML" : 1693,
          "Python" : 185516
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Understand and potentially handle pointer keys other than local ones in tests",
      "validationOrRequirement" : "Handling of pointer keys other than local ones during tests, with a question about whether it's bad and how to handle them",
      "attemptedFixes" : "",
      "otherNotes" : "Issue related to handling pointer keys in tests, with a specific reference to a line number in TestTensorflow2Model.java",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283263
  }, {
    "issueDTO" : {
      "id" : 3214299192,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/yorkshire4/issues/24",
      "repositoryName" : "beeware/yorkshire4",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same.",
      "updatedAt" : 1752261536.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The classic Usborne computer programming books - now in Python!",
        "homepage" : "https://yorkshire4.readthedocs.io",
        "name" : "yorkshire4",
        "fullName" : "beeware/yorkshire4",
        "htmlUrl" : "https://github.com/beeware/yorkshire4",
        "gitUrl" : "git://github.com/beeware/yorkshire4.git",
        "sshUrl" : "git@github.com:beeware/yorkshire4.git",
        "cloneUrl" : "https://github.com/beeware/yorkshire4.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 40,
        "watchersCount" : 40,
        "size" : 572,
        "openIssuesCount" : 2,
        "subscribersCount" : 9,
        "pushedAt" : "2022-04-20T05:52:16Z",
        "languages" : {
          "Python" : 78908
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "convert README.rst from reStructuredText to GitHub-flavored Markdown",
      "validationOrRequirement" : "verify that the two files are rendering the same, cleanup around headers and code syntax",
      "attemptedFixes" : "none",
      "otherNotes" : "README file currently formatted in reStructuredText, possible conversion method is pandoc, cleanup may be required around headers and code syntax, title formatting should be as '# Title', verify rendering of both files.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283266
  }, {
    "issueDTO" : {
      "id" : 3214300789,
      "title" : "Convert `README.rst` from reStructuredText to GitHub-flavored Markdown",
      "url" : "https://github.com/beeware/rubicon/issues/4",
      "repositoryName" : "beeware/rubicon",
      "description" : "### What is the problem or limitation you are having?\n\nThe README file for this repository is currently formatted using reStructuredText.\n\n### Describe the solution you'd like\n\nThe README should be converted to GitHub-flavored Markdown from rST. There are multiple methods to convert rST to Markdown. \n\nOnce conversion is complete, verify that the two files are rendering the same. This may require some cleanup, especially around headers and code syntax.\n\nDelete the `README.rst` file before submitting a PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nOne possible conversion option is `pandoc`. Pandoc installation instructions can be found [here](https://pandoc.org/installing.html).\n\nTo use `pandoc` to convert the `README.rst` file from rST to GitHub-flavored Markdown, run the following command from the same directory as the `README.rst` file:\n\n```\npandoc -s README.rst -t gfm -o README.md\n```\n\nThis command may result in an incorrect formatting of the title; the title should be formatted as `# Title`. Ensure you are verifying that the results you are getting are what you expect.\n\nThen verify the two files are rendering the same. \n",
      "updatedAt" : 1752261533.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A collection of tools to bridge between Python and other language environments.",
        "homepage" : null,
        "name" : "rubicon",
        "fullName" : "beeware/rubicon",
        "htmlUrl" : "https://github.com/beeware/rubicon",
        "gitUrl" : "git://github.com/beeware/rubicon.git",
        "sshUrl" : "git@github.com:beeware/rubicon.git",
        "cloneUrl" : "https://github.com/beeware/rubicon.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 42,
        "watchersCount" : 42,
        "size" : 5,
        "openIssuesCount" : 1,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-10T02:58:26Z",
        "languages" : {
          "Python" : 815
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the README.rst file from reStructuredText to GitHub-flavored Markdown.",
      "validationOrRequirement" : "The README.rst file should be deleted before submitting a PR. The title in the Markdown file should be formatted as `# Title`. The resulting Markdown file should render the same as the original reStructuredText file.",
      "attemptedFixes" : "The conversion can be done using pandoc, which is a popular method. The command to use is `pandoc -s README.rst -t gfm -o README.md`.",
      "otherNotes" : "The README file is currently in reStructuredText, and the goal is to convert it to GitHub-flavored Markdown. The conversion should be done using multiple methods, and the resulting Markdown file should be verified to render the same as the original reStructuredText file. The README.rst file should be deleted before submitting a PR.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283272
  }, {
    "issueDTO" : {
      "id" : 3082598828,
      "title" : "Allow paths with spaces in prompt commands in spf mode",
      "url" : "https://github.com/yorukot/superfile/issues/834",
      "repositoryName" : "yorukot/superfile",
      "description" : "**The part you want to Enhancement**\nAllow paths with spaces in prompt commands in spf mode. Right now, command like cd \"/abc/my folder\" will not work.\n\n**Why it is necessary to enhancement**\nTo allow directories with spaces, which are common in MacOS and windows.\n\n**Additional context**\n\nLikely need to adjust src/internal/ui/prompt/tokenize.go . \n\nRight now its\n\n```go\nfunc tokenizePromptCommand(command string, cwdLocation string) ([]string, error) {\n\tcommand, err := resolveShellSubstitution(shellSubTimeout, command, cwdLocation)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn strings.Fields(command), nil\n}\n```\n\nInstead of using strings.Field, we need to handle quotes correctly.\n",
      "updatedAt" : 1752261445.000000000,
      "user" : "lazysegtree",
      "userHtmlUrl" : "https://github.com/lazysegtree",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/59679977?v=4",
      "labels" : [ "bug", "high priority", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! May I work on this issue?" ],
      "repository" : {
        "description" : "Pretty fancy and modern terminal file manager",
        "homepage" : "https://superfile.netlify.app",
        "name" : "superfile",
        "fullName" : "yorukot/superfile",
        "htmlUrl" : "https://github.com/yorukot/superfile",
        "gitUrl" : "git://github.com/yorukot/superfile.git",
        "sshUrl" : "git@github.com:yorukot/superfile.git",
        "cloneUrl" : "https://github.com/yorukot/superfile.git",
        "owner" : {
          "login" : "yorukot",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 348,
        "stargazersCount" : 14147,
        "watchersCount" : 14147,
        "size" : 86209,
        "openIssuesCount" : 129,
        "subscribersCount" : 30,
        "pushedAt" : "2025-07-11T19:58:51Z",
        "languages" : {
          "MDX" : 9827,
          "PowerShell" : 9720,
          "TypeScript" : 269,
          "Shell" : 12333,
          "CSS" : 1888,
          "Astro" : 5113,
          "Makefile" : 892,
          "JavaScript" : 5794,
          "Go" : 481901,
          "HTML" : 53,
          "Nix" : 1617,
          "Python" : 36492
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow paths with spaces in prompt commands in spf mode",
      "validationOrRequirement" : "handle quotes correctly",
      "attemptedFixes" : "need to adjust src/internal/ui/prompt/tokenize.go",
      "otherNotes" : "directories with spaces are common in MacOS and windows",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283274
  }, {
    "issueDTO" : {
      "id" : 3185472146,
      "title" : "[feature] don't allow Unpacked TypedDict kwargs to overlap with any named parameter",
      "url" : "https://github.com/facebook/pyrefly/issues/595",
      "repositoryName" : "facebook/pyrefly",
      "description" : "### Describe the Bug\n\nRefer to the linked sandbox for an example.\n\nI think the place to change is https://github.com/facebook/pyrefly/blob/c247d452349c10958a44a3842540b12f7634e220/pyrefly/lib/alt/function.rs#L374\n\nWe should check if kwargs is an unpacked TypedDict, and if so, make sure it does not overlap with any existing named params.\n\nWhen completing this task, please add an integration test with the sandbox example to pyrefly/lib/tests/typed_dict.rs, run test.py, and commit any generated changes.\n\n### Sandbox Link\n\nhttps://pyrefly.org/sandbox/?code=GYJw9gtgBALgngBwJYDsDmUkQWEMoBUAUEQMYA2AhgM7VQDSA7pSGtQBQAqiApgCYARJKRgBKAFxEo0qAA9xmFDBIBiWAAskdLVADy9KACMepSgFdqPDVeBIQ1fLMx0c1JDCRgUlcgFov5HBEfDzAsDwO7PKKMAA0UAD08QQEANbMrNQKAKooCJSkqQDaTCxsALoSUAB0taoaOtTqYGbkfFAoYPjGevTBoeGR0ahxhGkZbDl5BcWlmZUKtdVAA\n\n### (Only applicable for extension issues) IDE Information\n\n_No response_",
      "updatedAt" : 1752260954.000000000,
      "user" : "yangdanny97",
      "userHtmlUrl" : "https://github.com/yangdanny97",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18299205?v=4",
      "labels" : [ "typechecking", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@yangdanny97 Hi, I???d like to work on this issue. I???m setting up the environment and will start with the changes in `function.rs`. Any additional guidance or clarification on the sandbox example would be appreciated!", "Cool, let me know if you have any questions.\n\nRe: the examples, the reason why this check needs to exist is to prevent declaring 2 parameters with the same name.\n\nThis:\n```\ndef test(**kwargs: Unpack[Kwargs]): ...\n```\n\nIs equivalent to:\n```\ndef test(*, x: int): ...\n```\n\nSo having both would be wrong\n\n```\ndef test(x: int, **kwargs: Unpack[Kwargs]): ...\n```\n\njust like doing this is wrong\n\n```\ndef test(*, x: int, x: int): ...\n```", "@yangdanny97 I???ve implemented the overlap check in `function.rs` for both `kwargs: TypedDict` and `kwargs: Unpack[TypedDict]`, and added `test_typed_dict_kwargs_overlap` in `typed_dict.rs` with cases for both annotations and a non-overlapping scenario. I???ve also included `test.py` based on the sandbox example. The PR is open at https://github.com/facebook/pyrefly/pull/665. Could you confirm if the `Unpack` handling is sufficient or if additional edge cases (e.g., multiple overlaps, nested TypedDicts) should be tested? Thanks for the guidance!" ],
      "repository" : {
        "description" : "A fast type checker and IDE for Python",
        "homepage" : "http://pyrefly.org/",
        "name" : "pyrefly",
        "fullName" : "facebook/pyrefly",
        "htmlUrl" : "https://github.com/facebook/pyrefly",
        "gitUrl" : "git://github.com/facebook/pyrefly.git",
        "sshUrl" : "git@github.com:facebook/pyrefly.git",
        "cloneUrl" : "https://github.com/facebook/pyrefly.git",
        "owner" : {
          "login" : "facebook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 121,
        "stargazersCount" : 3222,
        "watchersCount" : 3222,
        "size" : 163435,
        "openIssuesCount" : 212,
        "subscribersCount" : 21,
        "pushedAt" : "2025-07-12T00:16:10Z",
        "languages" : {
          "TypeScript" : 191380,
          "MDX" : 124963,
          "CSS" : 9844,
          "Shell" : 9589,
          "Rust" : 3326419,
          "Starlark" : 1111,
          "JavaScript" : 6980,
          "HTML" : 5099,
          "Ruby" : 73,
          "Python" : 35935
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to prevent overlap between unpacked TypedDict kwargs and named parameters in a function, and to add an integration test with the sandbox example to pyrefly/lib/tests/typed_dict.rs.",
      "validationOrRequirement" : "The issue requires the check to prevent declaring 2 parameters with the same name. The validation is to ensure that kwargs is an unpacked TypedDict and does not overlap with any existing named params.",
      "attemptedFixes" : "The author has implemented the overlap check in function.rs for both kwargs: TypedDict and kwargs: Unpack[TypedDict], and added test_typed_dict_kwargs_overlap in typed_dict.rs with cases for both annotations and a non-overlapping scenario.",
      "otherNotes" : "This issue is about preventing overlap between unpacked TypedDict kwargs and named parameters in a function. The issue is related to typechecking and is considered a good first issue. The author, yangdanny97, has implemented the overlap check in function.rs and added an integration test in typed_dict.rs. A PR is open at https://github.com/facebook/pyrefly/pull/665.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283281
  }, {
    "issueDTO" : {
      "id" : 3165205973,
      "title" : "Design Call for Speaker Flyer - Online Conference",
      "url" : "https://github.com/asyncapi/conference-website/issues/760",
      "repositoryName" : "asyncapi/conference-website",
      "description" : "Hey there! We need a flyer design for the **Call for Speakers** for the 2025 AsyncAPI online Conference.\n\nPlease feel free to include all necessary details you think should be in the flyer, and don't hesitate to ask for more information if you need it.\n\nPlease ensure you work is done on this Figma file - https://www.figma.com/design/rPSEsjwg2pYs8zb5w1imjl/AsyncAPI-Conference-Designs?node-id=3802-834&t=kbwMS7i8OsGDUhAw-1\n\nOR\n\nMoved to the Figma file above once you are done.\n\nThe purpose of this is to ensure that all our designs are stored in a single location, making it easier for us to reference them in the future. So I would greatly appreciate it if you could work/move your work there.",
      "updatedAt" : 1752260858.000000000,
      "user" : "Mayaleeeee",
      "userHtmlUrl" : "https://github.com/Mayaleeeee",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/105395613?v=4",
      "labels" : [ "design", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @thulieblack \n\nWe'll need details like date and the like.", "https://conference.asyncapi.com/venue/Online", "Hello @Mayaleeeee \n\nI'd love to work on this issue, thank you!", "Assigned to you @Mojetioluwa03 ", "Please make sure to create the design on the page assigned for this issue in the Figma board.\n\nThank you and happy designing!", "@Mojetioluwa03 \nWhat's the update on this issue?", "Hello @Mayaleeeee. I'm still on it, I'll communicate when I'm done, thank you!\n\n> [@Mojetioluwa03](https://github.com/Mojetioluwa03) What's the update on this issue?\n\n" ],
      "repository" : {
        "description" : "Website for the AsyncAPI online conference",
        "homepage" : "https://conference.asyncapi.com",
        "name" : "conference-website",
        "fullName" : "asyncapi/conference-website",
        "htmlUrl" : "https://github.com/asyncapi/conference-website",
        "gitUrl" : "git://github.com/asyncapi/conference-website.git",
        "sshUrl" : "git@github.com:asyncapi/conference-website.git",
        "cloneUrl" : "https://github.com/asyncapi/conference-website.git",
        "owner" : {
          "login" : "asyncapi",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 156,
        "stargazersCount" : 40,
        "watchersCount" : 40,
        "size" : 182362,
        "openIssuesCount" : 48,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-01T10:17:31Z",
        "languages" : {
          "TypeScript" : 117411,
          "CSS" : 5387,
          "JavaScript" : 1536
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Design a flyer for the Call for Speakers for the 2025 AsyncAPI online Conference",
      "validationOrRequirement" : "The design should be done on the Figma file provided, and should include necessary details like date and the like.",
      "attemptedFixes" : "None mentioned in the comments",
      "otherNotes" : "The design should include details like date and the like, and should be created on the page assigned for this issue in the Figma board. The purpose is to ensure all designs are stored in a single location for future reference.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283285
  }, {
    "issueDTO" : {
      "id" : 2644824082,
      "title" : "Refactor HybridQueryBuilderTests to decouple types from K-NN library",
      "url" : "https://github.com/opensearch-project/neural-search/issues/979",
      "repositoryName" : "opensearch-project/neural-search",
      "description" : "### Is your feature request related to a problem?\r\nComing from https://github.com/opensearch-project/neural-search/issues/859. Refactored `HybridQueryTests` and `HybridQueryPhaseSearcherTests` in https://github.com/opensearch-project/neural-search/pull/977. Similarly, need to decouple knn for `HybridQueryBuilderTests`. \r\n\r\n### What solution would you like?\r\n_A clear and concise description of what you want to happen._\r\n\r\n### What alternatives have you considered?\r\n_A clear and concise description of any alternative solutions or features you've considered._\r\n\r\n### Do you have any additional context?\r\n_Add any other context or screenshots about the feature request here._\r\n",
      "updatedAt" : 1752260846.000000000,
      "user" : "owaiskazi19",
      "userHtmlUrl" : "https://github.com/owaiskazi19",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16099877?v=4",
      "labels" : [ "hybrid search", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "The PR https://github.com/opensearch-project/neural-search/pull/977 has been merged. What else do we need to do?", "> The PR https://github.com/opensearch-project/neural-search/pull/977 has been merged. What else do we need to do?\n\nPR was for other 2 different test classes.", "Scope for this issue is removal of compile time dependency from\r\n[HybridQueryTests](https://github.com/opensearch-project/neural-search/blob/main/src/test/java/org/opensearch/neuralsearch/query/HybridQueryTests.java) and [HybridQueryBuilderTests](https://github.com/opensearch-project/neural-search/blob/main/src/test/java/org/opensearch/neuralsearch/query/HybridQueryBuilderTests.java) \r\n" ],
      "repository" : {
        "description" : "Neural search transforms text into vectors and facilitates vector search both at ingestion time and at search time. ",
        "homepage" : "",
        "name" : "neural-search",
        "fullName" : "opensearch-project/neural-search",
        "htmlUrl" : "https://github.com/opensearch-project/neural-search",
        "gitUrl" : "git://github.com/opensearch-project/neural-search.git",
        "sshUrl" : "git@github.com:opensearch-project/neural-search.git",
        "cloneUrl" : "https://github.com/opensearch-project/neural-search.git",
        "owner" : {
          "login" : "opensearch-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 94,
        "stargazersCount" : 87,
        "watchersCount" : 87,
        "size" : 90540,
        "openIssuesCount" : 113,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-11T16:49:52Z",
        "languages" : {
          "Java" : 3782321
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor HybridQueryBuilderTests to decouple types from K-NN library",
      "validationOrRequirement" : "removal of compile time dependency from HybridQueryTests and HybridQueryBuilderTests",
      "attemptedFixes" : "PR was for other 2 different test classes.",
      "otherNotes" : "The PR https://github.com/opensearch-project/neural-search/pull/977 has been merged. What else do we need to do?; Scope for this issue is removal of compile time dependency from HybridQueryTests and HybridQueryBuilderTests",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283289
  }, {
    "issueDTO" : {
      "id" : 2092744051,
      "title" : "Other \"good first issues\"",
      "url" : "https://github.com/Rust-for-Linux/linux/issues/1058",
      "repositoryName" : "Rust-for-Linux/linux",
      "description" : "If you are looking for more \"good first issues\" (https://github.com/Rust-for-Linux/linux/labels/good%20first%20issue), please also take a look at our https://rust-for-linux.com/contributing page ??? there are some ideas there.\n\nIn addition, please check our wishlists about other projects such as Rust, at the top of https://github.com/Rust-for-Linux/linux/issues/2. For instance, the [Compiler Explorer wishlist](https://github.com/Rust-for-Linux/linux/issues/949) mentions several features we would like to have there, such as [the ability to run Clippy](https://github.com/compiler-explorer/compiler-explorer/issues/2562) there.\n\nThank you!",
      "updatedAt" : 1752260829.000000000,
      "user" : "ojeda",
      "userHtmlUrl" : "https://github.com/ojeda",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1054456?v=4",
      "labels" : [ "meta", "medium", "hard", "good first issue", "easy" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for the information!" ],
      "repository" : {
        "description" : "Adding support for the Rust language to the Linux kernel.",
        "homepage" : "https://rust-for-linux.com",
        "name" : "linux",
        "fullName" : "Rust-for-Linux/linux",
        "htmlUrl" : "https://github.com/Rust-for-Linux/linux",
        "gitUrl" : "git://github.com/Rust-for-Linux/linux.git",
        "sshUrl" : "git@github.com:Rust-for-Linux/linux.git",
        "cloneUrl" : "https://github.com/Rust-for-Linux/linux.git",
        "owner" : {
          "login" : "Rust-for-Linux",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : true,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 467,
        "stargazersCount" : 4199,
        "watchersCount" : 4199,
        "size" : 5614420,
        "openIssuesCount" : 278,
        "subscribersCount" : 132,
        "pushedAt" : "2025-07-09T14:01:38Z",
        "languages" : {
          "Yacc" : 128725,
          "C++" : 180074,
          "Jinja" : 30246,
          "C" : 1355090294,
          "Rust" : 1355074,
          "RPC" : 962,
          "Makefile" : 2766419,
          "M4" : 3329,
          "Perl" : 1225160,
          "MATLAB" : 2482,
          "UnrealScript" : 16878,
          "SmPL" : 166781,
          "Shell" : 5297435,
          "sed" : 2433,
          "Awk" : 72230,
          "Gherkin" : 10795,
          "Linker Script" : 10018,
          "Roff" : 205267,
          "XS" : 1239,
          "Assembly" : 9651336,
          "Lex" : 72539,
          "Python" : 3310362,
          "Clojure" : 2621
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To provide information on 'good first issues' and other projects' wishlists.",
      "validationOrRequirement" : "None mentioned in the description.",
      "attemptedFixes" : "None mentioned in the description.",
      "otherNotes" : "The issue is about providing information on 'good first issues' and other projects' wishlists, specifically mentioning Compiler Explorer wishlist.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283291
  }, {
    "issueDTO" : {
      "id" : 3223920443,
      "title" : "Remove the `expectedNumberOfTensorParameters` parameter",
      "url" : "https://github.com/wala/ML/issues/283",
      "repositoryName" : "wala/ML",
      "description" : "Since `expectedNumberOfTensorParameters` must be equal to `expectedTensorParameterValueNumbers.length`, we can remove the `expectedNumberOfTensorParameters`  parameter and just use `expectedTensorParameterValueNumbers`.\n\nhttps://github.com/wala/ML/blob/53d2f0a82446e4913682249af7de1b270addb32a/com.ibm.wala.cast.python.ml.test/source/com/ibm/wala/cast/python/ml/test/TestTensorflow2Model.java#L3496-L3500",
      "updatedAt" : 1752260659.000000000,
      "user" : "khatchad",
      "userHtmlUrl" : "https://github.com/khatchad",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2048831?v=4",
      "labels" : [ "java", "cleanup", "testing", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "ML",
        "fullName" : "wala/ML",
        "htmlUrl" : "https://github.com/wala/ML",
        "gitUrl" : "git://github.com/wala/ML.git",
        "sshUrl" : "git@github.com:wala/ML.git",
        "cloneUrl" : "https://github.com/wala/ML.git",
        "owner" : {
          "login" : "wala",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 26,
        "watchersCount" : 26,
        "size" : 158156,
        "openIssuesCount" : 50,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-11T14:16:23Z",
        "languages" : {
          "Java" : 915457,
          "Shell" : 293,
          "HTML" : 1693,
          "Python" : 185516
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove the `expectedNumberOfTensorParameters` parameter as it is not necessary and can be replaced with `expectedTensorParameterValueNumbers`.",
      "validationOrRequirement" : "The `expectedNumberOfTensorParameters` parameter must be equal to `expectedTensorParameterValueNumbers.length`.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to a Java file in the ML repository.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283294
  }, {
    "issueDTO" : {
      "id" : 3223853928,
      "title" : "Fix: Wrong link for meshery discussion forum",
      "url" : "https://github.com/meshery/meshery.io/issues/2292",
      "repositoryName" : "meshery/meshery.io",
      "description" : "### Description\nMore info: https://mesheryio.slack.com/archives/CDM0ACDM5/p1752243729027379\n\n### Expected Behavior\n<!-- A brief description of what you expected to happen.-->\n\n### Screenshots\n<!--- Add screenshots, if applicable, to help explain your problem.-->\n\n### Environment:\n - OS: Mac Linux Windows\n - Browser: Chrome Safari Firefox\n - Version: \n - Device: Desktop Mobile\n\n---\n## Contributor [Guides](https://docs.meshery.io/project/contributing) and [Handbook](https://meshery.io/community/handbook)\n\nThe meshery.io website uses Jekyll and GitHub Pages. Site content is found under the [`master` branch](https://github.com/meshery/meshery.io/tree/master).\n- \uD83D\uDCDA See the [Contributing to Meshery.io Website](https://github.com/meshery/meshery.io#contributing-to-the-mesheryio-website) section of the readme.md and other [contributing instructions](https://docs.meshery.io/project/contributing), too.\n- \uD83C\uDFA8 Wireframes and [designs for Meshery UI](https://www.figma.com/file/SMP3zxOjZztdOLtgN4dS2W/Meshery-UI) in Figma [(open invite)](https://www.figma.com/team_invite/redeem/qJy1c95qirjgWQODApilR9)\n- \uD83D\uDE4B\uD83C\uDFFE\uD83D\uDE4B\uD83C\uDFFC Questions: [Discussion Forum](/community#discussion-forums) and [Community Slack](https://slack.meshery.io)\n",
      "updatedAt" : 1752260644.000000000,
      "user" : "FaheemOnHub",
      "userHtmlUrl" : "https://github.com/FaheemOnHub",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/35933338?v=4",
      "labels" : [ "kind/bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for opening this issue. A contributor will be by to give feedback soon. In the meantime, please review the [Newcomers' Guide](https://docs.meshery.io/project/community#getting-involved-in-the-community) and sure to join the [community Slack](https://slack.meshery.io/).\n", "assign it to me I will fix it @FaheemOnHub " ],
      "repository" : {
        "description" : "Website for Meshery",
        "homepage" : "https://meshery.io",
        "name" : "meshery.io",
        "fullName" : "meshery/meshery.io",
        "htmlUrl" : "https://github.com/meshery/meshery.io",
        "gitUrl" : "git://github.com/meshery/meshery.io.git",
        "sshUrl" : "git@github.com:meshery/meshery.io.git",
        "cloneUrl" : "https://github.com/meshery/meshery.io.git",
        "owner" : {
          "login" : "meshery",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 683,
        "stargazersCount" : 627,
        "watchersCount" : 627,
        "size" : 365506,
        "openIssuesCount" : 63,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-12T00:16:27Z",
        "languages" : {
          "CSS" : 29654,
          "SCSS" : 146605,
          "Makefile" : 965,
          "JavaScript" : 1218073,
          "Go" : 26988,
          "HTML" : 466667,
          "Ruby" : 380
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the wrong link for the meshery discussion forum",
      "validationOrRequirement" : "The contributor should review the [Newcomers' Guide](https://docs.meshery.io/project/community#getting-involved-in-the-community) and join the [community Slack](https://slack.meshery.io/)",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is related to the meshery.io website, which uses Jekyll and GitHub Pages. The contributor is expected to review the Newcomers' Guide and join the community Slack.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283298
  }, {
    "issueDTO" : {
      "id" : 3144884443,
      "title" : "[Feature]: Elasticsearch support for API Keys",
      "url" : "https://github.com/jaegertracing/jaeger/issues/7225",
      "repositoryName" : "jaegertracing/jaeger",
      "description" : "### Requirement\n\nAs a Jaeger operator, I want to be able to authenticate with API keys, such that I can more easily rotate my secrets without incurring downtime.\n\nIn my enterprise, passwords must be rotated on a regular basis. However, when they are, because only one password can be active at a time, it incurs downtime after the password has been rotated on the server side but not yet on the client side. With API keys, we can create an API key, rotate it on the client side, and then delete the old API key.\n\n### Problem\n\nWith API keys, we can create an API key, rotate it on the client side, and then delete the old API key, thus avoiding downtime.\n\n### Proposal\n\n_No response_\n\n### Open questions\n\n_No response_",
      "updatedAt" : 1752260339.000000000,
      "user" : "richardmcsong",
      "userHtmlUrl" : "https://github.com/richardmcsong",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9144514?v=4",
      "labels" : [ "help wanted", "enhancement", "storage/elasticsearch", "good first issue", "area/storage" ],
      "state" : "OPEN",
      "comments" : [ "is API key simply passed as a standard Auth header and we just need to add the ability to attach extra headers (plus auto-reload it from a file as we already do with passwords)?", "Looks like it should be passed in via\n```\n  -H \"Authorization: ApiKey ${API_KEY}\"\n```\n\nhttps://www.elastic.co/docs/api/doc/elasticsearch/authentication#doc-authentication-api-key-auth", "Hi is this issue still available? I'd love to get started on my first contribution!", "Go for it", "@yurishkuro can i work on this pls " ],
      "repository" : {
        "description" : "CNCF Jaeger, a Distributed Tracing Platform",
        "homepage" : "https://www.jaegertracing.io/",
        "name" : "jaeger",
        "fullName" : "jaegertracing/jaeger",
        "htmlUrl" : "https://github.com/jaegertracing/jaeger",
        "gitUrl" : "git://github.com/jaegertracing/jaeger.git",
        "sshUrl" : "git@github.com:jaegertracing/jaeger.git",
        "cloneUrl" : "https://github.com/jaegertracing/jaeger.git",
        "owner" : {
          "login" : "jaegertracing",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2607,
        "stargazersCount" : 21573,
        "watchersCount" : 21573,
        "size" : 33554,
        "openIssuesCount" : 321,
        "subscribersCount" : 322,
        "pushedAt" : "2025-07-11T19:54:15Z",
        "languages" : {
          "Dockerfile" : 9030,
          "Shell" : 84186,
          "sed" : 534,
          "Makefile" : 35903,
          "JavaScript" : 340,
          "Go" : 3235151,
          "HTML" : 1821,
          "Python" : 79987,
          "Jsonnet" : 9510
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement Elasticsearch support for API Keys to allow authentication and rotation of secrets without incurring downtime",
      "validationOrRequirement" : "API key authentication must follow elastic.co's API key authentication documentation and must be able to attach extra headers, auto-reload from a file as done with passwords",
      "attemptedFixes" : "none mentioned in the comments",
      "otherNotes" : "API key should be passed as a standard Auth header with the ability to attach extra headers, auto-reload from a file as done with passwords, and follows elastic.co's API key authentication documentation",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283302
  }, {
    "issueDTO" : {
      "id" : 3213766508,
      "title" : "Incorrect string conversion for `ENUM`s in `CASE` statements",
      "url" : "https://github.com/dolthub/dolt/issues/9473",
      "repositoryName" : "dolthub/dolt",
      "description" : "MySQL:\n```sql\nmysql> create table t (e enum('abc', 'defg', 'hijkl'));\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> insert into t values(1), (2), (3);\nQuery OK, 3 rows affected (0.00 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n\nmysql> select (case e when 'abc' then e when 'defg' then e when 'hijkl' then 'something' end) as e from t order by e;\n+-----------+\n| e         |\n+-----------+\n| abc       |\n| defg      |\n| something |\n+-----------+\n3 rows in set (0.00 sec)\n```\n\ndolt:\n```sql\ntmp/main*> create table t (e enum('abc', 'defg', 'hijkl'));\nQuery OK, 0 rows affected (0.02 sec)\ntmp/main*> insert into t values(1), (2), (3);\nQuery OK, 3 rows affected (0.02 sec)\ntmp/main*> select (case e when 'abc' then e when 'defg' then e when 'hijkl' then 'something' end) as e from t order by e;\n+-----------+\n| e         |\n+-----------+\n| 1         |\n| 2         |\n| something |\n+-----------+\n3 rows in set (0.00 sec) \n\n```\n\nSkipped test here: https://github.com/dolthub/go-mysql-server/pull/3077/files#diff-a2fc9c77f73a02bb06e3742498bfffe92aa39331918f0f396f0150fbbce3c2adR8773-R8781",
      "updatedAt" : 1752260272.000000000,
      "user" : "jycor",
      "userHtmlUrl" : "https://github.com/jycor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30810879?v=4",
      "labels" : [ "correctness", "good repro", "good first issue", "sql" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Dolt ??? Git for Data",
        "homepage" : "https://www.dolthub.com",
        "name" : "dolt",
        "fullName" : "dolthub/dolt",
        "htmlUrl" : "https://github.com/dolthub/dolt",
        "gitUrl" : "git://github.com/dolthub/dolt.git",
        "sshUrl" : "git@github.com:dolthub/dolt.git",
        "cloneUrl" : "https://github.com/dolthub/dolt.git",
        "owner" : {
          "login" : "dolthub",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 568,
        "stargazersCount" : 18870,
        "watchersCount" : 18870,
        "size" : 155830,
        "openIssuesCount" : 429,
        "subscribersCount" : 116,
        "pushedAt" : "2025-07-11T23:37:55Z",
        "languages" : {
          "C#" : 8841,
          "Java" : 12609,
          "C++" : 2745,
          "C" : 4925,
          "Rust" : 1991,
          "CMake" : 591,
          "Makefile" : 3258,
          "Go" : 15461516,
          "Perl" : 3555,
          "TypeScript" : 2938,
          "Dockerfile" : 578,
          "Shell" : 2668304,
          "R" : 4965,
          "Batchfile" : 521,
          "JavaScript" : 46932,
          "PHP" : 2434,
          "Tcl" : 1569,
          "Ruby" : 2603,
          "Elixir" : 2236,
          "Python" : 11991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Incorrect string conversion for ENUMs in CASE statements",
      "validationOrRequirement" : "Correctness, good repro, good first issue, sql",
      "attemptedFixes" : "Skipped test",
      "otherNotes" : "The issue is related to incorrect string conversion for ENUMs in CASE statements in both MySQL and Dolt databases.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283305
  }, {
    "issueDTO" : {
      "id" : 3223901984,
      "title" : "Queue list should start at \"1\" for users (not at \"0\")",
      "url" : "https://github.com/openzim/zimit-frontend/issues/151",
      "repositoryName" : "openzim/zimit-frontend",
      "description" : "<img width=\"925\" height=\"600\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bde02e4f-e13f-4483-a33f-e8d9ca960088\" />\n\n.... because users are not machines ;)",
      "updatedAt" : 1752260161.000000000,
      "user" : "kelson42",
      "userHtmlUrl" : "https://github.com/kelson42",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1029718?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Zimit Public Web UI",
        "homepage" : "https://zimit.kiwix.org",
        "name" : "zimit-frontend",
        "fullName" : "openzim/zimit-frontend",
        "htmlUrl" : "https://github.com/openzim/zimit-frontend",
        "gitUrl" : "git://github.com/openzim/zimit-frontend.git",
        "sshUrl" : "git@github.com:openzim/zimit-frontend.git",
        "cloneUrl" : "https://github.com/openzim/zimit-frontend.git",
        "owner" : {
          "login" : "openzim",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 20,
        "watchersCount" : 20,
        "size" : 611,
        "openIssuesCount" : 19,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-07T13:53:37Z",
        "languages" : {
          "TypeScript" : 20055,
          "Dockerfile" : 330,
          "Shell" : 1502,
          "CSS" : 941,
          "Vue" : 28651,
          "JavaScript" : 570,
          "HTML" : 2642,
          "Python" : 68513
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Queue list should start at '1' for users",
      "validationOrRequirement" : "enhancement, good first issue",
      "attemptedFixes" : "",
      "otherNotes" : "Users are not machines, the queue list should start at '1' for users, not at '0'.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283307
  }, {
    "issueDTO" : {
      "id" : 1076673661,
      "title" : "clang-change-namespace tool is not documented",
      "url" : "https://github.com/llvm/llvm-project/issues/35519",
      "repositoryName" : "llvm/llvm-project",
      "description" : "|  |  |\n| --- | --- |\n| Bugzilla Link | [36171](https://llvm.org/bz36171) |\n| Version | unspecified |\n| OS | Windows NT |\n\n## Extended Description \nclang-change-namespace tool is present in the repository, but is not documented anywhere.",
      "updatedAt" : 1752259314.000000000,
      "user" : "LegalizeAdulthood",
      "userHtmlUrl" : "https://github.com/LegalizeAdulthood",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4270863?v=4",
      "labels" : [ "documentation", "bugzilla", "clang-tools-extra", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@llvm/issue-subscribers-good-first-issue", "hello, is this adding documentation to the clang-tools-extra/docs docs or is this ticket wanting a more commented section within clang-change-namespace itself? If the former is true do I just add to the doxygen documentation files?\r\nthank you for the clarification" ],
      "repository" : {
        "description" : "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.",
        "homepage" : "http://llvm.org",
        "name" : "llvm-project",
        "fullName" : "llvm/llvm-project",
        "htmlUrl" : "https://github.com/llvm/llvm-project",
        "gitUrl" : "git://github.com/llvm/llvm-project.git",
        "sshUrl" : "git@github.com:llvm/llvm-project.git",
        "cloneUrl" : "https://github.com/llvm/llvm-project.git",
        "owner" : {
          "login" : "llvm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14443,
        "stargazersCount" : 33450,
        "watchersCount" : 33450,
        "size" : 2519038,
        "openIssuesCount" : 30765,
        "subscribersCount" : 577,
        "pushedAt" : "2025-07-12T01:01:34Z",
        "languages" : {
          "GDB" : 8473,
          "CMake" : 4075997,
          "Mustache" : 16482,
          "HTML" : 1956247,
          "Pawn" : 10154,
          "MATLAB" : 4946,
          "Fortran" : 11610249,
          "LLVM" : 631719945,
          "OCaml" : 335815,
          "Assembly" : 150737335,
          "Python" : 12915167,
          "Rust" : 4903,
          "Objective-C++" : 1173632,
          "SWIG" : 287770,
          "Tree-sitter Query" : 6195,
          "Perl" : 183797,
          "MLIR" : 21179643,
          "Cuda" : 1243342,
          "Scilab" : 160404,
          "Starlark" : 1177382,
          "Batchfile" : 52122,
          "AMPL" : 1662,
          "Swift" : 271,
          "DTrace" : 334,
          "C" : 202129658,
          "RPC" : 28,
          "Makefile" : 114902,
          "Cool" : 5401,
          "Jupyter Notebook" : 72939,
          "M" : 9785,
          "TypeScript" : 69121,
          "Shell" : 263950,
          "Awk" : 127345,
          "JavaScript" : 161607,
          "Mathematica" : 1118,
          "Objective-C" : 4269109,
          "Lua" : 12033,
          "PHP" : 64,
          "Limbo" : 303,
          "POV-Ray SDL" : 861,
          "Emacs Lisp" : 69003,
          "C++" : 488688394,
          "CSS" : 63859,
          "FIRRTL" : 4298018,
          "TeX" : 2141,
          "AppleScript" : 1429,
          "NASL" : 35217,
          "HIP" : 856703,
          "Julia" : 49676,
          "Dockerfile" : 23252,
          "Linker Script" : 903,
          "Roff" : 60700,
          "HLSL" : 1475332,
          "Mercury" : 14,
          "Vim Script" : 29186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add documentation for the clang-change-namespace tool",
      "validationOrRequirement" : "The issue requires documentation to be added for the clang-change-namespace tool, and the documentation should be added either to the clang-tools-extra/docs docs or within the clang-change-namespace itself.",
      "attemptedFixes" : "The author is seeking clarification on where the documentation should be added, and there is a suggestion to add to the doxygen documentation files if the documentation is to be added to clang-tools-extra/docs docs.",
      "otherNotes" : "The issue is about adding documentation for the clang-change-namespace tool, and there is a discussion about whether the documentation should be added to the clang-tools-extra/docs docs or within the clang-change-namespace itself.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283312
  }, {
    "issueDTO" : {
      "id" : 3216264548,
      "title" : "When you want to choose a theme for an email the select button do NOT look like a button",
      "url" : "https://github.com/mautic/mautic/issues/15202",
      "repositoryName" : "mautic/mautic",
      "description" : "### Mautic Series\n\n6.0.x series\n\n### Mautic installed version\n\n7.x\n\n### Way of installing\n\nI downloaded a release from https://www.mautic.org/mautic-releases\n\n### PHP version\n\n8\n\n### What browsers are you seeing the problem on?\n\n_No response_\n\n### What happened?\n\nIf I click on the theme I want to select it as the theme and not see the preview - it would be clearer if the select button looks like a button, even if not hovering it. Or, better, select the theme by clicking the theme anywhere and the button becomes a Preview button (also visible as a button)\n\n### How can we reproduce this issue?\n\nStep 1: create an email (triggered or segment)\nStep 2: try to choose a theme\n\n### Relevant log output\n\n```shell\n\n```\n\n### Code of Conduct\n\n- [x] I confirm that I have read and agree to follow this project's Code of Conduct\n\n<br /><hr>\nCare about this issue? Want to get it resolved sooner? If you are a <a href='https://www.mautic.org/become-a-member-of-mautic'>member of Mautic</a>, you can add some funds to the <a href='https://opencollective.com/mautic/projects/bounties'>Bounties Project</a> so that the person who completes this task can claim those funds once it is merged by a member of the core team! Read the docs <a href='https://contribute.mautic.org/product-team/mautic-bounty-programme'>here.</a>",
      "updatedAt" : 1752259311.000000000,
      "user" : "Bastian2718",
      "userHtmlUrl" : "https://github.com/Bastian2718",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/177823038?v=4",
      "labels" : [ "user-interface", "bug", "user-experience", "T1", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi team\n\nI???ve worked on Option A (minimum) as described:\n\n???Make the Select button clearly look like a button even before you hover it\"\n\nI updated the button styling so it always appears as a clear, obvious button???even without hovering.\n\nI???ve attached a screenshot below to show the result.\n\nPlease let me know if any further refinements are needed!\n\n![Image](https://github.com/user-attachments/assets/e051c997-c96a-43da-a447-0021434a608d)" ],
      "repository" : {
        "description" : "Mautic: Open Source Marketing Automation Software.",
        "homepage" : "https://www.mautic.org",
        "name" : "mautic",
        "fullName" : "mautic/mautic",
        "htmlUrl" : "https://github.com/mautic/mautic",
        "gitUrl" : "git://github.com/mautic/mautic.git",
        "sshUrl" : "git@github.com:mautic/mautic.git",
        "cloneUrl" : "https://github.com/mautic/mautic.git",
        "owner" : {
          "login" : "mautic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2905,
        "stargazersCount" : 8307,
        "watchersCount" : 8307,
        "size" : 249414,
        "openIssuesCount" : 386,
        "subscribersCount" : 294,
        "pushedAt" : "2025-07-11T15:08:14Z",
        "languages" : {
          "TypeScript" : 3387,
          "CSS" : 1077140,
          "Shell" : 6433,
          "Twig" : 2466852,
          "JavaScript" : 799568,
          "PHP" : 18883174,
          "HTML" : 334376,
          "Less" : 605507
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to make the select button for choosing a theme in Mautic 6.0.x series look like a button, even when not hovered.",
      "validationOrRequirement" : "No specific validation or requirement mentioned.",
      "attemptedFixes" : "Option A (minimum) was attempted, which is to make the Select button clearly look like a button even before you hover it. The button styling was updated to always appear as a clear, obvious button???even without hovering.",
      "otherNotes" : "The issue is related to the Mautic 6.0.x series and the user interface of choosing a theme for an email. The select button does not look like a button, even when not hovered.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283317
  }, {
    "issueDTO" : {
      "id" : 2957366768,
      "title" : "Defend against transactions that source nonce account addresses from lookup tables",
      "url" : "https://github.com/anza-xyz/kit/issues/309",
      "repositoryName" : "anza-xyz/kit",
      "description" : "<!-- Please fill in each section completely. Thank you! -->\n\n## Motivation\n\nhttps://github.com/solana-foundation/solana-improvement-documents/pull/242 will make it impossible to load a nonce account from an address lookup table, so we must adjust the ergonomics of the JS SDK to prohibit creating such a transaction message.\n\n## Details\n\n1. Make sure that `createAdvanceNonceAccountInstruction()` does not produce an `IAccountLookupMeta` (already the case, I think)\n2. `isAdvanceNonceAccountInstructionForNonce()` must assert that the nonce account in an `AdvanceNonce` instruction is not an `IAccountLookupMeta`\n3. `compressTransactionMessageUsingAddressLookupTables()` should refuse to convert an `AdvanceNonce` instruction's nonce account from an `IAccountMeta` to an `IAccountLookupMeta`. **Note**: this will be bad for package efficiency, because this will mean putting nonce-specific logic in a place where it will almost never be used. Think hard about whether this is worth it or not.\n4.  `getAddressMapFromInstructions()` should always [upgrade lookup table entries to static entries](https://github.com/anza-xyz/kit/blob/b97855f04ccb44d7dce873942b3fa1ed9437b9c5/packages/transaction-messages/src/compile/accounts.ts#L120-L124) if they belong to a nonce account that is subject to an `AdvanceNonce` instruction. **Note**: like 3, this will be bad for package efficiency, because this will mean putting nonce-specific logic into the message compiler where it will almost never be used. Think hard about whether this is worth it or not.\n\n> [!NOTE]\n> There is a world where, if we're OK with taking the hit on package efficiency to implement 4, then we can ignore all of the other changes. That is to say we can play fast and loose with whether we allow an `AdvanceNonceInstruction` to contain an `IAccountLookupMeta` knowing that eventually the transaction message compiler will ???upgrade??? it to a static entry. Thoughts?",
      "updatedAt" : 1752259278.000000000,
      "user" : "steveluscher",
      "userHtmlUrl" : "https://github.com/steveluscher",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13243?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hii @steveluscher is this issue still open, can I drop a PR?\nAlso what I'm understanding here is either we choose option 4 or we need to implement all of 1,2 and 3, and in both of these cases we lose on efficiency, since there isn't a faster way I think we should go with implementing 1,2,3 because it will be better for the devs. cause error at runtime, but no error while writing the code could be confusing to devs!", "Thanks for revisiting this with me. I just loaded this all back into my head.\n\nKnow what? I don't want to do any of this. Call it a personal challenge, but I'm uncomfortable jamming nonce-related logic into general purpose functions. In the fullness of time this leads to nightmare implementations where everything is everywhere and code efficiency is low.\n\nWe can do better. Let's introduce the concept of an incompressible account, and teach `compressTransactionMessageUsingAddressLookupTables()` to leave them alone.\n\n[Here](https://github.com/anza-xyz/kit/blob/efc90c990a03de8f5ec8214ac0621e6a2576545e/packages/instructions/src/accounts.ts#L5-L92), we have all of the different kinds of accounts that can be attached to an instruction. Let's add a new type.\n\n```ts\nexport type IncompressibleAccount<TAccount extends AccountMeta> = T & {\n    readonly incompressible: true;\n};\n```\n\nThen the fix looks more like this:\n\n1. Make sure that `createAdvanceNonceAccountInstruction()` produces an `AdvanceNonce` instruction having an `IncompressibleAccount<WritableAccount<TNonceAccountAddress>>`\n2. `isAdvanceNonceAccountInstructionForNonce()` must assert that the nonce account in an `AdvanceNonce` instruction has `incompressible` set to `true`.\n3. `compressTransactionMessageUsingAddressLookupTables()` should refuse to convert any account to a lookup account, if its `incompressible` property is `true`.\n\nThe only decision we have to make is the name. Compressibility is not a word that's used in the protocol, despite that being what address lookup tables were created for. If someone can think of a better name for ???a property of an account which prohibits it from being converted to an account lookup in an optimization step??? then comment below! cc/ @lorisleiva @mcintyre94 @jordaaash @alannza.", "How about the name\nNonLookupAccount, and nonLookup: true\n\nEmphasizes account cannot be referenced via ALTs\n\nOr \n\nStaticAccount, with static:true\n\nExplaining the account is unchanged and used as a full 32 byte instead of a reference from alt!\n\nI prefer StaticAccount.." ],
      "repository" : {
        "description" : "Solana JavaScript SDK",
        "homepage" : "https://solana-kit-docs.vercel.app",
        "name" : "kit",
        "fullName" : "anza-xyz/kit",
        "htmlUrl" : "https://github.com/anza-xyz/kit",
        "gitUrl" : "git://github.com/anza-xyz/kit.git",
        "sshUrl" : "git@github.com:anza-xyz/kit.git",
        "cloneUrl" : "https://github.com/anza-xyz/kit.git",
        "owner" : {
          "login" : "anza-xyz",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 77,
        "stargazersCount" : 480,
        "watchersCount" : 480,
        "size" : 63095,
        "openIssuesCount" : 62,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T22:24:51Z",
        "languages" : {
          "TypeScript" : 4730948,
          "Shell" : 2917,
          "JavaScript" : 3262
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Defend against transactions that source nonce account addresses from lookup tables. Make sure that createAdvanceNonceAccountInstruction() does not produce an IAccountLookupMeta and isAdvanceNonceAccountInstructionForNonce() must assert that the nonce account in an AdvanceNonce instruction is not an IAccountLookupMeta. Also, compressTransactionMessageUsingAddressLookupTables() should refuse to convert an AdvanceNonce instruction's nonce account from an IAccountMeta to an IAccountLookupMeta.",
      "validationOrRequirement" : "Make sure that createAdvanceNonceAccountInstruction() does not produce an IAccountLookupMeta (already the case, I think). ... isAdvanceNonceAccountInstructionForNonce() must assert that the nonce account in an AdvanceNonce instruction is not an IAccountLookupMeta ... compressTransactionMessageUsingAddressLookupTables() should refuse to convert an AdvanceNonce instruction's nonce account from an IAccountMeta to an IAccountLookupMeta. ... getAddressMapFromInstructions() should always upgrade lookup table entries to static entries if they belong to a nonce account that is subject to an AdvanceNonce instruction.",
      "attemptedFixes" : "Introduce the concept of an incompressible account, and teach compressTransactionMessageUsingAddressLookupTables() to leave them alone. ... Make sure that createAdvanceNonceAccountInstruction() produces an AdvanceNonce instruction having an IncompressibleAccount<WritableAccount<TNonceAccountAddress>>. ... isAdvanceNonceAccountInstructionForNonce() must assert that the nonce account in an AdvanceNonce instruction has incompressible set to true.",
      "otherNotes" : "There is a world where, if we're OK with taking the hit on package efficiency to implement 4, then we can ignore all of the other changes. That is to say we can play fast and loose with whether we allow an AdvanceNonceInstruction to contain an IAccountLookupMeta knowing that eventually the transaction message compiler will ???upgrade??? it to a static entry. Thoughts? ... I just loaded this all back into my head. Know what? I don't want to do any of this. Call it a personal challenge, but I'm uncomfortable jamming nonce-related logic into general purpose functions. In the fullness of time this leads to nightmare implementations where everything is everywhere and code efficiency is low.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283331
  }, {
    "issueDTO" : {
      "id" : 3212920676,
      "title" : "[data grid] About the dropdowns in the filter selection",
      "url" : "https://github.com/mui/mui-x/issues/18737",
      "repositoryName" : "mui/mui-x",
      "description" : "### Steps to reproduce\n\nSteps:\n1. Open this link to live example: https://mui.com/x/react-data-grid/#pro-version\n2. Open **Menu** for any columns and click on **Filter**\n\n\n### Current behavior\n\n<img width=\"848\" height=\"596\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/565fa759-7d4c-4b7b-9823-99241dd2e51c\" />\n\n### Expected behavior\n\nThe title of the first dropdown should be **Column** instead of **Columns**\n\n### Context\n\nOne field title is Plural \"Columns\" and other is Singular \"Operator\". This should be consistent.\n\n### Your environment\n\n<details>\n  <summary><code>npx @mui/envinfo</code></summary>\n\n```\n  Don't forget to mention which browser you used.\n  Output from `npx @mui/envinfo` goes here.\n```\n</details>\n\n\n\n**Search keywords**: DataGrid Pro, Filters\n\n**Order ID**:",
      "updatedAt" : 1752259225.000000000,
      "user" : "viral-pasad",
      "userHtmlUrl" : "https://github.com/viral-pasad",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/178989327?v=4",
      "labels" : [ "type: bug", "feature: Filtering", "good first issue", "scope: data grid" ],
      "state" : "OPEN",
      "comments" : [ "Hey @viral-pasad,\n\nI agree with your proposal; it should indeed be consistent.\n\nSince this is fairly straightforward, I'm adding it as a good first.\n\nHere's the `diff` it could potentially be fixed with (following up with running `l10n` script):\n\n```diff\ndiff --git a/packages/x-data-grid/src/components/panel/filterPanel/GridFilterForm.tsx b/packages/x-data-grid/src/components/panel/filterPanel/GridFilterForm.tsx\nindex 44b6b89d6..85b265a01 100644\n--- a/packages/x-data-grid/src/components/panel/filterPanel/GridFilterForm.tsx\n+++ b/packages/x-data-grid/src/components/panel/filterPanel/GridFilterForm.tsx\n@@ -506,7 +506,7 @@ const GridFilterForm = forwardRef<HTMLDivElement, GridFilterFormProps>(\n           size=\"small\"\n           labelId={columnSelectLabelId}\n           id={columnSelectId}\n-          label={apiRef.current.getLocaleText('filterPanelColumns')}\n+          label={apiRef.current.getLocaleText('filterPanelColumn')}\n           value={selectedField ?? ''}\n           onChange={changeColumn}\n           native={isBaseSelectNative}\ndiff --git a/packages/x-data-grid/src/constants/localeTextConstants.ts b/packages/x-data-grid/src/constants/localeTextConstants.ts\nindex 711b94649..36f9b63aa 100644\n--- a/packages/x-data-grid/src/constants/localeTextConstants.ts\n+++ b/packages/x-data-grid/src/constants/localeTextConstants.ts\n@@ -60,7 +60,7 @@ export const GRID_DEFAULT_LOCALE_TEXT: GridLocaleText = {\n   filterPanelOperator: 'Operator',\n   filterPanelOperatorAnd: 'And',\n   filterPanelOperatorOr: 'Or',\n-  filterPanelColumns: 'Columns',\n+  filterPanelColumn: 'Column',\n   filterPanelInputLabel: 'Value',\n   filterPanelInputPlaceholder: 'Filter value',\n \ndiff --git a/packages/x-data-grid/src/models/api/gridLocaleTextApi.ts b/packages/x-data-grid/src/models/api/gridLocaleTextApi.ts\nindex b3f804b72..c5115fa42 100644\n--- a/packages/x-data-grid/src/models/api/gridLocaleTextApi.ts\n+++ b/packages/x-data-grid/src/models/api/gridLocaleTextApi.ts\n@@ -63,7 +63,7 @@ export interface GridLocaleText {\n   filterPanelOperator: React.ReactNode;\n   filterPanelOperatorAnd: React.ReactNode;\n   filterPanelOperatorOr: React.ReactNode;\n-  filterPanelColumns: React.ReactNode;\n+  filterPanelColumn: React.ReactNode;\n   filterPanelInputLabel: string;\n   filterPanelInputPlaceholder: string;\n```\n\nFeel free to open up a PR.", "Thanks @MBilalShafi . Do I need to update the translations for all locales manually or is there a script/source to do it from?" ],
      "repository" : {
        "description" : "MUI X: Build complex and data-rich applications using a growing list of advanced React components, like the Data Grid, Date and Time Pickers, Charts, and more!",
        "homepage" : "https://mui.com/x/",
        "name" : "mui-x",
        "fullName" : "mui/mui-x",
        "htmlUrl" : "https://github.com/mui/mui-x",
        "gitUrl" : "git://github.com/mui/mui-x.git",
        "sshUrl" : "git@github.com:mui/mui-x.git",
        "cloneUrl" : "https://github.com/mui/mui-x.git",
        "owner" : {
          "login" : "mui",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1502,
        "stargazersCount" : 5347,
        "watchersCount" : 5347,
        "size" : 153997,
        "openIssuesCount" : 1577,
        "subscribersCount" : 63,
        "pushedAt" : "2025-07-11T20:13:22Z",
        "languages" : {
          "TypeScript" : 10612394,
          "CSS" : 38261,
          "JavaScript" : 457194,
          "HTML" : 2266
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The title of the first dropdown should be **Column** instead of **Columns** in the filter selection of the data grid.",
      "validationOrRequirement" : "Consistent field title. One field title is Plural \"Columns\" and other is Singular \"Operator\".",
      "attemptedFixes" : "A potential fix could be fixed with the following `diff`:\n```diff\n...snip...\n```\nand running `l10n` script.",
      "otherNotes" : "Steps to reproduce: Open this link to live example: https://mui.com/x/react-data-grid/#pro-version, Open **Menu** for any columns and click on **Filter**. The title of the first dropdown should be **Column** instead of **Columns**. This should be consistent. One field title is Plural \"Columns\" and other is Singular \"Operator\".",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283337
  }, {
    "issueDTO" : {
      "id" : 3172496800,
      "title" : "Incorrect suggestions after applying fix for `WiFi -> Wi-Fi`",
      "url" : "https://github.com/Automattic/harper/issues/1450",
      "repositoryName" : "Automattic/harper",
      "description" : "## Description\n\nWhen I write the sentence \"The WiFi at the office was slow today.\" on writewithharper.com I get the suggestion to replace `WiFi` with `Wi-Fi` which seems fine, but then it starts flagging `Wi` as a typo and the `Fi at` as a potential misspelling of `Fiat` which are both false positives in that context.\n\n## Resources\n\nWi-Fi appears to be the [correct way of writing this](https://en.wikipedia.org/wiki/Wi-Fi) so I don't know what Harper could do here but it sure is annoying\n\n## Screenshots\n\n<details><summary>Initial sentence</summary>\n<p>\n\n![Image](https://github.com/user-attachments/assets/6e62a20a-a540-4b75-a39d-786d6b9d1259)\n\n</p>\n</details> \n\n<details><summary>Incorrect suggestions after the edit is applied</summary>\n<p>\n\n![Image](https://github.com/user-attachments/assets/70e4b0a8-2e05-4b64-a529-49e618b2254b)\n\n</p>\n</details> \n",
      "updatedAt" : 1752259171.000000000,
      "user" : "msfjarvis",
      "userHtmlUrl" : "https://github.com/msfjarvis",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13348378?v=4",
      "labels" : [ "bug", "harper-core", "good first issue", "linting" ],
      "state" : "OPEN",
      "comments" : [ "So far, Harper has no way to spell-check multi-word terms, whether separated by a space or a hyphen. It can suggest them as corrections however.\n\nThis is definitely going to be needed.", "It is worth noting that this isn't a multi-word term, in the sense 'Wi' and 'Fi' are not valid words on their own and shouldn't be counted as individual words in a dictionary, and this also applies to a lot of acronyms in my field like \"SR-IOV\". It seems like a tricky problem to solve! \"SR-IOV-heavy\" and \"Wi-Fi-esque\" are both syntactically valid but use the hyphen in different ways, and I don't know how to make a spellchecker handle that in a scalable way. ", "Internally in Harper a `word` does not include whitespace and can only include hyphens when they are part of identifiers in certain file formats oddly enough. In the field of linguistics, linguistics don't even like to try to define `word` because it is famously nebulous. In plain text `-` is ambiguous too since keyboard don't generally make available en dashes, em dashes, minus signs, etc. are all covered by good old `U+002D` rather than `-` `???` `???` `???` etc.\n\nThose generally would be very tricky to handle. Hyphenated words could use a sliding window or maybe even an `Expr` from the linting engine. But I don't know that area of the code very well." ],
      "repository" : {
        "description" : "Offline, privacy-first grammar checker. Fast, open-source, Rust-powered",
        "homepage" : "https://writewithharper.com",
        "name" : "harper",
        "fullName" : "Automattic/harper",
        "htmlUrl" : "https://github.com/Automattic/harper",
        "gitUrl" : "git://github.com/Automattic/harper.git",
        "sshUrl" : "git@github.com:Automattic/harper.git",
        "cloneUrl" : "https://github.com/Automattic/harper.git",
        "owner" : {
          "login" : "Automattic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 163,
        "stargazersCount" : 6837,
        "watchersCount" : 6837,
        "size" : 20206,
        "openIssuesCount" : 311,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-11T17:55:54Z",
        "languages" : {
          "C#" : 3,
          "Java" : 898,
          "CSS" : 3509,
          "C++" : 326,
          "Rust" : 1431647,
          "C" : 96,
          "HTML" : 896014,
          "Svelte" : 78564,
          "Just" : 17187,
          "Kotlin" : 5336,
          "TypeScript" : 206279,
          "Dockerfile" : 989,
          "Shell" : 1709,
          "Typst" : 3731,
          "Solidity" : 1800,
          "JavaScript" : 6424,
          "PHP" : 5271,
          "Haskell" : 918,
          "Lua" : 459,
          "Nix" : 2875,
          "Ruby" : 364,
          "Clojure" : 1865,
          "Python" : 83
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to improve the spell-checking feature in Harper to correctly handle multi-word terms and avoid flagging false positives.",
      "validationOrRequirement" : "The issue requires a solution to handle multi-word terms, including those with hyphens, in a scalable way, without flagging false positives.",
      "attemptedFixes" : "The commenter mentioned that Harper has no way to spell-check multi-word terms, and it can suggest them as corrections however. They also mentioned that it's a tricky problem to solve and suggested using a sliding window or an Expr from the linting engine.",
      "otherNotes" : "The issue is about incorrect suggestions after applying a fix for 'WiFi -> Wi-Fi' on writewithharper.com, specifically flagging 'Wi' as a typo and 'Fi at' as a potential misspelling of 'Fiat' which are both false positives in that context.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283343
  }, {
    "issueDTO" : {
      "id" : 3217919617,
      "title" : "[Term Entry] JavaScript Number methods: .EPSILON",
      "url" : "https://github.com/Codecademy/docs/issues/7313",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `.EPSILON` under number-methods in JavaScript. The entry should be in `content/javascript/concepts/number-methods/terms/EPSILON/EPSILON.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that show an example of the current entry.\n- An ## Codebyte section that have a compilable code inside it showing the current entry in use. Use ```codebyte/javascript to add compilable code.\n\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752259052.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "good first issue", "javascript" ],
      "state" : "OPEN",
      "comments" : [ "hey, could i work on this?" ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new entry for the term `.EPSILON` under number-methods in JavaScript, including a description, syntax, example, and codebyte section.",
      "validationOrRequirement" : "New term entry for existing concept entry, follow term entry template, content standards, and markdown style guide.",
      "attemptedFixes" : "",
      "otherNotes" : "Please refer to the term entry template, content standards, and markdown style guide when working on the PR for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283346
  }, {
    "issueDTO" : {
      "id" : 3203320686,
      "title" : "[FEATURE] Support Vertex AI for generation and embedding",
      "url" : "https://github.com/cocoindex-io/cocoindex/issues/691",
      "repositoryName" : "cocoindex-io/cocoindex",
      "description" : "We already have [Google Gemini integration](https://cocoindex.io/docs/ai/llm#google-gemini), which is based on [Google AI Studio API](https://ai.google.dev/gemini-api/docs/text-generation).\n\nGoogle also have Vertex API (part of Google Cloud), which is recommended for production usage based on [here](https://cloud.google.com/ai/gemini?hl=en):\n\n> [Google AI Studio](https://aistudio.google.com/?utm_source=cgc-site&utm_medium=et&utm_campaign=FY24-Q4-global-aistudio&utm_content=cgc&utm_term=-)\n> \n> **Experiment, prototype, and deploy.** Google AI Studio is the fast path for developers, students, and researchers who want to try Gemini models and get started building with the Gemini Developer API.\n> \n> [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/overview)\n> \n> **Build AI agents and integrate generative AI into your applications,** Google Cloud offers Vertex AI, a single, fully-managed, unified development platform for using Gemini models and other third party models at scale.\n\nVertex AI APIs:\n- [content generation](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference)\n- [embedding](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api)\n\nWe can use the `LlmApiType.VERTEX_AI` enum for Vertex AI API (versus `LlmApiType.GEMINI` for AI studio API. This follows similar names as [LiteLLM](https://docs.litellm.ai/docs/providers/vertex), which uses `vertex_ai/` vs `gemini/`).\n\nCode locations:\n- Existing module for various LLM APIs: https://github.com/cocoindex-io/cocoindex/tree/main/src/llm\n- Documentation to update: https://github.com/cocoindex-io/cocoindex/blob/main/docs/docs/ai/llm.mdx\n\n\n---\n?????? Contributors, please refer to \uD83D\uDCD9[Contributing Guide](https://cocoindex.io/docs/about/contributing).\nUnless the PR can be sent immediately (e.g. just a few lines of code), we recommend you to leave a comment on the issue like **`I'm working on it`**  or **`Can I work on this issue?`** to avoid duplicating work. Our [Discord server](https://discord.com/invite/zpA9S2DR7s) is always open and friendly.\n",
      "updatedAt" : 1752258829.000000000,
      "user" : "badmonster0",
      "userHtmlUrl" : "https://github.com/badmonster0",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1772842?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I can work on this!" ],
      "repository" : {
        "description" : "Data transformation framework for AI. Ultra performant, with incremental processing.",
        "homepage" : "https://cocoindex.io",
        "name" : "cocoindex",
        "fullName" : "cocoindex-io/cocoindex",
        "htmlUrl" : "https://github.com/cocoindex-io/cocoindex",
        "gitUrl" : "git://github.com/cocoindex-io/cocoindex.git",
        "sshUrl" : "git@github.com:cocoindex-io/cocoindex.git",
        "cloneUrl" : "https://github.com/cocoindex-io/cocoindex.git",
        "owner" : {
          "login" : "cocoindex-io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 149,
        "stargazersCount" : 2163,
        "watchersCount" : 2163,
        "size" : 10294,
        "openIssuesCount" : 59,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-11T20:18:49Z",
        "languages" : {
          "Rust" : 820484,
          "Python" : 180407
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement support for Vertex AI for generation and embedding, including content generation and text embeddings API",
      "validationOrRequirement" : "Use the LlmApiType.VERTEX_AI enum for Vertex AI API, similar to LiteLLM",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "Contributors should refer to the Contributing Guide and leave a comment on the issue before starting work to avoid duplicating work. The Discord server is also open for discussion.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283350
  }, {
    "issueDTO" : {
      "id" : 3220543964,
      "title" : "[Bug]: Previous menu remains open when opening another three-dot menu in the conversation list",
      "url" : "https://github.com/All-Hands-AI/OpenHands/issues/9660",
      "repositoryName" : "All-Hands-AI/OpenHands",
      "description" : "### Is there an existing issue for the same bug? (If one exists, thumbs up or comment on the issue instead).\n\n- [x] I have checked the existing issues.\n\n### Describe the bug and reproduction steps\n\n**Description**\n\nWhen interacting with the conversation list, clicking the three-dot menu on one item and then clicking the same menu on a different item does not close the previously opened menu. Instead, both menus remain open until the first one is clicked again manually.\n\n\uD83D\uDD01 **Reproducing Steps**\nOpen the Conversations list.\n\nClick on the three-dot menu (???) of any conversation item.\n\nWithout closing the first menu, click on the three-dot menu of a different conversation.\n\nObserve that the first menu remains open instead of closing automatically.\n\n??? **Expected Behavior**\nClicking on the three-dot menu of another item should automatically close any previously opened menu, ensuring only one menu is open at a time.\n\n??? **Actual Behavior**\nThe previously opened menu remains open, resulting in multiple menus being visible simultaneously. The first one only closes when manually clicked again.\n\n<img width=\"666\" height=\"948\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2347f1b5-a73e-4ede-96b2-a71217dddaff\" />\n\n### OpenHands Installation\n\nDocker command in README\n\n### OpenHands Version\n\n_No response_\n\n### Model Name\n\n_No response_\n\n### Operating System\n\nNone\n\n### Logs, Errors, Screenshots, and Additional Context\n\n_No response_",
      "updatedAt" : 1752258723.000000000,
      "user" : "Abubakar-01",
      "userHtmlUrl" : "https://github.com/Abubakar-01",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/115794090?v=4",
      "labels" : [ "bug", "good first issue", "OH UI/UX" ],
      "state" : "OPEN",
      "comments" : [ "Can I work on this issue ?" ],
      "repository" : {
        "description" : "\uD83D\uDE4C OpenHands: Code Less, Make More",
        "homepage" : "https://all-hands.dev",
        "name" : "OpenHands",
        "fullName" : "All-Hands-AI/OpenHands",
        "htmlUrl" : "https://github.com/All-Hands-AI/OpenHands",
        "gitUrl" : "git://github.com/All-Hands-AI/OpenHands.git",
        "sshUrl" : "git@github.com:All-Hands-AI/OpenHands.git",
        "cloneUrl" : "https://github.com/All-Hands-AI/OpenHands.git",
        "owner" : {
          "login" : "All-Hands-AI",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 7063,
        "stargazersCount" : 60284,
        "watchersCount" : 60284,
        "size" : 215115,
        "openIssuesCount" : 383,
        "subscribersCount" : 423,
        "pushedAt" : "2025-07-11T23:12:30Z",
        "languages" : {
          "TypeScript" : 1244258,
          "Dockerfile" : 8086,
          "Shell" : 116664,
          "Jinja" : 77246,
          "CSS" : 7010,
          "Makefile" : 15534,
          "JavaScript" : 34600,
          "HTML" : 1849,
          "Python" : 4890085
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about the previous menu remaining open when opening another three-dot menu in the conversation list, which is not the expected behavior",
      "validationOrRequirement" : "No specific requirements mentioned, but expected behavior is to automatically close previously opened menu",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments",
      "otherNotes" : "No existing issue found, installation details provided, model name and operating system not mentioned, and no logs, errors, screenshots, or additional context provided",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283353
  }, {
    "issueDTO" : {
      "id" : 834110496,
      "title" : "Exception during comparing String value - java.lang.ClassCastException: org.javers.core.metamodel.property.MissingProperty incompatible with java.lang.String",
      "url" : "https://github.com/javers/javers/issues/1076",
      "repositoryName" : "javers/javers",
      "description" : "Using Javers I created custom comparator for String value so that null and empty String treat as same value. During manual tests in private project (I cant show you code of this project) I came accross such an exception:\r\n\r\n> java.lang.ClassCastException: org.javers.core.metamodel.property.MissingProperty incompatible with java.lang.String\r\n> at .StringComparator.compare(StringComparator.java:21)\r\n> at org.javers.core.diff.custom.CustomToNativeAppenderAdapter.calculateChanges(CustomToNativeAppenderAdapter.java:33)\r\n> at org.javers.core.diff.DiffFactory.appendChanges(DiffFactory.java:153)\r\n> at org.javers.core.diff.DiffFactory.appendPropertyChanges(DiffFactory.java:143)\r\n> at org.javers.core.diff.DiffFactory.createAndAppendChanges(DiffFactory.java:125)\r\n> at org.javers.core.diff.DiffFactory.create(DiffFactory.java:69)\r\n> at org.javers.core.diff.DiffFactory.compare(DiffFactory.java:54)\r\n> at org.javers.core.JaversCore.compare(JaversCore.java:175)\r\n> ...\r\n\r\nThis is what StringComparator look like:\r\n\r\n```\r\nclass StringComparator implements CustomPropertyComparator<String, SetChange> {\r\n\r\n    StringComparator() {\r\n    }\r\n    \r\n    @Override\r\n    public Optional<SetChange> compare(String originString, String modifizierteString,\r\n            PropertyChangeMetadata propertyChangeMetadata, Property property) {\r\n        if (equals(originString, modifizierteString)) {\r\n            return Optional.empty();\r\n        } else {\r\n            final Set<Character> leftSet = getSetCharacterFromString(originString);\r\n            final Set<Character> rightSet = getSetCharacterFromString(modifizierteString);\r\n\r\n            return getSetChangeFromDiffrentSets(leftSet, rightSet, propertyChangeMetadata);\r\n        }\r\n    }\r\n\r\n    @Override\r\n    public boolean equals(String s1, String s2) {\r\n        return StringUtils.equals(StringUtils.defaultString(s1), StringUtils.defaultString(s2));\r\n    }\r\n\r\n    @Override\r\n    public String toString(String s) {\r\n        return s;\r\n    }\r\n    \r\n    private Set<Character> getSetCharacterFromString(String s) {\r\n        return !isNull(s) ? s.chars().mapToObj(c -> (char) c).collect(Collectors.toSet()) : null;\r\n    }\r\n}\r\n```\r\nCan anyone tell me whether this is a javers bug or my code bug? I think I am not able to debug it, because immediately throws exception.\r\n\r\n**Javers' Version**\r\n5.14\r\n\r\n",
      "updatedAt" : 1752258381.000000000,
      "user" : "ArkadiuszBlejwas",
      "userHtmlUrl" : "https://github.com/ArkadiuszBlejwas",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/52347840?v=4",
      "labels" : [ "bug", "test case required", "good first issue", "contribution wanted" ],
      "state" : "OPEN",
      "comments" : [ "21 line:\r\n`class StringComparator implements CustomPropertyComparator<String, SetChange> {`", "looks like a bug in javers, it probably happens when you compare two objects with different type definition but the same type name", "@ArkadiuszBlejwas consider contributing a PR with the fix, there are lot of issues here and one only maintainer", "@bartoszwalacik I want to contribute but you should take into account that I have little professional experience in programming. I can try find bug but I promise nothing.", "Arkadiusz, if you want to became a professional developer, you have to learn how to use google :)\r\nhttps://www.google.com/search?q=what+is+pr+github", "@bartoszwalacik I will try debug this problem in next weekend, ok? I have also an idea for new features in javers. If you will like them, I will be happy to implement them.", "Is `getSetChangeFromDiffrentSets` supposed to be some already existing library method? Or is it lacking from the example?", "`getSetChangeFromDiffrentSets` isn't a javers method", "we need a working test case , see https://github.com/javers/javers/blob/master/CONTRIBUTING.md#guidelines-for-bug-reporting", "Hi @bartoszwalacik and team,\n\nAfter deeper analysis, this appears to be a design issue where:\n- The `CustomPropertyComparator<T>` contract implies type safety\n- But JaVers passes `MissingProperty` (breaking the contract)\n\n@bartoszwalacik Would you accept a PR that either:\n\nAuto-converts MissingProperty to null before comparison, or\n\nAt least documents this requirement prominently?\n", "Hi @AneenaThasneem , converting MissingProperty to null before passing it to CustomComparator seems like a good idea. This is a Javers internal thing , it shouldn't leak into user's code. Feel free to contribute a PR, I will merge, thanks." ],
      "repository" : {
        "description" : "JaVers - object auditing and diff framework for Java",
        "homepage" : "http://javers.org",
        "name" : "javers",
        "fullName" : "javers/javers",
        "htmlUrl" : "https://github.com/javers/javers",
        "gitUrl" : "git://github.com/javers/javers.git",
        "sshUrl" : "git@github.com:javers/javers.git",
        "cloneUrl" : "https://github.com/javers/javers.git",
        "owner" : {
          "login" : "javers",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 369,
        "stargazersCount" : 1483,
        "watchersCount" : 1483,
        "size" : 9460,
        "openIssuesCount" : 84,
        "subscribersCount" : 42,
        "pushedAt" : "2025-05-24T17:43:32Z",
        "languages" : {
          "Java" : 1309952,
          "Shell" : 618,
          "Groovy" : 875381
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about an exception thrown during comparing String value in Javers, specifically a ClassCastException: org.javers.core.metamodel.property.MissingProperty incompatible with java.lang.String.",
      "validationOrRequirement" : "The CustomPropertyComparator<T> contract implies type safety, but Javers passes MissingProperty, which breaks the contract.",
      "attemptedFixes" : "Several contributors have suggested fixes, including auto-converting MissingProperty to null before comparison or documenting the requirement prominently.",
      "otherNotes" : "This issue is related to a design issue in Javers where it passes MissingProperty which breaks the type safety contract of CustomPropertyComparator.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283358
  }, {
    "issueDTO" : {
      "id" : 3217306380,
      "title" : "Delegate `delete` to JUnit",
      "url" : "https://github.com/apache/iceberg/issues/13506",
      "repositoryName" : "apache/iceberg",
      "description" : "### Feature Request / Improvement\n\nFor the `TestParquetVectorizedReads` we delete the temp directory by hand:\n\nhttps://github.com/apache/iceberg/blob/c71e3eb4d0b4674758d1ed3c196fac9aed3c9ac2/spark/v3.5/spark/src/test/java/org/apache/iceberg/spark/data/vectorized/parquet/TestParquetVectorizedReads.java#L347-L348\n\nI think we should delegate that to JUnit since it distracts from the essence of the test: https://www.baeldung.com/junit-5-temporary-directory\n\n\n### Query engine\n\nNone\n\n### Willingness to contribute\n\n- [ ] I can contribute this improvement/feature independently\n- [ ] I would be willing to contribute this improvement/feature with guidance from the Iceberg community\n- [ ] I cannot contribute this improvement/feature at this time",
      "updatedAt" : 1752258169.000000000,
      "user" : "Fokko",
      "userHtmlUrl" : "https://github.com/Fokko",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1134248?v=4",
      "labels" : [ "improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hi @Fokko! I would like to work on this issue \nEdit: I would be willing to contribute this improvement/feature with guidance from the Iceberg community\n", "@saumyapandey1998 We can change the logic to create a file under `temp` directory something like:\n```java\n    File testFile = File.createTempFile(\"junit\", null, temp.toFile());\n    assertThat(testFile.delete()).as(\"Delete should succeed\").isTrue();\n```\n???\n```java\n    File testFile = temp.resolve(\"parquet\").toFile();\n```", "@ebyhr Thank you! I am looking at the code and setting it up on my system \nI will get back to you if I have questions", "Its me. I'm the one who was confused :)", "Hi @ebyhr! I keep running into the following error while trying to build the project:\n`\nA problem occurred configuring root project 'iceberg'.\n> Could not resolve all artifacts for configuration 'classpath'.\n   > Could not resolve com.gradleup.shadow:shadow-gradle-plugin:8.3.8.\n     Required by:\n         root project :\n      > Could not resolve com.gradleup.shadow:shadow-gradle-plugin:8.3.8.\n         > Could not get resource 'https://plugins.gradle.org/m2/com/gradleup/shadow/shadow-gradle-plugin/8.3.8/shadow-gradle-plugin-8.3.8.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/com/gradleup/shadow/shadow-gradle-plugin/8.3.8/shadow-gradle-plugin-8.3.8.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve com.palantir.baseline:gradle-baseline-java:5.72.0.\n     Required by:\n         root project :\n      > Could not resolve com.palantir.baseline:gradle-baseline-java:5.72.0.\n         > Could not get resource 'https://plugins.gradle.org/m2/com/palantir/baseline/gradle-baseline-java/5.72.0/gradle-baseline-java-5.72.0.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/com/palantir/baseline/gradle-baseline-java/5.72.0/gradle-baseline-java-5.72.0.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve com.diffplug.spotless:spotless-plugin-gradle:6.25.0.\n     Required by:\n         root project :\n      > Could not resolve com.diffplug.spotless:spotless-plugin-gradle:6.25.0.\n         > Could not get resource 'https://plugins.gradle.org/m2/com/diffplug/spotless/spotless-plugin-gradle/6.25.0/spotless-plugin-gradle-6.25.0.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/com/diffplug/spotless/spotless-plugin-gradle/6.25.0/spotless-plugin-gradle-6.25.0.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve gradle.plugin.org.inferred:gradle-processors:3.7.0.\n     Required by:\n         root project :\n      > Could not resolve gradle.plugin.org.inferred:gradle-processors:3.7.0.\n         > Could not get resource 'https://plugins.gradle.org/m2/gradle/plugin/org/inferred/gradle-processors/3.7.0/gradle-processors-3.7.0.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/gradle/plugin/org/inferred/gradle-processors/3.7.0/gradle-processors-3.7.0.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve me.champeau.jmh:jmh-gradle-plugin:0.7.3.\n     Required by:\n         root project :\n      > Could not resolve me.champeau.jmh:jmh-gradle-plugin:0.7.3.\n         > Could not get resource 'https://plugins.gradle.org/m2/me/champeau/jmh/jmh-gradle-plugin/0.7.3/jmh-gradle-plugin-0.7.3.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/me/champeau/jmh/jmh-gradle-plugin/0.7.3/jmh-gradle-plugin-0.7.3.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve gradle.plugin.io.morethan.jmhreport:gradle-jmh-report:0.9.6.\n     Required by:\n         root project :\n      > Could not resolve gradle.plugin.io.morethan.jmhreport:gradle-jmh-report:0.9.6.\n         > Could not get resource 'https://plugins.gradle.org/m2/gradle/plugin/io/morethan/jmhreport/gradle-jmh-report/0.9.6/gradle-jmh-report-0.9.6.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/gradle/plugin/io/morethan/jmhreport/gradle-jmh-report/0.9.6/gradle-jmh-report-0.9.6.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve com.github.alisiikh:gradle-scalastyle-plugin:3.5.0.\n     Required by:\n         root project :\n      > Could not resolve com.github.alisiikh:gradle-scalastyle-plugin:3.5.0.\n         > Could not get resource 'https://plugins.gradle.org/m2/com/github/alisiikh/gradle-scalastyle-plugin/3.5.0/gradle-scalastyle-plugin-3.5.0.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/com/github/alisiikh/gradle-scalastyle-plugin/3.5.0/gradle-scalastyle-plugin-3.5.0.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve org.revapi:gradle-revapi:1.8.0.\n     Required by:\n         root project :\n      > Could not resolve org.revapi:gradle-revapi:1.8.0.\n         > Could not get resource 'https://plugins.gradle.org/m2/org/revapi/gradle-revapi/1.8.0/gradle-revapi-1.8.0.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/org/revapi/gradle-revapi/1.8.0/gradle-revapi-1.8.0.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve com.gorylenko.gradle-git-properties:gradle-git-properties:2.5.0.\n     Required by:\n         root project :\n      > Could not resolve com.gorylenko.gradle-git-properties:gradle-git-properties:2.5.0.\n         > Could not get resource 'https://plugins.gradle.org/m2/com/gorylenko/gradle-git-properties/gradle-git-properties/2.5.0/gradle-git-properties-2.5.0.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/com/gorylenko/gradle-git-properties/gradle-git-properties/2.5.0/gradle-git-properties-2.5.0.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve com.palantir.gradle.gitversion:gradle-git-version:3.4.0.\n     Required by:\n         root project :\n      > Could not resolve com.palantir.gradle.gitversion:gradle-git-version:3.4.0.\n         > Could not get resource 'https://plugins.gradle.org/m2/com/palantir/gradle/gitversion/gradle-git-version/3.4.0/gradle-git-version-3.4.0.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/com/palantir/gradle/gitversion/gradle-git-version/3.4.0/gradle-git-version-3.4.0.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n   > Could not resolve org.openapitools:openapi-generator-gradle-plugin:7.14.0.\n     Required by:\n         root project :\n      > Could not resolve org.openapitools:openapi-generator-gradle-plugin:7.14.0.\n         > Could not get resource 'https://plugins.gradle.org/m2/org/openapitools/openapi-generator-gradle-plugin/7.14.0/openapi-generator-gradle-plugin-7.14.0.pom'.\n            > Could not GET 'https://plugins.gradle.org/m2/org/openapitools/openapi-generator-gradle-plugin/7.14.0/openapi-generator-gradle-plugin-7.14.0.pom'.\n               > Got socket exception during request. It might be caused by SSL misconfiguration\n                  > Broken pipe\n`\n\nAny pointers of what I could be doing wrong?" ],
      "repository" : {
        "description" : "Apache Iceberg",
        "homepage" : "https://iceberg.apache.org/",
        "name" : "iceberg",
        "fullName" : "apache/iceberg",
        "htmlUrl" : "https://github.com/apache/iceberg",
        "gitUrl" : "git://github.com/apache/iceberg.git",
        "sshUrl" : "git@github.com:apache/iceberg.git",
        "cloneUrl" : "https://github.com/apache/iceberg.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2663,
        "stargazersCount" : 7701,
        "watchersCount" : 7701,
        "size" : 96359,
        "openIssuesCount" : 600,
        "subscribersCount" : 180,
        "pushedAt" : "2025-07-11T23:04:08Z",
        "languages" : {
          "Java" : 38464163,
          "Dockerfile" : 1815,
          "Shell" : 22999,
          "CSS" : 13577,
          "ANTLR" : 27852,
          "Scala" : 645351,
          "Makefile" : 2614,
          "JavaScript" : 7255,
          "HTML" : 19904,
          "Python" : 50413
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Delegate `delete` to JUnit and resolve Gradle plugin dependencies and SSL misconfiguration issues in the Apache Iceberg repository.",
      "validationOrRequirement" : "The issue requires the ability to resolve Gradle plugin dependencies and fix SSL misconfiguration issues.",
      "attemptedFixes" : "The author and others have tried to resolve the Gradle plugin dependencies and SSL issues, but it seems that the problem persists.",
      "otherNotes" : "The issue is about delegating the deletion of a temp directory to JUnit, and there are also some issues with Gradle plugin dependencies and SSL misconfiguration.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283362
  }, {
    "issueDTO" : {
      "id" : 3217227607,
      "title" : "Resolve `BXXX` series ignored Ruff rules",
      "url" : "https://github.com/beeware/briefcase/issues/2381",
      "repositoryName" : "beeware/briefcase",
      "description" : "### What is the problem or limitation you are having?\n\nWhen Ruff was enabled, for review purposes, the identified errors were globally ignored, with the intention of resolving them in subsequent PRs.\n\n### Describe the solution you'd like\n\nThis repo currently ignores the following rules from the `BXXX` series:\n* `B007`\n* `B018`\n* `B019`\n* `B024`\n* `B027`\n* `B904`\n\nWork through the issues as follows:\n1. Comment out each error number in the `ignore` list found [here](https://github.com/beeware/briefcase/blob/1ffd045752d3a3d920a68d920201d890e8637e49/pyproject.toml#L257-L262).\n2. Run `pre-commit run -a` to run the checks.\n3. Work through each of the errors in the result until they are all resolved.\n4. `pre-commit run -a` should pass without the errors in the `ignore` list.\n5. Remove the `BXXX` series of rules from the `ignore` list.\n6. If this is the last of the errors in the `ignore` list, remove the [`ignore` list](https://github.com/beeware/briefcase/blob/1ffd045752d3a3d920a68d920201d890e8637e49/pyproject.toml#L251-L267) completely, including the comment above.\n7. Submit the PR.\n\n### Describe alternatives you've considered\n\nNone.\n\n### Additional context\n\nThe `SIMXXX` checks are explicitly disabled in the configuration. Do not remove the commented out `SIM` check, and avoid resolving the `SIMXXX` errors.",
      "updatedAt" : 1752257847.000000000,
      "user" : "kattni",
      "userHtmlUrl" : "https://github.com/kattni",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7865090?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'm having a little look at these, if that's ok!" ],
      "repository" : {
        "description" : "Tools to support converting a Python project into a standalone native application.",
        "homepage" : "https://briefcase.readthedocs.io/",
        "name" : "briefcase",
        "fullName" : "beeware/briefcase",
        "htmlUrl" : "https://github.com/beeware/briefcase",
        "gitUrl" : "git://github.com/beeware/briefcase.git",
        "sshUrl" : "git@github.com:beeware/briefcase.git",
        "cloneUrl" : "https://github.com/beeware/briefcase.git",
        "owner" : {
          "login" : "beeware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 424,
        "stargazersCount" : 2978,
        "watchersCount" : 2978,
        "size" : 12676,
        "openIssuesCount" : 181,
        "subscribersCount" : 48,
        "pushedAt" : "2025-07-12T00:58:14Z",
        "languages" : {
          "Python" : 3066398
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Resolve the BXXX series ignored Ruff rules by working through the issues and removing the ignore list once all errors are resolved.",
      "validationOrRequirement" : "Comment out each error number in the ignore list, run pre-commit run -a, work through each of the errors in the result until they are all resolved, and then remove the BXXX series of rules from the ignore list.",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "The SIMXXX checks are explicitly disabled in the configuration. Do not remove the commented out SIM check, and avoid resolving the SIMXXX errors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283367
  }, {
    "issueDTO" : {
      "id" : 3223785312,
      "title" : "[New Docs]: Stackblitz previews",
      "url" : "https://github.com/ngrx/platform/issues/4878",
      "repositoryName" : "ngrx/platform",
      "description" : "### Information\n\nIn our documentation we use stackblitz examples using the `live-example` component. For example:\n\n```\n1.  Generate a new project using StackBlitz <live-example name=\"ngrx-start\" noDownload></live-example> ....\n```\n\nBut, because that component doesn't exist, the link doesn't get rendered:\n\n<img width=\"1509\" height=\"1152\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8e0fd881-82d8-4ce4-90b1-ad5b75b40844\" />\n\nWe need to create a preview component in the new docs (www) and use the component to render the links. As a result, the new docs shouldn't contain references to `live-example` anymore.\n\n### Documentation page\n\nhttps://deploy-preview-4821--ngrx-site-v19.netlify.app/guide/store/walkthrough\n\n### I would be willing to submit a PR to fix this issue\n\n- [ ] Yes\n- [ ] No",
      "updatedAt" : 1752257286.000000000,
      "user" : "timdeschryver",
      "userHtmlUrl" : "https://github.com/timdeschryver",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/28659384?v=4",
      "labels" : [ "Good First Issue", "Accepting PRs", "New Docs" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Reactive State for Angular",
        "homepage" : "https://ngrx.io",
        "name" : "platform",
        "fullName" : "ngrx/platform",
        "htmlUrl" : "https://github.com/ngrx/platform",
        "gitUrl" : "git://github.com/ngrx/platform.git",
        "sshUrl" : "git@github.com:ngrx/platform.git",
        "cloneUrl" : "https://github.com/ngrx/platform.git",
        "owner" : {
          "login" : "ngrx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2026,
        "stargazersCount" : 8230,
        "watchersCount" : 8230,
        "size" : 29922,
        "openIssuesCount" : 70,
        "subscribersCount" : 212,
        "pushedAt" : "2025-07-11T18:00:21Z",
        "languages" : {
          "TypeScript" : 4753036,
          "Dockerfile" : 264,
          "Shell" : 11532,
          "CSS" : 1354,
          "SCSS" : 131010,
          "JavaScript" : 381092,
          "HTML" : 84543
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a preview component in the new docs (www) to render StackBlitz links and remove references to `live-example` component.",
      "validationOrRequirement" : "Create a preview component in the new docs (www) and use it to render the links.",
      "attemptedFixes" : "None mentioned in the description.",
      "otherNotes" : "The issue is related to documentation and the use of StackBlitz examples, specifically the `live-example` component which doesn't exist.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283370
  }, {
    "issueDTO" : {
      "id" : 3223776499,
      "title" : "[New Docs]: Code tabs",
      "url" : "https://github.com/ngrx/platform/issues/4877",
      "repositoryName" : "ngrx/platform",
      "description" : "### Information\n\nThe docs contain `code` tabs components to show multiple code files.\nThis was supported on ngrx.io:\n\n<img width=\"1641\" height=\"889\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/088f58d3-36a1-4754-a0a3-55e38ab54726\" />\n\nFor the new docs (www), we don't have a tabs component.\nWe should create one, or just split the code snippets for now.\n\nThe result of this issue is that:\n\n- a) there is a code tabs component\n- b) or, we remove the code tabs in the markdown files \n\n### Documentation page\n\nhttps://deploy-preview-4875--ngrx-site-v19.netlify.app/guide/signals/signal-state\n\n### I would be willing to submit a PR to fix this issue\n\n- [ ] Yes\n- [ ] No",
      "updatedAt" : 1752257055.000000000,
      "user" : "timdeschryver",
      "userHtmlUrl" : "https://github.com/timdeschryver",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/28659384?v=4",
      "labels" : [ "Good First Issue", "Accepting PRs", "New Docs" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Reactive State for Angular",
        "homepage" : "https://ngrx.io",
        "name" : "platform",
        "fullName" : "ngrx/platform",
        "htmlUrl" : "https://github.com/ngrx/platform",
        "gitUrl" : "git://github.com/ngrx/platform.git",
        "sshUrl" : "git@github.com:ngrx/platform.git",
        "cloneUrl" : "https://github.com/ngrx/platform.git",
        "owner" : {
          "login" : "ngrx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2026,
        "stargazersCount" : 8230,
        "watchersCount" : 8230,
        "size" : 29922,
        "openIssuesCount" : 70,
        "subscribersCount" : 212,
        "pushedAt" : "2025-07-11T18:00:21Z",
        "languages" : {
          "TypeScript" : 4753036,
          "Dockerfile" : 264,
          "Shell" : 11532,
          "CSS" : 1354,
          "SCSS" : 131010,
          "JavaScript" : 381092,
          "HTML" : 84543
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to create a code tabs component for the new docs (www) or to remove the code tabs in the markdown files.",
      "validationOrRequirement" : "There are no specific validations or requirements mentioned in the description.",
      "attemptedFixes" : "The author is willing to submit a PR to fix this issue, and there are no attempted fixes or blockers mentioned in the description.",
      "otherNotes" : "The issue is related to the new docs (www) and the lack of a code tabs component, which was supported on ngrx.io. The description also mentions an alternative solution to split the code snippets for now.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283374
  }, {
    "issueDTO" : {
      "id" : 930869193,
      "title" : "Cache directory location does not adhere to the XDG Base Directory specification.",
      "url" : "https://github.com/python-cachier/cachier/issues/61",
      "repositoryName" : "python-cachier/cachier",
      "description" : "See the [XDG Base directory specification](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html)\r\n\r\nSounds like `$XDG_CACHE_HOME/cachier` should be used if the `XDG_CACHE_HOME` environment variable is defined.\r\n\r\nBy the way, this is a good first issue for any first time contributor.\r\n",
      "updatedAt" : 1752257022.000000000,
      "user" : "shaypal5",
      "userHtmlUrl" : "https://github.com/shaypal5",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/917954?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @shaypal5 ! \uD83D\uDE04\n\nThis looks like a good first issue, and I'd love to work on it. Could you please assign it to me?\n\nLet me know if there are any specific guidelines or requirements before I submit a PR.\n\nThanks!\n", "Hey Habib! :)\n\nGreat pick! \uD83D\uDCAA\uD83C\uDFFD\nI've assigned the issue to you.\n\nFor guidelines on contributing you can read:\n1. The section of the README about contribution:\nhttps://github.com/python-cachier/cachier?tab=readme-ov-file#contributing\n\n2. The instructions file for Claude:\n[CLAUDE.md](https://github.com/python-cachier/cachier/blob/master/CLAUDE.md)\n\n3. The instructions file for CoPilot:\nhttps://github.com/python-cachier/cachier/blob/master/.github/copilot-instructions.md\n\nGood luck, and let me know how I can help,\nShay" ],
      "repository" : {
        "description" : "Persistent, stale-free, local and cross-machine caching for Python functions.",
        "homepage" : "",
        "name" : "cachier",
        "fullName" : "python-cachier/cachier",
        "htmlUrl" : "https://github.com/python-cachier/cachier",
        "gitUrl" : "git://github.com/python-cachier/cachier.git",
        "sshUrl" : "git@github.com:python-cachier/cachier.git",
        "cloneUrl" : "https://github.com/python-cachier/cachier.git",
        "owner" : {
          "login" : "python-cachier",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 68,
        "stargazersCount" : 601,
        "watchersCount" : 601,
        "size" : 471,
        "openIssuesCount" : 19,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-11T12:53:52Z",
        "languages" : {
          "Python" : 159135
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to ensure that the cache directory location in the python-cachier project adheres to the XDG Base Directory specification.",
      "validationOrRequirement" : "The cache directory location should adhere to the XDG Base Directory specification.",
      "attemptedFixes" : "None mentioned in the comments or description.",
      "otherNotes" : "The issue is a good first issue for any first time contributor and has been assigned to a contributor. There are guidelines for contributing available in the README, CLAUDE.md and .github/copilot-instructions.md files.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283378
  }, {
    "issueDTO" : {
      "id" : 3223765060,
      "title" : "[New Docs]: code-example styling",
      "url" : "https://github.com/ngrx/platform/issues/4876",
      "repositoryName" : "ngrx/platform",
      "description" : "### Information\n\nThere seems to be too much padding/margin to code samples that use a header.\n\n<img width=\"1318\" height=\"296\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5e7f9070-d77c-40f3-a435-c18bb2beb7a9\" />\n\n\n### Documentation page\n\nhttps://deploy-preview-4875--ngrx-site-v19.netlify.app/guide/component-store/usage\n\n### I would be willing to submit a PR to fix this issue\n\n- [ ] Yes\n- [ ] No",
      "updatedAt" : 1752256737.000000000,
      "user" : "timdeschryver",
      "userHtmlUrl" : "https://github.com/timdeschryver",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/28659384?v=4",
      "labels" : [ "Good First Issue", "Accepting PRs", "New Docs" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Reactive State for Angular",
        "homepage" : "https://ngrx.io",
        "name" : "platform",
        "fullName" : "ngrx/platform",
        "htmlUrl" : "https://github.com/ngrx/platform",
        "gitUrl" : "git://github.com/ngrx/platform.git",
        "sshUrl" : "git@github.com:ngrx/platform.git",
        "cloneUrl" : "https://github.com/ngrx/platform.git",
        "owner" : {
          "login" : "ngrx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2026,
        "stargazersCount" : 8230,
        "watchersCount" : 8230,
        "size" : 29922,
        "openIssuesCount" : 70,
        "subscribersCount" : 212,
        "pushedAt" : "2025-07-11T18:00:21Z",
        "languages" : {
          "TypeScript" : 4753036,
          "Dockerfile" : 264,
          "Shell" : 11532,
          "CSS" : 1354,
          "SCSS" : 131010,
          "JavaScript" : 381092,
          "HTML" : 84543
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix code-example styling in documentation with excessive padding/margin in code samples that use a header.",
      "validationOrRequirement" : "Code-example styling in documentation with no excessive padding/margin in code samples that use a header.",
      "attemptedFixes" : "",
      "otherNotes" : "Issue is related to code-example styling in documentation with excessive padding/margin in code samples that use a header. A PR is willing to be submitted to fix this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283381
  }, {
    "issueDTO" : {
      "id" : 3206444684,
      "title" : "[Bug] [Cloud Security] Missing loading indicator for misconfigurations and vulenrabilities in the expanded flyout",
      "url" : "https://github.com/elastic/kibana/issues/226694",
      "repositoryName" : "elastic/kibana",
      "description" : "**Issue**\n\n<!-- Why are we doing this task? what it the value to the user. -->\nWhen expanding a flyout to check related misconfigurations of an asset, a loading indicator is missing.\n\nhttps://github.com/user-attachments/assets/a4a2a140-be79-4eb5-b3c0-06937e97a0ed\n\n**Steps to reproduce**\n- Go into asset inventory\n- Open a flyout with missconfigurations\n- Expand the flyout\n\n**Expected:** A table's loading indicator is shown while loading the missconfigurations\n**Actual:** No data message is shown, after few moments it is replaced with missconfigurations data\n\n**Kibana version:** `9.1.0 BC1`\n**Integration version:** `0.21.0`",
      "updatedAt" : 1752256593.000000000,
      "user" : "kfirpeled",
      "userHtmlUrl" : "https://github.com/kfirpeled",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/61654899?v=4",
      "labels" : [ "bug", "Team:Cloud Security", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Pinging @elastic/kibana-cloud-security-posture (Team:Cloud Security)", "Please add a UT to check these scenarios both in vulnerabilities and misconfigurations", "Hello can you please assign me this issue? Thanks!\n\n", "> Hello can you please assign me this issue? Thanks!\n\nHi @zk2k2, I just assigned you. Thanks for your interest in taking a look at this issue. ", "I can work on it, if the issue is still there. :)", "Hey @itsagrox ! Just wanted to let you know I???ve already started working on this one. Thanks for checking in though, I???ll keep you posted if I need any help we can work on it together!", "Hi @opauloh, could you please take a look at the PR I just submitted? Let me know if I need to change anything, thanks!", "> Hi [@opauloh](https://github.com/opauloh), could you please take a look at the PR I just submitted? Let me know if I need to change anything, thanks!\n\nThanks for getting back to me @zk2k2! The PR looks good, and I have added the appropriate labels. I only need you to sign the [Contributor agreement](https://www.elastic.co/contributor-agreement) acknowledging that your code is open source before merging it." ],
      "repository" : {
        "description" : "Your window into the Elastic Stack",
        "homepage" : "https://www.elastic.co/products/kibana",
        "name" : "kibana",
        "fullName" : "elastic/kibana",
        "htmlUrl" : "https://github.com/elastic/kibana",
        "gitUrl" : "git://github.com/elastic/kibana.git",
        "sshUrl" : "git@github.com:elastic/kibana.git",
        "cloneUrl" : "https://github.com/elastic/kibana.git",
        "owner" : {
          "login" : "elastic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 8393,
        "stargazersCount" : 20574,
        "watchersCount" : 20574,
        "size" : 10549670,
        "openIssuesCount" : 13302,
        "subscribersCount" : 845,
        "pushedAt" : "2025-07-12T00:03:43Z",
        "languages" : {
          "MDX" : 2692507,
          "CSS" : 205865,
          "Standard ML" : 3033,
          "Handlebars" : 36535,
          "Makefile" : 5205,
          "HTML" : 19095,
          "Perl" : 12381,
          "Nunjucks" : 118640,
          "EJS" : 12706,
          "TypeScript" : 255927723,
          "Dockerfile" : 15257,
          "Shell" : 432108,
          "Starlark" : 40163,
          "PEG.js" : 20672,
          "Batchfile" : 5169,
          "ANTLR" : 41968,
          "SCSS" : 127063,
          "JavaScript" : 8674841,
          "Python" : 7624
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Missing loading indicator for misconfigurations and vulnerabilities in the expanded flyout",
      "validationOrRequirement" : "UT to check scenarios in vulnerabilities and misconfigurations, Contributor agreement",
      "attemptedFixes" : "PR submitted, UT to check scenarios in vulnerabilities and misconfigurations",
      "otherNotes" : "The issue is related to a missing loading indicator when expanding a flyout to check related misconfigurations of an asset. The expected behavior is to show a table's loading indicator while loading the misconfigurations, but instead, a no data message is shown and later replaced with the misconfigurations data.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283386
  }, {
    "issueDTO" : {
      "id" : 3208869878,
      "title" : "[MCP] Formstack",
      "url" : "https://github.com/activepieces/activepieces/issues/8286",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview\n\nFormstack is a powerful online forms, documents, and eSignature platform for automating data collection and workflows.  \nThis integration enables AI agents and workflows to collect, manage, and process form submissions, documents, and approvals automatically.\n\n---\n\n## ?????? Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## \uD83D\uDEA8 Triggers\n\n| **Trigger** | **Use Case** |\n|-------------|---------------|\n| **New Submission** | Fires when a new submission is received for a specific form. |\n| **New Form** | Fires when a new form is created in the account. |\n\n---\n\n## \uD83D\uDEE0??? Write Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Create Submission** | Programmatically submit data to a Formstack form. Useful for integrating external data sources into forms. |\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Action Item** | **Use Case** |\n|-----------------|---------------|\n| **Find Form by Name or ID** | Locate a specific form for submissions or updates. |\n| **Get Submission Details** | Fetch details of a specific submission by its ID. |\n| **Find Submission by Field Value** | Search for a submission based on field values (e.g., email, name). |\n\n---\n\n## \uD83D\uDCDA API Reference\n\n- [Official Formstack API Documentation](https://developers.formstack.com/)\n\n---\n\n## \uD83E\uDDEA Test Account Access\n\nYou can test Formstack APIs by creating a free trial account at [Formstack](https://www.formstack.com/) and generating an API token from your account settings.\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
      "updatedAt" : 1752256478.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "good first issue", "$50" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-807/mcp-formstack\">AP-807 [MCP] Formstack</a></p>", "/bounty $50", "## \uD83D\uDC8E $50 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8286` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8286` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @krushnarout | Jul 07, 2025, 12:54:25 PM | WIP |  |\n| \uD83D\uDFE2 @Sanket6652 | Jul 07, 2025, 01:21:45 PM | #8295 | [Reward](https://algora.io/claims/xDp1wrQrYUGoiuWU) |\n| \uD83D\uDFE2 @MayorChristopher | Jul 09, 2025, 09:45:51 AM | WIP |  |", "/attempt #8286\n", "/attempt #8286" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2193,
        "stargazersCount" : 15771,
        "watchersCount" : 15771,
        "size" : 300248,
        "openIssuesCount" : 388,
        "subscribersCount" : 96,
        "pushedAt" : "2025-07-11T13:16:13Z",
        "languages" : {
          "TypeScript" : 13976520,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 71760,
          "Shell" : 3862,
          "JavaScript" : 12636,
          "HTML" : 212998
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to integrate Formstack with Activepieces, enabling AI agents and workflows to collect, manage, and process form submissions, documents, and approvals automatically.",
      "validationOrRequirement" : "The feature must be submitted as a Piece following the Activepieces architecture, with specific requirements for consistency and maintainability. The contributor needs to review the Piece Development Guidelines before starting development.",
      "attemptedFixes" : "The issue has been attempted by @krushnarout, @Sanket6652, and @MayorChristopher, with @Sanket6652 claiming the bounty and creating a pull request #8295.",
      "otherNotes" : "The issue is about integrating Formstack with Activepieces, with specific requirements for submissions, forms, and approvals. There are multiple triggers and actions available for this integration. The issue has a $50 bounty and has been attempted by several contributors. The contributor needs to provide a short demo video of their changes in the pull request.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283392
  }, {
    "issueDTO" : {
      "id" : 3223467012,
      "title" : "Mismatched return type for Scene.clampToHeight, sampleHeight, and clampToHeightMostDetailed",
      "url" : "https://github.com/CesiumGS/cesium/issues/12729",
      "repositoryName" : "CesiumGS/cesium",
      "description" : "### What happened?\n\nReturn type for [Scene.clampToHeight](https://cesium.com/learn/ion-sdk/ref-doc/Scene.html?classFilter=Scene#clampToHeight) does not match description.  Description indicates that it may return `undefined` but return type is listed as `Cartesian3` and not `Cartesian3|undefined`.   This can also cause issues in Typescript since the return type does not include `undefined`\n\n<img width=\"1361\" height=\"287\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/901c7f59-7c64-4e78-bd71-54d7cecb5d47\" />\n\nSame issue with missing `undefined` for\n- [clampToHeightMostDetailed](https://cesium.com/learn/ion-sdk/ref-doc/Scene.html#clampToHeightMostDetailed)\n- [sampleHeight](https://cesium.com/learn/ion-sdk/ref-doc/Scene.html#sampleHeight)\n\n\n### Reproduction steps\n\n_No response_\n\n### Sandcastle example\n\n_No response_\n\n### Environment\n\n_No response_",
      "updatedAt" : 1752256441.000000000,
      "user" : "angrycat9000",
      "userHtmlUrl" : "https://github.com/angrycat9000",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/48362463?v=4",
      "labels" : [ "type - bug", "category - typescript", "category - doc", "needs triage", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "There are more (many) places where `undefined` is not mentioned explicitly (some are listed in https://github.com/CesiumGS/cesium/issues/11749#issuecomment-1950184016 and further comments there)" ],
      "repository" : {
        "description" : "An open-source JavaScript library for world-class 3D globes and maps :earth_americas:",
        "homepage" : "https://cesium.com/cesiumjs/",
        "name" : "cesium",
        "fullName" : "CesiumGS/cesium",
        "htmlUrl" : "https://github.com/CesiumGS/cesium",
        "gitUrl" : "git://github.com/CesiumGS/cesium.git",
        "sshUrl" : "git@github.com:CesiumGS/cesium.git",
        "cloneUrl" : "https://github.com/CesiumGS/cesium.git",
        "owner" : {
          "login" : "CesiumGS",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3625,
        "stargazersCount" : 13887,
        "watchersCount" : 13887,
        "size" : 774803,
        "openIssuesCount" : 1502,
        "subscribersCount" : 479,
        "pushedAt" : "2025-07-11T21:37:18Z",
        "languages" : {
          "TypeScript" : 11079,
          "CSS" : 55918,
          "JavaScript" : 22706174,
          "HTML" : 1959018,
          "GLSL" : 537864,
          "Python" : 4899
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Mismatched return type for Scene.clampToHeight, sampleHeight, and clampToHeightMostDetailed",
      "validationOrRequirement" : "Return type should match description, including `undefined`",
      "attemptedFixes" : "No response",
      "otherNotes" : "There are more (many) places where `undefined` is not mentioned explicitly",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283395
  }, {
    "issueDTO" : {
      "id" : 3205704728,
      "title" : "Add citation count field (including semantic scholar fetcher)",
      "url" : "https://github.com/JabRef/jabref/issues/13477",
      "repositoryName" : "JabRef/jabref",
      "description" : "### \uD83D\uDD0D Motivation\n\nCitation count provides a useful indicator of the academic impact of a publication. Automating the population of this field from Semantic Scholar saves manual effort and enhances bibliographic data quality in JabRef.\n\n### \uD83D\uDCCC Goal\n\nExtend the existing `SemanticScholarCitationFetcher` to retrieve the **citation count** for a given paper using the Semantic Scholar API and store it in a new BibTeX field `citationcount`.\n\n### \uD83D\uDEE0??? Tasks\n\n1. **Integrate citation count fetching**\n\n   * Implement logic in `org.jabref.logic.importer.fetcher.citation.semanticscholar.SemanticScholarCitationFetcher` using\n     `PaperDetails#getCitationCount()` from\n     `org.jabref.logic.importer.fetcher.citation.semanticscholar.PaperDetails`.\n\n2. **Add a new field**\n\n   * Define a new field `citationcount` in `org.jabref.model.entry.field.StandardField` (under JabRef-specific fields).\n   * Ensure that the field is recognized and included in citation fetcher updates.\n\n3. **Write tests**\n\n   * Add unit tests in\n     `org.jabref.logic.importer.fetcher.citation.semanticscholar.SemanticScholarCitationFetcherTest`\n     to verify that citation count is fetched and set correctly.\n   * Additonally, Mock or simulate Semantic Scholar API responses with citation counts.\n\n4. **UI integration**\n\n    * Add a new FieldEditor `CitationCount` (inspired by IdentifierEditor) and integrate it into the UI by modifying FieldEditors#getForField(...).\n    * Add an update button, which uses the SemanticScholarFEtcher to update the citation cound.\n\n### ??? Acceptance Criteria\n\n* When the fetcher is run on an entry with a DOI or title, and Semantic Scholar returns a citation count, the value is written to the `citationcount` field.\n* The value is stored as an integer.\n* Field appears in the entry editor in tab \"General\"\n\n\n### \uD83D\uDCDA Helpful resources\n\n* [[Semantic Scholar API](https://api.semanticscholar.org/)](https://api.semanticscholar.org/)\n* [`[PaperDetails](https://github.com/JabRef/jabref/blob/main/src/main/java/org/jabref/logic/importer/fetcher/citation/semanticscholar/PaperDetails.java)`](https://github.com/JabRef/jabref/blob/main/src/main/java/org/jabref/logic/importer/fetcher/citation/semanticscholar/PaperDetails.java)\n* [`[SemanticScholarCitationFetcher](https://github.com/JabRef/jabref/blob/main/src/main/java/org/jabref/logic/importer/fetcher/citation/semanticscholar/SemanticScholarCitationFetcher.java)`](https://github.com/JabRef/jabref/blob/main/src/main/java/org/jabref/logic/importer/fetcher/citation/semanticscholar/SemanticScholarCitationFetcher.java)\n* [[How to contribute to JabRef](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md)](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md)\n* [[Developer Docs](https://devdocs.jabref.org/)](https://devdocs.jabref.org/)\n\n",
      "updatedAt" : 1752256439.000000000,
      "user" : "koppor",
      "userHtmlUrl" : "https://github.com/koppor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1366654?v=4",
      "labels" : [ "good first issue", "\uD83D\uDCCD Assigned" ],
      "state" : "OPEN",
      "comments" : [ "Hey! I can work on this item in the next weeks but got a couple of question.  First, do you mean by adding a new method called something like` getCitationCount()`?. I noticed on the class that you share that when the request is sent in the `getApiUrl` , you pass a citation count in de query param and papares are return here `citationDataItem.getCitingPaper() ` are you expecting like a sum of all citation count or like a list of counts?  and that filed will be included  here `StandardField ` and that will be the response of the fetcher? something like `org.jabref.model.entry.field.StandardField.CitationCount getCitationCount`?", "@SalvadorRomo I have no clue yet \uD83D\uDE05", "General hints on Fetchers: https://devdocs.jabref.org/code-howtos/fetchers.html", "well, I think I can work for the next weeks, please assign it to me. Thks!\n ", "\uD83D\uDC4B Hey @SalvadorRomo, looks like you???re eager to work on this issue???great! \uD83C\uDF89 It also looks like you skipped reading our [CONTRIBUTING.md](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md), which explains exactly how to participate. No worries, it happens to the best of us. Give it a read, and you???ll discover the ancient wisdom of assigning issues to yourself. Trust me, it???s worth it. \uD83D\uDE80", "/assign-me ", "\uD83D\uDC4B Hey @SalvadorRomo, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80", "hey! by doing a quick search I found this [enpoint](https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data/operation/get_graph_get_paper_citations) .  And this is the [output ]( https://api.semanticscholar.org/graph/v1/paper/10.1007/s10623-009-9333-8/citations) it generates  on an paper regarding a current investigation I'm working. So,  maybe we can add a new tab called `Papaers citing this work `and list every entry from the json output. ", "> hey! by doing a quick search I found this [enpoint](https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data/operation/get_graph_get_paper_citations) . And this is the [output ](https://api.semanticscholar.org/graph/v1/paper/10.1007/s10623-009-9333-8/citations) it generates on an paper regarding a current investigation I'm working. So, maybe we can add a new tab called `Papaers citing this work `and list every entry from the json output.\n\nWe already have this tab. Check \"Citation Relations\"\n\n<img width=\"1222\" height=\"1009\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/21d3d823-8885-4185-88a3-9efc38fb2724\" />\n\nI also checked \"Citation information\"\n\n<img width=\"877\" height=\"369\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/89047610-6ecf-4e5d-8748-52b1323684b1\" />\n\nMaybe, the issue is as easy as using the the API at that tab.\n\n---\n\nBut I would love that https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data/operation/post_graph_get_papers would be used - only with one paper:\n\n<img width=\"1234\" height=\"774\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/58576fd0-a984-4b73-96c9-b0d4930b0250\" />", "Hey!! While looking at the code and try to fit the citation count,  i noticed that the logic on each tab is very tied on each  BibEntry, and  try to fit another fieled from a different souruce will  result in a mess, my idea is why not enable a different tab , and in addition to citation count we enable a few more fields, for example the ones I selected on the image \n\n<img width=\"1668\" height=\"559\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/dcf3bef1-17dd-404d-9b8e-4a82e9a27b0e\" />,   because sometimes happend to me when i work with some many  papaer i lost count on which one were open access , the date and  they were publish. the referecenteCount is just to have an extra one to display\n\nAnd with this change, we keep the fetch as clean as possible with the ability of having more filed in the future  from an specific source ", "> Hey!! While looking at the code and try to fit the citation count, i noticed that the logic on each tab is very tied on each BibEntry, and try to fit another fieled from a different souruce will result in a mess,\n\nPleae read into the DOI field. How it gets updated.\n\nYou should only add a button for manual updates. Not autoamtic updates.\n\nField content is text.\n\nThe citation count is for the bibentry at hand, no other bibentry.\n\nPlease, just add a new FieldEditor. Maybe, you should start with step 4. and then think how the \"update\" button will work (steps 1 to 3)", "gotcha! I know how it works, will have a PR ready by the end of my day so you can take a look !" ],
      "repository" : {
        "description" : "Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases",
        "homepage" : "https://www.jabref.org",
        "name" : "jabref",
        "fullName" : "JabRef/jabref",
        "htmlUrl" : "https://github.com/JabRef/jabref",
        "gitUrl" : "git://github.com/JabRef/jabref.git",
        "sshUrl" : "git@github.com:JabRef/jabref.git",
        "cloneUrl" : "https://github.com/JabRef/jabref.git",
        "owner" : {
          "login" : "JabRef",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2861,
        "stargazersCount" : 3942,
        "watchersCount" : 3942,
        "size" : 249107,
        "openIssuesCount" : 582,
        "subscribersCount" : 113,
        "pushedAt" : "2025-07-11T22:29:41Z",
        "languages" : {
          "PowerShell" : 2037,
          "Java" : 11216891,
          "CSS" : 74176,
          "TeX" : 758587,
          "AppleScript" : 1721,
          "XSLT" : 151843,
          "Just" : 1194,
          "Shell" : 9305,
          "Batchfile" : 637,
          "ANTLR" : 9176,
          "BibTeX Style" : 78034,
          "Ruby" : 507,
          "Python" : 22282
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add a citation count field in JabRef, which will be fetched from the Semantic Scholar API and stored in a new BibTeX field called `citationcount`. The field will be used to display the citation count for each paper in the entry editor.",
      "validationOrRequirement" : "The requirements for this issue include fetching the citation count from the Semantic Scholar API, storing the value in a new BibTeX field, and displaying the field in the entry editor. The acceptance criteria also include writing tests and ensuring that the field is recognized and included in citation fetcher updates.",
      "attemptedFixes" : "The issue has been discussed in the comments, with suggestions on how to implement the citation count fetching, including using the `get_graph_get_paper_citations` endpoint and adding a new tab to display the citing papers. The issue also requires creating a new FieldEditor and integrating it into the UI.",
      "otherNotes" : "The issue is to add a citation count field in JabRef, which will be fetched from the Semantic Scholar API. The field will be stored in a new BibTeX field called `citationcount`. The issue requires integrating citation count fetching, adding a new field, writing tests, and UI integration. The acceptance criteria include fetching the citation count when the fetcher is run on an entry with a DOI or title, storing the value as an integer, and displaying the field in the entry editor.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283404
  }, {
    "issueDTO" : {
      "id" : 1191806884,
      "title" : "YT: Highly compressed audio when using mobile data and in background",
      "url" : "https://github.com/TeamNewPipe/NewPipe/issues/8148",
      "repositoryName" : "TeamNewPipe/NewPipe",
      "description" : "### Checklist\n\n- [X] I am able to reproduce the bug with the [latest version](https://github.com/TeamNewPipe/NewPipe/releases/latest).\n- [X] I made sure that there are *no existing issues* - [open](https://github.com/TeamNewPipe/NewPipe/issues) or [closed](https://github.com/TeamNewPipe/NewPipe/issues?q=is%3Aissue+is%3Aclosed) - which I could contribute my information to.\n- [x] I have taken the time to fill in all the required details. I understand that the bug report will be dismissed otherwise.\n- [X] This issue contains only one bug.\n- [X] I have read and understood the [contribution guidelines](https://github.com/TeamNewPipe/NewPipe/blob/dev/.github/CONTRIBUTING.md).\n\n### Affected version\n\n0.22.1\n\n### Steps to reproduce the bug\n\n1. Use mobile data (whether WiFi is enabled or not).\r\n2. Play any Youtube video in the background.\n\n### Expected behavior\n\nThe audio is the same when playing the video in the \"foreground\".\n\n### Actual behavior\n\nThe audio is compressed and has notable artefacts.\n\n### Screenshots/Screen recordings\n\n_No response_\n\n### Logs\n\n_No response_\n\n### Affected Android/Custom ROM version\n\nAndroid 11 / Lineage 18.1\n\n### Affected device model\n\nSony Xperia XA2 Ultra\n\n### Additional information\n\nThis only happens when using data AND in background mode. If I play a video with mobile data the audio is fine. When using WiFi the audio is fine in both cases.\r\nIt happens regardless of the preferred audio format in the settings.\r\nI have no data usage restrictions on this app.\r\nIt seems the audio is 48 kbps M4A or 50 kbps Opus, since I tried downloading something with those settings and it sounded just like that.\r\nI've only observed this behaviour on Youtube videos.",
      "updatedAt" : 1752256182.000000000,
      "user" : "Mounster-Chef",
      "userHtmlUrl" : "https://github.com/Mounster-Chef",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/60630177?v=4",
      "labels" : [ "bug", "good first issue", "player" ],
      "state" : "OPEN",
      "comments" : [ "Related: #1583", "This bug has been a highly requested feature for some years now. xD", "After taking a look at the code, I now understand that if the resolution when on mobile data is limited at all, the most compact audio stream will be chosen. IMO this is a bad choice since, even if you set the limit to 1080p60, you will get the worst audio. Also, audio-only playback shouldn't be tied to the resolution limit, or at least not like how it is now.\r\n\r\nMaybe `ListHelper.getDefaultAudioFormat` could be adapted to account for a new settings item for bitrate (that would change according to the default format)?\r\nA simpler option is making it so `getDefaultAudioFormat` gets the most compact audio if the resolution limit is set at a certain resolution or lower, 480p would work well IMO, given that 720p is \"HD\".\r\n\r\nI think I could do the first one, although I've never participated in such a big project and it's my first time seeing Android code \uD83D\uDE05", "@Mounster-Chef Feel free to experiment with the code. If you happen to arrive at a proper implementation, this issue can be assigned to you.", "The audio quality is unacceptably low. It turned NewPipe unusable for me. I had to come back to playing music through Firefox.\r\n\r\nPlease improve it \uD83D\uDE4F " ],
      "repository" : {
        "description" : "A libre lightweight streaming front-end for Android.",
        "homepage" : "https://newpipe.net",
        "name" : "NewPipe",
        "fullName" : "TeamNewPipe/NewPipe",
        "htmlUrl" : "https://github.com/TeamNewPipe/NewPipe",
        "gitUrl" : "git://github.com/TeamNewPipe/NewPipe.git",
        "sshUrl" : "git@github.com:TeamNewPipe/NewPipe.git",
        "cloneUrl" : "https://github.com/TeamNewPipe/NewPipe.git",
        "owner" : {
          "login" : "TeamNewPipe",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3225,
        "stargazersCount" : 34343,
        "watchersCount" : 34343,
        "size" : 79589,
        "openIssuesCount" : 1232,
        "subscribersCount" : 610,
        "pushedAt" : "2025-07-12T00:34:31Z",
        "languages" : {
          "Java" : 2664590,
          "HTML" : 81544,
          "Kotlin" : 484005
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to improve the audio quality when playing YouTube videos in the background using mobile data, as the current audio compression and artefacts are unacceptable and make the app unusable.",
      "validationOrRequirement" : "The issue only occurs when using mobile data and in background mode, and not when using WiFi. The audio format is 48 kbps M4A or 50 kbps Opus. The issue is highly requested and has been observed on YouTube videos only.",
      "attemptedFixes" : "The commenter @Mounster-Chef suggested adapting `ListHelper.getDefaultAudioFormat` to account for a new settings item for bitrate, or making it so `getDefaultAudioFormat` gets the most compact audio if the resolution limit is set at a certain resolution or lower, such as 480p.",
      "otherNotes" : "Audio compression and artefacts occur when playing YouTube videos in the background using mobile data. The issue only happens when using data AND in background mode, and not when using WiFi. The audio format is 48 kbps M4A or 50 kbps Opus. The issue is highly requested and has been observed on YouTube videos only.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283412
  }, {
    "issueDTO" : {
      "id" : 3198336703,
      "title" : "[MCP] Pinterest",
      "url" : "https://github.com/activepieces/activepieces/issues/8236",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview  \n\nPinterest is a visual discovery engine for finding ideas like recipes, home and style inspiration, and more.\nThis integration allows AI agents and workflows to create, manage, and interact with Pins and Boards, automating content sharing and curation.\n\n---\n\n## ?????? Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## \uD83D\uDEA8 Triggers  \n\n| **Trigger** | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **New Pin on Board** | Fires when a new Pin is added to a specific board.|\n|**New Follower**| Triggers when a user gains a new follower.|\n|**New Board**| Fires when a new board is created in the account.|\n\n---\n\n## \uD83D\uDEE0??? Write Actions   \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Create Pin** | Upload an image or video to create a new Pin on a board.|\n|**Create Board**|Create a new Pinterest board for organizing Pins.|\n|**Update Board**| Modify a board???s name, description, or visibility settings.|\n|**Delete Pin**| Permanently delete a specific Pin. |\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Trigger** | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Find Pin by Title/Keyword** | Search for Pins using a title, description, or tag.|\n|**Find Board by Name**| Locate a board by its name for pinning or updates.|\n\n---\n\n## \uD83D\uDCDA API Reference  \n- [Official Pinterest API Documentation](https://developers.pinterest.com/docs/api/v5/)\n\n---\n\n## \uD83E\uDDEA Test Account Access  \nYou can test Pinterest APIs by registering your app on the [Pinterest Developers Portal](https://developers.pinterest.com/)  and generating OAuth tokens.\n\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n|",
      "updatedAt" : 1752255853.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "$100", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-791/mcp-pinterest\">AP-791 [MCP] Pinterest</a></p>", "/bounty $100", "## \uD83D\uDC8E $100 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8236` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8236` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @ezhil56x | Jul 03, 2025, 07:23:29 AM | WIP |  |\n| \uD83D\uDFE2 @dhvll | Jul 03, 2025, 10:33:03 AM | WIP |  |\n| \uD83D\uDFE2 @Sanket6652 | Jul 03, 2025, 07:00:10 PM | #8247 | [Reward](https://algora.io/claims/CjDgu8DkPYLGNkon) |\n| \uD83D\uDFE2 @aryel780 | Jul 11, 2025, 04:48:35 PM | #8336 | [Reward](https://algora.io/claims/JCvqk5BoWTxYkyXp) |", "/attempt #8236", "/attempt #8236", "/attempt #8236" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2193,
        "stargazersCount" : 15771,
        "watchersCount" : 15771,
        "size" : 300248,
        "openIssuesCount" : 388,
        "subscribersCount" : 96,
        "pushedAt" : "2025-07-11T13:16:13Z",
        "languages" : {
          "TypeScript" : 13976520,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 71760,
          "Shell" : 3862,
          "JavaScript" : 12636,
          "HTML" : 212998
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Integrate Pinterest with Activepieces to allow AI agents and workflows to create, manage, and interact with Pins and Boards, automating content sharing and curation.",
      "validationOrRequirement" : "The issue requires the contributor to submit the integration as a Piece following the Activepieces architecture. Submissions that do not follow this format will not be accepted. The contributor must also review the Piece Development Guidelines before starting development.",
      "attemptedFixes" : "Several contributors have attempted to solve this issue, including @ezhil56x, @dhvll, and @aryel780, but none have been successful. @Sanket6652 has submitted a solution but it requires further review.",
      "otherNotes" : "The issue is about integrating Pinterest with Activepieces, a leading open source AI automation platform. The integration allows AI agents and workflows to create, manage, and interact with Pins and Boards, automating content sharing and curation. The issue has a $100 bounty and requires the contributor to follow specific guidelines and provide a short demo video of their changes.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283419
  }, {
    "issueDTO" : {
      "id" : 3213615482,
      "title" : "[Bug]: F12 does not work as expected",
      "url" : "https://github.com/nextcloud/desktop/issues/8442",
      "repositoryName" : "nextcloud/desktop",
      "description" : "### ?????? Before submitting, please verify the following: ??????\n\n- [x] This is a **bug**, not a question or a configuration issue.\n- [x] This issue is **not** already reported on Github (I've searched it).\n- [x] Nextcloud Server and Desktop Client are **up to date**. See [Server Maintenance and Release Schedule](https://github.com/nextcloud/server/wiki/Maintenance-and-Release-Schedule) and [Desktop Releases](https://nextcloud.com/install/#install-clients) for supported versions.\n- [x] I agree to follow Nextcloud's [Code of Conduct](https://nextcloud.com/contribute/code-of-conduct/)\n\n### Bug description\n\nWe have documented that F12 shows a window with logs:\nhttps://docs.nextcloud.com/server/latest/admin_manual/desktop/troubleshooting.html#keyboard-shortcut\n\n### Steps to reproduce\n\n1 - open the client settings dialog\n2 - press F12\n\n<img width=\"605\" height=\"370\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f72a5449-9c11-41a6-994d-04f5c9e1aa18\" />\n\n3 - click 'open folder'\n4 - there are no logs\n\n<img width=\"691\" height=\"454\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3e6a18e1-e208-441c-87d1-15abc1a215fd\" />\n\n- In one case, the 'create debug archive' button got disabled after interacting with the dialog:\n\n<img width=\"821\" height=\"655\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cd56a48c-6650-4196-b8a3-f6266e33b38d\" />\n\n### Expected behavior\n\nDisplay/generate logs.\n\n\n### Proposed solution\nF12 should create debug archive as well.\n\n### Which files are affected by this bug\n\n-\n\n### Operating system\n\nWindows\n\n### Which version of the operating system you are running.\n\nLinux and mac OS\n\n### Package\n\nOther\n\n### Nextcloud Server version\n\n-\n\n### Nextcloud Desktop Client version\n\n3.16.6\n\n### Is this bug present after an update or on a fresh install?\n\nUpdated from a minor version (ex. 3.4.2 to 3.4.4)\n\n### Are you using the Nextcloud Server Encryption module?\n\nEncryption is Enabled\n\n### Are you using an external user-backend?\n\n- [ ] Default internal user-backend\n- [ ] LDAP/ Active Directory\n- [ ] SSO - SAML\n- [ ] Other\n\n### Nextcloud Server logs\n\n```shell\n\n```\n\n### Additional info\n\n_No response_",
      "updatedAt" : 1752255692.000000000,
      "user" : "camilasan",
      "userHtmlUrl" : "https://github.com/camilasan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/241266?v=4",
      "labels" : [ "feature: :cloud: GUI", "bug", "Prio: normal", "1. to develop", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "you would need to restart the client\nmy best guess is that the UI is lacking" ],
      "repository" : {
        "description" : "\uD83D\uDCBB Desktop sync client for Nextcloud",
        "homepage" : "https://nextcloud.com/install/#install-clients",
        "name" : "desktop",
        "fullName" : "nextcloud/desktop",
        "htmlUrl" : "https://github.com/nextcloud/desktop",
        "gitUrl" : "git://github.com/nextcloud/desktop.git",
        "sshUrl" : "git@github.com:nextcloud/desktop.git",
        "cloneUrl" : "https://github.com/nextcloud/desktop.git",
        "owner" : {
          "login" : "nextcloud",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 837,
        "stargazersCount" : 3307,
        "watchersCount" : 3307,
        "size" : 560005,
        "openIssuesCount" : 918,
        "subscribersCount" : 108,
        "pushedAt" : "2025-07-11T20:17:00Z",
        "languages" : {
          "C++" : 5528597,
          "C" : 48516,
          "CMake" : 273375,
          "Objective-C++" : 141928,
          "QMake" : 545,
          "NSIS" : 131944,
          "QML" : 253104,
          "Shell" : 19974,
          "JavaScript" : 1949,
          "Objective-C" : 39426,
          "Swift" : 152963,
          "Nix" : 4501,
          "Ruby" : 7726,
          "Python" : 30698
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "F12 does not work as expected, and instead of displaying logs, it does not create a debug archive.",
      "validationOrRequirement" : "The issue should be a bug, not a question or a configuration issue, and Nextcloud Server and Desktop Client should be up to date.",
      "attemptedFixes" : "The author suggests that the UI might be lacking, and recommends restarting the client.",
      "otherNotes" : "The bug is reported by camilasan, with screenshots of the issue, and has been labeled as a normal priority, good first issue, and a GUI bug. The author suggests that the UI might be lacking and recommends restarting the client.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283424
  }, {
    "issueDTO" : {
      "id" : 1244271212,
      "title" : "?????????????? ???????????????? ???????????? ???????????????????? ???????????????? ?????????? ????????????????????",
      "url" : "https://github.com/TauCetiStation/TauCetiClassic/issues/9327",
      "repositoryName" : "TauCetiStation/TauCetiClassic",
      "description" : "<!--\r\n??????????: ???????? ?????? ???????? ???????????????? ???? ???????????????? ?? ????????, ?? ???????????????????????? ?????? ????????-????????, ???? ?????????????????????? ???????????????? ?? ???????????????? ?????? [Proposal]\r\n\r\n\r\n1. ???????????? ?????????????????? ?????? ?????????????????????????????? ??????????????????\r\n(?????? ?? ?????????? ????????, ?????????? ???????? ????????????)\r\n2. ?? ?????????? ?????????????? ???????????? ???????? ???????????????? ???????????? ?????????? ????????????????\r\n3. ???????????????????? ???????????????? ?????????????? ???? ?????????? ?????????? ?????? ????????????????\r\n-. ???????? ???????????????? ?????????????? ????????????.\r\n\r\n1. ???????? ???????????? ?????????? ?????? ?????? ?????????????? ???? ?????? -\r\n???? ?????????????? ?? ???? ??????????????????????????.\r\n???????? ???????????? ???????????????? ?? ?????? ?????? ???????? ?????????? -\r\n???????????? ???????????????? ????????????.\r\n\r\n2. ???? ???????? ?????????????????? ?????????? ?????????? ?? ?????????? ??????????????,\r\n(!???????? ???????? ?????? ?????? ?????????????? ?????????? ?????????? ????????!)\r\n???????? ?????? ???? ???????????????? ???? ??????, ???????????? ??????.\r\n?? ?????? ???????????????????????? ???? ???????? ?????????????? ?????????????? -\r\n???????????????????????? ?????????????? ?????? ?????????? ???????? ???????????????? -\r\n?????????????????????????? ???????????? ????????????, ?????????? ????????????????????.\r\n\r\n3. ???????????????????? ?? ?? ???????? ?????????????????? ???????????????? ?????????????? -\r\n???????? ?????????? ??????????! ?????????? ???????? ???? ???????????? ?? ?????? ???????????? -\r\n???????? ?????????????? ?????? ???? ????????????????.\r\n???????????? ????????????: \"??????????.\" - ?????? ???? ???????????? ???????????? ???? ???????????? ?????????????????\r\n?????????????? ????????????: \"???????????????????????? ?????????????????????? ???????????????? ??????????.\" -\r\n?? ?????? ?????? ?????? ?????????? ?????????????? ?? ?????? ????????????.\r\n?????? ???????? ?????? ?????????????? ?????? ????????, ?????????? ?????? ???? ?????????? -\r\n???????? ??????????, ?????? ??????????????_???????? ?????? ?????? ?????? ????????????????,\r\n?????? ????????, ?? ?????? ?????????? ???????? ???????????? ???? ???????????????????? ?? -\r\n???????????? ?????????????? ?????????????? ????????????. ?????????? ???????????????? ???? ?????????? ????????????????????, ???? -\r\n???????????????? ???????????? ???????????? ?? ?????? ????????????, ?????? ?????????? ???????????????????? ?????????????? ????????????.\r\n-->\r\n\r\n#### ?????????????????? ???????????????? ????????????????\r\n???????? ?????????????? ?????????????? ???????????????????? ???????????? ?? ?????????????? ?????????????? ????????????, ?? ?????????? ?????????????????? ?????????????? ????????????????, ???? ?????????? ?????????? ???????????????? ???????????????????? ?????????????????? ???????????????? ????????????\r\n#### ?????? ???????????? ???????? ??????????????????\r\n???????????? ?????????????????????????????????? ?? ?????????????????????? ????????????????\r\n#### ?????? ?????????????????? ???? ?????????? ????????\r\n??????????\r\n#### ?????? ??????????????????\r\n?????????????? ???????????? ???????????? ?? ?????????????? ????????????????????, ?????????????????? ?????????????? ?????????? ??????, ???????????????? ????????????\r\n#### ???????????????????????????? ????????????????????:\r\n?????????? ???????? ?????? ?????????? ???????????????????? ??????????????\r\nIssue reported from  Round ID: 51430 (Tau Ceti Classic (RU))\r\nTestmerges: ```#9266 #9226 #9201 #9106 ```\r\nReporting client version: 514.1569\r\n",
      "updatedAt" : 1752255589.000000000,
      "user" : "Akellazp",
      "userHtmlUrl" : "https://github.com/Akellazp",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47355061?v=4",
      "labels" : [ "Good First Issue", "Bug" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "???????????????????????? ??????",
        "homepage" : null,
        "name" : "TauCetiClassic",
        "fullName" : "TauCetiStation/TauCetiClassic",
        "htmlUrl" : "https://github.com/TauCetiStation/TauCetiClassic",
        "gitUrl" : "git://github.com/TauCetiStation/TauCetiClassic.git",
        "sshUrl" : "git@github.com:TauCetiStation/TauCetiClassic.git",
        "cloneUrl" : "https://github.com/TauCetiStation/TauCetiClassic.git",
        "owner" : {
          "login" : "TauCetiStation",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 427,
        "stargazersCount" : 148,
        "watchersCount" : 148,
        "size" : 1110914,
        "openIssuesCount" : 1572,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-05T12:37:41Z",
        "languages" : {
          "C#" : 11504,
          "PowerShell" : 4157,
          "Java" : 62113,
          "CSS" : 51228,
          "C++" : 9423,
          "DM" : 16714091,
          "HTML" : 44956,
          "Groovy" : 4957,
          "TypeScript" : 88187,
          "Shell" : 21616,
          "Batchfile" : 1669,
          "Awk" : 752,
          "SCSS" : 115869,
          "JavaScript" : 622686,
          "Python" : 22649
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the console control system in the debt management section to prevent interaction with the console when it is turned off.",
      "validationOrRequirement" : "The console control system should be designed to prevent interaction with the console when it is turned off.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to a faulty console control system in the debt management section, where it is still possible to interact with the console even after it has been turned off. The expected behavior is that the console should be inaccessible after being turned off. The issue can be reproduced by opening the debt status in the console, turning off the consoles via APC, and then attempting to interact with the debt status.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283428
  }, {
    "issueDTO" : {
      "id" : 2360502207,
      "title" : "Moonboard logbook commands are broken",
      "url" : "https://github.com/lemeryfertitta/BoardLib/issues/39",
      "repositoryName" : "lemeryfertitta/BoardLib",
      "description" : "The Moonboard login flow has changed a bit with a site redesign that they have done since this library was released, and the logbook commands for `moon` are now broken as a result. The API appears unchanged, so just the login session creation needs to be updated.",
      "updatedAt" : 1752255573.000000000,
      "user" : "lemeryfertitta",
      "userHtmlUrl" : "https://github.com/lemeryfertitta",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6968022?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Utilities for interacting with climbing board APIs",
        "homepage" : "",
        "name" : "BoardLib",
        "fullName" : "lemeryfertitta/BoardLib",
        "htmlUrl" : "https://github.com/lemeryfertitta/BoardLib",
        "gitUrl" : "git://github.com/lemeryfertitta/BoardLib.git",
        "sshUrl" : "git@github.com:lemeryfertitta/BoardLib.git",
        "cloneUrl" : "https://github.com/lemeryfertitta/BoardLib.git",
        "owner" : {
          "login" : "lemeryfertitta",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 95,
        "watchersCount" : 95,
        "size" : 134,
        "openIssuesCount" : 7,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-06T16:17:34Z",
        "languages" : {
          "Python" : 52777
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Moonboard logbook commands are broken and need to be updated to accommodate the new login flow",
      "validationOrRequirement" : "update the login session creation",
      "attemptedFixes" : "",
      "otherNotes" : "The Moonboard login flow has changed due to a site redesign, and the logbook commands for 'moon' are now broken.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283431
  }, {
    "issueDTO" : {
      "id" : 1572656801,
      "title" : "rpk: print loaded node configuration",
      "url" : "https://github.com/redpanda-data/redpanda/issues/8643",
      "repositoryName" : "redpanda-data/redpanda",
      "description" : "### Who is this for and what problem do they have today?\r\n\r\nUsers who want to use rpk to query what node configuration properties are loaded in the node.\r\n\r\nSee this community slack thread as an example: https://redpandacommunity.slack.com/archives/C01AJDUT88N/p1675617152235159?thread_ts=1674497965.762759&cid=C01AJDUT88N\r\n\r\n### What are the success criteria?\r\n\r\nUse rpk to print the loaded configuration, a wrapper around the Admin API call:\r\n\r\n```\r\n$ curl localhost:9644/v1/node_config\r\n```\r\n\r\n### Why is solving this problem impactful?\r\n\r\nConsistency, we have a similar command for cluster properties: `rpk redpanda admin config print` \r\n\r\n### Additional notes\r\n\r\n<!--\r\nRelevant GH issues and pull requests\r\nDependencies on other features or components\r\nLink to PRD or Eng Proposal as needed\r\n-->\r\n\n\nJIRA Link: [CORE-1159](https://redpandadata.atlassian.net/browse/CORE-1159)\n\n[CORE-1159]: https://redpandadata.atlassian.net/browse/CORE-1159?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",
      "updatedAt" : 1752255386.000000000,
      "user" : "r-vasquez",
      "userHtmlUrl" : "https://github.com/r-vasquez",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/59714880?v=4",
      "labels" : [ "kind/enhance", "area/rpk", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @r-vasquez I would like to work on this issue.", "Hey @r-vasquez , is this issue still open? \r\nI can try my hands on this one.\r\n", "This is still open.", "Gave starting a Discussion a try for this one. Think I've got code for it, just working out how to get a PR submitted.\n\nhttps://github.com/redpanda-data/redpanda/discussions/26777", "Figured it out! PR #26796 submitted\n" ],
      "repository" : {
        "description" : "Redpanda is a streaming data platform for developers. Kafka API compatible. 10x faster. No ZooKeeper. No JVM!",
        "homepage" : "https://redpanda.com",
        "name" : "redpanda",
        "fullName" : "redpanda-data/redpanda",
        "htmlUrl" : "https://github.com/redpanda-data/redpanda",
        "gitUrl" : "git://github.com/redpanda-data/redpanda.git",
        "sshUrl" : "git@github.com:redpanda-data/redpanda.git",
        "cloneUrl" : "https://github.com/redpanda-data/redpanda.git",
        "owner" : {
          "login" : "redpanda-data",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 645,
        "stargazersCount" : 10547,
        "watchersCount" : 10547,
        "size" : 118431,
        "openIssuesCount" : 982,
        "subscribersCount" : 136,
        "pushedAt" : "2025-07-12T00:26:50Z",
        "languages" : {
          "Smarty" : 428,
          "Java" : 353374,
          "C++" : 23675319,
          "Jinja" : 491,
          "Rust" : 382766,
          "C" : 17575,
          "CMake" : 4906,
          "Makefile" : 3560,
          "Go" : 2454043,
          "TypeScript" : 1267,
          "OpenEdge ABL" : 20907,
          "Dockerfile" : 19331,
          "Shell" : 37851,
          "Starlark" : 826442,
          "JavaScript" : 3743,
          "Python" : 6969086,
          "Emacs Lisp" : 829
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Users who want to use rpk to query what node configuration properties are loaded in the node",
      "validationOrRequirement" : "Use rpk to print the loaded configuration, a wrapper around the Admin API call",
      "attemptedFixes" : "Starting a Discussion, Think I've got code for it, just working out how to get a PR submitted, Figured it out! PR #26796 submitted",
      "otherNotes" : "Relevant GH issues and pull requests, Dependencies on other features or components, Link to PRD or Eng Proposal as needed",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283435
  }, {
    "issueDTO" : {
      "id" : 3215517385,
      "title" : "Some \"good first issues\" (likely easy to fix) for contributors",
      "url" : "https://github.com/go-gitea/gitea/issues/35015",
      "repositoryName" : "go-gitea/gitea",
      "description" : "Here are some \"good first issues\", if you'd like to contribute, feel free to try (just do it, no need to ask \uD83D\uDE01 )\n\nThis issue will also be updated if there are new good first issues, welcome maintainers to add more.\n\n### Help to improve English sentences in \"locale_en-US.ini\"\n\n* Many contributors are not English native speakers (include me), so some sentences don't read good\n* Non-English translations are managed by Crowdin (see the contribution guideline)\n\n### Help to improve documents and config example\n\n* Gitea has far more features the the document describes (https://gitea.com/gitea/docs)\n* The `app.example.ini` could also be improved.\n\n### Refactor legacy \"delete-button\" to \"link-action\" + confirm dialog\n\n* Old \"delete-button\"'s design doesn't work well, now we have better \"link-action\" to handle various cases\n\n### Split large functions into small ones\n\n* In history, many functions were just patched and patched, became longer and longer\n* It's good to split large functions into small ones, and it's better to add some necessary tests\n\n### Refactor legacy `tw-flex tw-items-center tw-gap-xx` \n\n* to `flex-text-block` or `flex-text-inline`\n\n",
      "updatedAt" : 1752255384.000000000,
      "user" : "wxiaoguang",
      "userHtmlUrl" : "https://github.com/wxiaoguang",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2114189?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Please, could you point me to the folder containing the file \"locale_en-us.ini\". I would love to help", "It is in `options/locale/locale_en-US.ini` , you can use GitHub's \"Go to file\" to find it, or clone the repo and use some commands like `find`", "Found it. working on it", "Opened a pull request: [https://github.com/go-gitea/gitea/pull/35053](url)" ],
      "repository" : {
        "description" : "Git with a cup of tea! Painless self-hosted all-in-one software development service, including Git hosting, code review, team collaboration, package registry and CI/CD",
        "homepage" : "https://gitea.com",
        "name" : "gitea",
        "fullName" : "go-gitea/gitea",
        "htmlUrl" : "https://github.com/go-gitea/gitea",
        "gitUrl" : "git://github.com/go-gitea/gitea.git",
        "sshUrl" : "git@github.com:go-gitea/gitea.git",
        "cloneUrl" : "https://github.com/go-gitea/gitea.git",
        "owner" : {
          "login" : "go-gitea",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5910,
        "stargazersCount" : 49528,
        "watchersCount" : 49528,
        "size" : 310032,
        "openIssuesCount" : 2718,
        "subscribersCount" : 493,
        "pushedAt" : "2025-07-12T00:38:43Z",
        "languages" : {
          "CSS" : 434036,
          "Handlebars" : 1294849,
          "Makefile" : 39439,
          "Vue" : 131080,
          "Go" : 13009926,
          "Jsonnet" : 15441,
          "TypeScript" : 540626,
          "Dockerfile" : 4119,
          "Shell" : 45425,
          "JavaScript" : 362153,
          "Roff" : 44055,
          "Nix" : 895,
          "Less" : 1872
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "to provide good first issues for contributors to fix, including improving English sentences in locale_en-US.ini, documents and config example, refactor legacy code, and split large functions",
      "validationOrRequirement" : "no specific requirement mentioned",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "locale_en-US.ini is located in options/locale, contributors can use GitHub's 'Go to file' or clone the repo and use find command to locate it, a pull request is created for the issue",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283438
  }, {
    "issueDTO" : {
      "id" : 3197295260,
      "title" : "Remove stale .gitignore entries",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11574",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "There are a ton of entries in the root .gitignore that are no longer to the 2.x project. We should remove any entry that's stale for maintenance.",
      "updatedAt" : 1752255056.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 537,
        "stargazersCount" : 4626,
        "watchersCount" : 4626,
        "size" : 210688,
        "openIssuesCount" : 577,
        "subscribersCount" : 102,
        "pushedAt" : "2025-07-11T22:49:24Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16652,
          "Rust" : 20712,
          "Makefile" : 30384,
          "JavaScript" : 435,
          "Go" : 4010698,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove stale .gitignore entries for maintenance purposes.",
      "validationOrRequirement" : "Entries in the root .gitignore should be removed if they are stale.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the 2.x project and aims to maintain the root .gitignore by removing stale entries.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283440
  }, {
    "issueDTO" : {
      "id" : 3200556393,
      "title" : "Improve handling of nested Go modules",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11588",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "The project has nested Go modules, e.g. hack/utils/applier, where running `go mod tidy` produces a go.sum diff when you pushd into that directory. We should ensure that the nested Go modules are kept in sync like the root go.mod in the codgen verify target.",
      "updatedAt" : 1752255045.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "Should be a simple change:\n\n```diff\n+.PHONY: mod-tidy-nested\n+mod-tidy-nested:  ## Tidy go mod files in nested modules\n+       @cd hack/utils/applier && go mod tidy\n+\n .PHONY: mod-tidy\n-mod-tidy: mod-download  ## Tidy the go mod file\n+mod-tidy: mod-download mod-tidy-nested  ## Tidy the go mod files\n```" ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 537,
        "stargazersCount" : 4626,
        "watchersCount" : 4626,
        "size" : 210688,
        "openIssuesCount" : 577,
        "subscribersCount" : 102,
        "pushedAt" : "2025-07-11T22:49:24Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16652,
          "Rust" : 20712,
          "Makefile" : 30384,
          "JavaScript" : 435,
          "Go" : 4010698,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve handling of nested Go modules",
      "validationOrRequirement" : "ensure nested Go modules are kept in sync like root go.mod",
      "attemptedFixes" : "add .PHONY: mod-tidy-nested and modify mod-tidy to include mod-tidy-nested",
      "otherNotes" : "nested Go modules, e.g. hack/utils/applier, with go.sum diff on push",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283444
  }, {
    "issueDTO" : {
      "id" : 3200531595,
      "title" : "Remove knative.dev/pkg/network usage",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11587",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "We only import this dependency for the network.GetClusterDomainName function. Either manually vendor that function + attribution, or re-evaluate the code that currently calls it.",
      "updatedAt" : 1752255036.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "we have an existing tracker for this somewhere FWIW", "@lgadban I think it's in that massive \"cleanup repo epic\". I didn't see an existing tracker when I looked ~5m ago." ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 537,
        "stargazersCount" : 4626,
        "watchersCount" : 4626,
        "size" : 210688,
        "openIssuesCount" : 577,
        "subscribersCount" : 102,
        "pushedAt" : "2025-07-11T22:49:24Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16652,
          "Rust" : 20712,
          "Makefile" : 30384,
          "JavaScript" : 435,
          "Go" : 4010698,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove knative.dev/pkg/network usage, only import dependency for network.GetClusterDomainName function",
      "validationOrRequirement" : "manually vendor the function + attribution, or re-evaluate the code that currently calls it",
      "attemptedFixes" : "vendor the function + attribution, re-evaluate the code that currently calls it",
      "otherNotes" : "existing tracker mentioned in comments, cleanup repo epic",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283447
  }, {
    "issueDTO" : {
      "id" : 3213689532,
      "title" : "[Feature] Fix golangci-lint static checks",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/1318",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "https://github.com/mariadb-operator/mariadb-operator/blob/bb961528a4a3be0afe6cd90d78b4370214deb276/.golangci.yml#L27",
      "updatedAt" : 1752254926.000000000,
      "user" : "mmontes11",
      "userHtmlUrl" : "https://github.com/mmontes11",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4168911?v=4",
      "labels" : [ "go", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@mmontes11 Hi, I???ve opened a PR to start addressing issue here: https://github.com/mariadb-operator/mariadb-operator/pull/1321\n\nFor now, I???ve only fixed `ST1001` as it was simple to tackle.  \nI???d like to confirm if this direction is acceptable before moving on to the other checks.\n\nIn particular:\n\n- **ST1003** would involve renaming identifiers, which could make breaking changes.  \n  - For example: `type SqlFinalizer` ??? `type SQLFinalizer`.\n- **ST1005** would slightly change error message formats.  \n\nIf those changes are okay, I???m happy to work on them as well.  \nLooking forward to your feedback!" ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 137,
        "stargazersCount" : 685,
        "watchersCount" : 685,
        "size" : 17384,
        "openIssuesCount" : 109,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T19:59:39Z",
        "languages" : {
          "Smarty" : 5375,
          "Dockerfile" : 421,
          "Shell" : 171885,
          "Makefile" : 51174,
          "Go" : 2688034
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix golangci-lint static checks",
      "validationOrRequirement" : "Confirm direction before moving on to ST1003 and ST1005, potential breaking changes and error message format changes",
      "attemptedFixes" : "Fixed ST1001, PR: https://github.com/mariadb-operator/mariadb-operator/pull/1321",
      "otherNotes" : "https://github.com/mariadb-operator/mariadb-operator/blob/bb961528a4a3be0afe6cd90d78b4370214deb276/.golangci.yml#L27",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283451
  }, {
    "issueDTO" : {
      "id" : 3174516713,
      "title" : "forward_command_controller: Check message for finite values",
      "url" : "https://github.com/ros-controls/ros2_controllers/issues/1775",
      "repositoryName" : "ros-controls/ros2_controllers",
      "description" : "## Background\n> May be we should check here with std::all_of that all of the data elements are finite values\n\n_Originally posted by @saikishor in https://github.com/ros-controls/ros2_controllers/pull/1721#discussion_r2164917620_\n\n## Instructions\nHi, this is a `good-first-issue` issue. This means we've worked to make it more legible to people who either **haven't contributed to our codebase before, or even folks who haven't contributed to open source before**.\n\nWe're interested in helping you take the first step, and can answer questions and help you out along the way. Note that we're especially interested in contributions from underrepresented groups!\n\nWe know that creating a pull request is the biggest barrier for new contributors. This issue is for you \uD83D\uDC9D\n\nIf you have contributed before, **consider leaving this PR for someone new**, and looking through our general [bug](https://github.com/ros-controls/ros2_control/labels/bug) issues. Thanks!\n\n### \uD83E\uDD14 What you will need to know.\n\nNothing. This issue is meant to welcome you to Open Source :) We are happy to walk you through the process.\n\n### \uD83D\uDCCB Step by Step\n\n- [ ] \uD83D\uDE4B **Claim this issue**: Comment below. If someone else has claimed it, ask if they've opened a pull request already and if they're stuck -- maybe you can help them solve a problem or move it along!\n\n- [ ] \uD83D\uDDC4??? **Create a local workspace** for making your changes and testing [following these instructions](https://docs.ros.org/en/rolling/Tutorials/Workspace/Creating-A-Workspace.html), for Step 3 use \"Download Source Code\" section with [these instructions](https://control.ros.org/master/doc/getting_started/getting_started.html#building-from-source).\n\n- [ ] \uD83C\uDF74 **Fork the repository** using the handy button at the top of the repository page and **clone** it into `~/ws_ros2_control/src/ros-controls/ros2_control`, [here is a guide that you can follow](https://guides.github.com/activities/forking/) (You will have to remove or empty the existing `ros2_control` folder before cloning your own fork)\n\n- [ ] **Checkout a new branch** using `git checkout -b <branch_name>`\n\n- [ ] \uD83E\uDD16 **Apply `pre-commit`** auto formatting, by running `pip3 install pre-commit` and running `pre-commit install` in the ros2_control repo.\n\n- [ ] \uD83D\uDCBE **Commit and Push** your changes\n\n- [ ] \uD83D\uDD00 **Start a Pull Request** to request to merge your code into `master`. There are two ways that you can start a pull request:\n1. If you are not familiar with GitHub or how to create a pull request, [here is a guide you can follow](https://guides.github.com/activities/hello-world/) on how GitHub works.\n\n- [ ] \uD83C\uDFC1 **Done** Ask in comments for a review :)\n\n### Is someone else already working on this?\n\n\uD83D\uDD17- We encourage contributors to link to the original issue in their pull request so all users can easily see if someone's already started on it.\n\n\uD83D\uDC65- **If someone seems stuck, offer them some help!**\n\n### \uD83E\uDD14??? Questions?\n\nDon???t hesitate to ask questions or to get help if you feel like you are getting stuck. For example leave a comment below!\nFurthermore, you find helpful resources here:\n* [ROS2 Control Contribution Guide](https://control.ros.org/master/doc/contributing/contributing.html)\n* [ROS2 Tutorials](https://docs.ros.org/en/rolling/Tutorials.html)\n* [Robotics Stack Exchange](https://robotics.stackexchange.com)\n\n**Good luck with your first issue!**\n            ",
      "updatedAt" : 1752254829.000000000,
      "user" : "christophfroehlich",
      "userHtmlUrl" : "https://github.com/christophfroehlich",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3367244?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello @christophfroehlich. I would like to claim this issue as my first open source contribution :) " ],
      "repository" : {
        "description" : "Generic robotic controllers to accompany ros2_control",
        "homepage" : "https://control.ros.org",
        "name" : "ros2_controllers",
        "fullName" : "ros-controls/ros2_controllers",
        "htmlUrl" : "https://github.com/ros-controls/ros2_controllers",
        "gitUrl" : "git://github.com/ros-controls/ros2_controllers.git",
        "sshUrl" : "git@github.com:ros-controls/ros2_controllers.git",
        "cloneUrl" : "https://github.com/ros-controls/ros2_controllers.git",
        "owner" : {
          "login" : "ros-controls",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 389,
        "stargazersCount" : 508,
        "watchersCount" : 508,
        "size" : 8948,
        "openIssuesCount" : 123,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-08T15:30:05Z",
        "languages" : {
          "C++" : 1423779,
          "CMake" : 69461,
          "Python" : 70273
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Check message for finite values in the forward_command_controller.",
      "validationOrRequirement" : "Check message for finite values using std::all_of, possibly.",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments.",
      "otherNotes" : "This is a good-first-issue issue, welcoming new contributors to Open Source. The issue is to check if message data elements are finite values in the forward_command_controller.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283454
  }, {
    "issueDTO" : {
      "id" : 3206905562,
      "title" : "Remove Hatch completly",
      "url" : "https://github.com/mlco2/codecarbon/issues/887",
      "repositoryName" : "mlco2/codecarbon",
      "description" : "**Is your feature request related to a problem? Please describe.**\nWe switch from Hatch to UV so we could clean the project.\n\n**Describe the solution you'd like**\nNo more reference to Hatch anywhere in the project, specially in `pyproject.toml`. \nBut check how to maintain a `requirements.txt` with UV, maybe with `pip-compile` or `pip freeze` ?\n\nWe also need to fix https://github.com/mlco2/codecarbon/actions/runs/16102396938/job/45433202545:\n\n```\nRun uv pip install --system requests\n  uv pip install --system requests\n  python3 .github/check_version.py -o\n  shell: /usr/bin/bash -e {0}\n  env:\n    UV_CACHE_DIR: /home/runner/work/_temp/setup-uv-cache\nUsing Python 3.12.3 environment at: /usr\nerror: The interpreter at /usr is externally managed, and indicates the following:\n```",
      "updatedAt" : 1752254772.000000000,
      "user" : "benoit-cty",
      "userHtmlUrl" : "https://github.com/benoit-cty",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6603048?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Track emissions from Compute and recommend ways to reduce their impact on the environment.",
        "homepage" : "https://mlco2.github.io/codecarbon",
        "name" : "codecarbon",
        "fullName" : "mlco2/codecarbon",
        "htmlUrl" : "https://github.com/mlco2/codecarbon",
        "gitUrl" : "git://github.com/mlco2/codecarbon.git",
        "sshUrl" : "git@github.com:mlco2/codecarbon.git",
        "cloneUrl" : "https://github.com/mlco2/codecarbon.git",
        "owner" : {
          "login" : "mlco2",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 216,
        "stargazersCount" : 1482,
        "watchersCount" : 1482,
        "size" : 29944,
        "openIssuesCount" : 127,
        "subscribersCount" : 21,
        "pushedAt" : "2025-07-11T18:05:03Z",
        "languages" : {
          "TypeScript" : 292721,
          "Dockerfile" : 3284,
          "CSS" : 7031,
          "Shell" : 741,
          "Jinja" : 623,
          "JavaScript" : 257,
          "Mako" : 494,
          "Python" : 801798
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to completely remove Hatch from the project and clean up any remaining references, specifically in pyproject.toml.",
      "validationOrRequirement" : "No specific validations or requirements are mentioned in the issue description, but it seems that the solution should involve maintaining a requirements.txt file with UV, possibly using pip-compile or pip freeze.",
      "attemptedFixes" : "There is a specific error with installing requests using pip, as shown in the provided output.",
      "otherNotes" : "The issue is related to a problem where Hatch is being replaced by UV, and the project needs to be cleaned up by removing all references to Hatch, including in pyproject.toml. Additionally, there is a specific error with installing requests using pip.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283459
  }, {
    "issueDTO" : {
      "id" : 1791758220,
      "title" : "Configure data entry tables & menu items picker displays incorrectly ",
      "url" : "https://github.com/specify/specify7/issues/3728",
      "repositoryName" : "specify/specify7",
      "description" : "### When the screen is very narrow:\r\n<img width=\"738\" alt=\"image\" src=\"https://github.com/specify/specify7/assets/37256050/1dc0eceb-0869-4b97-9766-f84e115067b1\">\r\n\r\n### When the screen is narrow:\r\n<img width=\"845\" alt=\"image\" src=\"https://github.com/specify/specify7/assets/37256050/a679ab19-cb5e-4706-9c92-83a111766b60\">\r\n\r\n### Even the label for this piece (Position) is incorrect\r\n<img width=\"1181\" alt=\"image\" src=\"https://github.com/specify/specify7/assets/37256050/5b7b499a-ce16-48d3-b079-3216c6327e36\">\r\n\r\nhttps://github.com/specify/specify7/assets/37256050/ed661bee-be0b-4210-9c46-66ed0d9559f8\r\n\r\nSee the current issue:\r\n\r\n<img width=\"943\" alt=\"image\" src=\"https://github.com/specify/specify7/assets/37256050/9796a984-7552-4f71-a7ff-d63ae2035e6c\">\r\n\r\n\r\n## Solution\r\n\r\nThese two tables should occupy the full-width of this table.\r\n\r\n\r\nhttps://github.com/specify/specify7/assets/37256050/11d76055-e219-4c2c-b474-5efd7f7b2325",
      "updatedAt" : 1752254735.000000000,
      "user" : "grantfitzsimmons",
      "userHtmlUrl" : "https://github.com/grantfitzsimmons",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/37256050?v=4",
      "labels" : [ "2 - Preferences", "1 - Bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Can recreate in edge (7.9.6)", "![Image](https://github.com/user-attachments/assets/51231b17-1c64-43f7-bcf4-f36d7674f355)\n\nIt's been getting worse for me on Arc, macOS", "<img width=\"786\" height=\"555\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3a1230b4-2a43-46a5-a248-fe3bfa1c657a\" />\n\nReported by: Andy at KU, Windows" ],
      "repository" : {
        "description" : "An open-source platform for managing biological and geological collections.",
        "homepage" : "https://www.specifysoftware.org/products/specify-7/",
        "name" : "specify7",
        "fullName" : "specify/specify7",
        "htmlUrl" : "https://github.com/specify/specify7",
        "gitUrl" : "git://github.com/specify/specify7.git",
        "sshUrl" : "git@github.com:specify/specify7.git",
        "cloneUrl" : "https://github.com/specify/specify7.git",
        "owner" : {
          "login" : "specify",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 37,
        "stargazersCount" : 75,
        "watchersCount" : 75,
        "size" : 107580,
        "openIssuesCount" : 816,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-11T21:04:44Z",
        "languages" : {
          "TypeScript" : 5646278,
          "Dockerfile" : 8753,
          "CSS" : 15291,
          "Shell" : 588,
          "Makefile" : 1741,
          "JavaScript" : 48958,
          "HTML" : 3979,
          "Nix" : 312,
          "Python" : 5018879
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Configure data entry tables and menu items picker displays incorrectly when the screen is very narrow.",
      "validationOrRequirement" : "The tables should occupy the full-width of the table.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The issue is reproducible in Edge (7.9.6) and getting worse on Arc, macOS, with images provided to demonstrate the problem.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283462
  }, {
    "issueDTO" : {
      "id" : 3031998051,
      "title" : "support `target` parameter for `generate_random_paths`",
      "url" : "https://github.com/networkx/networkx/issues/8014",
      "repositoryName" : "networkx/networkx",
      "description" : "              Also, we can consider adding a `target` (ending node) parameter here too. btw, not a blocker for this PR :)\n\n_Originally posted by @Schefflera-Arboricola in https://github.com/networkx/networkx/pull/8002#discussion_r2062660325_\n            \n\nassumed pre-requisites:\n- know how `generate_random_paths` works? --> you can read the documentation to understand this.",
      "updatedAt" : 1752254663.000000000,
      "user" : "Schefflera-Arboricola",
      "userHtmlUrl" : "https://github.com/Schefflera-Arboricola",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/91629733?v=4",
      "labels" : [ "Good First Issue", "type: Enhancements" ],
      "state" : "OPEN",
      "comments" : [ "Is this particularly easy to do? It seems hard to constrain the end/`target` node because of the random nature of the walk. The dependence of the next step on the \"future\" would also lead to it no longer being a Markov process, I believe. That's pretty unusual for a random walk algorithm - so might warrant some consideration before implementing.", "I don't think there is any dependence of the steps on where the walk ends. You just use the probabilities for each step... and you stop when that walk hits the target.  I can imagine some very long walks though... :)  Each walk is still very much Markovian. ", "Ah, yeah, did not consider the infinite case! And even in the case where we are concerned with walks of fixed length $T$ like in the panther paper, I'm now thinking it's Markovian, albeit not time-homogenous anymore. \n\nGetting back to implementing `target`, if `source` is not specified, we could just 'reverse' the direction of time, and walk backward from the `target` node using the transposed transition matrix. So that doesn't seem too bad. :)\n\nImplementing it still seems rather tricky to me if we need to support the case where `source` can also be specified. I can't think of any smarter way to do it than computing all paths of length $T$ between `source` and `target`, using the transition matrix to calculate their probabilities in the broader space of all paths of length $T$ starting from `source`, and normalizing.", "It's actually fairly simple to find with a source and a target -- just don't use any mathematical equations :)  Start at the source and pick neighbors randomly the way you always do. Keep going until you hit the target node. Yield the resulting path.  That's the method folks used before Markov figured out how to \"do the math\" to compute long run probabilities.  This is just a straight forward monte carlo simulation.", "Ah, okay! So, in our case we're looking for paths specifically of exact length $T$, with target specifically being the $T$-th node in the path. \n\nIf I'm understanding correctly, this means there are two changes to be made:\n\n1. Check if a path of exact length $T$ exist between source and target, and raise some exception if not.\n\n2. We also currently perform a fixed number of random walks. To add target, and ensure we still return `sample_size` paths, we'll need to modify this to check if the final node of the path is indeed target, and if so, add the path to our samples, check the length, and break out of the loop once `sample_size` has been reached.", "Given that this is harder than users might realize, we should state it in the docs ", "Clearly only target node given is symmetrical to only source node given.\nIf both source and target nodes are given, here is another method which involves some preprocessing in which no sampling will be wasted:\n\nLet **P** be an **n x n** transition matrix, and define for each node **v** and remaining steps **k** the probability:\n\n$$\nh_k (v) = \\text{Pr(reach target in exactly k steps | start at v)}\n$$\n\nCompute **h\\_k(v)** using Dynamic Programming:\n\n$$\nh_0(v) = 1 \\text{ for target node } v \\text{, else 0}\n$$\n\n$$\nh_{k+1}(v) = \\sum P[v][u] \\cdot h_k(u) \\text{ for each } u \\text{ such that } v \\rightarrow u \\text{ is an edge}\n$$\n\nThen sampling is done with weight (at node **v**, **k** steps are left):\n\n$$\n\\text{Pr}(u | v, \\text{must hit target in k}) = \\frac{P[v][u] \\cdot h_{k-1}(u)}{h_k(u)}\n$$\n\nNote: if no path of length T exists, h[T, source] = 0. We may then raise error..", "There's a nice discussion here about *how* this might be done, but I don't think the *why* has been sufficiently addressed. Is this something that really a feature that needs to be added directly to `generate_random_paths`, or something better served by using the existing functionality?\n\nFor example, if I want to generate random walks (as noted in previous discussions, this function's name is a bit miscast) with a specific target I can do something like:\n\n```python\n>>> G = nx.star_graph(10)\n>>> walks = nx.generate_random_paths(G, sample_size=1000, path_length=6, source=1)\n>>> target_node = 5\n>>> targeted_walks = [p for p in gen if p[-1] == target_node]\n>>> len(targeted_walks)  # random when unseeded, expect ~10% of sample_size\n89\n```\n\nThe above formulation gives the number of walks for a given sample size. If instead a user wanted a fixed number of random walks (and how many iterations it takes to achieve this), they could do something like:\n\n```python\n>>> G = nx.star_graph(10)\n>>> walks = nx.generate_random_paths(G, sample_size=1000, path_length=6, source=1)\n>>> target_node = 5\n>>> desired_num_walks = 3\n>>> rws = []\n>>> for sample_no, walk in enumerate(walks, start=1):\n...     if walk[-1] == target_node:\n...         rws.append(walk)\n...     if len(rws) == desired_num_walks:\n...         break\n>>> rws\n[[1, 0, 5, 0, 7, 0, 5], [1, 0, 4, 0, 6, 0, 5], [1, 0, 8, 0, 10, 0, 5]]\n>>> sample_no\n9\n```\n\nI chose `star_graph` on purpose to illustrate one of the pitfalls of \"targeted\" random walks. If you start on any of the leaf nodes of the star, then an odd number of steps in the walk will *always* land on the root node[^1]. In other words, for this specific graph half of all n-length walks are not possible!\n\n```python\n>>> walks = nx.generate_random_paths(G, sample_size=1000, path_length=5, source=1)\n>>> [p for p in walks if p[-1] == 5]\n[]\n```\n\nKnowing that there's a path between the source and target nodes *doesn't* guarantee that there is a walk of a specific length between them!\n\nIMO, adding a `target` option to this function is not necessarily a good idea. I think forcing users to be explicit about what exactly it is they want (examples of which above) is much clearer and in the end would be less error-prone.\n\n[^1]: And vice-versa: if you start on the root node, all even-length walks will end on the root node.", "@rossbar I think this a good point. It might be easier to just try sampling random walks and filtering out the ones that satisfies the users requirements. If the graph has more nodes, the user could sample more times and this might be faster than computing probabilities. However, it might be that there are only 1 or 2 (or 0 paths as you mention!) path from source to target of the specified length, say 100 long. In these exceptional cases, a very small number of the samples will meet users' requirements and users would have to guess what a good sample size should be. I think that it is beneficial to have code that can calculate the probabilities and also tell you if there is no such possible path. It could be code that is independent from the `generate_random_paths` function.\n\n(I've never used the `generate_random_paths` function in a project before so I might not know what is the most common use case. This issue seemed doable for me so I gave it a shot.)" ],
      "repository" : {
        "description" : "Network Analysis in Python",
        "homepage" : "https://networkx.org",
        "name" : "networkx",
        "fullName" : "networkx/networkx",
        "htmlUrl" : "https://github.com/networkx/networkx",
        "gitUrl" : "git://github.com/networkx/networkx.git",
        "sshUrl" : "git@github.com:networkx/networkx.git",
        "cloneUrl" : "https://github.com/networkx/networkx.git",
        "owner" : {
          "login" : "networkx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3382,
        "stargazersCount" : 15944,
        "watchersCount" : 15944,
        "size" : 95347,
        "openIssuesCount" : 396,
        "subscribersCount" : 281,
        "pushedAt" : "2025-07-11T20:24:58Z",
        "languages" : {
          "Python" : 6351039
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a `target` parameter to the `generate_random_paths` function, which would allow users to generate random walks with a specific target node. The discussion revolves around the feasibility of this feature and the potential complexity of implementing it.",
      "validationOrRequirement" : "The issue requires a deep understanding of the `generate_random_paths` function and its implementation. The contributors have discussed the feasibility of adding a `target` parameter and the potential complexity of the implementation.",
      "attemptedFixes" : "Some contributors have suggested ways to implement the `target` feature, including using a Monte Carlo simulation and computing probabilities using dynamic programming. Others have raised concerns about the complexity of the implementation and the potential for errors.",
      "otherNotes" : "The issue is about adding a `target` parameter to `generate_random_paths` function. The discussion revolves around the feasibility of this feature and the potential complexity of implementing it. Some contributors think it's not a good idea to add this feature directly to the function, while others suggest using the existing functionality to achieve the desired result.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283470
  }, {
    "issueDTO" : {
      "id" : 3222190665,
      "title" : "[deploy] NPE when deploying to maven central",
      "url" : "https://github.com/jreleaser/jreleaser/issues/1926",
      "repositoryName" : "jreleaser/jreleaser",
      "description" : "I have this really wired NullPointerException when performing a publication to maven central with:\n\n`./gradlew --stacktrace jreleaserDeploy`\n\n```\norg.gradle.api.tasks.TaskExecutionException: Execution failed for task ':jreleaserDeploy'.\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.lambda$executeIfValid$1(ExecuteActionsTaskExecuter.java:142)\n\tat org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:282)\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:140)\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:128)\n\tat org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:77)\n\tat org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46)\n\tat org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:51)\n\tat org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57)\n\tat org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:57)\n\tat org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36)\n\tat org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77)\n\tat org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55)\n\tat org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n\tat org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52)\n\tat org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:69)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:322)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:309)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:302)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:288)\n\tat org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:462)\n\tat org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:379)\n\tat org.gradle.execution.plan.DefaultPlanExecutor.process(DefaultPlanExecutor.java:115)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph.executeWithServices(DefaultTaskExecutionGraph.java:135)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph.execute(DefaultTaskExecutionGraph.java:120)\n\tat org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:35)\n\tat org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:51)\n\tat org.gradle.execution.BuildOperationFiringBuildWorkerExecutor$ExecuteTasks.call(BuildOperationFiringBuildWorkerExecutor.java:54)\n\tat org.gradle.execution.BuildOperationFiringBuildWorkerExecutor$ExecuteTasks.call(BuildOperationFiringBuildWorkerExecutor.java:43)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n\tat org.gradle.execution.BuildOperationFiringBuildWorkerExecutor.execute(BuildOperationFiringBuildWorkerExecutor.java:40)\n\tat org.gradle.internal.build.DefaultBuildLifecycleController.lambda$executeTasks$6(DefaultBuildLifecycleController.java:167)\n\tat org.gradle.internal.model.StateTransitionController.doTransition(StateTransitionController.java:247)\n\tat org.gradle.internal.model.StateTransitionController.lambda$tryTransition$7(StateTransitionController.java:174)\n\tat org.gradle.internal.work.DefaultSynchronizer.withLock(DefaultSynchronizer.java:44)\n\tat org.gradle.internal.model.StateTransitionController.tryTransition(StateTransitionController.java:174)\n\tat org.gradle.internal.build.DefaultBuildLifecycleController.executeTasks(DefaultBuildLifecycleController.java:167)\n\tat org.gradle.internal.build.DefaultBuildWorkGraphController$DefaultBuildWorkGraph.runWork(DefaultBuildWorkGraphController.java:190)\n\tat org.gradle.internal.work.DefaultWorkerLeaseService.withLocks(DefaultWorkerLeaseService.java:249)\n\tat org.gradle.internal.work.DefaultWorkerLeaseService.runAsWorkerThread(DefaultWorkerLeaseService.java:109)\n\tat org.gradle.composite.internal.DefaultBuildController.doRun(DefaultBuildController.java:172)\n\tat org.gradle.composite.internal.DefaultBuildController.access$000(DefaultBuildController.java:47)\n\tat org.gradle.composite.internal.DefaultBuildController$BuildOpRunnable.run(DefaultBuildController.java:191)\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\n\tat org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:49)\nCaused by: java.lang.NullPointerException: Cannot invoke \"java.nio.file.Path.getFileName()\" because \"p\" is null\n\tat org.jreleaser.model.spi.deploy.maven.Deployable.<init>(Deployable.java:97)\n\tat org.jreleaser.sdk.commons.AbstractMavenDeployer$DeployableCollector.addDeployable(AbstractMavenDeployer.java:681)\n\tat org.jreleaser.sdk.commons.AbstractMavenDeployer$DeployableCollector.match(AbstractMavenDeployer.java:667)\n\tat org.jreleaser.sdk.commons.AbstractMavenDeployer$DeployableCollector.visitFile(AbstractMavenDeployer.java:717)\n\tat org.jreleaser.sdk.commons.AbstractMavenDeployer$DeployableCollector.visitFile(AbstractMavenDeployer.java:648)\n\tat org.jreleaser.sdk.commons.AbstractMavenDeployer.collectDeployables(AbstractMavenDeployer.java:167)\n\tat org.jreleaser.sdk.commons.AbstractMavenDeployer.collectDeployableArtifacts(AbstractMavenDeployer.java:118)\n\tat org.jreleaser.sdk.commons.AbstractMavenDeployer.collectDeployables(AbstractMavenDeployer.java:129)\n\tat org.jreleaser.sdk.commons.AbstractMavenDeployer.collectDeployables(AbstractMavenDeployer.java:125)\n\tat org.jreleaser.sdk.mavencentral.MavenCentralMavenDeployer.deploy(MavenCentralMavenDeployer.java:84)\n\tat org.jreleaser.engine.deploy.maven.ProjectMavenDeployer.deploy(ProjectMavenDeployer.java:55)\n\tat org.jreleaser.engine.deploy.maven.MavenDeployers.deploy(MavenDeployers.java:167)\n\tat org.jreleaser.engine.deploy.maven.MavenDeployers.doDeploy(MavenDeployers.java:150)\n\tat org.jreleaser.engine.deploy.maven.MavenDeployers.deploy(MavenDeployers.java:59)\n\tat org.jreleaser.workflow.DeployWorkflowItem.doInvoke(DeployWorkflowItem.java:35)\n\tat org.jreleaser.workflow.AbstractWorkflowItem.lambda$invoke$0(AbstractWorkflowItem.java:43)\n\tat org.jreleaser.engine.hooks.HookExecutor.execute(HookExecutor.java:72)\n\tat org.jreleaser.workflow.AbstractWorkflowItem.invoke(AbstractWorkflowItem.java:43)\n\tat org.jreleaser.workflow.WorkflowImpl.doExecute(WorkflowImpl.java:130)\n\tat org.jreleaser.workflow.WorkflowImpl.execute(WorkflowImpl.java:54)\n\tat org.jreleaser.gradle.plugin.tasks.JReleaserDeployTask.performAction(JReleaserDeployTask.groovy:98)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:125)\n\tat org.gradle.api.internal.project.taskfactory.StandardTaskAction.doExecute(StandardTaskAction.java:58)\n\tat org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:51)\n\tat org.gradle.api.internal.project.taskfactory.StandardTaskAction.execute(StandardTaskAction.java:29)\n\tat org.gradle.api.internal.tasks.execution.TaskExecution$3.run(TaskExecution.java:236)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$1.execute(DefaultBuildOperationRunner.java:29)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$1.execute(DefaultBuildOperationRunner.java:26)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.run(DefaultBuildOperationRunner.java:47)\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:68)\n\tat org.gradle.api.internal.tasks.execution.TaskExecution.executeAction(TaskExecution.java:221)\n\tat org.gradle.api.internal.tasks.execution.TaskExecution.executeActions(TaskExecution.java:204)\n\tat org.gradle.api.internal.tasks.execution.TaskExecution.executeWithPreviousOutputFiles(TaskExecution.java:187)\n\tat org.gradle.api.internal.tasks.execution.TaskExecution.execute(TaskExecution.java:165)\n\tat org.gradle.internal.execution.steps.ExecuteStep.executeInternal(ExecuteStep.java:89)\n\tat org.gradle.internal.execution.steps.ExecuteStep.access$000(ExecuteStep.java:40)\n\tat org.gradle.internal.execution.steps.ExecuteStep$1.call(ExecuteStep.java:53)\n\tat org.gradle.internal.execution.steps.ExecuteStep$1.call(ExecuteStep.java:50)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n\tat org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:50)\n\tat org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:40)\n\tat org.gradle.internal.execution.steps.RemovePreviousOutputsStep.execute(RemovePreviousOutputsStep.java:68)\n\tat org.gradle.internal.execution.steps.RemovePreviousOutputsStep.execute(RemovePreviousOutputsStep.java:38)\n\tat org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:41)\n\tat org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:74)\n\tat org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:55)\n\tat org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51)\n\tat org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:29)\n\tat org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.executeDelegateBroadcastingChanges(CaptureStateAfterExecutionStep.java:124)\n\tat org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.execute(CaptureStateAfterExecutionStep.java:80)\n\tat org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.execute(CaptureStateAfterExecutionStep.java:58)\n\tat org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48)\n\tat org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:36)\n\tat org.gradle.internal.execution.steps.BuildCacheStep.executeWithoutCache(BuildCacheStep.java:181)\n\tat org.gradle.internal.execution.steps.BuildCacheStep.lambda$execute$1(BuildCacheStep.java:71)\n\tat org.gradle.internal.Either$Right.fold(Either.java:175)\n\tat org.gradle.internal.execution.caching.CachingState.fold(CachingState.java:59)\n\tat org.gradle.internal.execution.steps.BuildCacheStep.execute(BuildCacheStep.java:69)\n\tat org.gradle.internal.execution.steps.BuildCacheStep.execute(BuildCacheStep.java:47)\n\tat org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:36)\n\tat org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:25)\n\tat org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:36)\n\tat org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:22)\n\tat org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:110)\n\tat org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$2(SkipUpToDateStep.java:56)\n\tat org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:56)\n\tat org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38)\n\tat org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:73)\n\tat org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:44)\n\tat org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:37)\n\tat org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:27)\n\tat org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:89)\n\tat org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:50)\n\tat org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:102)\n\tat org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:57)\n\tat org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:76)\n\tat org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:50)\n\tat org.gradle.internal.execution.steps.SkipEmptyWorkStep.executeWithNoEmptySources(SkipEmptyWorkStep.java:254)\n\tat org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:91)\n\tat org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:56)\n\tat org.gradle.internal.execution.steps.RemoveUntrackedExecutionStateStep.execute(RemoveUntrackedExecutionStateStep.java:32)\n\tat org.gradle.internal.execution.steps.RemoveUntrackedExecutionStateStep.execute(RemoveUntrackedExecutionStateStep.java:21)\n\tat org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsStartedStep.execute(MarkSnapshottingInputsStartedStep.java:38)\n\tat org.gradle.internal.execution.steps.LoadPreviousExecutionStateStep.execute(LoadPreviousExecutionStateStep.java:43)\n\tat org.gradle.internal.execution.steps.LoadPreviousExecutionStateStep.execute(LoadPreviousExecutionStateStep.java:31)\n\tat org.gradle.internal.execution.steps.AssignWorkspaceStep.lambda$execute$0(AssignWorkspaceStep.java:40)\n\tat org.gradle.api.internal.tasks.execution.TaskExecution$4.withWorkspace(TaskExecution.java:281)\n\tat org.gradle.internal.execution.steps.AssignWorkspaceStep.execute(AssignWorkspaceStep.java:40)\n\tat org.gradle.internal.execution.steps.AssignWorkspaceStep.execute(AssignWorkspaceStep.java:30)\n\tat org.gradle.internal.execution.steps.IdentityCacheStep.execute(IdentityCacheStep.java:37)\n\tat org.gradle.internal.execution.steps.IdentityCacheStep.execute(IdentityCacheStep.java:27)\n\tat org.gradle.internal.execution.steps.IdentifyStep.execute(IdentifyStep.java:44)\n\tat org.gradle.internal.execution.steps.IdentifyStep.execute(IdentifyStep.java:33)\n\tat org.gradle.internal.execution.impl.DefaultExecutionEngine$1.execute(DefaultExecutionEngine.java:76)\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:139)\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:128)\n\tat org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:77)\n\tat org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46)\n\tat org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:51)\n\tat org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57)\n\tat org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:57)\n\tat org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36)\n\tat org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77)\n\tat org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55)\n\tat org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n\tat org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52)\n\tat org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:69)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:322)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:309)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:302)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:288)\n\tat org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:462)\n\tat org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:379)\n\tat org.gradle.execution.plan.DefaultPlanExecutor.process(DefaultPlanExecutor.java:115)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph.executeWithServices(DefaultTaskExecutionGraph.java:135)\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionGraph.execute(DefaultTaskExecutionGraph.java:120)\n\tat org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:35)\n\tat org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:51)\n\tat org.gradle.execution.BuildOperationFiringBuildWorkerExecutor$ExecuteTasks.call(BuildOperationFiringBuildWorkerExecutor.java:54)\n\tat org.gradle.execution.BuildOperationFiringBuildWorkerExecutor$ExecuteTasks.call(BuildOperationFiringBuildWorkerExecutor.java:43)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n\tat org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n\tat org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n\tat org.gradle.execution.BuildOperationFiringBuildWorkerExecutor.execute(BuildOperationFiringBuildWorkerExecutor.java:40)\n\tat org.gradle.internal.build.DefaultBuildLifecycleController.lambda$executeTasks$6(DefaultBuildLifecycleController.java:167)\n\tat org.gradle.internal.model.StateTransitionController.doTransition(StateTransitionController.java:247)\n\tat org.gradle.internal.model.StateTransitionController.lambda$tryTransition$7(StateTransitionController.java:174)\n\tat org.gradle.internal.work.DefaultSynchronizer.withLock(DefaultSynchronizer.java:44)\n\tat org.gradle.internal.model.StateTransitionController.tryTransition(StateTransitionController.java:174)\n\tat org.gradle.internal.build.DefaultBuildLifecycleController.executeTasks(DefaultBuildLifecycleController.java:167)\n\tat org.gradle.internal.build.DefaultBuildWorkGraphController$DefaultBuildWorkGraph.runWork(DefaultBuildWorkGraphController.java:190)\n\tat org.gradle.internal.work.DefaultWorkerLeaseService.withLocks(DefaultWorkerLeaseService.java:249)\n\tat org.gradle.internal.work.DefaultWorkerLeaseService.runAsWorkerThread(DefaultWorkerLeaseService.java:109)\n\tat org.gradle.composite.internal.DefaultBuildController.doRun(DefaultBuildController.java:172)\n\tat org.gradle.composite.internal.DefaultBuildController.access$000(DefaultBuildController.java:47)\n\tat org.gradle.composite.internal.DefaultBuildController$BuildOpRunnable.run(DefaultBuildController.java:191)\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\n\tat org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:49)\n```\n\nI checked all the occurences of the file that I think is the parent being null with:\n\n`find . -name 'maven-metadata.xml*'` \n\nAnd the result looks good to me:\n```\n./build/staging-deploy/{groupid folders}/{artifactId 1}/maven-metadata.xml.sha256\n./build/staging-deploy/{groupid folders}/{artifactid 1}/maven-metadata.xml\n./build/staging-deploy/{groupid folders}/{artifactid 1}/maven-metadata.xml.sha512\n./build/staging-deploy/{groupid folders}/{artifactid 1}/maven-metadata.xml.md5\n./build/staging-deploy/{groupid folders}/{artifactid 1}/maven-metadata.xml.sha1\n./build/staging-deploy/{groupid folders}/{artifactid 2}/maven-metadata.xml.sha256\n./build/staging-deploy/{groupid folders}/{artifactid 2}/maven-metadata.xml\n./build/staging-deploy/{groupid folders}/{artifactid 2}/maven-metadata.xml.sha512\n./build/staging-deploy/{groupid folders}/{artifactid 2}/maven-metadata.xml.md5\n./build/staging-deploy/{groupid folders}/{artifactid 2}/maven-metadata.xml.sha1\n./build/staging-deploy/{groupid folders}/{artifactid 3}/maven-metadata.xml.sha256\n./build/staging-deploy/{groupid folders}/{artifactid 3}/maven-metadata.xml\n./build/staging-deploy/{groupid folders}/{artifactid 3}/maven-metadata.xml.sha512\n./build/staging-deploy/{groupid folders}/{artifactid 3}/maven-metadata.xml.md5\n./build/staging-deploy/{groupid folders}/{artifactid 3}/maven-metadata.xml.sha1\n...\n```\n\nNext step would be to suspend and debug my gradle build to be able to inspect what is going wired??? (not sure how to do this) or to recompile a jreleaser version that gives more logs at the corresponding method.\n\nCode location (line 97 is where the NPE occurs)\n\nhttps://github.com/jreleaser/jreleaser/blob/737bdb7c18303cea681123441a18ecc4873178af/core/jreleaser-model-impl/src/main/java/org/jreleaser/model/spi/deploy/maven/Deployable.java#L93-L104\n\nOf course [getParent()](https://docs.oracle.com/javase/8/docs/api/java/nio/file/Path.html#getParent--) can return null, but it makes no sense to me in that context...",
      "updatedAt" : 1752254650.000000000,
      "user" : "jmini",
      "userHtmlUrl" : "https://github.com/jmini",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1222165?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This is likely a problem trying to find a matching version number on a given file name. \n\nCould you post the contents of the local staged directory? Would be good if you use the `tree` command. ", "Debugging was not so hard\n\n```\n./gradlew --stop\n./gradlew -Dorg.gradle.debug=true  --no-daemon --stacktrace --console=PLAIN jreleaserDeploy\n```\n\nI think I opened the folder  with the macOS finder to verify something and this created invisible `.DS_Store` files???\n\n<img width=\"823\" height=\"438\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/87de1212-625b-44f2-89c7-185bb3aac9e3\" />", "Thanks. There's indeed a bug in the code due to unexpected inputs. ", "What would be the solution, ignore invisible files like `.DS_store`? \n\nSimilar to the `!filename.startsWith(MAVEN_METADATA_XML)` here:\nhttps://github.com/jreleaser/jreleaser/blob/737bdb7c18303cea681123441a18ecc4873178af/core/jreleaser-model-impl/src/main/java/org/jreleaser/model/spi/deploy/maven/Deployable.java#L93\n\nI need to check if you have a test suite and where it is???", "I believe we don't have a test for it yet. Also, the fix in the constructor is too late. Rather, there should be a factory method that either creates a Deployable instance or returns an empty Optional so that the caller may decide what to do. " ],
      "repository" : {
        "description" : ":rocket: Release projects quickly and easily with JReleaser",
        "homepage" : "https://jreleaser.org",
        "name" : "jreleaser",
        "fullName" : "jreleaser/jreleaser",
        "htmlUrl" : "https://github.com/jreleaser/jreleaser",
        "gitUrl" : "git://github.com/jreleaser/jreleaser.git",
        "sshUrl" : "git@github.com:jreleaser/jreleaser.git",
        "cloneUrl" : "https://github.com/jreleaser/jreleaser.git",
        "owner" : {
          "login" : "jreleaser",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 127,
        "stargazersCount" : 1139,
        "watchersCount" : 1139,
        "size" : 16599,
        "openIssuesCount" : 105,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-03T09:55:12Z",
        "languages" : {
          "Smarty" : 187235,
          "Java" : 5227725,
          "Shell" : 58802,
          "Groovy" : 1058187,
          "Tcl" : 12113
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the NPE when trying to get the parent directory of a file, which is likely an invisible file like .DS_Store.",
      "validationOrRequirement" : "The file should not be an invisible file like .DS_Store.",
      "attemptedFixes" : "The fix in the constructor is too late. Rather, there should be a factory method that either creates a Deployable instance or returns an empty Optional so that the caller may decide what to do.",
      "otherNotes" : "The issue seems to be related to the NPE when trying to get the parent directory of a file. The file is likely an invisible file like .DS_Store, which is created by the macOS finder. The solution could be to ignore invisible files like .DS_Store. The bug is due to unexpected inputs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283476
  }, {
    "issueDTO" : {
      "id" : 3223055261,
      "title" : "Document startscript format and options better",
      "url" : "https://github.com/beyond-all-reason/RecoilEngine/issues/2458",
      "repositoryName" : "beyond-all-reason/RecoilEngine",
      "description" : "We need a guide detailing what startscripts are for and how to use them (clarification on the format and each option).\n\nCurrently we only have [a page](https://github.com/beyond-all-reason/RecoilEngine/blob/master/doc/site/content/articles/start-script-format.md) for it that only contains a copy paste of an example start script. This page should be updated to contain this information.\n\nNote [technicalities-of-starting-a-match](https://github.com/beyond-all-reason/RecoilEngine/blob/master/doc/site/content/articles/technicalities-of-starting-a-match.markdown) should provide information on how to start a game with a startscript so we can focus just on the format itself.\n\nModoptions only need to be clarified briefly, it should link to a guide for modoptions. See https://github.com/beyond-all-reason/RecoilEngine/issues/2459\n\nSee:\n\n- [CGameSetup::Init](https://github.com/beyond-all-reason/RecoilEngine/blob/5e0e29257671e389e2e1e375f45bdb45f9d206c5/rts/Game/GameSetup.cpp#L551)",
      "updatedAt" : 1752254592.000000000,
      "user" : "badosu",
      "userHtmlUrl" : "https://github.com/badosu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/347552?v=4",
      "labels" : [ "area: documentation", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "There's this article https://github.com/beyond-all-reason/RecoilEngine/blob/master/doc/site/content/articles/technicalities-of-starting-a-match.markdown which is a human-readable description of adjacent topics, it also links to the startscript listing/example.", "That's great, we can restrict the scope of the new page to just clarify what exactly is the startscript format then.\n\nWe still don't have examples of how for example standalone (no luamenu) games are started by external lua lobbies or manually on the technicalities page, but I guess it's not a big deal." ],
      "repository" : {
        "description" : "A powerful free cross-platform RTS game engine",
        "homepage" : "https://beyond-all-reason.github.io/RecoilEngine/",
        "name" : "RecoilEngine",
        "fullName" : "beyond-all-reason/RecoilEngine",
        "htmlUrl" : "https://github.com/beyond-all-reason/RecoilEngine",
        "gitUrl" : "git://github.com/beyond-all-reason/RecoilEngine.git",
        "sshUrl" : "git@github.com:beyond-all-reason/RecoilEngine.git",
        "cloneUrl" : "https://github.com/beyond-all-reason/RecoilEngine.git",
        "owner" : {
          "login" : "beyond-all-reason",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 341,
        "watchersCount" : 341,
        "size" : 205721,
        "openIssuesCount" : 771,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-11T22:29:02Z",
        "languages" : {
          "Java" : 41936,
          "C++" : 24315759,
          "C" : 3074390,
          "CMake" : 333555,
          "Makefile" : 59811,
          "HTML" : 125785,
          "Perl" : 23604,
          "NSIS" : 32088,
          "Dockerfile" : 6431,
          "Shell" : 54303,
          "sed" : 1389,
          "Awk" : 278422,
          "Batchfile" : 573,
          "Lua" : 773509,
          "Objective-C" : 8705,
          "Assembly" : 721,
          "GLSL" : 129310,
          "Python" : 18613
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document the startscript format and options better, including a guide detailing what startscripts are for and how to use them",
      "validationOrRequirement" : "The page should contain information on the format and each option of startscripts, modoptions should be clarified briefly and link to a guide for modoptions.",
      "attemptedFixes" : "There's already a page for startscripts that only contains a copy paste of an example start script.",
      "otherNotes" : "There's this article https://github.com/beyond-all-reason/RecoilEngine/blob/master/doc/site/content/articles/technicalities-of-starting-a-match.markdown which is a human-readable description of adjacent topics, it also links to the startscript listing/example., We still don't have examples of how for example standalone (no luamenu) games are started by external lua lobbies or manually on the technicalities page, but I guess it's not a big deal.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283483
  }, {
    "issueDTO" : {
      "id" : 3223686591,
      "title" : "CmdPal: Use `EmptyContent` in more places for built-ins",
      "url" : "https://github.com/microsoft/PowerToys/issues/40565",
      "repositoryName" : "microsoft/PowerToys",
      "description" : "### Describe the requested doc changes\n\n`IListPage.EmptyContent` is a neat little treatment that a page can use to customize the appearance of the page when there are no results. \n\nCase in point: #40549\n\nWe didn't use it for most built-in, because PT Run had no concept of it. But we should use it in more places. \n\n(someone should feel free to hijack this thread and add the scenarios we're missing)",
      "updatedAt" : 1752254590.000000000,
      "user" : "zadjii-msft",
      "userHtmlUrl" : "https://github.com/zadjii-msft",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18356694?v=4",
      "labels" : [ "Issue-Task", "Good first issue", "Help Wanted", "Needs-Triage", "Product-Command Palette" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Windows system utilities to maximize productivity",
        "homepage" : "",
        "name" : "PowerToys",
        "fullName" : "microsoft/PowerToys",
        "htmlUrl" : "https://github.com/microsoft/PowerToys",
        "gitUrl" : "git://github.com/microsoft/PowerToys.git",
        "sshUrl" : "git@github.com:microsoft/PowerToys.git",
        "cloneUrl" : "https://github.com/microsoft/PowerToys.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 7174,
        "stargazersCount" : 120802,
        "watchersCount" : 120802,
        "size" : 436734,
        "openIssuesCount" : 6804,
        "subscribersCount" : 1157,
        "pushedAt" : "2025-07-11T22:19:12Z",
        "languages" : {
          "C#" : 9039749,
          "PowerShell" : 135117,
          "C++" : 6138973,
          "C" : 141691,
          "Batchfile" : 2484,
          "Makefile" : 1408,
          "JavaScript" : 11105,
          "HTML" : 9750,
          "HLSL" : 3261,
          "Rich Text Format" : 9666
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Use `EmptyContent` in more places for built-ins",
      "validationOrRequirement" : "use `EmptyContent` in more places for built-ins, PT Run had no concept of it",
      "attemptedFixes" : "",
      "otherNotes" : "IListPage.EmptyContent is a treatment to customize the appearance of a page when there are no results, used in #40549",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283486
  }, {
    "issueDTO" : {
      "id" : 3223670946,
      "title" : "Scene File Indentation Removed",
      "url" : "https://github.com/rust-av/Av1an/issues/1062",
      "repositoryName" : "rust-av/Av1an",
      "description" : "When av1an receives a scene file input, it overwrites the file with the indentations removed which makes it difficult to troubleshoot or recheck individual scenes.\n\n[Original scene file passed.json](https://github.com/user-attachments/files/21187415/Original.scene.file.passed.json)\n[Scene file after encoding.json](https://github.com/user-attachments/files/21187416/Scene.file.after.encoding.json)",
      "updatedAt" : 1752254542.000000000,
      "user" : "Ironclad17",
      "userHtmlUrl" : "https://github.com/Ironclad17",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20147654?v=4",
      "labels" : [ "rust", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Cross-platform command-line AV1 / VP9 / HEVC / H264  encoding framework with per scene quality encoding",
        "homepage" : "",
        "name" : "Av1an",
        "fullName" : "rust-av/Av1an",
        "htmlUrl" : "https://github.com/rust-av/Av1an",
        "gitUrl" : "git://github.com/rust-av/Av1an.git",
        "sshUrl" : "git@github.com:rust-av/Av1an.git",
        "cloneUrl" : "https://github.com/rust-av/Av1an.git",
        "owner" : {
          "login" : "rust-av",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 166,
        "stargazersCount" : 1657,
        "watchersCount" : 1657,
        "size" : 17277,
        "openIssuesCount" : 146,
        "subscribersCount" : 34,
        "pushedAt" : "2025-07-08T17:28:03Z",
        "languages" : {
          "Dockerfile" : 1318,
          "Rust" : 420224
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove scene file indentation removal when receiving a scene file input.",
      "validationOrRequirement" : "Scene file input should not overwrite the file with indentation removed.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description.",
      "otherNotes" : "Scene file indentation removal makes it difficult to troubleshoot or recheck individual scenes.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283488
  }, {
    "issueDTO" : {
      "id" : 3150622941,
      "title" : "Deploying with Helm by setting `trivy.configFile` not added into configmap",
      "url" : "https://github.com/aquasecurity/trivy-operator/issues/2616",
      "repositoryName" : "aquasecurity/trivy-operator",
      "description" : "**What steps did you take and what happened:**\n\nThe `trivy.configFile` value used with Helm is not being utilized in ConfigMaps template.\n\n**What did you expect to happen:**\n\nIncluding the content in the ConfigMap would be more effective.\n\n**Environment:**\n\n- Trivy-Operator version (use `trivy-operator version`): 0.29.0\n- Kubernetes version (use `kubectl version`): v1.29.14+7cf4c05\n- OS (macOS 10.15, Windows 10, Ubuntu 19.10 etc): CoreOS",
      "updatedAt" : 1752254397.000000000,
      "user" : "bprieur",
      "userHtmlUrl" : "https://github.com/bprieur",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/39614869?v=4",
      "labels" : [ "feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@bprieur thanks for the report. it's a good suggestion.", "I would like to work on this issue", "The fact that the helm value doesn't get passed through to the config map isn't the only issue with #2636. It would be great if this also worked in client/server mode so we can set a platform to support scanning images in an `arm64` only environment.  The current implementation completely breaks client server mode even if you manually patch the configmap as it sets the flag without actually creating the volume: https://github.com/aquasecurity/trivy-operator/blob/ca3d9d7b808615e5639e5639f51b809992b71f9c/pkg/plugins/trivy/image.go#L677-L679" ],
      "repository" : {
        "description" : "Kubernetes-native security toolkit",
        "homepage" : "https://aquasecurity.github.io/trivy-operator/latest",
        "name" : "trivy-operator",
        "fullName" : "aquasecurity/trivy-operator",
        "htmlUrl" : "https://github.com/aquasecurity/trivy-operator",
        "gitUrl" : "git://github.com/aquasecurity/trivy-operator.git",
        "sshUrl" : "git@github.com:aquasecurity/trivy-operator.git",
        "cloneUrl" : "https://github.com/aquasecurity/trivy-operator.git",
        "owner" : {
          "login" : "aquasecurity",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 235,
        "stargazersCount" : 1552,
        "watchersCount" : 1552,
        "size" : 43364,
        "openIssuesCount" : 113,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T06:24:28Z",
        "languages" : {
          "Smarty" : 2349,
          "Dockerfile" : 301,
          "Shell" : 3633,
          "Go" : 1361683
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The `trivy.configFile` value used with Helm is not being utilized in ConfigMaps template.",
      "validationOrRequirement" : "None mentioned",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The fact that the helm value doesn't get passed through to the config map isn't the only issue with #2636. It would be great if this also worked in client/server mode so we can set a platform to support scanning images in an `arm64` only environment. The current implementation completely breaks client server mode even if you manually patch the configmap as it sets the flag without actually creating the volume: https://github.com/aquasecurity/trivy-operator/blob/ca3d9d7b808615e5639e5639f51b809992b71f9c/pkg/plugins/trivy/image.go#L677-L679",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283494
  }, {
    "issueDTO" : {
      "id" : 2760588012,
      "title" : "[IMPROVEMENT] Check if the backup target is available before creating a backup, backup backing image, and system backup",
      "url" : "https://github.com/longhorn/longhorn/issues/10085",
      "repositoryName" : "longhorn/longhorn",
      "description" : "## Is your improvement request related to a feature? Please describe (\uD83D\uDC4D if you like this request)\r\n\r\n<!--A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]-->\r\n\r\nWe do not check the backup target status in the validator when we create a backup/backup backing image/system backup.\r\n\r\nIt will fail and mark the object when the controllers start to reconcile the object and check if the backup target is available. \r\n\r\n## Describe the solution you'd like\r\n\r\n<!--A clear and concise description of what you want to happen.-->\r\n\r\nCheck the backup target status (available) in the validator when creating the backup/backup backing image/system backup\r\n\r\n## Describe alternatives you've considered\r\n\r\n<!--A clear and concise description of any alternative solutions or features you've considered.-->\r\n\r\n## Additional context\r\n\r\n<!--Add any other context or screenshots about the feature request here.-->\r\n",
      "updatedAt" : 1752253943.000000000,
      "user" : "mantissahz",
      "userHtmlUrl" : "https://github.com/mantissahz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/14231257?v=4",
      "labels" : [ "kind/improvement", "priority/0", "area/backup-store", "area/admission-webhook", "require/auto-e2e-test", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @c3y1huang ", "Assigned to @nzhan126 because you have submitted a PR to handle this issue.", "Hi @nzhan126,\nDo we have any updates on this issue? ", "> Hi [@nzhan126](https://github.com/nzhan126), Do we have any updates on this issue?\n\n@mantissahz Hi sorry I have been caught up in something else. Should have it done by tomorrow!  ", "After a discussion with @nzhan126, we found that the backup target handling for backup, backup backing image, and system backup is different:\n- For SystemBackup, it does not support using a non-default backup target at all. Hence, its mutator webhook will blindly validate if the default backup target CR (but it won't check if the default backup target is really available).  Should we allow changing backup targets for SystemBackup?\n- For BackupBackingImage, if its `Spec.BackupTargetName` CR is not found, the mutator webhook will silently change the value to the default backup target. To be honest, this behavior is a little bit weird. Is there any context for this? And again, the webhook won't check if the backup target is really accessible.\n- For Backup, the mutator webhook will only check if `Labels[types.LonghornLabelBackupTarget]` is set or not. It does not care whether the related backup target CR exists and is available. I think this is the original issue we want to fix.\n\nIn this ticket, besides checking the backup target status for SystemBackup, BackupBackingImage, and Backup, we should make the backup target handling logic consistent. I mean, if all these 3 kinds of backup-related resources should:\n1. Support non-default backup target\n2. Change `Spec.BackupTargetName` to default if the user provided one is unavailable\n3. Validate if the backup target specified in `Spec.BackupTargetName` is accessible.\n\ncc @derekbit @mantissahz @c3y1huang ", "\n## Pre Ready-For-Testing Checklist\n* [x] Where is the reproduce steps/test steps documented?\nThe reproduce steps/test steps are at:\n1. Install Longhorn with image containing fix.\n2. Make sure no backup target is available\n3. Try to create new backup/backup backing image/system backup.\n4. Should return error message with corresponding errors\n\n* [ ] Is there a workaround for the issue? If so, where is it documented?\nThe workaround is at:\n\n* [x] Does the PR include the explanation for the fix or the feature?\n\n* [ ] Does the PR include deployment change (YAML/Chart)? If so, where are the PRs for both YAML file and Chart?\nThe PR for the YAML change is at:\nThe PR for the chart change is at:\n\n* [ ] Have the backend code been merged (Manager, Engine, Instance Manager, BackupStore etc) (including `backport-needed/*`)?\nThe PR is at\n\n* [x] Which areas/issues this PR might have potential impacts on?\nArea: backup/backup backing image/system backup\nIssues\n\n* [ ] **If labeled: require/LEP** Has the Longhorn Enhancement Proposal PR submitted?\nThe LEP PR is at\n\n* [ ] **If labeled: area/ui** Has the UI issue filed or ready to be merged (including `backport-needed/*`)?\nThe UI issue/PR is at\n\n* [ ] **If labeled: require/doc** Has the necessary document PR submitted or merged (including `backport-needed/*`)?\nThe documentation issue/PR is at\n\n* [ ] **If labeled: require/automation-e2e** Has the end-to-end test plan been merged? Have QAs agreed on the automation test case? If only test case skeleton w/o implementation, have you created an implementation issue (including `backport-needed/*`)\nThe automation skeleton PR is at\nThe automation test case PR is at \nThe issue of automation test case implementation is at (please create by [the template](https://github.com/longhorn/longhorn/issues/new?assignees=&labels=area%2Ftest&template=test.md&title=%5BTEST%5D))\n\n* [ ] **If labeled: require/automation-engine** Has the engine integration test been merged (including `backport-needed/*`)?\nThe engine automation PR is at\n\n* [ ] **If labeled: require/manual-test-plan** Has the manual test plan been documented?\nThe updated manual test plan is at\n\n* [ ] **If the fix introduces the code for backward compatibility** Has a separate issue been filed with the label `release/obsolete-compatibility`?\nThe compatibility issue is filed at" ],
      "repository" : {
        "description" : "Cloud-Native distributed storage built on and for Kubernetes",
        "homepage" : "https://longhorn.io",
        "name" : "longhorn",
        "fullName" : "longhorn/longhorn",
        "htmlUrl" : "https://github.com/longhorn/longhorn",
        "gitUrl" : "git://github.com/longhorn/longhorn.git",
        "sshUrl" : "git@github.com:longhorn/longhorn.git",
        "cloneUrl" : "https://github.com/longhorn/longhorn.git",
        "owner" : {
          "login" : "longhorn",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 645,
        "stargazersCount" : 6838,
        "watchersCount" : 6838,
        "size" : 17099,
        "openIssuesCount" : 1532,
        "subscribersCount" : 98,
        "pushedAt" : "2025-07-11T11:35:26Z",
        "languages" : {
          "Shell" : 42715,
          "Mustache" : 1972,
          "Python" : 6508
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Check if the backup target is available before creating a backup, backup backing image, and system backup, and make the backup target handling logic consistent across different types of backup-related resources.",
      "validationOrRequirement" : "The backup target handling logic should support non-default backup target, change `Spec.BackupTargetName` to default if the user provided one is unavailable, and validate if the backup target specified in `Spec.BackupTargetName` is accessible.",
      "attemptedFixes" : "The PR includes explanation for the fix or feature, and the PR includes deployment change (YAML/Chart).",
      "otherNotes" : "The issue is about checking the backup target status in the validator when creating a backup/backup backing image/system backup, and making the backup target handling logic consistent across different types of backup-related resources.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283499
  }, {
    "issueDTO" : {
      "id" : 3145768038,
      "title" : "update rust edition to 2024",
      "url" : "https://github.com/apache/datafusion-ballista/issues/1271",
      "repositoryName" : "apache/datafusion-ballista",
      "description" : "**Is your feature request related to a problem or challenge? Please describe what you are trying to do.**\n\nto keep up with latest rust edition we need to update rust to 2024\n\n**Describe the solution you'd like**\n\nupdate rust edition and code to support `edition = \"2024`\n\n**Describe alternatives you've considered**\n\n**Additional context**\n\n`configure_me` dependency looks as very outdated (and not maintained) from what i can tell code generated by it (`configure_me_codegen`) may not be valid according to `2024` specification\n\n- [ ] #1281\n- [ ] Fix issues with code",
      "updatedAt" : 1752253845.000000000,
      "user" : "milenkovicm",
      "userHtmlUrl" : "https://github.com/milenkovicm",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/956287?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "`configure_me` deps has clippy problems as well (https://github.com/apache/datafusion-ballista/pull/1270/commits/9131cc8395c0c86c89e38a94ba4b8f1ae91b8451)" ],
      "repository" : {
        "description" : "Apache DataFusion Ballista Distributed Query Engine",
        "homepage" : "https://datafusion.apache.org/ballista",
        "name" : "datafusion-ballista",
        "fullName" : "apache/datafusion-ballista",
        "htmlUrl" : "https://github.com/apache/datafusion-ballista",
        "gitUrl" : "git://github.com/apache/datafusion-ballista.git",
        "sshUrl" : "git@github.com:apache/datafusion-ballista.git",
        "cloneUrl" : "https://github.com/apache/datafusion-ballista.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 228,
        "stargazersCount" : 1790,
        "watchersCount" : 1790,
        "size" : 21624,
        "openIssuesCount" : 128,
        "subscribersCount" : 48,
        "pushedAt" : "2025-07-10T07:00:15Z",
        "languages" : {
          "Dockerfile" : 13903,
          "Shell" : 33503,
          "Rust" : 1188491,
          "Scala" : 10068,
          "Python" : 66428
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "update rust edition to 2024 to keep up with latest rust edition",
      "validationOrRequirement" : "update rust edition to 2024, code to support edition = 2024",
      "attemptedFixes" : "Fix issues with code",
      "otherNotes" : "configure_me dependency is outdated and not maintained, code generated by it may not be valid according to 2024 specification, clippy problems also exist",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283503
  }, {
    "issueDTO" : {
      "id" : 3223643825,
      "title" : "Replace configure_me with maintained alternative",
      "url" : "https://github.com/apache/datafusion-ballista/issues/1281",
      "repositoryName" : "apache/datafusion-ballista",
      "description" : "**Is your feature request related to a problem or challenge? Please describe what you are trying to do.**\n\n`configure_me` dependency does not look maintained, it is a blocker to update rust edition to 2024, also it started to be a source of clippy issues.\n\n**Describe the solution you'd like**\n\nReplace `configure_me` with maintained alternative, maybe `clap` or similar.\n\n**Describe alternatives you've considered**\nA clear and concise description of any alternative solutions or features you've considered.\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.",
      "updatedAt" : 1752253765.000000000,
      "user" : "milenkovicm",
      "userHtmlUrl" : "https://github.com/milenkovicm",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/956287?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Apache DataFusion Ballista Distributed Query Engine",
        "homepage" : "https://datafusion.apache.org/ballista",
        "name" : "datafusion-ballista",
        "fullName" : "apache/datafusion-ballista",
        "htmlUrl" : "https://github.com/apache/datafusion-ballista",
        "gitUrl" : "git://github.com/apache/datafusion-ballista.git",
        "sshUrl" : "git@github.com:apache/datafusion-ballista.git",
        "cloneUrl" : "https://github.com/apache/datafusion-ballista.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 228,
        "stargazersCount" : 1790,
        "watchersCount" : 1790,
        "size" : 21624,
        "openIssuesCount" : 128,
        "subscribersCount" : 48,
        "pushedAt" : "2025-07-10T07:00:15Z",
        "languages" : {
          "Dockerfile" : 13903,
          "Shell" : 33503,
          "Rust" : 1188491,
          "Scala" : 10068,
          "Python" : 66428
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace configure_me with a maintained alternative to unblock rust edition update to 2024 and resolve clippy issues",
      "validationOrRequirement" : "replace configure_me with a maintained alternative, possibly clap or similar",
      "attemptedFixes" : "no attempts or blockers mentioned in the issue description",
      "otherNotes" : "configure_me dependency is not maintained, causing clippy issues and blocking rust edition update to 2024",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283506
  }, {
    "issueDTO" : {
      "id" : 3223062648,
      "title" : "Guide on modoptions and document default engine modoptions",
      "url" : "https://github.com/beyond-all-reason/RecoilEngine/issues/2459",
      "repositoryName" : "beyond-all-reason/RecoilEngine",
      "description" : "A guide on how to pass and use modoptions on games.\n\nNote the engine [hardcodes a few keys for modoptions with defaults](https://github.com/beyond-all-reason/RecoilEngine/blob/5e0e29257671e389e2e1e375f45bdb45f9d206c5/rts/Game/GameSetup.cpp#L628-L638), for hardcoded behavior as well. We must have these documented.\n\nThis task is related to: https://github.com/beyond-all-reason/RecoilEngine/issues/2458. Notice we shouldn't need to provide much detail on how to pass modoptions via startscript, since the startscript guide should provide for it.",
      "updatedAt" : 1752253422.000000000,
      "user" : "badosu",
      "userHtmlUrl" : "https://github.com/badosu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/347552?v=4",
      "labels" : [ "area: documentation", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This exists and briefly talks about all the modsomethings, might be annoying to find though: https://github.com/beyond-all-reason/RecoilEngine/blob/master/doc/site/content/articles/modrules-and-others.markdown" ],
      "repository" : {
        "description" : "A powerful free cross-platform RTS game engine",
        "homepage" : "https://beyond-all-reason.github.io/RecoilEngine/",
        "name" : "RecoilEngine",
        "fullName" : "beyond-all-reason/RecoilEngine",
        "htmlUrl" : "https://github.com/beyond-all-reason/RecoilEngine",
        "gitUrl" : "git://github.com/beyond-all-reason/RecoilEngine.git",
        "sshUrl" : "git@github.com:beyond-all-reason/RecoilEngine.git",
        "cloneUrl" : "https://github.com/beyond-all-reason/RecoilEngine.git",
        "owner" : {
          "login" : "beyond-all-reason",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 341,
        "watchersCount" : 341,
        "size" : 205721,
        "openIssuesCount" : 771,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-11T22:29:02Z",
        "languages" : {
          "Java" : 41936,
          "C++" : 24315759,
          "C" : 3074390,
          "CMake" : 333555,
          "Makefile" : 59811,
          "HTML" : 125785,
          "Perl" : 23604,
          "NSIS" : 32088,
          "Dockerfile" : 6431,
          "Shell" : 54303,
          "sed" : 1389,
          "Awk" : 278422,
          "Batchfile" : 573,
          "Lua" : 773509,
          "Objective-C" : 8705,
          "Assembly" : 721,
          "GLSL" : 129310,
          "Python" : 18613
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a guide on how to pass and use modoptions on games, specifically focusing on hardcoded modoptions in GameSetup.cpp.",
      "validationOrRequirement" : "Documentation of hardcoded modoptions in GameSetup.cpp, with references to existing documentation.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is related to #2458 and mentions the need to document hardcoded modoptions in GameSetup.cpp, with the startscript guide covering modoptions passing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283509
  }, {
    "issueDTO" : {
      "id" : 2943107847,
      "title" : "Issues with Vietnamese sources (Known bugs)",
      "url" : "https://github.com/KotatsuApp/kotatsu-parsers/issues/1604",
      "repositoryName" : "KotatsuApp/kotatsu-parsers",
      "description" : "### Source information\n\nsite/vi-VN\n\n### Steps to reproduce\n\nTODO list (issues):\n\n> - [LXManga] Fix tags in `getDetails` ??? \n> - [HentaiVnBuzz] Nothing found ??? \n> - [NewTruyen] Crawl wrong chapter images ??? (Solved by #1888) \n> - [CManga] Wrong chapter number ??? (Solved by #1880)\n> - [TruyenHentai18] Content not found or removed (with some manga) ??? \n> - [TruyenHentai18] Content not found or removed ??? (Solved by #1879)\n> - [GocTruyenTranh] Content not found or removed ??? (Solved by #1778)\n> - [HangTruyen] Content not found or removed ??? (Solved by #1778)\n> - [Nhentai World] Content not found or removed ??? (Solved by #1769)\n> - [MeHentaiVN] Content not found or removed ??? (Solved by #1769)\n> - [DocTruyen3Q] Content not found or removed ??? (Solved by #1621)\n> - #1677 ??? (Solved by #1678)\n> - [NhatTruyenVN] Content not found or removed / No chapters ??? (Solved by #1816)\n> - [NetTruyen] Value <!DOCTYPE of type java.lang.String cannot be converted to JSONObject (with nettruyenx.net domain) ??? (Solved by #1830)\n> - [DamCoNuong] Blocked by Cloudflare ??? \n> - [MimiHentai] Cannot cast org.json.JSONObject to java.lang.String ??? (Solved by #1860)\n\nTODO list (features):\n> - [MimiHentai] Add custom CDN server for downscale image ??? (Solved by #1818)\n> - [MimiHentai] Add more filters ??? (Solved by #1872)\n> - [KuroNeko] Add more filters ??? (Solved by #1879)\n> - [CManga] Remove some / all ads images ??? (Solved by https://github.com/KotatsuApp/kotatsu-parsers/commit/3fe61a09b735b08a39b4a18513847ae56c0d2df2) \n> - [YuriGarden] Add author search support ??? \n\n### Kotatsu version\n\nLatest Nightly Build\n\n### Android version\n\nAndroid 5+\n\n### Other details\n\n_You can also report bugs to these sources by replying to this post \uD83D\uDC4C_\n_User b??o bug s???m = Dev fix s???m \uD83D\uDC4C_\n\n### Acknowledgements\n\n- [x] I have searched the existing issues and this is a new ticket, **NOT** a duplicate or related to another open issue.",
      "updatedAt" : 1752253127.000000000,
      "user" : "dragonx943",
      "userHtmlUrl" : "https://github.com/dragonx943",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131387159?v=4",
      "labels" : [ "Domain changed", "bug", "invalid", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Manga parsers library for Kotlin/JVM and Android",
        "homepage" : "https://kotatsu.app/dev/parsers-library/",
        "name" : "kotatsu-parsers",
        "fullName" : "KotatsuApp/kotatsu-parsers",
        "htmlUrl" : "https://github.com/KotatsuApp/kotatsu-parsers",
        "gitUrl" : "git://github.com/KotatsuApp/kotatsu-parsers.git",
        "sshUrl" : "git@github.com:KotatsuApp/kotatsu-parsers.git",
        "cloneUrl" : "https://github.com/KotatsuApp/kotatsu-parsers.git",
        "owner" : {
          "login" : "KotatsuApp",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 76,
        "stargazersCount" : 215,
        "watchersCount" : 215,
        "size" : 6111,
        "openIssuesCount" : 444,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-10T09:54:32Z",
        "languages" : {
          "HTML" : 4055,
          "Kotlin" : 2449951
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Issues with Vietnamese sources (Known bugs)",
      "validationOrRequirement" : "The issue tracker is used to report bugs to the sources by replying to this post.",
      "attemptedFixes" : "Some fixes have been made, including #1888, #1880, #1879, #1769, #1621, #1678, #1816, #1830, and #1860, and some commits.",
      "otherNotes" : "The issue is about Vietnamese sources with known bugs, with TODO lists for both issues and features. The issue tracker is used to report bugs to the sources by replying to this post.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283514
  }, {
    "issueDTO" : {
      "id" : 3158637940,
      "title" : "[Feature]: Reduce Redundant \"Network Error\" Notifications to a Single, Persistent Alert",
      "url" : "https://github.com/kubestellar/ui/issues/1079",
      "repositoryName" : "kubestellar/ui",
      "description" : "### Problem or Use Case\n\nCurrently, when a network error occurs, the UI displays a new \"Network Error\" notification every few seconds or whenever a new network request fails. This leads to a constant barrage of pop-up notifications that are disruptive, distracting, and obscure the UI, significantly degrading the user experience.\n\nThis is what network errors currently look like : \n\n<img width=\"300\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bb9db227-6814-477e-b080-36dbbc56f886\" />\n\n\n\n\n### Proposed Solution\n\nInstead of spawning multiple, identical network error notifications, the application should display a single, persistent notification that indicates a network issue. This notification should:\n\n1. Appear once when the first network error is detected.\n\n2. Remain visible (e.g., in a fixed position, or as a banner) as long as network issues persist.\n\n3. Potentially update its text or icon to reflect ongoing issues if different types of network errors occur.\n\n4. Automatically disappear or provide a clear dismissal option once the network connection is restored or the issue is resolved.\n\n5. Not constantly re-appear for every subsequent failed network request while the initial error is still active.\n\n\n### Are you willing to contribute?\n\n- [ ] Yes, I'd like to help implement this feature.\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752252771.000000000,
      "user" : "redpinecube",
      "userHtmlUrl" : "https://github.com/redpinecube",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/113033661?v=4",
      "labels" : [ "priority/medium", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/help-wanted", "/assign\n", "@rishi-rajat,\nI noticed you've been assigned to this issue for a few weeks. If you're not currently working on it, would it be okay if I pick it up? I???ve already made progress locally and would love to contribute a PR. Let me know, thanks!", "Thanks for checking in, @Pardhasardhiraob29. Okay, you can go ahead and pick it up.", "/unassign", "/assign\n" ],
      "repository" : {
        "description" : "KubeStellar's User Interface",
        "homepage" : "",
        "name" : "ui",
        "fullName" : "kubestellar/ui",
        "htmlUrl" : "https://github.com/kubestellar/ui",
        "gitUrl" : "git://github.com/kubestellar/ui.git",
        "sshUrl" : "git@github.com:kubestellar/ui.git",
        "cloneUrl" : "https://github.com/kubestellar/ui.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 141,
        "stargazersCount" : 52,
        "watchersCount" : 52,
        "size" : 6548,
        "openIssuesCount" : 86,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T19:42:46Z",
        "languages" : {
          "TypeScript" : 2377393,
          "Dockerfile" : 4363,
          "Shell" : 4960,
          "CSS" : 4768,
          "Makefile" : 7068,
          "JavaScript" : 5450,
          "Go" : 1062645,
          "HTML" : 345
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Reduce redundant 'Network Error' notifications to a single, persistent alert",
      "validationOrRequirement" : "Priority: medium, Help wanted, Enhancement, Good first issue",
      "attemptedFixes" : "No attempted fixes mentioned",
      "otherNotes" : "No response",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283516
  }, {
    "issueDTO" : {
      "id" : 2640233661,
      "title" : "Request: Mangacollec",
      "url" : "https://github.com/simple-icons/simple-icons/issues/12117",
      "repositoryName" : "simple-icons/simple-icons",
      "description" : "### Brand Name\n\nMangacollec\n\n### Website\n\nhttps://www.mangacollec.com\n\n### Popularity Metric\n\nthe Similarweb rank is 300,575; see https://www.similarweb.com/website/mangacollec.com\r\nAndroid app has 100k+ downloads; see [https://play.google.com/store/apps/details?id=com.mangacollec](https://play.google.com/store/apps/details?id=com.mangacollec&hl=en-fr)\n\n### Official Resources for Icon and Color\n\n- SVG: https://www.mangacollec.com/favicon.svg\r\n- Hex: #da1f05 (from Android & iOS apps icons)\r\n- Hex: #d00003 (from the eyedropper on webmanifest icons)\r\n- Hex: #cf000a (from the favicon, probably darker for constrast)\n\n### Additional Comments\n\n- the website is rarely used by users, as they tend to use the mobile app instead\r\n- unknown license\r\n- there is no official colour available, but the best bet is to use the mobile app colour (because that's the one everyone uses)\r\n- internationally this website isn't popular, but in France it's like a must-have for manga collectors\r\n- having an icon for that brand could help the ones who want to show off their collection",
      "updatedAt" : 1752252605.000000000,
      "user" : "apix0n",
      "userHtmlUrl" : "https://github.com/apix0n",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/64981298?v=4",
      "labels" : [ "new icon", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I'm trying to solve my first issue, but I am finding a problem when resizing the viewbox from the original (32x32) to the standardized one (24x24).\nOnce resized, the icon's details in the center (see image) appear a little imperfect, perhaps because of the decrease in coordinates available? Or is this an oversight on my part? (How) Can I solve this?\nIf it helps, I used Adobe Illustrator to modify the svg.\n\n![Image](https://github.com/user-attachments/assets/8385b267-6be0-4bb6-a365-57b37624b47a)", "hi! first, thanks for trying to fix this issue!\n\ni actually created a semi-proper svg file for this icon myself a while back (sometime after creating that issue) but forgot to submit a pull request here. i made it on inkscape where i had no issue resizing the original svg; so no idea what caused your issue..\n\ni'll tidy the icon up and shortly create a pull request with the icon i made. thanks again for your help!\n\nalso; on your version, i would have removed the circle in the background as it's not necessarily part of the logo, and i think it's more recognizable without it.\n\n<img width=\"1690\" height=\"1015\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/df06c120-00ad-4fb5-9d7a-4a9fd13111ef\" />" ],
      "repository" : {
        "description" : "SVG icons for popular brands",
        "homepage" : "https://simpleicons.org",
        "name" : "simple-icons",
        "fullName" : "simple-icons/simple-icons",
        "htmlUrl" : "https://github.com/simple-icons/simple-icons",
        "gitUrl" : "git://github.com/simple-icons/simple-icons.git",
        "sshUrl" : "git@github.com:simple-icons/simple-icons.git",
        "cloneUrl" : "https://github.com/simple-icons/simple-icons.git",
        "owner" : {
          "login" : "simple-icons",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2834,
        "stargazersCount" : 22976,
        "watchersCount" : 22976,
        "size" : 67016,
        "openIssuesCount" : 706,
        "subscribersCount" : 181,
        "pushedAt" : "2025-07-08T15:47:32Z",
        "languages" : {
          "Dockerfile" : 202,
          "Shell" : 977,
          "JavaScript" : 99557
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "create a new icon for Mangacollec and ensure it is recognizable and suitable for use in a standardized size (24x24)",
      "validationOrRequirement" : "create an icon for the Mangacollec brand; the icon should be recognizable and suitable for use in a standardized size (24x24); the author suggests using the mobile app color (#da1f05) for the icon",
      "attemptedFixes" : "the issue is about resizing the viewbox from the original (32x32) to the standardized one (24x24) and the icon's details in the center appear a little imperfect; the author tried using Adobe Illustrator to modify the svg",
      "otherNotes" : "the website is rarely used by users, as they tend to use the mobile app instead; unknown license; internationally this website isn't popular, but in France it's like a must-have for manga collectors; having an icon for that brand could help the ones who want to show off their collection",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283522
  }, {
    "issueDTO" : {
      "id" : 3223580259,
      "title" : "Release: notify of the merges to the release branches",
      "url" : "https://github.com/camunda/camunda/issues/35244",
      "repositoryName" : "camunda/camunda",
      "description" : "## Description\n\nThere's no automated alerts for:\n- PRs with backport release labels (targeted at \"release-*\" branches) being merged\n- Direct commits to \"release-*\" branches pushed\n\nThis causes missed RC decisions and concurrent automation runs.\n\n<!-- Describe the bug, feature or task regarding the Monorepo Release process that this ticket should be about. -->\n<!-- For bugs describe a) where it happened, b) what the impact is, c) how to reproduce it, if known. -->\n\n## Goal\n\nSend automated Slack notifications to #top-monorepo-release for:\n- PRs created with backport release labels (\"release-*\" branches)\n- Direct merges to \"release-*\" branches that bypass backporting\n\n<!-- For features and tasks, describe how the end result should look like and what steps are needed to get there, if known. -->\n\n## Hints\n\n<!-- Any additional context, links or information you have about this ticket. Also specify if any backporting should be done, see the guidelines:\nhttps://github.com/camunda/camunda/wiki/Release-Process#backporting-guidelines\n-->\n",
      "updatedAt" : 1752252589.000000000,
      "user" : "maxdanilov",
      "userHtmlUrl" : "https://github.com/maxdanilov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6655714?v=4",
      "labels" : [ "component/release", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Process Orchestration Framework",
        "homepage" : "https://camunda.com/platform/",
        "name" : "camunda",
        "fullName" : "camunda/camunda",
        "htmlUrl" : "https://github.com/camunda/camunda",
        "gitUrl" : "git://github.com/camunda/camunda.git",
        "sshUrl" : "git@github.com:camunda/camunda.git",
        "cloneUrl" : "https://github.com/camunda/camunda.git",
        "owner" : {
          "login" : "camunda",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 679,
        "stargazersCount" : 3723,
        "watchersCount" : 3723,
        "size" : 643351,
        "openIssuesCount" : 2373,
        "subscribersCount" : 114,
        "pushedAt" : "2025-07-11T23:23:17Z",
        "languages" : {
          "MDX" : 2383,
          "Smarty" : 230,
          "Java" : 53137212,
          "CSS" : 2925,
          "Makefile" : 20359,
          "Go" : 76584,
          "HTML" : 14209,
          "FreeMarker" : 94639,
          "TypeScript" : 6978501,
          "Dockerfile" : 23726,
          "Shell" : 47376,
          "Batchfile" : 3877,
          "SCSS" : 133874,
          "JavaScript" : 1534294
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Automate Slack notifications to #top-monorepo-release for PRs and direct merges to 'release-*' branches",
      "validationOrRequirement" : "PRs created with backport release labels ('release-*' branches), direct merges to 'release-*' branches that bypass backporting",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "Backporting guidelines: https://github.com/camunda/camunda/wiki/Release-Process#backporting-guidelines",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283526
  }, {
    "issueDTO" : {
      "id" : 2985344286,
      "title" : "Limit push down when there is index on expression",
      "url" : "https://github.com/risingwavelabs/risingwave/issues/21342",
      "repositoryName" : "risingwavelabs/risingwave",
      "description" : "### Is your feature request related to a problem? Please describe.\n\nCurrent behavior\n```sql\ntest=> create table t(v jsonb);\nCREATE_TABLE\ntest=> create index json_index on t (v->>'id', v->>'date' desc);\nCREATE_INDEX\n\ntest=> explain select * from t where v->>'id' = 'foo' order by v->>'date' desc limit 1;\n                                               QUERY PLAN                                               \n--------------------------------------------------------------------------------------------------------\n BatchProject { exprs: [json_index.v] }\n ??????BatchTopN { order: [$expr1 DESC], limit: 1, offset: 0 }\n   ??????BatchExchange { order: [], dist: Single }\n     ??????BatchTopN { order: [$expr1 DESC], limit: 1, offset: 0 }\n       ??????BatchProject { exprs: [json_index.v, JsonbAccessStr(json_index.v, 'date':Varchar) as $expr1] }\n         ??????BatchScan { table: json_index, columns: [v], scan_ranges: [JSONB_ACCESS_STR = Utf8(\"foo\")] }\n(6 rows)\n```\n\nOptimal behavior:\nUse BatchLimit and limit push down to scan:\n```sql\n...\n??????BatchLimit { limit: 1, offset: 0 }\n  ....\n        ??????BatchScan {  table: json_index, columns: [v], limit: 1, scan_ranges: [JSONB_ACCESS_STR = Utf8(\"foo\")] }\n```\n\n### Describe the solution you'd like\n\n_No response_\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752252302.000000000,
      "user" : "hzxa21",
      "userHtmlUrl" : "https://github.com/hzxa21",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5518566?v=4",
      "labels" : [ "type/feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Could someone help me?\n\n```\ndev=> create table t(a int, b int);\nCREATE_TABLE\ndev=> create index a_index on t(a);\nCREATE_INDEX\ndev=> explain select a + b from t order by a limit 1;\n```\n\nBefore optimization\n```                 \n--------------------------------------------------------------\n BatchProject { exprs: [$expr1] }\n ??????BatchTopN { order: [t.a ASC], limit: 1, offset: 0 }\n   ??????BatchExchange { order: [], dist: Single }\n     ??????BatchTopN { order: [t.a ASC], limit: 1, offset: 0 }\n       ??????BatchProject { exprs: [(t.a + t.b) as $expr1, t.a] }\n         ??????BatchScan { table: t, columns: [a, b] }\n```\nAfter\n``` \n--------------------------------------------------------------\nBatchProject { exprs: [$expr1] }\n ??????BatchProject { exprs: [(a_index.a + a_index.b) as $expr1, a_index.a] }\n   ??????BatchTopN { order: [a_index.a ASC], limit: 10, offset: 0 }\n     ??????BatchExchange { order: [], dist: Single }\n       ??????BatchLimit { limit: 1, offset: 0 }\n         ??????BatchScan { table: a_index, columns: [a, b], limit: 1 }\n```\nIt works on the above example, but I don't know how to deal with jsonb or other datatypes.\n", "> It works on the above example, but I don't know how to deal with jsonb or other datatypes.\n\n\nCan you elaborate more on what your current approach is and where you are stuck on? Maybe opening a draft PR can help. \ncc @chenzl25 @xiangjinwu ", "Saw your PR #22332. Let's move the discussion there.", "@chagelo  I think you can follow this PR to see how it solves the index selection of order matching with a prefix. The current issue is different in how the expression should be handled. The current expression is `where v->>'id' = 'foo' order by v->>'date' desc limit 1;` which involves json expression and related to the index `create index json_index on t (v->>'id', v->>'date' desc);`, so we need to match not just `InputRef`, but a `FunctionCall`, it means we need to match the [index_item](https://github.com/risingwavelabs/risingwave/blob/1f653d282d57c1fb874aafa94559c290aeeaab38/src/frontend/src/catalog/index_catalog.rs#L41) of an index directly which is more complicate.    https://github.com/risingwavelabs/risingwave/pull/20605 ", "@chenzl25 Ok, thanks. I will go to have a try.\n\nAnd I have another question. If I have the below plan:\n\n```sql\ndev=> create table t(a int, b int, c int);\nCREATE_TABLE\ndev=> create index t_index_bc on t(b asc, c asc);\nCREATE_INDEX\ndev=> explain (trace) select * from t where b=10 order by c limit 1;\ndev=> explain  select * from t where b=10 order by c limit 1;\n                                             QUERY PLAN                                              \n-----------------------------------------------------------------------------------------------------\n BatchSort { order: [t_index_bc.c ASC] }\n ??????BatchTopN { order: [t_index_bc.b ASC, t_index_bc.c ASC], limit: 1, offset: 0 }\n   ??????BatchExchange { order: [], dist: Single }\n     ??????BatchLimit { limit: 1, offset: 0 }\n       ??????BatchScan { table: t_index_bc, columns: [a, b, c], scan_ranges: [b = Int32(10)], limit: 1 }\n```\n\nAnd the below shows the intermediate of the optimization.\n\n```sql\n...\n ??????BatchTopN { order: [t_index_bc.b ASC, t_index_bc.c ASC], limit: 1, offset: 0 }\n   ??????BatchScan { table: t_index_bc, columns: [a, b, c], scan_ranges: [b = Int32(10)] }\n```\n\nAs the [two_phase_topn](https://github.com/risingwavelabs/risingwave/blob/main/src/frontend/src/optimizer/plan_node/batch_topn.rs#L54) shows, the `input.order()` is obtained from `TableScan.pk`. When I printed it, I found the pk was `[$0 ASC, $1 ASC, $3 ASC]`. This seems to correspond to columns `b, c`, and `_row_id` rather than a single column `_row_id`, which is strange because it relates to the index `t_index_bc`. This really confused me." ],
      "repository" : {
        "description" : "Stream processing and management platform.",
        "homepage" : "https://go.risingwave.com/slack",
        "name" : "risingwave",
        "fullName" : "risingwavelabs/risingwave",
        "htmlUrl" : "https://github.com/risingwavelabs/risingwave",
        "gitUrl" : "git://github.com/risingwavelabs/risingwave.git",
        "sshUrl" : "git@github.com:risingwavelabs/risingwave.git",
        "cloneUrl" : "https://github.com/risingwavelabs/risingwave.git",
        "owner" : {
          "login" : "risingwavelabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 658,
        "stargazersCount" : 7976,
        "watchersCount" : 7976,
        "size" : 175858,
        "openIssuesCount" : 1246,
        "subscribersCount" : 82,
        "pushedAt" : "2025-07-11T19:07:00Z",
        "languages" : {
          "C#" : 7520,
          "Java" : 786988,
          "CSS" : 403,
          "Rust" : 23717348,
          "PLpgSQL" : 939,
          "Go" : 73756,
          "TypeScript" : 147370,
          "Dockerfile" : 15249,
          "Shell" : 266870,
          "JavaScript" : 15756,
          "PHP" : 6093,
          "Nix" : 3678,
          "Ruby" : 5490,
          "TSQL" : 2956,
          "Python" : 636398
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Optimize push down when there is an index on an expression, specifically on JSONB data type, and deal with JSONB or other datatypes.",
      "validationOrRequirement" : "The issue requires optimizing push down when there is an index on an expression, specifically on JSONB data type, and dealing with JSONB or other datatypes.",
      "attemptedFixes" : "The author mentions that it works on a specific example, but doesn't know how to deal with JSONB or other datatypes. The issue is about optimizing push down when there is an index on an expression, specifically on JSONB data type.",
      "otherNotes" : "This issue is about optimizing push down when there is an index on an expression, specifically on JSONB data type. The author wants to use BatchLimit and limit push down to scan, but is stuck on how to deal with JSONB or other datatypes. The issue involves matching not just InputRef, but a FunctionCall, which is more complicated.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283533
  }, {
    "issueDTO" : {
      "id" : 3184289201,
      "title" : "Add link to scroll down to reviews",
      "url" : "https://github.com/bookwyrm-social/bookwyrm/issues/3632",
      "repositoryName" : "bookwyrm-social/bookwyrm",
      "description" : "**Is your feature request related to a problem? Please describe.**\nAt the top of a book page it displays the star rating and beside it, number of reviews. To read the reviews you have to scroll down a lot.\n\n**Describe the solution you'd like**\nThe (13 reviews) should include a link to `#reviews` anchor.\n\nI can make a PR to add this.",
      "updatedAt" : 1752252223.000000000,
      "user" : "Skivling",
      "userHtmlUrl" : "https://github.com/Skivling",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/145093975?v=4",
      "labels" : [ "UI", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I'd like to take this on. Could you assign it to me?" ],
      "repository" : {
        "description" : "Social reading and reviewing, decentralized with ActivityPub",
        "homepage" : "http://joinbookwyrm.com/",
        "name" : "bookwyrm",
        "fullName" : "bookwyrm-social/bookwyrm",
        "htmlUrl" : "https://github.com/bookwyrm-social/bookwyrm",
        "gitUrl" : "git://github.com/bookwyrm-social/bookwyrm.git",
        "sshUrl" : "git@github.com:bookwyrm-social/bookwyrm.git",
        "cloneUrl" : "https://github.com/bookwyrm-social/bookwyrm.git",
        "owner" : {
          "login" : "bookwyrm-social",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 279,
        "stargazersCount" : 2484,
        "watchersCount" : 2484,
        "size" : 58659,
        "openIssuesCount" : 477,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-09T12:21:05Z",
        "languages" : {
          "Dockerfile" : 803,
          "Shell" : 19666,
          "CSS" : 155,
          "SCSS" : 37863,
          "JavaScript" : 53491,
          "HTML" : 760193,
          "Python" : 2562758
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a link to the reviews section at the top of the book page, making it easier to access the reviews.",
      "validationOrRequirement" : "No specific validations or requirements mentioned, but the author is willing to make a PR to add the solution.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to a problem where the reviews are not easily accessible due to the long scrolling distance.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283536
  }, {
    "issueDTO" : {
      "id" : 3222790780,
      "title" : "Add 'name' and 'img' to `TypedPseudoDocument#createDialog`",
      "url" : "https://github.com/MetaMorphic-Digital/draw-steel/issues/718",
      "repositoryName" : "MetaMorphic-Digital/draw-steel",
      "description" : "Since all pseudo-documents now have these properties, it makes sense to allow for them to be input upon creation.\n\nWe should also add `createDialog` to the base `PseudoDocument` class for this purpose.",
      "updatedAt" : 1752251894.000000000,
      "user" : "krbz999",
      "userHtmlUrl" : "https://github.com/krbz999",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/50169243?v=4",
      "labels" : [ "good first issue", "apps" ],
      "state" : "OPEN",
      "comments" : [ "I wonder if we should make a simple template for this?", "> I wonder if we should make a simple template for this?\n\nThe current createDialog with just the `type` field was for sure just a \"good enough\" solution." ],
      "repository" : {
        "description" : "The fan-made Draw Steel implementation for FoundryVTT",
        "homepage" : null,
        "name" : "draw-steel",
        "fullName" : "MetaMorphic-Digital/draw-steel",
        "htmlUrl" : "https://github.com/MetaMorphic-Digital/draw-steel",
        "gitUrl" : "git://github.com/MetaMorphic-Digital/draw-steel.git",
        "sshUrl" : "git@github.com:MetaMorphic-Digital/draw-steel.git",
        "cloneUrl" : "https://github.com/MetaMorphic-Digital/draw-steel.git",
        "owner" : {
          "login" : "MetaMorphic-Digital",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 36,
        "watchersCount" : 36,
        "size" : 1649,
        "openIssuesCount" : 138,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T23:15:31Z",
        "languages" : {
          "CSS" : 24272,
          "Handlebars" : 85618,
          "JavaScript" : 560274
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add 'name' and 'img' properties to TypedPseudoDocument#createDialog and add createDialog to the base PseudoDocument class for input upon creation.",
      "validationOrRequirement" : "Add 'name' and 'img' to TypedPseudoDocument#createDialog, and add createDialog to the base PseudoDocument class.",
      "attemptedFixes" : "No specific fixes attempted or blockers encountered.",
      "otherNotes" : "The current createDialog with just the 'type' field was a 'good enough' solution, and a simple template for this is also discussed.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283540
  }, {
    "issueDTO" : {
      "id" : 2820019032,
      "title" : "Allow importing pre-instantiated DateTimes from an array format",
      "url" : "https://github.com/Crell/Serde/issues/79",
      "repositoryName" : "Crell/Serde",
      "description" : "We already have a custom `EnumOnArrayImporter`.  We ought to have one for DateTime, too.  Which is an ugly way to do it, but c'est la vie.",
      "updatedAt" : 1752251791.000000000,
      "user" : "Crell",
      "userHtmlUrl" : "https://github.com/Crell",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/254863?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Robust Serde (serialization/deserialization) library for PHP 8.",
        "homepage" : "",
        "name" : "Serde",
        "fullName" : "Crell/Serde",
        "htmlUrl" : "https://github.com/Crell/Serde",
        "gitUrl" : "git://github.com/Crell/Serde.git",
        "sshUrl" : "git@github.com:Crell/Serde.git",
        "cloneUrl" : "https://github.com/Crell/Serde.git",
        "owner" : {
          "login" : "Crell",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 328,
        "watchersCount" : 328,
        "size" : 733,
        "openIssuesCount" : 15,
        "subscribersCount" : 7,
        "pushedAt" : "2025-06-19T18:11:25Z",
        "languages" : {
          "Dockerfile" : 343,
          "Shell" : 523,
          "PHP" : 314527
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow importing pre-instantiated DateTimes from an array format",
      "validationOrRequirement" : "no specific requirements mentioned in the description",
      "attemptedFixes" : "no attempts or blockers mentioned in the description",
      "otherNotes" : "the issue is about creating a custom DateTime importer similar to EnumOnArrayImporter, and it is considered an enhancement and a good first issue",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283543
  }, {
    "issueDTO" : {
      "id" : 3116608284,
      "title" : "Failed to download model 'FishSpeech-1.5' after multiple retries",
      "url" : "https://github.com/xorbitsai/inference/issues/3569",
      "repositoryName" : "xorbitsai/inference",
      "description" : "### System Info / ????????????\n\nxprobe/xinference:latest\n\n### Running Xinference with Docker? / ???????????? Docker ?????? Xinfernece???\n\n- [x] docker / docker\n- [ ] pip install / ?????? pip install ??????\n- [ ] installation from source / ???????????????\n\n### Version info / ????????????\n\nlatest\n\n### The command used to start Xinference / ???????????? xinference ?????????\n\n xinference-local -H 0.0.0.0\n\n### Reproduction / ????????????\n\n![Image](https://github.com/user-attachments/assets/341e87a2-f0a4-4104-9277-087a696991f2)\n\n```\n2025-06-03 22:42:46,485 xinference.core.worker 141 ERROR    Failed to load model FishSpeech-1.5-0\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 203, in _new_conn\n    sock = connection.create_connection(\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n    raise err\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n    sock.connect(sa)\nTimeoutError: [Errno 110] Connection timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 791, in urlopen\n    response = self._make_request(\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 492, in _make_request\n    raise new_e\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 468, in _make_request\n    self._validate_conn(conn)\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 1097, in _validate_conn\n    conn.connect()\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 611, in connect\n    self.sock = sock = self._new_conn()\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 212, in _new_conn\n    raise ConnectTimeoutError(\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f5cc4030f40>, 'Connection to huggingface.co timed out. (connect timeout=None)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 845, in urlopen\n    retries = retries.increment(\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/fishaudio/fish-speech-1.5/revision/268b6ec86243dd683bc78dab7e9a6cedf9191f2a (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f5cc4030f40>, 'Connection to huggingface.co timed out. (connect timeout=None)'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_snapshot_download.py\", line 155, in snapshot_download\n    repo_info = api.repo_info(repo_id=repo_id, repo_type=repo_type, revision=revision, token=token)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 2748, in repo_info\n    return method(\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 2532, in model_info\n    r = get_session().get(path, headers=headers, timeout=timeout, params=params)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 602, in get\n    return self.request(\"GET\", url, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\", line 93, in send\n    return super().send(request, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 688, in send\n    raise ConnectTimeout(e, request=request)\nrequests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/fishaudio/fish-speech-1.5/revision/268b6ec86243dd683bc78dab7e9a6cedf9191f2a (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f5cc4030f40>, 'Connection to huggingface.co timed out. (connect timeout=None)'))\"), '(Request ID: a582035e-e8c5-4bda-b664-e1723e937b6b)')\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/xinference/model/utils.py\", line 119, in retry_download\n    return download_func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_snapshot_download.py\", line 235, in snapshot_download\n    raise LocalEntryNotFoundError(\nhuggingface_hub.errors.LocalEntryNotFoundError: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/xinference/core/worker.py\", line 1052, in launch_builtin_model\n    model, model_description = await asyncio.to_thread(\n  File \"/usr/lib/python3.10/asyncio/threads.py\", line 25, in to_thread\n    return await loop.run_in_executor(None, func_call)\n  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/xinference/model/core.py\", line 129, in create_model_instance\n    return create_audio_model_instance(\n  File \"/usr/local/lib/python3.10/dist-packages/xinference/model/audio/core.py\", line 193, in create_audio_model_instance\n    model_path = cache(model_spec)\n  File \"/usr/local/lib/python3.10/dist-packages/xinference/model/audio/core.py\", line 150, in cache\n    return cache(model_spec, AudioModelDescription)\n  File \"/usr/local/lib/python3.10/dist-packages/xinference/model/utils.py\", line 299, in cache\n    download_dir = retry_download(\n  File \"/usr/local/lib/python3.10/dist-packages/xinference/model/utils.py\", line 148, in retry_download\n    raise RuntimeError(\nRuntimeError: Failed to download model 'FishSpeech-1.5' after multiple retries\n```\n\n????????????modelscope????????????\n\n### Expected behavior / ????????????\n\n?????????modelscope??????",
      "updatedAt" : 1752251350.000000000,
      "user" : "yidasanqian",
      "userHtmlUrl" : "https://github.com/yidasanqian",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10655188?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "?????? modelscope ????????? fishspeech-1.5???????????????????????????https://modelscope.cn/models/fishaudio/fish-speech-1.5\n\n??????????????????????????????????????????????????????????????? model_path???\n\nhuggingface ?????????\n\nhttps://github.com/xorbitsai/inference/blob/04037236ec74ac9395786aba697069b5981c76dd/xinference/model/audio/model_spec.json#L330-L337\n\n???????????? modelscope???\n\nhttps://github.com/xorbitsai/inference/blob/main/xinference/model/audio/model_spec_modelscope.json", "??? modelscope ?????????????????????", "This issue is stale because it has been open for 7 days with no activity.", "This issue is stale because it has been open for 7 days with no activity.", "This issue was closed because it has been inactive for 5 days since being marked as stale.", "This issue is stale because it has been open for 7 days with no activity.", "This issue is stale because it has been open for 7 days with no activity." ],
      "repository" : {
        "description" : "Replace OpenAI GPT with another LLM in your app by changing a single line of code. Xinference gives you the freedom to use any LLM you need. With Xinference, you're empowered to run inference with any open-source language models, speech recognition models, and multimodal models, whether in the cloud, on-premises, or even on your laptop.",
        "homepage" : "https://inference.readthedocs.io",
        "name" : "inference",
        "fullName" : "xorbitsai/inference",
        "htmlUrl" : "https://github.com/xorbitsai/inference",
        "gitUrl" : "git://github.com/xorbitsai/inference.git",
        "sshUrl" : "git@github.com:xorbitsai/inference.git",
        "cloneUrl" : "https://github.com/xorbitsai/inference.git",
        "owner" : {
          "login" : "xorbitsai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 705,
        "stargazersCount" : 8204,
        "watchersCount" : 8204,
        "size" : 48269,
        "openIssuesCount" : 205,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-09T15:49:11Z",
        "languages" : {
          "Dockerfile" : 4536,
          "CSS" : 6812,
          "JavaScript" : 297416,
          "HTML" : 1722,
          "Python" : 2092400
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Failed to download model 'FishSpeech-1.5' after multiple retries, with a timeout error and a MaxRetryError.",
      "validationOrRequirement" : "The requirement is to download the FishSpeech-1.5 model from modelscope, with a specific model path.",
      "attemptedFixes" : "The error message indicates that the model was not downloaded after multiple retries, with a timeout error and a MaxRetryError.",
      "otherNotes" : "The issue is related to downloading the FishSpeech-1.5 model from modelscope, with a specific requirement to add modelscope support.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283547
  }, {
    "issueDTO" : {
      "id" : 3223500120,
      "title" : "Update ModalEditSocialLinks to use new form components",
      "url" : "https://github.com/activist-org/activist/issues/1355",
      "repositoryName" : "activist-org/activist",
      "description" : "### Terms\n\n- [x] I have searched [open and closed feature requests](https://github.com/activist-org/activist/issues?q=is%3Aissue+label%3Afeature)\n- [x] I agree to follow activist's [Code of Conduct](.github/CODE_OF_CONDUCT.md)\n\n### Description\n\nFollowing from the work in #1342 that was concluded in PR #1352 we would also like to update the [ModalEditSocialLinks](https://github.com/activist-org/activist/blob/main/frontend/components/modal/edit/ModalEditSocialLinks.vue) component to use the new form elements. Work for this issue would largely be mirroring the work done in #1352 for this component instead of the [ModalEditText*](https://github.com/activist-org/activist/tree/main/frontend/components/modal/edit/text) components.\n\n### Contribution\n\nHappy to support with this and review a PR! \uD83D\uDE0A",
      "updatedAt" : 1752251093.000000000,
      "user" : "andrewtavis",
      "userHtmlUrl" : "https://github.com/andrewtavis",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/24387426?v=4",
      "labels" : [ "vue", "help wanted", "typescript", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An open-source activism platform",
        "homepage" : "https://activist.org",
        "name" : "activist",
        "fullName" : "activist-org/activist",
        "htmlUrl" : "https://github.com/activist-org/activist",
        "gitUrl" : "git://github.com/activist-org/activist.git",
        "sshUrl" : "git@github.com:activist-org/activist.git",
        "cloneUrl" : "https://github.com/activist-org/activist.git",
        "owner" : {
          "login" : "activist-org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 333,
        "stargazersCount" : 421,
        "watchersCount" : 421,
        "size" : 51269,
        "openIssuesCount" : 77,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-12T00:46:18Z",
        "languages" : {
          "TypeScript" : 219865,
          "Dockerfile" : 680,
          "Shell" : 22364,
          "CSS" : 8131,
          "Vue" : 615015,
          "JavaScript" : 2183,
          "HTML" : 1882,
          "Python" : 378346
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update ModalEditSocialLinks to use new form components",
      "validationOrRequirement" : "I have searched [open and closed feature requests](https://github.com/activist-org/activist/issues?q=is%3Aissue+label%3Afeature) and agree to follow activist's Code of Conduct",
      "attemptedFixes" : "Work for this issue would largely be mirroring the work done in #1352 for this component",
      "otherNotes" : "Happy to support with this and review a PR!",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283551
  }, {
    "issueDTO" : {
      "id" : 3223500052,
      "title" : "Update ModalEditFaqEntry to use new form components",
      "url" : "https://github.com/activist-org/activist/issues/1354",
      "repositoryName" : "activist-org/activist",
      "description" : "### Terms\n\n- [x] I have searched [open and closed feature requests](https://github.com/activist-org/activist/issues?q=is%3Aissue+label%3Afeature)\n- [x] I agree to follow activist's [Code of Conduct](.github/CODE_OF_CONDUCT.md)\n\n### Description\n\nFollowing from the work in #1342 that was concluded in PR #1352 we would also like to update the [ModalEditFaqEntry](https://github.com/activist-org/activist/blob/main/frontend/components/modal/edit/ModalEditFaqEntry.vue) component to use the new form elements. Work for this issue would largely be mirroring the work done in #1352 for this component instead of the [ModalEditText*](https://github.com/activist-org/activist/tree/main/frontend/components/modal/edit/text) components.\n\n### Contribution\n\nHappy to support with this and review a PR! \uD83D\uDE80",
      "updatedAt" : 1752251092.000000000,
      "user" : "andrewtavis",
      "userHtmlUrl" : "https://github.com/andrewtavis",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/24387426?v=4",
      "labels" : [ "vue", "help wanted", "typescript", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An open-source activism platform",
        "homepage" : "https://activist.org",
        "name" : "activist",
        "fullName" : "activist-org/activist",
        "htmlUrl" : "https://github.com/activist-org/activist",
        "gitUrl" : "git://github.com/activist-org/activist.git",
        "sshUrl" : "git@github.com:activist-org/activist.git",
        "cloneUrl" : "https://github.com/activist-org/activist.git",
        "owner" : {
          "login" : "activist-org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 333,
        "stargazersCount" : 421,
        "watchersCount" : 421,
        "size" : 51269,
        "openIssuesCount" : 77,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-12T00:46:18Z",
        "languages" : {
          "TypeScript" : 219865,
          "Dockerfile" : 680,
          "Shell" : 22364,
          "CSS" : 8131,
          "Vue" : 615015,
          "JavaScript" : 2183,
          "HTML" : 1882,
          "Python" : 378346
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update ModalEditFaqEntry to use new form components",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description.",
      "otherNotes" : "Following from the work in #1342 that was concluded in PR #1352, this issue aims to update the ModalEditFaqEntry component to use new form elements, mirroring the work done in #1352 for this component instead of the ModalEditText* components.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283555
  }, {
    "issueDTO" : {
      "id" : 3223500577,
      "title" : "CI/CD: Spell-check documentation and code comments",
      "url" : "https://github.com/KiiChain/kiichain/issues/67",
      "repositoryName" : "KiiChain/kiichain",
      "description" : "**Is your feature request related to a problem? Please describe.**\nTypos and inconsistent terminology may exist in docs and comments.\n\n**Describe the solution you'd like**\nAdd an Action that runs a spell-checker like `cspell` or `markdownlint` on docs and .go comments, failing CI on new typos.\n\n**Describe alternatives you've considered**\nManual proofreading.\n\n**Additional context**\nUse whitelist for code terms (e.g., Tendermint, EVM, module names).\n",
      "updatedAt" : 1752251053.000000000,
      "user" : "jhelison",
      "userHtmlUrl" : "https://github.com/jhelison",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68653689?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "On-chain FX layer for stablecoins and RWA.",
        "homepage" : "https://kiichain.io/",
        "name" : "kiichain",
        "fullName" : "KiiChain/kiichain",
        "htmlUrl" : "https://github.com/KiiChain/kiichain",
        "gitUrl" : "git://github.com/KiiChain/kiichain.git",
        "sshUrl" : "git@github.com:KiiChain/kiichain.git",
        "cloneUrl" : "https://github.com/KiiChain/kiichain.git",
        "owner" : {
          "login" : "KiiChain",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 22,
        "watchersCount" : 22,
        "size" : 6051,
        "openIssuesCount" : 14,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-04T20:01:26Z",
        "languages" : {
          "Dockerfile" : 1718,
          "Shell" : 36098,
          "Solidity" : 9962,
          "Makefile" : 21606,
          "Go" : 1097509,
          "HTML" : 4061,
          "Python" : 2728
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Spell-check documentation and code comments",
      "validationOrRequirement" : "Add an Action that runs a spell-checker like `cspell` or `markdownlint` on docs and .go comments, failing CI on new typos",
      "attemptedFixes" : "Manual proofreading",
      "otherNotes" : "Typos and inconsistent terminology may exist in docs and comments. Use whitelist for code terms (e.g., Tendermint, EVM, module names).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283558
  }, {
    "issueDTO" : {
      "id" : 3223497515,
      "title" : "Automatically check for Swagger changes on build",
      "url" : "https://github.com/KiiChain/kiichain/issues/66",
      "repositoryName" : "KiiChain/kiichain",
      "description" : "**Is your feature request related to a problem? Please describe.**\nCurrently while working on the chain, the swagger file must be updated manually with `make proto-swagger-gen`. PRs that doesn't update the swagger file and its required should fail before merge.\n\n**Describe the solution you'd like**\nCreate a pipeline that runs  `make proto-swagger-gen` and fails if there is any diff created on the project.\n\n**Describe alternatives you've considered**\nRunning  `make proto-swagger-gen` manually on every PR\n",
      "updatedAt" : 1752250993.000000000,
      "user" : "jhelison",
      "userHtmlUrl" : "https://github.com/jhelison",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68653689?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "On-chain FX layer for stablecoins and RWA.",
        "homepage" : "https://kiichain.io/",
        "name" : "kiichain",
        "fullName" : "KiiChain/kiichain",
        "htmlUrl" : "https://github.com/KiiChain/kiichain",
        "gitUrl" : "git://github.com/KiiChain/kiichain.git",
        "sshUrl" : "git@github.com:KiiChain/kiichain.git",
        "cloneUrl" : "https://github.com/KiiChain/kiichain.git",
        "owner" : {
          "login" : "KiiChain",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 22,
        "watchersCount" : 22,
        "size" : 6051,
        "openIssuesCount" : 14,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-04T20:01:26Z",
        "languages" : {
          "Dockerfile" : 1718,
          "Shell" : 36098,
          "Solidity" : 9962,
          "Makefile" : 21606,
          "Go" : 1097509,
          "HTML" : 4061,
          "Python" : 2728
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Automatically check for Swagger changes on build by creating a pipeline that runs `make proto-swagger-gen` and fails if there is any diff created",
      "validationOrRequirement" : "PRs that don't update the swagger file and its required should fail before merge",
      "attemptedFixes" : "Running `make proto-swagger-gen` manually on every PR",
      "otherNotes" : "The issue is related to a problem of manual swagger file update and PR failure before merge. The proposed solution is to create a pipeline that runs `make proto-swagger-gen` and fails if there is any diff created.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283562
  }, {
    "issueDTO" : {
      "id" : 3215468795,
      "title" : "nodepool's node_pools_cgroup_mode is forced to be defined when setting any linux_node_config",
      "url" : "https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/issues/2382",
      "repositoryName" : "terraform-google-modules/terraform-google-kubernetes-engine",
      "description" : "### TL;DR\n\nI added values for `node_pools_linux_node_configs_sysctls` and the module was crashing with an error:\n\n```\nCall to function \"coalesce\" failed: no non-null, non-empty-string arguments.\n```\n\nat https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/v37.0.0/cluster.tf#L915\n\nThis is mainly due to the `coalesce` terraform function to expect at least one output not `null` or `\"\"` out of the choices.\n\n### Expected behavior\n\nit should be possible to use any of the `linux_node_config` without being forced to create all (or some) of them.\n\n\n\n### Observed behavior\n\n```\nCall to function \"coalesce\" failed: no non-null, non-empty-string arguments.\n```\n\nwhen `node_pools_cgroup_mode` is unset, the expression at https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/v37.0.0/cluster.tf#L915 will all evaluate to `null`\n\n```\n cgroup_mode = coalesce(local.node_pools_cgroup_mode[each.value[\"name\"]], local.node_pools_cgroup_mode[\"all\"], null)\n```\n\n\n\n### Terraform Configuration\n\n```hcl\n\"node_pools_linux_node_configs_sysctls\": {\n  \"all\": {},\n  \"default-node-pool\": {},\n  \"gke-shared-spot-c3st44\": {}\n}\n\"node_pools\": [\n  {\n    \"add_fallback\": \"true\",\n    \"auto_repair\": \"true\",\n    \"auto_upgrade\": \"true\",\n    \"autoscaling\": \"true\",\n    \"disk_size_gb\": \"100\",\n    \"disk_type\": \"pd-balanced\",\n    \"enable_gcfs\": \"true\",\n    \"enable_secure_boot\": \"true\",\n    \"image_type\": \"COS_CONTAINERD\",\n    \"initial_node_count\": \"0\",\n    \"instance_class\": \"n2d-standard;c3-standard\",\n    \"is_dedicated\": \"true\",\n    \"local_ssd_ephemeral_storage_count\": \"0\",\n    \"location_policy\": \"ANY\",\n    \"machine_type\": \"n2d-standard-32\",\n    \"max_count\": \"2000\",\n    \"max_pods_per_node\": \"110\",\n    \"max_surge\": \"5\",\n    \"min_count\": \"0\",\n    \"name\": \"gke-shared-spot-n2dst32\",\n    \"node_locations\": \"\",\n    \"number\": \"32\",\n    \"orig_name\": \"gke-shared-spot\",\n    \"sizes\": \"32,48;44\",\n    \"skip_on_demand\": \"true\",\n    \"spot\": \"true\"\n  }\n]\n```\n\n### Terraform Version\n\n```sh\nTerraform v1.5.7\non darwin_arm64\n+ provider registry.terraform.io/hashicorp/google v6.43.0\n+ provider registry.terraform.io/hashicorp/kubernetes v2.37.1\n+ provider registry.terraform.io/hashicorp/random v3.7.2\n```\n\n### Terraform Provider Versions\n\n```sh\n+ provider registry.terraform.io/hashicorp/google v6.43.0\n+ provider registry.terraform.io/hashicorp/kubernetes v2.37.1\n+ provider registry.terraform.io/hashicorp/random v3.7.2\n```\n\n### Additional information\n\nmodule version `37.0.0`",
      "updatedAt" : 1752250676.000000000,
      "user" : "prune998",
      "userHtmlUrl" : "https://github.com/prune998",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1110398?v=4",
      "labels" : [ "triaged", "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Configures opinionated GKE clusters",
        "homepage" : "https://registry.terraform.io/modules/terraform-google-modules/kubernetes-engine/google",
        "name" : "terraform-google-kubernetes-engine",
        "fullName" : "terraform-google-modules/terraform-google-kubernetes-engine",
        "htmlUrl" : "https://github.com/terraform-google-modules/terraform-google-kubernetes-engine",
        "gitUrl" : "git://github.com/terraform-google-modules/terraform-google-kubernetes-engine.git",
        "sshUrl" : "git@github.com:terraform-google-modules/terraform-google-kubernetes-engine.git",
        "cloneUrl" : "https://github.com/terraform-google-modules/terraform-google-kubernetes-engine.git",
        "owner" : {
          "login" : "terraform-google-modules",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : false,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1225,
        "stargazersCount" : 1214,
        "watchersCount" : 1214,
        "size" : 6238,
        "openIssuesCount" : 68,
        "subscribersCount" : 55,
        "pushedAt" : "2025-07-11T16:15:42Z",
        "languages" : {
          "HCL" : 1227488,
          "Smarty" : 341,
          "Shell" : 22172,
          "Makefile" : 3711,
          "Go" : 103914,
          "Python" : 21439
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "it should be possible to use any of the linux_node_config without being forced to create all (or some) of them.",
      "validationOrRequirement" : "node_pools_cgroup_mode is forced to be defined when setting any linux_node_config",
      "attemptedFixes" : "The issue is mainly due to the 'coalesce' terraform function to expect at least one output not null or '' out of the choices.",
      "otherNotes" : "Added values for node_pools_linux_node_configs_sysctls and the module was crashing with an error: Call to function 'coalesce' failed: no non-null, non-empty-string arguments.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283567
  }, {
    "issueDTO" : {
      "id" : 3223472061,
      "title" : "Improve ???Contributing??? guide with local dev steps",
      "url" : "https://github.com/KiiChain/kiichain/issues/64",
      "repositoryName" : "KiiChain/kiichain",
      "description" : "**Is your feature request related to a problem? Please describe.**\n`CONTRIBUTING.md` lacks detailed steps for setting up a dev environment (e.g., building, running tests).\n\n**Describe the solution you'd like**\nAdd sections covering:\n\n* Cloning repo\n* Installing Go, Docker, etc.\n* How to build (`make build` or `go build`)\n* Running unit tests (`go test ./...`)\n* Running e2e tests\n\n**Describe alternatives you've considered**\nUsers figure it out from CI builds.\n\n**Additional context**\nInclude screenshots or snippets.\n",
      "updatedAt" : 1752250482.000000000,
      "user" : "jhelison",
      "userHtmlUrl" : "https://github.com/jhelison",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68653689?v=4",
      "labels" : [ "documentation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "On-chain FX layer for stablecoins and RWA.",
        "homepage" : "https://kiichain.io/",
        "name" : "kiichain",
        "fullName" : "KiiChain/kiichain",
        "htmlUrl" : "https://github.com/KiiChain/kiichain",
        "gitUrl" : "git://github.com/KiiChain/kiichain.git",
        "sshUrl" : "git@github.com:KiiChain/kiichain.git",
        "cloneUrl" : "https://github.com/KiiChain/kiichain.git",
        "owner" : {
          "login" : "KiiChain",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 22,
        "watchersCount" : 22,
        "size" : 6051,
        "openIssuesCount" : 14,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-04T20:01:26Z",
        "languages" : {
          "Dockerfile" : 1718,
          "Shell" : 36098,
          "Solidity" : 9962,
          "Makefile" : 21606,
          "Go" : 1097509,
          "HTML" : 4061,
          "Python" : 2728
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve \"Contributing\" guide with local dev steps",
      "validationOrRequirement" : "Detailed steps for setting up a dev environment (e.g., building, running tests)",
      "attemptedFixes" : "Users figure it out from CI builds",
      "otherNotes" : "Include screenshots or snippets",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283569
  }, {
    "issueDTO" : {
      "id" : 3223460920,
      "title" : "Improve docs on precompiled-contracts in kiichain-docs and on repo",
      "url" : "https://github.com/KiiChain/kiichain/issues/62",
      "repositoryName" : "KiiChain/kiichain",
      "description" : "**Is your feature request related to a problem? Please describe.**\nPrecomplies are missing description and readmes explaining their implementation and usability\n\n**Describe the solution you'd like**\nNew readmes for the precompiles and description on kiichain-docs\n\n**Describe alternatives you've considered**\nReading the code\n\n**Additional context**\nPrecompiles can be found here: https://github.com/KiiChain/kiichain/tree/main/precompiles\n",
      "updatedAt" : 1752250263.000000000,
      "user" : "jhelison",
      "userHtmlUrl" : "https://github.com/jhelison",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68653689?v=4",
      "labels" : [ "documentation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "On-chain FX layer for stablecoins and RWA.",
        "homepage" : "https://kiichain.io/",
        "name" : "kiichain",
        "fullName" : "KiiChain/kiichain",
        "htmlUrl" : "https://github.com/KiiChain/kiichain",
        "gitUrl" : "git://github.com/KiiChain/kiichain.git",
        "sshUrl" : "git@github.com:KiiChain/kiichain.git",
        "cloneUrl" : "https://github.com/KiiChain/kiichain.git",
        "owner" : {
          "login" : "KiiChain",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 22,
        "watchersCount" : 22,
        "size" : 6051,
        "openIssuesCount" : 14,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-04T20:01:26Z",
        "languages" : {
          "Dockerfile" : 1718,
          "Shell" : 36098,
          "Solidity" : 9962,
          "Makefile" : 21606,
          "Go" : 1097509,
          "HTML" : 4061,
          "Python" : 2728
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve documentation on precompiled-contracts in kiichain-docs and on the repository",
      "validationOrRequirement" : "None mentioned",
      "attemptedFixes" : "Reading the code",
      "otherNotes" : "Precompiles can be found here: https://github.com/KiiChain/kiichain/tree/main/precompiles",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283572
  }, {
    "issueDTO" : {
      "id" : 1267900436,
      "title" : "Test that `downloadCurrentVersion.ts` actually downloads the latest version",
      "url" : "https://github.com/ethereum/solc-js/issues/632",
      "repositoryName" : "ethereum/solc-js",
      "description" : "We used to test that `solcjs --version` returns a version matching the one from `package.json`. I changed that in #626 because this is not really guaranteed - the returned version depends on the binary. So now we should also add a proper test that `downloadCurrentVersion.ts` actually does its job and downloads the right binary. It could be a JS test or an additional check in one of the jobs in CI.",
      "updatedAt" : 1752250209.000000000,
      "user" : "cameel",
      "userHtmlUrl" : "https://github.com/cameel",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/137030?v=4",
      "labels" : [ "testing :hammer:", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Is this issue still open.. I'd love to solve" ],
      "repository" : {
        "description" : "Javascript bindings for the Solidity compiler",
        "homepage" : "https://soliditylang.org",
        "name" : "solc-js",
        "fullName" : "ethereum/solc-js",
        "htmlUrl" : "https://github.com/ethereum/solc-js",
        "gitUrl" : "git://github.com/ethereum/solc-js.git",
        "sshUrl" : "git@github.com:ethereum/solc-js.git",
        "cloneUrl" : "https://github.com/ethereum/solc-js.git",
        "owner" : {
          "login" : "ethereum",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 495,
        "stargazersCount" : 1493,
        "watchersCount" : 1493,
        "size" : 729,
        "openIssuesCount" : 72,
        "subscribersCount" : 44,
        "pushedAt" : "2025-05-07T12:30:50Z",
        "languages" : {
          "TypeScript" : 108876,
          "Solidity" : 1407,
          "JavaScript" : 12915
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Test that downloadCurrentVersion.ts actually downloads the latest version of the binary.",
      "validationOrRequirement" : "The test should verify that downloadCurrentVersion.ts downloads the right binary.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue was changed in #626 and the test was modified to focus on downloading the latest version of the binary.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283574
  }, {
    "issueDTO" : {
      "id" : 3140465292,
      "title" : "Offer a pretty-print option for the JsonFormatter",
      "url" : "https://github.com/Crell/Serde/issues/86",
      "repositoryName" : "Crell/Serde",
      "description" : "This could be a pretty print flag that controls the flags that get used in json_encode(), or it could be a full flags bitmask.  Undecided.",
      "updatedAt" : 1752250056.000000000,
      "user" : "Crell",
      "userHtmlUrl" : "https://github.com/Crell",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/254863?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Robust Serde (serialization/deserialization) library for PHP 8.",
        "homepage" : "",
        "name" : "Serde",
        "fullName" : "Crell/Serde",
        "htmlUrl" : "https://github.com/Crell/Serde",
        "gitUrl" : "git://github.com/Crell/Serde.git",
        "sshUrl" : "git@github.com:Crell/Serde.git",
        "cloneUrl" : "https://github.com/Crell/Serde.git",
        "owner" : {
          "login" : "Crell",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 328,
        "watchersCount" : 328,
        "size" : 733,
        "openIssuesCount" : 15,
        "subscribersCount" : 7,
        "pushedAt" : "2025-06-19T18:11:25Z",
        "languages" : {
          "Dockerfile" : 343,
          "Shell" : 523,
          "PHP" : 314527
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Offer a pretty-print option for the JsonFormatter",
      "validationOrRequirement" : "Undecided",
      "attemptedFixes" : "",
      "otherNotes" : "This could be a pretty print flag that controls the flags that get used in json_encode(), or it could be a full flags bitmask. Undecided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283577
  }, {
    "issueDTO" : {
      "id" : 3223448563,
      "title" : "Add Docker image publishing via CI",
      "url" : "https://github.com/KiiChain/kiichain/issues/61",
      "repositoryName" : "KiiChain/kiichain",
      "description" : "**Is your feature request related to a problem? Please describe.**\nNo automated Docker release; users build their own images manually.\n\n**Describe the solution you'd like**\nOn tagged releases, have CI build and push Docker image (e.g. `kiichain:3.0.0`) to Docker Hub or GitHub Container Registry.\n\n**Describe alternatives you've considered**\nMaintainers manually upload images.\n\n**Additional context**\nRequires Dockerfile review and credentials stored in GitHub secrets.",
      "updatedAt" : 1752250038.000000000,
      "user" : "jhelison",
      "userHtmlUrl" : "https://github.com/jhelison",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68653689?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "On-chain FX layer for stablecoins and RWA.",
        "homepage" : "https://kiichain.io/",
        "name" : "kiichain",
        "fullName" : "KiiChain/kiichain",
        "htmlUrl" : "https://github.com/KiiChain/kiichain",
        "gitUrl" : "git://github.com/KiiChain/kiichain.git",
        "sshUrl" : "git@github.com:KiiChain/kiichain.git",
        "cloneUrl" : "https://github.com/KiiChain/kiichain.git",
        "owner" : {
          "login" : "KiiChain",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 22,
        "watchersCount" : 22,
        "size" : 6051,
        "openIssuesCount" : 14,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-04T20:01:26Z",
        "languages" : {
          "Dockerfile" : 1718,
          "Shell" : 36098,
          "Solidity" : 9962,
          "Makefile" : 21606,
          "Go" : 1097509,
          "HTML" : 4061,
          "Python" : 2728
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "On tagged releases, have CI build and push Docker image to Docker Hub or GitHub Container Registry.",
      "validationOrRequirement" : "Dockerfile review and credentials stored in GitHub secrets.",
      "attemptedFixes" : "Maintainers manually upload images.",
      "otherNotes" : "Requires Dockerfile review and credentials stored in GitHub secrets.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283579
  }, {
    "issueDTO" : {
      "id" : 3175780973,
      "title" : "Skeleton loaders for tables",
      "url" : "https://github.com/antiwork/flexile/issues/411",
      "repositoryName" : "antiwork/flexile",
      "description" : "Do one page at a time",
      "updatedAt" : 1752249995.000000000,
      "user" : "slavingia",
      "userHtmlUrl" : "https://github.com/slavingia",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/74396?v=4",
      "labels" : [ "$2.5K", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Interested. Picking up this issue\n", "Taking this up. ", "Hi @slavingia, can I work on the other parts of the site?", "Sure", "@slavingia are there more pages to cover in this? asking because the issue was closed. ", "Yes all pages should be done,\n\nPeople\nInvoices\nDocuments\nUpdates\nEquity\nCap table\nOptions\nShares\nConvertibles\nDividends\nBuybacks\n\n(Hopefully not missing any!)", "@slavingia\nPeople\nInvoices\nDocuments\nUpdates\nSettings (many)\nEquity\nCap table\ncan i work on this pages ?\n", "Sure! One at a time to keep PRs small.", "@MAVRICK-1 People, invoices, documents, are already covered. ", "@BeNikk thanx , working on the rest\n", "@slavingia still open to work on this issue?", "@slavingia I???d like to take up the following components if they are not currently being worked on by anyone:\n\n* Shares\n* Convertibles\n* Dividends\n* Buybacks\n\nPlease let me know if these are available. Happy to coordinate accordingly.\n\n", "For anyone who is willing to solve this issue, please note the following pages are already covered by me (so that you don't repeat the work), PR #443 \n- `/administrator/settings`\n- `/administrator/settings/details`\n- `/people/[id]`\n- `/settings/payouts`\n", "hi everyone i am working on  skeleton loading for these Tables\n\n\n  - /equity/cap_table\n  - /equity/tender_offers\n  - /equity/convertibles \n  - /equity/shares\n  - /equity/options \n  ", "Tables, please read contributing.md and use professional English!" ],
      "repository" : {
        "description" : "Contractor payments as easy as 1-2-3",
        "homepage" : "https://flexile.com",
        "name" : "flexile",
        "fullName" : "antiwork/flexile",
        "htmlUrl" : "https://github.com/antiwork/flexile",
        "gitUrl" : "git://github.com/antiwork/flexile.git",
        "sshUrl" : "git@github.com:antiwork/flexile.git",
        "cloneUrl" : "https://github.com/antiwork/flexile.git",
        "owner" : {
          "login" : "antiwork",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 194,
        "stargazersCount" : 597,
        "watchersCount" : 597,
        "size" : 18133,
        "openIssuesCount" : 37,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-11T22:18:59Z",
        "languages" : {
          "TypeScript" : 1286934,
          "CSS" : 4502,
          "Shell" : 3953,
          "Procfile" : 124,
          "SCSS" : 2966,
          "Makefile" : 766,
          "JavaScript" : 135928,
          "HTML" : 48280,
          "Ruby" : 2089215
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement skeleton loaders for tables, focusing on one page at a time to keep PRs small.",
      "validationOrRequirement" : "Contribute to the issue by implementing skeleton loaders for tables, and use professional English as specified in contributing.md.",
      "attemptedFixes" : "PR #443 covers some pages, and @BeNikk is currently working on the remaining pages.",
      "otherNotes" : "The issue involves implementing skeleton loaders for various tables, and contributors are asked to work on one page at a time to keep PRs small. Some pages are already covered by @MAVRICK-1, and @BeNikk is working on the rest.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283583
  }, {
    "issueDTO" : {
      "id" : 3223446003,
      "title" : "Document module boundaries in the README",
      "url" : "https://github.com/KiiChain/kiichain/issues/60",
      "repositoryName" : "KiiChain/kiichain",
      "description" : "**Is your feature request related to a problem? Please describe.**\nMonorepo structure (e.g., `ante`, `app`, `wasmbinding`) isn't explained in README.\n\n**Describe the solution you'd like**\nAdd a section that briefly describes each top-level directory and its purpose.\n\n**Describe alternatives you've considered**\nExplore code manually, which is time-consuming.\n\n**Additional context**\nThis benefits new contributors significantly.\n",
      "updatedAt" : 1752249987.000000000,
      "user" : "jhelison",
      "userHtmlUrl" : "https://github.com/jhelison",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68653689?v=4",
      "labels" : [ "documentation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "On-chain FX layer for stablecoins and RWA.",
        "homepage" : "https://kiichain.io/",
        "name" : "kiichain",
        "fullName" : "KiiChain/kiichain",
        "htmlUrl" : "https://github.com/KiiChain/kiichain",
        "gitUrl" : "git://github.com/KiiChain/kiichain.git",
        "sshUrl" : "git@github.com:KiiChain/kiichain.git",
        "cloneUrl" : "https://github.com/KiiChain/kiichain.git",
        "owner" : {
          "login" : "KiiChain",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 22,
        "watchersCount" : 22,
        "size" : 6051,
        "openIssuesCount" : 14,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-04T20:01:26Z",
        "languages" : {
          "Dockerfile" : 1718,
          "Shell" : 36098,
          "Solidity" : 9962,
          "Makefile" : 21606,
          "Go" : 1097509,
          "HTML" : 4061,
          "Python" : 2728
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document module boundaries in the README, specifically explaining the monorepo structure.",
      "validationOrRequirement" : "Add a section that briefly describes each top-level directory and its purpose.",
      "attemptedFixes" : "Explore code manually, which is time-consuming.",
      "otherNotes" : "This benefits new contributors significantly.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283586
  }, {
    "issueDTO" : {
      "id" : 2958027414,
      "title" : "Error : Report error for not matching string array types",
      "url" : "https://github.com/lfortran/lfortran/issues/6776",
      "repositoryName" : "lfortran/lfortran",
      "description" : "MRE \n```.f90\nprogram test\n  character(2):: x(200)\n  character(:),allocatable:: y(:)\n  call ss(x)   ! <<<<<<<<<<<<<<<<<< ERROR\n  ! call ss(y) ! <<<<<<<<<<<<<<<<<< This works\n  contains \n  subroutine ss (xx)\n    character(:), allocatable :: xx(:)  \n    xx(1) = \"AB\"\n  end subroutine \nend program test\n```\n```console\ncode generation error: asr_to_llvm: module failed verification. Error:\nStored value type does not match pointer operand type!\n  store [3 x i8]* %9, i8*** %10, align 8\n i8**Call parameter type does not match function signature!\n  %array_descriptor = alloca %array, align 8\n %array**  call void @ss(%array* %array_descriptor)\n\n\n\nNote: Please report unclear, confusing or incorrect messages as bugs at\nhttps://github.com/lfortran/lfortran/issues.\nassem@assem-PC:~/Desktop/fortran/compile_gsnap$ gfortran tt7.f90 \ntt7.f90:16:10:\n\n   16 |   call ss(x)   ! <<<<<<<<<<<<<<<<<< ERROR\n      |          1\nError: Actual argument at (1) to allocatable or pointer dummy argument ???xx??? must have a deferred length type parameter if and only if the dummy has one\nassem@assem-PC:~/Desktop/fortran/compile_gsnap$ \n\n```",
      "updatedAt" : 1752249809.000000000,
      "user" : "assem2002",
      "userHtmlUrl" : "https://github.com/assem2002",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/75497299?v=4",
      "labels" : [ "strings", "good first issue", "easy to fix" ],
      "state" : "OPEN",
      "comments" : [ "hi @assem2002, \nI would like to work on this issue, can you guide me a little bit please.\n ", "Hi @galactus3050. Thanks for your interest in this issue. \n\nHere is the ASR node for strings `String(int kind, int len, expr? len_expr, string_physical_type physical_type)`,    `int len` member if set to `-2` it means the length is deferred. You can them check the passed `ASR::Var` node in `ASR::Functioncall` against the actuall `ASR::Variable` type of the function `ss` if `m_len` aren't of the same value you can raise the same error raised by gfortran.\n\nReference : \n- Check function `inline bool check_equal_type(ASR::ttype_t* x, ASR::ttype_t* y, bool check_for_dimensions)` at file `asr_utils.h` https://github.com/lfortran/lfortran/blob/5026aeca39330a5f862c45111744d98be85a5e7b/src/libasr/asr_utils.h#L3994-L3995.\n- Check `ASR::string` node documentation https://github.com/lfortran/lfortran/blob/5026aeca39330a5f862c45111744d98be85a5e7b/doc/src/asr/asr.md?plain=1#L181-L185\n\nWe're now doing some string-related refactoring, so you may will find what I'm about to suggest got changed, but here is the appropriate way to fix that for now. even if things got changed about the string node, The mentioned fix above will be so much related.", "Hi @assem2002,\n\nI have tried to make changes in the 'Call_t_body' in the 'asr_utils.h', where the length check is taking place . I tried to add the check for the deferred length, but I am not able to understand from where will it throw the error for this. " ],
      "repository" : {
        "description" : "Official main repository for LFortran",
        "homepage" : "https://lfortran.org/",
        "name" : "lfortran",
        "fullName" : "lfortran/lfortran",
        "htmlUrl" : "https://github.com/lfortran/lfortran",
        "gitUrl" : "git://github.com/lfortran/lfortran.git",
        "sshUrl" : "git@github.com:lfortran/lfortran.git",
        "cloneUrl" : "https://github.com/lfortran/lfortran.git",
        "owner" : {
          "login" : "lfortran",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 202,
        "stargazersCount" : 1095,
        "watchersCount" : 1095,
        "size" : 52880,
        "openIssuesCount" : 2023,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-11T20:52:25Z",
        "languages" : {
          "Xonsh" : 671,
          "Yacc" : 92550,
          "C++" : 7944261,
          "Jinja" : 154,
          "C" : 236628,
          "CMake" : 212336,
          "Jupyter Notebook" : 33238,
          "Fortran" : 2003998,
          "Dockerfile" : 890,
          "Shell" : 52311,
          "Batchfile" : 323,
          "LLVM" : 121,
          "Nix" : 7698,
          "Python" : 768503
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Error: Report error for not matching string array types, code generation error: asr_to_llvm: module failed verification. Error: Stored value type does not match pointer operand type!",
      "validationOrRequirement" : "Actual argument at (1) to allocatable or pointer dummy argument 'xx' must have a deferred length type parameter if and only if the dummy has one",
      "attemptedFixes" : "tried to make changes in the 'Call_t_body' in the 'asr_utils.h', added check for deferred length but unable to understand where it will throw the error",
      "otherNotes" : "ASR node for strings, reference to check function and ASR::string node documentation, mention of string-related refactoring",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283591
  }, {
    "issueDTO" : {
      "id" : 3223068032,
      "title" : "[EPIC] Refactor all expression serde logic out of `QueryPlanSerde`",
      "url" : "https://github.com/apache/datafusion-comet/issues/2019",
      "repositoryName" : "apache/datafusion-comet",
      "description" : "### What is the problem the feature request solves?\n\nThe `QueryPlanSerde.exprToProtoInternal` method contains logic for serializing Spark expressions to protocol buffer format and also contains checks that Comet supports the expression. This file has grown very large and is hard to navigate, so we would like to refactor this logic such that the per-expression logic is moved into separate classes.\n\nAs an example, here is the original approach for handling the `Add` expression:\n\n```scala\n      case add @ Add(left, right, _) if supportedDataType(left.dataType) =>\n        createMathExpression(\n          expr,\n          left,\n          right,\n          inputs,\n          binding,\n          add.dataType,\n          add.evalMode == EvalMode.ANSI,\n          (builder, mathExpr) => builder.setAdd(mathExpr))\n\n      case add @ Add(left, _, _) if !supportedDataType(left.dataType) =>\n        withInfo(add, s\"Unsupported datatype ${left.dataType}\")\n        None\n```\n\nThe new approach is to move this into a separate file and class:\n\n```scala\nobject CometAdd extends CometExpressionSerde with MathBase {\n  override def convert(\n      expr: Expression,\n      inputs: Seq[Attribute],\n      binding: Boolean): Option[ExprOuterClass.Expr] = {\n    val add = expr.asInstanceOf[Add]\n    if (!supportedDataType(add.left.dataType)) {\n      withInfo(add, s\"Unsupported datatype ${add.left.dataType}\")\n      return None\n    }\n    createMathExpression(\n      expr,\n      add.left,\n      add.right,\n      inputs,\n      binding,\n      add.dataType,\n      add.evalMode == EvalMode.ANSI,\n      (builder, mathExpr) => builder.setAdd(mathExpr))\n  }\n}\n```\n\nThese classes are then referenced from QueryPlanSerde in a map:\n\n```scala\n  private val exprSerdeMap: Map[Class[_], CometExpressionSerde] = Map(\n    classOf[Add] -> CometAdd,\n    classOf[Subtract] -> CometSubtract,\n    classOf[Multiply] -> CometMultiply,\n    ...\n```\n\nThis approach has some benefits, such as:\n\n- Moving away from all expressions sharing the same logic for determining which data types are supported (different expressions support different types)\n- It makes it easier to write unit tests (https://github.com/apache/datafusion-comet/issues/2020)\n- Once all expressions migrate to the new pattern, it will be easier to automate generating documentation about supported expressions\n- It is likely that we will find common patterns and will be able to refactor the code to reduce boilerplate\n\n### Describe the potential solution\n\nConvert the following expressions:\n\n- [x] Add\n- [x] Subtract\n- [x] Multiply\n- [x] Divide\n- [x] IntegralDivide\n- [x] Remainder\n- [x] ArrayAppend\n- [x] ArrayContains\n- [x] ArrayDistinct\n- [x] ArrayExcept\n- [x] ArrayInsert\n- [x] ArrayIntersect\n- [x] ArrayJoin\n- [x] ArrayMax\n- [x] ArrayRemove\n- [x] ArrayRepeat\n- [x] ArraysOverlap\n- [x] ArrayUnion\n- [x] CreateArray\n- [x] Ascii\n- [x] ConcatWs\n- [x] Chr\n- [x] InitCap\n- [x] BitwiseCount\n- [x] BitwiseGet\n- [x] BitwiseNot\n- [x] BitwiseOr\n- [x] BitwiseXor\n- [x] BitLength\n- [x] FromUnixTime\n- [x] Length\n- [x] Acos\n- [x] Cos\n- [x] Asin\n- [x] Sin\n- [x] Atan\n- [x] Tan\n- [x] Exp\n- [x] Expm1\n- [x] Sqrt\n- [x] Signum\n- [x] Md5\n- [x] ShiftLeft\n- [x] ShiftRight\n- [x] StringInstr\n- [x] StringRepeat\n- [x] StringReplace\n- [x] StringTranslate\n- [x] StringTrim\n- [x] StringTrimLeft\n- [x] StringTrimRight\n- [x] StringTrimBoth\n- [x] Upper\n- [x] Lower\n- [x] Murmur3Hash\n- [x] XxHash64\n- [x] MapKeys\n- [x] MapValues\n- [x] MapFromArrays\n- [x] GetMapValue\n- [ ] Alias \n- [ ] TryCast \n- [ ] Cast \n- [ ] EqualTo \n- [ ] Not(EqualTo \n- [ ] EqualNullSafe \n- [ ] Not(EqualNullSafe \n- [ ] GreaterThan \n- [ ] GreaterThanOrEqual \n- [ ] LessThan \n- [ ] LessThanOrEqual \n- [ ] Literal\n- [ ] Substring \n- [ ] StructsToJson \n- [ ] Like \n- [ ] RLike \n- [ ] StartsWith \n- [ ] EndsWith \n- [ ] Contains \n- [ ] StringSpace \n- [ ] Hour \n- [ ] Minute \n- [ ] DateAdd \n- [ ] DateSub \n- [ ] TruncDate \n- [ ] TruncTimestamp \n- [ ] Second \n- [ ] Year \n- [ ] IsNull \n- [ ] IsNotNull \n- [ ] IsNaN\n- [ ] SortOrder \n- [ ] And \n- [ ] Or \n- [ ] PromotePrecision \n- [ ] CheckOverflow \n- [ ] Atan2 \n- [ ] Hex \n- [ ] Unhex \n- [ ] Ceil \n- [ ] Floor \n- [ ] Log \n- [ ] Log10 \n- [ ] Log2 \n- [ ] Pow \n- [ ] Round \n- [ ] StringDecode \n- [ ] RegExpReplace \n- [ ] If \n- [ ] CaseWhen \n- [ ] OctetLength \n- [ ] Reverse \n- [ ] BitwiseAnd \n- [ ] In \n- [ ] InSet \n- [ ] Not(In) \n- [ ] Not \n- [ ] UnaryMinus \n- [ ] StringRPad \n- [ ] KnownFloatingPointNormalized \n- [ ] ScalarSubquery \n- [ ] UnscaledValue \n- [ ] MakeDecimal \n- [ ] BloomFilterMightContain \n- [ ] Sha2 \n- [ ] CreateNamedStruct \n- [ ] GetStructField \n- [ ] GetArrayItem \n- [ ] ElementAt\n- [ ] GetArrayStructFields \n- [ ] ArrayFilter \n- [ ] ArrayExcept \n- [ ] Rand \n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752249649.000000000,
      "user" : "andygrove",
      "userHtmlUrl" : "https://github.com/andygrove",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/934084?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Apache DataFusion Comet Spark Accelerator",
        "homepage" : "https://datafusion.apache.org/comet",
        "name" : "datafusion-comet",
        "fullName" : "apache/datafusion-comet",
        "htmlUrl" : "https://github.com/apache/datafusion-comet",
        "gitUrl" : "git://github.com/apache/datafusion-comet.git",
        "sshUrl" : "git@github.com:apache/datafusion-comet.git",
        "cloneUrl" : "https://github.com/apache/datafusion-comet.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 222,
        "stargazersCount" : 989,
        "watchersCount" : 989,
        "size" : 19074,
        "openIssuesCount" : 249,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-11T21:47:57Z",
        "languages" : {
          "Java" : 477078,
          "Dockerfile" : 6894,
          "Shell" : 29303,
          "Rust" : 1894706,
          "Scala" : 1652880,
          "Makefile" : 5518,
          "Python" : 8374
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor all expression serde logic out of QueryPlanSerde to improve code navigation, reduce boilerplate, and make it easier to write unit tests and automate generating documentation about supported expressions.",
      "validationOrRequirement" : "The requirements for this refactoring include moving away from all expressions sharing the same logic for determining which data types are supported, and making it easier to write unit tests and automate generating documentation about supported expressions.",
      "attemptedFixes" : "The new approach is to move per-expression logic into separate classes, which are then referenced from QueryPlanSerde in a map.",
      "otherNotes" : "This issue aims to refactor all expression serde logic out of QueryPlanSerde to improve code navigation, reduce boilerplate, and make it easier to write unit tests and automate generating documentation about supported expressions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283596
  }, {
    "issueDTO" : {
      "id" : 3059642767,
      "title" : "Column Formatting: The number 1e-18 cannot be converted to a BigInt because it is not an integer",
      "url" : "https://github.com/metabase/metabase/issues/57884",
      "repositoryName" : "metabase/metabase",
      "description" : "### Describe the bug\n\nThis is a bug that appears when I upgrade to Metabase v54 from v53:\nI have a report that is using big numbers like that to format currencies, and it was working before but after upgrading I get this error in the frontend (javascript error)\n\n![Image](https://github.com/user-attachments/assets/f053c93f-b542-4c00-8aaf-d17ed0dda833)\n\n### To Reproduce\n\n1. Create a report that uses a column formatting to multiply a number\n2. Set to multiply by `1e-18`\n3. Report fails to load, error in JS console\n\n![Image](https://github.com/user-attachments/assets/74f867c5-145a-460a-9cc5-1d56b794df11)\n\n\n### Expected behavior\n\nI think this can be worked around by falling back to doing regular multiplication when the number is not an Integer, in this case `1e-18` is a Float\n\n### Logs\n\n_No response_\n\n### Information about your Metabase installation\n\n```JSON\n{\n  \"browser-info\": {\n    \"language\": \"en-US\",\n    \"platform\": \"MacIntel\",\n    \"userAgent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36\",\n    \"vendor\": \"Google Inc.\"\n  },\n  \"metabase-info\": {\n    \"databases\": [\n      \"postgres\",\n      \"h2\"\n    ],\n    \"run-mode\": \"prod\",\n    \"plan-alias\": \"\",\n    \"version\": {\n      \"date\": \"2025-05-06\",\n      \"tag\": \"v0.54.6\",\n      \"hash\": \"d56bf23\"\n    },\n    \"settings\": {\n      \"report-timezone\": null\n    },\n    \"hosting-env\": \"unknown\",\n    \"application-database\": \"postgres\",\n    \"application-database-details\": {\n      \"database\": {\n        \"name\": \"PostgreSQL\",\n        \"version\": \"16.9\"\n      },\n      \"jdbc-driver\": {\n        \"name\": \"PostgreSQL JDBC Driver\",\n        \"version\": \"42.7.4\"\n      }\n    }\n  },\n  \"system-info\": {\n    \"file.encoding\": \"UTF-8\",\n    \"java.runtime.name\": \"OpenJDK Runtime Environment\",\n    \"java.runtime.version\": \"21.0.7+6-LTS\",\n    \"java.vendor\": \"Eclipse Adoptium\",\n    \"java.vendor.url\": \"https://adoptium.net/\",\n    \"java.version\": \"21.0.7\",\n    \"java.vm.name\": \"OpenJDK 64-Bit Server VM\",\n    \"java.vm.version\": \"21.0.7+6-LTS\",\n    \"os.name\": \"Linux\",\n    \"os.version\": \"6.8.0-59-generic\",\n    \"user.language\": \"en\",\n    \"user.timezone\": \"GMT\"\n  }\n}\n```\n\n### Severity\n\nMedium - cannot upgrade to v54 without breaking most of my reports\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752248975.000000000,
      "user" : "adamJLev",
      "userHtmlUrl" : "https://github.com/adamJLev",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/188466?v=4",
      "labels" : [ ".Team/DashViz", ".Dashviz Triaged", "Visualization/Scalars", "Priority:P2", "Bug:v54", "Type:Bug", "good first issue", ".Regression" ],
      "state" : "OPEN",
      "comments" : [ "Bumping this one, this issue is preventing us from being able to upgrade to newer metabase versions\n\nI have the PR here but I need some help with the unit tests, although I'm pretty sure someone in the metabase team would fix this super easily since its just a few lines:\nhttps://github.com/metabase/metabase/pull/58428" ],
      "repository" : {
        "description" : "The easy-to-use open source Business Intelligence and Embedded Analytics tool that lets everyone work with data :bar_chart:",
        "homepage" : "https://metabase.com",
        "name" : "metabase",
        "fullName" : "metabase/metabase",
        "htmlUrl" : "https://github.com/metabase/metabase",
        "gitUrl" : "git://github.com/metabase/metabase.git",
        "sshUrl" : "git@github.com:metabase/metabase.git",
        "cloneUrl" : "https://github.com/metabase/metabase.git",
        "owner" : {
          "login" : "metabase",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5709,
        "stargazersCount" : 42723,
        "watchersCount" : 42723,
        "size" : 1187997,
        "openIssuesCount" : 3977,
        "subscribersCount" : 643,
        "pushedAt" : "2025-07-11T23:32:04Z",
        "languages" : {
          "TypeScript" : 17100740,
          "MDX" : 47155,
          "Dockerfile" : 4898,
          "CSS" : 260981,
          "Shell" : 40480,
          "Handlebars" : 31308,
          "JavaScript" : 6354275,
          "Mustache" : 2982,
          "HTML" : 6138,
          "Clojure" : 23623454,
          "Emacs Lisp" : 5176
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to resolve the bug that appears when upgrading to Metabase v54, specifically with column formatting and big numbers like 1e-18, and make it possible to upgrade without breaking reports.",
      "validationOrRequirement" : "The issue requires a fix to allow upgrading to Metabase v54 without breaking reports, and the author is looking for help with unit tests.",
      "attemptedFixes" : "The author suggests falling back to regular multiplication when the number is not an Integer, in this case 1e-18 is a Float.",
      "otherNotes" : "The issue is specific to Metabase v54 and appears when upgrading from v53, causing an error in the frontend (javascript error) when using big numbers for column formatting.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283602
  }, {
    "issueDTO" : {
      "id" : 2827823596,
      "title" : "AIP-84 | Add multisort to dags list request",
      "url" : "https://github.com/apache/airflow/issues/46383",
      "repositoryName" : "apache/airflow",
      "description" : "In the UI, we default the dags list to show dags with the latest dag run first , which we pass as `-last_dag_run_start_date`. Problem is that the minus symbol seems to make the default sorts also reverse so any dags without a dag run will be in reverse alphabetical order which is counterintuitive for users.\nIf you reverse the dag run start date order, it will also change the alphabetical order.\n\n<img width=\"1711\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/91c38cb5-bc15-4f75-9305-9e5cea966a0b\" />",
      "updatedAt" : 1752248895.000000000,
      "user" : "bbovenzi",
      "userHtmlUrl" : "https://github.com/bbovenzi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4600967?v=4",
      "labels" : [ "area:UI", "type:new-feature", "AIP-84", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Nice. For now the `dag_id` (name) is always used as the secondary sort criteria to ensure stability in the result set returned. (In case the primary criteria has identical values).\n\nWhen we use a descending sort, the secondary filter (which is the primary key of the table, here the `dag_id` is also `.desc()`).\n\nIn the following code `column` is the primary sort criteria, the one specified by the user. `primary_key_column` is the secondary sort criteria always used and retrieved from the models.\n\nhttps://github.com/apache/airflow/blob/ee6bd7ee162ff295b86d86fdd1b356c51b9bba78/airflow/api_fastapi/common/parameters.py#L202-L205\n\nI think we need to support multisort to be able to handle this case. Users would be able to specify that they want to sort on the primary criteria in asc(), but on a secondary criteria in desc() order for intance. (Or any other arbitrary combination).", "Hey can work on this. ", "Great, assigned ! ", "Hello @pierrejeambrun, Are both front-end and back-end changes being done by the assignee?", "Hello @prasad-madine, I assume so.\n\nWe need the backend contribution to start working on the front-end anyway.\n\n@Vishnu-sai-teja any progress ? Do you have plan on following up with the front-end changes as well ?", "Hey out of town, haven't started on it yet, Sorry I should have informed earlier", "The UI part should be fairly straightforward: https://tanstack.com/table/latest/docs/guide/sorting#multi-sorting", "Hello @pierrejeambrun , \n I am currently working on implementing sorting functionality in the backend and would appreciate your guidance on the following two approaches:\n\nOption 1\n1. Allow user to select the primary sort field and order(asc/desc)\n2. Allow user to select the secondary sort field and order(asc/desc)\n3. Allow user to select which field is primary and which field is secondary\n\nOption 2\n1. Allow user to select the primary sort field and order(asc/desc)\n2. Do not allow user to select the secondary sort field. Secondary sort field is always primary key.\n3. Allow user to select the order in which we sort based on primary key.\n\nCould you please advise on which option would be more appropriate or effective in this context?\n", "I would say option 1. The sort param would be passed in the url like so: `order_by=-run-after&order_by=dag_display_name`\n\nThe primary sort should be the first order_by param passed. Secondary sort, the second param.", "> I would say option 1. The sort param would be passed in the url like so: order_by=-run-after&order_by=dag_display_name\n\n> The primary sort should be the first order_by param passed. Secondary sort, the second param.\n\nThat's also what I had in mind.", "Hello @bbovenzi @pierrejeambrun , I've implemented the backend code in below PR, Could you please review that.\nhttps://github.com/apache/airflow/pull/47440\nThankyou.", "Hello @bbovenzi @pierrejeambrun ! I'm a senior CS and engineering student and i would love to contribute to the frontend part of this issue for a project for one of my final classes. Would that be possible?", "@mariana-marcal-santana you can follow along the backend change https://github.com/apache/airflow/pull/47440.\n\n@prasad-madine were you planning on following up with the frontend once you are done with the backend or do you want @mariana-marcal-santana to take this work ?", "> [@mariana-marcal-santana](https://github.com/mariana-marcal-santana) you can follow along the backend change [#47440](https://github.com/apache/airflow/pull/47440).\n> \n> [@prasad-madine](https://github.com/prasad-madine) were you planning on following up with the frontend once you are done with the backend or do you want [@mariana-marcal-santana](https://github.com/mariana-marcal-santana) to take this work ?\n\nYeah @mariana-marcal-santana can work on frontend portion.\nThanks", "@mariana-marcal-santana  you'r also assigned", "Hello @bbovenzi @pierrejeambrun ! I've been working on the frontend of this issue and I believe I'm in the right track to solve it. However, I have a few things that I would like to confirm. \nI followed the instructions on the link provided here https://github.com/apache/airflow/issues/46383#issuecomment-2657183808 to implement the multisort in the DAG table and now it's possible to define more sort parameters in the URL, as shown in the picture bellow.\n\n![Image](https://github.com/user-attachments/assets/366e5783-d88b-444b-8b65-03a934277d79)\n\nAs seen in the picture, the DAGs should be sorted firstly by \"last_run_start_date\" (OK) and secondly by \"-dag_id\" (not OK) because they appear sorted by \"dag_id\". Given this, I'm not sure where my implementation could be going wrong or if it's something related to the backend. @prasad-madine sorry to bother but could you take a look into this case please?\nI also wanted to point out that the parameters are mentioned in the URL as \"sort=\" and not \"order_by=\" like mentioned here https://github.com/apache/airflow/issues/46383#issuecomment-2660164876. I'm not sure if that would be a problem, especially because since I've been working on this issue, they've always appeared as \"sort=\" in the UI but I would appreciate it if someone could confirm that.\nThank you!\n", "@mariana-marcal-santana Thanks, looking good.\n\nhttps://github.com/apache/airflow/pull/47859 (backend) has not been merged into main yet, are you building your PR on top of https://github.com/apache/airflow/pull/47859  ? Otherwise you will need to wait for the backend to be completed (it is not supported yet). \n", "> I'm not sure if that would be a problem, especially because since I've been working on this issue, they've always appeared as \"sort=\" in the UI but I would appreciate it if someone could confirm that.\n\nIndeed, in the url we use `sort` and the front-end converts this to `order_by` before sending the request to the backend. (I don't know why we just didn't use `orderBy` too in the url, but just to answer your question, this is expected and shouldn't be a problem.)", "> [#47859](https://github.com/apache/airflow/pull/47859) (backend) has not been merged into main yet, are you building your PR on top of [#47859](https://github.com/apache/airflow/pull/47859) ? Otherwise you will need to wait for the backend to be completed (it is not supported yet).\n\nFor the multisort to fully work it needs the #47440's backend but I tested locally my changes by themselves and they don't break the platform even without the corresponding backend. I don't mind waiting for the backend and if anything is needed I would be happy to help!\n\nAlso, maybe I didn't fully understand the question but I don't know much about the PR mentioned in the comment and if it has any effect on mine...", "> Indeed, in the url we use `sort` and the front-end converts this to `order_by` before sending the request to the backend. (I don't know why we just didn't use `orderBy` too in the url, but just to answer your question, this is expected and shouldn't be a problem.)\n\nThanks for clearing that out!", "Hello @bbovenzi @pierrejeambrun ! \nHave you gotten a chance to look at the fixes from last commit? \nThanks", "Hello @mariana-marcal-santana,\n\nSorry for the delay, I just did a review, it will be easier to test and iterate once the backend is merged, we're working on that.", "Hello @pierrejeambrun ! \nIn the meantime, I've adapted the other sorts to work as a list of strings. Could you have a look please? \nAlso, when the backend is merged I'll test the implementation more thoroughly as suggested." ],
      "repository" : {
        "description" : "Apache Airflow - A platform to programmatically author, schedule, and monitor workflows",
        "homepage" : "https://airflow.apache.org/",
        "name" : "airflow",
        "fullName" : "apache/airflow",
        "htmlUrl" : "https://github.com/apache/airflow",
        "gitUrl" : "git://github.com/apache/airflow.git",
        "sshUrl" : "git@github.com:apache/airflow.git",
        "cloneUrl" : "https://github.com/apache/airflow.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15301,
        "stargazersCount" : 40971,
        "watchersCount" : 40971,
        "size" : 416042,
        "openIssuesCount" : 1526,
        "subscribersCount" : 763,
        "pushedAt" : "2025-07-11T23:51:39Z",
        "languages" : {
          "Java" : 1443,
          "Jinja" : 76192,
          "CSS" : 15733,
          "Go" : 63158,
          "HTML" : 42905,
          "Jupyter Notebook" : 7288,
          "TypeScript" : 2124349,
          "HCL" : 3786,
          "Dockerfile" : 119790,
          "Shell" : 230742,
          "JavaScript" : 328117,
          "Mako" : 2684,
          "Python" : 42415969
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add multisort to the dags list request in the UI, allowing users to specify multiple sort criteria.",
      "validationOrRequirement" : "The multisort functionality requires the backend to be fully implemented, as mentioned in the comments. The frontend changes do not break the platform even without the corresponding backend.",
      "attemptedFixes" : "The issue has been attempted to be fixed by implementing the multisort functionality in the backend and frontend. The backend code has been implemented in PR #47440, and the frontend code has been implemented in PR #47859.",
      "otherNotes" : "The issue is about adding multisort to the dags list request in the UI, allowing users to specify multiple sort criteria. The backend code has been implemented in PR #47440, and the frontend code has been implemented in PR #47859. The multisort functionality needs the backend to be fully implemented, but the frontend changes do not break the platform even without the corresponding backend.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283608
  }, {
    "issueDTO" : {
      "id" : 3218552145,
      "title" : "Wrong number of documents",
      "url" : "https://github.com/meilisearch/meilisearch/issues/5750",
      "repositoryName" : "meilisearch/meilisearch",
      "description" : "**Describe the bug**\nAfter indexing 35k documents with user-provided embeddings and deleting all the documents, the `/stats` route still returns that there are 35k docs even though the index is empty and returns zero results.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Send a bunch of documents\n2. Delete all the documents by using [the dedicated route](https://www.meilisearch.com/docs/reference/api/documents#delete-all-documents)\n3. Look at the stats and see the wrong number of documents\n\n**Expected behavior**\nShow zero documents in the stats after we deleted all the documents using the dedicated route.\n\n**Screenshots**\n\n```\n{\n  \"databaseSize\": 479502336,\n  \"usedDatabaseSize\": 364544,\n  \"lastUpdate\": \"2025-07-10T09:10:51.873776794Z\",\n  \"indexes\": {\n    \"main\": {\n      \"numberOfDocuments\": 35833,\n      \"rawDocumentDbSize\": 47812608,\n      \"avgDocumentSize\": 1326,\n      \"isIndexing\": false,\n      \"numberOfEmbeddings\": 0,\n      \"numberOfEmbeddedDocuments\": 0,\n      \"fieldDistribution\": {}\n    }\n  }\n}\n```\n\n**Meilisearch version:**\nv1.15.2\n",
      "updatedAt" : 1752248869.000000000,
      "user" : "Kerollmops",
      "userHtmlUrl" : "https://github.com/Kerollmops",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3610253?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'd like to work on this." ],
      "repository" : {
        "description" : "A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.",
        "homepage" : "https://www.meilisearch.com",
        "name" : "meilisearch",
        "fullName" : "meilisearch/meilisearch",
        "htmlUrl" : "https://github.com/meilisearch/meilisearch",
        "gitUrl" : "git://github.com/meilisearch/meilisearch.git",
        "sshUrl" : "git@github.com:meilisearch/meilisearch.git",
        "cloneUrl" : "https://github.com/meilisearch/meilisearch.git",
        "owner" : {
          "login" : "meilisearch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2102,
        "stargazersCount" : 52282,
        "watchersCount" : 52282,
        "size" : 74564,
        "openIssuesCount" : 257,
        "subscribersCount" : 295,
        "pushedAt" : "2025-07-11T20:00:33Z",
        "languages" : {
          "Dockerfile" : 1494,
          "Shell" : 5712,
          "RenderScript" : 1,
          "Rust" : 7048735
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about the `/stats` route still returning the wrong number of documents even after deleting all documents using the dedicated route.",
      "validationOrRequirement" : "Meilisearch version: v1.15.2, deleting all documents using the dedicated route, and checking the stats for correct number of documents.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "Screenshots provided showing database size, used database size, last update, and indexes with incorrect number of documents.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283612
  }, {
    "issueDTO" : {
      "id" : 3174436048,
      "title" : "[ACTION] Clevertap extend mcp servers to Campaign API",
      "url" : "https://github.com/PipedreamHQ/pipedream/issues/17282",
      "repositoryName" : "PipedreamHQ/pipedream",
      "description" : "Currently, the clevertap MCP server contains two tools:\n\n<img width=\"523\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/39ef5a26-472f-4d0f-a733-ea823c26a204\" />\n\nFor a customer, we need toe Capaign API integration as well. It would be amazing if you could integrate that. Below the endpoints:\n\n1. Campaign API:\n- Create Campaign\nThe Create Campaign API lets you create campaigns in CleverTap. For example, you can use this endpoint to send a push notification to a specific set of users based on their past behaviour in the app. You can also target your campaigns based on segments that match user profile properties you define.\n- Stop Campaign\nThe Stop Campaign API enables you to stop scheduled/running campaigns.\n- Get Campaign Report\nThe Get Campaign Report API lets you get performance metrics about a specific campaign.\n- Get Campaigns\nThe Get Campaigns API lets you get a list of campaigns created using the API.\n\nThanks in advance! Michiel\n",
      "updatedAt" : 1752248689.000000000,
      "user" : "MichielMAnalytics",
      "userHtmlUrl" : "https://github.com/MichielMAnalytics",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135761097?v=4",
      "labels" : [ "triaged", "help wanted", "action", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Any updates on this one?", "?", "Hi @MichielMAnalytics just a heads up here, we are waiting for some credentials so we can continue with testing the components in the PR we have created! \n\ncc @sergio-eliot-rodriguez " ],
      "repository" : {
        "description" : "Connect APIs, remarkably fast.  Free for developers.",
        "homepage" : "https://pipedream.com",
        "name" : "pipedream",
        "fullName" : "PipedreamHQ/pipedream",
        "htmlUrl" : "https://github.com/PipedreamHQ/pipedream",
        "gitUrl" : "git://github.com/PipedreamHQ/pipedream.git",
        "sshUrl" : "git@github.com:PipedreamHQ/pipedream.git",
        "cloneUrl" : "https://github.com/PipedreamHQ/pipedream.git",
        "owner" : {
          "login" : "PipedreamHQ",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5402,
        "stargazersCount" : 10157,
        "watchersCount" : 10157,
        "size" : 601491,
        "openIssuesCount" : 4073,
        "subscribersCount" : 277,
        "pushedAt" : "2025-07-11T19:30:29Z",
        "languages" : {
          "TypeScript" : 1305958,
          "MDX" : 1185411,
          "Dockerfile" : 295,
          "CSS" : 4596,
          "Shell" : 2688,
          "Makefile" : 270,
          "JavaScript" : 25109889,
          "HTML" : 568,
          "Jupyter Notebook" : 22765
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Integrate the Campaign API with the Clevertap MCP server",
      "validationOrRequirement" : "Integration of Campaign API with Clevertap MCP server",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The clevertap MCP server contains two tools, and the customer needs Campaign API integration. The Campaign API endpoints include Create Campaign, Stop Campaign, Get Campaign Report, and Get Campaigns. The issue is waiting for credentials to continue testing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283615
  }, {
    "issueDTO" : {
      "id" : 3223371580,
      "title" : "Revisit limits for list parameters in proto messages",
      "url" : "https://github.com/0xMiden/miden-node/issues/1080",
      "repositoryName" : "0xMiden/miden-node",
      "description" : "> Also, maybe not for this PR, but we should document how many tags can be passed in and adjust if needed. For example, I think currently the limit may be something like 1000, but we probably need to restrict it quite a bit more. This applies to most endpoints which take lists as parameters.\r\n\r\n_Originally posted by @bobbinth in https://github.com/0xMiden/miden-node/pull/1045#discussion_r2199993860_\r\n            \r\nWe should determine if we want to reduce the limit of list's sizes, and document it.\r\n\r\n",
      "updatedAt" : 1752248658.000000000,
      "user" : "SantiagoPittella",
      "userHtmlUrl" : "https://github.com/SantiagoPittella",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/87827390?v=4",
      "labels" : [ "node", "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Reference implementation of the node for the Miden blockchain",
        "homepage" : "https://0xmiden.github.io/miden-node/",
        "name" : "miden-node",
        "fullName" : "0xMiden/miden-node",
        "htmlUrl" : "https://github.com/0xMiden/miden-node",
        "gitUrl" : "git://github.com/0xMiden/miden-node.git",
        "sshUrl" : "git@github.com:0xMiden/miden-node.git",
        "cloneUrl" : "https://github.com/0xMiden/miden-node.git",
        "owner" : {
          "login" : "0xMiden",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 69,
        "stargazersCount" : 67,
        "watchersCount" : 67,
        "size" : 5128,
        "openIssuesCount" : 76,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-11T20:54:02Z",
        "languages" : {
          "Dockerfile" : 2801,
          "Shell" : 5646,
          "CSS" : 3546,
          "Rust" : 1278226,
          "Makefile" : 5647,
          "JavaScript" : 9714,
          "HTML" : 1976
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Determine if the limit of list's sizes should be reduced and document it",
      "validationOrRequirement" : "Reduce the limit of list's sizes and document it",
      "attemptedFixes" : "",
      "otherNotes" : "Documenting the limit of list sizes and adjusting it if needed, specifically for most endpoints that take lists as parameters.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283618
  }, {
    "issueDTO" : {
      "id" : 3095612487,
      "title" : "Text is not centered when event is 15 minutes long",
      "url" : "https://github.com/SwitchbackTech/compass/issues/464",
      "repositoryName" : "SwitchbackTech/compass",
      "description" : "### Feature Description\n\nThe text should always be centered in the rectangle, and it shouldn't appear clipped at the bottom.\n\n<img width=\"196\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/515b9b5d-2b6f-4c91-a93c-f6860fbdead0\" />\n\n### Use Case\n\nThis'll give users a consistent UX, rather than leaving them wondering why titles look \"off\" when the events are short\n\n### Additional Context\n\nIf needed, you can shrink the text slightly for these events.\n\nReference how other calendars handle this scenario, including: Gcal, Vim Cal, Notion Calendar, and Outlook.",
      "updatedAt" : 1752248049.000000000,
      "user" : "tyler-dane",
      "userHtmlUrl" : "https://github.com/tyler-dane",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30163055?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "GM!\nMy name is Dinah, I'm a front-end developer with experience working with typescript. Can I please be assigned this issue? I would love to work on it ", "Hey @dinahmaccodes , thanks for volunteering. Just assigned it to you", "Thanks will make PR soon @tyler-dane ", "Hello please can you unassign me? \nI'm having issue doing the setup and it's taking me too long to understand and get to the issue @tyler-dane \nMy apologies", "@dinahmaccodes Sure! If you are having setup issues you can always ask and we will do our best to help. For now I will unassign you.", "Thank you. Is there any telegram or discord group i can use to drop my queries and get help, or should i just drop  my questions here. ", "We don't have a separate chat, so you can just drop them here", "\nI'm trying to set up the dev environment to work on the text centering UI fix (#464). The setup requires Google Cloud credentials, but GCP - Google Cloud Platform won't let me create an account without adding a payment method (my card recently expired).\n\nI tried using placeholder values in .env which lets the project load, but authentication fails when it tries to connect to Google services.\n\n Is there a way to run the frontend in development mode without valid Google Cloud credentials? Since this is a pure CSS fix, ideally the frontend should work with mock data.\n I love the idea of this project and would love to contribute to it. ", "@dinahmaccodes Unfortunately there is no way to run the project locally without setting up a Google Cloud \nPlatform account :(", "Hii @tyler-dane  @that-one-arab  assign it to me. Thanks!", "@sarans-h assigned to you", "Just a suggestion when clicking on event it shows time below but when event is of 15 min the time too clipped so what i did is when event is 15 min it will be shown by side \nbefore \n![Image](https://github.com/user-attachments/assets/9561309f-a8f0-4939-b128-e3ef64aa9513)\nafter\n![Image](https://github.com/user-attachments/assets/09923fa5-1761-43be-8a8e-7d0d86fb2383)\nafter(without time)\n\n![Image](https://github.com/user-attachments/assets/3db4bb48-4f81-4d0b-bcb8-27336f5cb9db)\n\nPlease @that-one-arab  whatever needed. Will create PR accordingly. Thanks!", "@sarans-h yes that works thanks!\n", "Unassigned due to inactivity.", "@that-one-arab @tyler-dane could you assign this issue for me ?" ],
      "repository" : {
        "description" : "\uD83E\uDDED Weekly planner for minimalists who value their time",
        "homepage" : "https://www.compasscalendar.com",
        "name" : "compass",
        "fullName" : "SwitchbackTech/compass",
        "htmlUrl" : "https://github.com/SwitchbackTech/compass",
        "gitUrl" : "git://github.com/SwitchbackTech/compass.git",
        "sshUrl" : "git@github.com:SwitchbackTech/compass.git",
        "cloneUrl" : "https://github.com/SwitchbackTech/compass.git",
        "owner" : {
          "login" : "SwitchbackTech",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 44,
        "stargazersCount" : 185,
        "watchersCount" : 185,
        "size" : 8857,
        "openIssuesCount" : 75,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T22:28:24Z",
        "languages" : {
          "TypeScript" : 1225271,
          "Shell" : 124,
          "JavaScript" : 23712,
          "HTML" : 700
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to center the text in the rectangle when the event is 15 minutes long, and ensure that it doesn't appear clipped at the bottom, providing a consistent UX for users.",
      "validationOrRequirement" : "The issue requires a Google Cloud Platform account, and the frontend should work with mock data. The author also mentions that the text should always be centered in the rectangle, and it shouldn't appear clipped at the bottom.",
      "attemptedFixes" : "The author mentions that the issue requires a Google Cloud Platform account, and another contributor suggests using placeholder values in .env to load the project, but authentication fails when trying to connect to Google services. Another contributor proposes a workaround for the 15-minute event layout.",
      "otherNotes" : "The issue description includes an image to illustrate the problem, and several comments discuss the setup requirements, authentication issues, and potential solutions. The author suggests that the frontend should work with mock data, and another contributor proposes a workaround for the 15-minute event layout.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283625
  }, {
    "issueDTO" : {
      "id" : 3221173114,
      "title" : "[Feature Request]: Enhance Metrics Tab UI with Virtual Servers and Top 5 Performance Tables",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/368",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "# Enhance Metrics Tab UI with Virtual Servers and Top 5 Performance Tables\n\n**Priority:** Medium (UI/Analytics Enhancement)\n\n**Description:**\nThe Metrics tab in the Admin UI needs to be enhanced to provide more comprehensive analytics. Currently missing virtual servers in the metrics display, and the top performers section needs to be expanded to show detailed tables with performance statistics for each entity type (tools, resources, prompts, gateways, servers).\n\n**Current State:**\n- Metrics display shows basic counts and aggregate statistics\n- Top performers section exists but shows limited information (just name and execution count)\n- Virtual servers are not included in metrics\n- No detailed performance data in the top performers section\n\n<img width=\"3024\" height=\"1709\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0acaad4a-cf32-4918-8392-1f68603a782b\" />\n\n**Requested Enhancements:**\n\n1. **Add Virtual Servers to Metrics Display**\n   - Include virtual servers alongside tools, resources, prompts, gateways\n   - Show the same metrics as other entities (executions, response times, success rates)\n\n2. **Enhanced Top 5 Tables for Each Entity Type**\n   - Replace simple lists with detailed tables\n   - Include performance statistics:\n     - Number of calls (executions)\n     - Average response time\n     - Success rate\n     - Last execution time\n   - Make tables responsive and visually appealing\n\n**Suggested Implementation:**\n\n1. **Backend Changes** (`mcpgateway/admin/metrics.py` or equivalent):\n```python\n@router.get(\"/admin/metrics\")\nasync def get_aggregated_metrics(db: Session = Depends(get_db)):\n    metrics = {\n        \"tools\": await get_tools_metrics(db),\n        \"resources\": await get_resources_metrics(db),\n        \"prompts\": await get_prompts_metrics(db),\n        \"gateways\": await get_gateways_metrics(db),\n        \"servers\": await get_servers_metrics(db),  # Virtual servers\n        \"topPerformers\": {\n            \"tools\": await get_top_tools(db, limit=5),\n            \"resources\": await get_top_resources(db, limit=5),\n            \"prompts\": await get_top_prompts(db, limit=5),\n            \"gateways\": await get_top_gateways(db, limit=5),\n            \"servers\": await get_top_servers(db, limit=5)\n        }\n    }\n    return metrics\n\nasync def get_top_tools(db: Session, limit: int = 5):\n    \"\"\"Get top performing tools with detailed metrics\"\"\"\n    return db.query(\n        Tool.name,\n        Tool.id,\n        func.count(ToolExecution.id).label('execution_count'),\n        func.avg(ToolExecution.response_time).label('avg_response_time'),\n        func.sum(case((ToolExecution.success == True, 1), else_=0)).label('successful_count'),\n        func.max(ToolExecution.created_at).label('last_execution')\n    ).join(\n        ToolExecution, Tool.id == ToolExecution.tool_id\n    ).group_by(\n        Tool.id\n    ).order_by(\n        desc('execution_count')\n    ).limit(limit).all()\n```\n\n2. **Frontend Changes** (`admin.js` - enhance the `createTopPerformersSection` function):\n```javascript\nfunction createEnhancedTopPerformersSection(topData) {\n    try {\n        const section = document.createElement('div');\n        section.className = 'bg-white rounded-lg shadow p-6 dark:bg-gray-800';\n        \n        const title = document.createElement('h3');\n        title.className = 'text-lg font-medium mb-4 dark:text-gray-200';\n        title.textContent = 'Top Performers';\n        section.appendChild(title);\n        \n        const tabsContainer = document.createElement('div');\n        tabsContainer.className = 'border-b border-gray-200 dark:border-gray-700';\n        \n        const tabList = document.createElement('nav');\n        tabList.className = '-mb-px flex space-x-8';\n        tabList.setAttribute('aria-label', 'Tabs');\n        \n        // Create tabs for each entity type\n        const entityTypes = ['tools', 'resources', 'prompts', 'gateways', 'servers'];\n        entityTypes.forEach((type, index) => {\n            if (topData[type] && Array.isArray(topData[type])) {\n                const tab = createTab(type, index === 0);\n                tabList.appendChild(tab);\n            }\n        });\n        \n        tabsContainer.appendChild(tabList);\n        section.appendChild(tabsContainer);\n        \n        // Create content panels\n        const contentContainer = document.createElement('div');\n        contentContainer.className = 'mt-4';\n        \n        entityTypes.forEach((type, index) => {\n            if (topData[type] && Array.isArray(topData[type])) {\n                const panel = createTopPerformersTable(type, topData[type], index === 0);\n                contentContainer.appendChild(panel);\n            }\n        });\n        \n        section.appendChild(contentContainer);\n        return section;\n    } catch (error) {\n        console.error('Error creating enhanced top performers section:', error);\n        return document.createElement('div');\n    }\n}\n\nfunction createTopPerformersTable(entityType, data, isActive) {\n    const panel = document.createElement('div');\n    panel.id = `top-${entityType}-panel`;\n    panel.className = `${isActive ? '' : 'hidden'}`;\n    \n    if (data.length === 0) {\n        const emptyState = document.createElement('p');\n        emptyState.className = 'text-gray-500 dark:text-gray-400 text-center py-4';\n        emptyState.textContent = `No ${entityType} data available`;\n        panel.appendChild(emptyState);\n        return panel;\n    }\n    \n    // Create responsive table wrapper\n    const tableWrapper = document.createElement('div');\n    tableWrapper.className = 'overflow-x-auto';\n    \n    const table = document.createElement('table');\n    table.className = 'min-w-full divide-y divide-gray-200 dark:divide-gray-700';\n    \n    // Table header\n    const thead = document.createElement('thead');\n    thead.className = 'bg-gray-50 dark:bg-gray-700';\n    \n    const headerRow = document.createElement('tr');\n    const headers = ['Rank', 'Name', 'Executions', 'Avg Response Time', 'Success Rate', 'Last Used'];\n    \n    headers.forEach(headerText => {\n        const th = document.createElement('th');\n        th.className = 'px-6 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-300 uppercase tracking-wider';\n        th.textContent = headerText;\n        headerRow.appendChild(th);\n    });\n    \n    thead.appendChild(headerRow);\n    table.appendChild(thead);\n    \n    // Table body\n    const tbody = document.createElement('tbody');\n    tbody.className = 'bg-white dark:bg-gray-800 divide-y divide-gray-200 dark:divide-gray-700';\n    \n    data.forEach((item, index) => {\n        const row = document.createElement('tr');\n        row.className = 'hover:bg-gray-50 dark:hover:bg-gray-700';\n        \n        // Rank\n        const rankCell = document.createElement('td');\n        rankCell.className = 'px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900 dark:text-gray-100';\n        \n        const rankBadge = document.createElement('span');\n        rankBadge.className = `inline-flex items-center justify-center w-6 h-6 rounded-full ${\n            index === 0 ? 'bg-yellow-400 text-yellow-900' :\n            index === 1 ? 'bg-gray-300 text-gray-900' :\n            index === 2 ? 'bg-orange-400 text-orange-900' :\n            'bg-gray-100 text-gray-600'\n        }`;\n        rankBadge.textContent = index + 1;\n        rankCell.appendChild(rankBadge);\n        row.appendChild(rankCell);\n        \n        // Name\n        const nameCell = document.createElement('td');\n        nameCell.className = 'px-6 py-4 whitespace-nowrap text-sm text-gray-900 dark:text-gray-100';\n        nameCell.textContent = item.name || 'Unknown';\n        row.appendChild(nameCell);\n        \n        // Executions\n        const execCell = document.createElement('td');\n        execCell.className = 'px-6 py-4 whitespace-nowrap text-sm text-gray-500 dark:text-gray-300';\n        execCell.textContent = formatNumber(item.execution_count || item.executions || 0);\n        row.appendChild(execCell);\n        \n        // Avg Response Time\n        const avgTimeCell = document.createElement('td');\n        avgTimeCell.className = 'px-6 py-4 whitespace-nowrap text-sm text-gray-500 dark:text-gray-300';\n        const avgTime = item.avg_response_time || item.avgResponseTime;\n        avgTimeCell.textContent = avgTime ? `${Math.round(avgTime)}ms` : 'N/A';\n        row.appendChild(avgTimeCell);\n        \n        // Success Rate\n        const successCell = document.createElement('td');\n        successCell.className = 'px-6 py-4 whitespace-nowrap text-sm';\n        const successRate = calculateSuccessRate(item);\n        const successBadge = document.createElement('span');\n        successBadge.className = `inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium ${\n            successRate >= 95 ? 'bg-green-100 text-green-800' :\n            successRate >= 80 ? 'bg-yellow-100 text-yellow-800' :\n            'bg-red-100 text-red-800'\n        }`;\n        successBadge.textContent = `${successRate}%`;\n        successCell.appendChild(successBadge);\n        row.appendChild(successCell);\n        \n        // Last Used\n        const lastUsedCell = document.createElement('td');\n        lastUsedCell.className = 'px-6 py-4 whitespace-nowrap text-sm text-gray-500 dark:text-gray-300';\n        lastUsedCell.textContent = formatLastUsed(item.last_execution || item.lastExecution);\n        row.appendChild(lastUsedCell);\n        \n        tbody.appendChild(row);\n    });\n    \n    table.appendChild(tbody);\n    tableWrapper.appendChild(table);\n    panel.appendChild(tableWrapper);\n    \n    return panel;\n}\n\n// Helper functions\nfunction createTab(type, isActive) {\n    const tab = document.createElement('a');\n    tab.href = '#';\n    tab.className = `${\n        isActive \n            ? 'border-indigo-500 text-indigo-600 dark:text-indigo-400' \n            : 'border-transparent text-gray-500 hover:text-gray-700 hover:border-gray-300 dark:text-gray-400 dark:hover:text-gray-300'\n    } whitespace-nowrap py-4 px-1 border-b-2 font-medium text-sm capitalize`;\n    tab.textContent = type;\n    tab.onclick = (e) => {\n        e.preventDefault();\n        showTopPerformerTab(type);\n    };\n    return tab;\n}\n\nfunction showTopPerformerTab(activeType) {\n    const entityTypes = ['tools', 'resources', 'prompts', 'gateways', 'servers'];\n    entityTypes.forEach(type => {\n        const panel = document.getElementById(`top-${type}-panel`);\n        const tab = document.querySelector(`a[onclick*=\"showTopPerformerTab('${type}')\"]`);\n        if (panel) {\n            panel.classList.toggle('hidden', type !== activeType);\n        }\n        if (tab) {\n            if (type === activeType) {\n                tab.classList.add('border-indigo-500', 'text-indigo-600', 'dark:text-indigo-400');\n                tab.classList.remove('border-transparent', 'text-gray-500');\n            } else {\n                tab.classList.remove('border-indigo-500', 'text-indigo-600', 'dark:text-indigo-400');\n                tab.classList.add('border-transparent', 'text-gray-500');\n            }\n        }\n    });\n}\n\nfunction calculateSuccessRate(item) {\n    const total = item.execution_count || item.executions || 0;\n    const successful = item.successful_count || item.successfulExecutions || 0;\n    return total > 0 ? Math.round((successful / total) * 100) : 0;\n}\n\nfunction formatNumber(num) {\n    return new Intl.NumberFormat().format(num);\n}\n\nfunction formatLastUsed(timestamp) {\n    if (!timestamp) return 'Never';\n    \n    const date = new Date(timestamp);\n    const now = new Date();\n    const diffMs = now - date;\n    const diffMins = Math.floor(diffMs / 60000);\n    \n    if (diffMins < 1) return 'Just now';\n    if (diffMins < 60) return `${diffMins} min ago`;\n    if (diffMins < 1440) return `${Math.floor(diffMins / 60)} hours ago`;\n    if (diffMins < 10080) return `${Math.floor(diffMins / 1440)} days ago`;\n    \n    return date.toLocaleDateString();\n}\n```\n\n3. **Add Virtual Servers to Metrics Cards**:\n```javascript\n// In displayMetrics function, ensure servers are included\nif (data.servers) {\n    const serversCard = createMetricsCard('Virtual Servers', data.servers);\n    metricsContainer.appendChild(serversCard);\n}\n```\n\n**Visual Design Considerations:**\n- Use consistent color coding for performance indicators\n- Make tables responsive on mobile devices\n- Add hover effects for better interactivity\n- Use loading skeletons while data is being fetched\n- Consider adding export functionality for metrics data\n\n**Testing Requirements:**\n- Verify all entity types display correctly in top performers\n- Test with various data scenarios (no data, single item, many items)\n- Ensure responsive design works on mobile devices\n- Test dark mode appearance\n- Verify performance with large datasets\n- Test tab switching functionality\n\n**Acceptance Criteria:**\n- [ ] Virtual servers appear in main metrics display\n- [ ] Top 5 tables show for all entity types (tools, resources, prompts, gateways, servers)\n- [ ] Each table displays: rank, name, executions, avg response time, success rate, last used\n- [ ] Tables are responsive and work on mobile devices\n- [ ] Tab navigation works smoothly between entity types\n- [ ] Performance badges show appropriate colors based on success rates\n- [ ] Empty states display when no data is available\n- [ ] Dark mode styling is consistent throughout\n\n**Performance Considerations:**\n- Implement pagination if lists grow beyond 5 items\n- Consider caching metrics data with appropriate TTL\n- Use database indexes on frequently queried columns\n- Batch API calls where possible\n\n**Future Enhancements:**\n- Add time range filters (last hour, day, week, month)\n- Include sparkline charts for trend visualization\n- Add drill-down functionality to see detailed metrics\n- Export metrics to CSV/PDF\n- Real-time updates using WebSocket connections\n\n**Related Issues:**\n- General metrics endpoint optimization\n- Database query performance for aggregations\n- UI performance with large datasets",
      "updatedAt" : 1752248037.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue", "triage", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hi @crivetimihai , \nI would like to take this forward. Can you please assign it to me?" ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to enhance the Metrics tab UI with virtual servers and top 5 performance tables for each entity type, providing a more comprehensive analytics experience for users.",
      "validationOrRequirement" : "The issue requires the implementation of the following features: adding virtual servers to the metrics display, enhancing the top 5 tables for each entity type, and implementing responsive design and visual effects. The acceptance criteria include verifying the appearance of virtual servers in the main metrics display, the display of top 5 tables for all entity types, and the responsiveness of the tables on mobile devices.",
      "attemptedFixes" : "The issue includes suggested implementation details for backend and frontend changes, as well as visual design considerations, testing requirements, acceptance criteria, performance considerations, and future enhancements.",
      "otherNotes" : "The issue aims to enhance the Metrics tab UI with virtual servers and top 5 performance tables for each entity type, including tools, resources, prompts, gateways, and servers. The requested enhancements include adding virtual servers to the metrics display, enhancing the top 5 tables for each entity type, and implementing responsive design and visual effects.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283633
  }, {
    "issueDTO" : {
      "id" : 3217535820,
      "title" : "Remove no-throw-error ESLint suppressions in @liam-hq/agent",
      "url" : "https://github.com/liam-hq/liam/issues/2459",
      "repositoryName" : "liam-hq/liam",
      "description" : "## Summary\n\nThis issue tracks the removal of ESLint suppressions for the `no-throw-error/no-throw-error` rule in the `@liam-hq/agent` package.\n\n## Context\n\nPR #2442 introduced a custom ESLint rule that prohibits `throw new Error()` statements and encourages the use of neverthrow Result types instead. To enable incremental adoption, bulk suppressions were applied to existing violations.\n\n## Task\n\nReplace all `throw new Error()` statements in the `frontend/internal-packages/agent/` directory with neverthrow Result types (`err`, `ok`, `ResultAsync`) imported from \"neverthrow\".\n\n## Files to update\n\n- `frontend/internal-packages/agent/eslint-suppressions.json` - Contains 14 suppressed violations\n\n## Steps\n\n1. Review the suppressed violations in `frontend/internal-packages/agent/eslint-suppressions.json`\n2. Replace `throw new Error()` statements with appropriate neverthrow Result types\n3. Import neverthrow types: `import { err, ok, ResultAsync } from \"neverthrow\"`\n4. Update function return types to use `Result<T, E>` or `ResultAsync<T, E>`\n5. Update calling code to handle Result types appropriately\n6. Run `pnpm lint:eslint --prune-suppressions` to update eslint-suppressions.json after modifications\n7. Verify all suppressions are resolved\n\n## Related\n\n- Resolves: #2442",
      "updatedAt" : 1752247788.000000000,
      "user" : "claude[bot]",
      "userHtmlUrl" : "https://github.com/apps/claude",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/1236702?v=4",
      "labels" : [ "neverthrow", "eslint", "tech debt", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Automatically generates beautiful and easy-to-read ER diagrams from your database.",
        "homepage" : "https://liambx.com",
        "name" : "liam",
        "fullName" : "liam-hq/liam",
        "htmlUrl" : "https://github.com/liam-hq/liam",
        "gitUrl" : "git://github.com/liam-hq/liam.git",
        "sshUrl" : "git@github.com:liam-hq/liam.git",
        "cloneUrl" : "https://github.com/liam-hq/liam.git",
        "owner" : {
          "login" : "liam-hq",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 4149,
        "watchersCount" : 4149,
        "size" : 128286,
        "openIssuesCount" : 86,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-12T00:59:43Z",
        "languages" : {
          "TypeScript" : 1870996,
          "MDX" : 82980,
          "CSS" : 229518,
          "Shell" : 5433,
          "PLpgSQL" : 360220,
          "Handlebars" : 695,
          "JavaScript" : 42995,
          "HTML" : 985,
          "Ruby" : 7830
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove no-throw-error ESLint suppressions in @liam-hq/agent package",
      "validationOrRequirement" : "replace all throw new Error() statements in the frontend/internal-packages/agent/ directory with neverthrow Result types (err, ok, ResultAsync) imported from 'neverthrow'",
      "attemptedFixes" : "none mentioned in the description",
      "otherNotes" : "PR #2442 introduced a custom ESLint rule, bulk suppressions were applied to existing violations, and 14 suppressed violations need to be reviewed",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283636
  }, {
    "issueDTO" : {
      "id" : 3150637067,
      "title" : "[BUG] - recipe with name '---' can't be edit",
      "url" : "https://github.com/mealie-recipes/mealie/issues/5532",
      "repositoryName" : "mealie-recipes/mealie",
      "description" : "### First Check\n\n- [x] This is not a feature request.\n- [x] I added a very descriptive title to this issue (title field is above this).\n- [x] I used the GitHub search to find a similar issue and didn't find it.\n- [x] I searched the Mealie documentation, with the integrated search.\n- [x] I already read the docs and didn't find an answer.\n- [x] This issue can be replicated on the demo site (https://demo.mealie.io/).\n\n### What is the issue you are experiencing?\n\nhello \nfor a test i have created a recipe with name ---.\nThe recipe is available/visible in the recipes page but i can't access to it. So impossible to delete or update it. I delete it manuelly with sqlite client.\n\n\n### Steps to Reproduce\n\n1- create a recipe\n2- in the name type ---\n3- save the recipe\n4-a 404 page is displayed\n5-in the recipe page you can't do anything with --- recipe\n\n### Please provide relevant logs\n\nn/a\n\n### Mealie Version\n\n2.6.0\n\n### Deployment\n\nDocker (Linux)\n\n### Additional Deployment Details\n\n_No response_",
      "updatedAt" : 1752247660.000000000,
      "user" : "sragons",
      "userHtmlUrl" : "https://github.com/sragons",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12803741?v=4",
      "labels" : [ "bug", "bug: confirmed", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I was looking for a good first issue to start adding to this repo, I'll give it a go", "> I was looking for a good first issue to start adding to this repo, I'll give it a go\n\nI also want to help, maybe we can work together in this issue" ],
      "repository" : {
        "description" : "Mealie is a self hosted recipe manager and meal planner with a RestAPI backend and a reactive frontend application built in Vue for a pleasant user experience for the whole family. Easily add recipes into your database by providing the url and mealie will automatically import the relevant data or add a family recipe with the UI editor",
        "homepage" : "https://docs.mealie.io",
        "name" : "mealie",
        "fullName" : "mealie-recipes/mealie",
        "htmlUrl" : "https://github.com/mealie-recipes/mealie",
        "gitUrl" : "git://github.com/mealie-recipes/mealie.git",
        "sshUrl" : "git@github.com:mealie-recipes/mealie.git",
        "cloneUrl" : "https://github.com/mealie-recipes/mealie.git",
        "owner" : {
          "login" : "mealie-recipes",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 910,
        "stargazersCount" : 9517,
        "watchersCount" : 9517,
        "size" : 413662,
        "openIssuesCount" : 123,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-12T00:49:27Z",
        "languages" : {
          "TypeScript" : 303353,
          "Dockerfile" : 6585,
          "Shell" : 1768,
          "Jinja" : 543,
          "SCSS" : 231,
          "Vue" : 956732,
          "JavaScript" : 3071,
          "Mako" : 603,
          "Python" : 1916868
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about a bug where a recipe with name '--' cannot be edited or deleted",
      "validationOrRequirement" : "The recipe name should not be empty or contain special characters",
      "attemptedFixes" : "n/a",
      "otherNotes" : "The issue is specific to a recipe with name '--' which can't be edited or deleted, and the user had to manually delete it using a SQLite client.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283639
  }, {
    "issueDTO" : {
      "id" : 3174835856,
      "title" : "CLIENT INFO redis-py broken",
      "url" : "https://github.com/apache/kvrocks/issues/3038",
      "repositoryName" : "apache/kvrocks",
      "description" : "### Search before asking\n\n- [x] I had searched in the [issues](https://github.com/apache/kvrocks/issues) and found no similar issues.\n\n\n### Motivation\n\nref: \nhttps://github.com/redis/redis-py/blob/0d0cfe66eaa541dfc078398f37277e5de8d11dc8/redis/_parsers/helpers.py#L662-L679\n\n kvrocks return the following content:\n```\n{'id': '14620', 'addr': '172.17.0.1:58222', 'fd': '51', 'name': '', 'age': '0', 'idle': '0', 'flags': 'N', 'namespace': 'ns1', 'qbuf': '0', 'obuf': '0', 'cmd': 'client'} \n```\nredis:latest return the following content:\n```\n{'id': '18', 'addr': '172.17.0.1:46410', 'laddr': '172.17.0.3:6379', 'fd': '22', 'name': '', 'age': '0', 'idle': '0', 'flags': 'N', 'db': '0', 'sub': '0', 'psub': '0', 'ssub': '0', 'multi': '-1', 'watch': '0', 'qbuf': '26', 'qbuf-free': '20448', 'argv-mem': '10', 'multi-mem': '0', 'rbs': '16384', 'rbp': '16384', 'obl': '0', 'oll': '0', 'omem': '0', 'tot-mem': '37786', 'events': 'r', 'cmd': 'client|info', 'user': 'default', 'redir': '-1', 'resp': '2', 'lib-name': 'redis-py', 'lib-ver': '6.2.0', 'io-thread': '0'} \n```\n\n```\nFile \"/home/user/src/bloomfilter/pss-tools/.venv/lib/python3.13/site-packages/redis/_parsers/helpers.py\", line 679, in parse_client_info \n    client_info[int_key] = int(client_info[int_key]) \n\nKeyError: 'sub'\n```\n\nIf I'm understanding this correctly, the python library expects more key values, which should be delivered. \nref: https://github.com/redis/redis/blob/080b99d9827eac9e8a6639922d64b8a8cc5c930c/src/networking.c#L2824C1-L2824C265\n\n### Solution\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
      "updatedAt" : 1752247416.000000000,
      "user" : "be-a-panther",
      "userHtmlUrl" : "https://github.com/be-a-panther",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/174496845?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@be-a-panther This issue should be resolved after PR https://github.com/redis/redis-py/pull/3688. cc @PragmaTwice " ],
      "repository" : {
        "description" : "Apache Kvrocks is a distributed key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.",
        "homepage" : "https://kvrocks.apache.org/",
        "name" : "kvrocks",
        "fullName" : "apache/kvrocks",
        "htmlUrl" : "https://github.com/apache/kvrocks",
        "gitUrl" : "git://github.com/apache/kvrocks.git",
        "sshUrl" : "git@github.com:apache/kvrocks.git",
        "cloneUrl" : "https://github.com/apache/kvrocks.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 540,
        "stargazersCount" : 3929,
        "watchersCount" : 3929,
        "size" : 12292,
        "openIssuesCount" : 170,
        "subscribersCount" : 76,
        "pushedAt" : "2025-07-11T09:54:46Z",
        "languages" : {
          "Dockerfile" : 2744,
          "C++" : 2817762,
          "Shell" : 5189,
          "C" : 975,
          "CMake" : 51301,
          "Go" : 1266929,
          "Lua" : 3128,
          "Python" : 29665
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The CLIENT INFO redis-py broken issue is related to the redis-py library and the expected key values in the client info response.",
      "validationOrRequirement" : "The python library is expecting more key values in the client info response, which are not being delivered.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to the redis-py library and the expected key values in the client info response. The python library is expecting more key values which are not being delivered. The issue is linked to a PR https://github.com/redis/redis-py/pull/3688.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283644
  }, {
    "issueDTO" : {
      "id" : 3207075330,
      "title" : "Dialog \"Add file link\" should focus field \"Link\" when opening",
      "url" : "https://github.com/JabRef/jabref/issues/13486",
      "repositoryName" : "JabRef/jabref",
      "description" : "When the \"Add file link\" dialog is opened, the text field labeled \"Link\" should be focused automatically. This improves usability by allowing immediate typing without requiring a mouse click.\n\n**Steps to reproduce**\n\n1. Open JabRef\n2. Create a new library: *File ??? New library*\n3. Click the **+** button in the toolbar to add a new entry\n4. In the entry editor, select the **General** tab\n5. In the **File** section, click the **+** button\n6. The \"Add file link\" dialog appears ??? the \"Link\" field is **not focused**\n\n<img width=\"566\" height=\"274\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/12130c8f-fa61-4950-be7c-4c232e5caac6\" />\n\n**Expected behavior**\n\nThe cursor should automatically be placed in the \"Link\" field when the dialog opens.\n\n**Good first issue**\n\nThis is a simple UI improvement. Relevant code is in `org.jabref.gui.linkedfile.LinkedFileEditDialog`.\n",
      "updatedAt" : 1752247232.000000000,
      "user" : "koppor",
      "userHtmlUrl" : "https://github.com/koppor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1366654?v=4",
      "labels" : [ "\uD83D\uDCCC Pinned", "good first issue", "\uD83D\uDCCD Assigned", "component: ui" ],
      "state" : "OPEN",
      "comments" : [ "/assign-me", "\uD83D\uDC4B Hey @ankamde, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80" ],
      "repository" : {
        "description" : "Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases",
        "homepage" : "https://www.jabref.org",
        "name" : "jabref",
        "fullName" : "JabRef/jabref",
        "htmlUrl" : "https://github.com/JabRef/jabref",
        "gitUrl" : "git://github.com/JabRef/jabref.git",
        "sshUrl" : "git@github.com:JabRef/jabref.git",
        "cloneUrl" : "https://github.com/JabRef/jabref.git",
        "owner" : {
          "login" : "JabRef",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2861,
        "stargazersCount" : 3942,
        "watchersCount" : 3942,
        "size" : 249107,
        "openIssuesCount" : 582,
        "subscribersCount" : 113,
        "pushedAt" : "2025-07-11T22:29:41Z",
        "languages" : {
          "PowerShell" : 2037,
          "Java" : 11216891,
          "CSS" : 74176,
          "TeX" : 758587,
          "AppleScript" : 1721,
          "XSLT" : 151843,
          "Just" : 1194,
          "Shell" : 9305,
          "Batchfile" : 637,
          "ANTLR" : 9176,
          "BibTeX Style" : 78034,
          "Ruby" : 507,
          "Python" : 22282
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The 'Add file link' dialog should focus the 'Link' field when opened, improving usability by allowing immediate typing without requiring a mouse click.",
      "validationOrRequirement" : "The 'Link' field should be focused automatically when the 'Add file link' dialog opens.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description.",
      "otherNotes" : "Contributing guidelines are available at https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md, and workspace setup guidelines are available at https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace. For questions, consult the JabRef Guru or ask on the Gitter chat. In case of failing tests, check the developer FAQs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283649
  }, {
    "issueDTO" : {
      "id" : 3222975526,
      "title" : "Add flow cytometry data from FlowRepository",
      "url" : "https://github.com/snap-stanford/Biomni/issues/31",
      "repositoryName" : "snap-stanford/Biomni",
      "description" : "Using either FlowRepository API or R package FlowRepositoryR to download the raw data. I am glad to work with your team on this task. ",
      "updatedAt" : 1752247101.000000000,
      "user" : "ClaireChai929",
      "userHtmlUrl" : "https://github.com/ClaireChai929",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/40038548?v=4",
      "labels" : [ "new-dataset", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Biomni: a general-purpose biomedical AI agent",
        "homepage" : "https://biomni.stanford.edu",
        "name" : "Biomni",
        "fullName" : "snap-stanford/Biomni",
        "htmlUrl" : "https://github.com/snap-stanford/Biomni",
        "gitUrl" : "git://github.com/snap-stanford/Biomni.git",
        "sshUrl" : "git@github.com:snap-stanford/Biomni.git",
        "cloneUrl" : "https://github.com/snap-stanford/Biomni.git",
        "owner" : {
          "login" : "snap-stanford",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 137,
        "stargazersCount" : 1317,
        "watchersCount" : 1317,
        "size" : 737,
        "openIssuesCount" : 10,
        "subscribersCount" : 29,
        "pushedAt" : "2025-07-10T16:01:12Z",
        "languages" : {
          "Shell" : 44508,
          "R" : 4226,
          "Jupyter Notebook" : 332049,
          "Python" : 1371378
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add flow cytometry data from FlowRepository",
      "validationOrRequirement" : "Using either FlowRepository API or R package FlowRepositoryR to download the raw data.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description.",
      "otherNotes" : "The issue involves downloading raw flow cytometry data from FlowRepository using either the API or R package FlowRepositoryR.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283652
  }, {
    "issueDTO" : {
      "id" : 3151985026,
      "title" : "Evaluate openevolve on ALE Bench",
      "url" : "https://github.com/codelion/openevolve/issues/78",
      "repositoryName" : "codelion/openevolve",
      "description" : "https://sakana.ai/ale-bench/ ",
      "updatedAt" : 1752247086.000000000,
      "user" : "codelion",
      "userHtmlUrl" : "https://github.com/codelion",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/603317?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! Thank you for your interest in our ALE-Bench!\nAlthough I'm not familiar with OpenEvolve, but I can run one ALE-Bench problem (ahc046) with the files below. I can't work on this integration, but I'm commenting here to support your contribution :)\nThis example is not sophisticated, so please don't persist with this temporary solution!!!\n\n### Environment\nC6i EC2 Instance (Ubuntu)\nI used uv to create the OpenEvolve environment and then I add ale-bench\n```sh\ngit clone https://github.com/codelion/openevolve.git\ncd openevolve\nuv sync\nuv add https://github.com/SakanaAI/ALE-Bench.git\n```\n\n### Files\n- examples/ale_bench/config.yml\n```yml\n# Configuration for function minimization example\nmax_iterations: 5\ncheckpoint_interval: 1\nlog_level: \"INFO\"\n\n# LLM configuration\nllm:\n  primary_model: \"o4-mini-2025-04-16\"\n  primary_model_weight: 0.8\n  secondary_model: \"gpt-4.1-mini-2025-04-14\"\n  secondary_model_weight: 0.2\n  temperature: 1.0\n  top_p: 1.0\n  max_tokens: 32768\n  timeout: 300\n\n# Prompt configuration\nprompt:\n  system_message: |\n    You are a world-class algorithm engineer, and you are very good at programming. Now, you are participating in a programming contest. You are asked to solve a heuristic problem, known as an NP-hard problem.\n\n    [Problem statement]\n    Execution time limit: 2.0 sec / Memory limit: 1024 MB\n\n    Problem Statement\n    ...(problem statement from ahc046 here)...\n  num_top_programs: 1\n  num_diverse_programs: 2\n  use_template_stochasticity: false\n\n# Database configuration\ndatabase:\n  db_path: /path/to/openevolve/examples/ale_bench/database\n  in_memory: false\n  population_size: 25\n  archive_size: 25\n  num_islands: 5\n  migration_interval: 2\n  migration_rate: 0.2\n  elite_selection_ratio: 0.1\n  exploration_ratio: 0.3\n  exploitation_ratio: 0.6\n  feature_dimensions:\n    - \"score\"\n    - \"complexity\"\n  feature_bins: 10\n\n# Evaluator configuration\nevaluator:\n  timeout: 300\n  cascade_evaluation: false\n  parallel_evaluations: 1\n  use_llm_feedback: false\n\n# Evolution settings\ndiff_based_evolution: true\nallow_full_rewrites: false\n```\n\n- examples/ale_bench/evaluator.py\n```python\nimport traceback\nfrom pathlib import Path\n\nimport ale_bench\nfrom ale_bench.result import CaseResult, JudgeResult, Result\n\n\nroot_dir = Path(__file__).resolve().parent\nsession_file = root_dir / \"session.json\"\n\n\ndef result_feedback(result: Result) -> CaseResult:\n    if result.overall_judge_result == JudgeResult.ACCEPTED:\n        return result.case_results[0]\n    else:\n        selected_case_idx = 0\n        for idx, case_result in enumerate(result.case_results):\n            if case_result.judge_result == result.overall_judge_result:\n                selected_case_idx = idx\n                break\n        return result.case_results[selected_case_idx]\n\n\ndef evaluate(program_path):\n    try:\n        session = None\n        if not session_file.exists():\n            session = ale_bench.start(\n                problem_id=\"ahc046\",\n                num_workers=13,\n            )\n        else:\n            session = ale_bench.restart(session_saved_file=session_file, num_workers=13)\n        if not session:\n            raise RuntimeError(\"Failed to start or restart the session.\")\n\n        code = Path(program_path).read_text().replace(\"# EVOLVE-BLOCK-START\", \"\").replace(\"# EVOLVE-BLOCK-END\", \"\").strip()\n        public_result = session.public_eval(code=code, code_language=\"cpp23\")\n        extracted_case = result_feedback(public_result)\n        session.save(session_file)\n\n        return {\n            \"judge_result\": public_result.overall_judge_result.value,\n            \"overall_score\": public_result.overall_absolute_score,\n            \"max_execution_time_sec\": max([case_result.execution_time for case_result in public_result.case_results]),\n            \"max_memory_usage_mib\": max([case_result.memory_usage for case_result in public_result.case_results]) // 1024 // 1024,\n            \"standard_error\": extracted_case.error_str,\n            \"message\": extracted_case.message,\n        }\n    except Exception as e:\n        print(f\"Evaluation failed completely: {str(e)}\")\n        print(traceback.format_exc())\n        return {\n            \"overall_score\": 0.0,\n            \"error\": str(e),\n        }\n```\n\n- initial_program.cpp\n```cpp\n# EVOLVE-BLOCK-START\n#include <bits/stdc++.h>\n#include <atcoder/all>\nusing namespace std;\nusing namespace atcoder;\n\nint main() {\n    return 0;\n}\n# EVOLVE-BLOCK-END\n```\n\n### Run\n```sh\nOPENAI_API_KEY=\"sk-...\" .venv/bin/python openevolve-run.py examples/ale_bench/initial_program.cpp examples/ale_bench/evaluator.py --config examples/ale_bench/config.yaml\n```\n\n### Result\n- examples/ale_bench/openevolve_output/best/best_program.cpp\n\nI think this solution is a very simple greedy one.\n\n```cpp\n# EVOLVE-BLOCK-START\n#include <bits/stdc++.h>\n#include <atcoder/all>\nusing namespace std;\nusing namespace atcoder;\n\nint main() {\n    ios::sync_with_stdio(false);\n    cin.tie(nullptr);\n\n    int N, M;\n    cin >> N >> M;\n    vector<pair<int,int>> pts(M);\n    for (int i = 0; i < M; ++i) {\n        cin >> pts[i].first >> pts[i].second;\n    }\n\n    ...(omit)...\n\n    // Output all moves\n    for (auto &p : ans) {\n        cout << p.first << ' ' << p.second << \"\\n\";\n    }\n    return 0;\n}\n# EVOLVE-BLOCK-END\n```\n\n- examples/ale_bench/openevolve_output/best/best_program_info.json\n```json\n{\n  \"id\": \"c5d424dc-c68f-41b2-a866-805ea3ec7140\",\n  \"generation\": 2,\n  \"iteration\": 2,\n  \"timestamp\": 1750158033.155996,\n  \"parent_id\": \"6de7381d-38c3-4a03-a7d8-cc0d20a5abf6\",\n  \"metrics\": {\n    \"judge_result\": \"ACCEPTED\",\n    \"overall_score\": 67982,\n    \"max_execution_time_sec\": 0.0,\n    \"max_memory_usage_mib\": 3,\n    \"standard_error\": \"\",\n    \"message\": \"\"\n  },\n  \"language\": \"cpp\",\n  \"saved_at\": 1750158208.9139886\n}\n```", "Thanks for providing this, I think this is a great start for implementing the full harness for ALE-Bench,", "What other benchmarks could be included for OpenEvolve? MLE-Bench? RE-Bench? Anything SWE related?", "> What other benchmarks could be included for OpenEvolve? MLE-Bench? RE-Bench? Anything SWE related?\n\nAs a former competitive programmer, personally I'm very much interested in the (harder) problems in LiveCodeBenchPro https://livecodebenchpro.com/ It should be not hard to integrate.", "Thanks @BradKML for posting AlgoTune to this thread :) " ],
      "repository" : {
        "description" : "Open-source implementation of AlphaEvolve",
        "homepage" : "",
        "name" : "openevolve",
        "fullName" : "codelion/openevolve",
        "htmlUrl" : "https://github.com/codelion/openevolve",
        "gitUrl" : "git://github.com/codelion/openevolve.git",
        "sshUrl" : "git@github.com:codelion/openevolve.git",
        "cloneUrl" : "https://github.com/codelion/openevolve.git",
        "owner" : {
          "login" : "codelion",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 414,
        "stargazersCount" : 3174,
        "watchersCount" : 3174,
        "size" : 3598,
        "openIssuesCount" : 28,
        "subscribersCount" : 36,
        "pushedAt" : "2025-07-11T03:17:24Z",
        "languages" : {
          "Dockerfile" : 580,
          "CSS" : 21475,
          "Makefile" : 1656,
          "JavaScript" : 99514,
          "HTML" : 5681,
          "Python" : 321688
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Evaluate OpenEvolve on ALE-Bench, with a specific example of ahc046, and explore other potential benchmarks for OpenEvolve.",
      "validationOrRequirement" : "The contributor is looking for suggestions on other benchmarks that could be included for OpenEvolve, and is interested in integrating LiveCodeBenchPro with OpenEvolve.",
      "attemptedFixes" : "The contributor has tried running one ALE-Bench problem (ahc046) with OpenEvolve, but notes that the solution is not sophisticated and should not be persisted.",
      "otherNotes" : "The issue is about evaluating OpenEvolve on ALE-Bench, with a specific example of ahc046. The contributor is asking for suggestions on other benchmarks that could be included for OpenEvolve, such as MLE-Bench, RE-Bench, and SWE-related benchmarks. They also mention their interest in harder problems in LiveCodeBenchPro.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283659
  }, {
    "issueDTO" : {
      "id" : 3223265833,
      "title" : "Max thinking tokens can be set to a value that's too large",
      "url" : "https://github.com/Kilo-Org/kilocode/issues/1257",
      "repositoryName" : "Kilo-Org/kilocode",
      "description" : "### Description\n\nhttps://discord.com/channels/1349288496988160052/1393171027143561318",
      "updatedAt" : 1752246909.000000000,
      "user" : "chrarnoldus",
      "userHtmlUrl" : "https://github.com/chrarnoldus",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12196001?v=4",
      "labels" : [ "user-interface", "community-sourced", "kilocode-api-provider", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Open Source AI coding assistant for planning, building, and fixing code. We're a superset of Roo, Cline, and our own features. Follow us: kilocode.ai/social",
        "homepage" : "https://marketplace.visualstudio.com/items?itemName=kilocode.Kilo-Code",
        "name" : "kilocode",
        "fullName" : "Kilo-Org/kilocode",
        "htmlUrl" : "https://github.com/Kilo-Org/kilocode",
        "gitUrl" : "git://github.com/Kilo-Org/kilocode.git",
        "sshUrl" : "git@github.com:Kilo-Org/kilocode.git",
        "cloneUrl" : "https://github.com/Kilo-Org/kilocode.git",
        "owner" : {
          "login" : "Kilo-Org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 338,
        "stargazersCount" : 4259,
        "watchersCount" : 4259,
        "size" : 95476,
        "openIssuesCount" : 127,
        "subscribersCount" : 28,
        "pushedAt" : "2025-07-12T00:47:36Z",
        "languages" : {
          "TypeScript" : 6688813,
          "MDX" : 178,
          "CSS" : 80164,
          "Shell" : 23050,
          "JavaScript" : 52028,
          "Go" : 166,
          "PHP" : 633,
          "HTML" : 283,
          "Nix" : 599,
          "Python" : 1658
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to set a limit for the max thinking tokens.",
      "validationOrRequirement" : "The max thinking tokens can be set to a value that's too large.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned.",
      "otherNotes" : "The issue is related to a Discord channel.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283661
  }, {
    "issueDTO" : {
      "id" : 3140336360,
      "title" : "Tag is not removed",
      "url" : "https://github.com/apache/superset/issues/33758",
      "repositoryName" : "apache/superset",
      "description" : "### Bug description\n\nA user can add a tag but the remove is KO if it'is done in the element : \n- Remove a tag is OK if it'is done directly with \"Edit\" button from elements list (see at 30'' or 1'05'' in the video)\n- Remove a tag is KO if it'is done in the edition mode of an element with \"Edit properties\" button (see at 47'' in the video)\n\n### Screenshots/recordings\n\nhttps://github.com/user-attachments/assets/7afd3aa2-ae33-4f4d-9be3-5d696dd37195\n\n### Superset version\n\n5.0.0-RC2\n\n### Python version\n\n3.9\n\n### Node version\n\n16\n\n### Browser\n\nChrome\n\n### Additional context\n\n_No response_\n\n### Checklist\n\n- [ ] I have searched Superset docs and Slack and didn't find a solution to my problem.\n- [ ] I have searched the GitHub issue tracker and didn't find a similar bug report.\n- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the \"additional context\" section.",
      "updatedAt" : 1752246434.000000000,
      "user" : "xavier-GitHub76",
      "userHtmlUrl" : "https://github.com/xavier-GitHub76",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82046143?v=4",
      "labels" : [ "cares:preset", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "maybe u are missing some tag like handleClearTags   .  research it ", "Awaiting comments/feedback on the linked PR. Anyone is welcome to test there. " ],
      "repository" : {
        "description" : "Apache Superset is a Data Visualization and Data Exploration Platform",
        "homepage" : "https://superset.apache.org/",
        "name" : "superset",
        "fullName" : "apache/superset",
        "htmlUrl" : "https://github.com/apache/superset",
        "gitUrl" : "git://github.com/apache/superset.git",
        "sshUrl" : "git@github.com:apache/superset.git",
        "cloneUrl" : "https://github.com/apache/superset.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15298,
        "stargazersCount" : 67064,
        "watchersCount" : 67064,
        "size" : 756073,
        "openIssuesCount" : 803,
        "subscribersCount" : 1530,
        "pushedAt" : "2025-07-12T00:34:00Z",
        "languages" : {
          "Smarty" : 5044,
          "Jinja" : 5847,
          "CSS" : 4781,
          "Pug" : 2969,
          "Makefile" : 4133,
          "HTML" : 1278006,
          "Jupyter Notebook" : 10916999,
          "TypeScript" : 11362202,
          "Dockerfile" : 12025,
          "Shell" : 65877,
          "JavaScript" : 1839895,
          "Mako" : 1197,
          "Python" : 8964539
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Tag is not removed when removed in 'Edit properties' button.",
      "validationOrRequirement" : "Tag should be removed in both 'Edit' button from elements list and 'Edit properties' button.",
      "attemptedFixes" : "No attempted fixes mentioned.",
      "otherNotes" : "Additional context: _No response_. Checklist: [I have searched Superset docs and Slack and didn't find a solution to my problem.], [I have searched the GitHub issue tracker and didn't find a similar bug report.], [I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the 'additional context' section.].",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283666
  }, {
    "issueDTO" : {
      "id" : 3063054651,
      "title" : "Update references to DID Specification Registries throughout",
      "url" : "https://github.com/w3c/did-resolution/issues/148",
      "repositoryName" : "w3c/did-resolution",
      "description" : "We need to do an editorial pass to update DID Specification Registries to the appropriate extensions list. Most commonly I think this would be the DID Resolution Extensions.\n\nI think it is better to individually reference each of the extensions, e.g. https://www.w3.org/TR/did-extensions-resolution/.\n\nRather than pointing to the overall extensions document - https://w3c.github.io/did-extensions.\n\nOne thing I am unsure about is how the reference [[?DID-SPEC-REGISTRIES]] is defined/generated. Couldn't find it in the respecConfig, so is it being pulled from some other document? cc @msporny \n\n",
      "updatedAt" : 1752246431.000000000,
      "user" : "wip-abramson",
      "userHtmlUrl" : "https://github.com/wip-abramson",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18055112?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "RELEASED DRAFT: Decentralized Identifier Resolution (DID Resolution) 0.2 Specification",
        "homepage" : "https://w3c.github.io/did-resolution/",
        "name" : "did-resolution",
        "fullName" : "w3c/did-resolution",
        "htmlUrl" : "https://github.com/w3c/did-resolution",
        "gitUrl" : "git://github.com/w3c/did-resolution.git",
        "sshUrl" : "git@github.com:w3c/did-resolution.git",
        "cloneUrl" : "https://github.com/w3c/did-resolution.git",
        "owner" : {
          "login" : "w3c",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15,
        "stargazersCount" : 21,
        "watchersCount" : 21,
        "size" : 3298,
        "openIssuesCount" : 41,
        "subscribersCount" : 45,
        "pushedAt" : "2025-07-10T20:12:03Z",
        "languages" : {
          "JavaScript" : 16882,
          "HTML" : 827411
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update references to DID Specification Registries throughout to use individual references to each extension.",
      "validationOrRequirement" : "Individual references to each extension should be used, e.g. https://www.w3.org/TR/did-extensions-resolution/, instead of pointing to the overall extensions document - https://w3c.github.io/did-extensions.",
      "attemptedFixes" : "The author is unsure about how the reference [[?DID-SPEC-REGISTRIES]] is defined/generated.",
      "otherNotes" : "The issue is about updating references to DID Specification Registries to the appropriate extensions list, specifically DID Resolution Extensions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283670
  }, {
    "issueDTO" : {
      "id" : 2965439067,
      "title" : "Publish SNAPSHOT Images for Stable Branches",
      "url" : "https://github.com/camunda/camunda/issues/30477",
      "repositoryName" : "camunda/camunda",
      "description" : "## Description  \n\nCurrently, we do not publish SNAPSHOT images for our stable branches. Having these available would allow QA to run nightly cross-component tests against the stable heads. In the future, this would also enable running new E2E smoke tests, reducing friction due to integration testing at release time and potentially cutting down on most of the manual testing required during a release.  \n\nThe `stable/8.7` branch already has a SNAPSHOT image due to the new dual 8.7 and 8.8 release strategy, but this was implemented as a one-off and uses the discouraged `8.7.0-SNAPSHOT` naming. This ticket aims to extend that approach to all stable branches, ensuring that every supported version has a corresponding SNAPSHOT image available for testing.\n\n## Expected Outcome  \n\n- Each stable branch (e.g., `stable/8.6`, `stable/8.7`, etc.) has a corresponding `X.Y-SNAPSHOT` image published for each component present on that branch:\n    - 8.5 and older only have Zeebe component\n- Images follow a predictable naming convention (e.g., `8.6-SNAPSHOT`, `8.7-SNAPSHOT`).  \n- The images [are documented](https://github.com/camunda/camunda/wiki/CI-&-Automation#available-snapshot-artifacts) for reference.  \n- The CI pipeline builds and publishes these images automatically.  \n- The approach is sustainable for future versions (align the existing implementation of `stable/8.7` branch with how it's done on all other branches).\n\n## Open Questions\n\n- What were the previous blockers to implementing this for all stable branches?\n- Are there any concerns regarding support for these images?\n- Should each product team handle their own SNAPSHOT builds, or should Infra own this process?\n\n## Related Discussions\n\n- [Slack conversation from March 19???25, 2025](https://camunda.slack.com/archives/C071KP5BTHB/p1742395590166449) (internal discussion on why we need stable SNAPSHOT images and how they would benefit QA).  \n- Reference implementation for `stable/8.7` ([GitHub Issue #27193](https://github.com/camunda/camunda/issues/27193)).  \n\n## Next Steps\n\n1. Confirm the technical feasibility of extending the current `8.7-SNAPSHOT` implementation to all stable branches.\n2. Align on ownership (Monorepo Devops team vs. product teams).  \n3. Update the CI configuration to generate and publish the images.  \n4. Document the availability and usage of these images.  \n",
      "updatedAt" : 1752246378.000000000,
      "user" : "slolatte",
      "userHtmlUrl" : "https://github.com/slolatte",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/132344616?v=4",
      "labels" : [ "component/build-pipeline", "area/build", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@cmur2 just confirming that this will be implemented for all stable branches? And do you have a timeline of when this could be implemented by?", "> just confirming that this will be implemented for all stable branches?\n\nI wouldn't see why not since the ticket description (which I agree with) states that explicitly:\n\n> Expected Outcome\n>\n> * Each stable branch (e.g., stable/8.6, stable/8.7, etc.) has a corresponding X.Y-SNAPSHOT image published.\n\n> And do you have a timeline of when this could be implemented by?\n\nNo, not yet, sorry. I acknowledge that this ticket is quite important but as visible on [this board](https://github.com/orgs/camunda/projects/115/views/1) there are other important topics that we need to do and can't keep pushing. I will see if I might have capacity in my personal backlog or if there is another team with capacity that can help out.", "Thanks for the confirmation, that makes sense! Totally understand that there are competing priorities at the moment. If it helps, I'm happy to assist with any context or input needed to keep things moving, especially since this would have a big impact on testing and release processes. ", "Hi @liliancavalet , thanks for taking this on!\n\nJust checking in to see if there???s an estimated timeline or update on the implementation now that the issue has been assigned.\nLet me know if there???s anything I can do to help move it forward.\n\nThanks!", "Hi @slolatte!\nSorry for the delayed reply. As we discussed today, this task will be the next one I???ll pick up. I???ll reach out to you soon to gather more information once I have some time to focus on it.", "Hi @slolatte! \n\nBefore I move forward with the implementation, I???d like to confirm my understanding of the goals and surface a few clarifying questions to ensure we???re aligned on scope, naming, and process.\n\n## Understanding of the Goal\n\nThe core objective is to publish Docker images tagged as `X.Y-SNAPSHOT` (e.g., 8.7-SNAPSHOT, 8.6-SNAPSHOT) for each supported stable branch in the monorepo, so they can be consumed by:\n\n- QA's nightly cross-component testing\n- Future E2E smoke tests during the release cycle\n\nThere???s already a one-off implementation for stable/8.7 that publishes a `8.7.0-SNAPSHOT` image, and I understand this:\n\n- Includes Git commit metadata in the image (e.g., via git.properties or /actuator/info)\n- Need to be improved by removing the patch-level naming (X.Y.Z-SNAPSHOT), which we now want to avoid\n\n## Plan Going Forward\n\n- [x] Replace X.Y.Z-SNAPSHOT docker tag with a standardized branch-level X.Y-SNAPSHOT tag\n- [ ] Ensure images are published on every merge to a stable branch (TBD)\n- [x] Maintain commit metadata in the image for traceability\n\n## Questions / Clarifications\n\n1. Just confirming that `X.Y-SNAPSHOT` is solely a Docker image tag, and has no relation to Maven Central SNAPSHOT artifacts, correct?\n2. Is this currently limited to the monorepo (e.g., Zeebe, Modeler, etc.), or are other components like Optimize, etc. expected to follow the same approach for their own `stable/X.Y` branches?\n3. Should a new `X.Y-SNAPSHOT` image be published:\n   a. Every time a PR is merged into a stable branch?\n   b. Or on a nightly schedule only?\n4. What should happen to the previous `X.Y-SNAPSHOT` image when a new one is published?\n   a. Should it be overwritten/replaced immediately?\n   b. Should we retain previous images for some period (e.g., to avoid breaking a test in progress)?\n   c. If a new image is pushed while QA is running a test on the same `X.Y-SNAPSHOT` tag, is there any expected coordination?\n   d. Should we assume ???latest image wins???, and the next test will simply consume whatever???s available at the time?\n   e. Do we need stability guarantees per test run (e.g., lock to the SHA/tag used at test start)?\n\nThanks in advance for the help!", "I can give input on some of the questions from my POV:\n\n> 1. Just confirming that X.Y-SNAPSHOT is solely a Docker image tag, and has no relation to Maven Central SNAPSHOT artifacts, correct?\n\nYup\n\n> 2. Is this currently limited to the monorepo (e.g., Zeebe, Modeler, etc.), or are other components like Optimize\n\nOptimize is part of the monorepo on newer versions (8.8+), hence the phrasing in the ticket description:\n\n>> Each stable branch (e.g., stable/8.6, stable/8.7, etc.) has a corresponding X.Y-SNAPSHOT image published for each component present on that branch:\n>>   * 8.5 and older only have Zeebe component\n\n> 3. a. Every time a PR is merged (_a commit is pushed_) into a stable branch?\n\nThat would be in line how we do it for `main` (and people expect it to work like that here) and `stable/8.7` so I'd appreciate the consistency and staying with the people's expectations.\n\n> 4. a. Should it be overwritten/replaced immediately?\n\nAgain yes from my side, since I'd appreciate that to have consistency with how `main` does it (and people expect it to work)\n\n> 4. c. If a new image is pushed while QA is running a test on the same X.Y-SNAPSHOT tag, is there any expected coordination?\n\nDocker caches images locally (on the same GHA run+runner only) so overwriting images in an upstream Docker registry is usually not breaking.", "I agree with all of @cmur2 comments and just to add to that from a QA POV we don't need to retain previous images for any period nor do we need stability guarantees per test run. Please let me know if you have any other questions I can support with! ", "I am posting here my planning for this task then:\n- [x] Edit docker image tag from 8.7.0-SNAPSHOT to 8.7-SNAPSHOT\n   - [x] stable/8.7\n   - [x] stable/optimize-8.7\n- Edit docker image version from SNAPSHOT to X.Y-SNAPSHOT\n   - [x] stable/8.6\n- Replace `github.ref == 'refs/heads/main'` in `deploy-camunda-docker-snapshot` with `github.ref == 'refs/heads/stable/X.Y'`\n   - [x] stable/8.6\n- Replace `IS_DEFAULT_BRANCH` with `SHOULD_PUSH_DOCKER_SNAPSHOT`, where `SHOULD_PUSH_DOCKER_SNAPSHOT: ${{ inputs.branch == 'stable/X.Y' }}`\n   - [x] stable/8.6\n- Add `echo \"IS_STABLE_87=${{ github.ref == 'refs/heads/stable/optimize-8.6' }}\"`\n- [x] Add \n```\nif [ \"${IS_STABLE_87}\" = \"true\" ]; then\n    tags+=(\"${DOCKER_IMAGE_DOCKER_HUB}:8.7.0-SNAPSHOT\")\nfi\n```\nto optimise-8.6\n\n## After Merge:\n- [x] verify the image was properly generated (@cmur2 or @kellervater, can you help me with that? Also, should I delete the image with deprecated name, 8.7.0-SNAPSHOT, from docker hub?)\n- [ ] Delete old image from docker hub\n- [x] Update https://github.com/camunda/camunda/wiki/CI-&-Automation#available-snapshot-artifacts with the correct naming convention\n- [x] Inform the engineers about the change + updated documentation\n- [x] Come up with a plan for upcoming minor releases\n- [ ] Monitoring\n", "Hey team,\n\nAs part of implementing the docker image tag change from 8.7.0-SNAPSHOT ??? 8.7-SNAPSHOT, I noticed that the old tag (8.7.0-SNAPSHOT) is still being used in many places across the Camunda ecosystem. Some examples:\n\n- Integration tests (e.g., CamundaProcessTestConnectorsIT)\n- Tasklist e2e tests\n- Operate/tasklist clients\n- Docker-compose setups\n- Test `application.yaml`\n\nIf we just change the build & publish process without coordinating, all of these items will start breaking as soon as we have removed the old tag.\n\nBefore merging this improvement, should we:\n1. Temporarily publish both tags (8.7.0-SNAPSHOT and 8.7-SNAPSHOT), to avoid breaking tests immediately?\n2. Plan a coordinated cleanup after the merge, giving time to each component team update their references?\n3. How long should be this transition period?\n4. Do the teams have available capacity for that?\n\nPlease let me know how you'd like to proceed.", "Hey @liliancavalet I have added my thoughts from a QA POV [here](https://camunda.slack.com/archives/C071KP5BTHB/p1750233451799269?thread_ts=1742395590.166449&cid=C071KP5BTHB)", "> As part of implementing the docker image tag change from 8.7.0-SNAPSHOT ??? 8.7-SNAPSHOT, I noticed that the old tag (8.7.0-SNAPSHOT) is still being used in many places across the Camunda ecosystem. Some examples:\n\nIs the list complete? If not, let's find all usages first so we are aware of the impact.\n\n> If we just change the build & publish process without coordinating, all of these items will start breaking as soon as we have removed the old tag.\n\nIndeed, good catch. For each usage let's try to identify if it can be changed easily (by us or QA) and if so, prepare PR(s) to do that e.g. in `camunda/camunda` where we have the authority + announce that upcoming change once we committed to it. If there is any usages remaining that cannot be easily changed, we can consider how to deal with those (e.g. reach out to stakeholders).", "> Is the list complete? If not, let's find all usages first so we are aware of the impact.\n\nThe complete list is:\n\nfor stable/8.7\n- `TestFixture` from `io.camunda.tasklist.qa.migration.v870`\n- `pom.xml` from `tasklist/qa`\n- `test.properties` from `tasklist/qa/migration-tests`\n- `package.json` from `tasklist/client/`\n- `docker-compose` from `tasklist/config`\n- `application.yaml` from `camunda-process-test-example`\n- `application.yaml` from `camunda-process-test-spring`\n- `CamundaProcessTestConnectorsIT` from `io.camunda.process.test.api`\n- `CamundaProcessTestExtensionIT` from  `io.camunda.process.test.api`\n- `tasklist-e2e-tests.yml` from `workflows`\n- `docker-compose` from `core application-e2e-test-suite`\n\nfor stable/8.6\n- `ZeebeTaskListenersValidationTest.testEventTypeNotDefined.bpmn` from `zeebe-bpmn-model`\n- `shouldReturnCamundaVersion` from `ContainerRuntimeVersionUtilTest` at `io.camunda.process.test.impl.runtime`\n- `package.json` from `tasklist/client/`\n\n@slolatte can you help me understand if there are any of this files that aren't under your teams scope?\n\n> Indeed, good catch. For each usage let's try to identify if it can be changed easily (by us or QA) and if so, prepare PR(s) to do that e.g. in camunda/camunda where we have the authority + announce that upcoming change once we committed to it. If there is any usages remaining that cannot be easily changed, we can consider how to deal with those (e.g. reach out to stakeholders).\n\nFrom what I???ve seen, most references to the old image tag do look like straightforward string changes, especially in tests or config files.\nThat said, since I???m not fully familiar with how the entire test and CI ecosystem fits together (especially for non-unit tests like integration or system tests), I would be a bit cautious. Changing the Docker image tag could have side effects I can???t foresee, or there might be scripts and pipelines that rely on it implicitly.\nTo reduce risk,  it would make sense for me to go ahead and propose the image tag changes in separate PRs and then work with the teams responsible for each file, WDYT?\n", "> can you help me understand if there are any of this files that aren't under your teams scope?\n\n@liliancavalet The only file which is actually used by QA is the following:\n\n`docker-compose from core application-e2e-test-suite`", "[There are usages](https://github.com/search?q=org%3Acamunda%208.7.0-SNAPSHOT&type=code) also outside `camunda/camunda`, e.g. in https://github.com/camunda/c8-cross-component-e2e-tests (owner: QA) and https://github.com/camunda/rpa-worker (owner: ??) and https://github.com/camunda/camunda-deployment-references (owner: InfEx?)", "Well just for 8.7 we actually have this list of files with the soon to be deprecated tag:\n\n**Docs team ??? \ncamunda/camunda-docs | versioned_docs/version-8.7/self-managed/concepts/elasticsearch-without-cluster-privileges.md\n**Action:** https://github.com/camunda/camunda-docs/issues/6028**\n\nController team ??? \ncamunda/camunda-operator | pkg/apps/connectors/resources/connectors_deployment_test.go\n**Action:** https://github.com/camunda/camunda-operator/pull/4237\n\n**RPA team ??? \ncamunda/rpa-worker | rpa-worker-e2e-tests/camunda.helmrelease.yaml\n**Action:** team has a separate branch for that**\n\nInfrastructure Experience team ??? \n~camunda/camunda-deployment-references | .github/workflows/aws_compute_ec2_single_region_tests.yml\nhttps://github.com/camunda/camunda-deployment-references/pull/639~\n\n**c8-cross-component-e2e-tests ??? \ncamunda/c8-cross-component-e2e-tests | .github/workflows/playwright_sm_nightly_mt_8_7.yml\ncamunda/c8-cross-component-e2e-tests | .github/configs/camunda-platform-8-7-values.yml\ncamunda/c8-cross-component-e2e-tests | .github/workflows/playwright_sm_nightly_rba_8_7.yml\ncamunda/c8-cross-component-e2e-tests | .github/workflows/playwright_sm_weekly_license_key_8_7.yml\ncamunda/c8-cross-component-e2e-tests | .github/workflows/playwright_sm_nightly_tests_edge_8_7.yml\ncamunda/c8-cross-component-e2e-tests | .github/workflows/playwright_sm_nightly_tests_chrome_8_7.yml\ncamunda/c8-cross-component-e2e-tests | .github/workflows/playwright_sm_nightly_tests_firefox_8_7.yml\ncamunda/c8-cross-component-e2e-tests | .github/workflows/playwright_sm_nightly_tests_opensearch_8_7.yml\n**Action:** team is waiting to perform the fix**\n\n**Data Layer ??? \nmain:\ncamunda/camunda | qa/acceptance-tests/src/test/java/io/camunda/it/migration/ElasticsearchUpdateRegressionTest.java\ncamunda/camunda | qa/acceptance-tests/src/test/java/io/camunda/it/migration/PrefixMigrationIT.java\n**Action:** https://github.com/camunda/camunda/pull/34186**\n\n**QA ??? \ncamunda/camunda | qa/core-application-e2e-test-suite/config/docker-compose.yml\n**Action:** https://github.com/camunda/camunda/pull/33964/files**\n\n**Tasklist team ??? \nstable/8.7\ncamunda/camunda | tasklist/config/docker-compose.yml ok\ncamunda/camunda | tasklist/qa/pom.xml ok\ncamunda/camunda | tasklist/qa/migration-tests/test.properties ok\ncamunda/camunda | tasklist/client/package.json ok\ncamunda/camunda | io/camunda/tasklist/qa/migration/v870/TestFixture.java ok\ncamunda/camunda | .github/workflows/tasklist-e2e-tests.yml ok\n**Action:** https://github.com/camunda/camunda/pull/33961/files**\n\n**CPT ???  \nstable/8.7\ncamunda/camunda | testing/camunda-process-test-example/src/test/resources/application.yml ok\ncamunda/camunda | testing/camunda-process-test-spring/src/test/resources/application.yml ok \ncamunda/camunda | testing/camunda-process-test-java/src/test/java/io/camunda/process/test/api/CamundaProcessTestConnectorsIT.java ok\ncamunda/camunda | testing/camunda-process-test-java/src/test/java/io/camunda/process/test/api/CamundaProcessTestExtensionIT.java ok\n**Action:** https://github.com/camunda/camunda/pull/33963/files**\n\n**Operate team ??? \nstable/8.7\ncamunda/camunda | operate/client/package.json\n**Action:** https://github.com/camunda/camunda/pull/33965/files**\n\n~camunda/camunda | .github/workflows/tasklist-ci-build-reusable.yml~ - To be edited to create the new tag\n~camunda/camunda | .github/workflows/operate-ci-build-reusable.yml~ - To be edited to create the new tag\n~camunda/camunda | .github/workflows/ci.yml~ - To be edited to create the new tag\n~camunda/camunda | .github/workflows/zeebe-ci.yml~ - To be edited to create the new tag\nPRs: \nhttps://github.com/camunda/camunda/pull/33898/files\nhttps://github.com/camunda/camunda/pull/33900/files\n\nMost of those under camunda/camunda I already prepared the PR, but we still need help from the owners to understand if the changes and impact are more then the expected.\n", "for 8.6:\n\n**Tasklist team ??? \ncamunda/camunda | stable/8.6 | tasklist/client/package.json\ncamunda/camunda | stable/optimize-8.6 | tasklist/client/package.json\ncamunda/camunda | stable/optimize-8.7 | tasklist/client/package.json (why 8.7 is referencing 8.6?)\n**Action:** \nhttps://github.com/camunda/camunda/pull/34063\nhttps://github.com/camunda/camunda/pull/34078\nhttps://github.com/camunda/camunda/pull/34187**\n\nZeebe team ??? \n ~camunda/camunda | stable/8.7 | zeebe/bpmn-model/src/test/resources/io/camunda/zeebe/model/bpmn/validation/ZeebeLinkedResourcesValidationTest.testEvent.bpmn  (why 8.7 is referencing 8.6?)\ncamunda/camunda | stable/8.6 | zeebe/bpmn-model/src/test/resources/io/camunda/zeebe/model/bpmn/validation/ZeebeTaskListenersValidationTest.testEventTypeNotDefined.bpmn\nhttps://github.com/camunda/camunda/pull/33968/files\ncamunda/camunda | stable/8.7 | zeebe/bpmn-model/src/test/resources/io/camunda/zeebe/model/bpmn/validation/ZeebeTaskListenersValidationTest.testEventTypeNotDefined.bpmn  (why 8.7 is referencing 8.6?)\ncamunda/camunda | stable/optimize-8.6 | zeebe/bpmn-model/src/test/resources/io/camunda/zeebe/model/bpmn/validation/ZeebeTaskListenersValidationTest.testEventTypeNotDefined.bpmn\nhttps://github.com/camunda/camunda/pull/34079\ncamunda/camunda | stable/optimize-8.7 | zeebe/bpmn-model/src/test/resources/io/camunda/zeebe/model/bpmn/validation/ZeebeTaskListenersValidationTest.testEventTypeNotDefined.bpmn (why 8.7 is referencing 8.6?)~\n\n**CPT team ??? \ncamunda/camunda | stable/8.6 | testing/camunda-process-test-java/src/test/java/io/camunda/process/test/impl/runtime/ContainerRuntimePropertiesUtilTest.java ok\ncamunda/camunda | stable/8.6 | testing/camunda-process-test-java/src/test/java/io/camunda/process/test/impl/runtime/ContainerRuntimeVersionUtilTest.java ok\nhttps://github.com/camunda/camunda/pull/33967/files\ncamunda/camunda | stable/8.7 | testing/camunda-process-test-java/src/test/java/io/camunda/process/test/impl/runtime/ContainerRuntimeVersionUtilTest.java  (why 8.7 is referencing 8.6?)\ncamunda/camunda | stable/optimize-8.6 | testing/camunda-process-test-java/src/test/java/io/camunda/process/test/impl/runtime/ContainerRuntimeVersionUtilTest.java\ncamunda/camunda | stable/optimize-8.7 | testing/camunda-process-test-java/src/test/java/io/camunda/process/test/impl/runtime/ContainerRuntimeVersionUtilTest.java  (why 8.7 is referencing 8.6?)\n**Action:** ok**\n\n**Operate team ??? \ncamunda/camunda | stable/optimize-8.6 | operate/client/package.json\ncamunda/camunda | stable/optimize-8.7 | operate/client/package.json  (why 8.7 is referencing 8.6?)\n**Action:** \nhttps://github.com/camunda/camunda/pull/34897\nhttps://github.com/camunda/camunda/pull/34188**\n\nImprovent by using tag as 8.6-SNAPSHOT\nhttps://github.com/camunda/camunda/pull/33966/files\nhttps://github.com/camunda/camunda/pull/34067/files\n\n", "The search as done by combing github search + sourcegraph:\n\n8.7:\nhttps://github.com/search?q=org%3Acamunda+8.7.0-SNAPSHOT&type=code\nhttps://sourcegraph.com/search?q=repo:%5Egithub%5C.com/camunda/.*%24%40*refs/heads/stable/*+8.7.0-SNAPSHOT&patternType=keyword&sm=0\n\n8.6:\nhttps://github.com/search?q=org%3Acamunda+8.6.0-SNAPSHOT&type=code&p=2\nhttps://sourcegraph.com/search?q=repo:%5Egithub%5C.com/camunda/.*%24%40*refs/heads/stable/*+8.6.0-SNAPSHOT&patternType=keyword&sm=0", "For `camunda-deployment-references`, removed it with [PR](https://github.com/camunda/camunda-deployment-references/pull/639). Owner Infrastructure Experience team, we tag our repos with the GitHub topics feature `team-infrastructure-experience`.\n\n@liliancavalet, any plans to apply a similar logic to the current `SNAPSHOT` tag representing the \"next\" version?", "@Langleu currently our goal is just change the naming for stable branches. We don't foresee changes to the `main` branch, so it is expected that the image version `SNAPSHOT` (from main), won't change.\nAlso, thank you very much for the help and prompt implementation!", "@liliancavalet How will this be handled for Apps which are not apart of the mono repo (ex. Console, Web Modeler)? ", "> [@liliancavalet](https://github.com/liliancavalet) How will this be handled for Apps which are not apart of the mono repo (ex. Console, Web Modeler)?\n\nAs mentioned in [this comment](https://github.com/camunda/camunda/issues/30477#issuecomment-2992357539), I???ve already mapped the occurrences of 8.7.0-SNAPSHOT outside the camunda/camunda repository and have reached out to the respective teams to coordinate the tag update.\n\nAdditionally, based on [my research](https://github.com/camunda/camunda/issues/30477#issuecomment-2992596114), it seems that the teams involved are only the ones already listed. But if you???re aware of anything I might have missed, please let me know!\n\n", "> > [@liliancavalet](https://github.com/liliancavalet) How will this be handled for Apps which are not apart of the mono repo (ex. Console, Web Modeler)?\n> \n> As mentioned in [this comment](https://github.com/camunda/camunda/issues/30477#issuecomment-2992357539), I???ve already mapped the occurrences of 8.7.0-SNAPSHOT outside the camunda/camunda repository and have reached out to the respective teams to coordinate the tag update.\n> \n> Additionally, based on [my research](https://github.com/camunda/camunda/issues/30477#issuecomment-2992596114), it seems that the teams involved are only the ones already listed. But if you???re aware of anything I might have missed, please let me know!\n\n@liliancavalet Sorry for the confusion, I meant for teams which currently aren't publishing 8.7.0-SNAPSHOT already - so Console, Web Modeler & Identity for example", "> Sorry for the confusion, I meant for teams which currently aren't publishing 8.7.0-SNAPSHOT already - so Console, Web Modeler & Identity for example\n\n@slolatte I think we discussed this prior when creating the ticket. The scope of this ticket is just what the Monorepo DevOps team controls which is the monorepo and components inside it. Console, Web Modeler, etc are out of scope. If you want the same feature there, please approach those teams directly.", "@cmur2 Okay I will reach out to these teams directly. And just confirming that for 8.4 & 8.5, the Monorepo DevOps team will only do this for Zeebe and if I want this for other teams I will need to approach them as well?", "> [@cmur2](https://github.com/cmur2) Okay I will reach out to these teams directly. And just confirming that for 8.4 & 8.5, the Monorepo DevOps team will only do this for Zeebe and if I want this for other teams I will need to approach them as well?\n\n@slolatte 8.4 will drop out of support in less than a month, 8.5 in October. I'm not sure if we should still invest into that?", "\n> [@slolatte](https://github.com/slolatte) 8.4 will drop out of support in less than a month, 8.5 in October. I'm not sure if we should still invest into that?\n\n@cmur2 Regarding 8.4, I agree with you???it doesn???t seem to add much value. As for 8.5, I do think it could be beneficial if the implementation overhead is low. However, if it requires significant effort, it might not be worth pursuing.", "> As for 8.5, I do think it could be beneficial if the implementation overhead is low. However, if it requires significant effort, it might not be worth pursuing.\n\n@liliancavalet Looking at the [8.5 implementation in CI](https://github.com/camunda/camunda/blob/a07a940b8cb94c8676ddad93bea4626099ce6341/.github/workflows/zeebe-ci.yml#L698), it looks very similar to the newer branches, so adjustment should be straightforward and we can include it in the scope. WDYT?", "For the reviewer: \n\nBackporting PRs available:\nstable/8.5 -> https://github.com/camunda/camunda/pull/34716\nstable/8.6 -> https://github.com/camunda/camunda/pull/34821\nstable/8.7 -> https://github.com/camunda/camunda/pull/34717\nstable/optimize-8-6 ->https://github.com/camunda/camunda/pull/34067\nstable/optimize-8-7 -> https://github.com/camunda/camunda/pull/33900\n\nAfter that I should also update [this](https://github.com/camunda/camunda/wiki/CI-&-Automation#available-snapshot-artifacts) documentation", "/review @Kerruba ", "Images are available on dockerhub:\n- https://hub.docker.com/r/camunda/zeebe/tags?name=8.7-SNAPSHOT\n- https://hub.docker.com/r/camunda/tasklist/tags?name=8.7-SNAPSHOT\n- https://hub.docker.com/r/camunda/operate/tags?name=8.7-SNAPSHOT\n- https://hub.docker.com/r/camunda/zeebe/tags?name=8.6-SNAPSHOT\n- https://hub.docker.com/r/camunda/tasklist/tags?name=8.6-SNAPSHOT\n- https://hub.docker.com/r/camunda/operate/tags?name=8.6-SNAPSHOT\n\nEntering phase 2:\n- [x] informe engineering team\n- [x] Update [doc](https://github.com/camunda/camunda/wiki/CI-&-Automation#available-snapshot-artifacts)\n- [ ] remove existing references to 8.7.0-SNAPHOT and variations", "@liliancavalet for `8.6-SNAPSHOT`, I noticed the Zeebe image is available, but I???m not seeing Tasklist and Operate. Is that expected? Thanks!", "> [@liliancavalet](https://github.com/liliancavalet) for `8.6-SNAPSHOT`, I noticed the Zeebe image is available, but I???m not seeing Tasklist and Operate. Is that expected? Thanks!\n\nHi @slolatte,\nThis is a bit odd, I replicated the same behavior from 8.7 to 8.6, so it should be working as expected.\nI did a quick research and seems that this step is being skipped for 8.6, will give a look int that.", "> > [@liliancavalet](https://github.com/liliancavalet) for `8.6-SNAPSHOT`, I noticed the Zeebe image is available, but I???m not seeing Tasklist and Operate. Is that expected? Thanks!\n> \n> Hi [@slolatte](https://github.com/slolatte), This is a bit odd, I replicated the same behavior from 8.7 to 8.6, so it should be working as expected. I did a quick research and seems that this step is being skipped for 8.6, will give a look int that.\n\nFixed \uD83E\uDD73 " ],
      "repository" : {
        "description" : "Process Orchestration Framework",
        "homepage" : "https://camunda.com/platform/",
        "name" : "camunda",
        "fullName" : "camunda/camunda",
        "htmlUrl" : "https://github.com/camunda/camunda",
        "gitUrl" : "git://github.com/camunda/camunda.git",
        "sshUrl" : "git@github.com:camunda/camunda.git",
        "cloneUrl" : "https://github.com/camunda/camunda.git",
        "owner" : {
          "login" : "camunda",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 679,
        "stargazersCount" : 3723,
        "watchersCount" : 3723,
        "size" : 643351,
        "openIssuesCount" : 2373,
        "subscribersCount" : 114,
        "pushedAt" : "2025-07-11T23:23:17Z",
        "languages" : {
          "MDX" : 2383,
          "Smarty" : 230,
          "Java" : 53137212,
          "CSS" : 2925,
          "Makefile" : 20359,
          "Go" : 76584,
          "HTML" : 14209,
          "FreeMarker" : 94639,
          "TypeScript" : 6978501,
          "Dockerfile" : 23726,
          "Shell" : 47376,
          "Batchfile" : 3877,
          "SCSS" : 133874,
          "JavaScript" : 1534294
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to publish SNAPSHOT images for stable branches, including 8.6 and 8.7, with specific naming conventions and image tags.",
      "validationOrRequirement" : "The requirement is to publish SNAPSHOT images for stable branches, with specific naming conventions and image tags.",
      "attemptedFixes" : "Various PRs and changes to implement the feature, including updating CI configurations, Docker image tags, and documentation.",
      "otherNotes" : "Various comments and discussions around the implementation of publishing SNAPSHOT images for stable branches, including coordinating with other teams and updating documentation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283676
  }, {
    "issueDTO" : {
      "id" : 3218528689,
      "title" : "Official app-of-apps example helm-guestbook doesn't use values-production.yaml",
      "url" : "https://github.com/argoproj/argo-cd/issues/23732",
      "repositoryName" : "argoproj/argo-cd",
      "description" : "# Summary\n\nIn the [official app-of-apps example](https://github.com/argoproj/argocd-example-apps) helm-guestbook doesn't use [values-production.yaml](\nhttps://github.com/argoproj/argocd-example-apps/blob/master/helm-guestbook/values-production.yaml).\n\n# Motivation\n\nIt is unclear how to combine multiple values in the app-of-apps pattern. In the example case it is unclear how can the [values.yaml](https://github.com/argoproj/argocd-example-apps/blob/master/helm-guestbook/values.yaml\n) and [values-production.yaml](https://github.com/argoproj/argocd-example-apps/blob/master/helm-guestbook/values-production.yaml\n) be combined. Why is the [values-production.yaml](https://github.com/argoproj/argocd-example-apps/blob/master/helm-guestbook/values-production.yaml\n) file present in the repository?\n\n# Proposal\n\nPlease suggest how to idiomatically do values overriding in the app-of-apps helm-guestbook example and update the example.",
      "updatedAt" : 1752246155.000000000,
      "user" : "bofm",
      "userHtmlUrl" : "https://github.com/bofm",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3646419?v=4",
      "labels" : [ "component:docs", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I can work on this - pls assign it to me when possible", "@bofm I looked at the example and your question and it seems that there is some kind of misunderstanding about app of apps and helm charts. \n\nLet me clarify a few things\n\n1. The app of apps pattern is not related to any declarative framework ( helm, kustomize etc. ) \n2. If your question is how to combine multiple helm charts you can read the official argo cd [docs](https://argo-cd.readthedocs.io/en/latest/user-guide/helm/#values-files) for helm\n3. This file might be used by other external examples or repositories so it makes sense to keep it and not delete it. \n4. This repository contains multiple examples , not only for App of Apps. \n\nLet me know if the above are clear and I'm going to close the ticket " ],
      "repository" : {
        "description" : "Declarative Continuous Deployment for Kubernetes",
        "homepage" : "https://argo-cd.readthedocs.io",
        "name" : "argo-cd",
        "fullName" : "argoproj/argo-cd",
        "htmlUrl" : "https://github.com/argoproj/argo-cd",
        "gitUrl" : "git://github.com/argoproj/argo-cd.git",
        "sshUrl" : "git@github.com:argoproj/argo-cd.git",
        "cloneUrl" : "https://github.com/argoproj/argo-cd.git",
        "owner" : {
          "login" : "argoproj",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 6165,
        "stargazersCount" : 20039,
        "watchersCount" : 20039,
        "size" : 139340,
        "openIssuesCount" : 3674,
        "subscribersCount" : 184,
        "pushedAt" : "2025-07-11T18:42:21Z",
        "languages" : {
          "CSS" : 2209,
          "Procfile" : 10164,
          "Makefile" : 25368,
          "Go" : 7179373,
          "Mustache" : 1066,
          "HTML" : 895,
          "TypeScript" : 1354561,
          "Dockerfile" : 15719,
          "Shell" : 60435,
          "Starlark" : 6864,
          "SCSS" : 97697,
          "JavaScript" : 6255,
          "Lua" : 242895
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "It is unclear how to combine multiple values in the app-of-apps pattern in the official app-of-apps example helm-guestbook, specifically how to combine values.yaml and values-production.yaml files.",
      "validationOrRequirement" : "Idiomatically do values overriding in the app-of-apps helm-guestbook example and update the example.",
      "attemptedFixes" : "None",
      "otherNotes" : "The app of apps pattern is not related to any declarative framework (helm, kustomize etc.), and the values-production.yaml file might be used by other external examples or repositories.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283680
  }, {
    "issueDTO" : {
      "id" : 3105887694,
      "title" : "[Bug] Unlimited card upgrades at Campsite",
      "url" : "https://github.com/oskarrough/slaytheweb/issues/267",
      "repositoryName" : "oskarrough/slaytheweb",
      "description" : "As the title suggests, you can upgrade or remove an unlimited number of cards at campsite. After upgrading one card and returning to map, you simply need to click on the Map button at the top right corner to be prompted again. See [#2744](https://slaytheweb.cards/stats/run?id=2744), I was able to upgrade 11 cards in 1 campsite.\n\nAlso, you can't remove upgraded cards at campsite, which I think is a bit silly.",
      "updatedAt" : 1752246149.000000000,
      "user" : "frank3215",
      "userHtmlUrl" : "https://github.com/frank3215",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3163171?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hehe, is it a bug? Is it a hidden trick for people who want power? I'm not sure.. Kidding, no that should be fixed. Thank you for writing.\n\n- Make sure you can only upgrade one card per campfire\n- Make sure you can remove upgraded cards (non-upgraded works)", "Hi, I really appreciate this project! I would like to contribute to this issue to get familiar with it." ],
      "repository" : {
        "description" : "Slay the Web is a singleplayer, deck builder, roguelike card crawl game for the web based on Slay the Spire",
        "homepage" : "https://slaytheweb.cards",
        "name" : "slaytheweb",
        "fullName" : "oskarrough/slaytheweb",
        "htmlUrl" : "https://github.com/oskarrough/slaytheweb",
        "gitUrl" : "git://github.com/oskarrough/slaytheweb.git",
        "sshUrl" : "git@github.com:oskarrough/slaytheweb.git",
        "cloneUrl" : "https://github.com/oskarrough/slaytheweb.git",
        "owner" : {
          "login" : "oskarrough",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 46,
        "stargazersCount" : 228,
        "watchersCount" : 228,
        "size" : 22600,
        "openIssuesCount" : 20,
        "subscribersCount" : 6,
        "pushedAt" : "2025-04-14T06:20:30Z",
        "languages" : {
          "CSS" : 32491,
          "Astro" : 12637,
          "JavaScript" : 195838
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the issue of unlimited card upgrades and removals at campsite",
      "validationOrRequirement" : "Cards can only be upgraded or removed once per campfire, and upgraded cards can be removed",
      "attemptedFixes" : "Make sure you can only upgrade one card per campfire, make sure you can remove upgraded cards (non-upgraded works)",
      "otherNotes" : "Cards can be upgraded or removed unlimited times at campsite, and upgraded cards cannot be removed. This is not intended behavior.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283683
  }, {
    "issueDTO" : {
      "id" : 2625043266,
      "title" : "Investigate whether diagnostics should be applied to all methods in PersistenceMapKeyDiagnosticsParticipant.",
      "url" : "https://github.com/eclipse-lsp4jakarta/lsp4jakarta/issues/532",
      "repositoryName" : "eclipse-lsp4jakarta/lsp4jakarta",
      "description" : "While refactoring similar code in Liberty Tools for IntelliJ I noticed that it is looping over all methods on the application's class looking for annotations that seem to just apply to properties (accessor methods). Should this code be checking every method or should it filter the list so it only checks property methods? It seems like we might report false-positives but should probably check whether this is aligned with the Jakarta Persistence spec.\r\n\r\n```\r\nfor (IMethod method : methods) {\r\n                List<IAnnotation> mapKeyJoinCols = new ArrayList<IAnnotation>();\r\n                boolean hasMapKeyAnnotation = false;\r\n                boolean hasMapKeyClassAnnotation = false;\r\n                allAnnotations = method.getAnnotations();\r\n                for (IAnnotation annotation : allAnnotations) {\r\n                    String matchedAnnotation = DiagnosticUtils.getMatchedJavaElementName(type,\r\n                                                                                         annotation.getElementName(),\r\n                                                                                         Constants.SET_OF_PERSISTENCE_ANNOTATIONS);\r\n                    if (matchedAnnotation != null) {\r\n                        if (Constants.MAPKEY.equals(matchedAnnotation))\r\n                            hasMapKeyAnnotation = true;\r\n                        else if (Constants.MAPKEYCLASS.equals(matchedAnnotation))\r\n                            hasMapKeyClassAnnotation = true;\r\n                        else if (Constants.MAPKEYJOINCOLUMN.equals(matchedAnnotation)) {\r\n                            mapKeyJoinCols.add(annotation);\r\n                        }\r\n                    }\r\n                }\r\n```",
      "updatedAt" : 1752246053.000000000,
      "user" : "mrglavas",
      "userHtmlUrl" : "https://github.com/mrglavas",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/890521?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\nAs per the specification  MapKey and MapKeyClass annotations can be applied on persistent field or property.\n\nDefinitions:\n\nField: A field (also known as an instance variable or member variable) is a variable declared directly within a class (but outside any method, constructor, or block)\n\nProperty: A property (more formally, a JavaBean property) is a conceptual attribute of a class that is exposed through accessor methods, primarily getter and setter methods.\n\n     Getter: public T getPropertyName() (for a property propertyName of type T).\n     Boolean Getter: public boolean isPropertyName() (for a boolean property propertyName).\n     Setter: public void setPropertyName(T value) (for a property propertyName of type T).\n\nSpec Reference: \n     https://jakarta.ee/specifications/persistence/3.2/jakarta-persistence-spec-3.2#mapkey-annotation\n     https://jakarta.ee/specifications/persistence/3.2/jakarta-persistence-spec-3.2#mapkeyclass-annotation", "As of now the logic checks all the methods without any property access filter. And it is not restricting to apply on non access method as well. The Java compiler won't complain because @Target for @MapKeyClass/ @MapKey includes METHOD and FIELD. But the JPA runtime will ignore it because it's not on a method that represents a persistent property according to the JPA specification and the entity's defined access strategy. Should we introduce a filter based on property naming conventions?", "> Should we introduce a filter based on property naming conventions?\n\nIs it an error to apply the MapKey and MapKeyClass annotations to non-persistent fields or methods that are not property methods?", "It depends on what the specification says regarding which non-conformances need to be reported as errors. ", "In specification there is a general statement \"The MapKeyClass annotation is not used when MapKey is specified and vice versa\". That means it should not be use together irrespective of method type. ", "> should not be use together irrespective of method type.\n\nThis is where we started. " ],
      "repository" : {
        "description" : "Language Server for Jakarta EE",
        "homepage" : "",
        "name" : "lsp4jakarta",
        "fullName" : "eclipse-lsp4jakarta/lsp4jakarta",
        "htmlUrl" : "https://github.com/eclipse-lsp4jakarta/lsp4jakarta",
        "gitUrl" : "git://github.com/eclipse-lsp4jakarta/lsp4jakarta.git",
        "sshUrl" : "git@github.com:eclipse-lsp4jakarta/lsp4jakarta.git",
        "cloneUrl" : "https://github.com/eclipse-lsp4jakarta/lsp4jakarta.git",
        "owner" : {
          "login" : "eclipse-lsp4jakarta",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 55,
        "stargazersCount" : 34,
        "watchersCount" : 34,
        "size" : 8847,
        "openIssuesCount" : 108,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-09T17:45:59Z",
        "languages" : {
          "Java" : 1304208,
          "Shell" : 256
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Investigate whether diagnostics should be applied to all methods in PersistenceMapKeyDiagnosticsParticipant, specifically whether it should filter the list to only check property methods or report false-positives.",
      "validationOrRequirement" : "The issue is related to the Jakarta Persistence specification, specifically the application of MapKey and MapKeyClass annotations to persistent fields or properties. The specification states that these annotations can be applied on persistent field or property, and that the MapKeyClass annotation is not used when MapKey is specified and vice versa.",
      "attemptedFixes" : "None mentioned in the issue description",
      "otherNotes" : "The issue is related to the application of diagnostics to all methods in PersistenceMapKeyDiagnosticsParticipant, specifically whether it should filter the list to only check property methods or report false-positives. The Java compiler does not complain about the current logic, but the JPA runtime ignores it because it's not on a method that represents a persistent property according to the JPA specification and the entity's defined access strategy.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283690
  }, {
    "issueDTO" : {
      "id" : 3099871342,
      "title" : "Pyright diagnosticMode: \"workspace\" equivalent in Pyrefly",
      "url" : "https://github.com/facebook/pyrefly/issues/397",
      "repositoryName" : "facebook/pyrefly",
      "description" : "### Describe the Bug\n\nPyright has the following configurable settings when using it with an IDE like Zed, VSCode, etc.:\n\n> python.analysis.diagnosticMode [???openFilesOnly???, ???workspace???]: Determines whether pyright analyzes (and reports errors for) all files in the workspace, as indicated by the config file. If this option is set to ???openFilesOnly???, pyright analyzes only open files.\n\nCurrently, it appears that Pyrefly only supports the \"openFilesOnly\" diagnostic mode. Given the speed of Pyrefly, I believe it would make sense to implement support for the \"workspace\" mode as well.\n\n### Sandbox Link\n\n_No response_\n\n### (Only applicable for extension issues) IDE Information\n\n_No response_",
      "updatedAt" : 1752245965.000000000,
      "user" : "Pristor",
      "userHtmlUrl" : "https://github.com/Pristor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/58817292?v=4",
      "labels" : [ "User", "codenav", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @SamChou19815 ", "We do have the ability to emit all errors for a given projects. These errors are actually tracked within the LSP server, but we didn't emit them now, because we still have many type system gaps we need to close. I found that if we enable it for a large internal project, it will emit so many errors that it will freeze VSCode. That being said, we could gate it behind a flag for now.", "Pyright???s default behavior is the same; it needs to be explicitly set to ???workspace??? to work that way. Personally, I like having the option to emit all errors for medium-sized or completely new projects.", "@SamChou19815 @kinto0 should this be a configurable option so developers can test the functionality? It sounds like we are going to make it configurable in the future anyways, so allowing it to be turned on now could be nice for some developers. ", "> [@SamChou19815](https://github.com/SamChou19815) [@kinto0](https://github.com/kinto0) should this be a configurable option so developers can test the functionality? It sounds like we are going to make it configurable in the future anyways, so allowing it to be turned on now could be nice for some developers.\n\nyes. this setting should be added. @connernilsen do you think it should be part of an on-disk configuration too? I imagine certain projects will want to enable / disable it.", "@kinto0 like configuring the IDE in an on-disk config? If so, we can probably do that pretty easily. I could see it being confusing for users though, since changing that setting in the IDE won't do anything if it's set in the config file", "> [@kinto0](https://github.com/kinto0) like configuring the IDE in an on-disk config? If so, we can probably do that pretty easily. I could see it being confusing for users though, since changing that setting in the IDE won't do anything if it's set in the config file\n\nIDE setting should still override the config setting", "Oh in that case I think it's probably something that shouldn't be added to the config file.\n\nIDE-specific settings most shouldn't be added to a config file in most cases, especially if they're overridable in IDE.\n\nOffline @kinto0 and I spoke about allowing the IDE to override config file options. We need to talk about it more, but it could be a good idea in the future", "I'm using pyrefly with Zed, and it's quite unfortunate that the diagnostics panel says \"no errors detected in project\" when in fact i know there are errors that just happen to be in files i don't have open in the editor. I'd be willing to try get \"diagnosticMode: workspace\" working in a branch and open a PR, is there any straightforward place to start looking or is it hopeless to try this on my own? ", "> I'm using pyrefly with Zed, and it's quite unfortunate that the diagnostics panel says \"no errors detected in project\" when in fact i know there are errors that just happen to be in files i don't have open in the editor. I'd be willing to try get \"diagnosticMode: workspace\" working in a branch and open a PR, is there any straightforward place to start looking or is it hopeless to try this on my own?\n\nThanks!!! If you want some codepointers, I've laid out how I imagine the implementation should go [here](https://github.com/facebook/pyrefly/pull/664?fbclid=IwY2xjawLeBd9leHRuA2FlbQIxMQBicmlkETFjUlRabmV3Y0lxSDY1VGVZAR5sZF-SGZaHrtj6QRQcY5JGyRYmdAm8i0Lm0cvX-8luhtv-mfylJz1ADVmIZA_aem_vbIkgzjHNh4ih0ZSagxUmg). I don't think it's too difficult unless blockers come up. Happy to help as much as you want or even take over if you need. " ],
      "repository" : {
        "description" : "A fast type checker and IDE for Python",
        "homepage" : "http://pyrefly.org/",
        "name" : "pyrefly",
        "fullName" : "facebook/pyrefly",
        "htmlUrl" : "https://github.com/facebook/pyrefly",
        "gitUrl" : "git://github.com/facebook/pyrefly.git",
        "sshUrl" : "git@github.com:facebook/pyrefly.git",
        "cloneUrl" : "https://github.com/facebook/pyrefly.git",
        "owner" : {
          "login" : "facebook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 121,
        "stargazersCount" : 3222,
        "watchersCount" : 3222,
        "size" : 163435,
        "openIssuesCount" : 212,
        "subscribersCount" : 21,
        "pushedAt" : "2025-07-12T00:16:10Z",
        "languages" : {
          "TypeScript" : 191380,
          "MDX" : 124963,
          "CSS" : 9844,
          "Shell" : 9589,
          "Rust" : 3326419,
          "Starlark" : 1111,
          "JavaScript" : 6980,
          "HTML" : 5099,
          "Ruby" : 73,
          "Python" : 35935
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for Pyright's diagnosticMode: \"workspace\" in Pyrefly to analyze all files in the workspace, not just open files.",
      "validationOrRequirement" : "Implement support for the ",
      "attemptedFixes" : "Ideas were discussed about allowing the IDE to override config file options, and the idea of adding this setting to the config file was raised.",
      "otherNotes" : "Pyright has the following configurable settings when using it with an IDE like Zed, VSCode, etc. Pyright analyzes (and reports errors for) all files in the workspace, as indicated by the config file. If this option is set to ???openFilesOnly???, pyright analyzes only open files.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283695
  }, {
    "issueDTO" : {
      "id" : 2076107098,
      "title" : "Replace edit button with confirm / cancel buttons",
      "url" : "https://github.com/Altinn/altinn-studio/issues/12000",
      "repositoryName" : "Altinn/altinn-studio",
      "description" : "### Description\r\n\r\nI suggest replacing, in edit mode, the pencil icon with confirm / cancel icons.\r\n\r\n### Steps To Reproduce\r\n\r\nhttps://github.com/Altinn/altinn-studio/assets/24462611/d2183ce0-6556-483e-ae0d-94f96ba5375f",
      "updatedAt" : 1752245947.000000000,
      "user" : "mlqn",
      "userHtmlUrl" : "https://github.com/mlqn",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/24462611?v=4",
      "labels" : [ "user-need", "area/text-editor", "kind/user-story", "ux", "status/ready-for-specification", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Do we need a button to close it, or could it close when clicking outside the field?", "@mlqn can i work on this issue?", "@mlqn i would like to work on this issue?\n" ],
      "repository" : {
        "description" : "Next generation open source Altinn platform and applications.",
        "homepage" : "https://docs.altinn.studio",
        "name" : "altinn-studio",
        "fullName" : "Altinn/altinn-studio",
        "htmlUrl" : "https://github.com/Altinn/altinn-studio",
        "gitUrl" : "git://github.com/Altinn/altinn-studio.git",
        "sshUrl" : "git@github.com:Altinn/altinn-studio.git",
        "cloneUrl" : "https://github.com/Altinn/altinn-studio.git",
        "owner" : {
          "login" : "Altinn",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 84,
        "stargazersCount" : 146,
        "watchersCount" : 146,
        "size" : 122030,
        "openIssuesCount" : 827,
        "subscribersCount" : 38,
        "pushedAt" : "2025-07-11T14:25:02Z",
        "languages" : {
          "C#" : 3314927,
          "MDX" : 23663,
          "Smarty" : 1872,
          "Java" : 116870,
          "CSS" : 184603,
          "PLpgSQL" : 4075,
          "Makefile" : 835,
          "Mustache" : 3748,
          "HTML" : 28794,
          "TypeScript" : 7311139,
          "Dockerfile" : 9463,
          "Shell" : 4330,
          "JavaScript" : 350066
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace edit button with confirm/cancel buttons",
      "validationOrRequirement" : "replace edit button with confirm/cancel buttons in edit mode, confirm/cancel icons",
      "attemptedFixes" : "",
      "otherNotes" : "https://github.com/Altinn/altinn-studio/assets/24462611/d2183ce0-6556-483e-ae0d-94f96ba5375f, Do we need a button to close it, or could it close when clicking outside the field?, @mlqn can i work on this issue?, @mlqn i would like to work on this issue?",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283699
  }, {
    "issueDTO" : {
      "id" : 3217027126,
      "title" : "expose a way to build a url for a given resource",
      "url" : "https://github.com/akuity/kargo/issues/4585",
      "repositoryName" : "akuity/kargo",
      "description" : "# Checklist\n\n* [x] I've searched the issue queue to verify this is not a duplicate feature request.\n* [x] I've pasted the output of `kargo version`, if applicable.\n* [x] I've pasted logs, if applicable.\n\n# Proposed Feature\n\nExpose a way to build a URL for a given resource, such as exposing `ctx.UIBaseURL`, or a `url_for` expr function\n\n# Motivation\n\n<!-- Please give examples of your use case. i.e. When would someone use this? -->\n\nI want to build slack messages for deployment notification and include links without having to hardcode the url host in the message.\n\nExample uses:\n\n\"Freight `${{ ctx.targetFreight.name }}` is being promoted to Stage <${{ ctx.UIBaseURL }}/project/${{ ctx.project }}/stage/${{ ctx.stage }}|${{ ctx.stage }}>\"\n\n\"Freight `${{ ctx.targetFreight.name }}` is being promoted to Stage <${{ url_for(ctx.stage) }}|${{ ctx.stage }}>\" (possibly stage_url_for if they need to be differentiated by type to work properly in expr?)",
      "updatedAt" : 1752245843.000000000,
      "user" : "voidlily",
      "userHtmlUrl" : "https://github.com/voidlily",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/221749?v=4",
      "labels" : [ "help-wanted", "size/small", "kind/enhancement", "needs-discussion", "priority/normal", "good first issue", "area/controller" ],
      "state" : "OPEN",
      "comments" : [ "kargo version is 1.6.1", "Some thought needs to go into how exactly we want to expose this, but in general, I think this is a great idea and relatively easy. If @hiddeco and I can agree on an approach, this would be a good first issue for anyone looking to contribute.", "Wonder if it wouldn't be better to offer it behind an expr-lang function, as I can imagine this making the construction of the URL easier to the end user.", "I think _function_ (singular) wouldn't help much, as the following feels quite onerous and brittle:\n\n```\n${{ uiBaseURL() + \"/project/\" + ctx.project + \"/stage/\" + ctx.stage }}`\n```\n\nMeanwhile, more specific functions like `projectURL()`, `stageURL()`, or `promotionURL()` seem like they'd be very straightforward to use.\n\nI _think_ this is roughly what you were thinking @hiddeco? Or not?\n\nI do think pre-defined variables like `ctx.projectURL`, `ctx.stageUrl`, etc. would work quite nicely too. Compared to something like ConfigMap or Secret retrieval where we introduced functions to do retrieval just-in-time to avoid unnecessary overhead when they're _not_ used, I think the overhead of pre-constructing these URLs is low enough to tolerate. (Although I could also be convinced otherwise.)\n\nwdyt?\n\n\n", "The thing I had in mind would be something like:\n\n```\n${{ uiURL(\"project\", ctx.project) }}\n${{ uiURL(\"stage\", ctx.project, ctx.stage) }}\n# ...etc\n```\n\nWhile I agree that predefined variables could be useful, I struggle to think of what they should be called and where they should be placed. Would they be part of metadata, or something by themselves?", "> I struggle to think of what they should be called and where they should be placed\n\nI'd been thinking of adding them to the promotion context, but I'm not married to that.\n\nI don't hate the idea of using functions either, but I wonder if something like `uiStageURL()` would be much easier to use than relying on users to explicitly identify the URL they want to construct is for a Stage, and then provide the correct Project and Stage name arguments. It seems like something highly prone to human error.\n\nOn the other hand, I'm not sure if pre-poulated context entries and/or functions requiring no arguments might turn out to be too limiting. I'm trying to think of reasons you might, for instance, want a step in one Stage's promo process to generate a link for a _different_ Stage. My sense is that's an extreme outlier, but I'm also not so naive as to think someone's not going to be asking for exactly that eventually. \uD83E\uDD14 \n\n\n\n\n" ],
      "repository" : {
        "description" : "Application lifecycle orchestration",
        "homepage" : "https://kargo.io/",
        "name" : "kargo",
        "fullName" : "akuity/kargo",
        "htmlUrl" : "https://github.com/akuity/kargo",
        "gitUrl" : "git://github.com/akuity/kargo.git",
        "sshUrl" : "git@github.com:akuity/kargo.git",
        "cloneUrl" : "https://github.com/akuity/kargo.git",
        "owner" : {
          "login" : "akuity",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 238,
        "stargazersCount" : 2549,
        "watchersCount" : 2549,
        "size" : 80821,
        "openIssuesCount" : 203,
        "subscribersCount" : 26,
        "pushedAt" : "2025-07-11T22:42:38Z",
        "languages" : {
          "TypeScript" : 1920870,
          "Dockerfile" : 4341,
          "Shell" : 15294,
          "CSS" : 535,
          "Starlark" : 6336,
          "Makefile" : 24732,
          "JavaScript" : 6217,
          "Go" : 3808051,
          "Mustache" : 4456,
          "HTML" : 365,
          "Less" : 10832
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Expose a way to build a URL for a given resource, such as exposing ctx.UIBaseURL or a url_for expr function",
      "validationOrRequirement" : "The author wants to expose a way to build a URL for a given resource, such as exposing ctx.UIBaseURL or a url_for expr function. The author thinks this is a great idea and relatively easy, but some thought needs to go into how exactly we want to expose this.",
      "attemptedFixes" : "The author has searched the issue queue to verify this is not a duplicate feature request, and has pasted the output of kargo version and logs, if applicable. The idea is to build a URL for a given resource, such as exposing ctx.UIBaseURL or a url_for expr function.",
      "otherNotes" : "The author wants to build slack messages for deployment notification and include links without having to hardcode the url host in the message. The idea is to expose a way to build a URL for a given resource, such as exposing ctx.UIBaseURL or a url_for expr function.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283706
  }, {
    "issueDTO" : {
      "id" : 3199775535,
      "title" : "\"Not enough funds selected\" disappears when locktime is changed",
      "url" : "https://github.com/trezor/trezor-suite/issues/19960",
      "repositoryName" : "trezor/trezor-suite",
      "description" : "**Describe the bug**\nIf send with not enough funds through coin control selected, `Not enough funds selceted` disappears after locktime is added.\n\n**Info:**\n\n- Suite Version: web, `c855d592ad`\n- Browser: brave 138.1.80.115\n- Browser Installation Method: AUR\n- OS: linux, 6.15.4-arch2-1\n- Bridge + Firmware Version: emulator (trezor-user-env)\n\n**How to reproduce**\n\n1. Open desktop Trezor Suite\n2. Go to \"Send\"\n3. Turn on Coin Control and select one UTXO\n4. Set amount such that its higher then selected UTXO, but lower than wallet total\n5. Add Locktime\n\n**Expected behavior**\n\nThe error stays present.\n\n**Screenshots**\n\nWith locktime:\n\n![Image](https://github.com/user-attachments/assets/698519a8-2bd8-419d-a18a-00cf844c9f15)\n\nWithout locktime:\n\n![Image](https://github.com/user-attachments/assets/5cc13c59-1762-4af2-8953-f800f351eaf3)\n\n**Additional context**\nNote that `Review and Send` is disabled, so there should be an error present.\n",
      "updatedAt" : 1752245769.000000000,
      "user" : "5K1PY",
      "userHtmlUrl" : "https://github.com/5K1PY",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/54771191?v=4",
      "labels" : [ "send", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Caused by unnecessary call of `composeTransaction`:\n\nhttps://github.com/trezor/trezor-suite/blob/bf67a42a885270542bc63bcad8207ade3d4aaa6c/packages/suite/src/views/wallet/send/Options/BitcoinOptions/Locktime/Locktime.tsx#L66" ],
      "repository" : {
        "description" : "Trezor Suite Monorepo",
        "homepage" : "https://trezor.io/trezor-suite",
        "name" : "trezor-suite",
        "fullName" : "trezor/trezor-suite",
        "htmlUrl" : "https://github.com/trezor/trezor-suite",
        "gitUrl" : "git://github.com/trezor/trezor-suite.git",
        "sshUrl" : "git@github.com:trezor/trezor-suite.git",
        "cloneUrl" : "https://github.com/trezor/trezor-suite.git",
        "owner" : {
          "login" : "trezor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 303,
        "stargazersCount" : 866,
        "watchersCount" : 866,
        "size" : 953910,
        "openIssuesCount" : 1094,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T21:02:32Z",
        "languages" : {
          "TypeScript" : 20463148,
          "MDX" : 273490,
          "Dockerfile" : 7355,
          "CSS" : 73976,
          "Shell" : 51701,
          "Rust" : 49831,
          "JavaScript" : 432120,
          "HTML" : 249002,
          "Swift" : 1600,
          "Nix" : 6990,
          "Ruby" : 783,
          "Kotlin" : 22878
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The error 'Not enough funds selected' disappears when locktime is changed",
      "validationOrRequirement" : "Error stays present",
      "attemptedFixes" : "Caused by unnecessary call of composeTransaction",
      "otherNotes" : "Note that Review and Send is disabled, so there should be an error present.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283709
  }, {
    "issueDTO" : {
      "id" : 3153627559,
      "title" : "[BUG] Some structure scores fail for integer nodes",
      "url" : "https://github.com/pgmpy/pgmpy/issues/2227",
      "repositoryName" : "pgmpy/pgmpy",
      "description" : "**Describe the bug**\n\nScores that use log likelihood fail when the data/model has integer nodes (even when converted to strings). When nodes are integers, the log likelihood calculations run into other errors.\n\n**To Reproduce**\n\n<!--\nAdd a Minimal, Complete, and Verifiable example (for more details, see e.g. https://stackoverflow.com/help/mcve\n\nIf the code is too long, feel free to put it in a public gist and link it in the issue: https://gist.github.com\n-->\n\n```python\nIn [1]: from pgmpy.estimators import LogLikelihoodGauss\n\nIn [2]: from pgmpy.models import DiscreteBayesianNetwork\n\nIn [3]: import numpy as np\n\nIn [4]: import pandas as pd\n\nIn [5]: data = pd.DataFrame({\"0\": np.random.randn(100), \"1\": np.random.randn(100), \"2\": np.random.randn(100)})\n\nIn [6]: model = DiscreteBayesianNetwork([(\"0\", \"1\"), (\"1\", \"2\")])\n\nIn [7]: score = LogLikelihoodGauss(data).score(model)\nINFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n {'0': 'N', '1': 'N', '2': 'N'}\n.\n.\n.\nFile pgmpy\\.venv\\Lib\\site-packages\\patsy\\highlevel.py:312, in dmatrices(formula_like, data, eval_env, NA_action, return_type)\n    309 (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n    310                                   NA_action, return_type)\n    311 if lhs.shape[1] == 0:\n--> 312     raise PatsyError(\"model is missing required outcome variables\")\n    313 return (lhs, rhs)\n\nPatsyError: model is missing required outcome variables\n```\n\n**Expected behavior**\n<!--\nA clear and concise description of what you expected to happen.\n-->\nAn error should be raised as there does not seem to be a workaround. Or some other fix if possible.\n\n**Additional context**\n<!--\nAdd any other context about the problem here.\n-->\nOther scores that do not use `glm` from `statsmodels` do seem to work with integer columns.\n\n",
      "updatedAt" : 1752245695.000000000,
      "user" : "Nimish-4",
      "userHtmlUrl" : "https://github.com/Nimish-4",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/90456805?v=4",
      "labels" : [ "Good First Issue", "category: Learning" ],
      "state" : "OPEN",
      "comments" : [ "The issue seems to be at Line 535 and 538 in StructureScore.py. We construct the GLM model using the formula, which is a string, and hence statsmodels is unable to distinguish between the variable name or a constant value in the formula. A potential solution could be to avoid defining the model using the formula and instead use the standard statsmodels API.", "Yep, that seems to be the issue. Will take it up after my current PRs are resolved, if it is not fixed by then.", "hi @ankurankan if you don't mind may I take up the responsibility for fixing this bug?\n", "Thanks!!", "Hi @ankurankan pardon me for my naiveness but I am not able to possibly reproduce the error on my end due to the fact that I cannot locate the `LogLikelihoodGauss` file in the estimators subdirectory or anywhere as a matter of fact. Am i missing something here? I will be glad to receive a little directions. Thank you so much", "@badger751 The LogLikelihoodGauss class is here: https://github.com/pgmpy/pgmpy/blob/dev/pgmpy/estimators/StructureScore.py#L531", "Ok got thank you so much", "@badger751 Are you still working on this? Let up know if you need any help with it.", "Hi,\r\nYes i am still on the issue i may have some doubt but i am trying my best\r\nto solve them on my own really sorry for the delay i will fix it asap and\r\nincase I am stuck somewhere I will let you know very sorry again for the\r\ndelay.\r\n\r\nThanks for bearing me\r\n\r\nOn Sat, Jul 5, 2025, 22:21 Ankur Ankan ***@***.***> wrote:\r\n\r\n> *ankurankan* left a comment (pgmpy/pgmpy#2227)\r\n> <https://github.com/pgmpy/pgmpy/issues/2227#issuecomment-3039351050>\r\n>\r\n> @badger751 <https://github.com/badger751> Are you still working on this?\r\n> Let up know if you need any help with it.\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/pgmpy/pgmpy/issues/2227#issuecomment-3039351050>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AQLMK2IZHOOXRVOXQTJ7UQD3G77BDAVCNFSM6AAAAAB7QKCHW2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZTAMZZGM2TCMBVGA>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n", "Hi @ankurankan apologies for the delay. \nI went through the code and decided to do the following approach - \nOld **LogLikelihoodGauss** - \n```\n`class LogLikelihoodGauss(StructureScore):\n    def __init__(self, data, **kwargs):\n        super(LogLikelihoodGauss, self).__init__(data, **kwargs)\n\n    def _log_likelihood(self, variable, parents):\n        if len(parents) == 0:\n            glm_model = smf.glm(formula=f\"{variable} ~ 1\", data=self.data).fit()\n        else:\n            glm_model = smf.glm(\n                formula=f\"{variable} ~ {' + '.join(parents)}\", data=self.data\n            ).fit()\n\n        return (glm_model.llf, glm_model.df_model)\n\n    def local_score(self, variable, parents):\n        ll, df_model = self._log_likelihood(variable=variable, parents=parents)\n\n        return ll`\n```\n\nModified **LogLikelihoodGauss** - \n\n```\n\n`import statsmodels.api as sm\nimport numpy as np\nimport pandas as pd\n\nclass LogLikelihoodGauss(StructureScore):\n    def __init__(self, data, **kwargs):\n        if data is None:\n            raise ValueError(\"Data cannot be None\")\n        if not isinstance(data, pd.DataFrame):\n            raise TypeError(\"Data must be a pandas.DataFrame\")\n        super(LogLikelihoodGauss, self).__init__(data, **kwargs)\n\n    def _log_likelihood(self, variable, parents):\n        if self.data is None or variable not in self.data.columns:\n            raise ValueError(f\"Variable '{variable}' not found in data\")\n        y = self.data[variable]\n        if not pd.api.types.is_numeric_dtype(y):\n            raise ValueError(f\"Variable '{variable}' must be numeric\")\n        if y.isna().any():\n            raise ValueError(f\"Variable '{variable}' contains missing values\")\n        \n        if len(parents) == 0:\n            X = np.ones((len(y), 1))\n            glm_model = sm.GLM(y, X, family=sm.families.Gaussian()).fit()\n        else:\n            for parent in parents:\n                if parent not in self.data.columns:\n                    raise ValueError(f\"Parent variable '{parent}' not found in data\")\n                if not pd.api.types.is_numeric_dtype(self.data[parent]):\n                    raise ValueError(f\"Parent variable '{parent}' must be numeric\")\n                if self.data[parent].isna().any():\n                    raise ValueError(f\"Parent variable '{parent}' contains missing values\")\n            X = self.data[list(parents)].copy()\n            X = sm.add_constant(X)\n            glm_model = sm.GLM(y, X, family=sm.families.Gaussian()).fit()\n        return (glm_model.llf, glm_model.df_model)\n\n    def local_score(self, variable, parents):\n        ll, df_model = self._log_likelihood(variable=variable, parents=parents)\n        return ll`\n\n```\n### Change - \n\n Explicitly imported certain dependencies to support the  `sm.GLF ` approach. \n\n### Impact - \n\nImproved the addressing capabilities for type checking, patsy error and categoricalDtype issue \n\n### Change - \n\n Instead of using formula based interface (`f\"{variable} ~ 1\" or f\"{variable} ~ {' + '.join(parents)}`) relying on patsy, I replaced it with sm.GLM for constructing the design matrix mannually\n\n### Impact - \n\n Eliminates PatsyError caused by patsy failing to parse numeric or ambiguous column names (e.g., \"0\", \"1\").\n\n### Change - \n\n Added comprehensive validation for `self.data`, `variable` and `parents`.\n\n### Impact - \n\n Prevents typeError and categorical errors fixing runtime failures \n\n### Overall impact - \n \n **New test file for validating overall impact ** - \n\n```\n\n`import unittest\nimport pandas as pd\nimport numpy as np\nfrom pgmpy.estimators import LogLikelihoodGauss\nfrom pgmpy.models import DiscreteBayesianNetwork\n\nclass TestLogLikelihoodGaussFix(unittest.TestCase):\n    def setUp(self):\n        # Create a small Gaussian dataset with alphanumeric column names\n        self.data_alpha = pd.DataFrame({\n            \"A\": np.random.randn(100),\n            \"B\": np.random.randn(100),\n            \"C\": np.random.randn(100)\n        })\n        # Create a dataset with numeric column names (to test PatsyError fix)\n        self.data_numeric = pd.DataFrame({\n            \"0\": np.random.randn(100),\n            \"1\": np.random.randn(100),\n            \"2\": np.random.randn(100)\n        })\n        # Create a dataset with non-numeric data for error testing\n        self.data_invalid = pd.DataFrame({\n            \"A\": [\"x\", \"y\", \"z\"],\n            \"B\": np.random.randn(3),\n            \"C\": np.random.randn(3)\n        })\n        # Create a dataset with NaNs for error testing\n        self.data_nans = pd.DataFrame({\n            \"A\": np.random.randn(100),\n            \"B\": np.random.randn(100),\n            \"C\": np.array([np.nan] + [np.random.randn() for _ in range(99)])\n        })\n        self.model_alpha = DiscreteBayesianNetwork([(\"A\", \"C\"), (\"B\", \"C\")])\n        self.model_numeric = DiscreteBayesianNetwork([(\"0\", \"2\"), (\"1\", \"2\")])\n\n    def test_local_score_alphanumeric(self):\n        \"\"\"Test local_score with alphanumeric column names.\"\"\"\n        scorer = LogLikelihoodGauss(self.data_alpha)\n        ll_a = scorer.local_score(\"A\", parents=[])\n        self.assertIsInstance(ll_a, float, \"Log-likelihood should be a float\")\n        self.assertFalse(np.isnan(ll_a), \"Log-likelihood should not be NaN\")\n        ll_c = scorer.local_score(\"C\", parents=[\"A\", \"B\"])\n        self.assertIsInstance(ll_c, float, \"Log-likelihood should be a float\")\n        self.assertFalse(np.isnan(ll_c), \"Log-likelihood should not be NaN\")\n\n    def test_local_score_numeric(self):\n        \"\"\"Test local_score with numeric column names (fixes PatsyError).\"\"\"\n        scorer = LogLikelihoodGauss(self.data_numeric)\n        \n        ll_0 = scorer.local_score(\"0\", parents=[])\n        self.assertIsInstance(ll_0, float, \"Log-likelihood should be a float\")\n        self.assertFalse(np.isnan(ll_0), \"Log-likelihood should not be NaN\")\n                ll_2 = scorer.local_score(\"2\", parents=[\"0\", \"1\"])\n        self.assertIsInstance(ll_2, float, \"Log-likelihood should be a float\")\n        self.assertFalse(np.isnan(ll_2), \"Log-likelihood should not be NaN\")\n\n    def test_score_model(self):\n        \"\"\"Test score method with both alphanumeric and numeric column names.\"\"\"\n        \n        scorer_alpha = LogLikelihoodGauss(self.data_alpha)\n        score_alpha = scorer_alpha.score(self.model_alpha)\n        self.assertIsInstance(score_alpha, float, \"Model score should be a float\")\n        self.assertFalse(np.isnan(score_alpha), \"Model score should not be NaN\")\n        \n        scorer_numeric = LogLikelihoodGauss(self.data_numeric)\n        score_numeric = scorer_numeric.score(self.model_numeric)\n        self.assertIsInstance(score_numeric, float, \"Model score should be a float\")\n        self.assertFalse(np.isnan(score_numeric), \"Model score should not be NaN\")\n\n    def test_invalid_dtype(self):\n        \"\"\"Test error handling for non-numeric data.\"\"\"\n        scorer = LogLikelihoodGauss(self.data_invalid)\n        with self.assertRaises(ValueError, msg=\"Should raise ValueError for non-numeric variable\"):\n            scorer.local_score(\"A\", parents=[\"B\"])\n\n    def test_missing_values(self):\n        \"\"\"Test error handling for NaN values.\"\"\"\n        scorer = LogLikelihoodGauss(self.data_nans)\n        with self.assertRaises(ValueError, msg=\"Should raise ValueError for missing values\"):\n            scorer.local_score(\"C\", parents=[\"A\", \"B\"])\n\n    def tearDown(self):\n        \"\"\"Clean up test data.\"\"\"\n        del self.data_alpha\n        del self.data_numeric\n        del self.data_invalid\n        del self.data_nans\n        del self.model_alpha\n        del self.model_numeric`\n\n\n```\n  ### Results of the 5 tests  -  \n\n **Old -** \n```\n                                                         short test summary info \n\nFAILED pgmpy/tests/test_estimators/test_new.py::TestLogLikelihoodGaussFix::test_local_score_numeric - patsy.PatsyError: model is missing required outcome variables\nFAILED pgmpy/tests/test_estimators/test_new.py::TestLogLikelihoodGaussFix::test_missing_values - AssertionError: ValueError not raised : Should raise ValueError for missing values\nFAILED pgmpy/tests/test_estimators/test_new.py::TestLogLikelihoodGaussFix::test_score_model - patsy.PatsyError: model is missing required outcome variables\n                                                        \n                                                         3 failed, 2 passed in 4.27s \n\n\n```\n**New -**  \n\n```\n\nplatform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0\nrootdir: /Users/achintyapandey/Documents/pgmpy\nconfigfile: pytest.ini\nplugins: xdist-3.7.0, xdoctest-1.2.0, cov-6.2.1\ncollected 5 items                                                                                    \n\npgmpy/tests/test_estimators/test_new.py .....                                                  [100%]\n\n                                                                 5 passed in 4.12s \n\n```\nWould love to receive guidance on correcting the mistakes I may have made or what to do next. \n\nThank you.\n", "@ankurankan Is the approach not optimal?\n", "@badger751 Sorry for the delay in getting back. I think the changes are good, I would however, suggest not adding the checks in the LogLikelihood method. The scoring methods can be called thousands of times from the structure learning algorithms, so adding these checks can have a significant impact on the runtime of the algorithms. Could you please create a PR with the changes?" ],
      "repository" : {
        "description" : "Python Library for Causal and Probabilistic Modeling using Bayesian Networks",
        "homepage" : "https://pgmpy.org/",
        "name" : "pgmpy",
        "fullName" : "pgmpy/pgmpy",
        "htmlUrl" : "https://github.com/pgmpy/pgmpy",
        "gitUrl" : "git://github.com/pgmpy/pgmpy.git",
        "sshUrl" : "git@github.com:pgmpy/pgmpy.git",
        "cloneUrl" : "https://github.com/pgmpy/pgmpy.git",
        "owner" : {
          "login" : "pgmpy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 860,
        "stargazersCount" : 2996,
        "watchersCount" : 2996,
        "size" : 14026,
        "openIssuesCount" : 335,
        "subscribersCount" : 75,
        "pushedAt" : "2025-07-11T00:02:45Z",
        "languages" : {
          "Shell" : 7460,
          "Python" : 2580753
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the scores that use log likelihood failing when the data/model has integer nodes.",
      "validationOrRequirement" : "The validation includes checking if the data is None or not a pandas DataFrame, if the variable is not found in the data, if the variable is not numeric, and if the variable contains missing values.",
      "attemptedFixes" : "The issue was fixed by modifying the LogLikelihoodGauss class. The changes include explicit import of certain dependencies, adding comprehensive validation for self.data, variable, and parents, and replacing the formula based interface with sm.GLM for constructing the design matrix manually.",
      "otherNotes" : "The issue is about scores that use log likelihood failing when the data/model has integer nodes. The problem is that statsmodels is unable to distinguish between the variable name or a constant value in the formula. A potential solution is to avoid defining the model using the formula and instead use the standard statsmodels API. The fix involves replacing the formula based interface with sm.GLM for constructing the design matrix manually.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283717
  }, {
    "issueDTO" : {
      "id" : 3223193278,
      "title" : "[Task] spring ai alibaba playground Dockerfile ??????",
      "url" : "https://github.com/alibaba/spring-ai-alibaba/issues/1574",
      "repositoryName" : "alibaba/spring-ai-alibaba",
      "description" : "### Description\n\n1. ?????????????????????\n2. ??? #1426  ??????\n\n### Task List\n\n_No response_",
      "updatedAt" : 1752245684.000000000,
      "user" : "yuluo-yx",
      "userHtmlUrl" : "https://github.com/yuluo-yx",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/77964041?v=4",
      "labels" : [ "area/example", "kind/task", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/area example" ],
      "repository" : {
        "description" : "Agentic AI Framework for Java Developers",
        "homepage" : "https://java2ai.com",
        "name" : "spring-ai-alibaba",
        "fullName" : "alibaba/spring-ai-alibaba",
        "htmlUrl" : "https://github.com/alibaba/spring-ai-alibaba",
        "gitUrl" : "git://github.com/alibaba/spring-ai-alibaba.git",
        "sshUrl" : "git@github.com:alibaba/spring-ai-alibaba.git",
        "cloneUrl" : "https://github.com/alibaba/spring-ai-alibaba.git",
        "owner" : {
          "login" : "alibaba",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 938,
        "stargazersCount" : 4749,
        "watchersCount" : 4749,
        "size" : 146395,
        "openIssuesCount" : 259,
        "subscribersCount" : 62,
        "pushedAt" : "2025-07-11T16:12:30Z",
        "languages" : {
          "Java" : 5573403,
          "CSS" : 26756,
          "Makefile" : 7848,
          "TeX" : 4902,
          "Vue" : 410310,
          "Mustache" : 3851,
          "HTML" : 7375,
          "TypeScript" : 519129,
          "Dockerfile" : 2057,
          "Shell" : 4950,
          "Smalltalk" : 11272,
          "Batchfile" : 3003,
          "JavaScript" : 34104,
          "Less" : 6998,
          "Python" : 3892
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Optimize the Dockerfile for the spring ai alibaba playground to reduce the build package size.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description.",
      "otherNotes" : "This issue is related to #1426 and aims to optimize the Dockerfile for the spring ai alibaba playground.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283719
  }, {
    "issueDTO" : {
      "id" : 3217537489,
      "title" : "Remove no-throw-error ESLint suppressions in @liam-hq/ui",
      "url" : "https://github.com/liam-hq/liam/issues/2466",
      "repositoryName" : "liam-hq/liam",
      "description" : "## Summary\n\nThis issue tracks the removal of ESLint suppressions for the `no-throw-error/no-throw-error` rule in the `@liam-hq/ui` package.\n\n## Context\n\nPR #2442 introduced a custom ESLint rule that prohibits `throw new Error()` statements and encourages the use of neverthrow Result types instead. To enable incremental adoption, bulk suppressions were applied to existing violations.\n\n## Task\n\nReplace all `throw new Error()` statements in the `frontend/packages/ui/` directory with neverthrow Result types (`err`, `ok`, `ResultAsync`) imported from \"neverthrow\".\n\n## Files to update\n\n- `frontend/packages/ui/eslint-suppressions.json` - Contains 3 suppressed violations\n\n## Steps\n\n1. Review the suppressed violations in `frontend/packages/ui/eslint-suppressions.json`\n2. Replace `throw new Error()` statements with appropriate neverthrow Result types\n3. Import neverthrow types: `import { err, ok, ResultAsync } from \"neverthrow\"`\n4. Update function return types to use `Result<T, E>` or `ResultAsync<T, E>`\n5. Update calling code to handle Result types appropriately\n6. Run `pnpm lint:eslint --prune-suppressions` to update eslint-suppressions.json after modifications\n7. Verify all suppressions are resolved\n\n## Related\n\n- Resolves: #2442",
      "updatedAt" : 1752245672.000000000,
      "user" : "claude[bot]",
      "userHtmlUrl" : "https://github.com/apps/claude",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/1236702?v=4",
      "labels" : [ "neverthrow", "eslint", "tech debt", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Automatically generates beautiful and easy-to-read ER diagrams from your database.",
        "homepage" : "https://liambx.com",
        "name" : "liam",
        "fullName" : "liam-hq/liam",
        "htmlUrl" : "https://github.com/liam-hq/liam",
        "gitUrl" : "git://github.com/liam-hq/liam.git",
        "sshUrl" : "git@github.com:liam-hq/liam.git",
        "cloneUrl" : "https://github.com/liam-hq/liam.git",
        "owner" : {
          "login" : "liam-hq",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 4149,
        "watchersCount" : 4149,
        "size" : 128286,
        "openIssuesCount" : 86,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-12T00:59:43Z",
        "languages" : {
          "TypeScript" : 1870996,
          "MDX" : 82980,
          "CSS" : 229518,
          "Shell" : 5433,
          "PLpgSQL" : 360220,
          "Handlebars" : 695,
          "JavaScript" : 42995,
          "HTML" : 985,
          "Ruby" : 7830
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove no-throw-error ESLint suppressions in @liam-hq/ui",
      "validationOrRequirement" : "Replace all `throw new Error()` statements with appropriate neverthrow Result types, import neverthrow types, update function return types to use `Result<T, E>` or `ResultAsync<T, E>`, and update calling code to handle Result types appropriately.",
      "attemptedFixes" : "Replace all `throw new Error()` statements in the `frontend/packages/ui/` directory with neverthrow Result types (`err`, `ok`, `ResultAsync`) imported from 'neverthrow'.",
      "otherNotes" : "PR #2442 introduced a custom ESLint rule, bulk suppressions were applied to existing violations, and the issue tracks the removal of ESLint suppressions for the `no-throw-error/no-throw-error` rule in the `@liam-hq/ui` package.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283725
  }, {
    "issueDTO" : {
      "id" : 3104410397,
      "title" : "Extend `/health` to add instances",
      "url" : "https://github.com/ai-dynamo/dynamo/issues/1312",
      "repositoryName" : "ai-dynamo/dynamo",
      "description" : "### Feature request\n\nWe have endpoints to list models (OpenAI spec), endpoints (#1037 ) but not yet instances. I was expecting we'd have some kind of cluster management system that handled that, but it seems we need this sooner.\n\nExtend the `/health` endpoint to include instances. Add a function in `lib/runtime` to list them in etcd - see `component.rs` `list_instances` for an example (that one only lists the instances of a Component).\n\n\n### Describe the problem you're encountering\n\n/\n\n### Describe alternatives you've tried\n\n_No response_",
      "updatedAt" : 1752245648.000000000,
      "user" : "grahamking",
      "userHtmlUrl" : "https://github.com/grahamking",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/180418?v=4",
      "labels" : [ "language::rust", "dynamo-runtime", "backlog", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "May I  try it as my first issue, thanks\n/assign ", "/assign\n", "Please both go for it! Even if we don't merge your contribution it will be a nice chance to explore the code base and maybe improve your Rust.", "Hi,\n\nI'd like to pick up this issue (#1312) and work on extending the `/health` endpoint to include instance listings.\n\nBefore I dive in, could you please provide any updated information or context related to this feature request? Specifically:\n* Has any preliminary work been started or design decisions made since this issue was opened?\n* Are there any specific details or status fields that should be included for each instance in the `/health` response?\n\nAlso, what would be the recommended approach for testing this new functionality?\n\nThanks!", "Go for it. No changes since the issue was posted. Include a unit test.", "Hi @grahamking, I've been trying to build and run the project over the past couple of days on both my Mac and a Linux VM, but I keep encountering build errors and running into memory issues. Any guidance on possible alternatives or workarounds would be greatly appreciated.\n\nIn case I can't work on this issue, I'm still very interested in contributing and would love to help with the documentation. I've added a comment with a few questions to this DOC issue ??? would appreciate it if you could take a look: https://github.com/ai-dynamo/dynamo/issues/559\n\nThanks!", ">  keep encountering build errors and running into memory issues\n\nMake a new issue with what you're running and the output you're seeing, and someone may be able to help.", "Hey @grahamking, \n\nAttempting to open a PR for this. I have a question what is the correct way to access runtime on http service. I saw the comment on old [PR ](https://github.com/ai-dynamo/dynamo/pull/1384#discussion_r2143683547) it mentioned this isn't the right way to pass the runtime.\n\nIn my case, I need access to the runtime specifically to retrieve the `etcd_client `which is required for querying all registered instances using a prefix-based etcd query to implement the `list_all_instances` functionality that aggregates all instances.\n\nWould appreciate any guidance on whether injecting just the runtime into state is preferred or if we should expose a more generic mechanism for runtime-level operations within the HTTP layer." ],
      "repository" : {
        "description" : "A Datacenter Scale Distributed Inference Serving Framework",
        "homepage" : "https://docs.nvidia.com/dynamo/latest",
        "name" : "dynamo",
        "fullName" : "ai-dynamo/dynamo",
        "htmlUrl" : "https://github.com/ai-dynamo/dynamo",
        "gitUrl" : "git://github.com/ai-dynamo/dynamo.git",
        "sshUrl" : "git@github.com:ai-dynamo/dynamo.git",
        "cloneUrl" : "https://github.com/ai-dynamo/dynamo.git",
        "owner" : {
          "login" : "ai-dynamo",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 482,
        "stargazersCount" : 4455,
        "watchersCount" : 4455,
        "size" : 43885,
        "openIssuesCount" : 324,
        "subscribersCount" : 61,
        "pushedAt" : "2025-07-12T00:53:53Z",
        "languages" : {
          "Smarty" : 5903,
          "Shell" : 81634,
          "Rust" : 2607570,
          "Makefile" : 11313,
          "Earthly" : 8089,
          "Go" : 262554,
          "Python" : 702890,
          "Cuda" : 26267
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Extend the /health endpoint to include instances, and add a function in lib/runtime to list them in etcd.",
      "validationOrRequirement" : "The issue requires a function in lib/runtime to list instances in etcd, and a specific approach for testing the new functionality.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about extending the /health endpoint to include instances. The author is looking for guidance on preliminary work, design decisions, and testing approach. There are also comments about build errors and memory issues, and a suggestion to create a new issue for it. Additionally, a question about accessing the runtime on the HTTP service is asked.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283730
  }, {
    "issueDTO" : {
      "id" : 3220623076,
      "title" : "[MAINT] Refactor initWorkflow to reduce function complexity",
      "url" : "https://github.com/nipoppy/nipoppy/issues/683",
      "repositoryName" : "nipoppy/nipoppy",
      "description" : "Flake8 error from #682 \n```\nnipoppy/workflows/dataset_init.py:58:5: C901 'InitWorkflow.run_main' is too complex (13)\n```\n\nhttps://github.com/asmacdo/nipoppy/blob/89322e59f12cd0c3235b24b85f9841ed3f76df2b/nipoppy/workflows/dataset_init.py#L58",
      "updatedAt" : 1752245580.000000000,
      "user" : "mathdugre",
      "userHtmlUrl" : "https://github.com/mathdugre",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16450132?v=4",
      "labels" : [ "T.2 - Maintenance", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Lightweight framework for neuroimaging-clinical data organization/processing",
        "homepage" : "https://nipoppy.readthedocs.io/en/latest/",
        "name" : "nipoppy",
        "fullName" : "nipoppy/nipoppy",
        "htmlUrl" : "https://github.com/nipoppy/nipoppy",
        "gitUrl" : "git://github.com/nipoppy/nipoppy.git",
        "sshUrl" : "git@github.com:nipoppy/nipoppy.git",
        "cloneUrl" : "https://github.com/nipoppy/nipoppy.git",
        "owner" : {
          "login" : "nipoppy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 24,
        "stargazersCount" : 29,
        "watchersCount" : 29,
        "size" : 17515,
        "openIssuesCount" : 101,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-10T18:06:03Z",
        "languages" : {
          "Shell" : 2994,
          "Python" : 634146
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor initWorkflow to resolve Flake8 error",
      "validationOrRequirement" : "Reduce function complexity",
      "attemptedFixes" : "",
      "otherNotes" : "Issue related to Flake8 error in dataset_init.py file, line 58, with a complexity score of 13.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283732
  }, {
    "issueDTO" : {
      "id" : 3166551722,
      "title" : "SSL mode support for importer",
      "url" : "https://github.com/hiero-ledger/hiero-mirror-node/issues/11439",
      "repositoryName" : "hiero-ledger/hiero-mirror-node",
      "description" : "Can we have `hiero.mirror.importer.db.sslMode` like we have for other components?",
      "updatedAt" : 1752245503.000000000,
      "user" : "exodus-justinz",
      "userHtmlUrl" : "https://github.com/exodus-justinz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/109195976?v=4",
      "labels" : [ "importer", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I will work on this ticket" ],
      "repository" : {
        "description" : "Hiero Mirror Node archives data from consensus nodes and serves it via an API",
        "homepage" : "",
        "name" : "hiero-mirror-node",
        "fullName" : "hiero-ledger/hiero-mirror-node",
        "htmlUrl" : "https://github.com/hiero-ledger/hiero-mirror-node",
        "gitUrl" : "git://github.com/hiero-ledger/hiero-mirror-node.git",
        "sshUrl" : "git@github.com:hiero-ledger/hiero-mirror-node.git",
        "cloneUrl" : "https://github.com/hiero-ledger/hiero-mirror-node.git",
        "owner" : {
          "login" : "hiero-ledger",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 122,
        "stargazersCount" : 170,
        "watchersCount" : 170,
        "size" : 644394,
        "openIssuesCount" : 222,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-11T21:44:38Z",
        "languages" : {
          "Java" : 12084698,
          "Dockerfile" : 12554,
          "Shell" : 98576,
          "Solidity" : 617790,
          "Gherkin" : 71940,
          "PLpgSQL" : 87384,
          "JavaScript" : 1723385,
          "Go" : 501943,
          "Mustache" : 24547,
          "Kotlin" : 4328,
          "Python" : 1445
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement SSL mode support for importer",
      "validationOrRequirement" : "hiero.mirror.importer.db.sslMode like other components",
      "attemptedFixes" : "",
      "otherNotes" : "I will work on this ticket",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283734
  }, {
    "issueDTO" : {
      "id" : 2993814161,
      "title" : "Refactor setter methods in `TestingEventBuilder`",
      "url" : "https://github.com/hiero-ledger/hiero-consensus-node/issues/18833",
      "repositoryName" : "hiero-ledger/hiero-consensus-node",
      "description" : "## \uD83C\uDD95\uD83D\uDC25 First Timers Only\n\nThis issue is reserved for people who have never contributed to [Hedera](https://hedera.com) or any open source project in general.\nWe know that creating a pull request (PR) is a major barrier for new contributors.\nThe goal of this issue and all other issues labeled by [**'good first issue'**](https://github.com/issues?q=is%3Aopen+is%3Aissue+org%3Ahashgraph+archived%3Afalse+label%3A%22good+first+issue%22+) is to help you make your first contribution to Hedera.\n\n## \uD83D\uDC7E Description of the issue\n\nThe `TestingEventBuilder` class has many setter methods that return `this`. Such methods are usually named `withThisValue()` instead of `setThisValue()` because methods that start with `set` should be simple void setters. This ticket is to refactor all `set` methods in `TestingEventBuilder` to `with` methods.\n\n### Steps to reproduce\n\nSee the `TestingEventBuilder.java` class. Observe the set methods that return `this`.\n\n### Proposed Solution:\n\nRefactor the `set` methods to `with`. Example: `setTimeCreated(...)` should be refactored to `withTimeCreated(...)`. All other aspects of the method definition should remain unchanged.\n\n## \uD83D\uDCCB Step by step guide to do a contribution\n\nIf you have never contributed to an open source project at GitHub, the following step-by-step guide will introduce you to the workflow. More information and concrete samples for shell commands for each step can be found in our [CONTRIBUTING.md](https://github.com/hashgraph/.github/blob/main/CONTRIBUTING.md) file.\nA more detailed general documentation of the GitHub PR workflow can be found [here](https://github.com/firstcontributions/first-contributions/blob/master/README.md).\n\n- [ ] **Claim this issue:** Comment below that you are interested in working on the issue\n- [ ] **Wait for assignment:** A community member with the given rights will add you as an assignee of the issue\n- [ ] **Fork the repository:** You can do that in GitHub (by simply clicking the 'fork' button).\n- [ ] **Check out the forked repository**\n- [ ] **Create a feature branch** for the issue. We do not have a hard naming definition for branches but it is best practice to prefix the branch name with the issue id.\n- [ ] **Solve the issue** in your branch.\n- [ ] **Commit your changes:** Here, it is needed to add `sign-off` information to the commit to accept the \"Developer Certificate of Origin\" (https://developercertificate.org). More details can be found in our [CONTRIBUTING.md](https://github.com/hashgraph/.github/blob/main/CONTRIBUTING.md)\n- [ ] **Start a Pull Request (PR)**: We have a pattern for naming pull requests that a GitHub Action checks. We use that pattern to support the creation of automatic release notes.\n- [ ] **Check GitHub Actions:** Several GitHub Actions will be triggered automatically for each PR. If a GitHub Action fails and you do not understand the cause of that error do not hesitate to add a comment to the PR and ask the Hedera developer community for support.\n- [ ] **Wait for reviews:** Members of the Hedera developer community will review your PR. If a reviewer finds any missing pieces or a problem, he or she will start a discussion with you and describe the next steps for solving the problem.\n- [ ] **You did it \uD83C\uDF89:** We will merge the fix in the develop branch. Thanks for being part of the Hedera community as an open-source contributor ??????\n\n## \uD83C\uDF89 Contribute to Hacktoberfest\n\nSolve this issue as part of the [Hacktoberfest](https://hacktoberfest.digitalocean.com) event and get a chance to receive cool goodies like a T-Shirt. \uD83C\uDFBD\n\n## \uD83E\uDD14 Additional Information\n\nIf you have any questions, just ask us directly in this issue by adding a comment. You can join our community chat at [Discord](https://hedera.com/discord). A general manual about open-source contributions can be found [here](https://github.com/firstcontributions/first-contributions/blob/master/README.md).",
      "updatedAt" : 1752245399.000000000,
      "user" : "poulok",
      "userHtmlUrl" : "https://github.com/poulok",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82919061?v=4",
      "labels" : [ "Good First Issue", "Tech Debt Reduced" ],
      "state" : "OPEN",
      "comments" : [ "Hi, i'm very interest in take this issue for solve.", "@ladracu2001 thank you for your interest! You are now assigned.", "Thanks a lot! I'm already working on @poulok " ],
      "repository" : {
        "description" : "Crypto, token, consensus, file, and smart contract services for a Hiero based network",
        "homepage" : "",
        "name" : "hiero-consensus-node",
        "fullName" : "hiero-ledger/hiero-consensus-node",
        "htmlUrl" : "https://github.com/hiero-ledger/hiero-consensus-node",
        "gitUrl" : "git://github.com/hiero-ledger/hiero-consensus-node.git",
        "sshUrl" : "git@github.com:hiero-ledger/hiero-consensus-node.git",
        "cloneUrl" : "https://github.com/hiero-ledger/hiero-consensus-node.git",
        "owner" : {
          "login" : "hiero-ledger",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 161,
        "stargazersCount" : 341,
        "watchersCount" : 341,
        "size" : 510726,
        "openIssuesCount" : 1267,
        "subscribersCount" : 41,
        "pushedAt" : "2025-07-12T00:22:10Z",
        "languages" : {
          "Java" : 42954535,
          "Dockerfile" : 43725,
          "Shell" : 92407,
          "Solidity" : 888317,
          "Batchfile" : 7165,
          "ANTLR" : 29650,
          "HTML" : 626756,
          "Python" : 7861
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor setter methods in `TestingEventBuilder` to `with` methods for new contributors to Hedera",
      "validationOrRequirement" : "Refactor `set` methods to `with` methods. Example: `setTimeCreated(...)` should be refactored to `withTimeCreated(...)`",
      "attemptedFixes" : "None mentioned in the issue description",
      "otherNotes" : "This issue is reserved for people who have never contributed to Hedera or any open source project. It is to refactor setter methods in `TestingEventBuilder` to `with` methods.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283738
  }, {
    "issueDTO" : {
      "id" : 3103287634,
      "title" : "??????????????????????????????????????????????????????qwen-audio-turbo??????",
      "url" : "https://github.com/alibaba/spring-ai-alibaba/issues/1043",
      "repositoryName" : "alibaba/spring-ai-alibaba",
      "description" : "??????????????????????????????????????????????????????qwen-audio-turbo??????\n\nMessageFormat ??????????????????audio?????????\n\n![Image](https://github.com/user-attachments/assets/f793c033-a3cd-420c-b985-a4fdc6688117)",
      "updatedAt" : 1752245332.000000000,
      "user" : "flamezhang",
      "userHtmlUrl" : "https://github.com/flamezhang",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30311895?v=4",
      "labels" : [ "kind/enhancement", "help wanted", "kind/question", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Got" ],
      "repository" : {
        "description" : "Agentic AI Framework for Java Developers",
        "homepage" : "https://java2ai.com",
        "name" : "spring-ai-alibaba",
        "fullName" : "alibaba/spring-ai-alibaba",
        "htmlUrl" : "https://github.com/alibaba/spring-ai-alibaba",
        "gitUrl" : "git://github.com/alibaba/spring-ai-alibaba.git",
        "sshUrl" : "git@github.com:alibaba/spring-ai-alibaba.git",
        "cloneUrl" : "https://github.com/alibaba/spring-ai-alibaba.git",
        "owner" : {
          "login" : "alibaba",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 938,
        "stargazersCount" : 4749,
        "watchersCount" : 4749,
        "size" : 146395,
        "openIssuesCount" : 259,
        "subscribersCount" : 62,
        "pushedAt" : "2025-07-11T16:12:30Z",
        "languages" : {
          "Java" : 5573403,
          "CSS" : 26756,
          "Makefile" : 7848,
          "TeX" : 4902,
          "Vue" : 410310,
          "Mustache" : 3851,
          "HTML" : 7375,
          "TypeScript" : 519129,
          "Dockerfile" : 2057,
          "Shell" : 4950,
          "Smalltalk" : 11272,
          "Batchfile" : 3003,
          "JavaScript" : 34104,
          "Less" : 6998,
          "Python" : 3892
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support multimodal with audio recognition, specifically qwen-audio-turbo model",
      "validationOrRequirement" : "Support audio type in multimodal",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about supporting audio recognition in multimodal, specifically mentioning the qwen-audio-turbo model.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283741
  }, {
    "issueDTO" : {
      "id" : 1520874136,
      "title" : "\uD83D\uDC1B Bug Report: test email address cause SMTP disconnected ",
      "url" : "https://github.com/appwrite/appwrite/issues/4952",
      "repositoryName" : "appwrite/appwrite",
      "description" : "### \uD83D\uDC5F Reproduction steps\r\n\r\n1. Add your SMTP credentials in your `.env` file\r\n2. Run `docker exec appwrite doctor`\r\n3. You can get `SMTP.............disconnected \uD83D\uDC4E`\r\n\r\n### \uD83D\uDC4D Expected behavior\r\n\r\nYou should get `SMTP................connected \uD83D\uDC4D`\r\n\r\n### \uD83D\uDC4E Actual Behavior\r\n\r\nCurrently the doctor try to send an email to `demo@example.com` \r\n\r\nhttps://github.com/appwrite/appwrite/blob/15107f0f5cf40b647e8d282e2c84322ba0bfd370/app/tasks/doctor.php#L139\r\n\r\ndebuggin the error returned by the code, I have found this message:\r\n\r\n```\r\nPHPMailer\\PHPMailer\\Exception: SMTP Error: The following recipients failed: demo@example.com: The mail server could not deliver mail to demo@example.com.  The account or\r\ndomain may not exist, they may be blacklisted, or missing the proper dns\r\nentries.\r\n``` \r\n\r\nSo my SMTP server haven't any problem but as the server can't find the address `demo@example.com` it fails\r\n\r\nIn my instance I have updated the code and I've added the env var `_APP_SMTP_TEST_EMAIL` to change this address\r\n\r\nWould you accept a PR to fix this issue with this change? \r\n\r\n### \uD83C\uDFB2 Appwrite version\r\n\r\nVersion 1.2.x\r\n\r\n### \uD83D\uDCBB Operating system\r\n\r\nLinux\r\n\r\n### \uD83E\uDDF1 Your Environment\r\n\r\n_No response_\r\n\r\n### \uD83D\uDC40 Have you spent some time to check if this issue has been raised before?\r\n\r\n- [X] I checked and didn't find similar issue\r\n\r\n### \uD83C\uDFE2 Have you read the Code of Conduct?\r\n\r\n- [X] I have read the [Code of Conduct](https://github.com/appwrite/appwrite/blob/HEAD/CODE_OF_CONDUCT.md)",
      "updatedAt" : 1752245332.000000000,
      "user" : "gepd",
      "userHtmlUrl" : "https://github.com/gepd",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7091609?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@gepd thanks for raising this! let me check with the team on this.", "I am also encountering a problem with the SMTP configuration of the Outlook Office 365 email. Has anyone encountered this issue before? Can anyone help me with this, I would greatly appreciate it. Thank you.", "Actually, instead of an environment variable, I think it would be good to expose the email as a parameter to the CLI command.", "Hey there, can this issue be assigned to me? I would like to go a step forward and include a small feature with your permission to create a quick smtp test button with CSRF in the UI for quick smtp testing for easier onboarding as well.\r\n\r\nI'm quite intrigued by Appwrite and would like an opportunity to delve into the codebase and contribute beyond bugs. ", "Hey there @stnguyen90, can I handle this issue?\r\n", "> Hey there @stnguyen90, can I handle this issue?\r\n\r\nAssigning this to you. ", "@Haimantika Rest assured, I'm handling this issue. I should have a PR out by eod tomorrow, some of my changes could break our e2e tests so I'm trying to avert major changes. ", "@mustansirgodhrawala will you be able to address the comments in the PR and fix the merge conflict?", "> @mustansirgodhrawala will you be able to address the comments in the PR and fix the merge conflict?\r\n\r\nCan I continue this ? If yes, please assign me.", "Unassigning @mustansirgodhrawala due to inactivity. Assigning @DevilsAutumn now.", "can i work on this?", "@DevilsAutumn, are you still working on this? @nick2432, are you still interested in working on this?", "Hii , can i work on this SMTP bug?", "@Abhinav163 Are you still interested in working on this?", "Is this bug solved yet?", "Working on the same and will resolve it by 1st week of feb\r\n\r\nOn Tue, 28 Jan, 2025, 12:42 pm Raman Tank, ***@***.***> wrote:\r\n\r\n> Is this bug solved yet?\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/appwrite/appwrite/issues/4952#issuecomment-2618087465>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/A274Q675VXOJOIDETBBFTRL2M4UUTAVCNFSM6AAAAAATSBGRQWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDMMJYGA4DONBWGU>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n", "@Abhinav163 What's the progress on this?", "@Divyanshu7001 I'm assigning this to you", "@stnguyen90 is this issue still open?\nif yes..i will like to have a try on this\n", "@DH-555 thanks for assigning ..working on it\n", "@DH-555 is there a possible valid email for appwrite itself where i can redirect the SMTP test emails? \nthe fix needs a valid testing email..else the SMTP fails in testing due to invalid email.", "@Divyanshu7001 I think the best solution is adding an _APP_SMTP_TEST_EMAIL env variable so you set an example/test email.\n\nBut @stnguyen90 needs to confirm that's the best approach.", "@DH-555 I can understand that setting an test email in environment and import-use of it is the best approach, **I have already implemented and tested it in my local & that's working fine**.\n\n**But in my local,I have given my valid email id to test.**\nSimilarly I want to ask if there is a valid email of appwrite which I can provide in env when I push the code here.\n\nI just need a valid Email of Appwrite to put in there and go forward." ],
      "repository" : {
        "description" : "Build like a team of hundreds_",
        "homepage" : "https://appwrite.io",
        "name" : "appwrite",
        "fullName" : "appwrite/appwrite",
        "htmlUrl" : "https://github.com/appwrite/appwrite",
        "gitUrl" : "git://github.com/appwrite/appwrite.git",
        "sshUrl" : "git@github.com:appwrite/appwrite.git",
        "cloneUrl" : "https://github.com/appwrite/appwrite.git",
        "owner" : {
          "login" : "appwrite",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4563,
        "stargazersCount" : 51798,
        "watchersCount" : 51798,
        "size" : 341708,
        "openIssuesCount" : 786,
        "subscribersCount" : 385,
        "pushedAt" : "2025-07-11T14:39:14Z",
        "languages" : {
          "TypeScript" : 490130,
          "Dockerfile" : 3813,
          "Shell" : 1824,
          "PHP" : 158988
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the SMTP disconnected error when running the `docker exec appwrite doctor` command, and to provide a solution for SMTP testing and email configuration.",
      "validationOrRequirement" : "The issue requires a valid email address for SMTP testing, and the proposed solution is to add an environment variable `_APP_SMTP_TEST_EMAIL` to set a test email address.",
      "attemptedFixes" : "The author has attempted to fix the issue by adding the `_APP_SMTP_TEST_EMAIL` environment variable and changing the test email address. Some comments suggest that a valid email address of Appwrite itself could be used for testing.",
      "otherNotes" : "The issue is related to SMTP configuration and email testing, and there is a proposal to add an environment variable `_APP_SMTP_TEST_EMAIL` to set a test email address. The author has already implemented and tested the fix in their local environment.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283747
  }, {
    "issueDTO" : {
      "id" : 3186322234,
      "title" : "??????????????????????????????????????????????????????",
      "url" : "https://github.com/team-mirai-volunteer/action-board/issues/767",
      "repositoryName" : "team-mirai-volunteer/action-board",
      "description" : "?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n??????????????????????????????????????????????????????????????????????????????????????????",
      "updatedAt" : 1752245245.000000000,
      "user" : "kakuni0119",
      "userHtmlUrl" : "https://github.com/kakuni0119",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/213019521?v=4",
      "labels" : [ "Design", "?????????", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "icon?????????svg??????????????????????????????????????????????????????????????????????????????\nDB???icon_url????????????????????????????????????good first issue.", "public/img/missions?????????SVG????????????", "/assign", "@TomoeSakurai \n????????????SVG???????????????????????????????????????????????????????????????\n?????????????????????`public/img/missions`??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\uD83D\uDE4F", "@mzksoup \n?????????????????????????????????????????????????????????????????????\n????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n???????????????????????????.....???????????????????????????m(_ _)m", "@yukasato0226 \n????????????????????????????????????????????????\n?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????", "??????????????????????????????????????????????????????????????????????????????????????????\n??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????w", "???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\uD83D\uDE47", "??????????????????????????????????????????\n????????????????????????????????????????????????????????????????????????????????????????????????????????????", "@mzksoup \n???????????????????????????????????????????????????\n\nGoogle????????????\nhttps://drive.google.com/drive/folders/1Q_vNMAczeoAyZmrROWK9iZ0_brfY5BOd?usp=drive_link\n\n- ?????????????????????????????????????????????????????????????????????????????????\n- ?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????" ],
      "repository" : {
        "description" : "??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????",
        "homepage" : "",
        "name" : "action-board",
        "fullName" : "team-mirai-volunteer/action-board",
        "htmlUrl" : "https://github.com/team-mirai-volunteer/action-board",
        "gitUrl" : "git://github.com/team-mirai-volunteer/action-board.git",
        "sshUrl" : "git@github.com:team-mirai-volunteer/action-board.git",
        "cloneUrl" : "https://github.com/team-mirai-volunteer/action-board.git",
        "owner" : {
          "login" : "team-mirai-volunteer",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 62,
        "stargazersCount" : 43,
        "watchersCount" : 43,
        "size" : 11306,
        "openIssuesCount" : 205,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-12T00:58:18Z",
        "languages" : {
          "PowerShell" : 26064,
          "MDX" : 12898,
          "C++" : 24895,
          "CSS" : 9283,
          "C" : 1425,
          "CMake" : 19800,
          "PLpgSQL" : 86490,
          "HTML" : 14446,
          "Kotlin" : 126,
          "TypeScript" : 1347953,
          "HCL" : 29886,
          "Dockerfile" : 1536,
          "Shell" : 1764,
          "JavaScript" : 11267,
          "Objective-C" : 38,
          "Swift" : 2290,
          "Ruby" : 2757,
          "Dart" : 386360
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The goal of this issue is to allow individual specification of mission card icons, which will improve the discoverability of missions by using color and images to identify them.",
      "validationOrRequirement" : "The icon images should be stored in the public/img/missions directory and should be specified individually for each mission card.",
      "attemptedFixes" : "Icon images are stored in Google Drive, and the author suggests temporarily using the team mirai logo for missions that have not been updated in the past few days.",
      "otherNotes" : "Icon images are stored in Google Drive (https://drive.google.com/drive/folders/1Q_vNMAczeoAyZmrROWK9iZ0_brfY5BOd?usp=drive_link). The current icon is intended to be replaced. The author suggests temporarily using the team mirai logo for missions that have not been updated in the past few days.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283753
  }, {
    "issueDTO" : {
      "id" : 1830709640,
      "title" : "Sketcher: Greyed out (disabled) sketcher tools disrupts UX",
      "url" : "https://github.com/FreeCAD/FreeCAD/issues/10027",
      "repositoryName" : "FreeCAD/FreeCAD",
      "description" : "### Is there an existing issue for this?\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Version\r\n\r\n0.21 (Development)\r\n\r\n### Full version info\r\n\r\n```shell\r\nOS: Windows 10 build 19045\r\nWord size of FreeCAD: 64-bit\r\nVersion: 0.21.0.33636 (Git)\r\nBuild type: Release\r\nBranch: master\r\nHash: a5e350ad469f4030b46baa6fd3d1770375f1ddd1\r\nPython 3.10.12, Qt 5.15.8, Coin 4.0.0, Vtk 9.2.5, OCC 7.6.3\r\nLocale: Polish/Poland (pl_PL)\r\n```\r\n\r\n\r\n### Subproject(s) affected?\r\n\r\nSketcher\r\n\r\n### Problem description\r\n\r\nAlmost all sketcher tools (geometry and constraint tools) can become greyed out (and thus deactivated) after a sequence of clicks. The exact repeatable sequence leading to this hasn't been identified yet (the issue seems to occur somewhat randomly) but so far the most reliable way is to draw an arbitrary circle and repeat the following steps:\r\n1. Drag it\r\n2. Click on the background next to it\r\n\r\nSometimes it happens after doing it once or twice, sometimes after doing it 3 times or more and sometimes not at all. But it usually happens. On 3 different computers with Windows (10 and 11). To bring the tools back to the active state one has to click on the geometry of the sketch (clicking on the background doesn't help).\r\n\r\n![Greyed out sketcher tools](https://github.com/FreeCAD/FreeCAD/assets/59876896/c55ff28f-1a6e-407b-8a44-ad87e20576b6)\r\n\r\nForum discussion: https://forum.freecad.org/viewtopic.php?t=80069\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's Code of Conduct",
      "updatedAt" : 1752245219.000000000,
      "user" : "FEA-eng",
      "userHtmlUrl" : "https://github.com/FEA-eng",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/59876896?v=4",
      "labels" : [ "Type: Bug", "Topic: User Interface", "Good first issue", "Mod: Sketcher" ],
      "state" : "OPEN",
      "comments" : [ "I can reproduce it with\r\n\r\n```ruby\r\nOS: Windows 10 build 19044\r\nWord size of FreeCAD: 64-bit\r\nVersion: 0.21.0.33303 (Git)\r\nBuild type: Release\r\nBranch: master\r\nHash: 5b075a9938b78076fdde9034de4a05685e42690e\r\nPython 3.10.11, Qt 5.15.8, Coin 4.0.0, Vtk 9.1.0, OCC 7.6.3\r\nLocale: Russian/Russia (ru_RU)\r\n```\r\n\r\nand \r\n\r\n```ruby\r\nOS: Ubuntu 22.04.2 LTS (ubuntu:GNOME/ubuntu)\r\nWord size of FreeCAD: 64-bit\r\nVersion: 0.21.0.33631 (Git)\r\nBuild type: Debug\r\nBranch: master\r\nHash: 2167fb6f7ec6ac5c2f6365d4c3035d2db6879b1e\r\nPython 3.10.6, Qt 5.15.3, Coin 4.0.0, Vtk 9.1.0, OCC 7.5.1\r\nLocale: English/United States (en_US)\r\n```\r\n\r\n\r\nBut I can't provide the exact sequence of mouse clicks.\r\n\r\nWhen the toolbar buttons become disabled, one can toggle construction geometry or change workbench, the toolbar buttons will be enabled as usual.", "@xtemp09 Finally someone can reproduce it, thanks for checking. It's also good to know that it's not specific to Windows. It seems to be somewhat random.", "This traceback was quite difficult to get, found a method at last.\r\n\r\nEventually, we can see, that `Gui::Command::testActive` deactives the commands in Sketcher by `Action::setEnabled`.\r\n\r\nBut according to the documentation, the function isn't even meant to _change_ the commands state, it's only meant to to _test_  the state of the command.\r\n\r\n```cpp\r\n/// Get somtile called to check the state of the command\r\nvoid testActive();\r\n```\r\n\r\nThough if we look at the exact line in `Gui::Command::testActive` that changes the state, it seems like the state change is very intentionally.\r\n\r\nbool bActive = isActive();  // Command::isActive\r\n_pcAction->setEnabled(bActive);  // Action::setEnabled\r\n\r\nThe enabled state is eventually set to the value of `isActive()` defined in `CmdSketcherCreatePoint::isActive`:\r\n\r\n```cpp\r\nbool CmdSketcherCreatePoint::isActive()\r\n{\r\n    return isCommandActive(getActiveGuiDocument());  // SketcherGui::isCommandActive\r\n}\r\n```\r\n\r\n`CmdSketcherCreatePoint::isActive` just returns the value of `SketcherGui::isCommandActive`, that only return true or false depending on other functions return boolean value. \r\n\r\n```cpp\r\nbool SketcherGui::isCommandActive(Gui::Document* doc, bool actsOnSelection)\r\n{\r\n    if (isSketchInEdit(doc)) {\r\n        auto mode =\r\n            static_cast<SketcherGui::ViewProviderSketch*>(doc->getInEdit())->getSketchMode();\r\n\r\n        if (mode == ViewProviderSketch::STATUS_NONE\r\n            || mode == ViewProviderSketch::STATUS_SKETCH_UseHandler) {\r\n\r\n            if (!actsOnSelection) {\r\n                return true;\r\n            }\r\n            else if (Gui::Selection().countObjectsOfType(Sketcher::SketchObject::getClassTypeId())\r\n                     > 0) {\r\n                return true;\r\n            }\r\n        }\r\n    }\r\n\r\n    return false;\r\n}\r\n```\r\n\r\nHere we know that at least `mode == ViewProviderSketch::STATUS_NONE` and `mode == ViewProviderSketch::STATUS_SKETCH_UseHandler` both return false and thereby eventually causing all the Sketcher buttons to be disabled.\r\n\r\nWhat I do notice though is that `SketcherGui::isCommandActive` was changed heavily in 816fa3fe3e24fcc931336a055db3ea849ca6f99a a810fa68b43181426a6a24d74a5829f172a27bc1 bae8050fac84684e915832fcfaec5e0b2e834b0b... might these changes have introduced the bug? @FEA-eng how long has this been a bug?\r\n\r\nWell, further research show that\r\n```cpp\r\nmode == ViewProviderSketch::SketchStatus::STATUS_SKETCH_UseRubberBand\r\nmode == ViewProviderSketch::SketchStatus::STATUS_SKETCH_StartRubberBand\r\nmode == ViewProviderSketch::SketchStatus::STATUS_SELECT_Edge\r\nmode == ViewProviderSketch::SketchStatus::STATUS_SELECT_Cross\r\nmode == ViewProviderSketch::SketchStatus::STATUS_SKETCH_DragCurve\r\n```\r\n\r\ncauses the commands to be disabled. Sometimes the commands get disabled and auto recovers without user interaction. Mode is set in ViewProviderSketch\r\n\r\nSo now two questions arise. Why is the SketchMode thinking we are using a rubberband? Why does the commands only auto recover some times?\r\n\r\nI'm begging to get hungry and it's dinner time. So I'll stop for here and let someone else take over. I'd pinpoint the issue to being the SketchMode, that Sketcher falsely believes one is doing a rubberband selection. On the surface, it's seams like an easy fix, as it's just value comparison of click distances, but I'll avoid digging into it, as I know everything I touch just turns into a deep black rabbit hole. Also, ViewProviderSketch really needs some refactoring as code organization is currently non-existing where everything is just the long switch-cases.\r\n\r\nAlright, dinner time.\r\n\r\n```cpp\r\nif (done\r\n    && SbVec2f(cursorPos - DoubleClick::prvClickPos).length() < dblClickRadius\r\n    && (SbTime::getTimeOfDay() - DoubleClick::prvClickTime).getValue() < dci) {\r\n        // [...]\r\n}\r\nelse {\r\n    [...]\r\n    if (!done) {\r\n        Mode = STATUS_SKETCH_StartRubberBand;\r\n        raise(SIGINT);\r\n    }\r\n}\r\n```\r\n\r\nTraceback:\r\n\r\n```\r\n[...]\r\n#4  0x00007ffff6961202 in Gui::Action::setEnabled(bool)\r\n    (this=0x555558c2c540, enable=false)\r\n    at /home/bensay/Development/FreeCAD/src/Gui/Action.cpp:167\r\n#5  0x00007ffff6963a27 in Gui::ActionGroup::setEnabled(bool)\r\n    (this=0x555558c2c540, check=false)\r\n    at /home/bensay/Development/FreeCAD/src/Gui/Action.cpp:512\r\n#6  0x00007ffff697ac24 in Gui::Command::testActive() (this=0x555558f061d0)\r\n    at /home/bensay/Development/FreeCAD/src/Gui/Command.cpp:539\r\n        pcAction = 0x555558c2c540\r\n        bActive = false\r\n#7  0x00007ffff6984871 in Gui::CommandManager::testActive() (this=0x555555b18a30)\r\n    at /home/bensay/Development/FreeCAD/src/Gui/Command.cpp:1924\r\n        It = {first = \"Sketcher_CompCreateCircle\", second = 0x555558f061d0}\r\n#8  0x00007ffff6fa6e7f in Gui::MainWindow::_updateActions() (this=0x7fffffffd120)\r\n    at /home/bensay/Development/FreeCAD/src/Gui/MainWindow.cpp:1520\r\n#9  0x00007ffff6b1b9d2 in QtPrivate::FunctorCall<QtPrivate::IndexesList<>, QtPrivate::List<>, void, void (Gui::MainWindow::*)()>::call(void (Gui::MainWindow::*)(), Gui::MainWindow*, void**)\r\n    (f=(void (Gui::MainWindow::*)(class Gui::MainWindow * const)) 0x7ffff6fa6cd8 <Gui::MainWindow::_updateActions()>, o=0x7fffffffd120, arg=0x7fffffffc970)\r\n    at /usr/include/x86_64-linux-gnu/qt5/QtCore/qobjectdefs_impl.h:152\r\n#10 0x00007ffff6b1b908 in QtPrivate::FunctionPointer<void (Gui::MainWindow::*)()>::call<QtPrivate::List<>, void>(void (Gui::MainWindow::*)(), Gui::MainWindow*, void**)\r\n    (f=(void (Gui::MainWindow::*)(class Gui::MainWindow * const)) 0x7ffff6fa6cd8 <Gui::MainWindow::_updateActions()>, o=0x7fffffffd120, arg=0x7fffffffc970)\r\n    at /usr/include/x86_64-linux-gnu/qt5/QtCore/qobjectdefs_impl.h:185\r\n#11 0x00007ffff6b1b779 in QtPrivate::QSlotObject<void (Gui::MainWindow::*)(), QtPrivate::List<>, void>::impl(int, QtPrivate::QSlotObjectBase*, QObject*, void**, bool*)\r\n    (which=1, this_=0x55555609ed20, r=0x7fffffffd120, a=0x7fffffffc970, ret=0x0)\r\n    at /usr/include/x86_64-linux-gnu/qt5/QtCore/qobjectdefs_impl.h:418\r\n[...]\r\n```", "@abdullahtahiriyo ", "@benj5378 Thank you for investigating this. I noticed this problem in June, but it's possible that it had been there for some time before.", "bumping for progress", "I will try to tackle this over the next week. I mark it as unread not to lose track.", "@PaddleStroke Since Abdullah is gone, maybe you could take a look at this small but annoying issue when you have some time. The comment by @benj5378 provides a really comprehensive insight.", "I can reproduce. I'll investigate later", "> I can reproduce. I'll investigate later\r\n\r\nThis issue is still relevant. Any chance you could have a look at it for 1.0?", "Hi! This issue hasn???t seen activity in a while. If it???s still relevant, please update to the latest FreeCAD weekly build [download here](https://github.com/FreeCAD/FreeCAD-Bundle/releases/tag/weekly-builds) to see if the problem is resolved.\n\nIf the issue persists, let us know by adding a comment with any updates or details. Otherwise, we???ll close this issue automatically in 20 days to keep our backlog tidy. Feel free to comment anytime to keep it open. Closed issues can always be reopened.\nThanks for helping improve FreeCAD!\n\nAccess additional [FreeCAD](https://freecad.org) resources:\n  - **Forum**: https://forum.freecad.org\n  - **Blog**: https://blog.freecad.org\n  - **Wiki**: https://wiki.freecad.org", "Still relevant (and quite annoying) issue", "Any volunteers to tackle this long-standing UI/UX issue ?\n\nEdit: still valid in 1.1dev per duplicate ticket:  \n* #21532", "@PaddleStroke Could you have a look at this annoying issue?", "Yes it's true that this is very annoying" ],
      "repository" : {
        "description" : "Official source code of FreeCAD, a free and opensource multiplatform 3D parametric modeler.",
        "homepage" : "https://www.freecad.org",
        "name" : "FreeCAD",
        "fullName" : "FreeCAD/FreeCAD",
        "htmlUrl" : "https://github.com/FreeCAD/FreeCAD",
        "gitUrl" : "git://github.com/FreeCAD/FreeCAD.git",
        "sshUrl" : "git@github.com:FreeCAD/FreeCAD.git",
        "cloneUrl" : "https://github.com/FreeCAD/FreeCAD.git",
        "owner" : {
          "login" : "FreeCAD",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4663,
        "stargazersCount" : 25318,
        "watchersCount" : 25318,
        "size" : 2198503,
        "openIssuesCount" : 3170,
        "subscribersCount" : 549,
        "pushedAt" : "2025-07-11T21:33:14Z",
        "languages" : {
          "Yacc" : 23579,
          "C++" : 42440388,
          "CSS" : 8551,
          "C" : 1163472,
          "CMake" : 623284,
          "Max" : 605,
          "Makefile" : 6434,
          "QMake" : 1123,
          "HTML" : 52905,
          "NSIS" : 134853,
          "Shell" : 58950,
          "Batchfile" : 11874,
          "JavaScript" : 14016,
          "OpenSCAD" : 774,
          "Objective-C" : 6019,
          "Lex" : 111781,
          "Python" : 36828424,
          "GLSL" : 2097
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to identify and fix the problem that causes the Sketcher tools to become greyed out and disabled, which disrupts the user experience. The issue is still open and requires further investigation.",
      "validationOrRequirement" : "The issue is related to the Sketcher tools becoming greyed out and disabled, which disrupts the user experience. The problem seems to occur randomly and is not specific to Windows. The issue is still valid in 1.1dev and requires further investigation.",
      "attemptedFixes" : "Several developers have attempted to fix the issue, but the exact sequence of mouse clicks that causes the problem has not been identified. The code organization in ViewProviderSketch needs to be refactored, and the SketchMode needs to be reviewed. The issue is still open and requires further investigation.",
      "otherNotes" : "This issue is related to Sketcher tools becoming greyed out and disabled, which disrupts the user experience. The problem seems to occur randomly and is not specific to Windows. The issue was first noticed in June, but it's possible that it had been there for some time before. Several developers have investigated and tried to reproduce the issue, but the exact sequence of mouse clicks that causes the problem has not been identified. The issue is still relevant and has been marked as 'still valid in 1.1dev'.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283763
  }, {
    "issueDTO" : {
      "id" : 3222006169,
      "title" : "[Spark4] Fix SparkStreamingTest",
      "url" : "https://github.com/OpenLineage/OpenLineage/issues/3883",
      "repositoryName" : "OpenLineage/OpenLineage",
      "description" : "`SparkStreamingTest` is disabled for Spark 4.\nThis is a follow-up issue of https://github.com/OpenLineage/OpenLineage/pull/3877\nPlease fix the test, enable it and remove TODO comment.",
      "updatedAt" : 1752245186.000000000,
      "user" : "pawel-big-lebowski",
      "userHtmlUrl" : "https://github.com/pawel-big-lebowski",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1646950?v=4",
      "labels" : [ "area:integration/spark", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "can i take the issue? " ],
      "repository" : {
        "description" : "An Open Standard for lineage metadata collection",
        "homepage" : "http://openlineage.io",
        "name" : "OpenLineage",
        "fullName" : "OpenLineage/OpenLineage",
        "htmlUrl" : "https://github.com/OpenLineage/OpenLineage",
        "gitUrl" : "git://github.com/OpenLineage/OpenLineage.git",
        "sshUrl" : "git@github.com:OpenLineage/OpenLineage.git",
        "cloneUrl" : "https://github.com/OpenLineage/OpenLineage.git",
        "owner" : {
          "login" : "OpenLineage",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 356,
        "stargazersCount" : 2014,
        "watchersCount" : 2014,
        "size" : 65830,
        "openIssuesCount" : 289,
        "subscribersCount" : 47,
        "pushedAt" : "2025-07-11T18:15:49Z",
        "languages" : {
          "MDX" : 303458,
          "PowerShell" : 742,
          "Java" : 3610139,
          "CSS" : 12915,
          "Jinja" : 10687,
          "Rust" : 223402,
          "PLpgSQL" : 41573,
          "Scala" : 9325,
          "Makefile" : 634,
          "Groovy" : 11849,
          "Kotlin" : 32464,
          "TypeScript" : 57451,
          "Dockerfile" : 7360,
          "Shell" : 70649,
          "Batchfile" : 800,
          "JavaScript" : 10910,
          "Ruby" : 12631,
          "Python" : 1319715
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix SparkStreamingTest for Spark 4",
      "validationOrRequirement" : "fix the test, enable it and remove TODO comment",
      "attemptedFixes" : "",
      "otherNotes" : "This is a follow-up issue of https://github.com/OpenLineage/OpenLineage/pull/3877",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283765
  }, {
    "issueDTO" : {
      "id" : 1449185610,
      "title" : "No usage: in the README.",
      "url" : "https://github.com/CabbageDevelopment/qasync/issues/69",
      "repositoryName" : "CabbageDevelopment/qasync",
      "description" : "No usage in the README and no documentation  in the package or the module\r\n\r\nCould you cut-n-paste the Usage section of the quamash README\r\nhttps://github.com/harvimt/quamash/ and adapt it to qasync?\r\n\r\n",
      "updatedAt" : 1752244728.000000000,
      "user" : "emdee-is",
      "userHtmlUrl" : "https://github.com/emdee-is",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/109981937?v=4",
      "labels" : [ "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "There's some usage examples now, so maybe close?" ],
      "repository" : {
        "description" : "Python library for using asyncio in Qt-based applications.",
        "homepage" : "",
        "name" : "qasync",
        "fullName" : "CabbageDevelopment/qasync",
        "htmlUrl" : "https://github.com/CabbageDevelopment/qasync",
        "gitUrl" : "git://github.com/CabbageDevelopment/qasync.git",
        "sshUrl" : "git@github.com:CabbageDevelopment/qasync.git",
        "cloneUrl" : "https://github.com/CabbageDevelopment/qasync.git",
        "owner" : {
          "login" : "CabbageDevelopment",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 50,
        "stargazersCount" : 362,
        "watchersCount" : 362,
        "size" : 164,
        "openIssuesCount" : 34,
        "subscribersCount" : 9,
        "pushedAt" : "2024-07-17T13:30:34Z",
        "languages" : {
          "Python" : 66038
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Cut and paste the Usage section of the quamash README and adapt it to qasync",
      "validationOrRequirement" : "adapt the Usage section of the quamash README to qasync",
      "attemptedFixes" : "",
      "otherNotes" : "There's some usage examples now, so maybe close?",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283767
  }, {
    "issueDTO" : {
      "id" : 3198148834,
      "title" : "[MCP] ClickSend SMS",
      "url" : "https://github.com/activepieces/activepieces/issues/8234",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview  \n\nClickSend is a cloud-based messaging platform for sending SMS, MMS, voice, email, and more. This integration allows automation builders and AI agents to send messages, manage contacts, and monitor communication status across workflows.\n\n---\n\n## ?????? Important Note for Contributors  \n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n---\n\n## \uD83D\uDEA8 Triggers  \n\n| **Trigger** | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **New Incoming SMS** | Start a workflow when a new SMS is received (e.g., customer support, lead inquiry).|\n\n---\n\n## \uD83D\uDEE0??? Write Actions  \n\n| **Action Item**               | **Use Case** |\n|:--------------------------|:---------------------------------------|\n| **Send SMS** | Send one or more SMS messages to customers, leads, or internal users. |\n| **Send MMS** |  Send event posters or product images.|\n|**Create Contact**|Capture webinar registrations into SMS lists.|\n|**Update Contact**| Keep contact details current after CRM sync.|\n|**Delete Contact**|Opt-out contacts automatically when unsubscribed.|\n|**Create Contact List** | Set up segmented marketing lists automatically.|\n\n---\n\n## \uD83D\uDD0D Search Actions  \n\n| **Action Item**               | **Use Case**                                                                                                                                     |\n|:------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Search Contact by Email Address** | Retrieves a contact in a list by email.|\n|**Search Contact by Phone**| Retrieves a contact in a list by phone number.|\n|**Search Contact Lists**| Check if a marketing list exists before adding contacts.|\n\n---\n\n\n## \uD83D\uDCDA API Reference  \n- [Official ClickSend API Documentation](https://developers.clicksend.com/docs#ClickSend-v3-API-SMS)\n\n---\n\n## \uD83E\uDDEA Test Account Access  \nSign up for a free account at [ClickSend Signup](https://dashboard.clicksend.com/#/signup/step0).\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are built with our TypeScript framework and are easy to develop. Once merged into our repository, they become available as pieces in our automation builder and as MCPs usable by AI agents and MCP clients.\n\nStart building here: [Piece Development Docs](https://www.activepieces.com/docs/developers/building-pieces/overview)\n",
      "updatedAt" : 1752244677.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "$100", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-789/mcp-clicksend-sms\">AP-789 [MCP] ClickSend SMS</a></p>", "/bounty $100", "## \uD83D\uDC8E $100 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8234` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8234` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @Khalid6468 | Jul 03, 2025, 06:17:45 AM | WIP |  |\n| \uD83D\uDFE2 @krushnarout | Jul 03, 2025, 08:08:35 AM | WIP |  |\n| \uD83D\uDFE2 @Sanket6652 | Jul 05, 2025, 11:23:09 AM | #8264 | [Reward](https://algora.io/claims/GPDrAEt6LmhANo5p) |\n| \uD83D\uDFE2 @sparkybug | Jul 07, 2025, 10:28:48 AM | #8279 | [Reward](https://algora.io/claims/Pkw23Qw5ta8Puxtc) |", "/attempt #8234", "/attempt #8234" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2193,
        "stargazersCount" : 15771,
        "watchersCount" : 15771,
        "size" : 300248,
        "openIssuesCount" : 388,
        "subscribersCount" : 96,
        "pushedAt" : "2025-07-11T13:16:13Z",
        "languages" : {
          "TypeScript" : 13976520,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 71760,
          "Shell" : 3862,
          "JavaScript" : 12636,
          "HTML" : 212998
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to integrate ClickSend SMS with Activepieces, allowing automation builders and AI agents to send messages, manage contacts, and monitor communication status across workflows.",
      "validationOrRequirement" : "The feature must be submitted as a [Piece] following the Activepieces architecture, and the submission must follow the [Piece Development Guidelines].",
      "attemptedFixes" : "Several attempts have been made by @Khalid6468, @krushnarout, @Sanket6652, and @sparkybug, with @Sanket6652 and @sparkybug claiming the bounty and receiving rewards.",
      "otherNotes" : "To ensure consistency and maintainability, this feature must be submitted as a [Piece] following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines] before starting development.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283773
  }, {
    "issueDTO" : {
      "id" : 3220080517,
      "title" : "Create newtypes for LinearAddress and AreaIndex",
      "url" : "https://github.com/ava-labs/firewood/issues/1050",
      "repositoryName" : "ava-labs/firewood",
      "description" : "suggestion: it appears that these would not need to be exported if you could implement methods on `LinearAddress` (such as `const fn is_aligned(&self) -> bool`) suggesting we should convert the type alias into a newtype struct wrapping the NonZeroU64 that we can add methods to. However, this is out of scope for this change and should be a change of its own.\r\n\r\n_Originally posted by @demosdemon in https://github.com/ava-labs/firewood/pull/1046#discussion_r2198239644_\r\n            ",
      "updatedAt" : 1752244403.000000000,
      "user" : "demosdemon",
      "userHtmlUrl" : "https://github.com/demosdemon",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/310610?v=4",
      "labels" : [ "3rd party contributor", "good first issue", "techdebt" ],
      "state" : "OPEN",
      "comments" : [ "Hey @demosdemon , I would like to take this up.\nThanks" ],
      "repository" : {
        "description" : "Compaction-Less Database Optimized for Efficiently Storing Recent Merkleized Blockchain State",
        "homepage" : "https://ava-labs.github.io/firewood/",
        "name" : "firewood",
        "fullName" : "ava-labs/firewood",
        "htmlUrl" : "https://github.com/ava-labs/firewood",
        "gitUrl" : "git://github.com/ava-labs/firewood.git",
        "sshUrl" : "git@github.com:ava-labs/firewood.git",
        "cloneUrl" : "https://github.com/ava-labs/firewood.git",
        "owner" : {
          "login" : "ava-labs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 131,
        "watchersCount" : 131,
        "size" : 46567,
        "openIssuesCount" : 51,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-12T00:44:19Z",
        "languages" : {
          "Shell" : 5731,
          "Rust" : 635364,
          "C" : 13560,
          "Go" : 76076
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create newtypes for LinearAddress and AreaIndex",
      "validationOrRequirement" : "Implement methods on LinearAddress (such as is_aligned) and convert type alias into a newtype struct wrapping NonZeroU64",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue suggests converting type alias into a newtype struct wrapping NonZeroU64 and adding methods to it, but this is out of scope for this change and should be a separate change.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283777
  }, {
    "issueDTO" : {
      "id" : 2986483813,
      "title" : "Use the struct-initialization linter more",
      "url" : "https://github.com/OffchainLabs/nitro/issues/3121",
      "repositoryName" : "OffchainLabs/nitro",
      "description" : "In much of the go codebase, we use and initialize structs.\n\nIn most of those places, we should really ensure that all fields on the struct are explicitly initialized. This helps to ensure that new fields on structs aren't just silently getting the zero value for that type without anyone noticing.\n\nWe can annotate each struct initialization with:\n```\n// lint:require-exhaustive-initialization\n```\n\nTo ensure that structs are exhaustively initialized.\n\nOne example of this is:\nhttps://github.com/OffchainLabs/nitro/blob/7fd92faabe996f25a85b02b005cb1674d2fd7b66/linters/testdata/src/structinit/a/a.go#L5\n\nBut, that's just in the linter test. We want to start adopting this in more places in our codebase with the eventual goal of making the linter-opt out once the majority of struct initializations are exhaustive.\n\nIf you open a PR to add this annotation to a struct, be sure to reference this issue in the commit comment.",
      "updatedAt" : 1752244377.000000000,
      "user" : "eljobe",
      "userHtmlUrl" : "https://github.com/eljobe",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/679924?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "The lint:require-exhaustive-initialization directive should be placed directly above struct definitions, not initializations. When added, it enforces that all fields must be explicitly initialized when creating instances of that struct.\n\nSee the example: https://github.com/OffchainLabs/nitro/blob/7fd92faabe996f25a85b02b005cb1674d2fd7b66/linters/testdata/src/structinit/a/a.go#L5\n\nSo perhaps we should change the guidance for this issue to say that we should add it to select definitions that we care about being fully initialized?", "Is someone working on this @hkalodner @eljobe ? I'd be happy to do it / be assigned if not!", "@Oliverpt-1, please do just start opening PRs against this GitHub issue. We don't need to tackle the whole codebase at once, but we'd be happy to have multiple, focused PRs, (even possibly from multiple different authors) opened and working to increase the usage of this linter.", "Okay sounds great! Will do - thank you @eljobe " ],
      "repository" : {
        "description" : "Nitro goes vroom and fixes everything",
        "homepage" : "",
        "name" : "nitro",
        "fullName" : "OffchainLabs/nitro",
        "htmlUrl" : "https://github.com/OffchainLabs/nitro",
        "gitUrl" : "git://github.com/OffchainLabs/nitro.git",
        "sshUrl" : "git@github.com:OffchainLabs/nitro.git",
        "cloneUrl" : "https://github.com/OffchainLabs/nitro.git",
        "owner" : {
          "login" : "OffchainLabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 582,
        "stargazersCount" : 816,
        "watchersCount" : 816,
        "size" : 68923,
        "openIssuesCount" : 41,
        "subscribersCount" : 58,
        "pushedAt" : "2025-07-11T23:39:01Z",
        "languages" : {
          "Dockerfile" : 19398,
          "Yul" : 957,
          "Shell" : 21896,
          "Rust" : 1017557,
          "C" : 16266,
          "Solidity" : 98492,
          "Makefile" : 32449,
          "WebAssembly" : 79289,
          "Go" : 4721988,
          "Python" : 1125,
          "Brainfuck" : 6
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Use the struct-initialization linter more by adding the lint:require-exhaustive-initialization directive to select struct definitions to ensure that all fields are explicitly initialized.",
      "validationOrRequirement" : "Add the lint:require-exhaustive-initialization directive to select struct definitions that we care about being fully initialized.",
      "attemptedFixes" : "The lint:require-exhaustive-initialization directive should be placed directly above struct definitions, not initializations.",
      "otherNotes" : "The lint:require-exhaustive-initialization directive should be placed directly above struct definitions, not initializations. Also, it's suggested to add it to select definitions that we care about being fully initialized.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283781
  }, {
    "issueDTO" : {
      "id" : 3220322768,
      "title" : "Collapsed tower transformed by \"fire\"",
      "url" : "https://github.com/CleverRaven/Cataclysm-DDA/issues/81689",
      "repositoryName" : "CleverRaven/Cataclysm-DDA",
      "description" : "### Describe the bug\n\nI received the collapsed tower quest, went there, and saw that parts of the tower have been cleared out of rubble due to \"fire\".\n\n### Attach save file\n\nN/A. It should be obvious from the image that the \"fire\" processing has been performed, and a save is unlikely to add any info of value.\n\n### Steps to reproduce\n\n1. Get the quest.\n2. Go to the tower.\n3. Get (un)lucky.\n\n### Expected behavior\n\nThe collapsed tower should not be eligible for the \"fire\" post processing.\n\n### Screenshots\n\n<img width=\"3440\" height=\"1440\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/40dc9fca-3f99-4e78-ac12-c71145e5a269\" />\n\n### Versions and configuration\n\n- OS: Windows\n    - OS Version: 10.0.19045.6093 (22H2)\n- Game Version: cdda-experimental-2025-07-10-0705 [64-bit]\n- Graphics Version: Tiles\n- Game Language: System language []\n- Mods loaded: [\n    Dark Days Ahead [dda],\n    Disable NPC Needs [no_npc_food],\n    Portal Storms Ignore NPCs [personal_portal_storms]\n]\n\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752244254.000000000,
      "user" : "PatrikLundell",
      "userHtmlUrl" : "https://github.com/PatrikLundell",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22739822?v=4",
      "labels" : [ "Good First Issue", "[JSON]", "(S2 - Confirmed)" ],
      "state" : "OPEN",
      "comments" : [ "Looks like a simple mistake in #79593\n\nhttps://github.com/CleverRaven/Cataclysm-DDA/blob/0d8eb912a4b369778106714525de880bf9f5aca2/data/json/overmap/overmap_terrain/overmap_terrain_commercial.json#L221\n\nSimple fix, just need to remove the flag. Should happen on 0.I as well, since simple bugfix + leaving it unfixed could break a quest location.", "Also wizard basement location from corresponding startneed to be immune to fire. Before the game staart, the character and his teacher lived there, so they wouldn't have allowed the fire to happen. It's also very strange that you can leave the basement, but not return." ],
      "repository" : {
        "description" : "Cataclysm - Dark Days Ahead. A turn-based survival game set in a post-apocalyptic world.",
        "homepage" : "http://cataclysmdda.org",
        "name" : "Cataclysm-DDA",
        "fullName" : "CleverRaven/Cataclysm-DDA",
        "htmlUrl" : "https://github.com/CleverRaven/Cataclysm-DDA",
        "gitUrl" : "git://github.com/CleverRaven/Cataclysm-DDA.git",
        "sshUrl" : "git@github.com:CleverRaven/Cataclysm-DDA.git",
        "cloneUrl" : "https://github.com/CleverRaven/Cataclysm-DDA.git",
        "owner" : {
          "login" : "CleverRaven",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4329,
        "stargazersCount" : 11417,
        "watchersCount" : 11417,
        "size" : 11441918,
        "openIssuesCount" : 2468,
        "subscribersCount" : 317,
        "pushedAt" : "2025-07-11T23:27:21Z",
        "languages" : {
          "PowerShell" : 6893,
          "Java" : 235624,
          "C++" : 26581727,
          "C" : 17409,
          "CMake" : 91888,
          "Makefile" : 51118,
          "jq" : 4475,
          "HTML" : 17542,
          "Perl" : 1087,
          "Dockerfile" : 4925,
          "Shell" : 54923,
          "R" : 1408,
          "Batchfile" : 867,
          "Motoko" : 16,
          "JavaScript" : 5754,
          "CodeQL" : 3506,
          "Gnuplot" : 276,
          "Python" : 587283
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The collapsed tower should not be eligible for the 'fire' post processing.",
      "validationOrRequirement" : "The fix should happen on 0.I as well, and the wizard basement location should be immune to fire.",
      "attemptedFixes" : "A simple fix is suggested, just needing to remove the flag.",
      "otherNotes" : "The issue is related to a quest location being immune to fire, and a fix is suggested to remove a flag.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283785
  }, {
    "issueDTO" : {
      "id" : 2440771794,
      "title" : "Using the RenderingServer to add a texture to the scene, the texture appears at bad position during one frame",
      "url" : "https://github.com/godotengine/godot/issues/94988",
      "repositoryName" : "godotengine/godot",
      "description" : "### Tested versions\n\n4.3-rc1 Mono Win64\n\n### System information\n\nWindows 11\n\n### Issue description\n\nAs said in the title, I use the RenderingServer in order to add texture to the game scene. The problem is that during one frame, the texture appears at wrong position. More precisly, the wrong position is somewhere between the origin (0, 0) and the position it is supposed to be. After this wrong frame, the texture jumps to the expected position.\n\n### Steps to reproduce\n\nLaunch the attached project and click in the game scene. You will see the green circle popping at bad position during one frame.\n\n### Minimal reproduction project (MRP)\n\n[BugSpriteJumpingAtInstanciation.zip](https://github.com/user-attachments/files/16446283/BugSpriteJumpingAtInstanciation.zip)\r\n",
      "updatedAt" : 1752244226.000000000,
      "user" : "kakatoto-collab",
      "userHtmlUrl" : "https://github.com/kakatoto-collab",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/54040991?v=4",
      "labels" : [ "topic:physics", "documentation", "confirmed", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I don't have things set up to test with C#. But I strongly suspect the problem comes from when the sprite is added. You are creating the CanvasItem and issuing the draw command from the _process() function instead of doing the draw commands during the _draw() function. \r\n\r\nIn the scene-level API Godot enforces that all drawing operations are done through the _draw() function. I suspect that there is an order of operations issue happening here. \r\n\r\nI tried recreating the MRP in GDScript, but I can't reproduce the issue:\r\n```gdscript\r\nextends Node2D\r\n\r\nvar sprite_sheet: Texture2D\r\n\r\n# Called when the node enters the scene tree for the first time.\r\nfunc _ready() -> void:\r\n\tsprite_sheet = load(\"res://icon.svg\")\r\n\r\n\r\n# Called every frame. 'delta' is the elapsed time since the previous frame.\r\nfunc _process(delta: float) -> void:\r\n\tget_dev_input()\r\n\r\n\r\nfunc get_dev_input():\r\n\tif Input.is_action_just_pressed(\"ui_click_left\"):\r\n\t\ton_mouse_left_click()\r\n\t\r\nfunc on_mouse_left_click():\r\n\tunsafe_test_draw()\r\n\t\r\nfunc unsafe_test_draw():\r\n\tvar src_rect = Rect2(Vector2(0, 0), Vector2(128, 128))\r\n\tvar rid = RenderingServer.canvas_item_create()\r\n\tRenderingServer.canvas_item_set_parent(rid, get_canvas_item())\r\n\r\n\tvar rect = Rect2(Vector2.ZERO, src_rect.size)\r\n\tsprite_sheet.draw_rect_region(rid, rect, src_rect)\r\n\r\n\tvar transform_2d = Transform2D.IDENTITY\r\n\ttransform_2d.origin = get_global_mouse_position()\r\n\tRenderingServer.canvas_item_set_transform(rid, transform_2d)\r\n```", "Thanks for your reply, following your idea, I changed my code to this : \r\n\r\n```csharp\r\n\r\nusing Godot;\r\nusing System;\r\n\r\npublic partial class Game : Node2D\r\n{\r\n\tpublic World world;\r\n    public Texture2D Spritesheet;\r\n\r\n    public override void _Ready()\r\n\t{\r\n        Spritesheet = ResourceLoader.Load(\"res://Assets/Textures/Spritesheet.png\") as Texture2D;\r\n\r\n        world = GetNode(\"%World\") as World;\r\n\t}\r\n\r\n    public override void _Process(double delta)\r\n\t{\r\n        QueueRedraw();\r\n    }\r\n\r\n    public override void _Draw()\r\n    {\r\n        GetDevInput();\r\n    }\r\n\r\n    private void GetDevInput()\r\n    {\r\n        if (Input.IsActionJustPressed(\"ui_click_left\"))\r\n        {\r\n            OnMouseLeftClick();\r\n        }\r\n\r\n    }\r\n\r\n    private void OnMouseLeftClick()\r\n    {\r\n        UnsafeTestDraw();\r\n    }\r\n\r\n    private void UnsafeTestDraw()\r\n    {\r\n        Rect2 srcRect = new Rect2(new Vector2(256, 32), new Vector2(16, 16));\r\n        Rid rid = RenderingServer.CanvasItemCreate();\r\n        RenderingServer.CanvasItemSetParent(rid, world.entityLayer.GetCanvasItem());\r\n        Rect2 rect = new Rect2(Vector2.Zero, srcRect.Size);\r\n        Spritesheet.DrawRectRegion(rid, rect, srcRect);\r\n\r\n        Transform2D transform2D = Transform2D.Identity;\r\n        transform2D.Origin = GetGlobalMousePosition();\r\n        RenderingServer.CanvasItemSetTransform(rid, transform2D);\r\n    }\r\n}\r\n\r\n```\r\n\r\nbut the bug still occurs. ", "![BugSpritesJUmpingOnInstanciation](https://github.com/user-attachments/assets/5011d745-f1f1-45cc-8edc-598e42925c23)\r\n\r\nI created a gif so that you can see what happens @clayjohn  .", "Hmmm, let's see if someone from the @godotengine/dotnet team can confirm if this is a C# issue", "I'm able to reproduce with GDScript. I'll upload the ported MRP, but it's not too different from https://github.com/godotengine/godot/issues/94988#issuecomment-2261665421.\r\n\r\n[BugSpriteJumpingAtInstanciationGD.zip](https://github.com/user-attachments/files/16537583/BugSpriteJumpingAtInstanciationGD.zip)\r\n\r\n", "Thanks @raulsntos I can reproduce the issue with your MRP. I was able to narrow it down to physics interpolation. When you turn off physics interpolation, the issue goes away. ", "I took a quick look at how our CanvasItem code handles physics interpolation to avoid this issue. You have to flag for the RenderingServer that this item shouldn't be interpolated the frame it is created using: `RenderingServer.canvas_item_reset_physics_interpolation(rid)`\r\n\r\nI confirmed in the MRP from RaulSntos that adding that function is all that is needed to fix the issue. \r\n\r\n", "I confirm that the bug is solved here by deactivating Physics Interpolation in Project Settings. Thanks guys, great job!", "Sorry I closed by accident, I am not used to work on Github. ", "@kakatoto-collab I am new to Open Source and would like to contribute. Can I contribute to this?", "@cmagapu yes! Please go ahead ", "@kakatoto-collab Hey, I want to help with this project. How do I start?", "> @kakatoto-collab I am new to Open Source and would like to contribute. Can I contribute to this?\r\n\r\nYes sure, I am not the best to help you to do so though.", "@clayjohn so the task here is to document how the bug was solved (by deactivating Physics Interpolation in Project Settings), correct?\r\nDoes that mean I have to raise a PR here: https://github.com/godotengine/godot-docs ?", "No the documentation for classes is handled here", "> No the documentation for classes is handled here\r\n\r\nSo should add this to documentation or should we attempt to fix it?\r\n", "Hi, looking to make a contribution for OS project. How can I start?", "> Hi, looking to make a contribution for OS project. How can I start?\r\n\r\nA note needs to be added to the [documentation page](https://docs.godotengine.org/en/latest/tutorials/performance/using_servers.html) about servers letting users know that they should reset physics interpolation on the first frame an object is created using `RenderingServer.canvas_item_reset_physics_interpolation(rid)`", "Can't we reset physics interpolation  internally inside the engine on the first frame an object is created using `RenderingServer.canvas_item_reset_physics_interpolation(rid)` as this behavior is abnormal?", "> Can't we reset physics interpolation internally inside the engine on the first frame an object is created using `RenderingServer.canvas_item_reset_physics_interpolation(rid)` as this behavior is abnormal?\r\n\r\nMaybe! I'm not sure how that would work, here is what the function currently does:\r\n```\r\nvoid RendererCanvasCull::canvas_item_reset_physics_interpolation(RID p_item) {\r\n\tItem *canvas_item = canvas_item_owner.get_or_null(p_item);\r\n\tERR_FAIL_NULL(canvas_item);\r\n\tcanvas_item->xform_prev = canvas_item->xform_curr;\r\n}\r\n```\r\nYou could look into whether its possible to detect when xform_curr is set initially and then init xform_prev at the same time. Or handle the first frame in some other way.  \r\n\r\nThe way its implemented now, it needs to be called after the position is set, but if you can figure out a way around that, it would be a nice improvement!", "I want to contribute to Godot. Can I start here?", "Hello! I was trying to figure out this bug, but I don't think it is. It appears as expected behaviour.\r\n\r\nI made this change in Game.gd:\r\n```\r\nfunc unsafe_test_draw():\r\n\tvar src_rect: Rect2 = Rect2(Vector2(256, 32), Vector2(16, 16))\r\n\tvar rid: RID = RenderingServer.canvas_item_create()\r\n\tRenderingServer.canvas_item_set_parent(rid, world.entity_layer.get_canvas_item())\r\n\tvar rect: Rect2 = Rect2(Vector2(get_global_mouse_position()), src_rect.size)\r\n\tspritesheet.draw_rect_region(rid, rect, src_rect)\r\n```\r\n\r\nIt is set to start at Vector2.ZERO() then it translates to this mouse position. This would make it appear at (0,0) first, then move to it's proper location.\r\n\r\nHere it is in a gif:\r\n![bug](https://github.com/user-attachments/assets/61d8bfb6-3ecc-4350-8c4d-220769714ca9)\r\n", "hi, i would like to contribute to solving this issue. how can i do that? this is for a uni project ", "I agree with mcdubhghlas. I'm new to Godot and was not able to build the required version of Godot with dotnet in order to test the issue. However, from what I saw and what mcdubhghlas said it seems like the sprite appearing in between the origin and the specified coordinates is because physics interpolation causes the sprite to be drawn in between frames at an interpolated matrix (as said by Tuckertcs in the reddit thread below). In addition, the Godot docs also address this specific issue in the \"Call reset_physics_interpolation() when teleporting objects\" section. It states that to solve the issue stated in the post, you need to call reset_physics_interpolation() after setting the position/transform of the node and there won't be any unwanted streaking or intermediate sprites.\n\nIf this is right could this issue be closed? Thank you.\n\nReddit thread discussing physics interpolation:\nhttps://www.reddit.com/r/godot/comments/1cxzhkp/are_there_any_downsides_of_physics_interpolation/\n\nGodot docs regarding physics interpolation:\nhttps://docs.godotengine.org/en/3.5/tutorials/physics/interpolation/using_physics_interpolation.html" ],
      "repository" : {
        "description" : "Godot Engine ??? Multi-platform 2D and 3D game engine",
        "homepage" : "https://godotengine.org",
        "name" : "godot",
        "fullName" : "godotengine/godot",
        "htmlUrl" : "https://github.com/godotengine/godot",
        "gitUrl" : "git://github.com/godotengine/godot.git",
        "sshUrl" : "git@github.com:godotengine/godot.git",
        "cloneUrl" : "https://github.com/godotengine/godot.git",
        "owner" : {
          "login" : "godotengine",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 22778,
        "stargazersCount" : 98803,
        "watchersCount" : 98803,
        "size" : 1608396,
        "openIssuesCount" : 15746,
        "subscribersCount" : 1495,
        "pushedAt" : "2025-07-10T16:49:51Z",
        "languages" : {
          "C#" : 2221118,
          "Java" : 1942019,
          "C++" : 57349319,
          "C" : 2096437,
          "Objective-C++" : 1042409,
          "CMake" : 874,
          "GDScript" : 275458,
          "AIDL" : 1633,
          "Kotlin" : 338586,
          "Shell" : 7378,
          "JavaScript" : 291356,
          "GAP" : 66,
          "GLSL" : 1119844,
          "Python" : 649478
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the problem of a texture appearing at a wrong position during one frame in the game scene when using the RenderingServer to add a texture to the scene.",
      "validationOrRequirement" : "The issue requires the use of `RenderingServer.canvas_item_reset_physics_interpolation(rid)` to reset physics interpolation on the first frame an object is created.",
      "attemptedFixes" : "The author tried to fix the issue by changing the code to use `_draw()` function instead of `_process()` function, but the bug still occurred. The issue was also tested with GDScript, and the bug was still present.",
      "otherNotes" : "The issue was caused by physics interpolation, and the solution was to reset physics interpolation on the first frame an object is created using `RenderingServer.canvas_item_reset_physics_interpolation(rid)`. The author of the issue was able to reproduce the issue with a minimal reproduction project, and the issue was confirmed by others. The solution was tested and confirmed to work by the author and others.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283792
  }, {
    "issueDTO" : {
      "id" : 359187635,
      "title" : "Erro em aloca????o de bolsas ",
      "url" : "https://github.com/gems-uff/sapos/issues/269",
      "repositoryName" : "gems-uff/sapos",
      "description" : "O SAPOS est?? dando erro no momento em que se tenta alterar a data de fim de uma bolsa. Ele percorre a lista de aloca????es de bolsa e d?? as seguintes mensagens, para cada aloca????o: \r\n\r\nPara as 3 aloca????es da bolsa em quest??o, aparece a mensagem: \r\n\r\n- Data Limite de Concess??o posterior ?? data de fim de bolsa (e essa mensagem n??o est?? correta, pois as datas est??o consistentes) \r\n\r\nPara a segunda aloca????o (e apenas a segunda), aparece a mensagem:\r\n\r\n- Data de In??cio da aloca????o de bolsa deve ser posterior a data de limite de concess??o de uma aloca????o que n??o tem data de encerramento \r\n\r\nAl??m disso, em algum momento o SAPOS deixou realizar uma aloca????o de uma bolsa que j?? tinha sido encerrada (CAPESDDS12 encerrada em 2017, e o SAPOS deixou alocar em Mar??o de 2018 -- provavelmente usando a tela de aloca????o de bolsas, mas n??o h?? certeza disso). \r\n\r\n",
      "updatedAt" : 1752244014.000000000,
      "user" : "braganholo",
      "userHtmlUrl" : "https://github.com/braganholo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1494494?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Para ficar claro: a bolsa estava com data de encerramento incorreta. Eu ent??o exclu?? a aloca????o que feria os limites. Isso foi ok. Depois, entei alterar a data de encerramento da bolsa para vazio (mes e ano vazios). Deu a mensagem de erro acima para as aloca????es do passado dessa bolsa. Depois, tentei alterar a data de encerramento para uma data no futuro. Tamb??m deu os mesmos erros. " ],
      "repository" : {
        "description" : "SAPOS main goal is to ease the management of information related to graduate programs such as enrollments, courses, advisement, scholarships, requirements, among others.",
        "homepage" : "http://gems-uff.github.io/sapos/",
        "name" : "sapos",
        "fullName" : "gems-uff/sapos",
        "htmlUrl" : "https://github.com/gems-uff/sapos",
        "gitUrl" : "git://github.com/gems-uff/sapos.git",
        "sshUrl" : "git@github.com:gems-uff/sapos.git",
        "cloneUrl" : "https://github.com/gems-uff/sapos.git",
        "owner" : {
          "login" : "gems-uff",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 24089,
        "openIssuesCount" : 57,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:41:36Z",
        "languages" : {
          "Liquid" : 10328,
          "CSS" : 1542,
          "SCSS" : 31241,
          "JavaScript" : 93961,
          "HTML" : 233468,
          "Ruby" : 2693088
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the error in allocating scholarships when trying to change the end date of a scholarship.",
      "validationOrRequirement" : "The issue requires the data start date of a scholarship allocation to be posterior to the concession deadline of another allocation that does not have an end date.",
      "attemptedFixes" : "The author tried to fix the issue by excluding the allocation that was causing the error, then tried to change the end date of the scholarship to an empty value (month and year empty). However, this still resulted in the same error.",
      "otherNotes" : "The issue is related to an error in allocating scholarships, specifically when trying to change the end date of a scholarship. The error message mentions inconsistent dates, but the dates are actually consistent. Additionally, there was an incident where a scholarship was allocated that had already been closed (CAPESDDS12 was closed in 2017, but the SAPOS system allocated it in March 2018).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283798
  }, {
    "issueDTO" : {
      "id" : 496454224,
      "title" : "Prorroga????es finais concedidas n??o aparecem na tela de Prorroga????es Concedidas ",
      "url" : "https://github.com/gems-uff/sapos/issues/302",
      "repositoryName" : "gems-uff/sapos",
      "description" : "Helio reportou um problema: a tela de prorroga????es concedidas n??o est?? mostrando as prorroga????es finais concedidas em Julho/2019. Isso ?? certamente um bug. Eu reproduzi aqui, ordenando as prorroga????es concedidas por data, e realmente as finais n??o aparecem. Mas, ao consultar a matr??cula de algum aluno que teve essa prorroga????o, ela aparece l?? corretamente (exemplo, aluno de doutorado de matr??cula final 214.007). \r\n\r\n",
      "updatedAt" : 1752243972.000000000,
      "user" : "braganholo",
      "userHtmlUrl" : "https://github.com/braganholo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1494494?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "SAPOS main goal is to ease the management of information related to graduate programs such as enrollments, courses, advisement, scholarships, requirements, among others.",
        "homepage" : "http://gems-uff.github.io/sapos/",
        "name" : "sapos",
        "fullName" : "gems-uff/sapos",
        "htmlUrl" : "https://github.com/gems-uff/sapos",
        "gitUrl" : "git://github.com/gems-uff/sapos.git",
        "sshUrl" : "git@github.com:gems-uff/sapos.git",
        "cloneUrl" : "https://github.com/gems-uff/sapos.git",
        "owner" : {
          "login" : "gems-uff",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 24089,
        "openIssuesCount" : 57,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:41:36Z",
        "languages" : {
          "Liquid" : 10328,
          "CSS" : 1542,
          "SCSS" : 31241,
          "JavaScript" : 93961,
          "HTML" : 233468,
          "Ruby" : 2693088
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Display final extensions conceded in July 2019 on the 'Conceded Extensions' page",
      "validationOrRequirement" : "Check the ordering of extensions by date and verify if the final extensions are correctly stored in the database",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is about final extensions not appearing on the 'Conceded Extensions' page, specifically for July 2019. The problem was reported by Helio and reproduced by the author, but the extensions appear correctly on the student's record.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283802
  }, {
    "issueDTO" : {
      "id" : 452698295,
      "title" : "C??lculo de Limite de Concess??o de Bolsa incorreto",
      "url" : "https://github.com/gems-uff/sapos/issues/294",
      "repositoryName" : "gems-uff/sapos",
      "description" : "Na hora de fazer uma aloca????o de bolsa para um aluno, ao selecionar a bolsa no combobox, o SAPOS preenche automaticamente a data limite de concess??o. Essa data est?? sendo calculada de forma errada. Para uma bolsa com in??cio de aloca????o em Marco de 2019 ele calcula e preenche o combo de data limite para Julho de 2015, o que n??o faz nenhum sentido. A data limite tem que ser a soma da dura????o do curso ?? data de matr??cula do aluno (pegar esse valor do campo dura????o padr??o em meses no cadastro do n??vel correspondente daquela matr??cula), ou a data de fim da bolsa, o que for menor. \r\n\r\nExemplo 1: \r\n- data de fim da bolsa = Maio de 2019\r\n- data de matr??cula do aluno = Mar??o de 2017 \r\n- n??vel do aluno = Doutorado\r\n- dura????o padr??o do Doutorado (ver no cadastro de n??vel) = 48 meses\r\n- data de in??cio da aloca????o da bolsa de doutorado = Mar??o de 2019 \r\n\r\nNesse exemplo o SAPOS deveria preencher o campo Data Limite de Concess??o da aloca????o de bolsa como Maio de 2019, que ?? a data de fim da bolsa.\r\n\r\nExemplo 2: \r\n- data de fim da bolsa = NULL\r\n- data de matr??cula do aluno = Mar??o de 2017 \r\n- n??vel do aluno = Doutorado\r\n- dura????o padr??o do Doutorado (ver no cadastro de n??vel) = 48 meses\r\n- data de in??cio da aloca????o da bolsa de doutorado = Mar??o de 2019 \r\n\r\nNesse exemplo o SAPOS deveria preencher o campo Data Limite de Concess??o da aloca????o de bolsa como Fevereiro de 2021 (que ?? Mar??o de 2017 + 48 meses)  \r\n\r\n ",
      "updatedAt" : 1752243968.000000000,
      "user" : "braganholo",
      "userHtmlUrl" : "https://github.com/braganholo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1494494?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "SAPOS main goal is to ease the management of information related to graduate programs such as enrollments, courses, advisement, scholarships, requirements, among others.",
        "homepage" : "http://gems-uff.github.io/sapos/",
        "name" : "sapos",
        "fullName" : "gems-uff/sapos",
        "htmlUrl" : "https://github.com/gems-uff/sapos",
        "gitUrl" : "git://github.com/gems-uff/sapos.git",
        "sshUrl" : "git@github.com:gems-uff/sapos.git",
        "cloneUrl" : "https://github.com/gems-uff/sapos.git",
        "owner" : {
          "login" : "gems-uff",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 24089,
        "openIssuesCount" : 57,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:41:36Z",
        "languages" : {
          "Liquid" : 10328,
          "CSS" : 1542,
          "SCSS" : 31241,
          "JavaScript" : 93961,
          "HTML" : 233468,
          "Ruby" : 2693088
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "C??lculo de Limite de Concess??o de Bolsa incorreto",
      "validationOrRequirement" : "The system should calculate the date limit correctly by summing the course duration and the student's enrollment date, or the scholarship end date, whichever is smaller.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is about incorrect calculation of the limit date of a scholarship. The SAPOS system is supposed to automatically fill the date limit field when a scholarship is selected, but it's calculating it incorrectly. The correct calculation should be the sum of the course duration and the student's enrollment date, or the scholarship end date, whichever is smaller.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283807
  }, {
    "issueDTO" : {
      "id" : 429443389,
      "title" : "Desligamento n??o funciona na tela de matr??cula",
      "url" : "https://github.com/gems-uff/sapos/issues/291",
      "repositoryName" : "gems-uff/sapos",
      "description" : "Quando tento desligar um aluno usando a tela de edi????o de matr??cula, o desligamento n??o ?? efetuado e nenhuma mensagem de erro aparece. Quando fa??o isso pela tela de desligamentos,  o desligamento ?? inclu??do com sucesso. ",
      "updatedAt" : 1752243967.000000000,
      "user" : "braganholo",
      "userHtmlUrl" : "https://github.com/braganholo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1494494?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Aparentemente o bug ?? intermitente, pois eu testei depois novamente e funcionou pela tela de matr??cula. " ],
      "repository" : {
        "description" : "SAPOS main goal is to ease the management of information related to graduate programs such as enrollments, courses, advisement, scholarships, requirements, among others.",
        "homepage" : "http://gems-uff.github.io/sapos/",
        "name" : "sapos",
        "fullName" : "gems-uff/sapos",
        "htmlUrl" : "https://github.com/gems-uff/sapos",
        "gitUrl" : "git://github.com/gems-uff/sapos.git",
        "sshUrl" : "git@github.com:gems-uff/sapos.git",
        "cloneUrl" : "https://github.com/gems-uff/sapos.git",
        "owner" : {
          "login" : "gems-uff",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 24089,
        "openIssuesCount" : 57,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:41:36Z",
        "languages" : {
          "Liquid" : 10328,
          "CSS" : 1542,
          "SCSS" : 31241,
          "JavaScript" : 93961,
          "HTML" : 233468,
          "Ruby" : 2693088
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The desligamento feature does not work when trying to disable a student through the matricula screen, but it works when using the desligamentos screen.",
      "validationOrRequirement" : "The issue seems to be related to the desligamento functionality in the matricula screen.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The bug is intermittent, as the author tested it again and it worked through the matricula screen.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283810
  }, {
    "issueDTO" : {
      "id" : 3215005423,
      "title" : "Add version info to resources tab",
      "url" : "https://github.com/bisq-network/bisq2/issues/3603",
      "repositoryName" : "bisq-network/bisq2",
      "description" : "The version info is a bit hidden in network/p2p network - local version info\n\nWe should move or duplicate that content to Support/Resources before Web resources. ",
      "updatedAt" : 1752243927.000000000,
      "user" : "HenrikJannsen",
      "userHtmlUrl" : "https://github.com/HenrikJannsen",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/116298498?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello.  I'd like to work on this if you can assign it to me.  " ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "bisq2",
        "fullName" : "bisq-network/bisq2",
        "htmlUrl" : "https://github.com/bisq-network/bisq2",
        "gitUrl" : "git://github.com/bisq-network/bisq2.git",
        "sshUrl" : "git@github.com:bisq-network/bisq2.git",
        "cloneUrl" : "https://github.com/bisq-network/bisq2.git",
        "owner" : {
          "login" : "bisq-network",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 92,
        "stargazersCount" : 248,
        "watchersCount" : 248,
        "size" : 301201,
        "openIssuesCount" : 164,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-11T14:16:19Z",
        "languages" : {
          "Java" : 9757224,
          "Dockerfile" : 757,
          "CSS" : 377645,
          "Shell" : 13784,
          "Jinja" : 658,
          "Makefile" : 11757,
          "JavaScript" : 58334,
          "AppleScript" : 1666,
          "HTML" : 6506,
          "AGS Script" : 24,
          "Kotlin" : 96792
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add version info to resources tab",
      "validationOrRequirement" : "move or duplicate the content to Support/Resources before Web resources",
      "attemptedFixes" : "",
      "otherNotes" : "The version info is currently hidden in network/p2p network - local version info",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283812
  }, {
    "issueDTO" : {
      "id" : 1864132222,
      "title" : "Campo \"Data de expedi????o da Identidade\" de professores est?? como string ao inv??s de data",
      "url" : "https://github.com/gems-uff/sapos/issues/442",
      "repositoryName" : "gems-uff/sapos",
      "description" : "Estou adicionando um widget de data neste campo, mas no BD continua como string (diferente do mesmo campo em aluno). Ser?? que devemos fazer uma migration para transformar em data?",
      "updatedAt" : 1752243871.000000000,
      "user" : "JoaoFelipe",
      "userHtmlUrl" : "https://github.com/JoaoFelipe",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/327789?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Em princ??pio sim. S?? seria interessante antes ver os demais usos desse campo no Sapos, e o pr??prio commit que criou o campo, para entender se h?? uma raz??o em ser string." ],
      "repository" : {
        "description" : "SAPOS main goal is to ease the management of information related to graduate programs such as enrollments, courses, advisement, scholarships, requirements, among others.",
        "homepage" : "http://gems-uff.github.io/sapos/",
        "name" : "sapos",
        "fullName" : "gems-uff/sapos",
        "htmlUrl" : "https://github.com/gems-uff/sapos",
        "gitUrl" : "git://github.com/gems-uff/sapos.git",
        "sshUrl" : "git@github.com:gems-uff/sapos.git",
        "cloneUrl" : "https://github.com/gems-uff/sapos.git",
        "owner" : {
          "login" : "gems-uff",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 24089,
        "openIssuesCount" : 57,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:41:36Z",
        "languages" : {
          "Liquid" : 10328,
          "CSS" : 1542,
          "SCSS" : 31241,
          "JavaScript" : 93961,
          "HTML" : 233468,
          "Ruby" : 2693088
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to transform the 'Data de expedi????o da Identidade' field of professors from a string to a date.",
      "validationOrRequirement" : "The field should be stored as a date, not a string, and the author is looking for a solution to fix this.",
      "attemptedFixes" : "The author is considering creating a migration, but wants to investigate further to understand why the field was created as a string in the first place.",
      "otherNotes" : "The issue is related to a field in the database being stored as a string instead of a date, and the author is considering creating a migration to fix this.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283817
  }, {
    "issueDTO" : {
      "id" : 1677316214,
      "title" : "Novas checagens para aloca????o de bolsa",
      "url" : "https://github.com/gems-uff/sapos/issues/434",
      "repositoryName" : "gems-uff/sapos",
      "description" : "Seria interessante a cria????o de algumas novas checagens de datas para a aloca????o de bolsas\r\n\r\nNo caso, poderiam ser barradas e alertadas as seguintes situa????es:\r\n\r\n- Se algu??m tentar cadastrar um novo aluno sem ter cadastrado a data de encerramento do anterior\r\n- Se algu??m tentar cadastrar uma data de fim da bolsa com alguma aloca????o ainda sem encerramento",
      "updatedAt" : 1752243869.000000000,
      "user" : "Carlos-Eduardo-Cabral-da-Cunha",
      "userHtmlUrl" : "https://github.com/Carlos-Eduardo-Cabral-da-Cunha",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20929931?v=4",
      "labels" : [ "priority", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Parece semelhante a #269 " ],
      "repository" : {
        "description" : "SAPOS main goal is to ease the management of information related to graduate programs such as enrollments, courses, advisement, scholarships, requirements, among others.",
        "homepage" : "http://gems-uff.github.io/sapos/",
        "name" : "sapos",
        "fullName" : "gems-uff/sapos",
        "htmlUrl" : "https://github.com/gems-uff/sapos",
        "gitUrl" : "git://github.com/gems-uff/sapos.git",
        "sshUrl" : "git@github.com:gems-uff/sapos.git",
        "cloneUrl" : "https://github.com/gems-uff/sapos.git",
        "owner" : {
          "login" : "gems-uff",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 24089,
        "openIssuesCount" : 57,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:41:36Z",
        "languages" : {
          "Liquid" : 10328,
          "CSS" : 1542,
          "SCSS" : 31241,
          "JavaScript" : 93961,
          "HTML" : 233468,
          "Ruby" : 2693088
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create new checks for scholarship allocation to prevent common errors",
      "validationOrRequirement" : "Check for: 1) no previous student's end date when adding new student, 2) no ongoing allocation when setting new end date for scholarship",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Similar to #269",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283819
  }, {
    "issueDTO" : {
      "id" : 1677304652,
      "title" : "Erro sem tratamento em aloca????o de bolsa    ",
      "url" : "https://github.com/gems-uff/sapos/issues/433",
      "repositoryName" : "gems-uff/sapos",
      "description" : "Ao se tentar criar uma aloca????o de bolsa, cuja a data de inicio coincida com a data de encerramento de uma outra aloca????o j?? existente para a mesma bolsa, ocorre um erro na p??gina que n??o ?? tratado. O desej??vel ?? que essa tentativa de criar uma aloca????o seja tratada e n??o permitida, com a exibi????o uma mensagem. ",
      "updatedAt" : 1752243868.000000000,
      "user" : "Carlos-Eduardo-Cabral-da-Cunha",
      "userHtmlUrl" : "https://github.com/Carlos-Eduardo-Cabral-da-Cunha",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20929931?v=4",
      "labels" : [ "priority", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "SAPOS main goal is to ease the management of information related to graduate programs such as enrollments, courses, advisement, scholarships, requirements, among others.",
        "homepage" : "http://gems-uff.github.io/sapos/",
        "name" : "sapos",
        "fullName" : "gems-uff/sapos",
        "htmlUrl" : "https://github.com/gems-uff/sapos",
        "gitUrl" : "git://github.com/gems-uff/sapos.git",
        "sshUrl" : "git@github.com:gems-uff/sapos.git",
        "cloneUrl" : "https://github.com/gems-uff/sapos.git",
        "owner" : {
          "login" : "gems-uff",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 24089,
        "openIssuesCount" : 57,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:41:36Z",
        "languages" : {
          "Liquid" : 10328,
          "CSS" : 1542,
          "SCSS" : 31241,
          "JavaScript" : 93961,
          "HTML" : 233468,
          "Ruby" : 2693088
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a scholarship allocation without allowing the start date to be the same as the end date of an existing allocation for the same scholarship.",
      "validationOrRequirement" : "The allocation start date cannot be the same as the end date of an existing allocation for the same scholarship.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description or comments.",
      "otherNotes" : "The issue is about an error that occurs when trying to create a scholarship allocation with the same start and end date as an existing allocation for the same scholarship, and the desired behavior is to prevent this and show a message instead.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283824
  }, {
    "issueDTO" : {
      "id" : 3220448406,
      "title" : "Migrate payjoin-cli Sled db to sqlite3",
      "url" : "https://github.com/payjoin/rust-payjoin/issues/867",
      "repositoryName" : "payjoin/rust-payjoin",
      "description" : "![Image](https://github.com/user-attachments/assets/b7a4755c-7acd-4265-9c2e-435f188fd001)\n\n_Most_ of our current integrations use some form of sql-like database (Liana, bullbitcoin, bitcoin-core wallet, cake(?)). Payjoin-cli should migrate from sled to sqlite3 so our reference can continue to serve as an example for downstream wallet developers. Not a high priority. Wanted to make a note of this before I forget.  ",
      "updatedAt" : 1752243403.000000000,
      "user" : "arminsabouri",
      "userHtmlUrl" : "https://github.com/arminsabouri",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/24356537?v=4",
      "labels" : [ "enhancement", "good first issue", "payjoin-cli" ],
      "state" : "OPEN",
      "comments" : [ "The [crate by the name of sqlite3](https://crates.io/crates/sqlite3/versions) is 7 years old and unmaintained, so I'm assuming you just mean the actual database. Seems like we could use a slightly older version of [rusqlite 0.29](https://crates.io/crates/rusqlite/0.29.0) to make this happen", "Yes Thanks for pointing that out. sqlite3 the binary not the library. The library I have used is [rustqlite](https://github.com/rusqlite/rusqlite) with [r2d2](https://crates.io/crates/r2d2) for the connection pool", "FWIW [ldk-node uses 0.31.0](https://github.com/lightningdevkit/ldk-node/pull/403), IIUC that specific version of rusqlite is also in use in other projects and supports the MSRV of 1.63", "I'd like to handle this issue", "@Mshehu5 thanks for volunteering!\nI want to be clear about what the expected outcome. For both the receiver and sender there should be two tables:\n* Sessions: includes a primary key. IIRC in payjoin-cli today we call it session id and a `completed_at` timestamp which serves as a indicator for whether or not the session is closed.\n* Session events. When the session persister's `save_event` is invoke it should add a row to this table. Session events should include some form of `created_at` timestamp so they are sortable when we load them in the session persister. Lastly this table should have a fk relationship with the sessions table.\n" ],
      "repository" : {
        "description" : "Supercharged payment batching to save you fees and preserve your privacy",
        "homepage" : "https://payjoindevkit.org",
        "name" : "rust-payjoin",
        "fullName" : "payjoin/rust-payjoin",
        "htmlUrl" : "https://github.com/payjoin/rust-payjoin",
        "gitUrl" : "git://github.com/payjoin/rust-payjoin.git",
        "sshUrl" : "git@github.com:payjoin/rust-payjoin.git",
        "cloneUrl" : "https://github.com/payjoin/rust-payjoin.git",
        "owner" : {
          "login" : "payjoin",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 65,
        "stargazersCount" : 114,
        "watchersCount" : 114,
        "size" : 2671,
        "openIssuesCount" : 107,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T19:54:44Z",
        "languages" : {
          "Dockerfile" : 1777,
          "Shell" : 6491,
          "Rust" : 858515,
          "Nix" : 6351,
          "Python" : 18944
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Migrate payjoin-cli Sled db to sqlite3, so our reference can continue to serve as an example for downstream wallet developers.",
      "validationOrRequirement" : "The issue mentions that the Sessions table should include a primary key, a `completed_at` timestamp, and a `created_at` timestamp in the Session events table, with a fk relationship between the two tables.",
      "attemptedFixes" : "The comment mentions that sqlite3 the binary, not the library, should be used, and that a specific version of rusqlite 0.31.0 is in use in other projects and supports the MSRV of 1.63.",
      "otherNotes" : "Payjoin-cli should migrate from sled to sqlite3, using a slightly older version of rusqlite 0.29. The library used is rustqlite with r2d2 for the connection pool. The expected outcome is two tables: Sessions and Session events, with specific columns and relationships.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283830
  }, {
    "issueDTO" : {
      "id" : 3172875830,
      "title" : "Consolidation of Selective Build APIs for OSS",
      "url" : "https://github.com/pytorch/executorch/issues/11921",
      "repositoryName" : "pytorch/executorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nCurrently, there are three ways a user can enable the selective build process:\n\n0. Disable selective build and include all operators.\n1. Specify a string list of operators.\n2. Provide a YAML file to enumerate which operators and dtypes should be included.\n3. Provide a exported model (pte) to tailor the executorch build to the operators and tensor dtypes used in the model.\n\nRight now, these APIs are treated as [mutually exclusive](https://github.com/pytorch/executorch/blob/752f6a729d3a2090b43ace6915086d8b4e03644f/codegen/tools/gen_oplist.py#L222-L228), but there are use cases where a mixture of methods would be desirable. It would be ideal if there was a clearer/default way to enable selective builds without exposing too much of the configuration burden onto a user. \n\n### Example Use Case\n\nA user wants to run two different models, where the second model only contains one differing operator. The user could determine the complete union of operators used by the two models, and manually specify them using the list API, but it would be easier if they could simply pass in one of the models and augment the selected operator set with the single differing operator (i.e. use the model API in conjunction with the list API). \n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### RFC (Optional)\n\n_No response_",
      "updatedAt" : 1752243007.000000000,
      "user" : "BujSet",
      "userHtmlUrl" : "https://github.com/BujSet",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/23427946?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @lucylq @psiddh " ],
      "repository" : {
        "description" : "On-device AI across mobile, embedded and edge for PyTorch",
        "homepage" : "https://pytorch.org/executorch/",
        "name" : "executorch",
        "fullName" : "pytorch/executorch",
        "htmlUrl" : "https://github.com/pytorch/executorch",
        "gitUrl" : "git://github.com/pytorch/executorch.git",
        "sshUrl" : "git@github.com:pytorch/executorch.git",
        "cloneUrl" : "https://github.com/pytorch/executorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 613,
        "stargazersCount" : 3029,
        "watchersCount" : 3029,
        "size" : 238670,
        "openIssuesCount" : 1225,
        "subscribersCount" : 70,
        "pushedAt" : "2025-07-12T00:52:56Z",
        "languages" : {
          "Java" : 91154,
          "C++" : 7468950,
          "Jinja" : 11160,
          "C" : 92510,
          "Objective-C++" : 585572,
          "CMake" : 253562,
          "Kotlin" : 47365,
          "Dockerfile" : 2690,
          "Shell" : 234857,
          "Starlark" : 485277,
          "Batchfile" : 339,
          "Objective-C" : 192295,
          "Swift" : 90538,
          "Python" : 9370932,
          "GLSL" : 313850
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Consolidate selective build APIs for OSS, allowing a mixture of methods to be used and reducing the configuration burden on users.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about consolidating selective build APIs for OSS, currently there are three ways to enable selective build process, but they are treated as mutually exclusive and it would be ideal to have a clearer/default way to enable selective builds without exposing too much configuration burden onto a user.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283834
  }, {
    "issueDTO" : {
      "id" : 3222915144,
      "title" : "????????????????????????????????????????????????",
      "url" : "https://github.com/pt-plugins/PT-depiler/issues/272",
      "repositoryName" : "pt-plugins/PT-depiler",
      "description" : "## ?????????????????????????????????????????? ??????????????????\n<!-- ???????????????????????????????????? -->\n??????????????????????????????????????????????????????????????? [????????????] ??????\n\n## ??????????????????????????????\n<!-- ?????????????????? -->\n??????????????????????????????????????????????????? ????????? / ???????????? ?????????????????????????????????????????????????????????????????????url\n",
      "updatedAt" : 1752242928.000000000,
      "user" : "KeepNaivety3",
      "userHtmlUrl" : "https://github.com/KeepNaivety3",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/101695437?v=4",
      "labels" : [ "documentation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "????????????????????????????????????????????????????????????????????????", "> ????????????????????????????????????????????????????????????????????????\n\n?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????", "> > ????????????????????????????????????????????????????????????????????????\n> \n> ?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n\n???????????????????????????????????????????????????\n<img width=\"594\" height=\"199\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5d46586a-d175-4aec-b5b7-fb6e48901b2e\" />", "??????????????????????????????????????? ISiteMetadata ???????????????????????????ts??????????????????\n\n```ts\nimport type { ISiteMetadata } from \"@ptd/site\";\n\nexport const siteMetadata: ISiteMetadata = {\n  version: 1,\n  id: \"abtorrents\",\n  name: \"ABTorrents\",\n  type: \"private\",\n  urls: [\"https://xxxxxx.me/\"],\n};\n```\n\n???????????????????????????????????????????????????????????????????????????????????????????????????????????????bug??????\n\n\n> ?????????????????????????????????????????? ???????????????????????????????????????????????????????????????????????????????????????\n\n<img width=\"319\" height=\"86\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e4dccd95-f62f-4693-a2f0-15021e78b5be\" />\n\n> ????????????????????? SetSite ??????\n\n<img width=\"1662\" height=\"256\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4ab81e59-d4b2-44c7-a25a-4626f0414fad\" />\n\n> ?????????????????? MyData ??????????????????????????????????????? `??????????????????????????????????????? ???isOffline??? ???????????????????????????????????????` ???\n\n<img width=\"1673\" height=\"306\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/719525de-138b-487d-95d1-d8f23d258735\" />" ],
      "repository" : {
        "description" : "PT-depiler ????????? PT-Plugin-Plus ???????????? ???????????????????????? Manifest v3 ???????????????????????????????????????Web Extensions?????? ?????????????????? PT ??????????????????????????????",
        "homepage" : "",
        "name" : "PT-depiler",
        "fullName" : "pt-plugins/PT-depiler",
        "htmlUrl" : "https://github.com/pt-plugins/PT-depiler",
        "gitUrl" : "git://github.com/pt-plugins/PT-depiler.git",
        "sshUrl" : "git@github.com:pt-plugins/PT-depiler.git",
        "cloneUrl" : "https://github.com/pt-plugins/PT-depiler.git",
        "owner" : {
          "login" : "pt-plugins",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 55,
        "stargazersCount" : 695,
        "watchersCount" : 695,
        "size" : 10569,
        "openIssuesCount" : 18,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-11T14:42:19Z",
        "languages" : {
          "TypeScript" : 1488383,
          "CSS" : 419608,
          "Vue" : 439963,
          "HTML" : 623
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a temporary solution for sites that are not adapted, specifically a one-key open feature to open all unadapted/sites with status exceptions in the data panel.",
      "validationOrRequirement" : "The solution should be based on ISiteMetadata with the basic convention, but this approach may cause some problems and potential bugs if the subsequent version supports the corresponding function.",
      "attemptedFixes" : "The author mentions that it's not possible to get data and search, but at least they can occasionally open unadapted sites to prevent long-term account suspension. However, it's not supported to add sites one-key, only manual addition is possible.",
      "otherNotes" : "The issue is related to adding a temporary solution for sites that are not adapted, specifically a one-key open feature. The author suggests adding a one-key open function to open all unadapted/sites with status exceptions in the data panel, which can be added manually in the settings.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283841
  }, {
    "issueDTO" : {
      "id" : 3159609204,
      "title" : "?????????docke?????????????????????",
      "url" : "https://github.com/BAI-LAB/MemoryOS/issues/6",
      "repositoryName" : "BAI-LAB/MemoryOS",
      "description" : "??????????????????docke??????????????????",
      "updatedAt" : 1752242869.000000000,
      "user" : "loulinsheng",
      "userHtmlUrl" : "https://github.com/loulinsheng",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/192186620?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "????????????????????????", "???????????????Docker??????????????????" ],
      "repository" : {
        "description" : "MemoryOS is designed to provide a memory operating system for personalized AI agents.",
        "homepage" : "https://baijia.online/memoryos/",
        "name" : "MemoryOS",
        "fullName" : "BAI-LAB/MemoryOS",
        "htmlUrl" : "https://github.com/BAI-LAB/MemoryOS",
        "gitUrl" : "git://github.com/BAI-LAB/MemoryOS.git",
        "sshUrl" : "git@github.com:BAI-LAB/MemoryOS.git",
        "cloneUrl" : "https://github.com/BAI-LAB/MemoryOS.git",
        "owner" : {
          "login" : "BAI-LAB",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 40,
        "stargazersCount" : 453,
        "watchersCount" : 453,
        "size" : 29833,
        "openIssuesCount" : 5,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-11T15:27:19Z",
        "languages" : {
          "Python" : 270102
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Request for a Docker deployment method",
      "validationOrRequirement" : "providing a Docker deployment method",
      "attemptedFixes" : "",
      "otherNotes" : "The author, loulinsheng, is asking for a Docker deployment method, and the comment mentions that it's really needed.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283843
  }, {
    "issueDTO" : {
      "id" : 3188413685,
      "title" : "Fix thank-a-contributor widget to have minimum image size",
      "url" : "https://github.com/jenkins-infra/jenkins.io/issues/8232",
      "repositoryName" : "jenkins-infra/jenkins.io",
      "description" : "### Problem with this page\n\nhttps://www.jenkins.io/, https://www.jenkins.io/download/\n\n### Expected behavior\n\nThere should be a minimum image size (say width) for the avatar image in the thank-a-contributor widget so that the image will not become too small under some circumstances like when the text occupies a lot of space. \n\n### Actual behavior\n\nThe avatar image becomes too small sometimes, like as shown as below:\n\n![Image](https://github.com/user-attachments/assets/d6899cd4-2a3a-48f3-97ae-3393bc9f497b)\n\n### Possible solution\n\nAdd a minimum width to the image\n\n### Are you interested in contributing a fix?\n\n_No response_",
      "updatedAt" : 1752242477.000000000,
      "user" : "krisstern",
      "userHtmlUrl" : "https://github.com/krisstern",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/88480540?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks Kris for raising this , I too saw this now when I was checking the footer links ", "Hey @krisstern , I???d like to contribute a fix for this issue. Please let me know if I can take it up.", "Hey @sakina1303, sure go head with a PR! ", "Hey @krisstern I am also try to fix this issue!", "@AadiSharma49 Please allow @sakina1303 sometime before taking up the issue in case no PR will be submitted by them", "@strangelookingnerd is just tooo active \uD83D\uDE09 ", "> [@strangelookingnerd](https://github.com/strangelookingnerd) is just tooo active \uD83D\uDE09\n\nI'll print & frame this in my office \uD83D\uDE06 " ],
      "repository" : {
        "description" : "A static site for the Jenkins automation server",
        "homepage" : "https://jenkins.io",
        "name" : "jenkins.io",
        "fullName" : "jenkins-infra/jenkins.io",
        "htmlUrl" : "https://github.com/jenkins-infra/jenkins.io",
        "gitUrl" : "git://github.com/jenkins-infra/jenkins.io.git",
        "sshUrl" : "git@github.com:jenkins-infra/jenkins.io.git",
        "cloneUrl" : "https://github.com/jenkins-infra/jenkins.io.git",
        "owner" : {
          "login" : "jenkins-infra",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1335,
        "stargazersCount" : 370,
        "watchersCount" : 370,
        "size" : 708910,
        "openIssuesCount" : 163,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T15:53:26Z",
        "languages" : {
          "Dockerfile" : 1110,
          "CSS" : 60264,
          "Shell" : 16635,
          "SCSS" : 66981,
          "Makefile" : 5283,
          "JavaScript" : 716220,
          "HTML" : 864770,
          "Haml" : 236017,
          "Ruby" : 36937
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the thank-a-contributor widget to have a minimum image size, ensuring the image does not become too small under certain circumstances.",
      "validationOrRequirement" : "A minimum image size (specifically a minimum width) is required for the avatar image in the thank-a-contributor widget.",
      "attemptedFixes" : "Several contributors have shown interest in fixing this issue, including @sakina1303, @krisstern, and @strangelookingnerd, with @sakina1303 being given the go-ahead to create a PR.",
      "otherNotes" : "The issue is related to the thank-a-contributor widget on jenkins.io having a problem with image size, with the image becoming too small in certain circumstances. The possible solution is to add a minimum width to the image.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283849
  }, {
    "issueDTO" : {
      "id" : 3221218431,
      "title" : "Improve documentation and first user experience",
      "url" : "https://github.com/Kodo-Robotics/launchmap/issues/20",
      "repositoryName" : "Kodo-Robotics/launchmap",
      "description" : "The documentation does not seem to be very beginner friendly.\nTo add certain examples and resources to help users get started.",
      "updatedAt" : 1752242470.000000000,
      "user" : "SakshayMahna",
      "userHtmlUrl" : "https://github.com/SakshayMahna",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/40422728?v=4",
      "labels" : [ "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Sure @SakshayMahna ", "I'm on it.", "I will do it!" ],
      "repository" : {
        "description" : "Interactive ROS 2 launch file visualizer for VS Code. Explore and debug launch graphs with an intuitive UI.",
        "homepage" : null,
        "name" : "launchmap",
        "fullName" : "Kodo-Robotics/launchmap",
        "htmlUrl" : "https://github.com/Kodo-Robotics/launchmap",
        "gitUrl" : "git://github.com/Kodo-Robotics/launchmap.git",
        "sshUrl" : "git@github.com:Kodo-Robotics/launchmap.git",
        "cloneUrl" : "https://github.com/Kodo-Robotics/launchmap.git",
        "owner" : {
          "login" : "Kodo-Robotics",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 142,
        "watchersCount" : 142,
        "size" : 3154,
        "openIssuesCount" : 8,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T02:08:28Z",
        "languages" : {
          "TypeScript" : 4287,
          "CSS" : 4187,
          "JavaScript" : 40948,
          "Python" : 119016
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve documentation and first user experience for beginners",
      "validationOrRequirement" : "Add certain examples and resources to help users get started",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The documentation does not seem to be very beginner friendly.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283851
  }, {
    "issueDTO" : {
      "id" : 3222984234,
      "title" : "[FEATURE] complete localization check GH action work from https://github.com/kubestellar/ui/pull/1297",
      "url" : "https://github.com/kubestellar/ui/issues/1444",
      "repositoryName" : "kubestellar/ui",
      "description" : "### Problem or Use Case\n\ndont know why https://github.com/kubestellar/ui/pull/1297 was closed, but we still need it\n\n### Proposed Solution\n\nopen a new PR with contents of https://github.com/kubestellar/ui/pull/1297 and work it to completion\n\n### Are you willing to contribute?\n\n- [ ] Yes, I'd like to help implement this feature.\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752242468.000000000,
      "user" : "clubanderson",
      "userHtmlUrl" : "https://github.com/clubanderson",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/407614?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/assign" ],
      "repository" : {
        "description" : "KubeStellar's User Interface",
        "homepage" : "",
        "name" : "ui",
        "fullName" : "kubestellar/ui",
        "htmlUrl" : "https://github.com/kubestellar/ui",
        "gitUrl" : "git://github.com/kubestellar/ui.git",
        "sshUrl" : "git@github.com:kubestellar/ui.git",
        "cloneUrl" : "https://github.com/kubestellar/ui.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 141,
        "stargazersCount" : 52,
        "watchersCount" : 52,
        "size" : 6548,
        "openIssuesCount" : 86,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T19:42:46Z",
        "languages" : {
          "TypeScript" : 2377393,
          "Dockerfile" : 4363,
          "Shell" : 4960,
          "CSS" : 4768,
          "Makefile" : 7068,
          "JavaScript" : 5450,
          "Go" : 1062645,
          "HTML" : 345
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Complete the localization check GH action that was previously closed, and work it to completion by opening a new PR with the contents of the original PR.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the issue description or comments.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "Additional context is missing, but it seems the issue is about completing a localization check GH action that was previously closed, and the author is looking for contributors to reopen and complete the PR.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283855
  }, {
    "issueDTO" : {
      "id" : 3110313655,
      "title" : "[FEATURE] translate KubeStellar UI to Hindi",
      "url" : "https://github.com/kubestellar/ui/issues/962",
      "repositoryName" : "kubestellar/ui",
      "description" : "### Problem or Use Case\n\nKS UI is in English only \n\n### Proposed Solution\n\ncreate \"strings.hi\" to translate ks ui to Hindi\n\n### Are you willing to contribute?\n\n- [ ] Yes, I'd like to help implement this feature.\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752241930.000000000,
      "user" : "clubanderson",
      "userHtmlUrl" : "https://github.com/clubanderson",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/407614?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "not a priority", "@clubanderson Sir I am a native hindi speaker, If you say i can translate the strings to hindi. #972 merged", "@naman9271 Thank you for your offer, we are not prioritizing Hindi at this time. Your focus on the other issues is more important - Thank you ", "i am opening this issue , lets add this", "@rishi-jat you can take this if you want ", "@AayushSaini101 i am working on this , it's almost done\n", "> [@AayushSaini101](https://github.com/AayushSaini101) i am working on this , it's almost done\n\nsure : ) ", "Thanks for the update @MAVRICK-1! Since you???re already working on this and it???s almost done, feel free to continue. ", "@MAVRICK-1 do you want help with this?", "@MAVRICK-1 can you update us on your progress?", "Currently working on it , will be done by today \n" ],
      "repository" : {
        "description" : "KubeStellar's User Interface",
        "homepage" : "",
        "name" : "ui",
        "fullName" : "kubestellar/ui",
        "htmlUrl" : "https://github.com/kubestellar/ui",
        "gitUrl" : "git://github.com/kubestellar/ui.git",
        "sshUrl" : "git@github.com:kubestellar/ui.git",
        "cloneUrl" : "https://github.com/kubestellar/ui.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 141,
        "stargazersCount" : 52,
        "watchersCount" : 52,
        "size" : 6548,
        "openIssuesCount" : 86,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T19:42:46Z",
        "languages" : {
          "TypeScript" : 2377393,
          "Dockerfile" : 4363,
          "Shell" : 4960,
          "CSS" : 4768,
          "Makefile" : 7068,
          "JavaScript" : 5450,
          "Go" : 1062645,
          "HTML" : 345
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Translate the KubeStellar UI to Hindi.",
      "validationOrRequirement" : "strings.hi file needs to be created to translate the KS UI to Hindi.",
      "attemptedFixes" : "AayushSaini101 is working on the translation and claims it's almost done, MAVRICK-1 is also working on it and plans to finish it by today.",
      "otherNotes" : "KS UI is currently only in English, the issue aims to translate it to Hindi, there is a willingness to contribute, and some users have shown interest in helping with the translation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283859
  }, {
    "issueDTO" : {
      "id" : 2984165724,
      "title" : "More use of ProgressLogger.",
      "url" : "https://github.com/NethermindEth/nethermind/issues/8504",
      "repositoryName" : "NethermindEth/nethermind",
      "description" : "- There is a `ProgressLogger` class for logging progress. \n- It is quite nice.\n- Some part of the codebase does not use it.\n  - Full pruning.\n  - VerifyTrie\n  - Not sure what else, find it.\n- Make them use it.",
      "updatedAt" : 1752241617.000000000,
      "user" : "asdacap",
      "userHtmlUrl" : "https://github.com/asdacap",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1841324?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I would like to take this on. Feel free to assign it to me \uD83D\uDE04 ", "@asdacap checkout #8509 \n", "hi @asdacap pls checkout #8541 \n\nlet me know your feedback ", "Did this ever get solved or could I get assigned please? @asdacap " ],
      "repository" : {
        "description" : "A robust execution client for Ethereum node operators.",
        "homepage" : "https://nethermind.io/nethermind-client",
        "name" : "nethermind",
        "fullName" : "NethermindEth/nethermind",
        "htmlUrl" : "https://github.com/NethermindEth/nethermind",
        "gitUrl" : "git://github.com/NethermindEth/nethermind.git",
        "sshUrl" : "git@github.com:NethermindEth/nethermind.git",
        "cloneUrl" : "https://github.com/NethermindEth/nethermind.git",
        "owner" : {
          "login" : "NethermindEth",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 531,
        "stargazersCount" : 1418,
        "watchersCount" : 1418,
        "size" : 475414,
        "openIssuesCount" : 474,
        "subscribersCount" : 55,
        "pushedAt" : "2025-07-11T20:41:50Z",
        "languages" : {
          "C#" : 20942622,
          "PowerShell" : 240,
          "Dockerfile" : 2469,
          "Shell" : 24187,
          "CSS" : 247,
          "Solidity" : 3043,
          "Makefile" : 30,
          "JavaScript" : 28153,
          "Python" : 35356
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Make some parts of the codebase use the ProgressLogger class for logging progress",
      "validationOrRequirement" : "None mentioned in the description or comments",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "ProgressLogger class for logging progress is not used in some parts of the codebase, specifically in Full pruning and VerifyTrie. The goal is to make them use it.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283862
  }, {
    "issueDTO" : {
      "id" : 3163480846,
      "title" : "\uD83E\uDD1D Help wanted: Add workouts streaks in the header",
      "url" : "https://github.com/Snouzy/workout-cool/issues/53",
      "repositoryName" : "Snouzy/workout-cool",
      "description" : "**Context**\nCurrently, users don't get immediate feedback on their recent workout activity.  \nWe'd like to add a simple visual indicator in the top header to show whether a workout was done over the past 5 days.\n\n**Goal**\nDisplay 5 small squares in a row:  \n* filled (green) if a workout was done on that day  \n* outlined or gray if no workout  \n* only visible on `sm+`\n\n**How to get started**  \n1. Get the last 5 dates including today.  \n2. Check if the user did a workout on each date (via API or local state).  \n3. Create a new `WorkoutStreakHeader` component \n\n![Image](https://github.com/user-attachments/assets/e57a7ec9-c6e8-4f75-b8f9-9b91c628f41a)\n\n---\n\n**Interested in working on it?**\nComment below and we'll assign it to you. Happy to help you get started!",
      "updatedAt" : 1752241555.000000000,
      "user" : "Snouzy",
      "userHtmlUrl" : "https://github.com/Snouzy",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/32961176?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@Snouzy, I'd like to work on this.", "Sure, feel free mate. \uD83D\uDE4F", "@Snouzy I can take this one if it is abandoned", "hey mate' @silasburger\nYep, i think we can take it. He will come back in september and he's perfectly fine with us moving forward in the meantime (cf. discord conv)\n\nSo I can assign it to you \n\n<img width=\"1160\" height=\"766\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5a7ccb02-a268-4ccd-85a1-9321df3744bc\" />", "Hi @Snouzy, great sounds good. Did he share the branch?", "@silasburger @Snouzy this is the commit https://github.com/Norris1z/workout-cool/commit/8da9ff4227a2ac839688c598dfa1ef4ead7d14b0", "not sure how we can use the same branch here as I cant create branches directly on the project @Snouzy ", "also thanks @silasburger for taking over.", "> not sure how we can use the same branch here as I cant create branches directly on the project [@Snouzy](https://github.com/Snouzy)\n\nI can just recreate the branch in my fork. @Norris1z Thanks for sharing your progress" ],
      "repository" : {
        "description" : "\uD83C\uDFCB Modern open-source fitness coaching platform. Create workout plans, track progress, and access a comprehensive exercise database.",
        "homepage" : "https://workout.cool",
        "name" : "workout-cool",
        "fullName" : "Snouzy/workout-cool",
        "htmlUrl" : "https://github.com/Snouzy/workout-cool",
        "gitUrl" : "git://github.com/Snouzy/workout-cool.git",
        "sshUrl" : "git@github.com:Snouzy/workout-cool.git",
        "cloneUrl" : "https://github.com/Snouzy/workout-cool.git",
        "owner" : {
          "login" : "Snouzy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 302,
        "stargazersCount" : 4763,
        "watchersCount" : 4763,
        "size" : 7096,
        "openIssuesCount" : 30,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-10T11:41:58Z",
        "languages" : {
          "TypeScript" : 2187793,
          "MDX" : 101521,
          "Dockerfile" : 848,
          "CSS" : 19242,
          "Shell" : 600,
          "PLpgSQL" : 2583,
          "Makefile" : 917,
          "JavaScript" : 7111
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a simple visual indicator in the top header to show whether a workout was done over the past 5 days.",
      "validationOrRequirement" : "The issue requires the workout streak header to be visible only on sm+, and the squares should be filled (green) if a workout was done on that day, outlined or gray if no workout.",
      "attemptedFixes" : "The author has shared a commit link and has discussed how to get started with the task, but there is no mention of any attempted fixes or blockers.",
      "otherNotes" : "The issue is related to a specific commit and has a specific goal, the workout streak header should be visible only on sm+ and should display 5 small squares in a row. The author has shared an image and the commit link.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283867
  }, {
    "issueDTO" : {
      "id" : 3145978067,
      "title" : "bug: shared state features unreadable in dark mode",
      "url" : "https://github.com/ag-ui-protocol/ag-ui/issues/96",
      "repositoryName" : "ag-ui-protocol/ag-ui",
      "description" : "The shared state features are unreadable in dark mode as the text is white on white.\n\n**Dark mode**\n\n![Image](https://github.com/user-attachments/assets/19af0543-a6c3-48c1-b128-a7cd8ddb4722)\n\n**Light mode**\n\n![Image](https://github.com/user-attachments/assets/66fb3ec8-4fe1-4aab-893a-837227a59635)",
      "updatedAt" : 1752241473.000000000,
      "user" : "stevenh",
      "userHtmlUrl" : "https://github.com/stevenh",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/104239?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @stevenh, thank you for flagging this. \n\nWe will take a look at this and get back to you. \n\nWould you like to contribute a fix here?", "@stevenh, can you provide the URL for this example? ", "Sure its: http://localhost:3000/server-starter-all-features/feature/shared_state" ],
      "repository" : {
        "description" : "AG-UI: the Agent-User Interaction Protocol. Bring Agents into Frontend Applications.",
        "homepage" : "https://ag-ui.com",
        "name" : "ag-ui",
        "fullName" : "ag-ui-protocol/ag-ui",
        "htmlUrl" : "https://github.com/ag-ui-protocol/ag-ui",
        "gitUrl" : "git://github.com/ag-ui-protocol/ag-ui.git",
        "sshUrl" : "git@github.com:ag-ui-protocol/ag-ui.git",
        "cloneUrl" : "https://github.com/ag-ui-protocol/ag-ui.git",
        "owner" : {
          "login" : "ag-ui-protocol",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 451,
        "stargazersCount" : 4983,
        "watchersCount" : 4983,
        "size" : 2810,
        "openIssuesCount" : 68,
        "subscribersCount" : 55,
        "pushedAt" : "2025-07-11T22:25:39Z",
        "languages" : {
          "TypeScript" : 617729,
          "CSS" : 18188,
          "JavaScript" : 13539,
          "Python" : 283954
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The shared state features are unreadable in dark mode.",
      "validationOrRequirement" : "The issue description does not mention any specific requirements or validations.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The shared state features are unreadable in dark mode as the text is white on white.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283870
  }, {
    "issueDTO" : {
      "id" : 3192854912,
      "title" : "Documentation",
      "url" : "https://github.com/kinisi-dev/kinisi/issues/100",
      "repositoryName" : "kinisi-dev/kinisi",
      "description" : "Write documentation for kinisi 2.0 and new features i.e. custom trajectory subsampling etc",
      "updatedAt" : 1752240959.000000000,
      "user" : "Harry-Rich",
      "userHtmlUrl" : "https://github.com/Harry-Rich",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/180960475?v=4",
      "labels" : [ "documentation", "sprint", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This will be a good started issue for the new developers. ", "This issue is just getting the same documentation as previously. I will add new issues for new feature docs. " ],
      "repository" : {
        "description" : "A Python package for estimating diffusion properties from molecular dynamics simulations.",
        "homepage" : "https://kinisi.readthedocs.io",
        "name" : "kinisi",
        "fullName" : "kinisi-dev/kinisi",
        "htmlUrl" : "https://github.com/kinisi-dev/kinisi",
        "gitUrl" : "git://github.com/kinisi-dev/kinisi.git",
        "sshUrl" : "git@github.com:kinisi-dev/kinisi.git",
        "cloneUrl" : "https://github.com/kinisi-dev/kinisi.git",
        "owner" : {
          "login" : "kinisi-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 69,
        "watchersCount" : 69,
        "size" : 166693,
        "openIssuesCount" : 20,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T16:16:23Z",
        "languages" : {
          "TeX" : 8534,
          "Python" : 230066
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create documentation for kinisi 2.0 and new features",
      "validationOrRequirement" : "Write documentation for kinisi 2.0 and new features, including custom trajectory subsampling",
      "attemptedFixes" : "",
      "otherNotes" : "This issue is considered a good first issue for new developers and will be a starting point for new developers to get familiar with the project. The author will add new issues for new feature documentation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283873
  }, {
    "issueDTO" : {
      "id" : 2771700510,
      "title" : "Add tests for CRD CEL validation",
      "url" : "https://github.com/nginx/nginx-gateway-fabric/issues/2984",
      "repositoryName" : "nginx/nginx-gateway-fabric",
      "description" : "The gateway-api repository has tests for their CEL validation on CRDs found here: https://github.com/kubernetes-sigs/gateway-api/tree/main/pkg/test/cel. \n\nCurrently we manually test our CEL validation on CRDs, however it could be beneficial to follow the standard set in the gateway-api repository and create functional tests for them.\n\n### Acceptance\n- Verify that all CEL statements work as expected for the CRDs we own.\n\n---\n\n### Notes\n\nCEL is available as of K8S v1.25",
      "updatedAt" : 1752240827.000000000,
      "user" : "bjee19",
      "userHtmlUrl" : "https://github.com/bjee19",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/139261241?v=4",
      "labels" : [ "size/medium", "tests", "refined", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@bjee19 hi! I want to help you with this issue. Can you describe what I need to do ? \nIt's will be my the first contribute in this project, or maybe you have a smaller problem I could start with ?", "Hey @iaiw3br, thanks for your interest in our project! \n\nThis issue has to do with some [Common expression language](https://kubernetes.io/docs/reference/using-api/cel/) validation we put on our [CRDs](https://github.com/nginx/nginx-gateway-fabric/tree/main/apis). This is the kubebuilder explanation of various possible [CRD validations](https://book.kubebuilder.io/reference/markers/crd-validation), and here's what it looks like in our code:\n\nhttps://github.com/nginx/nginx-gateway-fabric/blob/a382a1cfa5c51dbfaf0a88c4854eb4c0089ed56f/apis/v1alpha1/nginxgateway_types.go#L66-L73\n\nWe currently don't have any tests for these CEL validation statements, so we have to do it all manually by creating the resource and ensuring it throws an error when we create a CRD which breaks the CEL validation. \n\nWe'd like to add tests for all our CRDs so we can avoid having to rely on our manual testing. Here's an example test of what we're looking for from the [gateway api repo](https://github.com/kubernetes-sigs/gateway-api/blob/main/pkg/test/cel/httproute_test.go). Where you can see how thoroughly they test their CEL validation on the [HTTPRoute resource ](https://github.com/kubernetes-sigs/gateway-api/blob/main/apis/v1/httproute_types.go). \n\nWe don't have as much CEL validation so it will be much smaller, but let me know if you have any more questions or if you'd like to choose something smaller. Here's another story https://github.com/nginx/nginx-gateway-fabric/issues/1939 which probably is smaller if that interests you more. " ],
      "repository" : {
        "description" : "NGINX Gateway Fabric provides an implementation for the Gateway API using NGINX as the data plane.",
        "homepage" : "",
        "name" : "nginx-gateway-fabric",
        "fullName" : "nginx/nginx-gateway-fabric",
        "htmlUrl" : "https://github.com/nginx/nginx-gateway-fabric",
        "gitUrl" : "git://github.com/nginx/nginx-gateway-fabric.git",
        "sshUrl" : "git@github.com:nginx/nginx-gateway-fabric.git",
        "cloneUrl" : "https://github.com/nginx/nginx-gateway-fabric.git",
        "owner" : {
          "login" : "nginx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 129,
        "stargazersCount" : 636,
        "watchersCount" : 636,
        "size" : 42613,
        "openIssuesCount" : 182,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-11T21:22:40Z",
        "languages" : {
          "Smarty" : 3332,
          "TypeScript" : 161,
          "Dockerfile" : 2057,
          "Shell" : 15079,
          "Makefile" : 23984,
          "JavaScript" : 21589,
          "Go" : 2790322,
          "Gnuplot" : 1710
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add tests for CRD CEL validation, currently manually tested, want to follow the standard set in the gateway-api repository",
      "validationOrRequirement" : "Verify that all CEL statements work as expected for the CRDs we own, follow the standard set in the gateway-api repository",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "CEL is available as of K8S v1.25, this issue is about adding tests for CRD CEL validation, manual testing is currently relied upon, an example test from the gateway api repo is provided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283877
  }, {
    "issueDTO" : {
      "id" : 3222947721,
      "title" : "Prevent startup if gateway enabled but discovery not, or vice versa",
      "url" : "https://github.com/zowe/zlux/issues/1050",
      "repositoryName" : "zowe/zlux",
      "description" : "> are you saying gateway was true but discovery was false?\n> app-server doesnt support this configuration.\n> if one is enabled, both must be enabled.\n> \n> i can't think of any scenario in which a user would or should ever do that but we don't have a way to prevent it at this time. \n\n _Originally posted by @1000TurquoisePogs in [#1047](https://github.com/zowe/zlux/issues/1047#issuecomment-2970401421)_",
      "updatedAt" : 1752240722.000000000,
      "user" : "1000TurquoisePogs",
      "userHtmlUrl" : "https://github.com/1000TurquoisePogs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30730276?v=4",
      "labels" : [ "priority-low", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "i suggest that validate.sh can check if gateway.enabled = true && discovery.enabled = false or vice versa and complain & exit." ],
      "repository" : {
        "description" : "The top-level superproject for zLUX. zLUX includes the Zowe Desktop framework in addition to several built-in apps and an example server implementation. ",
        "homepage" : null,
        "name" : "zlux",
        "fullName" : "zowe/zlux",
        "htmlUrl" : "https://github.com/zowe/zlux",
        "gitUrl" : "git://github.com/zowe/zlux.git",
        "sshUrl" : "git@github.com:zowe/zlux.git",
        "cloneUrl" : "https://github.com/zowe/zlux.git",
        "owner" : {
          "login" : "zowe",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 41,
        "stargazersCount" : 40,
        "watchersCount" : 40,
        "size" : 94,
        "openIssuesCount" : 222,
        "subscribersCount" : 12,
        "pushedAt" : "2022-10-28T20:50:11Z",
        "languages" : { },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Prevent the startup of the application if gateway and discovery are enabled or disabled in a way that is not supported by the app-server.",
      "validationOrRequirement" : "Both gateway and discovery must be enabled if one is enabled, and a validation is required to prevent the startup if this configuration is detected.",
      "attemptedFixes" : "One suggested fix is to add a validation in validate.sh to check if gateway.enabled = true && discovery.enabled = false or vice versa and complain & exit.",
      "otherNotes" : "The issue is related to a configuration scenario where gateway and discovery are enabled or disabled in a way that is not supported by the app-server.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283881
  }, {
    "issueDTO" : {
      "id" : 3215050434,
      "title" : "Tab thumbnail resets when ickong link to create new tab",
      "url" : "https://github.com/mozilla-mobile/firefox-ios/issues/27850",
      "repositoryName" : "mozilla-mobile/firefox-ios",
      "description" : "## steps to repro\nopen any web page (A)\n\nopen tab window to check thumbnail which should show A\nnavigate to a new web (B) page in existing tab which contains links to some external site\nclick any link to open it in a new tab\ncheck tab thumbnail\n\n### Expected behavior\nseeing thumbnail of page B from above\n\n### Actual behavior\nseeing thumbnail of page A\n\n### Device & build information\n* Device:\niPhone 14 PRO MAX\niOS 18.5 \n* Build version:\nFirefox 140.2 (57462)\n* First seen version:\nnot introduced in current v\n\n### Notes\nAttachments: \n\nnon for now, issue easy to repro\n\n:information_source: **Reference Person**\n\n[+@Foxbolts+](https://github.com/Foxbolts)\n\n\n\n???Issue is synchronized with this [Jira Task](https://mozilla-hub.atlassian.net/browse/FXIOS-12790)\n",
      "updatedAt" : 1752240629.000000000,
      "user" : "rayogunjimi",
      "userHtmlUrl" : "https://github.com/rayogunjimi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/81774312?v=4",
      "labels" : [ "Good first issue", "Contributor OK", "Bug \uD83D\uDC1E" ],
      "state" : "OPEN",
      "comments" : [ "Hey @rayogunjimi - I was not able to reproduce this issue, would you be willing to upload a screen recording of it happening?\n\ncc: @lmarceau @dataports ", "https://github.com/user-attachments/assets/f6278187-9cdc-46c6-9287-15ab5ca1d2be", "@rayogunjimi thanks for the recording - it looks like this can be boiled down to an incorrect tab thumbnail for the source tab when switching to a new tab via the toast notification", "Hi @Foxbolts, possible, but don't think it's limited only to the notification. Sometimes clicking a link opens a new tab automatically (not sure why) and the issue happens in this case also.\n\nThanks.", "I would want to work on this issue" ],
      "repository" : {
        "description" : "Firefox for iOS",
        "homepage" : "",
        "name" : "firefox-ios",
        "fullName" : "mozilla-mobile/firefox-ios",
        "htmlUrl" : "https://github.com/mozilla-mobile/firefox-ios",
        "gitUrl" : "git://github.com/mozilla-mobile/firefox-ios.git",
        "sshUrl" : "git@github.com:mozilla-mobile/firefox-ios.git",
        "cloneUrl" : "https://github.com/mozilla-mobile/firefox-ios.git",
        "owner" : {
          "login" : "mozilla-mobile",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3060,
        "stargazersCount" : 12607,
        "watchersCount" : 12607,
        "size" : 953793,
        "openIssuesCount" : 1740,
        "subscribersCount" : 519,
        "pushedAt" : "2025-07-12T00:31:07Z",
        "languages" : {
          "Dockerfile" : 2034,
          "Shell" : 69064,
          "CSS" : 20168,
          "C" : 943,
          "JavaScript" : 881910,
          "Objective-C" : 11873,
          "Swift" : 14606987,
          "HTML" : 256765,
          "Metal" : 3517,
          "Ruby" : 5885,
          "Python" : 180113
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the problem where the tab thumbnail resets to the previous page when clicking a link to open a new tab.",
      "validationOrRequirement" : "The issue should see the thumbnail of page B after navigating to a new web page in an existing tab and clicking a link to open it in a new tab.",
      "attemptedFixes" : "A screen recording was provided to help reproduce the issue, and the issue was boiled down to an incorrect tab thumbnail for the source tab when switching to a new tab via the toast notification or automatically clicking a link.",
      "otherNotes" : "The issue is synchronized with a Jira Task (FXIOS-12790) and has attachments, but none are provided for now.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283886
  }, {
    "issueDTO" : {
      "id" : 2254308260,
      "title" : "Help with eslint v9 upgrade",
      "url" : "https://github.com/jaegertracing/jaeger-ui/issues/2272",
      "repositoryName" : "jaegertracing/jaeger-ui",
      "description" : "#2271 is failing to bump eslint versions:\r\n  1. [x] We need to change our build to use Node 20 in `.github/workflow/**` and `.nvmrc`. It would be nice to [enforce it via package.json](https://stackoverflow.com/a/29349773/2673284).\r\n  2. [x] This error: `ESLintIgnoreWarning: The \".eslintignore\" file is no longer supported. Switch to using the \"ignores\" property in \"eslint.config.js\": https://eslint.org/docs/latest/use/configure/migration-guide#ignoring-files`\r\n  3. [ ] New error: `[eslint       ] Error: Could not find config file.`",
      "updatedAt" : 1752240579.000000000,
      "user" : "yurishkuro",
      "userHtmlUrl" : "https://github.com/yurishkuro",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3523016?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @yurishkuro , unit-tests workflow is failing in my commit, how can i resolve\r\n", "@Baalekshan the lint step is still failing after upgrade with\r\n```\r\n[eslint       ] Error: Could not find config file.\r\n[eslint       ]     at locateConfigFileToUse (/home/runner/work/jaeger-ui/jaeger-ui/node_modules/eslint/lib/eslint/eslint.js:350:21)\r\n[eslint       ]     at async calculateConfigArray (/home/runner/work/jaeger-ui/jaeger-ui/node_modules/eslint/lib/eslint/eslint.js:385:49)\r\n[eslint       ]     at async ESLint.lintFiles (/home/runner/work/jaeger-ui/jaeger-ui/node_modules/eslint/lib/eslint/eslint.js:815:25)\r\n[eslint       ]     at async Object.execute (/home/runner/work/jaeger-ui/jaeger-ui/node_modules/eslint/lib/cli.js:500:23)\r\n[eslint       ]     at async main (/home/runner/work/jaeger-ui/jaeger-ui/node_modules/eslint/bin/eslint.js:153:22)\r\n[eslint       ] error Command failed with exit code 2.\r\n```", "@yurishkuro  Is this a concern ? Since, it was safely merged without any errors in the workflow. I didn't find this error in the PR raised only faced this in my forked repo.", "@Baalekshan the change we merged was good, but it did not resolve this ticket, because the upgrade is still failing, just on a different error.", "Oh right, what could be done now. Should I try fixing these errors? If so what can I do.", "The upgrade is trying to bump eslint from 8.x to 9.x, there could be some breaking changes causing this issue.", "I will look into it", "ESlint 9.x won't find `.eslintrc.js` in default.\r\n\r\nThere are two difference ways to resolve this.\r\n1. Env `ESLINT_USE_FLAT_CONFIG` set `false`\r\n2. `.eslintrc.js` migrate to `eslint.config.js`\r\n\r\n- https://eslint.org/docs/latest/use/migrate-to-9.0.0\r\n- https://eslint.org/docs/latest/use/configure/migration-guide", "Unfortunately, there are still some packages that can't support flat config (eslint.config.js)\r\n\r\n- `eslint-config-airbnb`: https://github.com/airbnb/javascript/issues/2804\r\n\r\nIt may be necessary to re-filter the `.eslintrc.js` content.\r\n\r\n", "So do you mean we can't migrate completely but also use .eslint.config.js partially?", "@Baalekshan\r\nIf you want to migrate settings, some of the packages will not work. (e.g. `eslint-config-airbnb`)\r\n\r\nSet the environment variable `ESLINT_USE_FLAT_CONFIG` to false if you want to keep the full settings. (But I don't know about the possibility of `.eslintrc.js` being deprecated at some time.)\r\n\r\nWe can follow what @yurishkuro decides to do.\r\n", "@tico88612 Alright!", "@yurishkuro what should we do ?\r\n", "In the linked airbnb ticket there is some mentioning of compat workaround, maybe it could work. Otherwise we can wait till they support it. I don't see much point in using env var solution, if's probably temporary anyway. ", "Has anyone figured out the issue?", "@yurishkuro above issue is solved or something is still wrong? Should I work on it.\r\n", "@MiirzaBaig @ayushrakesh There is a workaround but it's temporary. So, @yurishkuro suggested to wait until they support it.", "At this point I would go with a workaround, because airbnb ticket says it will take a while for them to fix due to dependencies.", "ok \uD83D\uDC4D", "> At this point I would go with a workaround, because airbnb ticket says it will take a while for them to fix due to dependencies.\n\nI'm working on this \uD83D\uDE42\n\nThere are some remedies I found for this, looking more into it. \nAlso, there is an package [eslint-config-airbnb-extended](https://github.com/NishargShah/eslint-config-airbnb-extended), we can migrate the eslint to it's latest version and if things not work properly then we can go with this. \n\nIt's getting popular - \n\n![Image](https://github.com/user-attachments/assets/3f69ee65-80f1-4782-988d-d1e637820ca5)\n\ncc - @yurishkuro ", "Proceed with the workaround since the airbnb dependency fix will take time, with @abhayporwals exploring solutions like eslint-config-airbnb-extended.\n\n", "Is this issue still open? @jkowall @yurishkuro  can I work on this this?", "yes", "@yurishkuro Just to confirm???this issue is about migrating ESLint to version 9, right?\n\nIf yes, I???ve already started looking into the changes and would be happy to take it up. Please assign the task to me so I can proceed officially.", "@yurishkuro I'm currently working on migrating our ESLint setup to v9, and I wanted to confirm something before moving forward.\n\nAs you may know, eslint-config-airbnb doesn't yet support the new ESLint flat config format out of the box. While it???s technically possible to continue using Airbnb with the help of @eslint/eslintrc's FlatCompat bridge and some rule patching, it introduces added complexity and long-term maintenance concerns.\n\nWould you prefer that we:\n\nContinue using Airbnb, with compatibility patches and FlatCompat\nOR\n\nDrop Airbnb and switch to a modern ESLint 9 setup using core plugins (@eslint/js, @typescript-eslint, react, jsx-a11y, etc.) with equivalent stylistic rules?", "@gkbishnoi07 I saw that there was a workaround mentioned at the end of https://github.com/airbnb/javascript/issues/2804\n\nIf we were to go with \"using core plugins\", what is the delta compared to airbnb library? I don't have a strong preference.", "Hi @yurishkuro, thanks for your response!\nTo clarify: Airbnb provides a widely-used preset of ESLint rules, but it doesn???t yet support ESLint v9???s Flat Config format out of the box. While we can use compatibility workarounds (FlatCompat), they introduce complexity and extra maintenance.\n\nAlternatively, using core plugins like @eslint/js, @typescript-eslint, eslint-plugin-react, and eslint-plugin-jsx-a11y allows us to write a clean, native eslint.config.js file that is fully compatible with ESLint v9. We can manually define and extend rule sets to closely mirror Airbnb???s style, but with more flexibility and future-proofing.\n\nI???ve worked in several modern repositories where this approach is used and have rarely seen Airbnb config being used recently Jaeger is actually where I first encountered it.", "Ok, I'm all for to use modern configs", "Thanks @yurishkuro! I'm starting work on it now. You can go ahead and assign me the issue" ],
      "repository" : {
        "description" : "Web UI for Jaeger",
        "homepage" : "http://jaegertracing.io/",
        "name" : "jaeger-ui",
        "fullName" : "jaegertracing/jaeger-ui",
        "htmlUrl" : "https://github.com/jaegertracing/jaeger-ui",
        "gitUrl" : "git://github.com/jaegertracing/jaeger-ui.git",
        "sshUrl" : "git@github.com:jaegertracing/jaeger-ui.git",
        "cloneUrl" : "https://github.com/jaegertracing/jaeger-ui.git",
        "owner" : {
          "login" : "jaegertracing",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 579,
        "stargazersCount" : 1293,
        "watchersCount" : 1293,
        "size" : 15773,
        "openIssuesCount" : 245,
        "subscribersCount" : 1015,
        "pushedAt" : "2025-07-10T01:48:40Z",
        "languages" : {
          "TypeScript" : 1064835,
          "CSS" : 149485,
          "Shell" : 2064,
          "Makefile" : 532,
          "JavaScript" : 1403176,
          "HTML" : 3046,
          "EJS" : 253
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to help with the upgrade of ESLint to version 9, which is failing to bump the versions due to some errors. The issue is about migrating ESLint to version 9 and resolving the errors that are encountered during the process.",
      "validationOrRequirement" : "The issue requires the ability to change the build to use Node 20 in `.github/workflow/**` and `.nvmrc`. It would be nice to enforce it via package.json. The `.eslintignore` file is no longer supported and should be replaced with the `ignores` property in `eslint.config.js`.",
      "attemptedFixes" : "The issue is still open and contributors are discussing possible solutions. There are attempts to use a workaround and also exploring the possibility of using `eslint-config-airbnb-extended`.",
      "otherNotes" : "The issue is about migrating ESLint to version 9. There are two ways to resolve this: Env `ESLINT_USE_FLAT_CONFIG` set `false` or `.eslintrc.js` migrate to `eslint.config.js`. Some packages like `eslint-config-airbnb` don't support flat config and may need to be re-filtered. There is a workaround but it's temporary. The issue is still open and contributors are discussing possible solutions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283895
  }, {
    "issueDTO" : {
      "id" : 3221704575,
      "title" : "Mark certain doc/site files to not be tracked by git",
      "url" : "https://github.com/beyond-all-reason/RecoilEngine/issues/2457",
      "repositoryName" : "beyond-all-reason/RecoilEngine",
      "description" : "See [task that generates pages from spring binary](https://github.com/beyond-all-reason/RecoilEngine/blob/8490be7/doc/site/mise.toml#L74-L77)\n\nThe following files are present in the repository to enable running the site locally without the complexity of refreshing dynamic content[^1]:\n\n- `doc/site/data/configs.json`\n- `doc/site/data/weapondefs.json`\n- `doc/site/data/unsynced_commands.json`\n- `doc/site/data/synced_commands.json`\n- `doc/site/data/doc.json` (generated by emmylua doc json output instead for lua pages)\n\nWe should still have them on the repo but to not be tracked for changes, e.g. using `git update-index --skip-worktree <file>` or similar. That is: \n\n- Cloning a fresh repo should contain the files, pulling the last version forcibly updated.\n- Refreshing data and changing these files should not add a change to the git index (they don't show as \"modified\")\n\nAn example of a file that currently operates as such is the [index page for the lua api](https://github.com/beyond-all-reason/RecoilEngine/blob/master/doc/site/content/docs/lua-api/_index.md). \n\n[^1]: See \"Local Development\" sections on [site readme](https://github.com/beyond-all-reason/RecoilEngine/blob/master/doc/site/README.md) and the [`lua_pages`](https://github.com/beyond-all-reason/RecoilEngine/blob/8490be78f64e918bcce088c40f0576c932efb25c/doc/site/mise.toml#L36-L51) and [`binary_pages`](https://github.com/beyond-all-reason/RecoilEngine/blob/8490be78f64e918bcce088c40f0576c932efb25c/doc/site/mise.toml#L53-L94) tasks for refreshing dynamic content, for more context",
      "updatedAt" : 1752240362.000000000,
      "user" : "badosu",
      "userHtmlUrl" : "https://github.com/badosu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/347552?v=4",
      "labels" : [ "area: documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A powerful free cross-platform RTS game engine",
        "homepage" : "https://beyond-all-reason.github.io/RecoilEngine/",
        "name" : "RecoilEngine",
        "fullName" : "beyond-all-reason/RecoilEngine",
        "htmlUrl" : "https://github.com/beyond-all-reason/RecoilEngine",
        "gitUrl" : "git://github.com/beyond-all-reason/RecoilEngine.git",
        "sshUrl" : "git@github.com:beyond-all-reason/RecoilEngine.git",
        "cloneUrl" : "https://github.com/beyond-all-reason/RecoilEngine.git",
        "owner" : {
          "login" : "beyond-all-reason",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 341,
        "watchersCount" : 341,
        "size" : 205721,
        "openIssuesCount" : 771,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-11T22:29:02Z",
        "languages" : {
          "Java" : 41936,
          "C++" : 24315759,
          "C" : 3074390,
          "CMake" : 333555,
          "Makefile" : 59811,
          "HTML" : 125785,
          "Perl" : 23604,
          "NSIS" : 32088,
          "Dockerfile" : 6431,
          "Shell" : 54303,
          "sed" : 1389,
          "Awk" : 278422,
          "Batchfile" : 573,
          "Lua" : 773509,
          "Objective-C" : 8705,
          "Assembly" : 721,
          "GLSL" : 129310,
          "Python" : 18613
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Mark certain doc/site files to not be tracked by git, allowing for local development without tracking changes to generated files.",
      "validationOrRequirement" : "The files should be present in the repository, but not tracked for changes, allowing for cloning a fresh repo with the files and pulling the last version forcibly updated without adding changes to the git index.",
      "attemptedFixes" : "The solution involves using `git update-index --skip-worktree <file>` or similar to prevent changes to these files from being tracked by git.",
      "otherNotes" : "The issue is related to the local development process and involves files that are generated by tasks, such as lua pages.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283900
  }, {
    "issueDTO" : {
      "id" : 3219799241,
      "title" : "Create domain model for RequiredAction",
      "url" : "https://github.com/ferriskey/ferriskey/issues/281",
      "repositoryName" : "ferriskey/ferriskey",
      "description" : "### Is your feature request related to a problem?\n\nCreate a `RequiredAction` enum in the domain layer which describes the various actions to be completed before continuing the authentication flow (e.g. `CONFIGURE_TOTP`, `VERIFY_EMAIL`, etc.).\n\n### Desired Solution\n\n- [ ] `RequiredAction` enum\n- [ ] Add a `required_actions: Vec<RequiredAction>` field to the `User` template\n\n### Considered Alternatives\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752240093.000000000,
      "user" : "NathaelB",
      "userHtmlUrl" : "https://github.com/NathaelB",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/64804778?v=4",
      "labels" : [ "type:feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "FerrisKey is an open-source IAM solution designed for modern cloud-native environments. With its high-performance API written in Rust and its intuitive web interface developed in Typescript/React, FerrisKey offers a robust and flexible alternative to tradtional IAM solutions.",
        "homepage" : "https://docs.ferriskey.bonnal.cloud",
        "name" : "ferriskey",
        "fullName" : "ferriskey/ferriskey",
        "htmlUrl" : "https://github.com/ferriskey/ferriskey",
        "gitUrl" : "git://github.com/ferriskey/ferriskey.git",
        "sshUrl" : "git@github.com:ferriskey/ferriskey.git",
        "cloneUrl" : "https://github.com/ferriskey/ferriskey.git",
        "owner" : {
          "login" : "ferriskey",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 69,
        "watchersCount" : 69,
        "size" : 7442,
        "openIssuesCount" : 19,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-11T22:23:06Z",
        "languages" : {
          "TypeScript" : 294044,
          "HCL" : 4255,
          "Smarty" : 3664,
          "Dockerfile" : 2418,
          "CSS" : 10189,
          "Shell" : 379,
          "RenderScript" : 1,
          "Rust" : 395614,
          "SCSS" : 3901,
          "JavaScript" : 946,
          "HTML" : 378
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a domain model for RequiredAction, including a `RequiredAction` enum and a `required_actions: Vec<RequiredAction>` field in the `User` template",
      "validationOrRequirement" : "Create a `RequiredAction` enum in the domain layer which describes the various actions to be completed before continuing the authentication flow",
      "attemptedFixes" : "No attempted fixes or blockers mentioned",
      "otherNotes" : "No considered alternatives or additional context provided",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283903
  }, {
    "issueDTO" : {
      "id" : 185265773,
      "title" : "Some of our controls can't handle being built in 0x0 environments",
      "url" : "https://github.com/flutter/flutter/issues/6537",
      "repositoryName" : "flutter/flutter",
      "description" : "We should create tests that put each UI control into a 0x0 container and make sure they don't crash.\n\nSee https://github.com/flutter/flutter/pull/6535.\n",
      "updatedAt" : 1752239939.000000000,
      "user" : "Hixie",
      "userHtmlUrl" : "https://github.com/Hixie",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/551196?v=4",
      "labels" : [ "a: tests", "P2", "framework", "f: material design", "team-design", "triaged-design", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "See also https://github.com/flutter/flutter/issues/5259 which triggers this in release and debug --no-hot mode.\n", "Hey \uD83D\uDC4B, can you please describe What's this issue about? I am looking to contribute. Is this issue still pending or resolved?", "@Hixie I am looking forward to handling this issue, so please assign this to me." ],
      "repository" : {
        "description" : "Flutter makes it easy and fast to build beautiful apps for mobile and beyond",
        "homepage" : "https://flutter.dev",
        "name" : "flutter",
        "fullName" : "flutter/flutter",
        "htmlUrl" : "https://github.com/flutter/flutter",
        "gitUrl" : "git://github.com/flutter/flutter.git",
        "sshUrl" : "git@github.com:flutter/flutter.git",
        "cloneUrl" : "https://github.com/flutter/flutter.git",
        "owner" : {
          "login" : "flutter",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28842,
        "stargazersCount" : 171336,
        "watchersCount" : 171336,
        "size" : 395594,
        "openIssuesCount" : 12122,
        "subscribersCount" : 3502,
        "pushedAt" : "2025-07-12T00:32:46Z",
        "languages" : {
          "PowerShell" : 12057,
          "Java" : 2850308,
          "C++" : 17160615,
          "CSS" : 6019,
          "C" : 628665,
          "Objective-C++" : 2834064,
          "CMake" : 100149,
          "HTML" : 34304,
          "Kotlin" : 342834,
          "Shell" : 159110,
          "Batchfile" : 27058,
          "JavaScript" : 78130,
          "Objective-C" : 662487,
          "Swift" : 65260,
          "Roff" : 55608,
          "HLSL" : 898,
          "Ruby" : 46804,
          "Lex" : 2069,
          "Dart" : 78320789,
          "Python" : 504541,
          "GLSL" : 210145
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Some of our controls can't handle being built in 0x0 environments",
      "validationOrRequirement" : "create tests that put each UI control into a 0x0 container and make sure they don't crash",
      "attemptedFixes" : "",
      "otherNotes" : "See also https://github.com/flutter/flutter/issues/5259 which triggers this in release and debug --no-hot mode.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283906
  }, {
    "issueDTO" : {
      "id" : 2584366408,
      "title" : "[RULE] Disable local auth for Redis Cache instances",
      "url" : "https://github.com/Azure/PSRule.Rules.Azure/issues/3113",
      "repositoryName" : "Azure/PSRule.Rules.Azure",
      "description" : "### Existing rule\n\n_No response_\n\n### Suggested rule\n\nRedis Cache supports disabling access key-based access by setting the `disableAccessKeyAuthentication` propety to `true`.\n\ne.g.\n\n```json\n{\n    \"name\": \"sfvgsfdfsfsd\",\n    \"type\": \"Microsoft.Cache/redis\",\n    \"apiVersion\": \"2024-04-01-preview\",\n    \"location\": \"eastus\",\n    \"dependsOn\": [],\n    \"properties\": {\n        \"sku\": {\n            \"name\": \"Standard\",\n            \"family\": \"C\",\n            \"capacity\": 0\n        },\n        \"redisConfiguration\": {\n            \"aad-enabled\": \"true\"\n        },\n        \"enableNonSslPort\": false,\n        \"redisVersion\": \"6\",\n        \"disableAccessKeyAuthentication\": true\n    }\n}\n```\n\n### Pillar\n\nSecurity\n\n### Additional context\n\nSimilar rules: https://azure.github.io/PSRule.Rules.Azure/en/rules/Azure.Cosmos.DisableLocalAuth/\n\n- https://learn.microsoft.com/azure/azure-cache-for-redis/cache-azure-active-directory-for-authentication#disable-access-key-authentication-on-your-cache",
      "updatedAt" : 1752239893.000000000,
      "user" : "BernieWhite",
      "userHtmlUrl" : "https://github.com/BernieWhite",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13513058?v=4",
      "labels" : [ "rule: redis", "pillar: security", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Rules to validate Azure resources and infrastructure as code (IaC) using PSRule.",
        "homepage" : "https://azure.github.io/PSRule.Rules.Azure/",
        "name" : "PSRule.Rules.Azure",
        "fullName" : "Azure/PSRule.Rules.Azure",
        "htmlUrl" : "https://github.com/Azure/PSRule.Rules.Azure",
        "gitUrl" : "git://github.com/Azure/PSRule.Rules.Azure.git",
        "sshUrl" : "git@github.com:Azure/PSRule.Rules.Azure.git",
        "cloneUrl" : "https://github.com/Azure/PSRule.Rules.Azure.git",
        "owner" : {
          "login" : "Azure",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 96,
        "stargazersCount" : 420,
        "watchersCount" : 420,
        "size" : 468573,
        "openIssuesCount" : 131,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-11T13:57:53Z",
        "languages" : {
          "PowerShell" : 1511282,
          "C#" : 1324425,
          "Bicep" : 102831,
          "HTML" : 17438,
          "Python" : 4608
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Disable local auth for Redis Cache instances",
      "validationOrRequirement" : "Disable access key-based access by setting the `disableAccessKeyAuthentication` property to `true`",
      "attemptedFixes" : "",
      "otherNotes" : "Similar rules: https://azure.github.io/PSRule.Rules.Azure/en/rules/Azure.Cosmos.DisableLocalAuth/, https://learn.microsoft.com/azure/azure-cache-for-redis/cache-azure-active-directory-for-authentication#disable-access-key-authentication-on-your-cache",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283909
  }, {
    "issueDTO" : {
      "id" : 3162905429,
      "title" : "[FR]: New Evaluaton Metric \"Trajectory Accuracy\"",
      "url" : "https://github.com/comet-ml/opik/issues/2529",
      "repositoryName" : "comet-ml/opik",
      "description" : "### Proposal summary\n\nWe like to extend the existing evaluation metrics to include a new metric called \"Trajectory Accuracy\". Esentially we are evaluating ReAct style agents by reasoning about the sequence of actions taken and their outcomes. Based on the paper ???ReAct: Synergizing Reasoning and Acting in Language Models??? https://arxiv.org/abs/2210.03629. You can also see the Langchain implementation here:\n- https://python.langchain.com/api_reference/langchain/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html\n- https://github.com/langchain-ai/agentevals/tree/main/python/agentevals/trajectory\n\nExample of an existing judge metric (Hallucination) is defined here:\n- Docs: https://www.comet.com/docs/opik/evaluation/metrics/hallucination\n- Docs Code: https://github.com/comet-ml/opik/blob/main/apps/opik-documentation/documentation/fern/docs/evaluation/metrics/hallucination.mdx\n- Python SDK: https://github.com/comet-ml/opik/tree/main/sdks/python/src/opik/evaluation/metrics/llm_judges/hallucination\n- Python Examples: https://github.com/comet-ml/opik/blob/main/sdks/python/examples/metrics.py\n- Frontend: https://github.com/comet-ml/opik/blob/main/apps/opik-frontend/src/constants/llm.ts\n\nIdeally this is implemented as an LLM-as-a-judge. Expectation is the new judge is added to the frontend for using LLM-as-a-judge from the UI (Online Evaluation tab) as well as in the Python SDK. The appropriate docs needs to be updated and a video attached of the metric working.\n\nReturn should be float (0-1), and if its using LLM as a eval then should also contain a \"reason/explanation\"\n\n### Motivation\n\nI would like to see more robust set of metrics and evaluations based on recent research.",
      "updatedAt" : 1752239892.000000000,
      "user" : "vincentkoc",
      "userHtmlUrl" : "https://github.com/vincentkoc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25068?v=4",
      "labels" : [ "python", "\uD83D\uDC8E Bounty", "Frontend", "documentation", "good first issue", "Feature Request", "$50" ],
      "state" : "OPEN",
      "comments" : [ "_Please note this bounty is embargo'd for attendees to the Encode x Comet Vibe Coding Challenges in London from Friday 20th June till Sunday 22nd June (GMT). Any attempts from users not in the event will be ignored. Post 22nd June if unclaimed/no attempts then we will accept other entries._\n\n/bounty 50", "## \uD83D\uDC8E $50 bounty [??? Comet](https://algora.io/comet-ml)\n#### Steps to solve:\n1. **Read Contributing Docs**: See [contributing guide](https://www.comet.com/docs/opik/contributing/overview) and read on how to setup Opik and contribute to various parts of the code base.\n1. **Start working**: Comment `/attempt #2529` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #2529` in the PR body to claim the bounty\n4. **Review**: Team will review PR and any clarifying questions and if successful changes will be merged\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n#### ??? Important guidelines:\n- Do NOT start multiple bounties\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Please ask to be assigned before attempting to work on the bounty\n\nThank you for contributing to Comet!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @vishalpatil1899 | Jun 20, 2025, 11:40:20 AM | WIP |  |\n| \uD83D\uDFE2 @kaan-dogan | Jun 20, 2025, 10:00:06 PM | #2539 | [Reward](https://algora.io/claims/ydKMGS5Je9MR1pEq) |", "/attempt #2529", "@vishalpatil1899 did you read the notice? This is only accpeting people on the encore x comet hackathon for entry. After this time it will be open to public entries.", "Oh no \nIt's alright ", "Hi! I???m a participant in the Encore ?? Comet hackathon and would like to be assigned to this bounty. I noticed the previous attempt may not be eligible per the current participation rules. Please let me know if I can proceed!", "/attempt #2529", "@vincentkoc I would like to work on this issue. Can you please assign me this issue, if it is open to work upon(I see there has been no reply for some time in the opened PR).", "Hi @vincentkoc , is this issue closed? If not, I would love to contribute to this repository.", "@jayantpranjal0 happy for you tomproceed, if not will assign to @riturajFi " ],
      "repository" : {
        "description" : "Debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.",
        "homepage" : "https://www.comet.com/docs/opik/",
        "name" : "opik",
        "fullName" : "comet-ml/opik",
        "htmlUrl" : "https://github.com/comet-ml/opik",
        "gitUrl" : "git://github.com/comet-ml/opik.git",
        "sshUrl" : "git@github.com:comet-ml/opik.git",
        "cloneUrl" : "https://github.com/comet-ml/opik.git",
        "owner" : {
          "login" : "comet-ml",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 764,
        "stargazersCount" : 11036,
        "watchersCount" : 11036,
        "size" : 273368,
        "openIssuesCount" : 121,
        "subscribersCount" : 79,
        "pushedAt" : "2025-07-12T00:23:19Z",
        "languages" : {
          "TypeScript" : 3575987,
          "PowerShell" : 14419,
          "Smarty" : 2605,
          "Dockerfile" : 6149,
          "Shell" : 21129,
          "SCSS" : 8862,
          "Makefile" : 180,
          "JavaScript" : 4754,
          "HTML" : 827,
          "Jupyter Notebook" : 658485,
          "Python" : 6275580
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to extend the existing evaluation metrics to include a new metric called 'Trajectory Accuracy' for evaluating ReAct style agents by reasoning about the sequence of actions taken and their outcomes.",
      "validationOrRequirement" : "The new metric should be implemented as an LLM-as-a-judge and return a float value (0-1). If it's using LLM as an evaluation, it should also contain a 'reason/explanation'. The implementation should be documented and a video attached of the metric working.",
      "attemptedFixes" : "The issue has already been attempted by @vishalpatil1899 and @kaan-dogan, but it seems that the attempts are not eligible per the current participation rules. The issue is still open for other contributors to attempt.",
      "otherNotes" : "The issue is about implementing a new evaluation metric called 'Trajectory Accuracy' based on the ReAct paper and Langchain implementation. The new metric should be added to the frontend for UI evaluation and in the Python SDK. The author wants to see more robust set of metrics and evaluations based on recent research.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283917
  }, {
    "issueDTO" : {
      "id" : 3220621232,
      "title" : "[Developer Issue]: Writing RDS files is slow b/c they are compressed",
      "url" : "https://github.com/NOAA-FIMS/FIMS/issues/910",
      "repositoryName" : "NOAA-FIMS/FIMS",
      "description" : "### Description\n\n@msupernaw found out that the writing of RDS files in the helper functions for the testthat tests are slow. He also found that there is an argument `saveRDS(compress = FALSE)` that we can use to speed up the writing of the files where the default is `TRUE`. There are 16 (or maybe 14) instances where these files are written, see below for a single example\nhttps://github.com/NOAA-FIMS/FIMS/blob/ffefd20547cd8919305cbe84548a6e12752cdee5/tests/testthat/helper-integration-tests-setup-run.R#L34\nthat we should add the argument `compress = FALSE` to. @msupernaw can you provide differences in write times with and without the argument for writing a single file?",
      "updatedAt" : 1752239872.000000000,
      "user" : "kellijohnson-NOAA",
      "userHtmlUrl" : "https://github.com/kellijohnson-NOAA",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4108564?v=4",
      "labels" : [ "kind: test case", "attribute: low hanging \uD83C\uDF4E", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @kellijohnson-NOAA, this should be fixed in the recent PR." ],
      "repository" : {
        "description" : "The repository for development of FIMS",
        "homepage" : "https://noaa-fims.github.io/FIMS/",
        "name" : "FIMS",
        "fullName" : "NOAA-FIMS/FIMS",
        "htmlUrl" : "https://github.com/NOAA-FIMS/FIMS",
        "gitUrl" : "git://github.com/NOAA-FIMS/FIMS.git",
        "sshUrl" : "git@github.com:NOAA-FIMS/FIMS.git",
        "cloneUrl" : "https://github.com/NOAA-FIMS/FIMS.git",
        "owner" : {
          "login" : "NOAA-FIMS",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 25,
        "watchersCount" : 25,
        "size" : 70444,
        "openIssuesCount" : 102,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-11T18:50:32Z",
        "languages" : {
          "C++" : 577018,
          "R" : 480410,
          "Shell" : 104,
          "CSS" : 65,
          "CMake" : 9205
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Optimize the writing of RDS files in testthat tests by using the 'saveRDS(compress = FALSE)' argument to speed up the process.",
      "validationOrRequirement" : "Add the argument 'compress = FALSE' to the 'saveRDS' function in 16 (or 14) instances where RDS files are written.",
      "attemptedFixes" : "The issue is still open, no fixes have been attempted yet.",
      "otherNotes" : "The issue is related to slow writing of RDS files in testthat tests, specifically in the helper functions. There is an argument 'saveRDS(compress = FALSE)' that can be used to speed up the process. The default is 'TRUE'.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283922
  }, {
    "issueDTO" : {
      "id" : 2545473115,
      "title" : "Update `react-qr-reader`",
      "url" : "https://github.com/trezor/trezor-suite/issues/14512",
      "repositoryName" : "trezor/trezor-suite",
      "description" : "The [repo](https://github.com/JodusNodus/react-qr-reader) is no longer maintained and there are issues regarding compatibility with new versions of React. Also this bug: https://github.com/trezor/trezor-suite/issues/13460\r\n\r\nFind an alternative, e.g. https://www.npmjs.com/package/react-zxing.",
      "updatedAt" : 1752239311.000000000,
      "user" : "komret",
      "userHtmlUrl" : "https://github.com/komret",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/42465546?v=4",
      "labels" : [ "good first issue", "dependencies" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Trezor Suite Monorepo",
        "homepage" : "https://trezor.io/trezor-suite",
        "name" : "trezor-suite",
        "fullName" : "trezor/trezor-suite",
        "htmlUrl" : "https://github.com/trezor/trezor-suite",
        "gitUrl" : "git://github.com/trezor/trezor-suite.git",
        "sshUrl" : "git@github.com:trezor/trezor-suite.git",
        "cloneUrl" : "https://github.com/trezor/trezor-suite.git",
        "owner" : {
          "login" : "trezor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 303,
        "stargazersCount" : 866,
        "watchersCount" : 866,
        "size" : 953910,
        "openIssuesCount" : 1094,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T21:02:32Z",
        "languages" : {
          "TypeScript" : 20463148,
          "MDX" : 273490,
          "Dockerfile" : 7355,
          "CSS" : 73976,
          "Shell" : 51701,
          "Rust" : 49831,
          "JavaScript" : 432120,
          "HTML" : 249002,
          "Swift" : 1600,
          "Nix" : 6990,
          "Ruby" : 783,
          "Kotlin" : 22878
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update react-qr-reader with a compatible alternative due to maintenance issues and compatibility problems",
      "validationOrRequirement" : "Find an alternative to react-qr-reader, e.g. https://www.npmjs.com/package/react-zxing",
      "attemptedFixes" : "",
      "otherNotes" : "The repo is no longer maintained and there are issues regarding compatibility with new versions of React. Also, there is a related bug https://github.com/trezor/trezor-suite/issues/13460",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283926
  }, {
    "issueDTO" : {
      "id" : 3175245319,
      "title" : "move nursery",
      "url" : "https://github.com/syne-tune/syne-tune/issues/966",
      "repositoryName" : "syne-tune/syne-tune",
      "description" : "Clean up syne tune repo by moving nursery into a separate repo \n",
      "updatedAt" : 1752238866.000000000,
      "user" : "aaronkl",
      "userHtmlUrl" : "https://github.com/aaronkl",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5735696?v=4",
      "labels" : [ "chore", "good first issue", "refactor" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Large scale and asynchronous Hyperparameter and Architecture Optimization at your fingertips.",
        "homepage" : "https://syne-tune.readthedocs.io",
        "name" : "syne-tune",
        "fullName" : "syne-tune/syne-tune",
        "htmlUrl" : "https://github.com/syne-tune/syne-tune",
        "gitUrl" : "git://github.com/syne-tune/syne-tune.git",
        "sshUrl" : "git@github.com:syne-tune/syne-tune.git",
        "cloneUrl" : "https://github.com/syne-tune/syne-tune.git",
        "owner" : {
          "login" : "syne-tune",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 55,
        "stargazersCount" : 410,
        "watchersCount" : 410,
        "size" : 11185,
        "openIssuesCount" : 19,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T13:41:22Z",
        "languages" : {
          "Dockerfile" : 2370,
          "Shell" : 5299,
          "Python" : 3065044
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to refactor the syne-tune repository by moving the nursery into a separate repository.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "Repository syne-tune/syne-tune needs to be refactored by moving nursery into a separate repository.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283929
  }, {
    "issueDTO" : {
      "id" : 3028963814,
      "title" : "Locktime field infinite validation loop",
      "url" : "https://github.com/trezor/trezor-suite/issues/18652",
      "repositoryName" : "trezor/trezor-suite",
      "description" : "**Bug description**\nLocktime field has flickering validation loop with text \"Not enough funds selected\"\n\n\n**Steps to reproduce**\n1. Open desktop Trezor Suite\n2. Go to \"Send\"\n3. Turn on Coin Control\n4. Select one UTXO in Coin Control\n5. Add Locktime \"1\"\n6. Turn off Broadcast\n7. Sign transaction\n8. Copy transaction hex and close modal (Stay on \"Send\" page with selected UTXO)\n9. Transmit transaction on 3rd party app (eg. mempool)\n\n**Additional information**\nOccured on Testnet4 \nTrezor Suite version: 25.4.2\nOS: Windows 11\n\n**Video**\n\n![Image](https://github.com/user-attachments/assets/e5e39c55-dbd4-4854-8520-e336de886b6e)",
      "updatedAt" : 1752238775.000000000,
      "user" : "tomasarchalous",
      "userHtmlUrl" : "https://github.com/tomasarchalous",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20450039?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Couldn't reproduce this on current develop (c855d592ad)." ],
      "repository" : {
        "description" : "Trezor Suite Monorepo",
        "homepage" : "https://trezor.io/trezor-suite",
        "name" : "trezor-suite",
        "fullName" : "trezor/trezor-suite",
        "htmlUrl" : "https://github.com/trezor/trezor-suite",
        "gitUrl" : "git://github.com/trezor/trezor-suite.git",
        "sshUrl" : "git@github.com:trezor/trezor-suite.git",
        "cloneUrl" : "https://github.com/trezor/trezor-suite.git",
        "owner" : {
          "login" : "trezor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 303,
        "stargazersCount" : 866,
        "watchersCount" : 866,
        "size" : 953910,
        "openIssuesCount" : 1094,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T21:02:32Z",
        "languages" : {
          "TypeScript" : 20463148,
          "MDX" : 273490,
          "Dockerfile" : 7355,
          "CSS" : 73976,
          "Shell" : 51701,
          "Rust" : 49831,
          "JavaScript" : 432120,
          "HTML" : 249002,
          "Swift" : 1600,
          "Nix" : 6990,
          "Ruby" : 783,
          "Kotlin" : 22878
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Locktime field has flickering validation loop",
      "validationOrRequirement" : "Not enough funds selected",
      "attemptedFixes" : "Couldn't reproduce this on current develop (c855d592ad)",
      "otherNotes" : "Occured on Testnet4, Trezor Suite version: 25.4.2, OS: Windows 11, attached video",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283932
  }, {
    "issueDTO" : {
      "id" : 1592609918,
      "title" : "hide the signature format switch where it doesn't make a difference",
      "url" : "https://github.com/trezor/trezor-suite/issues/7674",
      "repositoryName" : "trezor/trezor-suite",
      "description" : "coins where message signing is enabled display the Trezor/Electrum signature format switch. I'm unsure if it makes sense for non-Bitcoin coins with Electrum-fork wallets (Litecoin, Dash), but it's definitely meaningless for those without. e.g. for Ethereum the signature is the same even if I choose the Electrum format. I suggest removing the switch for coins where it doesn't make a difference.\n\n![Image](https://github.com/user-attachments/assets/81190108-cc54-44fa-9c6c-b250dea2a4be)",
      "updatedAt" : 1752238762.000000000,
      "user" : "chaserene",
      "userHtmlUrl" : "https://github.com/chaserene",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/64873595?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Here is PR and issue  that introduced this format onto Suite \nhttps://github.com/trezor/trezor-suite/issues/4855 https://github.com/trezor/trezor-suite/pull/4951", "UPDATE:\n\n**Remove the switch from all ethereum-like and all bitcoin-like non-legacy accounts. In practice, only keep it for bitcoin and litecoin accounts except legacy.**\n\nExplanation:\nThe change is only in the first byte denoting account type, Electrum does not differentiate between account types. It makes sense to keep the switch for litecoin because there are Electrum forks for bitcoin-like coins.\n\nHow Sign & Verify works: https://trezor.io/guides/trezor-suite/trezor-suite-desktop/sign-and-verify-messages-trezor-suite" ],
      "repository" : {
        "description" : "Trezor Suite Monorepo",
        "homepage" : "https://trezor.io/trezor-suite",
        "name" : "trezor-suite",
        "fullName" : "trezor/trezor-suite",
        "htmlUrl" : "https://github.com/trezor/trezor-suite",
        "gitUrl" : "git://github.com/trezor/trezor-suite.git",
        "sshUrl" : "git@github.com:trezor/trezor-suite.git",
        "cloneUrl" : "https://github.com/trezor/trezor-suite.git",
        "owner" : {
          "login" : "trezor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 303,
        "stargazersCount" : 866,
        "watchersCount" : 866,
        "size" : 953910,
        "openIssuesCount" : 1094,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T21:02:32Z",
        "languages" : {
          "TypeScript" : 20463148,
          "MDX" : 273490,
          "Dockerfile" : 7355,
          "CSS" : 73976,
          "Shell" : 51701,
          "Rust" : 49831,
          "JavaScript" : 432120,
          "HTML" : 249002,
          "Swift" : 1600,
          "Nix" : 6990,
          "Ruby" : 783,
          "Kotlin" : 22878
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Hide the signature format switch where it doesn't make a difference, for coins where message signing is enabled.",
      "validationOrRequirement" : "Remove the switch for coins where it doesn't make a difference, specifically for coins with Electrum-fork wallets (Litecoin, Dash) and Ethereum.",
      "attemptedFixes" : "Remove the switch from all ethereum-like and all bitcoin-like non-legacy accounts. In practice, only keep it for bitcoin and litecoin accounts except legacy.",
      "otherNotes" : "The change is only in the first byte denoting account type, Electrum does not differentiate between account types. It makes sense to keep the switch for litecoin because there are Electrum forks for bitcoin-like coins.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283936
  }, {
    "issueDTO" : {
      "id" : 1237138860,
      "title" : "Do not try to broadcast transactions with a timelock",
      "url" : "https://github.com/trezor/trezor-suite/issues/5391",
      "repositoryName" : "trezor/trezor-suite",
      "description" : "If user has created a transaction where `lock_time > current block height`, the Suite should not offer to \"broadcast\" the transaction = the broadcast button should be disabled. Ideally with an explanation that the transaction could not be broadcasted to the mempool and should rather be saved (copy-paste as hex?) and broadcasted later.",
      "updatedAt" : 1752238756.000000000,
      "user" : "prusnak",
      "userHtmlUrl" : "https://github.com/prusnak",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/42201?v=4",
      "labels" : [ "feature", "bug", "send", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Was already fixed in 4a3c7b4a" ],
      "repository" : {
        "description" : "Trezor Suite Monorepo",
        "homepage" : "https://trezor.io/trezor-suite",
        "name" : "trezor-suite",
        "fullName" : "trezor/trezor-suite",
        "htmlUrl" : "https://github.com/trezor/trezor-suite",
        "gitUrl" : "git://github.com/trezor/trezor-suite.git",
        "sshUrl" : "git@github.com:trezor/trezor-suite.git",
        "cloneUrl" : "https://github.com/trezor/trezor-suite.git",
        "owner" : {
          "login" : "trezor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 303,
        "stargazersCount" : 866,
        "watchersCount" : 866,
        "size" : 953910,
        "openIssuesCount" : 1094,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T21:02:32Z",
        "languages" : {
          "TypeScript" : 20463148,
          "MDX" : 273490,
          "Dockerfile" : 7355,
          "CSS" : 73976,
          "Shell" : 51701,
          "Rust" : 49831,
          "JavaScript" : 432120,
          "HTML" : 249002,
          "Swift" : 1600,
          "Nix" : 6990,
          "Ruby" : 783,
          "Kotlin" : 22878
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Disable broadcast button for transactions with timelock and provide explanation",
      "validationOrRequirement" : "transaction lock_time > current block height",
      "attemptedFixes" : "Was already fixed in 4a3c7b4a",
      "otherNotes" : "Was already fixed in 4a3c7b4a",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283939
  }, {
    "issueDTO" : {
      "id" : 889877562,
      "title" : "Improve locktime field",
      "url" : "https://github.com/trezor/trezor-suite/issues/3746",
      "repositoryName" : "trezor/trezor-suite",
      "description" : "**Is your feature request related to a problem? Please describe.**\n\nWhen entering a locktime users need to use an external resource to either:\n- calculate the timestamp of the date and time they want to enter, or\n- look up the current block height.\n\nSuite should provide a simple means for them to do so inside the application.\n\n![Image](https://github.com/user-attachments/assets/644ae482-bc83-4616-a78b-005217b7ee81)\nNote to the screenshot: future blockheight and timestamp are not convertible, we could offer an estimate at best. Let's drop that. Instead, autofill current datetime/blockheight when the option is selected. Allow passing seconds as well, in format hh:mm:ss; when they are not provided, treat the seconds value as 00; the default value should not include seconds (format hh:mm, i.e. 00:00). Datetime will be the default variant. Below the input, on the right side, include info about current blockheight/datetime.",
      "updatedAt" : 1752238741.000000000,
      "user" : "andrewkozlik",
      "userHtmlUrl" : "https://github.com/andrewkozlik",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/42678794?v=4",
      "labels" : [ "feature", "send", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Trezor Suite Monorepo",
        "homepage" : "https://trezor.io/trezor-suite",
        "name" : "trezor-suite",
        "fullName" : "trezor/trezor-suite",
        "htmlUrl" : "https://github.com/trezor/trezor-suite",
        "gitUrl" : "git://github.com/trezor/trezor-suite.git",
        "sshUrl" : "git@github.com:trezor/trezor-suite.git",
        "cloneUrl" : "https://github.com/trezor/trezor-suite.git",
        "owner" : {
          "login" : "trezor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 303,
        "stargazersCount" : 866,
        "watchersCount" : 866,
        "size" : 953910,
        "openIssuesCount" : 1094,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T21:02:32Z",
        "languages" : {
          "TypeScript" : 20463148,
          "MDX" : 273490,
          "Dockerfile" : 7355,
          "CSS" : 73976,
          "Shell" : 51701,
          "Rust" : 49831,
          "JavaScript" : 432120,
          "HTML" : 249002,
          "Swift" : 1600,
          "Nix" : 6990,
          "Ruby" : 783,
          "Kotlin" : 22878
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve the locktime field by providing a simple means for users to calculate or look up the current block height or timestamp within the application.",
      "validationOrRequirement" : "Provide a simple means for users to calculate or look up the current block height or timestamp within the application. Support for seconds in the format hh:mm:ss and default value without seconds.",
      "attemptedFixes" : "None mentioned in the issue description",
      "otherNotes" : "The issue is related to improving the locktime field, specifically providing a simple means for users to calculate or look up the current block height or timestamp within the application. A screenshot is provided, showing the expected functionality and notes on the limitations of converting future block height and timestamp.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283943
  }, {
    "issueDTO" : {
      "id" : 3062897106,
      "title" : "Tracking progress for constexpr cmath (P0533R9, P1383R2)",
      "url" : "https://github.com/llvm/llvm-project/issues/139885",
      "repositoryName" : "llvm/llvm-project",
      "description" : "`constexpr` cmath papers ([P0533R9](https://wg21.link/P0533R9), [P1383R2](https://wg21.link/P1383R2) for C++23 and C++26 will take a while to implement.\n\nAs we plan to implement builtins in clang using llvm-libc' math functions, and then use that to implement `libc++`, it would be useful to have a page that tracks what builtins are implemented, what libc features are missing, and what is supported by libc++.\n\nThat would let\n   - LLVM contributors coordinate more effectively\n   - Let users know what they can use\n   - Let other implementers synchronize (MSVC wants to use libc, and MSSTL wants to be clang compatible)\n\nI'm not sure if the best place would be a GitHub issue or an RST file somewhere.\nNote that libc does an excellent job of tracking what they support https://libc.llvm.org/headers/math/index.html. \n\n \n",
      "updatedAt" : 1752238722.000000000,
      "user" : "cor3ntin",
      "userHtmlUrl" : "https://github.com/cor3ntin",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1409019?v=4",
      "labels" : [ "c++26", "clang:frontend", "c++23", "metaissue", "documentation", "libc", "good first issue", "libc++" ],
      "state" : "OPEN",
      "comments" : [ "\n@llvm/issue-subscribers-libc\n\nAuthor: cor3ntin (cor3ntin)\n\n<details>\n`constexpr` cmath papers ([P0533R9](https://wg21.link/P0533R9), [P1383R2](https://wg21.link/P1383R2) for C++23 and C++26 will take a while to implement.\n\nAs we plan to implement builtins in clang using llvm-libc' math functions, and then use that to implement `libc++`, it would be useful to have a page that tracks what builtins are implemented, what libc features are missing, and what is supported by libc++.\n\nThat would let\n   - LLVM contributors coordinate more effectively\n   - Let users know what they can use\n   - Let other implementers synchronize (MSVC wants to use libc, and MSSTL wants to be clang compatible)\n\nI'm not sure if the best place would be a GitHub issue or an RST file somewhere.\nNote that libc does an excellent job of tracking what they support https://libc.llvm.org/headers/math/index.html. \n\n \n\n</details>\n", "\nHi!\n\nThis issue may be a good introductory issue for people new to working on LLVM. If you would like to work on this issue, your first steps are:\n\n1. Check that no other contributor has already been assigned to this issue. If you believe that no one is actually working on it despite an assignment, ping the person. After one week without a response, the assignee may be changed.\n1. In the comments of this issue, request for it to be assigned to you, or just create a [pull request](https://github.com/llvm/llvm-project/pulls) after following the steps below. [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n1. Fix the issue locally.\n1. [Run the test suite](https://llvm.org/docs/TestingGuide.html#unit-and-regression-tests) locally. Remember that the subdirectories under `test/` create fine-grained testing targets, so you can e.g. use `make check-clang-ast` to only run Clang's AST tests.\n1. Create a Git commit.\n1. Run [`git clang-format HEAD~1`](https://clang.llvm.org/docs/ClangFormat.html#git-integration) to format your changes.\n1. Open a [pull request](https://github.com/llvm/llvm-project/pulls) to the [upstream repository](https://github.com/llvm/llvm-project) on GitHub. Detailed instructions can be found [in GitHub's documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request). [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n\nIf you have any further questions about this issue, don't hesitate to ask via a comment in the thread below.\n\n", "\n@llvm/issue-subscribers-good-first-issue\n\nAuthor: cor3ntin (cor3ntin)\n\n<details>\n`constexpr` cmath papers ([P0533R9](https://wg21.link/P0533R9), [P1383R2](https://wg21.link/P1383R2) for C++23 and C++26 will take a while to implement.\n\nAs we plan to implement builtins in clang using llvm-libc' math functions, and then use that to implement `libc++`, it would be useful to have a page that tracks what builtins are implemented, what libc features are missing, and what is supported by libc++.\n\nThat would let\n   - LLVM contributors coordinate more effectively\n   - Let users know what they can use\n   - Let other implementers synchronize (MSVC wants to use libc, and MSSTL wants to be clang compatible)\n\nI'm not sure if the best place would be a GitHub issue or an RST file somewhere.\nNote that libc does an excellent job of tracking what they support https://libc.llvm.org/headers/math/index.html. \n\n \n\n</details>\n", "\n@llvm/issue-subscribers-clang-frontend\n\nAuthor: cor3ntin (cor3ntin)\n\n<details>\n`constexpr` cmath papers ([P0533R9](https://wg21.link/P0533R9), [P1383R2](https://wg21.link/P1383R2) for C++23 and C++26 will take a while to implement.\n\nAs we plan to implement builtins in clang using llvm-libc' math functions, and then use that to implement `libc++`, it would be useful to have a page that tracks what builtins are implemented, what libc features are missing, and what is supported by libc++.\n\nThat would let\n   - LLVM contributors coordinate more effectively\n   - Let users know what they can use\n   - Let other implementers synchronize (MSVC wants to use libc, and MSSTL wants to be clang compatible)\n\nI'm not sure if the best place would be a GitHub issue or an RST file somewhere.\nNote that libc does an excellent job of tracking what they support https://libc.llvm.org/headers/math/index.html. \n\n \n\n</details>\n", "hi @cor3ntin, I would like to work on this issue, and I have a couple of questions:\n1. Where can I find all math functions that `libc++` is expected to implement, and which features already implemented.\n2. Is it acceptable to create a new RST file under \"libcxx/docs/Status\", similar to `Parallelism.rst` which tracks the status of the Parallelism TS implementation?", "I looked into this issue a while ago. The tracking for which functions are expected to be implemented can be found in `constexpr-cxx23-clang.pass.cpp` and `constexpr-cxx23-gcc.pass.cpp`. Reading the papers linked in the issues above and the mentioned PRs was also really helpful. I was thinking about splitting the changes for similar functions into separate PRs. Perhaps the two of us can split the work so we can get through this quicker and not step on each others toes? I have looked the most into the `abs` and `fabs` family of functions. How about I take them off your plate?", "@arjunUpatel Yes, of course. However, I have not started this work yet, as I have not received any response from the contributor. I will reach out to them to confirm whether this issue still needs to be completed. If it does, I can work on finishing the outline document so that you can focus on tracking progress for any functions you are interested in.", "@0w0zzzzzz Thanks for volunteering!\n\n> Where can I find all math functions that libc++ is expected to implement, and which features already implemented.\n\n\nThe list of function to implement is in https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p0533r9.pdf and https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2023/p1383r2.pdf\n\nI'm not sure we implemented anything yet. Let's mark anything as unimplemented for now, and we can update the list with any implemented features afterwards.\n\n> Is it acceptable to create a new RST file under \"libcxx/docs/Status\", similar to Parallelism.rst, which tracks the status of the Parallelism TS implementation?\n\nThat sounds reasonable!\n", "@cor3ntin @0w0zzzzzz Since we moved our WG21 conformance status tracking to Github issues, we discourage the creation of documentation pages like `libcxx/docs/Status/Parallelism.rst`. We now track everything inside GitHub.\n\nFor the libc++ parts, I would basically create sub-issues of https://github.com/llvm/llvm-project/issues/105174 and https://github.com/llvm/llvm-project/issues/105385 instead.", "@ldionne Got it. I suggested using a GitHub Project because it would provide better clarity, as we need to track each math function across several dimensions like implementation by builtin, libc, and libc++. However, I don't currently have permission to create or modify a Project here, and I'll look into how to use GitHub Projects.\n", "@cor3ntin @ldionne \n1. Could you please create a GitHub project for this and give me access to it? This way, I can set up a project board to track the progress, as GitHub projects allow separate permission management. Of course, if there are management concerns and project access can???t be granted, that???s totally fine. (Project permission settings could be found at \"xxx project-settings icon-Manage access\".)\n2. In the meantime, I???ve created a Google Sheet [Tracking Table for constexpr Support](https://docs.google.com/spreadsheets/d/1KEJ-ZNnGf6qWWHassOckj1JRqgjwagtuSpb1cbpc1yo/edit?usp=sharing) open editing permissions. We can first review the columns and value types there. If anything needs to be changed, please feel free to edit the sheet or leave a comment. Once the structure looks good, we can migrate the information to the GitHub project and update specific values there.", "Math functions added in C23 are also constexpr-ized when adopted into C++26. Currently, P3008R6 and P3348R4 have added a small number of them." ],
      "repository" : {
        "description" : "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.",
        "homepage" : "http://llvm.org",
        "name" : "llvm-project",
        "fullName" : "llvm/llvm-project",
        "htmlUrl" : "https://github.com/llvm/llvm-project",
        "gitUrl" : "git://github.com/llvm/llvm-project.git",
        "sshUrl" : "git@github.com:llvm/llvm-project.git",
        "cloneUrl" : "https://github.com/llvm/llvm-project.git",
        "owner" : {
          "login" : "llvm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14443,
        "stargazersCount" : 33450,
        "watchersCount" : 33450,
        "size" : 2519038,
        "openIssuesCount" : 30765,
        "subscribersCount" : 577,
        "pushedAt" : "2025-07-12T01:01:34Z",
        "languages" : {
          "GDB" : 8473,
          "CMake" : 4075997,
          "Mustache" : 16482,
          "HTML" : 1956247,
          "Pawn" : 10154,
          "MATLAB" : 4946,
          "Fortran" : 11610249,
          "LLVM" : 631719945,
          "OCaml" : 335815,
          "Assembly" : 150737335,
          "Python" : 12915167,
          "Rust" : 4903,
          "Objective-C++" : 1173632,
          "SWIG" : 287770,
          "Tree-sitter Query" : 6195,
          "Perl" : 183797,
          "MLIR" : 21179643,
          "Cuda" : 1243342,
          "Scilab" : 160404,
          "Starlark" : 1177382,
          "Batchfile" : 52122,
          "AMPL" : 1662,
          "Swift" : 271,
          "DTrace" : 334,
          "C" : 202129658,
          "RPC" : 28,
          "Makefile" : 114902,
          "Cool" : 5401,
          "Jupyter Notebook" : 72939,
          "M" : 9785,
          "TypeScript" : 69121,
          "Shell" : 263950,
          "Awk" : 127345,
          "JavaScript" : 161607,
          "Mathematica" : 1118,
          "Objective-C" : 4269109,
          "Lua" : 12033,
          "PHP" : 64,
          "Limbo" : 303,
          "POV-Ray SDL" : 861,
          "Emacs Lisp" : 69003,
          "C++" : 488688394,
          "CSS" : 63859,
          "FIRRTL" : 4298018,
          "TeX" : 2141,
          "AppleScript" : 1429,
          "NASL" : 35217,
          "HIP" : 856703,
          "Julia" : 49676,
          "Dockerfile" : 23252,
          "Linker Script" : 903,
          "Roff" : 60700,
          "HLSL" : 1475332,
          "Mercury" : 14,
          "Vim Script" : 29186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to track progress for constexpr cmath (P0533R9, P1383R2) and implementing builtins in clang using llvm-libc' math functions, then using that to implement libc++. The issue aims to provide a page that tracks what builtins are implemented, what libc features are missing, and what is supported by libc++.",
      "validationOrRequirement" : "The issue requires the contributor to check that no other contributor has already been assigned to this issue, and to request for it to be assigned to them. The issue also requires the contributor to create a pull request after fixing the issue locally.",
      "attemptedFixes" : "The issue mentions that the contributor has not started the work yet, and the contributor is looking for volunteers to help with the issue. The contributor also suggests creating a GitHub project to track the progress.",
      "otherNotes" : "The issue is about tracking progress for constexpr cmath (P0533R9, P1383R2) and implementing builtins in clang using llvm-libc' math functions, then using that to implement libc++. It would be useful to have a page that tracks what builtins are implemented, what libc features are missing, and what is supported by libc++. The issue also mentions that libc does an excellent job of tracking what they support.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283953
  }, {
    "issueDTO" : {
      "id" : 3092642119,
      "title" : "The readiness API returns inconsistent results across multiple versions",
      "url" : "https://github.com/alibaba/nacos/issues/13437",
      "repositoryName" : "alibaba/nacos",
      "description" : "<!-- Here is for bug reports and feature requests ONLY! \n\nIf you're looking for help, please check our mail list???WeChat group and the Gitter room.\n\nPlease try to use English to describe your issue, or at least provide a snippet of English translation.\n?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n-->\n\n**Describe the bug**\nThe readiness API returns inconsistent results across multiple versions\n\n```shell\nnacosv2-0:/home/nacos# curl 127.0.0.1:8848/nacos/v2/console/health/readiness -v\n*   Trying 127.0.0.1:8848...\n* Connected to 127.0.0.1 (127.0.0.1) port 8848\n* using HTTP/1.x\n> GET /nacos/v2/console/health/readiness HTTP/1.1\n> Host: 127.0.0.1:8848\n> User-Agent: curl/8.12.1\n> Accept: */*\n> \n* Request completely sent off\n< HTTP/1.1 200 \n< Vary: Origin\n< Vary: Access-Control-Request-Method\n< Vary: Access-Control-Request-Headers\n< Content-Security-Policy: script-src 'self'\n< Content-Type: application/json\n< Transfer-Encoding: chunked\n< Date: Tue, 27 May 2025 05:34:06 GMT\n< \n* Connection #0 to host 127.0.0.1 left intact\n{\"code\":30000,\"message\":\"naming not in readiness\",\"data\":null}nacosv2-0:/home/nacos# \nnacosv2-0:/home/nacos# \nnacosv2-0:/home/nacos# \nnacosv2-0:/home/nacos# \nnacosv2-0:/home/nacos# \nnacosv2-0:/home/nacos# curl 127.0.0.1:8848/nacos/v1/console/health/readiness -v\n*   Trying 127.0.0.1:8848...\n* Connected to 127.0.0.1 (127.0.0.1) port 8848\n* using HTTP/1.x\n> GET /nacos/v1/console/health/readiness HTTP/1.1\n> Host: 127.0.0.1:8848\n> User-Agent: curl/8.12.1\n> Accept: */*\n> \n* Request completely sent off\n< HTTP/1.1 500 \n< Vary: Origin\n< Vary: Access-Control-Request-Method\n< Vary: Access-Control-Request-Headers\n< Content-Security-Policy: script-src 'self'\n< Content-Type: text/plain;charset=UTF-8\n< Content-Length: 23\n< Date: Tue, 27 May 2025 05:34:10 GMT\n< Connection: close\n< \n* shutting down connection #0\nnaming not in readiness\n```\n\n**Expected behavior**\nall both return 200\n\n**Actually behavior**\n200 and 500\n\n**How to Reproduce**\nSteps to reproduce the behavior:\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See errors\n\n**Desktop (please complete the following information):**\n - OS: Docker\n - Version nacos-server 2.5.1\n",
      "updatedAt" : 1752238576.000000000,
      "user" : "lin1005q",
      "userHtmlUrl" : "https://github.com/lin1005q",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15811933?v=4",
      "labels" : [ "version/3.x", "good first issue", "kind/research" ],
      "state" : "OPEN",
      "comments" : [ "v1 and v2 API will deprecated in 3.1.0.\n\nsuggest you use v3 api.", "also need check the v3 api whether return 200 when readiness is not pass.", "3.1 ?????????????????????", "@ I will resolve it ", "I check this on develop branch. with compatible enabled. It is not problem.\n```\n for i in {1..3}\ndo\n curl -I 127.0.0.1:8080/v$i/console/health/readiness\ndone\nHTTP/1.1 200\nVary: Origin\nVary: Access-Control-Request-Method\nVary: Access-Control-Request-Headers\nContent-Security-Policy: script-src 'self'\nX-Content-Type-Options: nosniff\nX-XSS-Protection: 0\nCache-Control: no-cache, no-store, max-age=0, must-revalidate\nPragma: no-cache\nExpires: 0\nX-Frame-Options: DENY\nContent-Type: text/plain;charset=UTF-8\nContent-Length: 2\nDate: Fri, 11 Jul 2025 12:48:56 GMT\n\nHTTP/1.1 200\nVary: Origin\nVary: Access-Control-Request-Method\nVary: Access-Control-Request-Headers\nContent-Security-Policy: script-src 'self'\nX-Content-Type-Options: nosniff\nX-XSS-Protection: 0\nCache-Control: no-cache, no-store, max-age=0, must-revalidate\nPragma: no-cache\nExpires: 0\nX-Frame-Options: DENY\nContent-Type: application/json\nDate: Fri, 11 Jul 2025 12:48:56 GMT\n\nHTTP/1.1 200\nVary: Origin\nVary: Access-Control-Request-Method\nVary: Access-Control-Request-Headers\nContent-Security-Policy: script-src 'self'\nX-Content-Type-Options: nosniff\nX-XSS-Protection: 0\nCache-Control: no-cache, no-store, max-age=0, must-revalidate\nPragma: no-cache\nExpires: 0\nX-Frame-Options: DENY\nContent-Type: application/json\nDate: Fri, 11 Jul 2025 12:48:56 GMT\n```", "i also check with develop-2.x . I think this is not a problem\n\n```\nnacos on v2.x-develop via ??? v1.8.0\n??? for i in {1..2}\ndo\necho \"----\" &&  curl  127.0.0.1:8848/nacos/v$i/console/health/readiness && echo \"\" && echo \"----\"\ndone\n----\nOK\n----\n----\n{\"code\":0,\"message\":\"success\",\"data\":\"ok\"}\n----\n\nnacos on v2.x-develop via ??? v1.8.0\n??? for i in {1..2}\ndo\necho \"----\" &&  curl -I  127.0.0.1:8848/nacos/v$i/console/health/readiness && echo \"\" && echo \"----\"\ndone\n----\nHTTP/1.1 200\nVary: Origin\nVary: Access-Control-Request-Method\nVary: Access-Control-Request-Headers\nContent-Security-Policy: script-src 'self'\nContent-Type: text/plain;charset=UTF-8\nContent-Length: 2\nDate: Fri, 11 Jul 2025 12:54:45 GMT\n\n\n----\n----\nHTTP/1.1 200\nVary: Origin\nVary: Access-Control-Request-Method\nVary: Access-Control-Request-Headers\nContent-Security-Policy: script-src 'self'\nContent-Type: application/json\nContent-Length: 42\nDate: Fri, 11 Jul 2025 12:54:45 GMT\n\n\n----\n```" ],
      "repository" : {
        "description" : "an easy-to-use dynamic service discovery, configuration and service management platform for building AI cloud native applications.",
        "homepage" : "https://nacos.io",
        "name" : "nacos",
        "fullName" : "alibaba/nacos",
        "htmlUrl" : "https://github.com/alibaba/nacos",
        "gitUrl" : "git://github.com/alibaba/nacos.git",
        "sshUrl" : "git@github.com:alibaba/nacos.git",
        "cloneUrl" : "https://github.com/alibaba/nacos.git",
        "owner" : {
          "login" : "alibaba",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 13094,
        "stargazersCount" : 31743,
        "watchersCount" : 31743,
        "size" : 63250,
        "openIssuesCount" : 283,
        "subscribersCount" : 910,
        "pushedAt" : "2025-07-04T02:18:40Z",
        "languages" : {
          "TypeScript" : 4774,
          "Java" : 14900574,
          "Shell" : 15470,
          "Batchfile" : 6817,
          "SCSS" : 95019,
          "JavaScript" : 14316,
          "EJS" : 2645
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The readiness API returns inconsistent results across multiple versions, with v1 API returning a 500 error and v2 API returning a 200 error.",
      "validationOrRequirement" : "The issue is related to the readiness API and the deprecation of v1 and v2 APIs in 3.1.0.",
      "attemptedFixes" : "The author has checked the issue on the develop branch with compatible enabled and found it not to be a problem.",
      "otherNotes" : "The issue is about the readiness API returning inconsistent results across multiple versions. The v1 API returns a 500 error, while the v2 API returns a 200 error. The issue is related to the deprecation of v1 and v2 APIs in 3.1.0, and the suggestion to use v3 API.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283959
  }, {
    "issueDTO" : {
      "id" : 3222825056,
      "title" : "Release:",
      "url" : "https://github.com/camunda/camunda/issues/35226",
      "repositoryName" : "camunda/camunda",
      "description" : "## Description\n\n\n<!-- Describe the bug, feature or task regarding the Monorepo Release process that this ticket should be about. -->\n<!-- For bugs describe a) where it happened, b) what the impact is, c) how to reproduce it, if known. -->\n\n## Goal\n\n- Create [custom instructions](https://docs.github.com/en/copilot/how-tos/custom-instructions/adding-repository-custom-instructions-for-github-copilot) file for the release repo: https://github.com/camunda/zeebe-engineering-processes:\n  - Document high outline of the release process (main steps, forms)\n  - Document variables used (e.g. `release_candidate_version` etc.)\n  - Document specifics of the repo (e.g. Camunda FEEL expression flavor, Camunda 8 stack, Kotlin for testing etc.)\n\n<!-- For features and tasks, describe how the end result should look like and what steps are needed to get there, if known. -->\n\n## Hints\n\n<!-- Any additional context, links or information you have about this ticket. Also specify if any backporting should be done, see the guidelines:\nhttps://github.com/camunda/camunda/wiki/Release-Process#backporting-guidelines\n-->\n\nNB: Only cover the release part, don't worry about the medic process.",
      "updatedAt" : 1752238551.000000000,
      "user" : "maxdanilov",
      "userHtmlUrl" : "https://github.com/maxdanilov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6655714?v=4",
      "labels" : [ "component/release", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Process Orchestration Framework",
        "homepage" : "https://camunda.com/platform/",
        "name" : "camunda",
        "fullName" : "camunda/camunda",
        "htmlUrl" : "https://github.com/camunda/camunda",
        "gitUrl" : "git://github.com/camunda/camunda.git",
        "sshUrl" : "git@github.com:camunda/camunda.git",
        "cloneUrl" : "https://github.com/camunda/camunda.git",
        "owner" : {
          "login" : "camunda",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 679,
        "stargazersCount" : 3723,
        "watchersCount" : 3723,
        "size" : 643351,
        "openIssuesCount" : 2373,
        "subscribersCount" : 114,
        "pushedAt" : "2025-07-11T23:23:17Z",
        "languages" : {
          "MDX" : 2383,
          "Smarty" : 230,
          "Java" : 53137212,
          "CSS" : 2925,
          "Makefile" : 20359,
          "Go" : 76584,
          "HTML" : 14209,
          "FreeMarker" : 94639,
          "TypeScript" : 6978501,
          "Dockerfile" : 23726,
          "Shell" : 47376,
          "Batchfile" : 3877,
          "SCSS" : 133874,
          "JavaScript" : 1534294
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a custom instructions file for the release repo, documenting high outline of the release process, variables used, and specifics of the repo.",
      "validationOrRequirement" : "The issue requires creating a custom instructions file for the release repo, documenting high outline of the release process, variables used, and specifics of the repo.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description.",
      "otherNotes" : "The issue is related to the Monorepo Release process and focuses on creating a custom instructions file for the release repo https://github.com/camunda/zeebe-engineering-processes. The file should document high outline of the release process, variables used, and specifics of the repo.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283964
  }, {
    "issueDTO" : {
      "id" : 291349926,
      "title" : "?????? ???? ???????????????????????? ??????????",
      "url" : "https://github.com/TauCetiStation/TauCetiClassic/issues/2177",
      "repositoryName" : "TauCetiStation/TauCetiClassic",
      "description" : "<!-- \r\n??????????: ???????? ?????? ???????? ???????????????? ???? ???????????????? ?? ????????, ?? ???????????????????????? ?????? ????????-????????, ???? ?????????????????????? ???????????????? ?? ???????????????? ?????? [Proposal]\r\n\r\n\r\n1. ???????????? ?????????????????? ?????? ?????????????????????????????? ??????????????????\r\n(?????? ?? ?????????? ????????, ?????????? ???????? ????????????)\r\n2. ?? ?????????? ?????????????? ???????????? ???????? ???????????????? ???????????? ?????????? ????????????????\r\n3. ???????????????????? ???????????????? ?????????????? ???? ?????????? ?????????? ?????? ????????????????\r\n-. ???????? ???????????????? ?????????????? ????????????.\r\n\r\n1. ???????? ???????????? ?????????? ?????? ?????? ?????????????? ???? ?????? -\r\n???? ?????????????? ?? ???? ??????????????????????????.\r\n???????? ???????????? ???????????????? ?? ?????? ?????? ???????? ?????????? -\r\n???????????? ???????????????? ????????????.\r\n\r\n2. ???? ???????? ?????????????????? ?????????? ?????????? ?? ?????????? ??????????????,\r\n(!???????? ???????? ?????? ?????? ?????????????? ?????????? ?????????? ????????!)\r\n???????? ?????? ???? ???????????????? ???? ??????, ???????????? ??????.\r\n?? ?????? ???????????????????????? ???? ???????? ?????????????? ?????????????? -\r\n???????????????????????? ?????????????? ?????? ?????????? ???????? ???????????????? -\r\n?????????????????????????? ???????????? ????????????, ?????????? ????????????????????.\r\n\r\n3. ???????????????????? ?? ?? ???????? ?????????????????? ???????????????? ?????????????? -\r\n???????? ?????????? ??????????! ?????????? ???????? ???? ???????????? ?? ?????? ???????????? -\r\n???????? ?????????????? ?????? ???? ????????????????.\r\n???????????? ????????????: \"??????????.\" - ?????? ???? ???????????? ???????????? ???? ???????????? ?????????????????\r\n?????????????? ????????????: \"???????????????????????? ?????????????????????? ???????????????? ??????????.\" -\r\n?? ?????? ?????? ?????? ?????????? ?????????????? ?? ?????? ????????????.\r\n?????? ???????? ?????? ?????????????? ?????? ????????, ?????????? ?????? ???? ?????????? -\r\n???????? ??????????, ?????? ??????????????_???????? ?????? ?????? ?????? ????????????????,\r\n?????? ????????, ?? ?????? ?????????? ???????? ???????????? ???? ???????????????????? ?? -\r\n???????????? ?????????????? ?????????????? ????????????. ?????????? ???????????????? ???? ?????????? ????????????????????, ???? -\r\n???????????????? ???????????? ???????????? ?? ?????? ????????????, ?????? ?????????? ???????????????????? ?????????????? ????????????.\r\n-->\r\n\r\n#### ?????????????????? ???????????????? ????????????????\r\n???????? ?????????? ???????????????????????? Blackout ???????????? ??????????????\r\n#### ?????? ???????????? ???????? ??????????????????\r\n?????????????? ???????? ???? ?????????? ???????????????????????? ???????? ????????????\r\n#### ?????? ?????????????????? ???? ?????????? ????????\r\n?????????????? ????????????????\r\n#### ?????? ??????????????????\r\n???????????????????????? ?????????????? ???????????? ??????????????\r\n#### ???????????????????????????? ????????????????????:\r\n\r\n\r\n<bountysource-plugin>\r\n\r\n---\r\nWant to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/54183829-?utm_campaign=plugin&utm_content=tracker%2F34704297&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F34704297&utm_medium=issues&utm_source=github).\r\n</bountysource-plugin>",
      "updatedAt" : 1752238524.000000000,
      "user" : "WallShrabnic",
      "userHtmlUrl" : "https://github.com/WallShrabnic",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19407748?v=4",
      "labels" : [ "Good First Issue", "Low priority", "Bug" ],
      "state" : "OPEN",
      "comments" : [ "???????? ???????? ???????????? ???????????????? ?????????? ????????????????. ????????????????????, ????????????????, ???????????????? ???? ???? ???????????????????? ?????? ?????????????? ???????????? ???????????\n", "??????????????????.\n\n<img width=\"202\" height=\"50\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/67a85cfa-a6fc-46d5-96e2-3d0286d14400\" />\n\n???????? ?????????????????????? ?????????????????????????? ???? ?????????? ????????????.\n<img width=\"524\" height=\"528\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f4910324-9350-4c6e-9a94-b75ff501d167\" />\n\n?????????????? Chernika Sunset ?? Snacks Man ???? ????????????!", "???????? ???? ???????????? ???????????? ?????? ??????????????, ?????????????? ????." ],
      "repository" : {
        "description" : "???????????????????????? ??????",
        "homepage" : null,
        "name" : "TauCetiClassic",
        "fullName" : "TauCetiStation/TauCetiClassic",
        "htmlUrl" : "https://github.com/TauCetiStation/TauCetiClassic",
        "gitUrl" : "git://github.com/TauCetiStation/TauCetiClassic.git",
        "sshUrl" : "git@github.com:TauCetiStation/TauCetiClassic.git",
        "cloneUrl" : "https://github.com/TauCetiStation/TauCetiClassic.git",
        "owner" : {
          "login" : "TauCetiStation",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 427,
        "stargazersCount" : 148,
        "watchersCount" : 148,
        "size" : 1110914,
        "openIssuesCount" : 1572,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-05T12:37:41Z",
        "languages" : {
          "C#" : 11504,
          "PowerShell" : 4157,
          "Java" : 62113,
          "CSS" : 51228,
          "C++" : 9423,
          "DM" : 16714091,
          "HTML" : 44956,
          "Groovy" : 4957,
          "TypeScript" : 88187,
          "Shell" : 21616,
          "Batchfile" : 1669,
          "Awk" : 752,
          "SCSS" : 115869,
          "JavaScript" : 622686,
          "Python" : 22649
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the bug where Malf can use Blackout even when he is dead.",
      "validationOrRequirement" : "The issue is labeled as a 'Good First Issue' and has a low priority.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is about a bug where Malf can use Blackout even when he is dead.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283967
  }, {
    "issueDTO" : {
      "id" : 278781520,
      "title" : "???????????? ???????????????? ???????????????? ???????????? ?????????????? ???? ???????????? ????????????????????",
      "url" : "https://github.com/TauCetiStation/TauCetiClassic/issues/2038",
      "repositoryName" : "TauCetiStation/TauCetiClassic",
      "description" : "<!-- \r\n??????????: ???????? ?????? ???????? ???????????????? ???? ???????????????? ?? ????????, ?? ???????????????????????? ?????? ????????-????????, ???? ?????????????????????? ???????????????? ?? ???????????????? ?????? [Proposal]\r\n\r\n\r\n1. ???????????? ?????????????????? ?????? ?????????????????????????????? ??????????????????\r\n(?????? ?? ?????????? ????????, ?????????? ???????? ????????????)\r\n2. ?? ?????????? ?????????????? ???????????? ???????? ???????????????? ???????????? ?????????? ????????????????\r\n3. ???????????????????? ???????????????? ?????????????? ???? ?????????? ?????????? ?????? ????????????????\r\n-. ???????? ???????????????? ?????????????? ????????????.\r\n\r\n1. ???????? ???????????? ?????????? ?????? ?????? ?????????????? ???? ?????? -\r\n???? ?????????????? ?? ???? ??????????????????????????.\r\n???????? ???????????? ???????????????? ?? ?????? ?????? ???????? ?????????? -\r\n???????????? ???????????????? ????????????.\r\n\r\n2. ???? ???????? ?????????????????? ?????????? ?????????? ?? ?????????? ??????????????,\r\n(!???????? ???????? ?????? ?????? ?????????????? ?????????? ?????????? ????????!)\r\n???????? ?????? ???? ???????????????? ???? ??????, ???????????? ??????.\r\n?? ?????? ???????????????????????? ???? ???????? ?????????????? ?????????????? -\r\n???????????????????????? ?????????????? ?????? ?????????? ???????? ???????????????? -\r\n?????????????????????????? ???????????? ????????????, ?????????? ????????????????????.\r\n\r\n3. ???????????????????? ?? ?? ???????? ?????????????????? ???????????????? ?????????????? -\r\n???????? ?????????? ??????????! ?????????? ???????? ???? ???????????? ?? ?????? ???????????? -\r\n???????? ?????????????? ?????? ???? ????????????????.\r\n???????????? ????????????: \"??????????.\" - ?????? ???? ???????????? ???????????? ???? ???????????? ?????????????????\r\n?????????????? ????????????: \"???????????????????????? ?????????????????????? ???????????????? ??????????.\" -\r\n?? ?????? ?????? ?????? ?????????? ?????????????? ?? ?????? ????????????.\r\n?????? ???????? ?????? ?????????????? ?????? ????????, ?????????? ?????? ???? ?????????? -\r\n???????? ??????????, ?????? ??????????????_???????? ?????? ?????? ?????? ????????????????,\r\n?????? ????????, ?? ?????? ?????????? ???????? ???????????? ???? ???????????????????? ?? -\r\n???????????? ?????????????? ?????????????? ????????????. ?????????? ???????????????? ???? ?????????? ????????????????????, ???? -\r\n???????????????? ???????????? ???????????? ?? ?????? ????????????, ?????? ?????????? ???????????????????? ?????????????? ????????????.\r\n-->\r\n\r\n#### ?????????????????? ???????????????? ????????????????\r\n???????? ???? ?????????????? Commands ???????????? Threaten to push, ???? ?????????? ?????????????? ???? ???????????????????? ?????????????? ????????????. ???????? ?????????? ????????????. ???????? ???????? ?????????????????? ????????????????\r\n\r\n#### ?????? ???????????? ???????? ??????????????????\r\n???????????? ???????? ?????????????????????? ???????????????? ?????? ????????????????\r\n\r\n#### ?????? ?????????????????? ???? ?????????? ????????\r\n?? ?????? ???????????????????? ?????????? \"%username% ???????????? ???????????? ???????? ???????????? ???????????????????? ???????????? ????????????\"\r\n\r\n#### ?????? ??????????????????\r\n?????????? ?????????????????? ?? ???????????? Threaten to push\r\n\r\n#### ???????????????????????????? ????????????????????:\r\n\r\n\r\n<bountysource-plugin>\r\n\r\n---\r\nWant to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/52262761-?utm_campaign=plugin&utm_content=tracker%2F34704297&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F34704297&utm_medium=issues&utm_source=github).\r\n</bountysource-plugin>",
      "updatedAt" : 1752238433.000000000,
      "user" : "Sakuya-Izayoi",
      "userHtmlUrl" : "https://github.com/Sakuya-Izayoi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30875884?v=4",
      "labels" : [ "Good First Issue", "Bug" ],
      "state" : "OPEN",
      "comments" : [ "???????? ???????? ???????????? ???????????????? ?????????? ????????????????. ????????????????????, ????????????????, ???????????????? ???? ???? ???????????????????? ?????? ?????????????? ???????????? ???????????\n", "??????????????????????.\n\n???????????????????? \"remote signaling device\" ???? ???????????????? ?????? ??????.\n<img width=\"565\" height=\"143\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/95faf663-c31c-4c89-902e-9cfd39adb4f3\" />", "@fukkatsumichanpewpew ?? ?????????? ?????????????????????? ???? ?????? ??????-???? ?????? ??????????????????? ???????? ???????????? ?? ???????????? ?????? ?????????? ?????????????????", "> [@fukkatsumichanpewpew](https://github.com/fukkatsumichanpewpew) ?? ?????????? ?????????????????????? ???? ?????? ??????-???? ?????? ??????????????????? ???????? ???????????? ?? ???????????? ?????? ?????????? ?????????????????\n\n????????????????????.", "?? ???????????????? ????????????????. ?? ?????????????? ??????.\n\n<img width=\"562\" height=\"158\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b3de730a-e4d8-4c6b-b960-5fbe5a2de9cd\" />", "?????????? ??????????, ?????? ???????????? ??????????????????. ???? ???????????????? ???? ????????????????, ?????????????????? ???? ?????????????????? ?? ??????????. ???? ?? ???????????? ???? ?????????????? ??????????????, ?????? ???????? ???????? ???????????? ???????????? ?? ??????????- ???????????? ???????????????? ???????? ?????????????? ?????? ?????? ??????-???? ?????????? ?????????????????????? ?????????????? ???????????? ????????????????????????????." ],
      "repository" : {
        "description" : "???????????????????????? ??????",
        "homepage" : null,
        "name" : "TauCetiClassic",
        "fullName" : "TauCetiStation/TauCetiClassic",
        "htmlUrl" : "https://github.com/TauCetiStation/TauCetiClassic",
        "gitUrl" : "git://github.com/TauCetiStation/TauCetiClassic.git",
        "sshUrl" : "git@github.com:TauCetiStation/TauCetiClassic.git",
        "cloneUrl" : "https://github.com/TauCetiStation/TauCetiClassic.git",
        "owner" : {
          "login" : "TauCetiStation",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 427,
        "stargazersCount" : 148,
        "watchersCount" : 148,
        "size" : 1110914,
        "openIssuesCount" : 1572,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-05T12:37:41Z",
        "languages" : {
          "C#" : 11504,
          "PowerShell" : 4157,
          "Java" : 62113,
          "CSS" : 51228,
          "C++" : 9423,
          "DM" : 16714091,
          "HTML" : 44956,
          "Groovy" : 4957,
          "TypeScript" : 88187,
          "Shell" : 21616,
          "Batchfile" : 1669,
          "Awk" : 752,
          "SCSS" : 115869,
          "JavaScript" : 622686,
          "Python" : 22649
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to allow the player to cancel the action of threatening to push the button.",
      "validationOrRequirement" : "The issue should be reproducible by taking the signaling device and clicking the Threaten to push button.",
      "attemptedFixes" : "No specific attempts or blockers are mentioned in the comments.",
      "otherNotes" : "The issue is related to the remote signaling device not working outside of hands, and the author is unsure what the device is supposed to do.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283971
  }, {
    "issueDTO" : {
      "id" : 3222263090,
      "title" : "Remove version dependency for typing_extensions",
      "url" : "https://github.com/beetbox/beets/issues/5869",
      "repositoryName" : "beetbox/beets",
      "description" : "Currently, we only install the `typing_extensions` package for Python versions `< 3.11`. This has caused some issues, for example #5695. Additionally, we rely on conditional version checks like:\n\n```python\nif sys.version_info < (3, 11):\n    from typing_extensions import ...\nelse:\n    from typing import ...\n```\n\nWe should eliminate these version checks and consistently use `typing_extensions` regardless of the python version. This simplifies the codebase and avoids subtle bugs caused by discrepancies between `typing` and `typing_extensions`.\n\nMoreover, using typing_extensions unconditionally would allow us to adopt newer typing features available in Python >=3.11 without adding complexity.",
      "updatedAt" : 1752238352.000000000,
      "user" : "semohr",
      "userHtmlUrl" : "https://github.com/semohr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/39738318?v=4",
      "labels" : [ "typehints", "good first issue", "refactor", "dependencies" ],
      "state" : "OPEN",
      "comments" : [ "Part of why we have this is https://github.com/beetbox/beets/pull/5331: Apparently someone maintaining this downstream prefers not to ship `typing_extensions`.\n\nI don't have a strong opinion here, but I'd lean towards simplifying this on our end (I don't think we test that we're actually consistently using such version checks, i.e. we're likely to regress in this regard) and have people patch it out if it's really an issue for them.", "We already started using 3.13 typing features. This has not caused issues yet but in theory would need a typing_extension import even for python>3.11. No idea why this wasn't an issue yet.\n\nE.g. default values for typevars are introduced in 3.13 and backported with typing_extension. In our code [here](https://github.com/beetbox/beets/blob/24dd40eed213bde14341e8c994466b29bf71de0e/beets/dbcore/db.py#L51C1-L52C52), typing ref [here](https://docs.python.org/3/library/typing.html#typing.TypeVar.__default__)." ],
      "repository" : {
        "description" : "music library manager and MusicBrainz tagger",
        "homepage" : "http://beets.io/",
        "name" : "beets",
        "fullName" : "beetbox/beets",
        "htmlUrl" : "https://github.com/beetbox/beets",
        "gitUrl" : "git://github.com/beetbox/beets.git",
        "sshUrl" : "git@github.com:beetbox/beets.git",
        "cloneUrl" : "https://github.com/beetbox/beets.git",
        "owner" : {
          "login" : "beetbox",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : false,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1889,
        "stargazersCount" : 13603,
        "watchersCount" : 13603,
        "size" : 29134,
        "openIssuesCount" : 683,
        "subscribersCount" : 401,
        "pushedAt" : "2025-07-10T09:32:43Z",
        "languages" : {
          "Shell" : 8289,
          "CSS" : 2951,
          "JavaScript" : 86763,
          "HTML" : 3306,
          "Python" : 2313294
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to simplify the codebase and avoid subtle bugs caused by discrepancies between typing and typing_extensions by removing version checks and using typing_extensions unconditionally.",
      "validationOrRequirement" : "The requirement is to remove version dependency for typing_extensions and consistently use it regardless of the python version.",
      "attemptedFixes" : "The current solution is to simplify the codebase and consistently use typing_extensions regardless of the python version, which would allow adopting newer typing features available in Python >=3.11 without adding complexity.",
      "otherNotes" : "The issue is related to a pull request #5331 and has been discussed in the comments. The main concern is that someone maintaining a downstream project prefers not to ship typing_extensions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283976
  }, {
    "issueDTO" : {
      "id" : 3220543871,
      "title" : "Convert Images into Meshery Design.",
      "url" : "https://github.com/layer5io/docs/issues/647",
      "repositoryName" : "layer5io/docs",
      "description" : "#### Current Behavior\n\n<img width=\"957\" height=\"575\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/adfb8429-51bb-4440-b7fa-2fdafa5bea85\" />\n\n#### Desired Behavior\n<!-- A brief description of the enhancement. -->\n\n#### Implementation\n<!-- [Optional] Specifics on the approach to fulfilling the feature request. -->\n\n#### Acceptance Tests\n<!-- [Optional] Stipulations of functional behavior or non-functional items that must be in-place in order for the issue to be closed. -->\n\n#### Mockups\n<!-- [Optional] Any visual diagrams of the desired user interface. -->\n\n---\n\n#### Contributor Guide and Resources\n- \uD83D\uDCDA [Instructions for contributing to documentation](https://github.com/layer5io/docs/blob/master/CONTRIBUTING.md)\n   - Layer5 documentation [site](https://docs.layer5.io) and [source](https://github.com/layer5io/docs/)\n- \uD83C\uDFA8 Wireframes and [designs for Layer5 site](https://www.figma.com/file/5ZwEkSJwUPitURD59YHMEN/Layer5-Designs) in Figma [(open invite)](https://www.figma.com/team_invite/redeem/qJy1c95qirjgWQODApilR9)\n- \uD83D\uDE4B\uD83C\uDFFE\uD83D\uDE4B\uD83C\uDFFC Questions: [Layer5 Discussion Forum](https://discuss.layer5.io) and [Layer5 Community Slack](http://slack.layer5.io)\n",
      "updatedAt" : 1752237624.000000000,
      "user" : "vr-varad",
      "userHtmlUrl" : "https://github.com/vr-varad",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/114755221?v=4",
      "labels" : [ "framework/hugo", "language/javascript", "language/html", "kind/enhancement", "help wanted", "language/css", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @vr-varad, here is the link to the design: https://playground.meshery.io/extension/meshmap?mode=design&design=dbfb44b7-5d93-4dc8-9ca7-8396dd0ecb9b", "Thanks @bakayu " ],
      "repository" : {
        "description" : "Documentation and Developer resources for Layer5 products",
        "homepage" : "https://docs.layer5.io",
        "name" : "docs",
        "fullName" : "layer5io/docs",
        "htmlUrl" : "https://github.com/layer5io/docs",
        "gitUrl" : "git://github.com/layer5io/docs.git",
        "sshUrl" : "git@github.com:layer5io/docs.git",
        "cloneUrl" : "https://github.com/layer5io/docs.git",
        "owner" : {
          "login" : "layer5io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 121,
        "stargazersCount" : 60,
        "watchersCount" : 60,
        "size" : 329333,
        "openIssuesCount" : 74,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-11T17:07:59Z",
        "languages" : {
          "Dockerfile" : 2365,
          "SCSS" : 85700,
          "Makefile" : 1397,
          "JavaScript" : 12196497,
          "HTML" : 93998
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to convert images into Meshery Design, with provided mockups and wireframes available in Figma.",
      "validationOrRequirement" : "Validation or requirements mentioned include: converting images into Meshery Design, with optional specifics on the approach to fulfilling the feature request and stipulations of functional behavior or non-functional items that must be in-place for the issue to be closed.",
      "attemptedFixes" : "No specific attempted fixes or blockers mentioned in the issue description or comments.",
      "otherNotes" : "The issue involves converting images into Meshery Design, with provided mockups and wireframes available in Figma. Contributor guide and resources include instructions for contributing to documentation, Layer5 documentation site and source, and links to Layer5 Discussion Forum and Community Slack.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283981
  }, {
    "issueDTO" : {
      "id" : 2784035422,
      "title" : "[Slash] [UX] - Modal Component",
      "url" : "https://github.com/AxaFrance/design-system/issues/740",
      "repositoryName" : "AxaFrance/design-system",
      "description" : "### Nom : Modal\n\nType : Organisme\n\n---\n\n### Objectif : \n\nModification css du composant\nCr??ation de variant : \n\n- \"popin-action\"\n- \"popin-information\"\n\n??? Utilisation de l'atom [Icon]\n??? Utilisation de la molecule [Button]\n\n\n---\n### Popin-action :\nActual version : https://axafrance.github.io/design-system/slash/css/latest/?path=/story/components-modal--default\n![image](https://github.com/user-attachments/assets/959fa94d-d67c-4f4b-abfb-f305d5b87dc8)\n\nDesign version : https://6ssje8.axshare.com/?code=6172ed7cc6f5e951da863b1b2d54378c&id=ma4eqp&p=popin&c=1\n\n![Image](https://github.com/user-attachments/assets/4c11b407-70c9-4a21-baa8-13117ce69eb8)\n\n**Description :** \n\n??? ??? At the opening of the modal, focus should be on the close icon. ??? ??? \n\nBackdrop : \nbackgroung-color : --black 80%\nOn click -> close the modal\n\n![Image](https://github.com/user-attachments/assets/d2b6a388-b999-40c3-9dff-b3e40cf7d3c3)\n\nContainer : \nBorder 1px \ncolor : #CCCCCC\nmin-width : 460px\n\nTitle : \nmargin-left : 24px\nfont-family : source sans pro\nfont-weight : semibold\ncolor : #333333\nfont-size 22px\n\nClose icon : \nUtiliser l'atom [Icon]\nmargin-right 24px\n\nDivider : \nmargin-top : 8px\nmargin-bottom : 12px\nSize 1px \ncolor : #CCCCCC\n\nText : \nmargin-left : 24px\nmargin-right : 24px\nmargin-bottom : 40px\n\nCTAs : \nUtiliser la mol??cule [Button]\nCTA Secondary on bottom-left-corner\nCTA Primary on bottom-right-corner\n\nSecondary : \nmargin-left : 24px\nmargin-bottom : 24px\n\nPrimary : \nPrimary button could be : success / default / error\nmargin-right : 24px\nmargin-bottom : 24px\n\n\n\n\n---\n\n### Popin-information :\nDesign version : https://6ssje8.axshare.com/?code=6172ed7cc6f5e951da863b1b2d54378c&id=0m2eml&p=popin_-_information&g=1\n\n![Image](https://github.com/user-attachments/assets/023544c5-cad6-4924-89ad-f94b146cfc3a)\n\n**Description :** \nCTAs : \nUtiliser la mol??cule [Button]\nCTA Secondary on bottom-right-corner",
      "updatedAt" : 1752237438.000000000,
      "user" : "adrien-dos",
      "userHtmlUrl" : "https://github.com/adrien-dos",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/154349821?v=4",
      "labels" : [ "component", "ux", "design", "agent-slash", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Specs Padding : \n\n![Image](https://github.com/user-attachments/assets/97e8ac2c-da85-4fc3-851f-4ff13d664324)" ],
      "repository" : {
        "description" : "CSS & React implementation of AXA's design systems",
        "homepage" : "",
        "name" : "design-system",
        "fullName" : "AxaFrance/design-system",
        "htmlUrl" : "https://github.com/AxaFrance/design-system",
        "gitUrl" : "git://github.com/AxaFrance/design-system.git",
        "sshUrl" : "git@github.com:AxaFrance/design-system.git",
        "cloneUrl" : "https://github.com/AxaFrance/design-system.git",
        "owner" : {
          "login" : "AxaFrance",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 82,
        "stargazersCount" : 26,
        "watchersCount" : 26,
        "size" : 33441,
        "openIssuesCount" : 163,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-11T14:52:55Z",
        "languages" : {
          "TypeScript" : 940026,
          "MDX" : 162557,
          "CSS" : 12675,
          "SCSS" : 367599,
          "JavaScript" : 23330,
          "HTML" : 475
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Modification css du composant, Cr??ation de variant, Cr??ation de design pour les popins \"popin-action\" et \"popin-information\"",
      "validationOrRequirement" : "Utilisation de l'atom [Icon], Utilisation de la molecule [Button], Cr??ation de variant : \"popin-action\" et \"popin-information\"",
      "attemptedFixes" : "",
      "otherNotes" : "Specs Padding : ![Image](https://github.com/user-attachments/assets/97e8ac2c-da85-4fc3-851f-4ff13d664324)",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283985
  }, {
    "issueDTO" : {
      "id" : 2920623380,
      "title" : "[SLASH] [UX] - Stepper horizontal (train d'??tape)",
      "url" : "https://github.com/AxaFrance/design-system/issues/969",
      "repositoryName" : "AxaFrance/design-system",
      "description" : "### Nom : Stepper\n\n**Objectif :** \n- Cr??ation de l'atom [Step]\n- Modification CSS du composant [Stepper] : https://axafrance.github.io/react-toolkit/latest/storybook/?path=/story/form-elements-steps--new-steps-story\n\n---\n\n**Version actuelle :** \n\n![Image](https://github.com/user-attachments/assets/b60e3dd7-531c-4658-8d4b-97d2cf693b26)\nhttps://axafrance.github.io/react-toolkit/latest/storybook/?path=/story/form-elements-steps--new-steps-story\n\n---\n\n### Atom Step\n\n**Done step :**\n\n![Image](https://github.com/user-attachments/assets/a37440ab-be33-487d-b5bd-06112ce71790)\n\nhttps://6ssje8.axshare.com/?code=6172ed7cc6f5e951da863b1b2d54378c&id=4cdoym&p=train_etape___horizontal&sc=3&g=15\n\n**Taille en rouge \nPadding en bleu\nMargin en rose**\n\n??? ajouter un padding de 40px pour centrer le nom de l'??tape sans prendre en consid??ration l'icone. \n\nStep number : \nFont : Source sans pro, semibold, 22px #333333 (--gray-80)\n\nStep name : \nFont : Source sans pro, semibold, 18px #333333 (--gray-80)\n\nIcone : \n- icon material -> arrow_forward_ios\n- color : #333333 (--gray-80)\n\n\n---\n\n**Etats :** \n\n![Image](https://github.com/user-attachments/assets/c4a42100-8203-47b0-a534-88174fab0246)\n\n**Active step :** \n\nStep number : \nFont : Source sans pro, semibold, 22px #00008F(--axablue-80)\n\nStep name : \nFont : Source sans pro, semibold, 18px #00008F(--axablue-80)\n\nIcone : \n- color : #00008F(--axablue-80)\n\n**Disabled Step :** \n\nStep number : \nFont : Source sans pro, semibold, 22px #CCCCCC (--gray-40)\n\nStep name : \nFont : Source sans pro, semibold, 18px #CCCCCC (--gray-40)\n\nIcone : \n- color : #CCCCCC (--gray-40)\n\n**Finale step - Disabled :** \n\nStep name : \nFont : Source sans pro, semibold, 18px #CCCCCC (--gray-40)\n\nIcone : \n- color : #CCCCCC (--gray-40)\n\n**Finale step - Active :** \n\nStep name : \nFont : Source sans pro, semibold, 18px #0C7D3B(--green-40)\n\nIcone : \n- color :  #0C7D3B(--green-40)\n\n--- \n### Stepper\n\n![Image](https://github.com/user-attachments/assets/840478cd-2580-410f-bd49-b3c572465738)\nhttps://6ssje8.axshare.com/?code=6172ed7cc6f5e951da863b1b2d54378c&id=j43xdd&p=train_etape___fond___horizontal&sc=3&g=15\n\nStepper : \nWidth : 100%\nBorder-bottom : 1px #CCCCCC (--gray-40) inside\n\nLa taille des ??tapes doit s'adapter ?? la taille totale du composant Stepper. \n\n",
      "updatedAt" : 1752237418.000000000,
      "user" : "Murphy-UX",
      "userHtmlUrl" : "https://github.com/Murphy-UX",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/198597559?v=4",
      "labels" : [ "ux", "agent-slash", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Je prends" ],
      "repository" : {
        "description" : "CSS & React implementation of AXA's design systems",
        "homepage" : "",
        "name" : "design-system",
        "fullName" : "AxaFrance/design-system",
        "htmlUrl" : "https://github.com/AxaFrance/design-system",
        "gitUrl" : "git://github.com/AxaFrance/design-system.git",
        "sshUrl" : "git@github.com:AxaFrance/design-system.git",
        "cloneUrl" : "https://github.com/AxaFrance/design-system.git",
        "owner" : {
          "login" : "AxaFrance",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 82,
        "stargazersCount" : 26,
        "watchersCount" : 26,
        "size" : 33441,
        "openIssuesCount" : 163,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-11T14:52:55Z",
        "languages" : {
          "TypeScript" : 940026,
          "MDX" : 162557,
          "CSS" : 12675,
          "SCSS" : 367599,
          "JavaScript" : 23330,
          "HTML" : 475
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create an atom called Step, modify the CSS of the Stepper component, and add a padding of 40px to center the step name without considering the icon.",
      "validationOrRequirement" : "The step number font should be Source sans pro, semibold, 22px #333333 (--gray-80), step name font should be Source sans pro, semibold, 18px #333333 (--gray-80), and icon color should be #333333 (--gray-80). The step size should adapt to the total size of the Stepper component.",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is about creating an atom called Step, modifying the CSS of the Stepper component, and adding a padding of 40px to center the step name without considering the icon. It also involves defining the states of the step, including active, disabled, and final states.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752283991
  }, {
    "issueDTO" : {
      "id" : 1518780831,
      "title" : "[discussion] Analyzing a list of tensors stored as intermediate values / saved_for_backward in autograd graph",
      "url" : "https://github.com/pytorch/pytorch/issues/91692",
      "repositoryName" : "pytorch/pytorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\r\n\r\nIt's useful for understanding memory usage and if memory can be saved by refatoring to fusion + inplace\r\n\r\nThe parent issue would be https://github.com/pytorch/pytorch/issues/1529, here's the scope is only on stored intermediate values in autograd graph.\r\n\r\nBut overall, being able to get a list of all tensors and storages currently allocated (including from C++) is very useful for simple form of memory profiling (even ignoring possible memory overlaps / views etc)\r\n\r\nE.g. it would be interesting to compare theses lists for vanilla fp32 TransformerEncoder, autocast+bf16 TransformerEncoder, autocast+fp16 TransformerEncoder, BetterTransformer / efficient_attention / flash_attention variants of TransformerEncoder. This utility should also clearly demonstrate the effect of activation checkpointing / CPU offloading techniques; Reversible Transformers / Reversible ConvNets and would be very useful for pedagogical use and debugging\r\n\r\nSome previous discussion: https://discuss.pytorch.org/t/memory-size-of-all-tensors-referenced-by-autograd-graph/169227/4\r\n\r\n### Alternatives\r\n\r\n_No response_\r\n\r\n### Additional context\r\n\r\n_No response_\n\ncc @ezyang @albanD @zou3519 @gqchen @pearu @nikitaved @soulitzer @Lezcano @Varal7",
      "updatedAt" : 1752237407.000000000,
      "user" : "vadimkantorov",
      "userHtmlUrl" : "https://github.com/vadimkantorov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1041752?v=4",
      "labels" : [ "triaged", "module: autograd", "actionable", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "It should be possible to implement this with saved tensor hooks: https://pytorch.org/tutorials/intermediate/autograd_saved_tensors_hooks_tutorial.html.", "Interesting. Does it also include tensors saved_for_backward from C++, right?", "cc @zdevito ", "Even without the hooks, if you have the loss, you can just traverse the graph and look for the `_saved_*` attributes similarly to how we do it for torchviz visualization:\r\nhttps://github.com/szagoruyko/pytorchviz/blob/0adcd83af8aa7ab36d6afd139cabbd9df598edb7/torchviz/dot.py#L102-L117", "Oh, that's very cool. Does it also include any tensors  saved-for-backward from C++ (if that exists at all?)?\r\n\r\nIn general, I think, it's worth including such a function in stock pytorch under some torch.testing or torch.profiling as it's a very direct demonstration of what's taking memory", "> Does it also include any tensors saved-for-backward from C++ (if that exists at all?)?\r\n\r\nYes it includes everything stored in the graph!\r\n\r\nYes, @soulitzer is also fleshing out the autograd graph doc. Maybe that would be a good place to share this code sample?", "probably assigning some readable names to these intermediate tensors would be a challenge, but even without them, it should be very useful for simple memory profiling as stored activations probably often dominate the used memory!", "> probably assigning some readable names to these intermediate tensors would be a challenge\r\n\r\nIf you're ready to use anomaly mode / build a custom Mode / use Module global hooks, you can easily know either the Module or the line of code where the Tensor comes from or the line of code where it was saved tbh.", "might be a bit related to memory-debugging utils theme by @zdevito \r\n\r\nespecially for demonstrating visually how activation checkpointing / reversible transformers work in terms of memory allocation", "Hi! I'm interested in working on this issue. Could you provide more guidance on the preferred approach for implementing the autograd graph analysis?", "@zdevito @albanD a question might be if DTensor / TP adds something to these saved_for_backward tensors or activations? Basically trying to debug OOM in FSDP set-up... Ideally, these snapshots should illustrate well how CPU-offloading works. Would it be possible to fetch from the autograd graph CPU-offloaded tensors?\n\nIt would be great for PyTorch to be able to give the user a categorized snapshot of allocated tensors / workspace buffers (and of python gc-freed, but not gc-collected yet)... Ideally without having to enable the profiler upfront", "Also, the categorized plot from memory profiler is non-interactive - only a raster image, so you cannot hover or click to figure out what tensor caused a peak", "@albanD My current draft impl, also sets `__name__` attributes recursively as proposed in:\n- https://github.com/pytorch/pytorch/issues/104247\n\nCertainly name construction can be improved somehow (https://github.com/vadimkantorov/torchlisttensors)\n\n```python\n# References:\n# - https://discuss.python.org/t/list-all-objects-gc-tracked-or-not-of-a-given-type-for-debugging-introspection-and-memory-profiling/98194/5\n# - https://www.mail-archive.com/numpy-discussion@scipy.org/msg46120.html\n# - https://github.com/szagoruyko/pytorchviz/blob/0adcd83af8aa7ab36d6afd139cabbd9df598edb7/torchviz/dot.py#L146\n\nimport gc\nimport sys\n\nimport torch\n\ndef torch_list_tensors(*roots):\n    SAVED_PREFIX = \"_saved_\"\n    seen = set()\n    nodes = {}\n\n    def found_tensor_hook(tensor, name):\n        if id(tensor) not in nodes:\n            nodes[id(tensor)] = name\n\n    def get_var_name(var, name = '', from_var = None):\n        if not name:\n            #name = param_map[id(var)] if id(var) in param_map else ''\n            if hasattr(var, '__name__'):\n                name = var.__name__\n            else:\n                name = '__' + str(id(var)) + '__'\n        return 'shape=({})\\tname={}'.format(','.join(map(str, var.shape)), name)\n\n    def add_nodes(fn, from_var = None):\n        assert not torch.is_tensor(fn)\n        if fn in seen:\n            return\n        seen.add(fn)\n\n        fmtvarname = lambda varname, saved = False: varname + '_{}_{}'.format(type(fn).__name__, from_var) + ('_SAVED' * saved)\n\n        if True:\n            for attr in dir(fn):\n                if not attr.startswith(SAVED_PREFIX):\n                    continue\n                val = getattr(fn, attr)\n                seen.add(val)\n                attr = attr[len(SAVED_PREFIX):]\n                if torch.is_tensor(val):\n                    varname = get_var_name(val, attr, from_var = id(fn) )\n                    found_tensor_hook(val, fmtvarname(varname, saved = True))\n                if isinstance(val, tuple):\n                    for i, t in enumerate(val):\n                        if torch.is_tensor(t):\n                            varname = get_var_name(t, attr + '[{}]'.format(i), from_var = id(fn))\n                            found_tensor_hook(t, fmtvarname(varname, saved = True))\n\n        if hasattr(fn, 'variable'):\n            var = fn.variable\n            seen.add(var)\n            varname = get_var_name(var, from_var = id(fn))\n            found_tensor_hook(var, fmtvarname(varname))\n\n        if hasattr(fn, 'next_functions'):\n            for u in fn.next_functions:\n                if u[0] is not None:\n                    add_nodes(u[0], from_var = id(fn))\n\n        if hasattr(fn, 'saved_tensors'):\n            for t in fn.saved_tensors:\n                seen.add(t)\n                varname = get_var_name(t, from_var = id(fn))\n                found_tensor_hook(t, fmtvarname(varname))\n\n    def add_base_tensor(var):\n        if var in seen:\n            return\n        seen.add(var)\n        found_tensor_hook(var, get_var_name(var))\n        if var.grad_fn:\n            add_nodes(var.grad_fn, from_var = id(var))\n        if var._is_view():\n            add_base_tensor(var._base, from_var = id(var))\n\n    seeds = roots[:]\n    for objs in [gc.get_objects(), sys.getobjects() if hasattr(sys, 'getobjects') else []]:\n        for obj in objs:\n            try:\n                if torch.is_tensor(obj):\n                    tensor = obj\n                elif hasattr(obj, 'data') and torch.is_tensor(obj.data):\n                    tensor = obj.data\n                else:\n                    continue\n                if hasattr(tensor, '__name__'):\n                    found_tensor_hook(tensor, get_var_name(tensor))\n                elif tensor not in seeds:\n                    seeds.append(tensor)\n            except Exception as e:\n                pass\n\n    for tensor in seeds:\n        add_base_tensor(tensor)\n\n    return nodes\n\ndef assign_names(model, name):\n    for __name__, m in model.named_modules(prefix = name):\n        m.__name__ = __name__\n    for __name__, p in model.named_parameters(prefix = name):\n        p.__name__ = __name__\n    for __name__, b in model.named_buffers(prefix = name):\n        b.__name__ = __name__\n    return model\n\nif __name__ == '__main__':\n    model = torch.nn.Sequential(torch.nn.Linear(20, 20), torch.nn.Linear(20, 20), torch.nn.Linear(20, 20))\n    model = assign_names(model, 'model')\n\n    x = torch.zeros(4, 20)\n    x.__name__ = 'x'\n\n    loss = model(x).sum()\n    loss.__name__ = 'loss'\n\n    z = torch.zeros(65, 35)\n    z.__name__ = 'z'\n\n    tensors2 = torch_list_tensors(loss)\n    for i, t in tensors2.items():\n        print(i, '\\t', t)\n```", "@albanD this prints this:\n```\n/home/vadimkantorov/.local/lib/python3.12/site-packages/torch/__init__.py:1028: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n  return isinstance(obj, torch.Tensor)\n/mnt/c/Users/vadim/torchlisttensors/torchlisttensors.py:112: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n  elif hasattr(obj, 'data') and torch.is_tensor(obj.data):\n140022603754192          shape=(20,20)  name=model.0.weight\n140022604499456          shape=(20)     name=model.0.bias\n140022604499376          shape=(20,20)  name=model.1.weight\n140022604499536          shape=(20)     name=model.1.bias\n140022604499696          shape=(20,20)  name=model.2.weight\n140022604499616          shape=(20)     name=model.2.bias\n140022606243040          shape=(4,20)   name=x\n140022604499776          shape=()       name=loss\n140022604500336          shape=(65,35)  name=z\n140022604500256          shape=(4,20)   name=mat1_AddmmBackward0_140021819231392_SAVED\n140022604506656          shape=(20,20)  name=mat2_AddmmBackward0_140021819231392_SAVED\n140022604500176          shape=(4,20)   name=mat1_AddmmBackward0_140021821040880_SAVED\n140022604507136          shape=(20,20)  name=mat2_AddmmBackward0_140021821040880_SAVED\n```\n\nUnfortunately, if I add `del z` or even `gc.disable(); del z`, it would not find `z`, unless `sys.getobjects()` is available (this currently requires a specially built python, bit it's not that hard using pyenv or maybe even uv?).\n\nOverall, it would be extremely useful for memory debugging/introspection to be able to have a built-in PyTorch support for listing all currently alive tensors (including those allocated from C++ and invisible from this graph traversal) - even if without full stack trace attached. Then e.g. these printouts can be analyzed in backward hooks or similar. As opposed to Python (https://discuss.python.org/t/list-all-objects-gc-tracked-or-not-of-a-given-type-for-debugging-introspection-and-memory-profiling/), probably PyTorch can afford to have some tracking of alive tensor objects (at least under an environment variable or runtime option).\n\nAlso, for this goal it would be useful to have `__name__` propagation. Even if PyTorch appends to names the name of the current Python function/nn.Module, it would already be useful. And probably this can be done somehow without full stack trace (might be done with module hooks? some special decorator or context manager providing a name prefix? or certainly when torch.compile is used)", "Also, `hasattr(torch.distributed.reduce_op, 'data')` prints this nasty `FutureWarning`", "Also, a bit interesting divergence of NumPy and PyTorch wrt arrays being gc-tracked:\n```python\nimport gc\n\nimport numpy, torch\n\na = numpy.random.rand(3, 4)\nprint(gc.is_tracked(a))\n# False\n\n#a = torch.random.rand(3, 4) # AttributeError: module 'torch.random' has no attribute 'rand'\na = torch.rand(3, 4)\nprint(gc.is_tracked(a))\n# True\n```\n\nMost NumPy arrays are not gc-tracked, but instead only ref-counted as explained by https://www.mail-archive.com/numpy-discussion@scipy.org/msg46120.html (it appears, for that some slots support is needed) - making `gc.get_objects()` not reporting any NumPy arrays at all, even alive, non-`del`'d ones\n\nI wonder, are all PyTorch tensors always gc-tracked?\n\nAnd also wondering if PyTorch has plans of aligning its random package to NumPy's...", "> Also, `hasattr(torch.distributed.reduce_op, 'data')` prints this nasty `FutureWarning`\n\n@albanD it appears that this warning is quite old: 2022 on SO  https://stackoverflow.com/questions/71205404/pytorch-reduce-op-warning-message-despite-not-calling-it\n\nmaybe worth deleting `torch.distributed.reduce_op` from 2.8.0?", "cc @d4l3k for deleting very old ops?\n\n> I wonder, are all PyTorch tensors always gc-tracked?\n\nYes they are. Because we have a lot of other python objects being kept alive by Tensors and we even allow arbitrary attributes on Tensors. So it will continue to be true for sure.\n\n> And also wondering if PyTorch has plans of aligning its random package to NumPy's...\n\nDo we have an issue for that? Happy to review PRs towards that for sure!" ],
      "repository" : {
        "description" : "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
        "homepage" : "https://pytorch.org",
        "name" : "pytorch",
        "fullName" : "pytorch/pytorch",
        "htmlUrl" : "https://github.com/pytorch/pytorch",
        "gitUrl" : "git://github.com/pytorch/pytorch.git",
        "sshUrl" : "git@github.com:pytorch/pytorch.git",
        "cloneUrl" : "https://github.com/pytorch/pytorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 24655,
        "stargazersCount" : 91465,
        "watchersCount" : 91465,
        "size" : 1080672,
        "openIssuesCount" : 16562,
        "subscribersCount" : 1785,
        "pushedAt" : "2025-07-12T01:02:24Z",
        "languages" : {
          "C" : 1814194,
          "GDB" : 653,
          "CMake" : 829778,
          "Makefile" : 12990,
          "HTML" : 384,
          "Metal" : 312044,
          "Jupyter Notebook" : 186191,
          "Shell" : 475776,
          "JavaScript" : 92859,
          "Objective-C" : 58784,
          "Ruby" : 2774,
          "Assembly" : 336348,
          "Python" : 72951131,
          "GLSL" : 204577,
          "Thrift" : 7013,
          "PowerShell" : 3657,
          "Smarty" : 376,
          "Java" : 87332,
          "C++" : 42265232,
          "Objective-C++" : 1375996,
          "HIP" : 287192,
          "Cuda" : 3659747,
          "Dockerfile" : 34238,
          "Starlark" : 328636,
          "Batchfile" : 80571,
          "Linker Script" : 473,
          "Vim Script" : 154
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to analyze a list of tensors stored as intermediate values/saved_for_backward in the autograd graph, which can be useful for memory profiling and debugging.",
      "validationOrRequirement" : "The issue requires the ability to implement this with saved tensor hooks and traverse the graph to find _saved_* attributes. The author also mentions the need for assigning readable names to intermediate tensors and having a built-in PyTorch support for listing all currently alive tensors.",
      "attemptedFixes" : "The author has provided a draft implementation, which sets __name__ attributes recursively as proposed in https://github.com/pytorch/pytorch/issues/104247. The implementation uses torch_list_tensors function to list all tensors, including those allocated from C++ and invisible from the graph traversal.",
      "otherNotes" : "The issue aims to analyze a list of tensors stored as intermediate values/saved_for_backward in the autograd graph, which can be useful for memory profiling and debugging. It includes discussion on saved tensor hooks, traversing the graph to find _saved_* attributes, and assigning readable names to intermediate tensors. The author also mentions the importance of including this feature in stock PyTorch under torch.testing or torch.profiling.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284000
  }, {
    "issueDTO" : {
      "id" : 2986896767,
      "title" : "add LinkingLion traffic measuring in metrics tool",
      "url" : "https://github.com/0xB10C/peer-observer/issues/142",
      "repositoryName" : "0xB10C/peer-observer",
      "description" : "A small tool to measure the traffic between us and LinkingLion IPs & us and non-LinkingLion IPs would be helpful to find out how much bandwidth LinkingLion uses. Just summing up the bytes is probably enough.\n\nhttps://b10c.me/observations/06-linkinglion/\n\n\nI think gmax meant LinkingLion in his delvingpost https://delvingbitcoin.org/t/bitcoin-node-p2p-traffic-analysis/1490/3:\n\n> There are a number of very long term abusers that are probably wasting a majority of the network???s total non-ibd bandwidth usage on identifiable networks.\n> It might be useful to break out those networks in any further reporting for them because they have different implications. E.g. they won???t benefit from erlay gains??? and probably the only way to mitigate them is to start shipping a list of subnets that are relegated to blocks only by default or similar.\n\nI'm not convinced that LinkingLion has a major impact on node traffic, but happy to stand corrected by empirical results.",
      "updatedAt" : 1752237341.000000000,
      "user" : "0xB10C",
      "userHtmlUrl" : "https://github.com/0xB10C",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19157360?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This is from a bit more than two days:\n\non node bob:\n```\nother download:           2.33GB       upload:     4.76GB      total:     7.10GB\nlinking lion download:    70.86MB      upload:   589.15MB      total:   660.02MB\nlinking lion share: 2.95% up: 11.00% total: 8.51%\n```\n\non node ian:\n```\nother download:     2.38GB      upload:     4.85GB      total:     7.23GB\nlinking lion download:    34.15MB      upload:   348.61MB      total:   382.76MB\nlinking lion share: down: 1.41% up: 6.71% total: 5.03%\n```\n\nSo 5% and 8.5% of the total bandwidth. Since we send INVs and they don't we have a higher upload bandwidth than download.\n\n", "Roughly two weeks:\n\non node bob:\n```\nother download:    18.03GB      upload:    38.32GB      total:    56.35GB\nllion download:   473.48MB      upload:     3.96GB      total:     4.44GB\ndown: 2.56% up: 9.37% t: 7.30%\n```\non node ian:\n```\nother download:    18.65GB      upload:    38.92GB      total:    57.56GB\nllion download:   229.18MB      upload:     2.42GB      total:     2.65GB\ndown: 1.21% up: 5.85% t: 4.40%\n```\n\n7.3% and 4.4% of total bandwidth.\n\n\nStopping the recording for now.", "While the tool from #143 works well, the data collection it should ideally be done as a prometheus metrics in the `metrics` tool." ],
      "repository" : {
        "description" : "Tool to monitor for P2P anomalies and attacks using Bitcoin Core honeynodes",
        "homepage" : "https://public.peer.observer",
        "name" : "peer-observer",
        "fullName" : "0xB10C/peer-observer",
        "htmlUrl" : "https://github.com/0xB10C/peer-observer",
        "gitUrl" : "git://github.com/0xB10C/peer-observer.git",
        "sshUrl" : "git@github.com:0xB10C/peer-observer.git",
        "cloneUrl" : "https://github.com/0xB10C/peer-observer.git",
        "owner" : {
          "login" : "0xB10C",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 29,
        "watchersCount" : 29,
        "size" : 2426,
        "openIssuesCount" : 12,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T14:51:57Z",
        "languages" : {
          "Shell" : 104,
          "C" : 6760286,
          "Rust" : 184190,
          "JavaScript" : 7714,
          "HTML" : 54934,
          "Nix" : 653,
          "Python" : 1532
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add LinkingLion traffic measuring in metrics tool to help find out how much bandwidth LinkingLion uses.",
      "validationOrRequirement" : "The requirement is to measure the traffic between us and LinkingLion IPs & us and non-LinkingLion IPs and to find out how much bandwidth LinkingLion uses. The author wants to sum up the bytes to achieve this.",
      "attemptedFixes" : "The author mentions that the tool from #143 works well, but it should ideally be done as a Prometheus metrics in the `metrics` tool.",
      "otherNotes" : "The issue is about measuring the traffic between us and LinkingLion IPs & us and non-LinkingLion IPs to find out how much bandwidth LinkingLion uses. The author thinks LinkingLion might not have a major impact on node traffic but wants to be corrected by empirical results. There are some data collection examples provided from node bob and node ian, and the author suggests doing data collection as Prometheus metrics in the `metrics` tool.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284007
  }, {
    "issueDTO" : {
      "id" : 3222751815,
      "title" : "Prometheus metric for unsolicited and unannouced transactions in `metrics` tool",
      "url" : "https://github.com/0xB10C/peer-observer/issues/182",
      "repositoryName" : "0xB10C/peer-observer",
      "description" : "Currently, the txrelay.html site of the `websocket` tool keeps track of *unsolicited* (we didn't ask for it with a GETDATA, but got send them anyway) and *unannounced* (we never announced them to the peer, but the peer requested them anyway):\n\nhttps://github.com/0xB10C/peer-observer/blob/07b290b8b7bebe8480fbb444b2ce842a31bad697/tools/websocket/www/txrelay.html#L260-L278\n\n<img width=\"2048\" height=\"1223\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b8b85b17-64ac-464d-bfea-687bdf7c8388\" />\n\n\nSince data is only collected when visiting the website, there is no historical data for this. Adding this to the `metrics` tool could be worthwhile for historical data.\n\nSome implementation notes:\n- need to limit per peer list of recent INVed and GETDATAed to not OOM at some point. This also means potential rare false positives, since the list is already trimmed.\n- remove disconnected peers from the tracking to not OOM\n- keep track of last message received/sent per peer. In-case we somehow miss a peer disconnect, clean it up after a few minutes (e.g 5)\n\n@darosior   ",
      "updatedAt" : 1752237310.000000000,
      "user" : "0xB10C",
      "userHtmlUrl" : "https://github.com/0xB10C",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19157360?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Tool to monitor for P2P anomalies and attacks using Bitcoin Core honeynodes",
        "homepage" : "https://public.peer.observer",
        "name" : "peer-observer",
        "fullName" : "0xB10C/peer-observer",
        "htmlUrl" : "https://github.com/0xB10C/peer-observer",
        "gitUrl" : "git://github.com/0xB10C/peer-observer.git",
        "sshUrl" : "git@github.com:0xB10C/peer-observer.git",
        "cloneUrl" : "https://github.com/0xB10C/peer-observer.git",
        "owner" : {
          "login" : "0xB10C",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 29,
        "watchersCount" : 29,
        "size" : 2426,
        "openIssuesCount" : 12,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T14:51:57Z",
        "languages" : {
          "Shell" : 104,
          "C" : 6760286,
          "Rust" : 184190,
          "JavaScript" : 7714,
          "HTML" : 54934,
          "Nix" : 653,
          "Python" : 1532
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Adding a Prometheus metric for unsolicited and unannounced transactions in the `metrics` tool to collect historical data",
      "validationOrRequirement" : "need to limit per peer list of recent INVed and GETDATAed to not OOM at some point, remove disconnected peers from the tracking to not OOM, keep track of last message received/sent per peer",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "Some implementation notes: need to limit per peer list of recent INVed and GETDATAed to not OOM at some point. This also means potential rare false positives, since the list is already trimmed. Remove disconnected peers from the tracking to not OOM. Keep track of last message received/sent per peer. In-case we somehow miss a peer disconnect, clean it up after a few minutes (e.g 5)",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284013
  }, {
    "issueDTO" : {
      "id" : 3217915943,
      "title" : "[Term Entry] JavaScript Arrays: .flatMap()",
      "url" : "https://github.com/Codecademy/docs/issues/7311",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `.flatMap()` under arrays in JavaScript. The entry should be in `content/javascript/concepts/arrays/terms/flatMap/flatMap.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that show an example of the current entry.\n- An ## Codebyte section that have a compilable code inside it showing the current entry in use. Use ```codebyte/javascript to add compilable code.\n\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752237231.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "claimed", "good first issue", "javascript" ],
      "state" : "OPEN",
      "comments" : [ "Hi \uD83D\uDC4B\uD83C\uDFFB I would like to work on this issue.", "Hey @StuartMosquera You???re assigned \uD83C\uDF89 In addition to the documents linked in the description, please also look at the [Contribution Guide](https://www.codecademy.com/resources/docs/contribution-guide). After creating a PR, the maintainer(s) (with the collaborator label) will add comments/suggestions to address any revisions before approval.\n\nIs this your first contribution to Codecademy Docs? If so, we???re curious to know how you found out about contributing to Docs.", "Thanks, @mamtawardhani :tada:\nActually, it's going to be my second contribution." ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new term entry for the .flatMap() method under arrays in JavaScript, including a description, syntax, example, and codebyte section.",
      "validationOrRequirement" : "The entry should include a description, syntax, example, and codebyte section; refer to the term entry template, content standards, and markdown style guide.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Please refer to the term entry template, content standards, and markdown style guide when working on the PR for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284017
  }, {
    "issueDTO" : {
      "id" : 3209006978,
      "title" : "Prefer `Random.nextInt` over `nextDouble` and truncation/rounding",
      "url" : "https://github.com/openrewrite/rewrite-static-analysis/issues/621",
      "repositoryName" : "openrewrite/rewrite-static-analysis",
      "description" : "## What problem are you trying to solve?\n\nPerformance and possibly numeric accuracy of randomness too.\n\nIt's suboptimal to call `Random.nextDouble` (or friends) only to cast it to an integer (via truncation or rounding).\n\n## Describe the situation before applying the recipe\n<!-- Ideally as a self-contained code example, as a start to the recipe unit tests. -->\n```java\n(int) (new Random().nextDouble() * 10)\n```\n\nor\n\n```java\n(int) Math.round(new Random().nextDouble() * 10)\n```\n\n## Describe the situation after applying the recipe\n<!-- Ideally as a self-contained code example, as a start to the recipe unit tests. -->\n```java\nnew Random().nextInt(10)\n```\n\n## Any additional context\nThe `new Random()` in these examples are artificial. Typically one would have a re-used `Random` constant.",
      "updatedAt" : 1752237046.000000000,
      "user" : "greg-at-moderne",
      "userHtmlUrl" : "https://github.com/greg-at-moderne",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/192309513?v=4",
      "labels" : [ "recipe", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Also seems like a good candidate for a Refaster style recipe, using variables for the random, but otherwise matching what's described above.", "@rickie would you all be open to something like the following?\n- https://github.com/PicnicSupermarket/error-prone-support/compare/master...timtebeek:error-prone-support:random-rules?expand=1", "@timtebeek yes, I think so! \uD83D\uDE80" ],
      "repository" : {
        "description" : "OpenRewrite recipes for identifying and fixing static analysis issues.",
        "homepage" : "",
        "name" : "rewrite-static-analysis",
        "fullName" : "openrewrite/rewrite-static-analysis",
        "htmlUrl" : "https://github.com/openrewrite/rewrite-static-analysis",
        "gitUrl" : "git://github.com/openrewrite/rewrite-static-analysis.git",
        "sshUrl" : "git@github.com:openrewrite/rewrite-static-analysis.git",
        "cloneUrl" : "https://github.com/openrewrite/rewrite-static-analysis.git",
        "owner" : {
          "login" : "openrewrite",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 82,
        "stargazersCount" : 40,
        "watchersCount" : 40,
        "size" : 4108,
        "openIssuesCount" : 171,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T12:05:28Z",
        "languages" : {
          "Java" : 2504180
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve performance and numeric accuracy of randomness by using Random.nextInt instead of Random.nextDouble with truncation or rounding.",
      "validationOrRequirement" : "Use of Random.nextInt over Random.nextDouble and truncation/rounding is considered suboptimal.",
      "attemptedFixes" : "No specific attempted fixes mentioned in the description.",
      "otherNotes" : "The issue is related to reusing a Random constant, and the Refaster style recipe is suggested.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284020
  }, {
    "issueDTO" : {
      "id" : 3200409864,
      "title" : "Tour appears to be broken on latest stable version",
      "url" : "https://github.com/bluerobotics/BlueOS/issues/3413",
      "repositoryName" : "bluerobotics/BlueOS",
      "description" : null,
      "updatedAt" : 1752236840.000000000,
      "user" : "patrickelectric",
      "userHtmlUrl" : "https://github.com/patrickelectric",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1215497?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The open source platform for ROV, USV, robotic system operation, development, and expansion.",
        "homepage" : "https://blueos.cloud/docs/",
        "name" : "BlueOS",
        "fullName" : "bluerobotics/BlueOS",
        "htmlUrl" : "https://github.com/bluerobotics/BlueOS",
        "gitUrl" : "git://github.com/bluerobotics/BlueOS.git",
        "sshUrl" : "git@github.com:bluerobotics/BlueOS.git",
        "cloneUrl" : "https://github.com/bluerobotics/BlueOS.git",
        "owner" : {
          "login" : "bluerobotics",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 102,
        "stargazersCount" : 260,
        "watchersCount" : 260,
        "size" : 40118,
        "openIssuesCount" : 537,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-11T10:49:37Z",
        "languages" : {
          "TypeScript" : 240785,
          "Dockerfile" : 5228,
          "Shell" : 72273,
          "CSS" : 1820,
          "Vue" : 914193,
          "JavaScript" : 10053,
          "Lua" : 4441,
          "HTML" : 28674,
          "Python" : 747916
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the broken Tour on the latest stable version of BlueOS.",
      "validationOrRequirement" : "none specified",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the BlueOS repository and the author is patrickelectric.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284022
  }, {
    "issueDTO" : {
      "id" : 3055095371,
      "title" : "Feature Request: Add Filtering Options to the Subjects Page",
      "url" : "https://github.com/alphaonelabs/alphaonelabs-education-website/issues/600",
      "repositoryName" : "alphaonelabs/alphaonelabs-education-website",
      "description" : "**Description**\n\nI???d like to propose adding filter functionality to the Subjects page to improve navigation and usability. Currently, all subjects are displayed without any way to narrow down or sort through them.\n\n**Proposed Feature**\n\nIntroduce filters on the Subjects page based on relevant criteria, such as:\n\n- Name\n- Number of interested students\n- level\n- number of courses\n- teacher availability\n- Alphabetical order or recently added\n\n**Before**\n<img width=\"1440\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/44975f65-778d-4a46-8a26-a5565299acf8\" />\n\n**After**\n<img width=\"1150\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/beeb745a-764e-4a83-8818-145ed49f4a09\" />\n",
      "updatedAt" : 1752236687.000000000,
      "user" : "meyyy03",
      "userHtmlUrl" : "https://github.com/meyyy03",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/115250706?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Assign me" ],
      "repository" : {
        "description" : "Alpha One Labs Educational Website",
        "homepage" : "https://alphaonelabs.com",
        "name" : "alphaonelabs-education-website",
        "fullName" : "alphaonelabs/alphaonelabs-education-website",
        "htmlUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website",
        "gitUrl" : "git://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "sshUrl" : "git@github.com:alphaonelabs/alphaonelabs-education-website.git",
        "cloneUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "owner" : {
          "login" : "alphaonelabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 80,
        "stargazersCount" : 23,
        "watchersCount" : 23,
        "size" : 32019,
        "openIssuesCount" : 119,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-11T07:05:39Z",
        "languages" : {
          "Dockerfile" : 1189,
          "Shell" : 49732,
          "Jinja" : 7703,
          "CSS" : 2056,
          "JavaScript" : 105473,
          "HTML" : 1763491,
          "Python" : 1207774
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add filtering options to the Subjects page, including filters based on name, number of interested students, level, number of courses, teacher availability, and alphabetical order or recently added",
      "validationOrRequirement" : "No specific validation or requirement mentioned",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "The issue description includes two images before and after the proposed feature, showing the current and desired state of the Subjects page.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284026
  }, {
    "issueDTO" : {
      "id" : 946770974,
      "title" : "Good first issues & getting started, for new contributors",
      "url" : "https://github.com/sktime/sktime/issues/1147",
      "repositoryName" : "sktime/sktime",
      "description" : "A number of good issues to start working on as a new contributor.\nContributions to documentation are especially appreciated.\n\n### getting started with contributions\n\n1. Say hello [on Discord](https://discord.com/invite/54ACzaFsn7) and get set up for development, see [instructions in the developer guide](https://www.sktime.net/en/stable/developer_guide.html)\n2. Pick a ???good first issue??? to work on, see a collection [in this summary issue](https://github.com/sktime/sktime/issues/1147), or from [this list](https://github.com/sktime/sktime/labels/good%20first%20issue)\nsuggestion: pick something small with simple content to learn the ???process???\n3. Feel free to attend the regular community collab sessions or one of the topic specific stand-ups and tech sessions (see schedule on discord)\n4. Once your first PR is merged and you???ve seen how things work, think about your regular time commitment. Optionally, continue attending the Friday community collaboration sessions and stand-ups; or, optionally, [apply for mentoring](https://github.com/sktime/mentoring/blob/main/README.md)\n\n### introductory and user testing\n\n* work through the [sktime tutorials](https://www.sktime.net/en/latest/tutorials.html) and record feedback, you can post it in this issue #1447\n* work through user testing sheets for [forecasting](https://github.com/sktime/sktime-workshops/blob/main/sktime_worksheet_forecasting.ipynb) or [time series classification](https://github.com/sktime/sktime-workshops/blob/main/sktime_worksheet_TSC.ipynb), record feedback and send us your user testing sheet with code (e.g., attach to this issue)\n* open an issue with a time series related algorithm that you would like to see implemented or interfaced in `sktime`\n* work through the [installation instructions](https://www.sktime.net/en/latest/installation.html) to install a development version of `sktime`. Record carefully things that are unclear or don't work as described, return the full feedback to us (e.g., in an issue).\n\n### contributors new to open source\n\n* current open small tasks with a \"recipe\": https://github.com/sktime/sktime/issues/3429, https://github.com/sktime/sktime/issues/8515\n* documentation: some in-memory formats are missing complete specification documentation. Pick one and add these: https://github.com/sktime/sktime/issues/7386\n* documentation: some estimators are missing examples. Pick a file and start adding these, here is the umbrella issue: https://github.com/sktime/sktime/issues/4264 - these should follow the general documentation style outlined in #1148 or the [extension templates](https://github.com/sktime/sktime/tree/main/extension_templates). If you start, post the name of the estimator you are working on in #1148; when you open a PR, refer to the issue.\n\nNOTE: #1148 is closed, but there are still modules without good docstrings. They are just no longer tracked by the issue, which covered the priority items only. So, feel free to go through the code base and help improve docstrings!\n\n### small-to-medium documentation and technical writing tasks\n\n* an extension templates for time series regression is missing. The current [extension templates](https://github.com/sktime/sktime/tree/main/extension_templates) can be used as a template for writing an extension template.\n* there is a lot of new content in conference presentations and workshops that has not been included in the main tutorials yet! Have a look at the workshops - these are repositories in the github.com/sktime organizations ending in \"tutorial\" or \"workshop\", and find a topic that interests you (e.g., you want to learn about). Then, ping a developer on discord/dev-chat to verify the latest priorities on that topic??s documentation.\n\n### small-to-medium python/coding tasks\n\n* pick a performance metric and implement the `_evaluate_by_index` method, recipe: https://github.com/sktime/sktime/issues/4304\n* pick an unverified bug from the bugfixing board: https://github.com/sktime/sktime/projects/18 and try to reproduce it. Post operating system, python version and (if relevant) package versions, and whether you can yes/no. Investigate further if the bug looks simple - but note that bugs can be anywhere between easy to very difficult to track down.\n* Pick an algorithm to implement or interface, according to the [extension templates](https://github.com/sktime/sktime/tree/main/extension_templates). Possible choices are forecasters (univariate or multivariate), time series classifiers, time series regressors, detectors, distances, kernels - these can be existing feature requests, or new suggestions. We currently do not recommend transformers as they undergo refactoring.\n\n### mid to longer term tasks\n\nFor contributing across a period of weeks or months, consider joining one of the major workstreams and weekly stand-ups on Fridays, or work on a mini-project.\n\nActive workstreams are in the \"workstream\" group of channels, on discord.\n\nProject ideas are listed here:\nhttps://github.com/sktime/mentoring/blob/main/internships/projects_2024.md\n\n### challenging tasks\n\n??? Your time to shine! ??? \nTalk to a core dev before starting with these.\n\nIdeas for more difficult tasks are listed on the current roadmap:\nhttps://github.com/sktime/sktime/issues/7707",
      "updatedAt" : 1752236667.000000000,
      "user" : "fkiraly",
      "userHtmlUrl" : "https://github.com/fkiraly",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7985502?v=4",
      "labels" : [ "documentation", "module:classification", "API design", "implementing framework", "good first issue", "implementing algorithms", "module:detection", "module:tests", "interfacing algorithms", "module:clustering", "module:forecasting", "module:distances&kernels", "maintenance" ],
      "state" : "OPEN",
      "comments" : [ "Closing this now but perhaps we should rework this into a template for sprint planning, some of the items will be relevant for future sprints too?", "Why not just open it and remove the scipy reference? Still good for pinning, no?", "Hi, thanks for the list of first issues! Where can I send my feedback on the tutorials?\r\n", "Hi @gepitis ,\r\nyou could open a new issue with ideas of improvement that you have in mind", ">Where can I send my feedback on the tutorials?\r\n\r\nI just opened an issue here\r\nhttps://github.com/alan-turing-institute/sktime/issues/1447\r\nthanks for any feedback!", "The links for the sktime website are for the .org domain.", "thanks for pointing out - the domain got swooped up by third parties, it's now on sktime.net - fixed all the links!", "Hello @fkiraly , I want to contribute to GSOC'24 , So this org caught my eye.I tried to join the discord channel , but It is showing invalid link", "Thanks for the note, @priyakumari02!\r\nThe discord invite and the link to projects have been updated to 2024.", "hi @fkiraly ,  I want to contribute to GSOC'24 , can you spot some good first issue?", "Welcome to sktime! You seem to be new to open source, how about this one?\r\nhttps://github.com/sktime/sktime/issues/3429", "Hello @fkiraly, I am pretty new to open source and maybe late to the participating. I would still like to know what are some issues you'd recommend I tackle?", "> I am pretty new to open source and maybe late to the participating.\r\n\r\nWelcome, and rest assured that it is never too late!\r\n\r\nHow about #3429 as a starter? It is relatively simple python-wise, but allows you to practice open source workflows, git, PR, reviews, etc.", "> > I am pretty new to open source and maybe late to the participating.\r\n> \r\n> Welcome, and rest assured that it is never too late!\r\n> \r\n> How about #3429 as a starter? It is relatively simple python-wise, but allows you to practice open source workflows, git, PR, reviews, etc.\r\n\r\nOn it ", " I'm interested to working on refactoring of `tutorial for Time series classification`.\r\n Any suggestions for me", "@MihirsinhChauhan, thanks! Truth is, there already have been gradual updates over time, so what would be helpful:\r\n\r\n* work through the tutorial and check whether all is clear\r\n    * any suggestions for improvement, record in a new issue\r\n    * we can then discuss and turn into actions\r\n* 2nd step or alt option: check more recent tutorials from conferences/workshops, on new features, in the `github.com/sktime` organization. See whether the new content from there could be distributed across the existing notebooks, or makes sense to add as a new notebook.", "Hay @fkiraly, I would like to contribute to sktime for my GSOC as well. \r\n1. Could you help to assign any Good First Issue to me? I have little Python coding experience. But I have walked through the example notebooks on Binder.\r\n2. I work for 8hrs/day throughout workdays in GMT+8, Taipei. So you can consider me a full-time contributor.\r\n3. I would like to work extensively with other harder tasks if desired, of course, up to your assignment.\r\n\r\nThank you so much.\r\n\r\nP.s. I implemented the command line `pydocstyle sktime/ --config=setup.cfg | grep ./ | cut -d ':' -f1 | uniq ` but nothing really comes into information of docstrings needed to be complete. Do I miss something here?", "Hey @fkiraly \r\nI would love to cotribute to this project. I have professional exeperience as a Fraud Analyst at a FinTech company and as an Applied Scientist at Amazon. Currently I am pursuing my Masters in AI from University of Amsterdam.\r\n1. I can work for 16 hrs per week.\r\n2. We have some research courses on Deep Learning and Foundation Models.\r\n\r\nI would love to contribute to the Foundation Models project, which will be an enriching reseach experience for me.", "Welcome to sktime, @tunglinwood, @sohamchatterjee50.\r\nConsider applying for mentoring: https://github.com/sktime/mentoring\r\n\r\nAlso, you can look on discord in the workstream channels for your preferred topics.", "> I implemented the command line `pydocstyle sktime/ --config=setup.cfg | grep ./ | cut -d ':' -f1 | uniq` but nothing really comes into information of docstrings needed to be complete. Do I miss something here?\r\n\r\n@tunglinwood, not sure, can you kindly explain what you are trying to do?", "Hello @fkiraly, I am an open source enthusiast and I tend to use open source softwares as much as possible, but have faced a lot of issues while contributing to open source projects. This project gave me a hope that maybe I could contribute to open source after all.\r\nIf possible, Can you please suggest me an issue to get started with? I am ready to devote a lot of time if it's for open source. But getting a good start seems like an issue for me.", "Hey there, I would like to take this issue\r\n", "Hello @fkiraly, I am interested in contributing to GSOC'25. I have knowledge of Time Series and would like to know if you can suggest some good first issues to get started.", "Hey @fkiraly, I???m interested in contributing to sktime for GSoC 2025. I have experience with research publications and internships, but I'm new to open-source contributions. Could you suggest some good first issues to help me get started?", "Sure! There is a list of good first issues to get started at the top of this issue, have a look!\n\nLet us know if you need further guidance, and feel free to chat with the developers on discord (link also above).", "Hello @fkiraly , I am Iremide and I am interested in contributing to sktime for GSoC2025. Is there any plans to have a virtual office hour for interested participants about the projects focus this year?\n\nOr the Fridays meetups are the only avenue available for now?", "> Is there any plans to have a virtual office hour for interested participants about the projects focus this year?\n\nYes, if we get accepted to GSoC as an organization, we will hold an info session soon after, which will be announced on the discord.", "Hi, I???m Nithin Terli, an aspiring GSoC 2025 contributor. I???d love to work on this issue. May I take it up?", "Hi! I'd like to contribute to this project and take on some small-to-medium tasks. Specifically, I'm interested in:\n\n- Refactoring the time series classification tutorial to match the forecasting tutorial style\n- Adding an extension template for time series regression\n- Exploring topics from the sktime workshops and contributing to documentation/tutorials\n- Working on [ENH] issues like ensuring test parameter sets (#3429) or implementing _evaluate_by_index for a metric (#4304)\n- Trying to reproduce and investigate bugs from the [bugfixing board](https://github.com/sktime/sktime/projects/18)\n\nCould you please assign an issue or suggest where I should begin? Thanks!", "Hi @fkiraly and sktime maintainers,\nI???d like to work on the following task from this issue:\n??? Add a Jupyter notebook example and unit test for the ExponentialSmoothing estimator (forecasting demo).\nIs that all right?", "@KALYANI2309K3, where do you get this notebook task from? Not sure if this is still open." ],
      "repository" : {
        "description" : "A unified framework for machine learning with time series",
        "homepage" : "https://www.sktime.net",
        "name" : "sktime",
        "fullName" : "sktime/sktime",
        "htmlUrl" : "https://github.com/sktime/sktime",
        "gitUrl" : "git://github.com/sktime/sktime.git",
        "sshUrl" : "git@github.com:sktime/sktime.git",
        "cloneUrl" : "https://github.com/sktime/sktime.git",
        "owner" : {
          "login" : "sktime",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1659,
        "stargazersCount" : 9149,
        "watchersCount" : 9149,
        "size" : 83131,
        "openIssuesCount" : 1527,
        "subscribersCount" : 112,
        "pushedAt" : "2025-07-11T08:53:14Z",
        "languages" : {
          "Dockerfile" : 1942,
          "CSS" : 8789,
          "Shell" : 1823,
          "Makefile" : 3358,
          "Jupyter Notebook" : 22524,
          "MATLAB" : 4442,
          "Python" : 11501863
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to provide a collection of good first issues for new contributors to get started with the sktime project, covering topics such as documentation, technical writing, coding, and more.",
      "validationOrRequirement" : "No specific validations or requirements mentioned, but the issue is about providing a collection of good first issues for new contributors, so it's likely that the contributors will need to follow the guidelines and instructions provided in the issue description.",
      "attemptedFixes" : "None mentioned in the description, but the issue is about providing a starting point for new contributors, so it's likely that the contributors will attempt to fix issues and implement features.",
      "otherNotes" : "The issue is about providing a collection of good first issues for new contributors to get started with the sktime project, covering topics such as documentation, technical writing, coding, and more.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284032
  }, {
    "issueDTO" : {
      "id" : 712743275,
      "title" : "Added Counting Sort.cpp",
      "url" : "https://github.com/hacktoberfest2k20/DataStructures-and-Algorithms/issues/46",
      "repositoryName" : "hacktoberfest2k20/DataStructures-and-Algorithms",
      "description" : "Please assign this to me @AdarshSR28 , @s-ayush2903  .\r\nI am new to open source contributions.\r\nI have opened a PR for this #45 \r\nThank You. ",
      "updatedAt" : 1752236503.000000000,
      "user" : "ghost",
      "userHtmlUrl" : "https://github.com/ghost",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10137?v=4",
      "labels" : [ "c++", "hacktoberfest", "community", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Yeah, I see, can you please link this issue with the PR you opened", "I have linked the issue with the PR.", "It will be now be reviewed manually. Thanks for contributions. If you have more concerns, you may get the conversation started at our  [discord server](https://discord.gg/4XRsmx)\n" ],
      "repository" : {
        "description" : "Structure the Data in a correct and efficient way :fire:",
        "homepage" : "",
        "name" : "DataStructures-and-Algorithms",
        "fullName" : "hacktoberfest2k20/DataStructures-and-Algorithms",
        "htmlUrl" : "https://github.com/hacktoberfest2k20/DataStructures-and-Algorithms",
        "gitUrl" : "git://github.com/hacktoberfest2k20/DataStructures-and-Algorithms.git",
        "sshUrl" : "git@github.com:hacktoberfest2k20/DataStructures-and-Algorithms.git",
        "cloneUrl" : "https://github.com/hacktoberfest2k20/DataStructures-and-Algorithms.git",
        "owner" : {
          "login" : "hacktoberfest2k20",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : true,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 17,
        "watchersCount" : 17,
        "size" : 92,
        "openIssuesCount" : 110,
        "subscribersCount" : 1,
        "pushedAt" : "2022-10-08T18:13:53Z",
        "languages" : {
          "Java" : 2757,
          "C++" : 21214,
          "C" : 4621,
          "Python" : 501
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Assign the issue to the contributor @AdarshSR28 and @s-ayush2903.",
      "validationOrRequirement" : "None mentioned, but the issue is labeled as a 'good first issue' and 'hacktoberfest'.",
      "attemptedFixes" : "PR #45 has been opened and linked with the issue.",
      "otherNotes" : "The contributor is new to open source contributions and has opened a PR for Counting Sort.cpp. The reviewer has linked the issue with the PR and will review it manually.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284036
  }, {
    "issueDTO" : {
      "id" : 3222715269,
      "title" : "beta button when exporting sbom in white mode is not readable",
      "url" : "https://github.com/l3montree-dev/devguard/issues/877",
      "repositoryName" : "l3montree-dev/devguard",
      "description" : "<img width=\"1115\" height=\"708\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/52d5db2d-e66a-4785-90b4-ce4631384486\" />",
      "updatedAt" : 1752236302.000000000,
      "user" : "5byuri",
      "userHtmlUrl" : "https://github.com/5byuri",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/191719832?v=4",
      "labels" : [ "good first issue", "component/devguard-web" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "DevGuard Backend - Secure your Software Supply Chain - Attestation-based compliance as Code, manage your CVEs seamlessly, Integrate your Vulnerability Scanners, Security Framework Documentation made easy - OWASP Incubating Project",
        "homepage" : "https://devguard.org/",
        "name" : "devguard",
        "fullName" : "l3montree-dev/devguard",
        "htmlUrl" : "https://github.com/l3montree-dev/devguard",
        "gitUrl" : "git://github.com/l3montree-dev/devguard.git",
        "sshUrl" : "git@github.com:l3montree-dev/devguard.git",
        "cloneUrl" : "https://github.com/l3montree-dev/devguard.git",
        "owner" : {
          "login" : "l3montree-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 76,
        "watchersCount" : 76,
        "size" : 94149,
        "openIssuesCount" : 151,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T08:27:11Z",
        "languages" : {
          "Smarty" : 475,
          "Dockerfile" : 1454,
          "Shell" : 8095,
          "TeX" : 12808,
          "Makefile" : 748,
          "Open Policy Agent" : 597,
          "Go" : 1355680,
          "Jsonnet" : 560
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The beta button for exporting SBOM in white mode is not readable.",
      "validationOrRequirement" : "The button in white mode should be readable when exporting SBOM.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description.",
      "otherNotes" : "An image is attached to the description, which may provide additional context.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284039
  }, {
    "issueDTO" : {
      "id" : 3126425254,
      "title" : "Test KvSnapshotITCase.testKvSnapshotAndDelete is unstable",
      "url" : "https://github.com/apache/fluss/issues/1027",
      "repositoryName" : "apache/fluss",
      "description" : "### Search before asking\n\n- [x] I searched in the [issues](https://github.com/alibaba/fluss/issues) and found nothing similar.\n\n\n### Fluss version\n\nmain (development)\n\n### Please describe the bug \uD83D\uDC1E\n\nhttps://github.com/alibaba/fluss/actions/runs/15492095552/job/43619797481\n\n```\nError:  Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 140.065 s <<< FAILURE! - in com.alibaba.fluss.server.replica.KvSnapshotITCase\nError:  com.alibaba.fluss.server.replica.KvSnapshotITCase.testKvSnapshotAndDelete  Time elapsed: 129.54 s  <<< FAILURE!\njava.lang.AssertionError: Fail to wait for the snapshot 0 for bucket TableBucket{tableId=2, bucket=1}\n\tat com.alibaba.fluss.testutils.common.CommonTestUtils.waitUtil(CommonTestUtils.java:80)\n\tat com.alibaba.fluss.testutils.common.CommonTestUtils.waitUtil(CommonTestUtils.java:98)\n\tat com.alibaba.fluss.testutils.common.CommonTestUtils.waitValue(CommonTestUtils.java:112)\n\tat com.alibaba.fluss.server.replica.KvSnapshotITCase.testKvSnapshotAndDelete(KvSnapshotITCase.java:127)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)\n\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)\n\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\n\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)\n\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)\n\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)\n\tat org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:129)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)\n\tat org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService.invokeAll(ForkJoinPoolHierarchicalTestExecutorService.java:129)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n\tat org.junit.platform.engine.support.hierarchical.ForkJoinPoolHierarchicalTestExecutorService$ExclusiveTask.compute(ForkJoinPoolHierarchicalTestExecutorService.java:185)\n\tat java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)\n\n[INFO] Running com.alibaba.fluss.server.tablet.TabletServerFailOverITCase\n```\n\n### Solution\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
      "updatedAt" : 1752236268.000000000,
      "user" : "wuchong",
      "userHtmlUrl" : "https://github.com/wuchong",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5378924?v=4",
      "labels" : [ "component=test", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @swuferhong , please check if it is related to the recent metadata change.", "> cc [@swuferhong](https://github.com/swuferhong) , please check if it is related to the recent metadata change.\n\nOk, I will check it.\n", "another failed instance: https://github.com/apache/fluss/actions/runs/16218873781/job/45794430779" ],
      "repository" : {
        "description" : "Apache Fluss is a streaming storage built for real-time analytics.",
        "homepage" : "https://fluss.apache.org/",
        "name" : "fluss",
        "fullName" : "apache/fluss",
        "htmlUrl" : "https://github.com/apache/fluss",
        "gitUrl" : "git://github.com/apache/fluss.git",
        "sshUrl" : "git@github.com:apache/fluss.git",
        "cloneUrl" : "https://github.com/apache/fluss.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 349,
        "stargazersCount" : 1307,
        "watchersCount" : 1307,
        "size" : 41783,
        "openIssuesCount" : 299,
        "subscribersCount" : 33,
        "pushedAt" : "2025-07-11T14:01:28Z",
        "languages" : {
          "TypeScript" : 17752,
          "MDX" : 17568,
          "Java" : 10712509,
          "Dockerfile" : 1561,
          "Shell" : 40748,
          "CSS" : 10287,
          "JavaScript" : 6256
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to resolve the instability in the test case for KvSnapshotITCase.testKvSnapshotAndDelete, which is failing due to an error related to waiting for the snapshot 0 for bucket TableBucket{tableId=2, bucket=1}.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the issue description.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description.",
      "otherNotes" : "This issue is related to the test case for KvSnapshotITCase.testKvSnapshotAndDelete, which is unstable. The error is related to waiting for the snapshot 0 for bucket TableBucket{tableId=2, bucket=1}.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284044
  }, {
    "issueDTO" : {
      "id" : 2267710166,
      "title" : "Can't enter commas into database configuration setup",
      "url" : "https://github.com/apache/superset/issues/28252",
      "repositoryName" : "apache/superset",
      "description" : "### Bug description\n\nWhen attempting to enter commas in order to limit the ability to upload data to specific database schemas only, the UI doesn't accept comma keystrokes and the comma separated value list therefore cannot be created.\r\n\r\n![image](https://github.com/apache/superset/assets/40233203/5c7d29d4-f8c2-4391-a8eb-f57d17a37030)\r\n\n\n### How to reproduce the bug\n\nMy deployment:\r\n\r\nDocker compose onto Linux VPS (Ubuntu)\r\n\r\nReproduction steps:\r\n\r\n-> Click into database connections\r\n-> Edit a database\r\n-> Advanced options\r\n-> Limit upload permissions to specific schemas\r\n-> Attempt to upload desired schemas as comma separated values by typing names of desired schemas with separating commas\n\n### Screenshots/recordings\n\n_No response_\n\n### Superset version\n\nmaster / latest-dev\n\n### Python version\n\n3.9\n\n### Node version\n\n16\n\n### Browser\n\nChrome\n\n### Additional context\n\n_No response_\n\n### Checklist\n\n- [X] I have searched Superset docs and Slack and didn't find a solution to my problem.\n- [X] I have searched the GitHub issue tracker and didn't find a similar bug report.\n- [X] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the \"additional context\" section.",
      "updatedAt" : 1752236241.000000000,
      "user" : "danielrosehill",
      "userHtmlUrl" : "https://github.com/danielrosehill",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/40233203?v=4",
      "labels" : [ "preset:bounty", "preset:bounty:bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This still seems to be the case in 4.1.1 / master. Seems like it shouldn't be tough to fix, so I'll ping @yousoph / @geido in case they want to farm this out.", "I can work on this but I have a question.\r\n\r\nIf we already have schema present, should it be immutable? That seems to be the behavior now. After the input field is populated by the existing schema, we are unable to edit it.\r\n\r\n\r\n", "Hi Ajay-Satish-01\r\n\r\nThank you for your question and for your interest in contributing to Apache Superset.\r\nThe current behavior where the schema field becomes immutable after being populated might be intentional to prevent accidental modifications to critical database configurations. However, this can be inconvenient in scenarios where updates to the schema are necessary.\r\nTo address this, we can consider the following approach:\r\n1.)Make the Schema Editable: This allow users to edit the schema field after it has been populated to provide flexibility for making necessary updates without resetting the entire configuration.\r\n2.)Add a Confirmation Mechanism: Implement a confirmation dialog that prompts users to confirm changes to the schema. This can help prevent accidental modifications while still allowing for updates when needed. \r\n3.)Version Control for Configurations: Introduce a version control mechanism for database configurations. This way, any changes to the schema can be tracked, and users can revert to previous configurations if necessary.\r\n4.)User Permissions: Ensure that only users with the appropriate permissions can edit the schema field. This can help maintain the integrity of the database configurations.\r\nNext Steps:\r\nDiscuss with the maintainers or the community to get their input on whether making the schema editable aligns with the project's design principles.\r\nImplement the changes based on the feedback received.\r\nThoroughly test the implementation to ensure it works as expected and does not introduce any new issues.\r\nBy making the schema field editable with the appropriate safeguards, we can provide a more flexible and user-friendly experience while maintaining the integrity of the database configurations.\r\n\r\nYour feedback on this approach would be greatly appreciated.\r\n\r\nBest regards,\r\nVam-tech-star\r\n\r\n\r\n\r\n\r\n\r\n", "@rusackas Could you please assign me that issue?", "Hey @dev-mohit06 sure! Thanks for the help!", "The issue persists, just to throw a new timestamp on this issue.", "---\n\n### \uD83C\uDF89 **Preset Bounty Available: $100 USD** \uD83C\uDF89\n\nTo claim this bounty, please carefully follow the steps below.\n\n---\n\n#### \uD83D\uDCCB **Steps to Participate**\n\n1. **Review Guidelines:**  \n   Read through the [Preset Bounty Program Contribution Guide](https://preset.notion.site/preset-bounty-program-apache-superset) for complete details on bounty requirements.\n\n2. **Show Your Interest:**  \n   Complete the [Preset Bounty Program Survey](https://docs.google.com/forms/d/e/1FAIpQLSeDsR1iWvPxFydUIXs2agsUg3kMDaAooeD4P9P1L5sI0Yu5QQ/viewform?usp=sharing) and comment this issue to express your interest.\n\n3. **Join the Slack Channel:**  \n   After completing the survey, you???ll receive an invitation to the dedicated [Apache Superset Slack](https://join.slack.com/t/apache-superset/shared_invite/zt-2be0drwz8-bxPfkdz28ozzk1Iox29ufg) channel.\n\n4. **Get Assigned:**  \n   To officially start, ensure a **Bounty Program Manager** has assigned you to this issue.\n\n5. **Submit Your Solution:**  \n   When ready, submit your solution with the `Fixes #{issue_number}` notation in your Pull Request description.\n\n6. **Claim Your Bounty:**  \n   Sign up at [GitPay.me](https://gitpay.me/) and submit your solution via: [https://gitpay.me/#/task/1212](https://gitpay.me/#/task/1212)\n\n---\n\n#### \uD83D\uDCA1 **Additional Notes**\n\n- Only developers assigned by a **Bounty Program Manager** should start working on this issue to win the bounty.\n- Be sure to follow the guide closely to avoid any delays in payment. Please, allow a few days after your PR has been merged for the bounty to be released.\n\nGood luck, and happy coding! \uD83C\uDF89", "@geido I would like to take this, Please assign to me", "@dosu can you tell me where the code is located for this and also why this is happening and possible solutions.", "<!-- Answer -->\nThe code for the \"Schemas Allowed for File Upload\" field is in the frontend at `superset-frontend/src/features/databases/DatabaseModal/ExtraOptions.tsx`. It's implemented as a plain text `<Input />` (not a Select or tag input), and its value is managed by the `dbReducer` in `DatabaseModal/index.tsx`???which splits the input by commas and stores it as an array in the `extra` JSON for the database config. The field is only shown if file uploads are supported and enabled for the database. You can see the relevant code [here](https://github.com/apache/superset/blob/2e9939baf253e607a54722b1996baaf625e72133/superset-frontend/src/features/databases/DatabaseModal/ExtraOptions.tsx).\n\nThere are no props like `disabled` or `readOnly` on the input, so the field should be editable as long as file upload is enabled and the database isn't managed externally. No event handlers block comma input. If you're unable to type commas or edit the field after it's populated, it's likely a UI bug or a state issue, not a deliberate restriction in the component code. The reducer logic does convert the input into an array, but this shouldn't prevent further editing as a comma-separated string unless something else in the UI is interfering [source](https://github.com/apache/superset/blob/2e9939baf253e607a54722b1996baaf625e72133/superset-frontend/src/features/databases/DatabaseModal/index.tsx).\n\nPossible solutions: \n- Double-check that \"Allow file uploads to database\" is enabled; otherwise, the field is hidden.\n- If the field is visible but not editable, look for any UI state or modal logic that could be disabling it (for example, if the database is managed externally, the modal disables the action button, but the field itself should still be editable).\n- If you confirm a UI bug (e.g., the field is visible but not accepting input), focus on the state management and input handler logic in `ExtraOptions.tsx` and `dbReducer` for debugging.\n\nLet me know if you need a more detailed walkthrough of the code or want to discuss a specific fix!\n\n\n<!-- Dosu Comment Footer -->\n*To reply, just mention [@dosu](https://go.dosu.dev/dosubot).*\n\n---\n<sup>How did I do? [Good](https://app.dosu.dev/response-feedback/9395430f-ad0c-4719-a287-8a5038631727?feedback_type=great_response) | [Irrelevant](https://app.dosu.dev/response-feedback/9395430f-ad0c-4719-a287-8a5038631727?feedback_type=irrelevant_answer) | [Incorrect](https://app.dosu.dev/response-feedback/9395430f-ad0c-4719-a287-8a5038631727?feedback_type=incorrect_sources) | [Verbose](https://app.dosu.dev/response-feedback/9395430f-ad0c-4719-a287-8a5038631727?feedback_type=too_verbose) | [Hallucination](https://app.dosu.dev/response-feedback/9395430f-ad0c-4719-a287-8a5038631727?feedback_type=hallucination) | [Report \uD83D\uDC1B](https://app.dosu.dev/response-feedback/9395430f-ad0c-4719-a287-8a5038631727?feedback_type=bug_report) | [Other](https://app.dosu.dev/response-feedback/9395430f-ad0c-4719-a287-8a5038631727?feedback_type=other)</sup>&nbsp;&nbsp;[![Join Discord](https://img.shields.io/badge/join-5865F2?logo=discord&logoColor=white&label=)](https://go.dosu.dev/discord-bot)&nbsp;[![Share on X](https://img.shields.io/badge/X-share-black)](https://twitter.com/intent/tweet?text=%40dosu_ai%20helped%20me%20solve%20this%20issue!&url=https%3A//github.com/apache/superset/issues/28252)" ],
      "repository" : {
        "description" : "Apache Superset is a Data Visualization and Data Exploration Platform",
        "homepage" : "https://superset.apache.org/",
        "name" : "superset",
        "fullName" : "apache/superset",
        "htmlUrl" : "https://github.com/apache/superset",
        "gitUrl" : "git://github.com/apache/superset.git",
        "sshUrl" : "git@github.com:apache/superset.git",
        "cloneUrl" : "https://github.com/apache/superset.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15298,
        "stargazersCount" : 67064,
        "watchersCount" : 67064,
        "size" : 756073,
        "openIssuesCount" : 803,
        "subscribersCount" : 1530,
        "pushedAt" : "2025-07-12T00:34:00Z",
        "languages" : {
          "Smarty" : 5044,
          "Jinja" : 5847,
          "CSS" : 4781,
          "Pug" : 2969,
          "Makefile" : 4133,
          "HTML" : 1278006,
          "Jupyter Notebook" : 10916999,
          "TypeScript" : 11362202,
          "Dockerfile" : 12025,
          "Shell" : 65877,
          "JavaScript" : 1839895,
          "Mako" : 1197,
          "Python" : 8964539
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to resolve the issue where the schema field becomes immutable after being populated, and to make it editable with a confirmation mechanism to prevent accidental modifications.",
      "validationOrRequirement" : "The schema field should be editable after being populated, and a confirmation mechanism should be implemented to prevent accidental modifications. The field should not be immutable.",
      "attemptedFixes" : "The code for the 'Schemas Allowed for File Upload' field is in the frontend at superset-frontend/src/features/databases/DatabaseModal/ExtraOptions.tsx. It's implemented as a plain text <Input /> (not a Select or tag input), and its value is managed by the dbReducer in DatabaseModal/index.tsx. Possible solutions include double-checking that 'Allow file uploads to database' is enabled, looking for any UI state or modal logic that could be disabling it, and focusing on the state management and input handler logic in ExtraOptions.tsx and dbReducer for debugging.",
      "otherNotes" : "The issue persists, and the schema field becomes immutable after being populated. The current behavior might be intentional to prevent accidental modifications to critical database configurations. The proposed solution is to make the schema field editable, add a confirmation mechanism, introduce version control for configurations, and ensure user permissions. The bounty is $100 USD, and the preset bounty program has specific guidelines and steps to participate.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284053
  }, {
    "issueDTO" : {
      "id" : 2147916154,
      "title" : "Bootstrap GSM tech debt",
      "url" : "https://github.com/IntersectMBO/ouroboros-consensus/issues/964",
      "repositoryName" : "IntersectMBO/ouroboros-consensus",
      "description" : "Taken from https://github.com/IntersectMBO/ouroboros-consensus/pull/808#issuecomment-1954913114, upon clicking the \"Merge when ready\" button.\r\n\r\n- [x] s-r-p stanzas (see https://github.com/IntersectMBO/ouroboros-consensus/pull/808#discussion_r1490714381)\r\n- [ ] Either move the GSM logic into the ChainDB and keep the GSM arguments as part of the ChainDB arguments (which would be encapsulated inside of openChainDB) or remove the argument from the ChainDB arguments and keep it as a NodeKernel-level thing.\r\n- [ ] move the anti-thundering herd delay into the Diffusion Layer, _between_ the two states CaughtUp and OnlyBootstrap\r\n- regression tests (code review and ad-hoc manual testing has already evidenced that they're _currently_ correct):\r\n    - [ ] `realMarkerFileView` regression tests\r\n    - [ ] `initializationLedgerJudgement` regression tests\r\n    - [ ] `realDurationUntilTooOld` regression tests\r\n    - [ ] The ChainSync client should signal idle exactly when and only when the `MsgAwaitReply` is processed.\r\n    - [ ] The ChainSync client subsequently should signal no-longer-idle exactly when and only when the next message is received.\r\n- [x] #1149\r\n- [ ] use `ArbitraryLedgerStateJudgement` from `ouroboros-network:sim-tests-lib`\r\n",
      "updatedAt" : 1752236235.000000000,
      "user" : "nfrisby",
      "userHtmlUrl" : "https://github.com/nfrisby",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1106131?v=4",
      "labels" : [ "technical debt", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "- Either move the GSM logic into the ChainDB and keep the GSM arguments as part of the ChainDB arguments (which would be encapsulated inside of `openChainDB`) or remove the argument from the ChainDB arguments and keep it as a NodeKernel-level thing.", "~What is the status of the non-bootstrap GSM? Have we ever implemented one?~ What I meant is whether the Genesis SoW is finished and we've integrated it?", "Yes, the GSM now actually deserves its name. The changes for that were rather small:\n\n - https://github.com/IntersectMBO/ouroboros-consensus/pull/975\n - https://github.com/IntersectMBO/ouroboros-consensus/pull/1031\n\nThe tasks in this ticket should be independent of that." ],
      "repository" : {
        "description" : "Implementation of a Consensus Layer for the Ouroboros family of protocols",
        "homepage" : "https://ouroboros-consensus.cardano.intersectmbo.org",
        "name" : "ouroboros-consensus",
        "fullName" : "IntersectMBO/ouroboros-consensus",
        "htmlUrl" : "https://github.com/IntersectMBO/ouroboros-consensus",
        "gitUrl" : "git://github.com/IntersectMBO/ouroboros-consensus.git",
        "sshUrl" : "git@github.com:IntersectMBO/ouroboros-consensus.git",
        "cloneUrl" : "https://github.com/IntersectMBO/ouroboros-consensus.git",
        "owner" : {
          "login" : "IntersectMBO",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 54,
        "watchersCount" : 54,
        "size" : 61724,
        "openIssuesCount" : 435,
        "subscribersCount" : 33,
        "pushedAt" : "2025-07-11T16:46:52Z",
        "languages" : {
          "Shell" : 36381,
          "Awk" : 120,
          "jq" : 528,
          "Haskell" : 6086113,
          "Gnuplot" : 7235,
          "Nix" : 18264,
          "Ruby" : 42,
          "Kaitai Struct" : 530,
          "Python" : 2097
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Addressing technical debt and good first issue by refactoring GSM logic and removing GSM argument from ChainDB arguments, and implementing anti-thundering herd delay in Diffusion Layer.",
      "validationOrRequirement" : "Move GSM logic into ChainDB, remove GSM argument from ChainDB arguments and keep it as NodeKernel-level thing, move anti-thundering herd delay into Diffusion Layer, regression tests (realMarkerFileView, initializationLedgerJudgement, realDurationUntilTooOld, signal idle/no-longer-idle when processing/ receiving messages).",
      "attemptedFixes" : "s-r-p stanzas, #1149, use `ArbitraryLedgerStateJudgement` from `ouroboros-network:sim-tests-lib`.",
      "otherNotes" : "The GSM now actually deserves its name, with changes made in https://github.com/IntersectMBO/ouroboros-consensus/pull/975 and https://github.com/IntersectMBO/ouroboros-consensus/pull/1031.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284060
  }, {
    "issueDTO" : {
      "id" : 3212712689,
      "title" : "The `test_login_username_refresh_token()` method should use the `MatrixMockServer`",
      "url" : "https://github.com/matrix-org/matrix-rust-sdk/issues/5366",
      "repositoryName" : "matrix-org/matrix-rust-sdk",
      "description" : "Related to https://github.com/matrix-org/matrix-rust-sdk/issues/3716.\n\nMany of the integration tests for the refresh token support still don't use the `MatrixMockServer`. A good starting point to kickstart the conversion would be the `test_login_username_refresh_token()` method:\n\nhttps://github.com/matrix-org/matrix-rust-sdk/blob/a4e4b5534befc481b7c018aed9c8d60b5d138f56/crates/matrix-sdk/tests/integration/refresh_token.rs#L44-L69\n\nThe test can't be converted right of the bat, we first need to extend the `MatrixMockServer` a bit:\n\n- [ ] The `LoginEndpoint` mock needs to be extended so we can ensure that the request body contains certain JSON fields.\n- [ ] We need to be able to configure what the `LoginEndpoint` mock will respond with.\n\nFor the first part we can take a look at the `ReceiptEndpoint`:\n\nhttps://github.com/matrix-org/matrix-rust-sdk/blob/a4e4b5534befc481b7c018aed9c8d60b5d138f56/crates/matrix-sdk/src/test_utils/mocks/mod.rs#L3172-L3176\n\nThe second point should add a parametrized variant of the `ok()` method we have:\n\nhttps://github.com/matrix-org/matrix-rust-sdk/blob/a4e4b5534befc481b7c018aed9c8d60b5d138f56/crates/matrix-sdk/src/test_utils/mocks/mod.rs#L3229-L3232\n\nAfter this, the test itself can be converted to utilize the `MatrixMockServer` with the newly introduced methods.",
      "updatedAt" : 1752236181.000000000,
      "user" : "poljar",
      "userHtmlUrl" : "https://github.com/poljar",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/552026?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This has been closed by #5383." ],
      "repository" : {
        "description" : "Matrix Client-Server SDK for Rust",
        "homepage" : "",
        "name" : "matrix-rust-sdk",
        "fullName" : "matrix-org/matrix-rust-sdk",
        "htmlUrl" : "https://github.com/matrix-org/matrix-rust-sdk",
        "gitUrl" : "git://github.com/matrix-org/matrix-rust-sdk.git",
        "sshUrl" : "git@github.com:matrix-org/matrix-rust-sdk.git",
        "cloneUrl" : "https://github.com/matrix-org/matrix-rust-sdk.git",
        "owner" : {
          "login" : "matrix-org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 310,
        "stargazersCount" : 1541,
        "watchersCount" : 1541,
        "size" : 66088,
        "openIssuesCount" : 268,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T18:10:18Z",
        "languages" : {
          "Dockerfile" : 125,
          "Shell" : 5632,
          "Rust" : 11299833,
          "Makefile" : 288,
          "Swift" : 3872,
          "Perl" : 782,
          "Ruby" : 2075,
          "Python" : 2588
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to use the `MatrixMockServer` in the `test_login_username_refresh_token()` method, which is a starting point for converting many of the integration tests for the refresh token support.",
      "validationOrRequirement" : "The test `test_login_username_refresh_token()` should use the `MatrixMockServer`, extending the `MatrixMockServer` to include a `LoginEndpoint` mock and configuring the `LoginEndpoint` mock to respond with certain values.",
      "attemptedFixes" : "Extending the `MatrixMockServer` to include a `LoginEndpoint` mock that can ensure certain JSON fields in the request body and configuring the `LoginEndpoint` mock to respond with certain values.",
      "otherNotes" : "This issue is related to #3716, has been closed by #5383, and is marked as a good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284066
  }, {
    "issueDTO" : {
      "id" : 2486549499,
      "title" : "[ntuple] Compare RNTuple to ORC",
      "url" : "https://github.com/root-project/root/issues/16310",
      "repositoryName" : "root-project/root",
      "description" : "### Explain what you would like to see improved and how.\n\nImplement the RNTuple standard benchmarks using ORC: https://orc.apache.org/\r\nMeasure read/write time, memory consumption, and final file size.\r\n\r\nMoved from https://its.cern.ch/jira/browse/ROOT-10264\n\n### ROOT version\n\nn/a\n\n### Installation method\n\nn/a\n\n### Operating system\n\nn/a\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752236116.000000000,
      "user" : "jblomer",
      "userHtmlUrl" : "https://github.com/jblomer",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1557360?v=4",
      "labels" : [ "JIRA", "good first issue", "in:RNTuple" ],
      "state" : "OPEN",
      "comments" : [ "@enirolf can this be closed with Stijn's thesis, do we need more investigations into nested data structures with collections?" ],
      "repository" : {
        "description" : "The official repository for ROOT: analyzing, storing and visualizing big data, scientifically",
        "homepage" : "https://root.cern",
        "name" : "root",
        "fullName" : "root-project/root",
        "htmlUrl" : "https://github.com/root-project/root",
        "gitUrl" : "git://github.com/root-project/root.git",
        "sshUrl" : "git@github.com:root-project/root.git",
        "cloneUrl" : "https://github.com/root-project/root.git",
        "owner" : {
          "login" : "root-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1360,
        "stargazersCount" : 2898,
        "watchersCount" : 2898,
        "size" : 1487060,
        "openIssuesCount" : 748,
        "subscribersCount" : 121,
        "pushedAt" : "2025-07-11T14:07:21Z",
        "languages" : {
          "C#" : 27973,
          "C" : 38447377,
          "CMake" : 2572993,
          "Makefile" : 472675,
          "M4" : 8712,
          "HTML" : 2672014,
          "Jupyter Notebook" : 744990,
          "Pawn" : 2074,
          "Fortran" : 489996,
          "Shell" : 356013,
          "R" : 402,
          "Awk" : 16093,
          "JavaScript" : 13633788,
          "Objective-C" : 89949,
          "Assembly" : 871256,
          "Python" : 5443931,
          "Emacs Lisp" : 32268,
          "Smarty" : 473,
          "PowerShell" : 405,
          "C++" : 256054340,
          "CSS" : 108100,
          "Objective-C++" : 674298,
          "SWIG" : 243,
          "AppleScript" : 1429,
          "Perl" : 108925,
          "Cuda" : 325984,
          "Dockerfile" : 8987,
          "Batchfile" : 44252,
          "Linker Script" : 3048,
          "Roff" : 1739545,
          "Vim Script" : 21290
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Compare RNTuple to ORC and implement standard benchmarks using ORC",
      "validationOrRequirement" : "Implement the RNTuple standard benchmarks using ORC, measure read/write time, memory consumption, and final file size",
      "attemptedFixes" : "No attempted fixes mentioned, only a suggestion to close the issue with Stijn's thesis",
      "otherNotes" : "Additional context: No response, ROOT version: n/a, Installation method: n/a, Operating system: n/a",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284070
  }, {
    "issueDTO" : {
      "id" : 3189825559,
      "title" : "\"Search ShortSience\" should to a latex-to-unicode conversion",
      "url" : "https://github.com/JabRef/jabref/issues/13418",
      "repositoryName" : "JabRef/jabref",
      "description" : "I have the title\n\n    {The Difference Between Graph-Based and Block-Structured Business Process Modelling Languages}\n\nI click \"Search ShortSience\" \n\nThe braces are searched\n\n![Image](https://github.com/user-attachments/assets/031197f4-e628-4d5d-9980-20d05ef0b975)\n\nBefore the search is done, the title should be converted to unicode. \n\n---\n\nHnts\n\n1. Try to use `org.jabref.model.strings.LatexToUnicodeAdapter#format` for the conversion\n2. Add test case\n\n---\n\n![Image](https://github.com/user-attachments/assets/20c251e9-9322-4b40-831f-376e5a3f43ad)\n\n```bibtex\n@Article{Kopp2009,\n  author    = {Oliver Kopp and Daniel Martin and Daniel Wutke and Frank Leymann},\n  journal   = {Enterprise Modelling and Information Systems},\n  title     = {{The Difference Between Graph-Based and Block-Structured Business Process Modelling Languages}},\n  year      = {2009},\n  month     = jun,\n  number    = {1},\n  pages     = {3--13},\n  volume    = {4},\n}\n```\n",
      "updatedAt" : 1752236071.000000000,
      "user" : "koppor",
      "userHtmlUrl" : "https://github.com/koppor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1366654?v=4",
      "labels" : [ "good first issue", "\uD83D\uDCCD Assigned", "\uD83D\uDD14 reminder-sent" ],
      "state" : "OPEN",
      "comments" : [ "/assign-me", "\uD83D\uDC4B Hey @xIshanSandhux, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80", "### ??? Assignment Reminder\n\nHi @xIshanSandhux, this is a friendly reminder about your assignment to this issue.\n\n> [!WARNING]\n> This issue will be **automatically unassigned** in **11 days** if there's no activity.\n\nRemember that you can ask the [JabRef Guru](https://gurubase.io/g/jabref) or [DeepWiki](https://deepwiki.com/JabRef/jabref) about anything regarding JabRef.\nAdditionally, our contributing guide has [hints on creating a pull request](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md#pull-request-process) and a link to our Gitter chat.\n\n<details open>\n<summary>How to keep your assignment</summary>\n\n\\\nIf you are working on it, you can prevent automatic unassignment by:\n\n- Submitting a [draft pull request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests#draft-pull-requests) with your progress within 11 days\n- Asking for the **\uD83D\uDCCC Pinned** label if you need more time\n</details>\n\nWe appreciate your contribution and are here to help if needed!" ],
      "repository" : {
        "description" : "Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases",
        "homepage" : "https://www.jabref.org",
        "name" : "jabref",
        "fullName" : "JabRef/jabref",
        "htmlUrl" : "https://github.com/JabRef/jabref",
        "gitUrl" : "git://github.com/JabRef/jabref.git",
        "sshUrl" : "git@github.com:JabRef/jabref.git",
        "cloneUrl" : "https://github.com/JabRef/jabref.git",
        "owner" : {
          "login" : "JabRef",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2861,
        "stargazersCount" : 3942,
        "watchersCount" : 3942,
        "size" : 249107,
        "openIssuesCount" : 582,
        "subscribersCount" : 113,
        "pushedAt" : "2025-07-11T22:29:41Z",
        "languages" : {
          "PowerShell" : 2037,
          "Java" : 11216891,
          "CSS" : 74176,
          "TeX" : 758587,
          "AppleScript" : 1721,
          "XSLT" : 151843,
          "Just" : 1194,
          "Shell" : 9305,
          "Batchfile" : 637,
          "ANTLR" : 9176,
          "BibTeX Style" : 78034,
          "Ruby" : 507,
          "Python" : 22282
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert the title to unicode before searching ShortSience",
      "validationOrRequirement" : "Use org.jabref.model.strings.LatexToUnicodeAdapter#format for the conversion and add test cases",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is about converting the title to unicode before searching ShortSience. It also mentions the use of LatexToUnicodeAdapter#format for the conversion and adding test cases. The author is asking for help in setting up the local workspace and provides links to the contributing guidelines and developer FAQs. There is also a reminder about the assignment deadline.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284074
  }, {
    "issueDTO" : {
      "id" : 2541195652,
      "title" : "[Looking for help!] Localization of WGDashboard",
      "url" : "https://github.com/donaldzou/WGDashboard/issues/397",
      "repositoryName" : "donaldzou/WGDashboard",
      "description" : "Hi all, I finally finished adding the support of localization, and currently WGDashboard support the following languages:\r\n\r\n- Czech\r\n- Chinese (Simplified)\r\n- Chinese (Traditional)\r\n- Dutch\r\n- English\r\n- German\r\n- Italian\r\n- Polish\r\n- Spanish\r\n- Swedish\r\n- Russian\r\n- Turkish\r\n- Ukrainian\r\n\r\nIf anyone are willing to contribute, you can follow the instructions below:\r\n\r\n1. `git clone` the main branch\r\n2. Copy `language_template.json and rename them using the locale code in this list: https://www.science.co.il/language/Locale-codes.php\r\n3. Start translate! **Remember don't edit the `key`, just the value.**\r\n\r\n> You might notice there are some Regex syntax in the existing locale files. Basically, the dashboard will match the key to the texts in the UI, and replace the value using regex. So you can adjust the position of matching groups to better fit your language.\r\n> For example: `You can add up to (.*) peers` have one matching group which is matching a number between **to** and **peers**, and you can use `$1` in the value to represent the number.\r\n\r\nAfter you're done translating:\r\n\r\n1. Add your translation to `active_languages.json` by following this format\r\n\r\n```json\r\n[\r\n    {\r\n        \"lang_id\": \"zh-cn\",\r\n        \"lang_name\": \"Chinese (Simplified)\",\r\n        \"lang_name_localized\": \"?????? ????????????\"\r\n    }\r\n]\r\n```\r\n\r\n2. Run the check script\r\n\r\n```bash\r\npython3 verify_locale_files.py\r\n```\r\n\r\nIt will tell you if your translation have missing translation or deprecated one, and it will insert or remove them directly for you:\r\n\r\n```bash\r\npython3 verify_locale_files.py\r\n \r\n========================================================\r\n| WGDashboard Locale File Verification [by @donaldzou] |\r\n========================================================\r\n\r\nActive Languages\r\n\r\nCzech | cs\r\nGerman | de-de\r\nEnglish | en\r\nSpanish | es-es\r\nItalian | it-it\r\nDutch | nl-nl\r\nRussian | ru\r\nTurkish | tr-tr\r\nUkrainian | uk\r\nChinese (Simplified) | zh-cn\r\nChinese (Traditional) | zh-hk\r\nSwedish | sv-se\r\nPolish | pl\r\n\r\nPlease enter the language ID to verify: zh-cn\r\n\r\n\t[Missing Translations] 0 translation\r\n\t[Deprecated Translations] 0 translation\r\n\t[Note] All missing translations are added into zh-cn.json, all deprecated translations are removed from zh-cn.json\r\n```\r\n\r\n\r\n\r\n\r\nPlease comment below if you have any questions \uD83D\uDE04 ",
      "updatedAt" : 1752235520.000000000,
      "user" : "donaldzou",
      "userHtmlUrl" : "https://github.com/donaldzou",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25237201?v=4",
      "labels" : [ "ongoing", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I can provide Dutch if you'd like, but how would I do that?", "> I can provide Dutch if you'd like, but how would I do that?\r\n\r\nHi @DaanSelen, I provided an instruction above :) Is fairly easy as I already have an example in the `v4.1-dev` branch. Basically the file looks like this:\r\n\r\n```json\r\n{\r\n\t\"Welcome to\": \"????????????\",\r\n\t\"Username\": \"?????????\",\r\n\t\"Password\": \"??????\",\r\n\t\"OTP from your authenticator\": \"?????????????????????????????????????????????\",\r\n\t\"Sign In\": \"??????\"\r\n...\r\n}\r\n\r\n```\r\nWhere the key is what you translating from, and the value is what you are translating to. The example provided is Chinese (Traditional)", "@donaldzou I can do the Spanish &  Portuguese bit.", "@donaldzou I will support with German! :) ", "Hi @3vis97 ! Thank you for providing the Italian translation. Do you mind creating a PR to my `v4.1-dev` branch so I can merge your work to mine? ", "> Hi @3vis97 ! Thank you for providing the Italian translation. Do you mind creating a PR to my `v4.1-dev` branch so I can merge your work to mine?\r\n\r\nHi @donaldzou!\r\nYes i will do, but before I create the PR, I'd like to test the translation in a live instance to ensure the female, male and plural forms are correct and the translation sounds natural in the web interface.\r\n\r\nI only need to find the time to do it. I hope to do it in the next few days \uD83D\uDC4D\uD83C\uDFFB", "> > Hi @3vis97 ! Thank you for providing the Italian translation. Do you mind creating a PR to my `v4.1-dev` branch so I can merge your work to mine?\r\n> \r\n> Hi @donaldzou! Yes i will do, but before I create the PR, I'd like to test the translation in a live instance to ensure the female, male and plural forms are correct and the translation sounds natural in the web interface.\r\n> \r\n> I only need to find the time to do it. I hope to do it in the next few days \uD83D\uDC4D\uD83C\uDFFB\r\n\r\nFor sure! Please take your time and can't thank you enough for providing this ;)", "> > > Hi @3vis97 ! Thank you for providing the Italian translation. Do you mind creating a PR to my `v4.1-dev` branch so I can merge your work to mine?\r\n> > \r\n> > \r\n> > Hi @donaldzou! Yes i will do, but before I create the PR, I'd like to test the translation in a live instance to ensure the female, male and plural forms are correct and the translation sounds natural in the web interface.\r\n> > I only need to find the time to do it. I hope to do it in the next few days \uD83D\uDC4D\uD83C\uDFFB\r\n> \r\n> For sure! Please take your time and can't thank you enough for providing this ;)\r\n\r\nHi @donaldzou, Here's the the PR https://github.com/donaldzou/WGDashboard/pull/406 !", "> @donaldzou I can do the Spanish & Portuguese bit.\r\n\r\nI can do Brazilian Portuguese", "> > @donaldzou I can do the Spanish & Portuguese bit.\n> \n> \n> \n> I can do Brazilian Portuguese\n\n@velrino For sure! Thanks is advanced.", "I added a Czech translation, see PR https://github.com/donaldzou/WGDashboard/pull/452. :slightly_smiling_face: ", "How can I verify the made translations? Can I already toggle it somehow - somewhere in a configuration file.", "Hi Daan,\r\n\r\n\r\nYes if you use the `v4.1-dev` branch, you can toggle it in ???Settings??? => ???WGDashboard Settings??? => ???Appearance??? => ???Language??? ;)\r\n\r\n\r\nBest,\r\n\r\nDonald\r\n\r\n\r\n\r\nOn Nov 7, 2024, at 5:57???PM, dselen ***@***.***> wrote:\r\n\r\n\r\n\r\nHow can I verify the made translations? Can I already toggle it somehow - somewhere in a configuration file.\r\n\r\n???\r\nReply to this email directly, view it on GitHub<https://github.com/donaldzou/WGDashboard/issues/397#issuecomment-2461795228>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AGARNUOKQXPOSL2Y4SKJ24LZ7M2QTAVCNFSM6AAAAABOUYVWKCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDINRRG44TKMRSHA>.\r\nYou are receiving this because you were mentioned.Message ID: ***@***.***>\r\n\r\n", "I can do Swedish if its needed?", "Yes! Of course, do you know how to contribute?", "> Yes! Of course, do you know how to contribute?\n\nNot really. There is some instruction at the top and I can try and see if I get it.", "Sure, let me know if you run into problems. Fastest way is Discord or matrix\r\n", "> Sure, let me know if you run into problems. Fastest way is Discord or matrix\r\n\r\nSo its done now. My first so please be gentle. I am learning :)\r\n", "Of course!", "> Of course!\r\n\r\ni have uploaded the new json file to my test system and it seems to work as it should. ", "I can do Persian\r\ndo you need it ?\r\n", "Yeah! Make a PR", "I'm doing the Arabic translation, is it needed ?", "> I'm doing the Arabic translation, is it needed ?\r\n\r\nAlways!", "Hey. I translate the Thai language. I made the PR.", "I can do Malay translation, need any?", "> I can do Malay translation, need any?\n\nYou are very welcome! Look at the instructions above and submit a PR. You can ask for help in Discord (or Matrix) or here.", "Hi @donaldzou Thank you for starting this project! really helped me out a lot in managing my WG peers, I'd like to contribute a bit by adding Bahasa Indonesia to the language localization, please help to review my PR #722, cheers!", "Hello, I would be happy to contribute by translating the project into Romanian. Based on my previous experience, I believe there's always a need for additional language support. I will begin contributing soon, if that???s okay.\nAll the best!", "This issue has not been updated for 20 days", "I will update the thai translation soon. please wait.", "> I will update the thai translation soon. please wait.\n\nThanks!", "@donaldzou Added a PR for PT-BR translation: #817 \n\n@NOXCIS @velrino You mentioned helping with Portuguese. Would be great to have you review my PR." ],
      "repository" : {
        "description" : "Simple dashboard for WireGuard VPN written in Python & Vue.js",
        "homepage" : "https://wgdashboard.dev",
        "name" : "WGDashboard",
        "fullName" : "donaldzou/WGDashboard",
        "htmlUrl" : "https://github.com/donaldzou/WGDashboard",
        "gitUrl" : "git://github.com/donaldzou/WGDashboard.git",
        "sshUrl" : "git@github.com:donaldzou/WGDashboard.git",
        "cloneUrl" : "https://github.com/donaldzou/WGDashboard.git",
        "owner" : {
          "login" : "donaldzou",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 351,
        "stargazersCount" : 2560,
        "watchersCount" : 2560,
        "size" : 45945,
        "openIssuesCount" : 72,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-10T15:39:26Z",
        "languages" : {
          "Dockerfile" : 2981,
          "Shell" : 27944,
          "CSS" : 27584,
          "Vue" : 398180,
          "JavaScript" : 25092,
          "HTML" : 613,
          "Python" : 167644
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to localize WGDashboard by translating it into different languages, making it accessible to users who speak different languages.",
      "validationOrRequirement" : "Contributors must follow the instructions provided in the issue description, including cloning the main branch, copying language template files, translating the values, and adding the translations to active_languages.json. The verify_locale_files.py script must be run to check for missing or deprecated translations.",
      "attemptedFixes" : "Several contributors have attempted to translate WGDashboard into different languages, including Czech, Chinese (Simplified), Chinese (Traditional), Dutch, English, German, Italian, Polish, Russian, Spanish, Swedish, Turkish, Ukrainian, and others.",
      "otherNotes" : "Contributors are needed to translate WGDashboard into various languages. Instructions are provided in the issue description. The translation process involves cloning the main branch, copying language template files, translating the values, and adding the translations to active_languages.json. The verify_locale_files.py script is used to check for missing or deprecated translations. Contributors can ask for help in Discord or Matrix if needed.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284082
  }, {
    "issueDTO" : {
      "id" : 2447532492,
      "title" : "[FAQ] Is it possible to check that an object can be cast to the type (something like `\"test\" is B`)?",
      "url" : "https://github.com/kcl-lang/kcl-lang.io/issues/433",
      "repositoryName" : "kcl-lang/kcl-lang.io",
      "description" : "## General Question\r\n\r\nI want to check that an obkect can be cast to the type.\r\nCurrently I found only one method: get type name with `typeof` and compare with target type name and all of childs target type names.\r\n\r\nFor example:\r\n```\r\nschema A:\r\n    name: str\r\n\r\nschema B(A):\r\n    foo: str\r\n\r\nschema B1(B):\r\n    foo = \"1\"\r\n\r\nschema B2(B):\r\n    foo = \"2\"\r\n\r\nis_B = lambda o: A {\r\n    # Is it possible make this expression without compare with all child type names?\r\n    typeof(o) == \"B\" or typeof(o) == \"B1\" or typeof(o) == \"B2\"\r\n}\r\n\r\na = A {name = \"a\"}\r\n\r\nb = B {name = \"b\", foo = \"3\"}\r\n\r\nb1 = B1 {name = \"b1\"}\r\n\r\nb2 = B2 {name = \"b2\"}\r\n\r\ncheck_a = is_B(a)\r\ncheck_b = is_B(b)\r\ncheck_b1 = is_B(b1)\r\ncheck_b2 = is_B(b2)\r\n```\r\n",
      "updatedAt" : 1752235479.000000000,
      "user" : "bozaro",
      "userHtmlUrl" : "https://github.com/bozaro",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2458138?v=4",
      "labels" : [ "faq", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "KCL currently supports two types of type assertions: `typeof(foo) == \"B\"` or `foo as B`. Your requirement seems to be to directly obtain the reflection ability of subclasses of `B`?\r\n\r\nAs an aside, although implementing complex reflections for KCL is not that difficult, perhaps we can increase the ability of `runtime.subclasses()`. However, even in languages such as Go and Rust, obtaining a subtype of a type is not an easy task.", "In finally I wan create some logic for type `B` and all subtypes.\r\n\r\nSomething like:\r\n```\r\nis_B = lambda o: A {\r\n    # Is it possible make this expression without compare with all child type names?\r\n    typeof(o) == \"B\" or typeof(o) == \"B1\" or typeof(o) == \"B2\"\r\n}\r\nto_B = lambda o: A -> B {\r\n    # Is it possible make this expression without compare with all child type names?\r\n    _x: B = Undefined\r\n    if typeof(o) == \"B\":\r\n        _x = o as B\r\n\r\n    if typeof(o) == \"B1\":\r\n        _x = o as B1\r\n\r\n    if typeof(o) == \"B2\":\r\n        _x = o as B2\r\n\r\n    _x\r\n}\r\n\r\nbar = lambda a: A {\r\n    _x: B = Undefined\r\n    if is_B(a):\r\n        _x = to_B(a)\r\n\r\n    {\r\n        if _x:\r\n            test: _x.foo\r\n        \r\n    }\r\n}\r\n```\r\n\r\nIn my current task type hierary is something like: `endpoint declaration` -> `endpoint declaration with chart deploy info` -> `endpoint declaration with chart deploy info with project-specific default`", "I see. \r\n\r\nTo achieve this, there is currently no great way in KCL. Possible solutions in the future:\r\n\r\n+ Use advanced API of runtime reflection in KCL code to obtain B and all subtypes of B e.g. `runtime.subtypes(A)`\r\n+ Obtain B and all subtypes of B through static analysis through `GetSchemaTypeMapping` API, and then generate `is_B` and `to_B` functions.", "Would this support casting an object imported from a file and yaml decoded as an object? ie:\n\n```python\nyaml.decode(file.open(\"myfile.yaml\")) as MyObject\n```", "You can just use.\n\n```python\nobj: MyObject = yaml.decode(file.open(\"myfile.yaml\"))\n```" ],
      "repository" : {
        "description" : "KCL Website and Documentation Repo",
        "homepage" : "https://kcl-lang.io",
        "name" : "kcl-lang.io",
        "fullName" : "kcl-lang/kcl-lang.io",
        "htmlUrl" : "https://github.com/kcl-lang/kcl-lang.io",
        "gitUrl" : "git://github.com/kcl-lang/kcl-lang.io.git",
        "sshUrl" : "git@github.com:kcl-lang/kcl-lang.io.git",
        "cloneUrl" : "https://github.com/kcl-lang/kcl-lang.io.git",
        "owner" : {
          "login" : "kcl-lang",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 49,
        "stargazersCount" : 18,
        "watchersCount" : 18,
        "size" : 267623,
        "openIssuesCount" : 28,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T12:11:43Z",
        "languages" : {
          "TypeScript" : 42328,
          "PowerShell" : 20579,
          "Dockerfile" : 209,
          "Shell" : 40368,
          "CSS" : 27657,
          "Rust" : 5046,
          "TeX" : 16536,
          "Makefile" : 3244,
          "JavaScript" : 25810,
          "Go" : 2036,
          "HTML" : 7138
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to check if an object can be cast to a specific type, and to know if there's a way to do this without comparing with all child type names.",
      "validationOrRequirement" : "The author wants to check that an object can be cast to the type, and wants to know if there's a way to do this without comparing with all child type names. The author also mentions a requirement to create some logic for type B and all subtypes.",
      "attemptedFixes" : "The author has tried to implement a solution using typeof and comparing with target type name and all of child target type names, but wants to know if there's a better way. The author also mentions a lambda function is_B that checks if an object can be cast to type B, and a lambda function to_B that attempts to cast an object to type B.",
      "otherNotes" : "The issue is related to checking if an object can be cast to a specific type, and the author wants to know if there's a way to do this without comparing with all child type names. The author also mentions a current task involving type hierarchy and sees no great way to achieve this in KCL. Possible solutions mentioned include using advanced API of runtime reflection or obtaining the subtypes through static analysis.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284090
  }, {
    "issueDTO" : {
      "id" : 2830474229,
      "title" : "Add migration guide from Training Operator to Kubeflow Trainer V2",
      "url" : "https://github.com/kubeflow/trainer/issues/2412",
      "repositoryName" : "kubeflow/trainer",
      "description" : "Ref: https://github.com/kubeflow/training-operator/issues/2170\n\nWe should add user guide on how to migrate from Kubeflow Training Operator to Kubeflow Trainer V2.\n\n\ncc @varodrig \n\n/area docs\n/good-first-issue\n",
      "updatedAt" : 1752235393.000000000,
      "user" : "andreyvelich",
      "userHtmlUrl" : "https://github.com/andreyvelich",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/31112157?v=4",
      "labels" : [ "help wanted", "area/docs", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@andreyvelich: \n\tThis request has been marked as suitable for new contributors.\n\nPlease ensure the request meets the requirements listed [here](https://git.k8s.io/community/contributors/guide/help-wanted.md#good-first-issue).\n\nIf this request no longer meets these requirements, the label can be removed\nby commenting with the `/remove-good-first-issue` command.\n\n\n<details>\n\nIn response to [this](https://github.com/kubeflow/training-operator/issues/2412):\n\n>Ref: https://github.com/kubeflow/training-operator/issues/2170\n>\n>We should add user guide on how to migrate from Kubeflow Training Operator to Kubeflow Trainer V2.\n>\n>\n>cc @varodrig \n>\n>/area docs\n>/good-first-issue\n>\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>", "/assign", "Hi @akagami-harsh, do you still work on this issue or we can search for new contributors ?", "Apologies for the delay! I got caught up with other tasks, but I???m back on it now and will try to submit a PR as soon as possible.", "No worries, if you want we can delegate this task to other contributors.\nWe also need to create a lot of docs for Kubeflow Trainer cluster operators, feel free to create separate issues if you want to propose something!\n", "/unassign", "/assign", "/unassign\n", "I would like to take this up, I'm a new contributor so would love any advice about the recommended solution and potential steps. @andreyvelich ", "/assign", "@andreyvelich Since PR #3958 is already approved, it seems we can close this issue. If there are any pending tasks or areas where I can contribute, please let me know where I might be able to jump in.", "@akiseakusa We still require to write a guide for user migration from Training Operator v1 to Kubeflow Trainer V2: \nhttps://www.kubeflow.org/docs/components/trainer/operator-guides/migration/", "@andreyvelich I???m referring to PR [#2402](https://github.com/kubeflow-trainer/issues/2402) for kubeflow Trainer V2 migration guide. Are there any resources I should refer to for this?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.", "/remove-lifecycle stale", "Hi @akiseakusa, did you have a chance to work on this guide? We'd love to have this completed since we're planning to release trainer v2 soon.\nSome useful resources could be https://github.com/kubeflow/trainer/tree/master/docs/proposals/2170-kubeflow-trainer-v2, https://docs.google.com/document/d/1X1x2UwAYpKdQggbuSiF2l3i5Z3cQQztWLS-4ay7QD-Q/edit?usp=sharing. \nPlease let us know if you're willing to continue working on this or if we should look for other contributors to help out.", "Hi @kramaranya, thank you for following up! I???ve created a PR to add the migration guide as discussed: [kubeflow/website#4142](https://github.com/kubeflow/website/pull/4142). \n\nIt includes the PyTorchJob ??? TrainingRuntime migration example, a version compatibility table, and aligns with the Trainer v2 design proposal. Please let me know if there are any suggestions or changes needed. \n" ],
      "repository" : {
        "description" : "Distributed ML Training and Fine-Tuning on Kubernetes",
        "homepage" : "https://www.kubeflow.org/docs/components/training",
        "name" : "trainer",
        "fullName" : "kubeflow/trainer",
        "htmlUrl" : "https://github.com/kubeflow/trainer",
        "gitUrl" : "git://github.com/kubeflow/trainer.git",
        "sshUrl" : "git@github.com:kubeflow/trainer.git",
        "cloneUrl" : "https://github.com/kubeflow/trainer.git",
        "owner" : {
          "login" : "kubeflow",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 790,
        "stargazersCount" : 1841,
        "watchersCount" : 1841,
        "size" : 104992,
        "openIssuesCount" : 127,
        "subscribersCount" : 79,
        "pushedAt" : "2025-07-11T23:18:53Z",
        "languages" : {
          "Smarty" : 6426,
          "Dockerfile" : 4329,
          "Shell" : 12203,
          "Makefile" : 8547,
          "Go" : 627250,
          "Python" : 1890530
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a user guide on how to migrate from Kubeflow Training Operator to Kubeflow Trainer V2.",
      "validationOrRequirement" : "The guide should include a version compatibility table and align with the Trainer v2 design proposal.",
      "attemptedFixes" : "PR #4142 has been created to add the migration guide.",
      "otherNotes" : "The issue has been marked as suitable for new contributors, and the author has created a PR to add the migration guide.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284094
  }, {
    "issueDTO" : {
      "id" : 3220487799,
      "title" : "Missing Data on PowerCAT KPI",
      "url" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/issues/232",
      "repositoryName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
      "description" : "We started troubleshooting and noticed rows were dropped on Table AgentTranscript (existed in table ConversationTranscript) hence the PowerCAT KPI missed conversation records.\nWe verified Cloud Flows (Copy Child & Copy GrandChild) but none of them was failed lately.\n\nPlease help. Thanks...Pierra",
      "updatedAt" : 1752235304.000000000,
      "user" : "PierraWong",
      "userHtmlUrl" : "https://github.com/PierraWong",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/28659016?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @PierraWong ,\nJust to clarify ??? are you suggesting that records are being deleted from the AgentTranscript table?\n\nCould you please confirm whether:\n\n- The records were initially copied to the AgentTranscript table and later removed, or\n- The records exist in the ConversationTranscript table but were never copied to the AgentTranscript table?\n\nUnderstanding this distinction will help us narrow down the root cause. Please help us with any additional insights or observations you may have regarding the issue.\n", "[like]  Pierra Wong reacted to your message:\r\n________________________________\r\nFrom: SiddharthPoweCat ***@***.***>\r\nSent: Friday, July 11, 2025 5:42:36 AM\r\nTo: microsoft/Power-CAT-Copilot-Studio-Kit ***@***.***>\r\nCc: Pierra Wong ***@***.***>; Mention ***@***.***>\r\nSubject: [EXTERNAL] Re: [microsoft/Power-CAT-Copilot-Studio-Kit] Missing Data on PowerCAT KPI (Issue #232)\r\n\r\n\r\nCAUTION This email is from an external sender, be cautious with links and attachments.\r\n\r\n[https://avatars.githubusercontent.com/u/199201783?s=20&v=4]SiddharthPoweCat left a comment (microsoft/Power-CAT-Copilot-Studio-Kit#232)<https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/issues/232#issuecomment-3060654316>\r\n\r\nHi @PierraWong<https://github.com/PierraWong> ,\r\n\r\nIn the AgentTranscript table, we are using a plugin that performs an upsert operation ??? meaning it inserts records from the ConversationTranscript table only if they do not already exist. If a record is already present in the AgentTranscript table, the plugin is designed to skip it. This behavior could potentially explain the missing entries.\r\n\r\nTo help us gather more insights and troubleshoot this further, we invite you to join our upcoming Office Hours<https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/blob/main/OFFICEHOURS.md> session. We???ll walk through the issue and work toward a resolution.\r\n\r\n???\r\nReply to this email directly, view it on GitHub<https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/issues/232#issuecomment-3060654316>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AG2U2SCYO2MY4MF2ONRKG3T3H5FEZAVCNFSM6AAAAACBH6IZ2CVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZTANRQGY2TIMZRGY>.\r\nYou are receiving this because you were mentioned.Message ID: ***@***.***>\r\n\r\nSTATEMENT OF CONFIDENTIALITY The information contained in this email message and any attachments may be confidential and legally privileged and is intended for the use of the addressee(s) only. If you are not an intended recipient, please: (1) notify me immediately by replying to this message; (2) do not use, disseminate, distribute or reproduce any part of the message or any attachment; and (3) destroy all copies of this message and any attachments.\r\n" ],
      "repository" : {
        "description" : null,
        "homepage" : "",
        "name" : "Power-CAT-Copilot-Studio-Kit",
        "fullName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
        "htmlUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit",
        "gitUrl" : "git://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "sshUrl" : "git@github.com:microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "cloneUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 180,
        "watchersCount" : 180,
        "size" : 48361,
        "openIssuesCount" : 27,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-09T12:45:38Z",
        "languages" : {
          "C#" : 24850,
          "CSS" : 4368,
          "JavaScript" : 33528,
          "HTML" : 16742
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to identify the reason for missing data on PowerCAT KPI, specifically rows being dropped on Table AgentTranscript, and resolve the issue",
      "validationOrRequirement" : "The plugin used in AgentTranscript table performs an upsert operation, inserting records from ConversationTranscript only if they do not already exist, and skipping records already present in AgentTranscript",
      "attemptedFixes" : "None mentioned, but the team is working to gather more insights and troubleshoot the issue",
      "otherNotes" : "The issue is about missing data on PowerCAT KPI, specifically rows being dropped on Table AgentTranscript, which is a copy of ConversationTranscript. The plugin used in AgentTranscript performs an upsert operation, which could explain the missing entries. An upcoming Office Hours session is invited to troubleshoot the issue further.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284099
  }, {
    "issueDTO" : {
      "id" : 3222643745,
      "title" : "feat(bin): support combined up- and download benchmark",
      "url" : "https://github.com/mozilla/neqo/issues/2792",
      "repositoryName" : "mozilla/neqo",
      "description" : "Today, when a server receives a POST, it will read all data off the stream till the end, and then close the stream, sending nothing but a `200` in return.\n\nhttps://github.com/mozilla/neqo/blob/7c7f1c321e86f395a5276ba26e89dfd5ce339135/neqo-bin/src/server/http3.rs#L156-L170\n\nIn case the client requested a response via the `/<some-number-of-bytes-to-respond-with>` pattern, the server ignores it.\n\nhttps://github.com/mozilla/neqo/blob/7c7f1c321e86f395a5276ba26e89dfd5ce339135/neqo-bin/src/server/http3.rs#L123-L124\n\nIn other words, `neqo-bin/src/server/http3.rs` does not support a combined up- and download.\n\nFixing this, I assume, is more about eliminating this pitfall than about providing value through a combined upload and download benchmark.\n",
      "updatedAt" : 1752235113.000000000,
      "user" : "mxinden",
      "userHtmlUrl" : "https://github.com/mxinden",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7047859?v=4",
      "labels" : [ "p3", "bug", "help wanted", "good first issue", "task-tiny" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Neqo, the Mozilla Firefox implementation of QUIC in Rust",
        "homepage" : "https://firefox-source-docs.mozilla.org/networking/http/http3.html",
        "name" : "neqo",
        "fullName" : "mozilla/neqo",
        "htmlUrl" : "https://github.com/mozilla/neqo",
        "gitUrl" : "git://github.com/mozilla/neqo.git",
        "sshUrl" : "git@github.com:mozilla/neqo.git",
        "cloneUrl" : "https://github.com/mozilla/neqo.git",
        "owner" : {
          "login" : "mozilla",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 135,
        "stargazersCount" : 1991,
        "watchersCount" : 1991,
        "size" : 10236,
        "openIssuesCount" : 125,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T07:02:57Z",
        "languages" : {
          "Dockerfile" : 1925,
          "Shell" : 8631,
          "Rust" : 3074873,
          "C" : 3698,
          "Python" : 8260
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support combined up- and download benchmark in neqo-bin/src/server/http3.rs by eliminating the pitfall where the server ignores the client's request for a response.",
      "validationOrRequirement" : "The server should not ignore the client's request for a response via the `/<some-number-of-bytes-to-respond-with>` pattern.",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is about supporting combined up- and download benchmark in neqo-bin/src/server/http3.rs, but it's more about eliminating a pitfall than providing value through a combined upload and download benchmark.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284104
  }, {
    "issueDTO" : {
      "id" : 3207692712,
      "title" : "Make log location configurable for multithreading lock contention",
      "url" : "https://github.com/openssl/openssl/issues/27975",
      "repositoryName" : "openssl/openssl",
      "description" : "Could we consider allowing the output file to be configurable via environment variable or config, rather than hardcoding it?\r\n\r\n_Originally posted by @shahsb in https://github.com/openssl/openssl/pull/27884#discussion_r2180755197_\r\n            ",
      "updatedAt" : 1752235014.000000000,
      "user" : "shahsb",
      "userHtmlUrl" : "https://github.com/shahsb",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20738488?v=4",
      "labels" : [ "triaged: feature", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I think opening an issue for any suggestion you have is not useful. Nobody will probably ever do anything with this. It's a debug tool that's probably only ever going to be used by someone working on OpenSSL." ],
      "repository" : {
        "description" : "TLS/SSL and crypto library",
        "homepage" : "https://www.openssl.org",
        "name" : "openssl",
        "fullName" : "openssl/openssl",
        "htmlUrl" : "https://github.com/openssl/openssl",
        "gitUrl" : "git://github.com/openssl/openssl.git",
        "sshUrl" : "git@github.com:openssl/openssl.git",
        "cloneUrl" : "https://github.com/openssl/openssl.git",
        "owner" : {
          "login" : "openssl",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 10654,
        "stargazersCount" : 27938,
        "watchersCount" : 27938,
        "size" : 293332,
        "openIssuesCount" : 2015,
        "subscribersCount" : 1027,
        "pushedAt" : "2025-07-11T16:53:16Z",
        "languages" : {
          "C++" : 645140,
          "C" : 30309232,
          "CMake" : 12086,
          "DIGITAL Command Language" : 5687,
          "M4" : 46625,
          "Perl" : 9040625,
          "Dockerfile" : 1860,
          "Shell" : 121570,
          "sed" : 502,
          "Ruby" : 1344,
          "Assembly" : 194659,
          "eC" : 7476,
          "Raku" : 203883,
          "Python" : 35171
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Make log location configurable for multithreading lock contention, allowing the output file to be configurable via environment variable or config instead of hardcoding it.",
      "validationOrRequirement" : "None mentioned, but the issue is labeled as 'good first issue', implying that it may be suitable for new contributors.",
      "attemptedFixes" : "No specific fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue was originally posted in a pull request discussion, and the author suggests allowing the output file to be configurable via environment variable or config instead of hardcoding it.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284108
  }, {
    "issueDTO" : {
      "id" : 2099020026,
      "title" : "changing boards and firmware should trigger parameters re-download",
      "url" : "https://github.com/bluerobotics/BlueOS/issues/2343",
      "repositoryName" : "bluerobotics/BlueOS",
      "description" : "I'm not 100% if the firmware change does it, but the board change does not trigger it.",
      "updatedAt" : 1752234915.000000000,
      "user" : "Williangalvani",
      "userHtmlUrl" : "https://github.com/Williangalvani",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4013804?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The open source platform for ROV, USV, robotic system operation, development, and expansion.",
        "homepage" : "https://blueos.cloud/docs/",
        "name" : "BlueOS",
        "fullName" : "bluerobotics/BlueOS",
        "htmlUrl" : "https://github.com/bluerobotics/BlueOS",
        "gitUrl" : "git://github.com/bluerobotics/BlueOS.git",
        "sshUrl" : "git@github.com:bluerobotics/BlueOS.git",
        "cloneUrl" : "https://github.com/bluerobotics/BlueOS.git",
        "owner" : {
          "login" : "bluerobotics",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 102,
        "stargazersCount" : 260,
        "watchersCount" : 260,
        "size" : 40118,
        "openIssuesCount" : 537,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-11T10:49:37Z",
        "languages" : {
          "TypeScript" : 240785,
          "Dockerfile" : 5228,
          "Shell" : 72273,
          "CSS" : 1820,
          "Vue" : 914193,
          "JavaScript" : 10053,
          "Lua" : 4441,
          "HTML" : 28674,
          "Python" : 747916
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to ensure that changing boards or firmware triggers the re-download of parameters in BlueOS.",
      "validationOrRequirement" : "The issue requires verification of whether firmware changes trigger the re-download of parameters, and if not, a fix needs to be implemented.",
      "attemptedFixes" : "No attempted fixes or blockers have been mentioned in the description or comments.",
      "otherNotes" : "The issue is related to BlueOS, specifically the re-download of parameters when changing boards or firmware. The author, Williangalvani, is unsure if firmware changes trigger the re-download, but knows that board changes do not.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284112
  }, {
    "issueDTO" : {
      "id" : 3222637793,
      "title" : "Add/Explore Records API",
      "url" : "https://github.com/coreyjs/nhl-api-py/issues/110",
      "repositoryName" : "coreyjs/nhl-api-py",
      "description" : "This endpoint in particular.  I dont know where it was found, but there could be more.\n\nhttps://records.nhl.com/site/api/player",
      "updatedAt" : 1752234912.000000000,
      "user" : "coreyjs",
      "userHtmlUrl" : "https://github.com/coreyjs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1228838?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "NHL API (2025 Updated) - For accessing most of the NHL EDGE statistical API's, scores, schedules and more",
        "homepage" : "",
        "name" : "nhl-api-py",
        "fullName" : "coreyjs/nhl-api-py",
        "htmlUrl" : "https://github.com/coreyjs/nhl-api-py",
        "gitUrl" : "git://github.com/coreyjs/nhl-api-py.git",
        "sshUrl" : "git@github.com:coreyjs/nhl-api-py.git",
        "cloneUrl" : "https://github.com/coreyjs/nhl-api-py.git",
        "owner" : {
          "login" : "coreyjs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 67,
        "watchersCount" : 67,
        "size" : 249,
        "openIssuesCount" : 3,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T12:15:21Z",
        "languages" : {
          "Python" : 107340
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add/Explore Records API endpoint",
      "validationOrRequirement" : "Unknown endpoint origin, possibly more endpoints to explore",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to an endpoint found at https://records.nhl.com/site/api/player, and it's unclear where it was found, but it's believed there could be more.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284114
  }, {
    "issueDTO" : {
      "id" : 3011441714,
      "title" : "Order Agents in Library by \"most recently ran\"",
      "url" : "https://github.com/Significant-Gravitas/AutoGPT/issues/9860",
      "repositoryName" : "Significant-Gravitas/AutoGPT",
      "description" : "Currently the Agents list in the Library is ordered based on time of last edit to an agent in the builder, instead this should be ordered by the time of last execution. (all executions should be counted, not just those manually triggered through the GUI).",
      "updatedAt" : 1752234912.000000000,
      "user" : "Torantulino",
      "userHtmlUrl" : "https://github.com/Torantulino",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22963551?v=4",
      "labels" : [ "Improvement", "UI", "platform/frontend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.",
        "homepage" : "https://agpt.co",
        "name" : "AutoGPT",
        "fullName" : "Significant-Gravitas/AutoGPT",
        "htmlUrl" : "https://github.com/Significant-Gravitas/AutoGPT",
        "gitUrl" : "git://github.com/Significant-Gravitas/AutoGPT.git",
        "sshUrl" : "git@github.com:Significant-Gravitas/AutoGPT.git",
        "cloneUrl" : "https://github.com/Significant-Gravitas/AutoGPT.git",
        "owner" : {
          "login" : "Significant-Gravitas",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 45864,
        "stargazersCount" : 176830,
        "watchersCount" : 176830,
        "size" : 262609,
        "openIssuesCount" : 198,
        "subscribersCount" : 1557,
        "pushedAt" : "2025-07-11T23:24:03Z",
        "languages" : {
          "Jinja" : 31626,
          "C++" : 23419,
          "CSS" : 9008,
          "C" : 1425,
          "CMake" : 18862,
          "PLpgSQL" : 44427,
          "HTML" : 3023,
          "Kotlin" : 140,
          "TypeScript" : 1441508,
          "Dockerfile" : 4782,
          "Shell" : 17650,
          "Batchfile" : 4101,
          "JavaScript" : 15888,
          "Objective-C" : 38,
          "Swift" : 2384,
          "Ruby" : 2803,
          "Elixir" : 1068,
          "Python" : 3328219,
          "Dart" : 203562
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Order agents in the library by the time of last execution, including all executions.",
      "validationOrRequirement" : "The order should be based on the time of last execution, including all executions, not just those manually triggered through the GUI.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about ordering agents in the library by the time of last execution, not by the time of last edit to an agent in the builder. This should include all executions, not just those manually triggered through the GUI.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284118
  }, {
    "issueDTO" : {
      "id" : 1802877417,
      "title" : "version-chooser: Catch up with others services",
      "url" : "https://github.com/bluerobotics/BlueOS/issues/1866",
      "repositoryName" : "bluerobotics/BlueOS",
      "description" : "Remove yaml and using the same api libraries that we are using ",
      "updatedAt" : 1752234843.000000000,
      "user" : "patrickelectric",
      "userHtmlUrl" : "https://github.com/patrickelectric",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1215497?v=4",
      "labels" : [ "good first issue", "refactor" ],
      "state" : "OPEN",
      "comments" : [ "We should move from aiohttp to fastapi" ],
      "repository" : {
        "description" : "The open source platform for ROV, USV, robotic system operation, development, and expansion.",
        "homepage" : "https://blueos.cloud/docs/",
        "name" : "BlueOS",
        "fullName" : "bluerobotics/BlueOS",
        "htmlUrl" : "https://github.com/bluerobotics/BlueOS",
        "gitUrl" : "git://github.com/bluerobotics/BlueOS.git",
        "sshUrl" : "git@github.com:bluerobotics/BlueOS.git",
        "cloneUrl" : "https://github.com/bluerobotics/BlueOS.git",
        "owner" : {
          "login" : "bluerobotics",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 102,
        "stargazersCount" : 260,
        "watchersCount" : 260,
        "size" : 40118,
        "openIssuesCount" : 537,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-11T10:49:37Z",
        "languages" : {
          "TypeScript" : 240785,
          "Dockerfile" : 5228,
          "Shell" : 72273,
          "CSS" : 1820,
          "Vue" : 914193,
          "JavaScript" : 10053,
          "Lua" : 4441,
          "HTML" : 28674,
          "Python" : 747916
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove yaml and use the same api libraries that we are using",
      "validationOrRequirement" : "refactor",
      "attemptedFixes" : "",
      "otherNotes" : "We should move from aiohttp to fastapi",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284120
  }, {
    "issueDTO" : {
      "id" : 1114227266,
      "title" : "core: frontend: stores: Files have different name conventions ",
      "url" : "https://github.com/bluerobotics/BlueOS/issues/737",
      "repositoryName" : "bluerobotics/BlueOS",
      "description" : "![image](https://user-images.githubusercontent.com/1215497/151036941-d09653ab-6873-4688-b0a8-0f91f292b73b.png)\r\n",
      "updatedAt" : 1752234804.000000000,
      "user" : "patrickelectric",
      "userHtmlUrl" : "https://github.com/patrickelectric",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1215497?v=4",
      "labels" : [ "core", "good first issue", "refactor", "P3 - Low priority" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The open source platform for ROV, USV, robotic system operation, development, and expansion.",
        "homepage" : "https://blueos.cloud/docs/",
        "name" : "BlueOS",
        "fullName" : "bluerobotics/BlueOS",
        "htmlUrl" : "https://github.com/bluerobotics/BlueOS",
        "gitUrl" : "git://github.com/bluerobotics/BlueOS.git",
        "sshUrl" : "git@github.com:bluerobotics/BlueOS.git",
        "cloneUrl" : "https://github.com/bluerobotics/BlueOS.git",
        "owner" : {
          "login" : "bluerobotics",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 102,
        "stargazersCount" : 260,
        "watchersCount" : 260,
        "size" : 40118,
        "openIssuesCount" : 537,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-11T10:49:37Z",
        "languages" : {
          "TypeScript" : 240785,
          "Dockerfile" : 5228,
          "Shell" : 72273,
          "CSS" : 1820,
          "Vue" : 914193,
          "JavaScript" : 10053,
          "Lua" : 4441,
          "HTML" : 28674,
          "Python" : 747916
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor the frontend stores to have consistent name conventions.",
      "validationOrRequirement" : "No specific validations or requirements are mentioned in the issue.",
      "attemptedFixes" : "No attempted fixes or blockers are mentioned in the issue.",
      "otherNotes" : "The issue is accompanied by an image, but there is no additional context provided in the description or comments.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284123
  }, {
    "issueDTO" : {
      "id" : 2891891027,
      "title" : "\uD83D\uDC1ERandomly, whenever i reply to a comment, i get \"/video\" prefixed to the message.",
      "url" : "https://github.com/code-charity/youtube/issues/2837",
      "repositoryName" : "code-charity/youtube",
      "description" : "### Concise Description\n\n![Image](https://github.com/user-attachments/assets/d4f579cc-e09d-483f-86e4-d28742b84156)\n\n### Browser/s\n\nFirefox\n\n### Other Browser:\n\nNone.\n\n### 'Steps to reproduce' - Which of our features is required for the bug to happen?\n\nReply to any comment. It happens randomly.\n\n### Since when?\n\nSince the plugin was installed.\n\n### Does the bug still happen when you log out of YouTube?\n\nN/A\n\n### ..No? Then please paste your yt.config_.EXPERIMENT_FLAGS. Twice (With the error & Without)\n\n_No response_\n\n### Are any errors or related log-messages shown in the Browser-Console? (F12)\n\nNo\n\n### Tested as the only active extension? (incognito mode or another browser users):\n\nNo (happens too randomly to do so)\n\n### Expected preferred behavior:\n\n_No response_\n\n### ImprovedTube Version\n\n4.1188\n\n### Your Settings (From the Extension's `???`-Hamburger menu > Settings > Backup & reset > Export settings)\n\n'{\"ambient_lighting\":false,\"below_player_pip\":false,\"blocklist_activate\":true,\"channel_compact_theme\":true,\"channel_default_tab\":\"/videos\",\"channel_trailer_autoplay\":false,\"chapters\":false,\"columns\":false,\"comments_sidebar\":true,\"comments_sidebar_scrollbars\":true,\"comments_sidebar_simple\":false,\"compactSpacing\":false,\"day_of_week\":true,\"description\":\"normal\",\"duration_with_speed\":true,\"forced_theater_mode\":false,\"header_hide_logo\":false,\"header_improve_logo\":true,\"header_position\":\"hover_on_video_page\",\"header_transparent\":false,\"header_transparent_alternative\":true,\"hide_sidebar\":false,\"improvedtube_home\":\"bubbles\",\"lastDarkTheme\":\"dark\",\"lastLightTheme\":\"custom\",\"pause_while_typing_on_youtube\":false,\"player_auto_cinema_mode\":false,\"player_cinema_mode_button\":false,\"player_color\":\"green\",\"player_crop_chapter_titles\":false,\"player_fit_to_win_button\":false,\"player_forced_volume\":false,\"player_hamburger_button\":false,\"player_hide_cards\":false,\"player_hide_endscreen\":true,\"player_hide_skip_overlay\":true,\"player_quality_without_focus\":\"disabled\",\"player_remaining_duration\":false,\"player_show_cards_on_mouse_hover\":false,\"player_transparent_background\":true,\"playlist_autoplay\":true,\"playlist_popup\":false,\"playlist_shuffle\":true,\"playlist_up_next_autoplay\":false,\"popup_ad\":true,\"red_dislike_button\":true,\"remove_black_bars\":false,\"sidebar_left\":false,\"squared_user_images\":true,\"theme\":\"dark\",\"theme_primary_color\":[23,23,23],\"theme_text_color\":[251,249,249],\"thumbnails_right\":false,\"transcript\":false,\"undo_the_new_sidebar\":false,\"remove_member_only\":true,\"related_videos\":\"normal\",\"relatedVideosPrev\":\"notTitles\",\"no_page_margin\":false,\"mark_watched_videos\":true}'\n\n### Your YouTube-Document\n\nFound no way to make it fit here. Too large.\n\n### OS / Device:\n\nWindows 10 x64 LTS",
      "updatedAt" : 1752234726.000000000,
      "user" : "NancokPS2",
      "userHtmlUrl" : "https://github.com/NancokPS2",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/55665720?v=4",
      "labels" : [ "Bug", "help wanted", "good first issue", "up-for-grabs" ],
      "state" : "OPEN",
      "comments" : [ "can i take this up?", "If there is any more info needed for this, i am happy to provide it.  \nAm i the only person to be affected by this?  \n  \nI think it is related to this setting:  \n\n<img width=\"337\" height=\"128\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/aaf73fc0-ccfe-43c5-9896-03ad361fbe6a\" />" ],
      "repository" : {
        "description" : "Open YouTube & Video browser-extension [top~1] Enrich your experience&choice!\uD83E\uDDF0200+options; clever features\uD83D\uDCCCset&forget\uD83D\uDCCCLongest-standing. Join\uD83E\uDDE9us?\uD83D\uDC68???\uD83D\uDC69???\uD83D\uDC67???\uD83D\uDC67  ??? {playback|content discovery|player|extra buttons|distractions|related videos|shorts|ads|quality|codec|full tab|full screen}",
        "homepage" : "http://improvedtube.com",
        "name" : "youtube",
        "fullName" : "code-charity/youtube",
        "htmlUrl" : "https://github.com/code-charity/youtube",
        "gitUrl" : "git://github.com/code-charity/youtube.git",
        "sshUrl" : "git@github.com:code-charity/youtube.git",
        "cloneUrl" : "https://github.com/code-charity/youtube.git",
        "owner" : {
          "login" : "code-charity",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 645,
        "stargazersCount" : 3834,
        "watchersCount" : 3834,
        "size" : 11908,
        "openIssuesCount" : 907,
        "subscribersCount" : 274,
        "pushedAt" : "2025-07-05T20:55:21Z",
        "languages" : {
          "CSS" : 282481,
          "JavaScript" : 535751,
          "HTML" : 4280,
          "Python" : 11326
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the issue where '/video' is randomly prefixed to the message when replying to a comment.",
      "validationOrRequirement" : "The issue requires the 'Reply to any comment' feature to reproduce.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The issue occurs randomly when replying to a comment, and the '/video' prefix is added to the message. The user has tried to reproduce the issue in incognito mode, but it still happens.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284127
  }, {
    "issueDTO" : {
      "id" : 3221105495,
      "title" : "\uD83D\uDEA8 Confetti celebration does not respect the \"Disable All Animations\" anymore",
      "url" : "https://github.com/johannesjo/super-productivity/issues/4736",
      "repositoryName" : "johannesjo/super-productivity",
      "description" : "### Version Used\n\n14.0.5 (EXE from github)\n\n### Expected Behavior\n\nThis might be a small issue, but until some major releases ago, before confetti celebration was introduced (or refactored), the celebration animation would respect the setting of Disable All Animations, meaning it would not play at all if we have this setting enabled (expected).\n\nI'm remoting into a work machine quite often and usually try to disable all animation types to reduce latency and frame stream glitches, so being able to disable them (as we could before) would be great.\n\nHowever, since the introduction of confetti animation, this setting does not work with it.\n\n### Current Behavior\n\nWhen enabling \"Disable All Animations\", user should not see the Confetti Celebration.\n\n### Steps to Reproduce\n\n1. Open Super Productivity and go to `Settings`;\n2. Under `Misc Settings`, toggle `Disable all animations` On;\n3. Go to `Today` view and click on `Finish Day`;\n4. The Confetti animation should not play in this scenario.\n\n### Can you reproduce this reliably?\n\nYes, I can reproduce it reliably.\n\n### Console Output\n\n```shell\n\n```",
      "updatedAt" : 1752234685.000000000,
      "user" : "Xlindvain",
      "userHtmlUrl" : "https://github.com/Xlindvain",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68164563?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thank you very much for opening up this issue! I am currently a bit overwhelmed by the many requests that arrive each week, so please forgive me, if I fail to respond personally. I am still very likely to at least skim read your request and I'll probably try to fix all (real) bugs if possible and I will likely review every single PR being made (please, give me a heads up if you intent to do so) and I will try to work on popular requests (please upvote via thumbs up on the original issue) whenever possible, but trying to respond to every single issue over the last years has been kind of draining and I need to adjust my approach for this project to remain fun for me and to make any progress with actually coding new stuff. Thanks for your understanding!" ],
      "repository" : {
        "description" : "Super Productivity is an advanced todo list app with integrated Timeboxing and time tracking capabilities. It also comes with integrations for Jira, GitLab, GitHub and Open Project.",
        "homepage" : "http://super-productivity.com",
        "name" : "super-productivity",
        "fullName" : "johannesjo/super-productivity",
        "htmlUrl" : "https://github.com/johannesjo/super-productivity",
        "gitUrl" : "git://github.com/johannesjo/super-productivity.git",
        "sshUrl" : "git@github.com:johannesjo/super-productivity.git",
        "cloneUrl" : "https://github.com/johannesjo/super-productivity.git",
        "owner" : {
          "login" : "johannesjo",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1136,
        "stargazersCount" : 14248,
        "watchersCount" : 14248,
        "size" : 95616,
        "openIssuesCount" : 483,
        "subscribersCount" : 131,
        "pushedAt" : "2025-07-11T20:14:09Z",
        "languages" : {
          "TypeScript" : 4915296,
          "Dockerfile" : 1591,
          "Java" : 1160,
          "CSS" : 43715,
          "Shell" : 2124,
          "SCSS" : 266700,
          "JavaScript" : 75679,
          "HTML" : 436946,
          "Ruby" : 46,
          "Kotlin" : 44578
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Confetti Celebration does not respect the 'Disable All Animations' setting anymore, causing it to play even when the setting is enabled.",
      "validationOrRequirement" : "The setting 'Disable All Animations' should not play the Confetti Celebration when enabled.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The author is overwhelmed by requests and may not respond personally, but will try to fix bugs and review PRs whenever possible.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284130
  }, {
    "issueDTO" : {
      "id" : 2507382310,
      "title" : "Calibration functionalities",
      "url" : "https://github.com/JeffSteinbok/hass-dreo/issues/184",
      "repositoryName" : "JeffSteinbok/hass-dreo",
      "description" : "Most of the oscillating ventilators have a calibrate functionality, would it be possible to have it available as a service/button?\r\nI could help with logs",
      "updatedAt" : 1752234578.000000000,
      "user" : "apocaliss92",
      "userHtmlUrl" : "https://github.com/apocaliss92",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/23080650?v=4",
      "labels" : [ "enhancement", "good first issue", "no-issue-activity" ],
      "state" : "OPEN",
      "comments" : [ "Just chiming in, another use case could be automating it -- my fan's calibration constantly drifts (within 10 minutes or so), and based on comments online it's a common issue with this model. With HA, you could do a periodic recalibration if this was implemented.\r\n\r\nI might give this a shot at some point.", "This issue stale." ],
      "repository" : {
        "description" : "Dreo Smart Device Integration for Home Assistant",
        "homepage" : "",
        "name" : "hass-dreo",
        "fullName" : "JeffSteinbok/hass-dreo",
        "htmlUrl" : "https://github.com/JeffSteinbok/hass-dreo",
        "gitUrl" : "git://github.com/JeffSteinbok/hass-dreo.git",
        "sshUrl" : "git@github.com:JeffSteinbok/hass-dreo.git",
        "cloneUrl" : "https://github.com/JeffSteinbok/hass-dreo.git",
        "owner" : {
          "login" : "JeffSteinbok",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 53,
        "stargazersCount" : 209,
        "watchersCount" : 209,
        "size" : 1001,
        "openIssuesCount" : 22,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-08T17:32:05Z",
        "languages" : {
          "Python" : 297723
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement calibrate functionality for oscillating ventilators, potentially with automation option.",
      "validationOrRequirement" : "Availability of calibrate functionality as a service/button, possibly with automation option.",
      "attemptedFixes" : "None mentioned in the comments.",
      "otherNotes" : "The calibrate functionality is requested for oscillating ventilators, with a use case for automating periodic recalibration to address a common issue with the model.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284133
  }, {
    "issueDTO" : {
      "id" : 990836431,
      "title" : "Doc: add an update/upgrade section",
      "url" : "https://github.com/volta-cli/volta/issues/1025",
      "repositoryName" : "volta-cli/volta",
      "description" : "Hi,\r\n\r\nI just realized there is no update/upgrade section in your doc. It could be nice to have clear command on how to update the software, specially if there is some breaking changes or whatever.",
      "updatedAt" : 1752234530.000000000,
      "user" : "yescapa",
      "userHtmlUrl" : "https://github.com/yescapa",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/75252617?v=4",
      "labels" : [ "docs", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I have the same need.", "By the way, you just have to re-run the install script which is `curl https://get.volta.sh | bash`.", "But what I need is a command that can detect the version of the installed package, similar to npm-g outdated", "So `volta --version` is your friend but there is no built-in function to check for available volta updates.", "> So `volta --version` is your friend but there is no built-in function to check for available volta updates.\r\n\r\nNo, no, what I need is a command like npm -g outdated.", "@JS-mark are you looking for the ability to check for when Volta itself has a new version available, or when packages you have installed *using* Volta are out of date? ", "To achieve an \"update volta and all global packages\" command I've setup an alias to simply re-run my Node install script:\r\n\r\nhttps://github.com/AlecRust/dotfiles/blob/master/scripts/node.sh\r\n\r\nThis is far from ideal, as it seems to reinstall each global package from scratch even if they are on the latest version.", "Volta not being able to \"upgrade interactively\" like npm/yarn already do is what refrain me from using Volta... too bad", "are there any plans to add commands like `volta outdated` and `volta upgrade` or something?", "There are not currently, but I think we would be very happy if someone wanted to design how that would work. I think it would be reasonably straightforward:\r\n\r\n- get the list of packages installed at the user level\r\n- check those for updates\r\n- update them on demand\r\n\r\nThe main thing that would be mildly annoying here is that in a na??ve implementation you would be issuing a *lot* of different API calls for that, because you need to ask for them across a bunch of different Node versions (the version they were installed with). Notionally, though, you could simplify that by just getting the installed versions and then doing a separate query against the npm API to find out what is outdated.\r\n\r\nIf someone wants to do that, let us know and I will turn this comment into the start of a new issue for that!", "@chriskrycho Hi! I???d love to work on this if it???s still open. I???m Alexander, a Rust backend developer." ],
      "repository" : {
        "description" : "Volta: JS Toolchains as Code. ???",
        "homepage" : "https://volta.sh",
        "name" : "volta",
        "fullName" : "volta-cli/volta",
        "htmlUrl" : "https://github.com/volta-cli/volta",
        "gitUrl" : "git://github.com/volta-cli/volta.git",
        "sshUrl" : "git@github.com:volta-cli/volta.git",
        "cloneUrl" : "https://github.com/volta-cli/volta.git",
        "owner" : {
          "login" : "volta-cli",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 292,
        "stargazersCount" : 12123,
        "watchersCount" : 12123,
        "size" : 67563,
        "openIssuesCount" : 321,
        "subscribersCount" : 50,
        "pushedAt" : "2025-07-11T14:20:35Z",
        "languages" : {
          "Dockerfile" : 609,
          "Shell" : 46537,
          "Rust" : 921229,
          "Batchfile" : 28
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add an update/upgrade section to the documentation for Volta, including a command to check for updates and upgrade Volta and its global packages.",
      "validationOrRequirement" : "The requirement is to provide a clear command on how to update the software, especially for breaking changes. There is also a mention of the need for a command like npm -g outdated to check for available updates.",
      "attemptedFixes" : "There are no direct fixes mentioned, but a potential solution is proposed to check for updates and upgrade Volta and its global packages.",
      "otherNotes" : "The issue is about adding an update/upgrade section to the documentation, specifically for Volta. There are comments about the lack of built-in commands for checking for updates, and a potential solution is proposed. The main goal is to provide a command to check for updates and upgrade Volta and its global packages.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284139
  }, {
    "issueDTO" : {
      "id" : 3222431028,
      "title" : "di-engine 0.5.3 requires numpy<2,>=1.18.0",
      "url" : "https://github.com/opendilab/DI-engine/issues/869",
      "repositoryName" : "opendilab/DI-engine",
      "description" : "- [ ] I have marked all applicable categories:\n    + [ ] exception-raising bug\n    + [ ] code design/refactor\n- [ ] I have mentioned version numbers, operating system and environment, where applicable:\n  ```python\n  import ding, torch, sys\n  print(ding.__version__, torch.__version__, sys.version, sys.platform)\n  ```\nPython 3.9.23 (main, Jun  5 2025, 13:40:20) \n[GCC 11.2.0] :: Anaconda, Inc. on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import ding,torch,sys\n>>> print(ding.__version__, torch.__version__, sys.version, sys.platform)\nv0.5.3 2.9.0.dev20250710+cu128 3.9.23 (main, Jun  5 2025, 13:40:20) \n[GCC 11.2.0] linux\n\nI am using NVIDIA 5060TI??? the pytorch require numpy>2.0??? but the di-engine 0.5.3 requires numpy  numpy<2,>=1.18.0",
      "updatedAt" : 1752234474.000000000,
      "user" : "Johnny-Zhang92",
      "userHtmlUrl" : "https://github.com/Johnny-Zhang92",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/35098184?v=4",
      "labels" : [ "env", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for your feedback. We will check the specifics and loosen the numpy version restriction." ],
      "repository" : {
        "description" : "OpenDILab Decision AI Engine. The Most Comprehensive Reinforcement Learning Framework B.P.",
        "homepage" : "https://di-engine-docs.readthedocs.io",
        "name" : "DI-engine",
        "fullName" : "opendilab/DI-engine",
        "htmlUrl" : "https://github.com/opendilab/DI-engine",
        "gitUrl" : "git://github.com/opendilab/DI-engine.git",
        "sshUrl" : "git@github.com:opendilab/DI-engine.git",
        "cloneUrl" : "https://github.com/opendilab/DI-engine.git",
        "owner" : {
          "login" : "opendilab",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 405,
        "stargazersCount" : 3480,
        "watchersCount" : 3480,
        "size" : 306367,
        "openIssuesCount" : 23,
        "subscribersCount" : 22,
        "pushedAt" : "2025-06-06T12:01:34Z",
        "languages" : {
          "Shell" : 8592,
          "Makefile" : 1610,
          "Python" : 8227336
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the compatibility issue between di-engine 0.5.3 and numpy versions.",
      "validationOrRequirement" : "numpy<2,>=1.18.0",
      "attemptedFixes" : "The author mentioned that the numpy version restriction will be loosened.",
      "otherNotes" : "The issue is related to the compatibility of di-engine 0.5.3 with numpy versions, where pytorch requires numpy>2.0 and di-engine requires numpy<2,>=1.18.0.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284143
  }, {
    "issueDTO" : {
      "id" : 3218232449,
      "title" : "Incorrect Translation for \"Add Organization\" Button on Role Page",
      "url" : "https://github.com/ohcnetwork/care_fe/issues/12841",
      "repositoryName" : "ohcnetwork/care_fe",
      "description" : "The \"Add Organization\" button on the Role,supplier,Governance page is displaying the raw translation key (add_organization) instead of the properly translated string.\n\n**Expected Behavior**:\nThe button should display a translated label such as \"Add Organization\", depending on the selected locale.\n\n**Current Behavior**:\nThe button displays: add_organization (likely the i18n key).\n\n**Screenshots**\n<img width=\"1595\" height=\"604\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a9be1ec6-f13a-4941-ac96-42ed193f6c8a\" />\n\n**Desktop (please complete the following information):**\n\n- OS: [e.g. iOS]\n- Browser [e.g. chrome, safari]\n- Version [e.g. 22]\n\n**Smartphone (please complete the following information):**\n\n- Device: [e.g. iPhone6]\n- OS: [e.g. iOS8.1]\n- Browser [e.g. stock browser, safari]\n- Version [e.g. 22]\n\n**Additional context**\nAdd any other context about the problem here.\n\n---\n\n### \uD83D\uDEA8 DO NOT EDIT BELOW THIS LINE \uD83D\uDEA8\n\n### Instructions for Requesting Assignment:\n\nTo request assignment, please clearly outline your solution and timeline by commenting on the issue using the format below:\n\n**Describe your solution clearly:**\nProvide a detailed explanation of your proposed solution, including your approach, key implementation steps, and relevant examples or references. Mention any dependencies, assumptions, or risks you foresee that might affect your timeline or implementation.\n\n**Expected Timeline:**\n- End date: [Expected submission date of a completed Pull Request]\n\n**Additional Context:**\nInclude any other relevant context, links, screenshots, or resources that support your proposed solution.\n\n> \uD83D\uDEA8 Your assignment may be unassigned if there is no activity or progress within the stated timeline unless communicated clearly and agreed upon.\n",
      "updatedAt" : 1752234395.000000000,
      "user" : "yadavshubham01",
      "userHtmlUrl" : "https://github.com/yadavshubham01",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/126192924?v=4",
      "labels" : [ "question", "needs-triage", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "good first issue ", "Hey @Jacobjeevan @rithviknishad,\nI noticed that several i18n keys are not displaying the correct translated labels in Admin panel . For example:\n- In Categories: advance_directive is shown as the key instead of the translated text.\n- In Resources: keys like charge_item, token_booking, and many more are also showing untranslated.\nI???d like to work on fixing this issue. Could you please assign it to me?\nETA : today", "@Jacobjeevan @rithviknishad , can I work on this issue,\n\n**Proposed Solution**\n\n- Change the label to add_organization_one which is correct key\n\n**ETA:** 1 hour from assignment \n", "Hey Team @rithviknishad @yadavshubham01, i would like to work on this issue \nETA : 30 min", "@Akhileswaran-K-R Assigned. ", "> Hey [@Jacobjeevan](https://github.com/Jacobjeevan) [@rithviknishad](https://github.com/rithviknishad), I noticed that several i18n keys are not displaying the correct translated labels in Admin panel . For example:\n> \n>     * In Categories: advance_directive is shown as the key instead of the translated text.\n> \n>     * In Resources: keys like charge_item, token_booking, and many more are also showing untranslated.\n>       I???d like to work on fixing this issue. Could you please assign it to me?\n>       ETA : today\n\nThere's a lot of places where keys need to be added - we are adding as we go (i.e if you are editing a file, add them then, than dedicating an issue for it).", "@Jacobjeevan  i think this will be resolve in this pr #12859", "Hi @Jacobjeevan, the issue is already resolved. Can I proceed with removing the label \"add_organization_one\" as it is not used anywhere", "@Akhileswaran-K-R  it used dynamic in code don't remove it" ],
      "repository" : {
        "description" : "Care is a Digital Public Good enabling TeleICU & Decentralised Administration of Healthcare Capacity across States.",
        "homepage" : "https://care.ohc.network",
        "name" : "care_fe",
        "fullName" : "ohcnetwork/care_fe",
        "htmlUrl" : "https://github.com/ohcnetwork/care_fe",
        "gitUrl" : "git://github.com/ohcnetwork/care_fe.git",
        "sshUrl" : "git@github.com:ohcnetwork/care_fe.git",
        "cloneUrl" : "https://github.com/ohcnetwork/care_fe.git",
        "owner" : {
          "login" : "ohcnetwork",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 834,
        "stargazersCount" : 537,
        "watchersCount" : 537,
        "size" : 55125,
        "openIssuesCount" : 219,
        "subscribersCount" : 20,
        "pushedAt" : "2025-07-11T14:40:03Z",
        "languages" : {
          "TypeScript" : 4936598,
          "Dockerfile" : 560,
          "CSS" : 7532,
          "JavaScript" : 9703,
          "HTML" : 3683
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The 'Add Organization' button on the Role,supplier,Governance page is displaying the raw translation key (add_organization) instead of the properly translated string.",
      "validationOrRequirement" : "The button should display a translated label such as 'Add Organization', depending on the selected locale.",
      "attemptedFixes" : "Proposed Solution: Change the label to add_organization_one which is correct key. ETA: 1 hour from assignment",
      "otherNotes" : "Several i18n keys are not displaying the correct translated labels in Admin panel. In Categories, advance_directive is shown as the key instead of the translated text. In Resources, keys like charge_item, token_booking, and many more are also showing untranslated.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284148
  }, {
    "issueDTO" : {
      "id" : 2765997399,
      "title" : "CER/WER metrics",
      "url" : "https://github.com/tracel-ai/burn/issues/2649",
      "repositoryName" : "tracel-ai/burn",
      "description" : "### Discussed in https://github.com/tracel-ai/burn/discussions/2643\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **pmalex** December 26, 2024</sup>\r\nIs it possible to use these metrics in burn? I'm not found any examples so far.</div>",
      "updatedAt" : 1752234075.000000000,
      "user" : "laggui",
      "userHtmlUrl" : "https://github.com/laggui",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7225623?v=4",
      "labels" : [ "feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @laggui ! I am new to Burn and thought working on an issue would be a nice way to learn how it works. Do you know if this issue is still relevant? thanks", "Yep, the metrics have not been implemented yet \uD83D\uDE42\n\nI am not sure how widely these are used, but you can also have a look at the [current metrics in `burn-train`](https://github.com/tracel-ai/burn/tree/main/crates/burn-train/src/metric) and check if any useful/common metrics are missing." ],
      "repository" : {
        "description" : "Burn is a next generation Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.",
        "homepage" : "https://burn.dev",
        "name" : "burn",
        "fullName" : "tracel-ai/burn",
        "htmlUrl" : "https://github.com/tracel-ai/burn",
        "gitUrl" : "git://github.com/tracel-ai/burn.git",
        "sshUrl" : "git@github.com:tracel-ai/burn.git",
        "cloneUrl" : "https://github.com/tracel-ai/burn.git",
        "owner" : {
          "login" : "tracel-ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 615,
        "stargazersCount" : 11529,
        "watchersCount" : 11529,
        "size" : 59354,
        "openIssuesCount" : 256,
        "subscribersCount" : 82,
        "pushedAt" : "2025-07-11T18:14:12Z",
        "languages" : {
          "C++" : 692,
          "Shell" : 256,
          "RenderScript" : 2,
          "Rust" : 6763013,
          "Python" : 192763
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To implement CER/WER metrics in Burn",
      "validationOrRequirement" : "None mentioned in the comments or description.",
      "attemptedFixes" : "None mentioned in the comments or description.",
      "otherNotes" : "The issue is still relevant, and the author is unsure about the usage of the metrics.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284151
  }, {
    "issueDTO" : {
      "id" : 1437265011,
      "title" : "Android Port Doesn't Handle Mouse Events Properly, Specifically Scroll Wheel",
      "url" : "https://github.com/codenameone/CodenameOne/issues/3657",
      "repositoryName" : "codenameone/CodenameOne",
      "description" : "Looking at the code we will probably need to add a listener to mouse events [here](https://github.com/codenameone/CodenameOne/blob/master/Ports/Android/src/com/codename1/impl/android/AndroidImplementation.java#L4232) and some handling similar to [this](https://github.com/codenameone/CodenameOne/blob/master/Ports/Android/src/com/codename1/impl/android/CodenameOneView.java#L443).\r\n\r\nAndroid docs have some discussion about the types of events available in newer versions of Android that should include those gestures [here](https://developer.android.com/guide/topics/large-screens/input-compatibility-large-screens#navigation).\r\n\r\nRFE based on [this reddit thread](https://www.reddit.com/r/cn1/comments/yn1mu1/windows_android/).",
      "updatedAt" : 1752233935.000000000,
      "user" : "shai-almog",
      "userHtmlUrl" : "https://github.com/shai-almog",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/67850168?v=4",
      "labels" : [ "your-first-pr", "Hacktoberfest", "help wanted", "good first issue", "up-for-grabs" ],
      "state" : "OPEN",
      "comments" : [ "In the simulator, the scroll wheel generates a down/drag/up sequence which tricks things that thought they were\r\nimplementing drag scrolling into working.  In a fresh start this ought to be tossed.  Given that android devices with\r\nkeyboards and mice are not a common thing now, I would favor starting over with an api like the native java.", "@shai-almog Hi, I am a first-time contributor. I would like to spend some time to look into this issue and crack it!", "codenameone isn't the most approachable crew for outside contributors.  Generally\r\nthe procedure is for you to do all the work on spec, and produce a pull request.", "@Tianfeng-Chen good luck. We're here for you.\r\n\r\n@ddyer0 get lost. Seriously. You literally asked for this feature and you're actively trying to discourage people who want to help. This has been your attitude in our community for a while now. Maybe that's why people don't want to help **you**.", "i wasn't trying to discourage him, I was pointing him in the direction to move.", "Hey, is this issue still open? I am very new to open source and think I might be able to help with this issue ", "I'm not sure. There's a PR that we somehow missed and didn't review. I just asked @shannah to review it again.", "hi, is the issue still open?", "It's still open. Steve reviewed the PR here: https://github.com/codenameone/CodenameOne/pull/3663\r\nBut no action was taken. If someone else wants to continue that's probably a good starting point.", "Hi, is this issue still open? I would like to contribute", "@ATC68 Yes.", "Is the issue still open??\n" ],
      "repository" : {
        "description" : "Cross-platform framework for building truly native mobile apps with Java or Kotlin. Write Once Run Anywhere support for iOS, Android, Desktop & Web.",
        "homepage" : "https://www.codenameone.com/",
        "name" : "CodenameOne",
        "fullName" : "codenameone/CodenameOne",
        "htmlUrl" : "https://github.com/codenameone/CodenameOne",
        "gitUrl" : "git://github.com/codenameone/CodenameOne.git",
        "sshUrl" : "git@github.com:codenameone/CodenameOne.git",
        "cloneUrl" : "https://github.com/codenameone/CodenameOne.git",
        "owner" : {
          "login" : "codenameone",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 420,
        "stargazersCount" : 1774,
        "watchersCount" : 1774,
        "size" : 223989,
        "openIssuesCount" : 632,
        "subscribersCount" : 103,
        "pushedAt" : "2025-07-06T13:21:16Z",
        "languages" : {
          "C#" : 1923833,
          "Java" : 26275187,
          "C++" : 73666,
          "Shell" : 18048,
          "CSS" : 2285,
          "C" : 272453,
          "Batchfile" : 222,
          "JavaScript" : 4054,
          "Objective-C" : 1149336,
          "PHP" : 2999,
          "HTML" : 254778
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to handle mouse events properly on Android, specifically scroll wheel, by adding a listener and handling similar to CodenameOneView.java#L443.",
      "validationOrRequirement" : "Add a listener to mouse events and handle similar to CodenameOneView.java#L443.",
      "attemptedFixes" : "A PR was created but not reviewed and no action was taken.",
      "otherNotes" : "The issue is about handling mouse events properly on Android, specifically scroll wheel, and has been discussed in Android docs and a Reddit thread. It's a good first issue and has been open for a while.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284155
  }, {
    "issueDTO" : {
      "id" : 2109337721,
      "title" : "bug: uninstaller not working when the `.bash_profile` is not a regular file.",
      "url" : "https://github.com/WasmEdge/WasmEdge/issues/3185",
      "repositoryName" : "WasmEdge/WasmEdge",
      "description" : "### Summary\n\nPlease check this issue:\r\nhttps://github.com/second-state/LlamaEdge/issues/100\r\n\r\nSomeone is running the `installer`. However, it will run the uninstaller first to remove the previous installation. Then, it encountered the bug.\n\n### Current State\n\n`sed: /Users/user/.bash_profile: in-place editing only works for regular files`\r\n\r\nI believe the error is caused by https://github.com/WasmEdge/WasmEdge/blob/master/utils/uninstall.sh#L254-L255\n\n### Expected State\n\nEverything is fine.\n\n### Reproduction steps\n\nRun the uninstaller on a machine which `.bash_profile` is not a regular file.\n\n### Screenshots\n\n![DESCRIPTION](LINK.png)\r\n\n\n### Any logs you want to share for showing the specific issue\n\n_No response_\n\n### Components\n\nOthers\n\n### WasmEdge Version or Commit you used\n\nmaster\n\n### Operating system information\n\nmacOS 14.2.1\n\n### Hardware Architecture\n\nx86_64\n\n### Compiler flags and options\n\nnone.",
      "updatedAt" : 1752233767.000000000,
      "user" : "hydai",
      "userHtmlUrl" : "https://github.com/hydai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2776756?v=4",
      "labels" : [ "bug", "help wanted", "c-Installer", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I see, macOS by default comes with BSD `sed` which does not work for non-regular files in place.", "Hi @SAtacker \r\nI have an idea. How about printing the message showing that users should remove some configuration by themselves if the `.bash_profile` is a symbolic file instead of running BSD `sed` on it? We should be able to detect the file type via the `-h` option to identify whether it's a regular or symbolic file.", "> Hi @SAtacker I have an idea. How about printing the message showing that users should remove some configuration by themselves if the `.bash_profile` is a symbolic file instead of running BSD `sed` on it? We should be able to detect the file type via the `-h` option to identify whether it's a regular or symbolic file.\r\n\r\nThat's a good way to approach this. Thanks!", "After doing some research, I found this is a pretty old issue on StackOverflow: https://stackoverflow.com/questions/5694228/sed-in-place-flag-that-works-both-on-mac-bsd-and-linux\r\n\r\nMaybe we only need to add `''` to MacOS for this.", "Hii @hydai ,\r\nWe can do like this if `.bash_profile` is a symbolic link (a shortcut to another file). If it is, it tells the user to update it manually. or If `.bash_profile` is a regular file (a standard file), the script uses `sed` to edit it. and for macOS, the `sed `command needs a slightly different format. the script will detects if it???s running on macOS and adjusts the `sed` command accordingly. And If `.bash_profile` is not a regular file or a symbolic link, the script tells the user to update it manually.\r\nCan we do like this?", "> Hii @hydai , We can do like this if `.bash_profile` is a symbolic link (a shortcut to another file). If it is, it tells the user to update it manually. or If `.bash_profile` is a regular file (a standard file), the script uses `sed` to edit it. and for macOS, the `sed `command needs a slightly different format. the script will detects if it???s running on macOS and adjusts the `sed` command accordingly. And If `.bash_profile` is not a regular file or a symbolic link, the script tells the user to update it manually. Can we do like this?\r\n\r\nThe error is triggered on macOS because of the different format. Letting the script detect the platform and using different ways to handle the condition should be enough.", "@hydai is it alright if i work on this?", "Sure", "@hydai  i have completed and tested the uninstaller on my local system but how do i go about creating a test? also how do i test specifically on intel macs or versions pre catalina because that seems to be where the bug is most prominent , also my current method of testing just has been to run ./install_v2.sh and then run the uninstall script , and read through the shell config to see if it worked. i hope that works", "> how do i go about creating a test? \n\nIt's on macOS. Additionally, according to the report, it will occur on both Intel and Apple Silicon platforms. The root cause of this issue is that the command usage of `sed` differs between macOS and Linux. See https://github.com/WasmEdge/WasmEdge/issues/3185#issuecomment-2187919503\n\nTherefore, you just need to create a .bash_profile on macOS and try running the installer and uninstaller to trigger it. It's acceptable to include these tests in the installer workflows to verify the fix." ],
      "repository" : {
        "description" : "WasmEdge is a lightweight, high-performance, and extensible WebAssembly runtime for cloud native, edge, and decentralized applications. It powers serverless apps, embedded functions, microservices, smart contracts, and IoT devices.",
        "homepage" : "https://WasmEdge.org",
        "name" : "WasmEdge",
        "fullName" : "WasmEdge/WasmEdge",
        "htmlUrl" : "https://github.com/WasmEdge/WasmEdge",
        "gitUrl" : "git://github.com/WasmEdge/WasmEdge.git",
        "sshUrl" : "git@github.com:WasmEdge/WasmEdge.git",
        "cloneUrl" : "https://github.com/WasmEdge/WasmEdge.git",
        "owner" : {
          "login" : "WasmEdge",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 870,
        "stargazersCount" : 9588,
        "watchersCount" : 9588,
        "size" : 25445,
        "openIssuesCount" : 191,
        "subscribersCount" : 103,
        "pushedAt" : "2025-07-10T07:36:34Z",
        "languages" : {
          "C++" : 6732347,
          "C" : 208003,
          "Rust" : 15711,
          "CMake" : 183781,
          "Objective-C++" : 840,
          "Makefile" : 1841,
          "WebAssembly" : 11799,
          "Kotlin" : 1732,
          "HCL" : 6111,
          "Dockerfile" : 30,
          "Shell" : 70366,
          "Linker Script" : 91,
          "JavaScript" : 245,
          "Nix" : 1453,
          "Python" : 57827
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to fix the uninstaller not working when the .bash_profile is not a regular file on macOS.",
      "validationOrRequirement" : "The script should detect if it's running on macOS and adjust the sed command accordingly. The script should also detect if .bash_profile is a regular file or a symbolic link and handle it accordingly.",
      "attemptedFixes" : "The idea is to print a message showing that users should remove some configuration by themselves if the .bash_profile is a symbolic file instead of running BSD sed on it. It's suggested to use the -h option to identify whether the file is a regular or symbolic file. It's also proposed to add '' to MacOS for this.",
      "otherNotes" : "The error is caused by the different format of sed command on macOS, and the issue is triggered on both Intel and Apple Silicon platforms.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284161
  }, {
    "issueDTO" : {
      "id" : 2890619163,
      "title" : "Improve the performance of pack_codes_into_bytes() - test_insert_jpg_lzwdecode",
      "url" : "https://github.com/py-pdf/fpdf2/issues/1380",
      "repositoryName" : "py-pdf/fpdf2",
      "description" : "Quoting: https://github.com/py-pdf/fpdf2/pull/1286#issuecomment-2491039241\n\n> I noticed today that the unit test `test_insert_jpg_lzwdecode` is quite slow to execute: ~78s on my computer.\n> \n> And 90% of this execution is spent in `pack_codes_into_bytes()` based on this quick test:\n> \n> ```\n> pip install pytest-profiling\n> pytest test/image/image_types/test_insert_images.py -k lzwdecode --profile\n> ```\n\nWe should make this code faster.",
      "updatedAt" : 1752233382.000000000,
      "user" : "Lucas-C",
      "userHtmlUrl" : "https://github.com/Lucas-C",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/925560?v=4",
      "labels" : [ "performance", "hacktoberfest", "research needed", "enhancement", "good first issue", "up-for-grabs" ],
      "state" : "OPEN",
      "comments" : [ "I was able to bring the time down from ~41s to ~0.6s with numpy. Is that something we can do?", "> I was able to bring the time down from ~41s to ~0.6s with numpy. Is that something we can do?\n\nThat???s an impressive improvement!\n\nIn this project, we strive to minimize external dependencies, especially for functionality that isn???t widely used. Since this is a test for a less commonly used function, adding a dependency like NumPy isn???t ideal by default.\n\nThat said, the performance gain is significant. If we can make NumPy an optional dependency (i.e., use it if it???s installed, and fall back to a pure Python implementation otherwise), then that???s definitely a yes.\n\nIf it turns out there???s no clean way to make it optional, we can bring it up with Lucas and discuss the trade-offs." ],
      "repository" : {
        "description" : "Simple PDF generation for Python",
        "homepage" : "https://py-pdf.github.io/fpdf2/",
        "name" : "fpdf2",
        "fullName" : "py-pdf/fpdf2",
        "htmlUrl" : "https://github.com/py-pdf/fpdf2",
        "gitUrl" : "git://github.com/py-pdf/fpdf2.git",
        "sshUrl" : "git@github.com:py-pdf/fpdf2.git",
        "cloneUrl" : "https://github.com/py-pdf/fpdf2.git",
        "owner" : {
          "login" : "py-pdf",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : true,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 280,
        "stargazersCount" : 1310,
        "watchersCount" : 1310,
        "size" : 396803,
        "openIssuesCount" : 63,
        "subscribersCount" : 20,
        "pushedAt" : "2025-07-07T18:43:29Z",
        "languages" : {
          "Jinja" : 5079,
          "Shell" : 3376,
          "HTML" : 1067,
          "Jupyter Notebook" : 7321,
          "Python" : 1783456
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve the performance of the `pack_codes_into_bytes()` function in the `test_insert_jpg_lzwdecode` unit test.",
      "validationOrRequirement" : "Minimize external dependencies, especially for functionality that isn???t widely used. Make numpy an optional dependency (use it if it???s installed, and fall back to a pure Python implementation otherwise) if possible.",
      "attemptedFixes" : "The author was able to bring the time down from ~41s to ~0.6s using numpy.",
      "otherNotes" : "The test execution is slow due to the `pack_codes_into_bytes()` function, which takes ~90% of the total execution time. The author was able to improve the time from ~41s to ~0.6s using numpy, but this is not ideal due to the external dependency.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284166
  }, {
    "issueDTO" : {
      "id" : 3002781570,
      "title" : "linter: bunch of small auto-fix missing",
      "url" : "https://github.com/oxc-project/oxc/issues/10477",
      "repositoryName" : "oxc-project/oxc",
      "description" : "### What version of Oxlint are you using?\n\n0.16.5\n\n### What command did you run?\n\noxlint --fix --fix-suggestions --quiet\n\n### What happened?\n\nMissing lot of quick auto-fixes:\n\n- [x] eslint-plugin-unicorn(prefer-number-properties): Use `Number.parseFloat` instead of the global `parseFloat` => Same for parseInt, isNaN #10693\n    - Should add `Number.` before `parseFloat`\n- [x] eslint(radix): Missing radix parameter https://github.com/oxc-project/oxc/pull/10652\n    - Should add `, 10` in the code as `Number.parseInt(str, 10)`\n- [x] eslint-plugin-unicorn(prefer-spread): Prefer the spread operator (`...`) over Array.from()\n    - Should replace `Array.from(store.getItems())` with `[...store.getItems()]` #10691 \n    - Should replace `store.getItems()?.concat(anotherItem) ?? [anotherItem]` with `[...store.getItems() ?? [], anotherItem]` // More complex\n- [ ] eslint-plugin-react(jsx-curly-brace-presence): Curly braces are unnecessary here\n    - Should replace `<div id={'my-div'} />` with `<div id=\"my-div\" />`\n- [x] eslint(require-await): Async function has no 'await' expression\n    - Should strip out `async` // Maybe a dangerous fix\n- [x] eslint-plugin-react(self-closing-comp): Unnecessary closing tag\n    - Should replace to self closing tag\n- [x]  eslint-plugin-react(jsx-no-useless-fragment): Fragments should contain more than one child. #10800\n    - Should replace to `<></>` with `null` `<>{something}</>` with `something`\n- [x] eslint(eqeqeq): Expected === and instead saw ==\n    - Should replace `==` to `===` #10499 \n- [ ] eslint-plugin-react(exhaustive-deps): React Hook useMyHook has a missing dependency myDep\n    - Should add to the dependencies array myDep\n- [ ] eslint-plugin-import(no-named-as-default): Module \"@testing-library/user-event\" has named export \"userEvent\"\n    - Should transform `import userEvent` to `import { userEvent }`\n- [ ] eslint-plugin-import(consistent-type-specifier-style): Prefer using a top-level type-only import instead of inline type specifiers.\n    - Should rework import according to config (here top-level)\n- [ ] eslint-plugin-react(jsx-curly-brace-presence): Curly braces are unnecessary here\n    - Should replace `<Comp foo={'bar'} />` to `<Comp foo=\"bar\" />`\n- [ ] eslint(arrow-body-style): Unexpected block statement surrounding arrow body; move the returned value immediately after the `=>`.\n    - Should remove body and inline return",
      "updatedAt" : 1752232761.000000000,
      "user" : "Hideman42",
      "userHtmlUrl" : "https://github.com/Hideman42",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/207526572?v=4",
      "labels" : [ "E-Help Wanted", "A-linter", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thank you for such a useful issue to help us improve!", "Just a heads up (since you mentioned youre using `--fix and --fix-suggestions` flags), `eqeqeq` should be a dangerous fix since just blindly changing `==` to `===` can change the logic.", "> Just a heads up (since you mentioned youre using `--fix and --fix-suggestions` flags), `eqeqeq` should be a dangerous fix since just blindly changing `==` to `===` can change the logic.\n\nI think this is fair to have it as dangerous fix. Something is weird tho, I went to the rules doc and it is tagged as auto-fixable (safe) and I checked the rule source it seem to have a fix implemented but with `oxlint --fix --fix-suggestions --fix-dangerously --quiet` it doesnt auto fix it. Do you also confirm in your try? ", "@Hideman42 I'll take a look at this. I think it is only safely auto fixable in some cases. But we could provide it as a dangerous fix in all cases.", "I added another usefull small auto-fix to the list, the eslint-plugin-react(exhaustive-deps) to add needed dependencies to the array.", "I'd like to pick up implementation of `eslint-plugin-react(exhaustive-deps)` fix. Need it to migrate projects from eslint to oxlint. Is it ok?", "> I'd like to pick up implementation of `eslint-plugin-react(exhaustive-deps)` fix. Need it to migrate projects from eslint to oxlint. Is it ok?\n\nyeah this is great, thank you", "I just added to the list some missing auto-fix that are very annoying and would be great time saver when migrating old projects up to quality.\n- eslint-plugin-import(no-named-as-default): Module \"@testing-library/user-event\" has named export \"userEvent\"\n- eslint-plugin-import(consistent-type-specifier-style): Prefer using a top-level type-only import instead of inline type specifiers.\n- eslint-plugin-react(jsx-curly-brace-presence): Curly braces are unnecessary here\n- eslint(arrow-body-style): Unexpected block statement surrounding arrow body; move the returned value immediately after the =>." ],
      "repository" : {
        "description" : "??? A collection of JavaScript tools written in Rust.",
        "homepage" : "https://oxc.rs",
        "name" : "oxc",
        "fullName" : "oxc-project/oxc",
        "htmlUrl" : "https://github.com/oxc-project/oxc",
        "gitUrl" : "git://github.com/oxc-project/oxc.git",
        "sshUrl" : "git@github.com:oxc-project/oxc.git",
        "cloneUrl" : "https://github.com/oxc-project/oxc.git",
        "owner" : {
          "login" : "oxc-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 609,
        "stargazersCount" : 15617,
        "watchersCount" : 15617,
        "size" : 476380,
        "openIssuesCount" : 224,
        "subscribersCount" : 67,
        "pushedAt" : "2025-07-11T22:11:25Z",
        "languages" : {
          "TypeScript" : 395630,
          "CoffeeScript" : 45,
          "Rust" : 17783289,
          "Astro" : 526,
          "JavaScript" : 1447235,
          "Vue" : 622,
          "Svelte" : 955,
          "Just" : 6403
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to identify and fix missing auto-fixes in the linter output, with a focus on improving the quality of the code and making it easier to maintain.",
      "validationOrRequirement" : "The user is using Oxlint 0.16.5 and ran the command `oxlint --fix --fix-suggestions --quiet`. The issue is about missing auto-fixes.",
      "attemptedFixes" : "The user tried to use the `--fix` and `--fix-suggestions` flags with `oxlint`, but some fixes were not applied, and there are concerns about the safety of some fixes.",
      "otherNotes" : "The issue is about missing auto-fixes from the linter, with specific examples of fixes that were not applied. There are also comments discussing the potential dangers of some fixes and the need for a more cautious approach.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284172
  }, {
    "issueDTO" : {
      "id" : 3222095487,
      "title" : "application_start_module interferes with gleam run -m command",
      "url" : "https://github.com/gleam-lang/gleam/issues/4771",
      "repositoryName" : "gleam-lang/gleam",
      "description" : "When `application_start_module` is configured in `gleam.toml`, running a specific module using `gleam run -m <module>` causes the application start module to interfere.\n\nSee discord discussion https://discord.com/channels/768594524158427167/1392886040385032245",
      "updatedAt" : 1752232435.000000000,
      "user" : "binajmen",
      "userHtmlUrl" : "https://github.com/binajmen",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15611419?v=4",
      "labels" : [ "help wanted", "good first issue", "priority:medium" ],
      "state" : "OPEN",
      "comments" : [ "Oh yes! This is a bug, sorry about that.\n\nhttps://github.com/gleam-lang/gleam/blob/bed57729dfed84c609f5b002c5337a76abcf96ae/compiler-core/templates/gleam%40%40main.erl#L22\n\nWe are ensuring the root application is started, but it should be the application that the module being run belongs to." ],
      "repository" : {
        "description" : "?????? A friendly language for building type-safe, scalable systems!",
        "homepage" : "https://gleam.run",
        "name" : "gleam",
        "fullName" : "gleam-lang/gleam",
        "htmlUrl" : "https://github.com/gleam-lang/gleam",
        "gitUrl" : "git://github.com/gleam-lang/gleam.git",
        "sshUrl" : "git@github.com:gleam-lang/gleam.git",
        "cloneUrl" : "https://github.com/gleam-lang/gleam.git",
        "owner" : {
          "login" : "gleam-lang",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 828,
        "stargazersCount" : 19565,
        "watchersCount" : 19565,
        "size" : 22037,
        "openIssuesCount" : 185,
        "subscribersCount" : 87,
        "pushedAt" : "2025-07-09T19:42:30Z",
        "languages" : {
          "PowerShell" : 723,
          "CSS" : 23755,
          "Rust" : 4508238,
          "Makefile" : 5266,
          "HTML" : 28439,
          "Erlang" : 19189,
          "TypeScript" : 2024,
          "Dockerfile" : 1352,
          "Shell" : 8917,
          "Cap'n Proto" : 6580,
          "Gleam" : 101625,
          "JavaScript" : 101426,
          "Elixir" : 744
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "application_start_module interferes with gleam run -m command",
      "validationOrRequirement" : "none mentioned",
      "attemptedFixes" : "ensuring the root application is started, but it should be the application that the module being run belongs to",
      "otherNotes" : "https://github.com/gleam-lang/gleam/blob/bed57729dfed84c609f5b002c5337a76abcf96ae/compiler-core/templates/gleam%40%40main.erl#L22",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284177
  }, {
    "issueDTO" : {
      "id" : 3222510692,
      "title" : "Permit adding relative links in `gleam.toml`",
      "url" : "https://github.com/gleam-lang/gleam/issues/4772",
      "repositoryName" : "gleam-lang/gleam",
      "description" : "Currently links in `gleam.toml` have to be full URLs with a protocol. It is nice that we validate their syntax, but it means that you cannot use relative links, which @oderwat has a use-case for.\n\nShould we disable the validation entirely and let the programmer be responsible for checking these issues?\n\nI think we should prevent packages with relative links from being published to Hex, as those links would not be valid on HexDocs.\n\n### Discussed in https://github.com/gleam-lang/gleam/discussions/4768\n\n<div type='discussions-op-text'>\n\n<sup>Originally posted by **oderwat** July 10, 2025</sup>\nWe need to build our own Gleam documentation server that works similarly to https://hexdocs.pm/, but builds documentation by accessing our private repositories containing private Gleam packages for our team's use.\n\nThe documentation updater clones the repositories and modifies the `gleam.toml` file to add back-links to the documentation server index. This is typically an HTTPS address for our documentation server, but when running locally, it's something like `http://localhost:8000`.\n\nWe attempted to add `links = [{ title = \"Home\", href = \"/index.html\" }]` to the `gleam.toml` file, but this doesn't work because the documentation builder validates that links have a valid scheme, throwing an error: `uri without scheme for key 'links'...`.\n\nIs this validation really necessary? It also prevents adding relative links within the documentation (including fragment identifiers using \"#\").\n\nWe could work around this by using a fixed URI and performing string replacement in the generated documentation, but this approach feels clunky and inelegant.</div>",
      "updatedAt" : 1752232145.000000000,
      "user" : "lpil",
      "userHtmlUrl" : "https://github.com/lpil",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6134406?v=4",
      "labels" : [ "help wanted", "good first issue", "priority:medium" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "?????? A friendly language for building type-safe, scalable systems!",
        "homepage" : "https://gleam.run",
        "name" : "gleam",
        "fullName" : "gleam-lang/gleam",
        "htmlUrl" : "https://github.com/gleam-lang/gleam",
        "gitUrl" : "git://github.com/gleam-lang/gleam.git",
        "sshUrl" : "git@github.com:gleam-lang/gleam.git",
        "cloneUrl" : "https://github.com/gleam-lang/gleam.git",
        "owner" : {
          "login" : "gleam-lang",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 828,
        "stargazersCount" : 19565,
        "watchersCount" : 19565,
        "size" : 22037,
        "openIssuesCount" : 185,
        "subscribersCount" : 87,
        "pushedAt" : "2025-07-09T19:42:30Z",
        "languages" : {
          "PowerShell" : 723,
          "CSS" : 23755,
          "Rust" : 4508238,
          "Makefile" : 5266,
          "HTML" : 28439,
          "Erlang" : 19189,
          "TypeScript" : 2024,
          "Dockerfile" : 1352,
          "Shell" : 8917,
          "Cap'n Proto" : 6580,
          "Gleam" : 101625,
          "JavaScript" : 101426,
          "Elixir" : 744
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Permit adding relative links in gleam.toml, as the author has a use-case for it, and disabling the validation entirely might not be the best solution, as it could lead to packages with relative links being published to Hex, which would not be valid on HexDocs.",
      "validationOrRequirement" : "The validation of links having a valid scheme is necessary, according to the author, but it prevents adding relative links within the documentation and fragment identifiers using #.",
      "attemptedFixes" : "The author attempted to add relative links to the gleam.toml file, but the validation of links having a valid scheme throws an error.",
      "otherNotes" : "The issue is related to https://github.com/gleam-lang/gleam/discussions/4768, and the author wants to build a Gleam documentation server that works similarly to https://hexdocs.pm/, but with private repositories containing private Gleam packages.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284183
  }, {
    "issueDTO" : {
      "id" : 3222046554,
      "title" : "Create a workflow that runs MDX to check the correctness of code blocks in tutorials",
      "url" : "https://github.com/ocaml/ocaml.org/issues/3210",
      "repositoryName" : "ocaml/ocaml.org",
      "description" : "https://github.com/realworldocaml/mdx\n\n- [ ] `make test_code_examples` to check that all code examples in the documentation work as they should\n- [ ] Check in the CI that modified documentation in a PR has working code examples",
      "updatedAt" : 1752231855.000000000,
      "user" : "sabine",
      "userHtmlUrl" : "https://github.com/sabine",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6594573?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The official OCaml website.",
        "homepage" : "https://ocaml.org",
        "name" : "ocaml.org",
        "fullName" : "ocaml/ocaml.org",
        "htmlUrl" : "https://github.com/ocaml/ocaml.org",
        "gitUrl" : "git://github.com/ocaml/ocaml.org.git",
        "sshUrl" : "git@github.com:ocaml/ocaml.org.git",
        "cloneUrl" : "https://github.com/ocaml/ocaml.org.git",
        "owner" : {
          "login" : "ocaml",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 360,
        "stargazersCount" : 176,
        "watchersCount" : 176,
        "size" : 145384,
        "openIssuesCount" : 198,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-11T13:55:43Z",
        "languages" : {
          "Dockerfile" : 2368,
          "CSS" : 31918,
          "Shell" : 2009,
          "Standard ML" : 54,
          "OCaml" : 488264,
          "Makefile" : 2516,
          "JavaScript" : 9360,
          "Dune" : 2986,
          "HTML" : 514815,
          "Markdown" : 17757489,
          "YAML" : 494598,
          "Python" : 3416
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a workflow that runs MDX to check the correctness of code blocks in tutorials",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about creating a workflow that runs MDX to check the correctness of code blocks in tutorials. The workflow involves two tasks: running `make test_code_examples` to check all code examples in the documentation, and checking in the CI that modified documentation in a PR has working code examples.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284187
  }, {
    "issueDTO" : {
      "id" : 2971739780,
      "title" : "[FEATURE REQUEST] Add release date by performance plot to leaderboard",
      "url" : "https://github.com/EuroEval/EuroEval/issues/900",
      "repositoryName" : "EuroEval/EuroEval",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nAdd release date by performance plot to leaderboard.\n\n\nSomething like:\n![Image](https://github.com/user-attachments/assets/ddf255b2-74d5-41fc-8ed9-ccd1374e7813)\n\n\nThis would require us to add the release date to the current models. I could imagine that we could fetch most of these from Huggingface, but a few would have to be annotated.",
      "updatedAt" : 1752231852.000000000,
      "user" : "KennethEnevoldsen",
      "userHtmlUrl" : "https://github.com/KennethEnevoldsen",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/23721977?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This would be really cool!" ],
      "repository" : {
        "description" : "The robust European language model benchmark.",
        "homepage" : "https://euroeval.com",
        "name" : "EuroEval",
        "fullName" : "EuroEval/EuroEval",
        "htmlUrl" : "https://github.com/EuroEval/EuroEval",
        "gitUrl" : "git://github.com/EuroEval/EuroEval.git",
        "sshUrl" : "git@github.com:EuroEval/EuroEval.git",
        "cloneUrl" : "https://github.com/EuroEval/EuroEval.git",
        "owner" : {
          "login" : "EuroEval",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28,
        "stargazersCount" : 110,
        "watchersCount" : 110,
        "size" : 93177,
        "openIssuesCount" : 135,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-05T21:21:38Z",
        "languages" : {
          "Makefile" : 4371,
          "Python" : 998202
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add release date by performance plot to leaderboard, allowing users to visualize performance over time.",
      "validationOrRequirement" : "Add release date by performance plot to leaderboard, requires adding release date to current models and fetching most from Huggingface, with some annotations needed.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The feature requires adding release date to current models, which could be fetched from Huggingface, but some would need to be annotated.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284191
  }, {
    "issueDTO" : {
      "id" : 3195353420,
      "title" : "Refactor the impl of pkg/util/nodelock to remove dependency on `update` verb",
      "url" : "https://github.com/Project-HAMi/HAMi/issues/1156",
      "repositoryName" : "Project-HAMi/HAMi",
      "description" : "<!-- Please use this template while publishing a good first issue. Thanks!\n-->\n\n**Task description**:\nAs mentioned in pull request #1152\n> The `pkg/utils/nodelock` package is the only package within the HAMi scheduler that depends the `update` verb for `nodes` resource. Since we only update the annotations in node's metadata, i think we can refactor it to use `Patch`.\n\n**Solution**:\n\n1. Please do some research to make sure that replacing `Update` with `Patch` does not change the behavior of current impl.\n2. If it is possible to using `Patch`, then refactor the code in this package. \n3. Pass the test in this package.\n4. Update the `charts/hami/templates/scheduler/clusterrole.yaml` file after that pull request merged.\n\n**Who can join or take the task**:\n\nThe good first issue is intended for `first-time contributors` to get started on his/her contributor journey.\n\n**How to join or take the task**:\n\nJust reply on the issue with the message `/assign` in a separate line.\n\nThen, the issue will be assigned to you.\n\n**How to ask for help**:\n\nIf you need help or have questions, please feel free to ask on this issue.\nThe issue author or other members of the community will guide you through the contribution process.",
      "updatedAt" : 1752231832.000000000,
      "user" : "Shouren",
      "userHtmlUrl" : "https://github.com/Shouren",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1401515?v=4",
      "labels" : [ "kind/enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/assign", "/assign", "@Shouren, can you take a look at this [PR](https://github.com/Project-HAMi/HAMi/pull/1192)?", "@mayooot Thank you for your PR. I want to know if it is safe to replace `Update` with `Patch` ? For two clients sending a `Patch` request to API Server simultaneously, will the later request failed using `Patch` ?", "> [@mayooot](https://github.com/mayooot) Thank you for your PR. I want to know if it is safe to replace `Update` with `Patch` ? For two clients sending a `Patch` request to API Server simultaneously, will the later request failed using `Patch` ?\n\n\n\nI don't tink any failures will occur. I guess you're worried that it might fail when the Kubernetes object's `ResourceVersion` faills behind the latest `ResourceVersion`, but that won't happen.\n\nI alway using Patch instead of Update in my work, you can refer this: https://zhuanlan.zhihu.com/p/721919153\n", "> > [@mayooot](https://github.com/mayooot) Thank you for your PR. I want to know if it is safe to replace `Update` with `Patch` ? For two clients sending a `Patch` request to API Server simultaneously, will the later request failed using `Patch` ?\n> \n> I don't tink any failures will occur. I guess you're worried that it might fail when the Kubernetes object's `ResourceVersion` faills behind the latest `ResourceVersion`, but that won't happen.\n> \n> I alway using Patch instead of Update in my work, you can refer this: https://zhuanlan.zhihu.com/p/721919153\n\n@mayooot But in HAMi's situation, the later request should fail so that it knows that the node is locked by another client. I checked the [docs](https://kubernetes.io/docs/reference/using-api/api-concepts/#update-mechanism-json-patch), it mentioned `resourceVersion` in a patch update, i think you should add it to you PR" ],
      "repository" : {
        "description" : "Heterogeneous AI Computing Virtualization Middleware(Project under CNCF)",
        "homepage" : "https://project-hami.io",
        "name" : "HAMi",
        "fullName" : "Project-HAMi/HAMi",
        "htmlUrl" : "https://github.com/Project-HAMi/HAMi",
        "gitUrl" : "git://github.com/Project-HAMi/HAMi.git",
        "sshUrl" : "git@github.com:Project-HAMi/HAMi.git",
        "cloneUrl" : "https://github.com/Project-HAMi/HAMi.git",
        "owner" : {
          "login" : "Project-HAMi",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 329,
        "stargazersCount" : 1876,
        "watchersCount" : 1876,
        "size" : 135586,
        "openIssuesCount" : 305,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-11T17:48:51Z",
        "languages" : {
          "Smarty" : 6526,
          "Dockerfile" : 1991,
          "Shell" : 26579,
          "Makefile" : 3962,
          "Go" : 981343
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor the implementation of `pkg/util/nodelock` to remove dependency on the `update` verb and use `Patch` instead.",
      "validationOrRequirement" : "Replace `Update` with `Patch` and ensure it does not change the behavior of the current implementation.",
      "attemptedFixes" : "The issue author suggests that the later request should fail so that it knows that the node is locked by another client. The documentation also mentions adding `resourceVersion` in a patch update.",
      "otherNotes" : "The issue author suggests that the later request should fail so that it knows that the node is locked by another client. The documentation also mentions adding `resourceVersion` in a patch update.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284196
  }, {
    "issueDTO" : {
      "id" : 2381006292,
      "title" : "\uD83D\uDEA8FAQs | ????????????\uD83D\uDEA8",
      "url" : "https://github.com/hiyouga/LLaMA-Factory/issues/4614",
      "repositoryName" : "hiyouga/LLaMA-Factory",
      "description" : "> [!NOTE]\n> Please **avoid** creating issues regarding the following questions, as they might be closed without a response.\n> ???**??????**?????????????????????????????? issues????????? issues ????????????????????????\n\n> [!TIP]\n> Documentation: https://llamafactory.readthedocs.io/en/latest/\n> ???????????????https://llamafactory.readthedocs.io/zh-cn/latest/\n> NPU ???????????????https://ascend.github.io/docs/sources/llamafactory/\n> ????????????????????????https://zhuanlan.zhihu.com/p/695287607\n> ????????????????????????https://www.bilibili.com/video/BV1djgRzxEts/\n\n----\n\n### Most of problems / ???????????????\n\n#### How to update code / ??????????????????\n\n#### Supported models are not found / ??????????????????????????????\n\n#### llamafactory-cli: command not found / ??????????????????\n\nPlease update repository and install again using the following approach.\n\n???????????????????????????????????????????????????\n\n```bash\ngit clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git && cd LLaMA-Factory\npip install -e \".[torch,metrics]\" --no-build-isolation\n```\n\n----\n\n### Out-of-memory / ????????????\n\nThe out-of-memory (OOM) error during training is usually due to insufficient VRAM of the current device to complete the computation. You can try the following methods to deal with this issue:\n\n1. Reduce the training batch size `per_device_train_batch_size: 1`\n2. Replace compute kernels `enable_liger_kernel: true` and `use_unsloth_gc: true`\n3. Reduce the maximum sequence length `cutoff_len: 512`\n4. Use DeepSpeed ZeRO-3 or FSDP to partition model weights on multiple devices or use CPU offloading\n5. Set `quantization_bit: 4` to quantize model parameters (only compatible with LoRA tuning)\n6. Use the paged optimizer `optim: paged_adamw_8bit`\n\n??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n\n1. ????????????????????? `per_device_train_batch_size: 1`\n2. ?????????????????? `enable_liger_kernel: true` ??? `use_unsloth_gc: true`\n3. ???????????????????????? `cutoff_len: 512`\n4. ?????? DeepSpeed ZeRO-3 ??? FSDP ????????????????????????????????????????????? CPU Offloading\n5. ?????? `quantization_bit: 4` ?????????????????????????????? LoRA ?????????\n6. ?????????????????????????????? `optim: paged_adamw_8bit`\n\n----\n\n### Unsatisfying fine-tuning results / ??????????????????????????????\n\nUnsatisfying fine-tuning results are usually due to insufficient training samples, leading to underfitting. You can try the following methods to deal with this issue:\n\n1. Increase the size of the training dataset\n2. Increase the number of epochs `num_train_epochs: 5.0` or steps `max_steps: 1000`\n3. Use a larger learning rate `learning_rate: 2.0e-4`\n4. Use different fine-tuning method `finetuning_type: freeze` or `finetuning_type: full`\n\n???????????????????????????????????????????????????????????????????????????????????????????????????????????????\n\n1. ??????????????????????????????\n2. ?????????????????? `num_train_epochs: 5.0` ????????? `max_steps: 1000`\n3. ??????????????? `learning_rate: 2.0e-4`\n4. ??????????????????????????? `finetuning_type: freeze` ??? `finetuning_type: full`\n\n----\n\n### Corrupted or repeated model responses / ??????????????????????????????\n\nIf this issue occurs before training, it is usually due to using an unaligned (base) model or a mismatched `template`. Please ensure an aligned (instruct/chat) model and correct `template` are used.\nIf this issue occurs after training, please check if the `template` used for training and inference is consistent. And do not forget to check if the overfitting appeared. You can try decreasing the number of epochs `num_train_epochs` and learning rate `learning_rate` to deal with the overfitting issue.\n\n???????????????????????????????????????????????????????????????????????????base????????????????????????????????? `template`??????????????????????????????instruct/chat?????????????????????????????? `template`???\n??????????????????????????????????????????????????????????????????????????? `template` ?????????????????????????????????????????????????????????????????????????????????????????????????????? `num_train_epochs` ???????????? `learning_rate`???\n\n----\n\n### Training hangs / ??????????????????\n\nIf distributed training was not enabled, please use the following command to check if the CUDA version of PyTorch is installed correctly:\n\n??????????????????????????????????????????????????????????????? CUDA ????????? PyTorch ????????????????????????\n\n```bash\npython -c \"import torch; print(torch.cuda.is_available())\"\n```\n\nIf distributed training was enabled, try setting the environment variable `export NCCL_P2P_LEVEL=NVL`.\n\n???????????????????????????????????????????????????????????? `export NCCL_P2P_LEVEL=NVL`???\n\n----\n\n### LLaMA Board cannot display datasets / LLaMA Board ?????????????????????\n\nPlease ensure that the working directory when launching the LLaMA Board is the same as the LLaMA-Factory directory.\n\n??????????????? LLaMA Board ????????????????????? LLaMA-Factory ??????????????????\n\n----\n\n### How to shard model weights on multiple devices / ??????????????????????????????????????????\n\nDuring the training phase, please refer to the [examples](https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/README.md#supervised-fine-tuning-with-deepspeed-zero-3-weight-sharding) about how to use the DeepSpeed ZeRO-3 (recommended) or FSDP.\nDuring the inference phase, please use vLLM to enable the tensor parallelism: [examples](https://github.com/hiyouga/LLaMA-Factory/tree/main/examples#inferring-lora-fine-tuned-models).\n\n??????????????????????????? [examples](https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/README_zh.md#%E4%BD%BF%E7%94%A8-deepspeed-zero-3-%E5%B9%B3%E5%9D%87%E5%88%86%E9%85%8D%E6%98%BE%E5%AD%98) ?????? DeepSpeed ZeRO-3??????????????? FSDP???\n??????????????????????????? vLLM ????????????????????????[examples](https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/README_zh.md#%E6%8E%A8%E7%90%86-lora-%E6%A8%A1%E5%9E%8B).\n\n----\n\n### How to use ORPO or SimPO / ???????????? ORPO ??? SimPO\n\nModify the `pref_loss` in [example script](https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/train_lora/llama3_lora_dpo.yaml) to `orpo` or `simpo`.\n\n???[????????????](https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/train_lora/llama3_lora_dpo.yaml) ?????? `pref_loss` ?????? `orpo` ??? `simpo`???\n\n----\n\n### How to debug with VSCode / ????????? VSCode ????????????\n\nSee #5337\n\n----\n\n### Why the number of examples is small in pre-training / ??????????????????????????????????????????\n\nWe automatically use packing in pre-training, where we concatenate multiple samples into one sequence, so the number of examples displayed is less than the actual number.\n\n??????????????????????????????????????? Packing??????????????????????????????????????????????????????????????????????????????????????????\n\n----\n\n### Will the training data be shuffled / ??????????????????????????????\n\nLLaMA-Factory will randomly shuffle the training data by default. You can use `disable_shuffling` to turn off the shuffling.\n\nLLaMA-Factory ????????????????????????????????????????????? `disable_shuffling` ???????????????\n\n----\n\n### How to enable streaming / ??????????????????????????????\n\nWe recommend shuffling the dataset before training if you want to use streaming. Add the following arguments to your yaml file.\n\n????????????????????????????????????????????????????????????????????????????????????????????????????????? YAML ????????????\n\n```yaml\nbuffer_size: 128\npreprocessing_batch_size: 128\nstreaming: true\naccelerator_config:\n  dispatch_batches: false\n```\n\n----\n\n### Versions of dependencies conflict / ?????????????????????\n\nSet `DISABLE_VERSION_CHECK=1`.\n\n?????????????????? `DISABLE_VERSION_CHECK=1`???\n\n----\n\n### How to resolve `Processor was not found` / ???????????? `Processor was not found`\n\nPlease run the following code and paste the full error log to Issue.\n\n?????????????????????????????????????????????????????? Issue???\n\n```python\nfrom transformers import AutoProcessor\nprocessor = AutoProcessor.from_pretrained(\"path-to-your-model\")\n```\n\n----\n\n> [!TIP]\n> If the problems still exist with the **latest** code, please create an issue.\n> ?????????**?????????**???????????????????????????????????????????????? issue???\n",
      "updatedAt" : 1752231820.000000000,
      "user" : "hiyouga",
      "userHtmlUrl" : "https://github.com/hiyouga",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16256802?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024)",
        "homepage" : "https://llamafactory.readthedocs.io",
        "name" : "LLaMA-Factory",
        "fullName" : "hiyouga/LLaMA-Factory",
        "htmlUrl" : "https://github.com/hiyouga/LLaMA-Factory",
        "gitUrl" : "git://github.com/hiyouga/LLaMA-Factory.git",
        "sshUrl" : "git@github.com:hiyouga/LLaMA-Factory.git",
        "cloneUrl" : "https://github.com/hiyouga/LLaMA-Factory.git",
        "owner" : {
          "login" : "hiyouga",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 6616,
        "stargazersCount" : 54076,
        "watchersCount" : 54076,
        "size" : 52654,
        "openIssuesCount" : 530,
        "subscribersCount" : 275,
        "pushedAt" : "2025-07-11T10:59:53Z",
        "languages" : {
          "Dockerfile" : 5439,
          "Makefile" : 457,
          "Python" : 1270147
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to provide a comprehensive FAQ for LLaMA-Factory, covering various topics and solutions for common problems, and to help users troubleshoot and resolve issues with the library.",
      "validationOrRequirement" : "The issue provides several validation or requirement checks, including ensuring aligned models, correct templates, and consistent template usage, as well as checking for overfitting, distributed training, and CUDA version installation.",
      "attemptedFixes" : "The issue provides several attempted fixes and solutions for the common problems, including reducing training batch size, replacing compute kernels, reducing maximum sequence length, using DeepSpeed ZeRO-3 or FSDP, setting quantization bit, using the paged optimizer, and more.",
      "otherNotes" : "The issue is related to FAQs, common problems, and solutions for LLaMA-Factory. It covers various topics such as updating code, out-of-memory errors, unsatisfying fine-tuning results, corrupted or repeated model responses, training hangs, LLaMA Board display issues, sharding model weights, using ORPO or SimPO, debugging with VSCode, and more.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284204
  }, {
    "issueDTO" : {
      "id" : 3160421787,
      "title" : "Links to Memory Representation of Values broken",
      "url" : "https://github.com/ocaml/ocaml.org/issues/3175",
      "repositoryName" : "ocaml/ocaml.org",
      "description" : "On the [Compiler Backend](https://ocaml.org/docs/compiler-backend) page, the link to [Memory Representation of Values](https://ocaml.org/docs/memory-representation) is broken.",
      "updatedAt" : 1752231708.000000000,
      "user" : "Forthoney",
      "userHtmlUrl" : "https://github.com/Forthoney",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/85617794?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The official OCaml website.",
        "homepage" : "https://ocaml.org",
        "name" : "ocaml.org",
        "fullName" : "ocaml/ocaml.org",
        "htmlUrl" : "https://github.com/ocaml/ocaml.org",
        "gitUrl" : "git://github.com/ocaml/ocaml.org.git",
        "sshUrl" : "git@github.com:ocaml/ocaml.org.git",
        "cloneUrl" : "https://github.com/ocaml/ocaml.org.git",
        "owner" : {
          "login" : "ocaml",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 360,
        "stargazersCount" : 176,
        "watchersCount" : 176,
        "size" : 145384,
        "openIssuesCount" : 198,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-11T13:55:43Z",
        "languages" : {
          "Dockerfile" : 2368,
          "CSS" : 31918,
          "Shell" : 2009,
          "Standard ML" : 54,
          "OCaml" : 488264,
          "Makefile" : 2516,
          "JavaScript" : 9360,
          "Dune" : 2986,
          "HTML" : 514815,
          "Markdown" : 17757489,
          "YAML" : 494598,
          "Python" : 3416
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the broken link to Memory Representation of Values on the Compiler Backend page",
      "validationOrRequirement" : "The link should be working",
      "attemptedFixes" : "",
      "otherNotes" : "The link on the Compiler Backend page to Memory Representation of Values is broken.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284206
  }, {
    "issueDTO" : {
      "id" : 1960569471,
      "title" : "More helpful error when function is missing",
      "url" : "https://github.com/maplibre/martin/issues/969",
      "repositoryName" : "maplibre/martin",
      "description" : "Thanks for developing martin, it is a pleasure to use.\r\n\r\nI recently spun up martin, asking it to serve a function that did not exist. An error reported that the schema `public` was not found, with an empty list of possible values:\r\n\r\n```\r\n[2023-10-25T05:27:45Z WARN  martin::pg::utils] Unable to configure source foot because schema 'public' was not found.  Possible values are:\r\n```\r\nI suggest that a more descriptive/helpful error be returned, indicating that the function itself may be missing.",
      "updatedAt" : 1752231693.000000000,
      "user" : "jacobwhall",
      "userHtmlUrl" : "https://github.com/jacobwhall",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/55111303?v=4",
      "labels" : [ "pg", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I duplicate it with a yaml like this and martin list all the schemas I already created:\r\n```yaml\r\n  functions:\r\n    function_not_exist:\r\n      schema: not_exist_schema \r\n      function: function_not_exist\r\n```\r\n```shell\r\nUnable to configure source function_not_exist because schema 'not_exist_schema' was not found.  Possible values are: MixedCase, public\r\n```\r\nHow about update the warning to \r\n```shell\r\nUnable to configure source \"source1\" because the associated function \"foo\".\"bar\"  was not found. Please ensure that the schema and function have been created. In case misspelling in the config file, possible schemas values: schema1, schema2\r\n```\r\nI'm not experienced with logs???any suggestions to improve it? @nyurik  @jacobwhall ", "I think the reason you got that message is because we do not differentiate between these two cases:\r\n* schema does not exist\r\n* schema exists, but it has no functions that match expected `_____(z,x,y) -> blob` pattern\r\n\r\nTo make the message better, we will need to add another PG query to find all available schemas, and then when parsing, use that to make it a bit more helpful. Alternatively, a simpler solution could be to explain that in a message:\r\n\r\n```\r\nUnable to configure source 'src' because function 'schema.func' was not found.\r\nThe following schemas with usable function were found: schema1, schema2\r\n```\r\n\r\n@jacobwhall would that have helped in your case?", ">  schema exists, but it has no functions that match expected `_____(z,x,y) -> blob` pattern\r\n\r\nYes, this is the case I hope to clarify. I think the easiest solution is to suggest that the schema might exist without the specified function. For example:\r\n\r\n```\r\nUnable to configure source 'src' because a schema 'public' with function 'func' was not found.\r\n```\r\n\r\nThis would suggest to the user that either the schema or the function could be missing / misspelled / etc.\r\n\r\n@nyurik, your suggestion of adding a list of possible options would be even better. If another query is added, it might be best to search for usable functions within the specified schema. Building off your example:\r\n\r\n```\r\nUnable to configure source 'src' because function 'schema.func' was not found.\r\nThe following usable functions in schema 'schema' were found: schema.func1, schema.func2\r\n```\r\n\r\nThank you both for your replies. I hope to contribute more substantially to martin in the future.", "Suggestions is a bit trickier because the user may have autodiscover enabled, in which case all those functions will be added as sources anyway, unless they also filter by schema.  Listing all available functions in that case would be useless.  I think we should start with simply improving the existing message.  The only problem is that it uses a generic function that does all sorts of lookups - i.e. lookups among schemas, among functions, among tables, etc.\r\n\r\nOk, I just looked at the code (below), and it seems we actually have the handling of your case, but it never gets triggered, because an empty array is never returned! So we should simply modify `query_available_function` to contain all schemas, and not just the ones that have relevant functions, and we should be good!\r\n\r\nInitiating code:\r\nhttps://github.com/maplibre/martin/blob/94f2c16267122647bcb8cf054ec8708c94bd6ffd/martin/src/pg/configurator.rs#L244-L254\r\n\r\nCode that actually prints the message:\r\nhttps://github.com/maplibre/martin/blob/94f2c16267122647bcb8cf054ec8708c94bd6ffd/martin/src/pg/utils.rs#L104-L109\r\n\r\n", "Anyone wants to add a simple SQL query to fix this?  Should be an easy change to the code:\n\n* [ ] Add a new SQL file - `martin/src/pg/scripts/query_schemas.sql` that simply returns a list of all schemas (as a single column table)\n* [ ] modify `PgBuilder`\n  * [ ] add a new field `schemas: Vec<String>`\n  * [ ] in `PgBuilder::new` run the above query, add store results into `schemas` field\n  * [ ] add a new helper function that adds all missing schemas to a hashmap, and call that function inside `instantiate_functions` and `instantiate_tables` right after calling `query_available_function`.  This way `db_funcs_info` will contain empty HashMaps for all schemas if they don't have relevant functions\n\nIf you only feel comfortable with writing the SQL query, I can do the rest too, but we are always welcoming new contributors :)", "Did some digging into this:\r\n\r\n### `tests/fixtures/functions/unsupported_function.sql`\r\n\r\n```sql\r\nDROP FUNCTION IF EXISTS other_schema.not_matching_func;\r\n\r\n-- missing \"zoom\" value\r\nCREATE OR REPLACE FUNCTION other_schema.not_matching_func(x integer, y integer) RETURNS bytea AS $$\r\nSELECT ('123' || x || y)::bytea\r\n$$ LANGUAGE SQL;\r\n```\r\n\r\n### `tests/fixtures/tables/unsupported_table.sql`\r\n\r\n```sql\r\nDROP SCHEMA IF EXISTS other_schema CASCADE;\r\nCREATE SCHEMA other_schema;\r\n\r\nCREATE TABLE other_schema.table_without_geo\r\n(\r\n    id   SERIAL PRIMARY KEY,\r\n    name TEXT\r\n);\r\n\r\nINSERT INTO other_schema.table_without_geo\r\nvalues (1, 'foo'),\r\n       (2, 'bar');\r\n```\r\n\r\n### `myconfig.yaml`\r\n\r\n```yaml\r\npostgres:\r\n  connection_string: postgres://postgres:postgres@localhost:5411/db\r\n  tables:\r\n    test_good_schema_bad_table:\r\n      schema: other_schema\r\n      table: table_without_geo\r\n      srid: 4326\r\n      geometry_column: Geom\r\n    test_good_schema_missing_table:\r\n      schema: other_schema\r\n      table: no_such_table\r\n      srid: 4326\r\n      geometry_column: Geom\r\n    test_bad_schema_bad_table:\r\n      schema: invalid_schema\r\n      table: invalid_table\r\n      srid: 4326\r\n      geometry_column: Geom\r\n  functions:\r\n    test_good_schema_bad_func:\r\n      schema: other_schema\r\n      function: not_matching_func\r\n    test_good_schema_missing_func:\r\n      schema: other_schema\r\n      function: missing_func\r\n    test_bad_schema_bad_func:\r\n      schema: invalid_schema\r\n      function: invalid_func\r\n```\r\n\r\n## Testing\r\n\r\n```bash\r\njust start\r\nmartin myconfig.yaml\r\n```\r\n\r\n#### Current Output\r\n\r\n```\r\n########### these are ok, and should not be changed\r\n[... WARN  martin::pg::utils] Unable to configure source test_bad_schema_bad_table because schema 'invalid_schema' was not found.  Possible values are: MixedCase, autodetect, public\r\n[... WARN  martin::pg::utils] Unable to configure source test_bad_schema_bad_func because schema 'invalid_schema' was not found.  Possible values are: MixedCase, public\r\n\r\n########### these should be modified\r\n[... WARN  martin::pg::utils] Unable to configure source test_good_schema_bad_table because schema 'other_schema' was not found.  Possible values are: MixedCase, autodetect, public\r\n[... WARN  martin::pg::utils] Unable to configure source test_good_schema_bad_func because schema 'other_schema' was not found.  Possible values are: MixedCase, public\r\n[... WARN  martin::pg::utils] Unable to configure source test_good_schema_missing_table because schema 'other_schema' was not found.  Possible values are: MixedCase, autodetect, public\r\n[... WARN  martin::pg::utils] Unable to configure source test_good_schema_missing_func because schema 'other_schema' was not found.  Possible values are: MixedCase, public\r\n```\r\n\r\n#### Desired Output\r\n\r\nThis is not have to be exact, but should give some ideas to implementers\r\n\r\n**Table exists, but has no geometries**\r\n> Unable to configure source test_good_schema_bad_table because the table 'table_without_geo' has no geometry columns. Other valid tables are: ...\r\n\r\n---or---\r\n\r\n> Unable to configure source test_good_schema_bad_table because the table 'table_without_geo' has no geometry columns. No valid tables found in schema 'other_schema'.\r\n\r\n**Table does not exist**\r\n\r\n> Unable to configure source test_good_schema_missing_table because table 'no_such_table' does not exist in schema 'other_schema'.  Possible values are: ...\r\n\r\n---or---\r\n\r\n> Unable to configure source test_good_schema_missing_table because table 'no_such_table' does not exist in schema 'other_schema'. No valid tables found in schema 'other_schema'.\r\n\r\n**Function exists, but does not have recognizable signature**\r\n> Unable to configure source test_good_schema_bad_func because function 'not_matching_func'  does not have the expected signature like (z,x,y) -> bytea. See docs for other supported variants. Other valid functions are: ...\r\n\r\n> Unable to configure source test_good_schema_missing_func because function 'missing_func' does not exist in the schema 'other_schema'.  Possible values are: ...\r\n" ],
      "repository" : {
        "description" : "Blazing fast and lightweight PostGIS, MBtiles and PMtiles tile server, tile generation, and mbtiles tooling.",
        "homepage" : "https://martin.maplibre.org",
        "name" : "martin",
        "fullName" : "maplibre/martin",
        "htmlUrl" : "https://github.com/maplibre/martin",
        "gitUrl" : "git://github.com/maplibre/martin.git",
        "sshUrl" : "git@github.com:maplibre/martin.git",
        "cloneUrl" : "https://github.com/maplibre/martin.git",
        "owner" : {
          "login" : "maplibre",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 266,
        "stargazersCount" : 2828,
        "watchersCount" : 2828,
        "size" : 20365,
        "openIssuesCount" : 99,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T02:52:40Z",
        "languages" : {
          "TypeScript" : 830,
          "Shell" : 29490,
          "CSS" : 198,
          "Rust" : 672567,
          "JavaScript" : 436,
          "HTML" : 18833,
          "Just" : 14278
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to improve the error message when a function is missing in martin, a PostgreSQL database client. The goal is to make the error message more descriptive and helpful, indicating that the function itself may be missing.",
      "validationOrRequirement" : "The validation or requirement is that the error message should be more descriptive and helpful, indicating that the function itself may be missing. The error message should also provide information about the possible values.",
      "attemptedFixes" : "The issue has been attempted to be fixed by adding a new SQL query to find all available schemas, and then using that to make the error message more helpful. Alternatively, a simpler solution could be to explain that in a message. The issue has also been discussed about adding a list of possible options.",
      "otherNotes" : "The issue is about improving the error message when a function is missing. The current error message is not helpful and does not provide enough information. The goal is to make the error message more descriptive and helpful, indicating that the function itself may be missing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284213
  }, {
    "issueDTO" : {
      "id" : 3135896827,
      "title" : "Link to Odoc for authors is broken",
      "url" : "https://github.com/ocaml/ocaml.org/issues/3160",
      "repositoryName" : "ocaml/ocaml.org",
      "description" : "On this page - https://ocaml.org/docs/tour-of-ocaml\n\n> This is discussed further in [odoc for Authors: Special Comments](https://ocaml.github.io/odoc/odoc_for_authors.html#special_comments).\n\nThe link is broken",
      "updatedAt" : 1752231689.000000000,
      "user" : "dinakajoy",
      "userHtmlUrl" : "https://github.com/dinakajoy",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/39722740?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "correct link: https://ocaml.github.io/odoc/odoc/odoc_for_authors.html" ],
      "repository" : {
        "description" : "The official OCaml website.",
        "homepage" : "https://ocaml.org",
        "name" : "ocaml.org",
        "fullName" : "ocaml/ocaml.org",
        "htmlUrl" : "https://github.com/ocaml/ocaml.org",
        "gitUrl" : "git://github.com/ocaml/ocaml.org.git",
        "sshUrl" : "git@github.com:ocaml/ocaml.org.git",
        "cloneUrl" : "https://github.com/ocaml/ocaml.org.git",
        "owner" : {
          "login" : "ocaml",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 360,
        "stargazersCount" : 176,
        "watchersCount" : 176,
        "size" : 145384,
        "openIssuesCount" : 198,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-11T13:55:43Z",
        "languages" : {
          "Dockerfile" : 2368,
          "CSS" : 31918,
          "Shell" : 2009,
          "Standard ML" : 54,
          "OCaml" : 488264,
          "Makefile" : 2516,
          "JavaScript" : 9360,
          "Dune" : 2986,
          "HTML" : 514815,
          "Markdown" : 17757489,
          "YAML" : 494598,
          "Python" : 3416
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the broken link to Odoc for authors",
      "validationOrRequirement" : "good first issue",
      "attemptedFixes" : "correct link: https://ocaml.github.io/odoc/odoc/odoc_for_authors.html",
      "otherNotes" : "The link is broken and is discussed further in [odoc for Authors: Special Comments](https://ocaml.github.io/odoc/odoc_for_authors.html#special_comments).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284217
  }, {
    "issueDTO" : {
      "id" : 3222473391,
      "title" : "create `toBytesLE` and `toBytesBE` utilites that fill already allocated array",
      "url" : "https://github.com/vacp2p/nim-libp2p/issues/1522",
      "repositoryName" : "vacp2p/nim-libp2p",
      "description" : "currently code uses  `toBytesLE` and `toBytesBE`  (as defied [here](https://github.com/status-im/nim-stew/blob/e5740014961438610d336cd81706582dbf2c96f0/stew/endians2.nim#L107C6-L107C15)) that return `array[sizeof(x), byte]`.\n\nsince all code that uses these utilities already have allocated sequence where bytes should be written it would be nice to create another set of utilities that will write directly to allocated buffer.\n\n```nim\n# instead of doing this\nresult[4 .. 7] = toBytesBE(header.streamId)\n\n# should be:\ntoBytesBE(header.streamId, result, 4)\n\n# where\n# first argument is the same\n# second argument is `openArray[byte]` where data should be encoded\n# third argument is offset where encoding should start\n```  ",
      "updatedAt" : 1752231645.000000000,
      "user" : "vladopajic",
      "userHtmlUrl" : "https://github.com/vladopajic",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4353513?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "libp2p implementation in Nim",
        "homepage" : "https://vacp2p.github.io/nim-libp2p/docs/",
        "name" : "nim-libp2p",
        "fullName" : "vacp2p/nim-libp2p",
        "htmlUrl" : "https://github.com/vacp2p/nim-libp2p",
        "gitUrl" : "git://github.com/vacp2p/nim-libp2p.git",
        "sshUrl" : "git@github.com:vacp2p/nim-libp2p.git",
        "cloneUrl" : "https://github.com/vacp2p/nim-libp2p.git",
        "owner" : {
          "login" : "vacp2p",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 63,
        "stargazersCount" : 279,
        "watchersCount" : 279,
        "size" : 69348,
        "openIssuesCount" : 151,
        "subscribersCount" : 29,
        "pushedAt" : "2025-07-11T21:03:54Z",
        "languages" : {
          "Dockerfile" : 1578,
          "Shell" : 3240,
          "Nim" : 2106620,
          "C" : 33151
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create toBytesLE and toBytesBE utilities that fill already allocated array",
      "validationOrRequirement" : "The new utilities should be able to write directly to an allocated buffer, and should be used with openArray[byte] and an offset where encoding should start.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Code currently uses toBytesLE and toBytesBE utilities that return an array of bytes, but these utilities are not used with already allocated arrays. This issue aims to create new utilities that can write directly to an allocated buffer.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284221
  }, {
    "issueDTO" : {
      "id" : 3208051474,
      "title" : "Plugins installer should inherit permissions if possible",
      "url" : "https://github.com/grafana/grafana/issues/107678",
      "repositoryName" : "grafana/grafana",
      "description" : "When someone runs `grafana cli plugins ...`, we should make the directory we touch inherit its permissions from the parent directory. This is especially important if the user running the CLI is `root`, while Grafana itself runs as e.g. `grafana`.\n\nRelated: https://github.com/grafana/grafana-image-renderer/issues/650\nRelated: https://github.com/grafana/grafana-image-renderer/issues/651",
      "updatedAt" : 1752231566.000000000,
      "user" : "Proximyst",
      "userHtmlUrl" : "https://github.com/Proximyst",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19861299?v=4",
      "labels" : [ "area/plugins", "internal", "\uD83C\uDF50-programming", "good first issue", "area/grafana-cli" ],
      "state" : "OPEN",
      "comments" : [ "Hello can you please assign me this issue? I want to contribute, thanks!", "@zk2k2 It's yours :) If you need any support, please feel free to reach out to me on [the community Slack](https://slack.grafana.com/).", "@Proximyst sure, thank you! I will try to submit a PR ASAP :) !", "Hi @Proximyst , I submitted a PR for the issue, let me know if I need to review or fix anything, thanks!" ],
      "repository" : {
        "description" : "The open and composable observability and data visualization platform. Visualize metrics, logs, and traces from multiple sources like Prometheus, Loki, Elasticsearch, InfluxDB, Postgres and many more. ",
        "homepage" : "https://grafana.com",
        "name" : "grafana",
        "fullName" : "grafana/grafana",
        "htmlUrl" : "https://github.com/grafana/grafana",
        "gitUrl" : "git://github.com/grafana/grafana.git",
        "sshUrl" : "git@github.com:grafana/grafana.git",
        "cloneUrl" : "https://github.com/grafana/grafana.git",
        "owner" : {
          "login" : "grafana",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12766,
        "stargazersCount" : 68934,
        "watchersCount" : 68934,
        "size" : 1200123,
        "openIssuesCount" : 3785,
        "subscribersCount" : 1275,
        "pushedAt" : "2025-07-12T00:42:36Z",
        "languages" : {
          "MDX" : 152355,
          "Smarty" : 2116,
          "PowerShell" : 367,
          "Jinja" : 5716,
          "CSS" : 3116,
          "Makefile" : 37420,
          "Handlebars" : 859,
          "Go" : 25415437,
          "Mustache" : 2716,
          "HTML" : 297389,
          "Jsonnet" : 39308,
          "TypeScript" : 33735158,
          "HCL" : 5251,
          "Dockerfile" : 15265,
          "CUE" : 346909,
          "Shell" : 172769,
          "Starlark" : 101062,
          "SCSS" : 112108,
          "JavaScript" : 243620,
          "Ruby" : 1148,
          "Rich Text Format" : 351017,
          "Assembly" : 168
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to make the directory touched by the `grafana cli plugins` command inherit its permissions from the parent directory.",
      "validationOrRequirement" : "The issue requires inheriting permissions from the parent directory when running the Grafana CLI, especially when the user running the CLI is `root` and Grafana itself runs as `grafana`.",
      "attemptedFixes" : "A PR has been submitted for the issue, and the author is seeking review or feedback.",
      "otherNotes" : "The issue is related to https://github.com/grafana/grafana-image-renderer/issues/650 and https://github.com/grafana/grafana-image-renderer/issues/651, and has been assigned to @Proximyst, who is also thanked for their contribution.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284226
  }, {
    "issueDTO" : {
      "id" : 3211009817,
      "title" : "Recipe to avoid concatenating with empty String to perform type conversion",
      "url" : "https://github.com/openrewrite/rewrite-static-analysis/issues/628",
      "repositoryName" : "openrewrite/rewrite-static-analysis",
      "description" : "## What problem are you trying to solve?\n\nCode readability and possibly performance when using the `\"\" + ...` trick to convert something to a String.\n`String.valueOf()` is a better alternative.\n\n## Describe the situation before applying the recipe\n<!-- Ideally as a self-contained code example, as a start to the recipe unit tests. -->\n```java\n\"\" + 1\n```\n\n## Describe the situation after applying the recipe\n<!-- Ideally as a self-contained code example, as a start to the recipe unit tests. -->\n```java\nString.valueOf(1)\n```\n\n## OSS repro\n- https://github.com/encryptedsystems/Clusion/blob/d6f89c1269f618ec42a9bfc42e940382fa14ae69/src/main/java/org/crypto/sse/DynRR.java#L47\n- https://github.com/xebialabs/overcast/blob/8a494dc8f8572ae337ce91b06829eb9567c91f5d/src/main/java/com/xebialabs/overcast/host/CachedLibvirtHost.java#L57",
      "updatedAt" : 1752231476.000000000,
      "user" : "greg-at-moderne",
      "userHtmlUrl" : "https://github.com/greg-at-moderne",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/192309513?v=4",
      "labels" : [ "recipe", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I'd like to work on this issue. Let me know if it's still available. Thanks!", "It sure is. I suggest you start with forking the repo, creating a branch with unit test with a few cases showing the desired behavior.", "Here's a quick first attempt:\n- https://github.com/openrewrite/rewrite-static-analysis/pull/634/", "Just to clarify, since the PR #634 is now open and seems to fully address this, should I consider this issue closed or still open for contribution? ", "No need to start a parallel effort, thanks! Any suggestions on how to handle (or skip) chained concatenations on #634 appreciated!" ],
      "repository" : {
        "description" : "OpenRewrite recipes for identifying and fixing static analysis issues.",
        "homepage" : "",
        "name" : "rewrite-static-analysis",
        "fullName" : "openrewrite/rewrite-static-analysis",
        "htmlUrl" : "https://github.com/openrewrite/rewrite-static-analysis",
        "gitUrl" : "git://github.com/openrewrite/rewrite-static-analysis.git",
        "sshUrl" : "git@github.com:openrewrite/rewrite-static-analysis.git",
        "cloneUrl" : "https://github.com/openrewrite/rewrite-static-analysis.git",
        "owner" : {
          "login" : "openrewrite",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 82,
        "stargazersCount" : 40,
        "watchersCount" : 40,
        "size" : 4108,
        "openIssuesCount" : 171,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T12:05:28Z",
        "languages" : {
          "Java" : 2504180
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To avoid concatenating with empty String to perform type conversion and improve code readability and performance.",
      "validationOrRequirement" : "The issue requires a solution that improves code readability and performance, with a focus on avoiding concatenation with empty string to perform type conversion.",
      "attemptedFixes" : "A PR #634 is already open and seems to fully address this issue, and another attempt is suggested to handle chained concatenations.",
      "otherNotes" : "This issue is about improving code readability and performance by avoiding concatenation with empty string to perform type conversion, with examples provided in the description.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284230
  }, {
    "issueDTO" : {
      "id" : 3125529231,
      "title" : "Pass Dependencies when Proposing Partitions",
      "url" : "https://github.com/pytorch/executorch/issues/11447",
      "repositoryName" : "pytorch/executorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nCurrently an issue with the capability based partitioner (https://github.com/pytorch/pytorch/blob/2e2ea7290a1cf2da3c3efd6e6ad4836bb94beaeb/torch/fx/passes/infra/partitioner.py#L78) is that there is no way to specify node dependencies together. For example if there is a graph that looks like:\n```\n\ninput --> choose_q_params --> q --> dq --> linear --> (not_supported_op) --> bmm --> output\n                                       \\\n                                         -------------------------------> linear --> output\n```\n\nIn this case since both linear patterns are dynamically quantized and share the same QDQ Chain then then partition should be:\n\n```\nPartition 1\ninput --> choose_q_params --> q --> dq --> linear --> output\n                                       \\\n                                         -------------------------------> linear --> output\n\nPartition 2\n(not supported op output) --> bmm --> output\n```\n\nHowever, in reality we can get a case where we see:\n```\nPartition 1\ninput --> choose_q_params --> q --> dq --> linear --> output\n                                       \\\n                                         -------------> output\n\nPartition 2\ninput --> bmm --> output\n\ndq_output --> linear --> output\n```\n\nThis is problematic because in the second linear we lose the semantics of a quantized linear from the graph. We need a way to pass in groups of nodes that must be partitioned together\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### RFC (Optional)\n\n_No response_",
      "updatedAt" : 1752231459.000000000,
      "user" : "mcr229",
      "userHtmlUrl" : "https://github.com/mcr229",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/40742183?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "> This is problematic because in the second linear we lose the semantics of a quantized linear from the graph\n\nIs this because cqp -> q are not part of the 2nd partition? Can we dup cqp->q->dq instead of just dup dq? Just an idea." ],
      "repository" : {
        "description" : "On-device AI across mobile, embedded and edge for PyTorch",
        "homepage" : "https://pytorch.org/executorch/",
        "name" : "executorch",
        "fullName" : "pytorch/executorch",
        "htmlUrl" : "https://github.com/pytorch/executorch",
        "gitUrl" : "git://github.com/pytorch/executorch.git",
        "sshUrl" : "git@github.com:pytorch/executorch.git",
        "cloneUrl" : "https://github.com/pytorch/executorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 613,
        "stargazersCount" : 3029,
        "watchersCount" : 3029,
        "size" : 238670,
        "openIssuesCount" : 1225,
        "subscribersCount" : 70,
        "pushedAt" : "2025-07-12T00:52:56Z",
        "languages" : {
          "Java" : 91154,
          "C++" : 7468950,
          "Jinja" : 11160,
          "C" : 92510,
          "Objective-C++" : 585572,
          "CMake" : 253562,
          "Kotlin" : 47365,
          "Dockerfile" : 2690,
          "Shell" : 234857,
          "Starlark" : 485277,
          "Batchfile" : 339,
          "Objective-C" : 192295,
          "Swift" : 90538,
          "Python" : 9370932,
          "GLSL" : 313850
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The feature aims to pass dependencies when proposing partitions, allowing for correct partitioning of nodes in the graph",
      "validationOrRequirement" : "Pass in groups of nodes that must be partitioned together",
      "attemptedFixes" : "Dup cqp->q->dq instead of just dup dq, as an idea.",
      "otherNotes" : "The capability based partitioner has an issue with specifying node dependencies together, causing loss of semantics in the graph.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284233
  }, {
    "issueDTO" : {
      "id" : 3053308362,
      "title" : "[pt] Localize docs/contributing/development.md",
      "url" : "https://github.com/open-telemetry/opentelemetry.io/issues/6859",
      "repositoryName" : "open-telemetry/opentelemetry.io",
      "description" : "## Description\n\n**What needs to be changed?** \n\nThis issue is part of the Portuguese localization for the pages under the `contributing` directory.\n\nURL: https://opentelemetry.io/pt/docs/contributing/development/\n\n**What is the name + path of the page that needs changed?** \n\n* [content/en/docs/contributing/development.md](https://github.com/open-telemetry/opentelemetry.io/blob/main/content/en/docs/contributing/development.md)\n\n## How to contribute\n\n1. Read [this guide](https://vasconcellos.dev/posts/2024-07-26-guia-contribuicao-otel-docs-pt) to familiarize yourself with the contribution process.\n2. Comment on this issue about which page you want to localize.\n3. If you have any questions, let us know at [#otel-localization-ptbr](https://cloud-native.slack.com/archives/C076LET8YSK).",
      "updatedAt" : 1752231393.000000000,
      "user" : "vitorvasc",
      "userHtmlUrl" : "https://github.com/vitorvasc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12118857?v=4",
      "labels" : [ "lang:pt", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'm gonna work on this issue. " ],
      "repository" : {
        "description" : "The OpenTelemetry website and documentation",
        "homepage" : "https://opentelemetry.io",
        "name" : "opentelemetry.io",
        "fullName" : "open-telemetry/opentelemetry.io",
        "htmlUrl" : "https://github.com/open-telemetry/opentelemetry.io",
        "gitUrl" : "git://github.com/open-telemetry/opentelemetry.io.git",
        "sshUrl" : "git@github.com:open-telemetry/opentelemetry.io.git",
        "cloneUrl" : "https://github.com/open-telemetry/opentelemetry.io.git",
        "owner" : {
          "login" : "open-telemetry",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1450,
        "stargazersCount" : 727,
        "watchersCount" : 727,
        "size" : 66736,
        "openIssuesCount" : 452,
        "subscribersCount" : 62,
        "pushedAt" : "2025-07-11T10:32:16Z",
        "languages" : {
          "Shell" : 22122,
          "CSS" : 888,
          "SCSS" : 11412,
          "Makefile" : 1959,
          "JavaScript" : 56541,
          "HTML" : 47175,
          "Perl" : 32882
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Localize docs/contributing/development.md",
      "validationOrRequirement" : "Read [this guide](https://vasconcellos.dev/posts/2024-07-26-guia-contribuicao-otel-docs-pt) to familiarize yourself with the contribution process. Comment on this issue about which page you want to localize. If you have any questions, let us know at [#otel-localization-ptbr](https://cloud-native.slack.com/archives/C076LET8YSK).",
      "attemptedFixes" : "I'm gonna work on this issue.",
      "otherNotes" : "This issue is part of the Portuguese localization for the pages under the `contributing` directory. URL: https://opentelemetry.io/pt/docs/contributing/development/. The page that needs to be changed is [content/en/docs/contributing/development.md](https://github.com/open-telemetry/opentelemetry.io/blob/main/content/en/docs/contributing/development.md).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284240
  }, {
    "issueDTO" : {
      "id" : 3198337417,
      "title" : "[Term Entry] PyTorch Tensor Operations: .digamma()",
      "url" : "https://github.com/Codecademy/docs/issues/7211",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the `.digamma()` term in PyTorch. The entry should go in a new file under `docs/content/pytorch/concepts/tensor-operations/terms/digamma/digamma.md`.\n\nThe entry should include:\n\n- An introduction to the concept\n- A `Syntax` section that provides the syntax for the concept\n- An `Example` section that provides an example demonstrating the concept in use\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md), and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752231304.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "pytorch", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Can I take this one?\n" ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new entry on the .digamma() term in PyTorch, including an introduction, syntax, and example, in a new file under docs/content/pytorch/concepts/tensor-operations/terms/digamma/digamma.md.",
      "validationOrRequirement" : "The entry should include: an introduction to the concept, a Syntax section that provides the syntax for the concept, an Example section that provides an example demonstrating the concept in use.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "Please refer to the term entry template, content standards, and markdown style guide when working on the PR for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284245
  }, {
    "issueDTO" : {
      "id" : 3212002841,
      "title" : "Improve code for defining architecture levels",
      "url" : "https://github.com/z390development/z390/issues/656",
      "repositoryName" : "z390development/z390",
      "description" : "Architecture levels are defined using constants in tz390.\nPlease replace with an enum. For details, please see (closed) PR 644.",
      "updatedAt" : 1752231207.000000000,
      "user" : "abekornelis",
      "userHtmlUrl" : "https://github.com/abekornelis",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/51093073?v=4",
      "labels" : [ "Lang:Java", "component-core", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "z390 Portable Mainframe Assembler and Emulator Project",
        "homepage" : null,
        "name" : "z390",
        "fullName" : "z390development/z390",
        "htmlUrl" : "https://github.com/z390development/z390",
        "gitUrl" : "git://github.com/z390development/z390.git",
        "sshUrl" : "git@github.com:z390development/z390.git",
        "cloneUrl" : "https://github.com/z390development/z390.git",
        "owner" : {
          "login" : "z390development",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 54,
        "watchersCount" : 54,
        "size" : 14858,
        "openIssuesCount" : 285,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-08T10:28:38Z",
        "languages" : {
          "Java" : 2990769,
          "Shell" : 219450,
          "Batchfile" : 421991,
          "COBOL" : 2973464,
          "ZAP" : 264,
          "Perl" : 21525,
          "HTML" : 247,
          "Roff" : 17,
          "Groovy" : 94160,
          "MAXScript" : 19115
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve code for defining architecture levels",
      "validationOrRequirement" : "Replace constants with an enum in tz390.",
      "attemptedFixes" : "",
      "otherNotes" : "For details, please see (closed) PR 644.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284246
  }, {
    "issueDTO" : {
      "id" : 3221849343,
      "title" : "InputNumber: wrong internal value for decimal numbers using the spin",
      "url" : "https://github.com/primefaces/primereact/issues/8132",
      "repositoryName" : "primefaces/primereact",
      "description" : "### Describe the bug\n\nDefining a InputNumber with minFractionDigits={1} and step={0.1} when pressing arrows button (+0.1) internal values are randomly incorrect:\nsetValue 0.1\nsetValue 0.2\nsetValue **0.30000000000000004**\nsetValue 0.4\nsetValue 0.5\nsetValue 0.6\nsetValue 0.7\nsetValue **0.7999999999999999**\nsetValue 0.9\n\n\n### Reproducer\n\nhttps://stackblitz.com/edit/vitejs-vite-dsayvjx6\n\n### System Information\n\n```Shell\nPrimeReact: 10.9.6\n React: 18.2.0\n```\n\n### Steps to reproduce the behavior\n\n1 define an inputNumber as follows \n  const [val, setVal] = useState<number | null>(0.0);\n function setValue(value: number | null): void {\n    console.log(\"setValue\", value);\n    setVal(value);\n  }\n\n <InputNumber key={'test'} id={'test'} value={val} onChange={(e) => setValue(e.value)} showButtons minFractionDigits={1} step={0.1} />\n2 press the up arrow repeatedly\n3 check the outputs of console.log. Randomly the e.value is wrong\n\n### Expected behavior\n\nThe expected behavioor is that the e.value increases of 0.1",
      "updatedAt" : 1752231151.000000000,
      "user" : "mem70",
      "userHtmlUrl" : "https://github.com/mem70",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/220317983?v=4",
      "labels" : [ "Type: Bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@mem70 here is the answer: https://chatgpt.com/share/6870ec82-3b70-8005-bc95-175d9f93b33f\n\n> You're seeing floating-point precision issues, which are common in JavaScript (and many other languages) due to how decimal numbers are represented in binary using the IEEE 754 standard.\n\n```js\nfunction addWithPrecision(base, increment, precision = 10) {\n  return Math.round((base + increment) * precision) / precision;\n}\n```" ],
      "repository" : {
        "description" : "The Most Complete React UI Component Library",
        "homepage" : "https://primereact.org",
        "name" : "primereact",
        "fullName" : "primefaces/primereact",
        "htmlUrl" : "https://github.com/primefaces/primereact",
        "gitUrl" : "git://github.com/primefaces/primereact.git",
        "sshUrl" : "git@github.com:primefaces/primereact.git",
        "cloneUrl" : "https://github.com/primefaces/primereact.git",
        "owner" : {
          "login" : "primefaces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1151,
        "stargazersCount" : 7850,
        "watchersCount" : 7850,
        "size" : 255770,
        "openIssuesCount" : 325,
        "subscribersCount" : 75,
        "pushedAt" : "2025-07-11T12:35:43Z",
        "languages" : {
          "CSS" : 13976519,
          "SCSS" : 116235,
          "JavaScript" : 9273088
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the internal value calculation for decimal numbers when using the spin buttons in the `InputNumber` component.",
      "validationOrRequirement" : "The issue is specific to the `InputNumber` component with `minFractionDigits` and `step` set to specific values.",
      "attemptedFixes" : "The author provided a solution using the `addWithPrecision` function, which rounds the result to the specified precision.",
      "otherNotes" : "The issue is due to floating-point precision issues in JavaScript, which is a common problem when dealing with decimal numbers.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284251
  }, {
    "issueDTO" : {
      "id" : 3134062873,
      "title" : "Enable pinning / favoriting dashboards",
      "url" : "https://github.com/SigNoz/signoz/issues/8210",
      "repositoryName" : "SigNoz/signoz",
      "description" : "Users should be able to pin / favorite dashboards in dashboards listing page. \n\n- Pinned dashboards are moved to the pinned section similar to all dashboards section (check screenshot)\n\nUse the preference framework. *\n\n\n\n\n<img width=\"669\" height=\"422\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/94a88419-5c9d-43cb-9a5c-068edf96d7c8\" />",
      "updatedAt" : 1752231070.000000000,
      "user" : "YounixM",
      "userHtmlUrl" : "https://github.com/YounixM",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3520897?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey, I'm a beginner but would love to work on this issue. Could someone guide me if this is a good first issue and what files I should start with?", "Hi, it seems noone is working on this issue, can you assign it to me ?", "@YounixM  do we need to update 'dashboards' table as well (new column -> pinned/isPinned) because on re-render in dashboard listing page, data is being fetched from 'useGetAllDashboard()' which eventually calls -> GET /dashboards", "https://github.com/user-attachments/assets/c8b0d369-fcd8-4091-9650-5c521767609e\n\n* 'Pin/Unpin' button triggers a new PUT api /pinDashboard to update a new column 'pinned' in 'dashboards' table.\n* On success updation, refetch is triggered to remove cache and update the UI\n\nIf this is as per the expectation, I would raise the PR.  @YounixM  @ankitnayan ", "@harshitrajsinha : Have updated the issue with screenshot to get better understanding of the requirement. Ideally we should just re-render the section.\n", "The dashboard page running on my localhost looks different from the shared image. Not sure its because of different version or configuration\n\n![Image](https://github.com/user-attachments/assets/b883b724-b2b5-4d4f-903f-8a4a1e693c06)", "Hi, I'm new to open source and would love to contribute. Can you please assign this issue to me? \nThanks!" ],
      "repository" : {
        "description" : "SigNoz is an open-source observability platform native to OpenTelemetry with logs, traces and metrics in a single application. An open-source alternative to DataDog, NewRelic, etc. \uD83D\uDD25 \uD83D\uDDA5.   \uD83D\uDC49  Open source Application Performance Monitoring (APM) & Observability tool",
        "homepage" : "https://signoz.io",
        "name" : "signoz",
        "fullName" : "SigNoz/signoz",
        "htmlUrl" : "https://github.com/SigNoz/signoz",
        "gitUrl" : "git://github.com/SigNoz/signoz.git",
        "sshUrl" : "git@github.com:SigNoz/signoz.git",
        "cloneUrl" : "https://github.com/SigNoz/signoz.git",
        "owner" : {
          "login" : "SigNoz",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1620,
        "stargazersCount" : 22737,
        "watchersCount" : 22737,
        "size" : 95410,
        "openIssuesCount" : 1521,
        "subscribersCount" : 122,
        "pushedAt" : "2025-07-11T19:29:47Z",
        "languages" : {
          "TypeScript" : 7191448,
          "Dockerfile" : 725,
          "Shell" : 38255,
          "ANTLR" : 4864,
          "SCSS" : 848997,
          "Makefile" : 9878,
          "JavaScript" : 13968,
          "Go" : 5045126,
          "Python" : 45420,
          "EJS" : 3975
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Users should be able to pin / favorite dashboards in dashboards listing page, which will move pinned dashboards to a separate section",
      "validationOrRequirement" : "Use the preference framework",
      "attemptedFixes" : "The 'Pin/Unpin' button triggers a new PUT api /pinDashboard to update a new column 'pinned' in 'dashboards' table. On success updation, refetch is triggered to remove cache and update the UI",
      "otherNotes" : "The dashboard page running on my localhost looks different from the shared image. Not sure its because of different version or configuration",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284255
  }, {
    "issueDTO" : {
      "id" : 3221425628,
      "title" : "Buttons of specific monitors are to big and go out of view on mobile",
      "url" : "https://github.com/louislam/uptime-kuma/issues/5978",
      "repositoryName" : "louislam/uptime-kuma",
      "description" : "### \uD83D\uDCD1 I have found these related issues/pull requests\n\nButtons are slightly out of view on mobile screens:\n\n<img width=\"548\" height=\"1033\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/950f7947-2033-4f6b-8460-fb7a1eb6c1db\" />\n\n\n<img width=\"1663\" height=\"876\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8ae2b09d-2326-4e2d-b3d1-a1d0d294ad0e\" />\n\n@dev I'll add more info later but it's related to .btn having to much padding on small screens still.\n\n\n### \uD83D\uDEE1??? Security Policy\n\n- [x] I have read and agree to Uptime Kuma's [Security Policy](https://github.com/louislam/uptime-kuma/security/policy).\n\n\n### \uD83D\uDCDD Description\n\n//\n\n### \uD83D\uDC5F Reproduction steps\n\n/\n\n### \uD83D\uDC40 Expected behavior\n\n//\n\n### \uD83D\uDE13 Actual Behavior\n\n//\n\n### \uD83D\uDC3B Uptime-Kuma Version\n\n//\n\n### \uD83D\uDCBB Operating System and Arch\n\n//\n\n### \uD83C\uDF10 Browser\n\n//\n\n### \uD83D\uDDA5??? Deployment Environment\n\n//\n\n\n### \uD83D\uDCDD Relevant log output\n\n```bash session\n\n```",
      "updatedAt" : 1752231063.000000000,
      "user" : "VNRARA",
      "userHtmlUrl" : "https://github.com/VNRARA",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3942672?v=4",
      "labels" : [ "bug", "A:ui/ux", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "should I create a PR for it", "that would be really nice \uD83D\uDC4D\uD83C\uDFFB " ],
      "repository" : {
        "description" : "A fancy self-hosted monitoring tool",
        "homepage" : "https://uptime.kuma.pet",
        "name" : "uptime-kuma",
        "fullName" : "louislam/uptime-kuma",
        "htmlUrl" : "https://github.com/louislam/uptime-kuma",
        "gitUrl" : "git://github.com/louislam/uptime-kuma.git",
        "sshUrl" : "git@github.com:louislam/uptime-kuma.git",
        "cloneUrl" : "https://github.com/louislam/uptime-kuma.git",
        "owner" : {
          "login" : "louislam",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 6354,
        "stargazersCount" : 71779,
        "watchersCount" : 71779,
        "size" : 29555,
        "openIssuesCount" : 777,
        "subscribersCount" : 294,
        "pushedAt" : "2025-07-11T21:41:44Z",
        "languages" : {
          "C#" : 557,
          "PowerShell" : 387,
          "Java" : 908,
          "Vue" : 729299,
          "Go" : 2699,
          "HTML" : 1102,
          "TypeScript" : 23073,
          "Dockerfile" : 4408,
          "Shell" : 2058,
          "SCSS" : 15559,
          "JavaScript" : 945636,
          "PHP" : 322,
          "Python" : 216
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Buttons of specific monitors are too big and go out of view on mobile screens.",
      "validationOrRequirement" : "Related to .btn having too much padding on small screens still.",
      "attemptedFixes" : "",
      "otherNotes" : "Related issues/pull requests will be added later. It's related to .btn having too much padding on small screens still. There is a security policy agreement. Reproduction steps, expected behavior, actual behavior, uptime-kuma version, operating system and arch, browser, and deployment environment details are missing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284259
  }, {
    "issueDTO" : {
      "id" : 3221252684,
      "title" : "1 validation error for I18nObject en_US Input should be a valid string",
      "url" : "https://github.com/langgenius/dify/issues/22179",
      "repositoryName" : "langgenius/dify",
      "description" : "### Self Checks\n\n- [x] This is only for bug report, if you would like to ask a question, please head to [Discussions](https://github.com/langgenius/dify/discussions/categories/general).\n- [x] I have searched for existing issues [search for existing issues](https://github.com/langgenius/dify/issues), including closed ones.\n- [x] I confirm that I am using English to submit this report (????????????????????? [Language Policy](https://github.com/langgenius/dify/issues/1542)).\n- [x] [FOR CHINESE USERS] ??????????????????????????? Issue?????????????????????????????????:)\n- [x] Please do not modify this template :) and fill in all the required fields.\n\n### Dify version\n\n1.6.0\n\n### Cloud or Self Hosted\n\nSelf Hosted (Docker)\n\n### Steps to reproduce\n\n\n??When I updated to version 1.6.0 and clicked on the Tools page, this error appeared, and all tools became invisible.\n\n1 validation error for I18nObject en_US Input should be a valid string [type=string_type, input_value=None, input_type=NoneType] For further information visit https://errors.pydantic.dev/2.11/v/string_type\n\n### ?????? Expected Behavior\n\n<img width=\"1817\" height=\"795\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f83b25f0-7938-4995-a0f1-66e0ecaadd76\" />\n\n### ??? Actual Behavior\n\n_No response_",
      "updatedAt" : 1752230826.000000000,
      "user" : "1193700079",
      "userHtmlUrl" : "https://github.com/1193700079",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/43908729?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<!-- Answer -->\nThis error happens because one or more tools have i18n fields (like label or description) where the `en_US` value is missing or set to `null` instead of a string. This breaks Pydantic validation and causes all tools to disappear from the Tools page.\n\nTo fix it, check your tool metadata (YAML files for built-in tools, or database entries for custom/API tools) and make sure every i18n object has a valid, non-null string for `en_US`???even an empty string is acceptable. After correcting any missing or null values, restart your backend.\n\nRecent changes to i18n files in Dify 1.6.0 may have introduced this issue, so it's worth reviewing any recent updates to your tool definitions or translations as well??[cite](https://github.com/langgenius/dify/pull/21459).\n\nIf you have a lot of tools, consider writing a quick script to scan for missing or null `en_US` fields in your tool configs before restarting. This should resolve the validation error and restore the Tools page.\n\n\n<!-- Dosu Comment Footer -->\n*To reply, just mention [@dosu](https://go.dosu.dev/dosubot).*\n\n---\n<sup>How did I do? [Good](https://app.dosu.dev/response-feedback/2e3fe54f-9f9c-4559-89b7-bc4c4b6eedbd?feedback_type=great_response) | [Irrelevant](https://app.dosu.dev/response-feedback/2e3fe54f-9f9c-4559-89b7-bc4c4b6eedbd?feedback_type=irrelevant_answer) | [Incorrect](https://app.dosu.dev/response-feedback/2e3fe54f-9f9c-4559-89b7-bc4c4b6eedbd?feedback_type=incorrect_sources) | [Verbose](https://app.dosu.dev/response-feedback/2e3fe54f-9f9c-4559-89b7-bc4c4b6eedbd?feedback_type=too_verbose) | [Hallucination](https://app.dosu.dev/response-feedback/2e3fe54f-9f9c-4559-89b7-bc4c4b6eedbd?feedback_type=hallucination) | [Report \uD83D\uDC1B](https://app.dosu.dev/response-feedback/2e3fe54f-9f9c-4559-89b7-bc4c4b6eedbd?feedback_type=bug_report) | [Other](https://app.dosu.dev/response-feedback/2e3fe54f-9f9c-4559-89b7-bc4c4b6eedbd?feedback_type=other)</sup>&nbsp;&nbsp;[![Join Discord](https://img.shields.io/badge/join-5865F2?logo=discord&logoColor=white&label=)](https://go.dosu.dev/discord-bot)&nbsp;[![Share on X](https://img.shields.io/badge/X-share-black)](https://twitter.com/intent/tweet?text=%40dosu_ai%20helped%20me%20solve%20this%20issue!&url=https%3A//github.com/langgenius/dify/issues/22179)", "Please provide more information.\n\nI can not reproduce this issue.", "\n> Please provide more information.\n> \n> I can not reproduce this issue.\n\nThe problem occurred when I modified the MCP in the tools.\n", "<img width=\"2151\" height=\"627\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c6dde9bb-4c58-40ce-8606-c31682c1daeb\" />", "<img width=\"1372\" height=\"1270\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d1176a6c-dedd-4ce9-897b-d12872526500\" />", "I used Google Chrome's Developer Tools to inspect some content, and I hope it will be helpful to you. Since I'm using a local Docker deployment with the latest pulled image, the source code hasn't been modified.", "1.6.0 ????????????MCP ?????????????????????????????????MCP????????????????????????MCP ??????????????????dify????????????????????????????????????????????? ???????????? mcp typescript sdk ?????????mcp ?????????\n\n??????MCP ??????????????????????????????????????????????????????????????????????????????????????????mcp ?????? ??????????????????" ],
      "repository" : {
        "description" : "Production-ready platform for agentic workflow development.",
        "homepage" : "https://dify.ai",
        "name" : "dify",
        "fullName" : "langgenius/dify",
        "htmlUrl" : "https://github.com/langgenius/dify",
        "gitUrl" : "git://github.com/langgenius/dify.git",
        "sshUrl" : "git@github.com:langgenius/dify.git",
        "cloneUrl" : "https://github.com/langgenius/dify.git",
        "owner" : {
          "login" : "langgenius",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16148,
        "stargazersCount" : 106618,
        "watchersCount" : 106618,
        "size" : 103462,
        "openIssuesCount" : 777,
        "subscribersCount" : 653,
        "pushedAt" : "2025-07-11T14:34:26Z",
        "languages" : {
          "TypeScript" : 11601485,
          "MDX" : 865160,
          "Dockerfile" : 4139,
          "CSS" : 182041,
          "Shell" : 19709,
          "SCSS" : 21945,
          "Makefile" : 1304,
          "JavaScript" : 1430743,
          "PHP" : 6106,
          "HTML" : 33871,
          "Mako" : 518,
          "Python" : 6709901
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "1 validation error for I18nObject en_US Input should be a valid string when updating to version 1.6.0 and clicking on the Tools page, causing all tools to become invisible",
      "validationOrRequirement" : "1 validation error for I18nObject en_US Input should be a valid string",
      "attemptedFixes" : "Check tool metadata (YAML files for built-in tools, or database entries for custom/API tools) and make sure every i18n object has a valid, non-null string for `en_US`???even an empty string is acceptable. After correcting any missing or null values, restart the backend.",
      "otherNotes" : "The issue is related to i18n fields in tool metadata where the `en_US` value is missing or set to `null` instead of a string, which breaks Pydantic validation and causes all tools to disappear from the Tools page.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284265
  }, {
    "issueDTO" : {
      "id" : 3215539766,
      "title" : "[DAG] SelectionDAG::canCreateUndefOrPoison - add ISD::AVGFLOORS/AVGFLOORU/AVGCEILS/AVGCEILU handling + tests",
      "url" : "https://github.com/llvm/llvm-project/issues/147696",
      "repositoryName" : "llvm/llvm-project",
      "description" : "- [ ] Create alive2 tests proving AVGFLOOR / AVGCEIL patterns don't create poison/undef\n- [ ] Add ISD::AVGFLOORS/AVGFLOORU/AVGCEILS/AVGCEILU to SelectionDAG::canCreateUndefOrPoison and add suitable test coverage",
      "updatedAt" : 1752230130.000000000,
      "user" : "RKSimon",
      "userHtmlUrl" : "https://github.com/RKSimon",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2175834?v=4",
      "labels" : [ "llvm:SelectionDAG", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\nHi!\n\nThis issue may be a good introductory issue for people new to working on LLVM. If you would like to work on this issue, your first steps are:\n\n1. Check that no other contributor is working on this issue. If someone is assigned to the issue or claimed to be working on it, ping the person. After one week without a response, the assignee may be changed.\n1. Leave a comment indicating that you are working on the issue, or just create a [pull request](https://github.com/llvm/llvm-project/pulls) after following the steps below. [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n1. Fix the issue locally.\n1. [Run the test suite](https://llvm.org/docs/TestingGuide.html#unit-and-regression-tests) locally. Remember that the subdirectories under `test/` create fine-grained testing targets, so you can e.g. use `make check-clang-ast` to only run Clang's AST tests.\n1. Create a Git commit.\n1. Run [`git clang-format HEAD~1`](https://clang.llvm.org/docs/ClangFormat.html#git-integration) to format your changes.\n1. Open a [pull request](https://github.com/llvm/llvm-project/pulls) to the [upstream repository](https://github.com/llvm/llvm-project) on GitHub. Detailed instructions can be found [in GitHub's documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request). [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n\nIf you have any further questions about this issue, don't hesitate to ask via a comment in the thread below.\n\n", "\n@llvm/issue-subscribers-good-first-issue\n\nAuthor: Simon Pilgrim (RKSimon)\n\n<details>\n- [ ] Create alive2 tests proving AVGFLOOR / AVGCEIL patterns don't create poison/undef\n- [ ] Add ISD::AVGFLOORS/AVGFLOORU/AVGCEILS/AVGCEILU to SelectionDAG::canCreateUndefOrPoison and add suitable test coverage\n</details>\n", "Hi @RKSimon \n#148191 marks `ISD::AVGFLOORS` and `ISD::AVGCEILS` as safe in `SelectionDAG::canCreateUndefOrPoison`.\n\nVerified using Alive2 that these operations do **not introduce poison or undef**:\n\n-  [AVGFLOORS proof (Alive2)](https://alive2.llvm.org/ce/z/JWZcNr)\n-  [AVGCEILS proof (Alive2)](https://alive2.llvm.org/ce/z/cW3jrR)\n\nLet me know if further clarification or changes are needed. Thanks!\n" ],
      "repository" : {
        "description" : "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.",
        "homepage" : "http://llvm.org",
        "name" : "llvm-project",
        "fullName" : "llvm/llvm-project",
        "htmlUrl" : "https://github.com/llvm/llvm-project",
        "gitUrl" : "git://github.com/llvm/llvm-project.git",
        "sshUrl" : "git@github.com:llvm/llvm-project.git",
        "cloneUrl" : "https://github.com/llvm/llvm-project.git",
        "owner" : {
          "login" : "llvm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14443,
        "stargazersCount" : 33450,
        "watchersCount" : 33450,
        "size" : 2519038,
        "openIssuesCount" : 30765,
        "subscribersCount" : 577,
        "pushedAt" : "2025-07-12T01:01:34Z",
        "languages" : {
          "GDB" : 8473,
          "CMake" : 4075997,
          "Mustache" : 16482,
          "HTML" : 1956247,
          "Pawn" : 10154,
          "MATLAB" : 4946,
          "Fortran" : 11610249,
          "LLVM" : 631719945,
          "OCaml" : 335815,
          "Assembly" : 150737335,
          "Python" : 12915167,
          "Rust" : 4903,
          "Objective-C++" : 1173632,
          "SWIG" : 287770,
          "Tree-sitter Query" : 6195,
          "Perl" : 183797,
          "MLIR" : 21179643,
          "Cuda" : 1243342,
          "Scilab" : 160404,
          "Starlark" : 1177382,
          "Batchfile" : 52122,
          "AMPL" : 1662,
          "Swift" : 271,
          "DTrace" : 334,
          "C" : 202129658,
          "RPC" : 28,
          "Makefile" : 114902,
          "Cool" : 5401,
          "Jupyter Notebook" : 72939,
          "M" : 9785,
          "TypeScript" : 69121,
          "Shell" : 263950,
          "Awk" : 127345,
          "JavaScript" : 161607,
          "Mathematica" : 1118,
          "Objective-C" : 4269109,
          "Lua" : 12033,
          "PHP" : 64,
          "Limbo" : 303,
          "POV-Ray SDL" : 861,
          "Emacs Lisp" : 69003,
          "C++" : 488688394,
          "CSS" : 63859,
          "FIRRTL" : 4298018,
          "TeX" : 2141,
          "AppleScript" : 1429,
          "NASL" : 35217,
          "HIP" : 856703,
          "Julia" : 49676,
          "Dockerfile" : 23252,
          "Linker Script" : 903,
          "Roff" : 60700,
          "HLSL" : 1475332,
          "Mercury" : 14,
          "Vim Script" : 29186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add ISD::AVGFLOORS/AVGFLOORU/AVGCEILS/AVGCEILU handling and tests to SelectionDAG::canCreateUndefOrPoison",
      "validationOrRequirement" : "Create alive2 tests and add test coverage",
      "attemptedFixes" : "Verified using Alive2 that ISD::AVGFLOORS and ISD::AVGCEILS do not introduce poison or undef",
      "otherNotes" : "Create alive2 tests proving AVGFLOOR / AVGCEIL patterns don't create poison/undef, add ISD::AVGFLOORS/AVGFLOORU/AVGCEILS/AVGCEILU to SelectionDAG::canCreateUndefOrPoison and add suitable test coverage",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284270
  }, {
    "issueDTO" : {
      "id" : 3215459473,
      "title" : "Incorrect help text on system terminal settings",
      "url" : "https://github.com/codefori/vscode-ibmi/issues/2783",
      "repositoryName" : "codefori/vscode-ibmi",
      "description" : "The system terminal settings list the example connection string as \"ssl:localhost 992\" which is missing the colon between the host and port.\n\nEntering it like that causes a route to host not found error and fails to start the emilator.\n\n\n|Context|Version|\n|-|-|\n|Code for IBM i version|2.16.3|\n|Visual Studio Code version|1.101.2|\n|Operating System|win32_x64|\n",
      "updatedAt" : 1752230083.000000000,
      "user" : "pnicolay",
      "userHtmlUrl" : "https://github.com/pnicolay",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13331910?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello, text changed in \n\n<img width=\"751\" height=\"145\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8f9ab8b3-988b-4296-80eb-a0d7fa3c0c61\" />", "Actually the template is wrong now (it's missing the colon after the options), it should be [options:]HOST[:PORT]   \n\nIe. it is \"ssl:localhost:992\" and not \"ssl localhost:992\"\n\nPS. I noticed that the port number automatically defaults to 992 when ssl is specified as option.", "> Actually the template is wrong now (it's missing the colon after the options), it should be [options:]HOST[:PORT]\n> \n> Ie. it is \"ssl:localhost:992\" and not \"ssl localhost:992\"\n\nThat template looks good to me. Actual options (e.g. `+uninhibited`) are specified before the host definition and don't require a colon, and the host definition is `[ssl:]host[:port]`.\n" ],
      "repository" : {
        "description" : "\uD83C\uDF0D IBM i development extension for VS Code",
        "homepage" : "https://codefori.github.io/docs/#/",
        "name" : "vscode-ibmi",
        "fullName" : "codefori/vscode-ibmi",
        "htmlUrl" : "https://github.com/codefori/vscode-ibmi",
        "gitUrl" : "git://github.com/codefori/vscode-ibmi.git",
        "sshUrl" : "git@github.com:codefori/vscode-ibmi.git",
        "cloneUrl" : "https://github.com/codefori/vscode-ibmi.git",
        "owner" : {
          "login" : "codefori",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 111,
        "stargazersCount" : 328,
        "watchersCount" : 328,
        "size" : 17763,
        "openIssuesCount" : 82,
        "subscribersCount" : 26,
        "pushedAt" : "2025-07-06T08:54:38Z",
        "languages" : {
          "TypeScript" : 896803,
          "C" : 279,
          "JavaScript" : 2960
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Correct the help text on system terminal settings to include a colon between the host and port.",
      "validationOrRequirement" : "The help text should be corrected to include a colon between the host and port.",
      "attemptedFixes" : "None mentioned in the issue description or comments",
      "otherNotes" : "The template is missing a colon after the options, and the port number defaults to 992 when ssl is specified as an option.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284273
  }, {
    "issueDTO" : {
      "id" : 3053310737,
      "title" : "[pt] Localize docs/contributing/acknowledgements.md",
      "url" : "https://github.com/open-telemetry/opentelemetry.io/issues/6861",
      "repositoryName" : "open-telemetry/opentelemetry.io",
      "description" : "## Description\n\n**What needs to be changed?** \n\nThis issue is part of the Portuguese localization for the pages under the `contributing` directory.\n\nURL: https://opentelemetry.io/pt/docs/contributing/acknowledgements/\n\n**What is the name + path of the page that needs changed?** \n\n* [content/en/docs/contributing/acknowledgements.md](https://github.com/open-telemetry/opentelemetry.io/blob/main/content/en/docs/contributing/acknowledgements.md)\n\n## How to contribute\n\n1. Read [this guide](https://vasconcellos.dev/posts/2024-07-26-guia-contribuicao-otel-docs-pt) to familiarize yourself with the contribution process.\n2. Comment on this issue about which page you want to localize.\n3. If you have any questions, let us know at [#otel-localization-ptbr](https://cloud-native.slack.com/archives/C076LET8YSK).",
      "updatedAt" : 1752229984.000000000,
      "user" : "vitorvasc",
      "userHtmlUrl" : "https://github.com/vitorvasc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12118857?v=4",
      "labels" : [ "lang:pt", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The OpenTelemetry website and documentation",
        "homepage" : "https://opentelemetry.io",
        "name" : "opentelemetry.io",
        "fullName" : "open-telemetry/opentelemetry.io",
        "htmlUrl" : "https://github.com/open-telemetry/opentelemetry.io",
        "gitUrl" : "git://github.com/open-telemetry/opentelemetry.io.git",
        "sshUrl" : "git@github.com:open-telemetry/opentelemetry.io.git",
        "cloneUrl" : "https://github.com/open-telemetry/opentelemetry.io.git",
        "owner" : {
          "login" : "open-telemetry",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1450,
        "stargazersCount" : 727,
        "watchersCount" : 727,
        "size" : 66736,
        "openIssuesCount" : 452,
        "subscribersCount" : 62,
        "pushedAt" : "2025-07-11T10:32:16Z",
        "languages" : {
          "Shell" : 22122,
          "CSS" : 888,
          "SCSS" : 11412,
          "Makefile" : 1959,
          "JavaScript" : 56541,
          "HTML" : 47175,
          "Perl" : 32882
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Localize the page [content/en/docs/contributing/acknowledgements.md](https://github.com/open-telemetry/opentelemetry.io/blob/main/content/en/docs/contributing/acknowledgements.md) to Portuguese.",
      "validationOrRequirement" : "Read [this guide](https://vasconcellos.dev/posts/2024-07-26-guia-contribuicao-otel-docs-pt) to familiarize yourself with the contribution process.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is part of the Portuguese localization for the pages under the `contributing` directory.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284277
  }, {
    "issueDTO" : {
      "id" : 2134049780,
      "title" : "[Bug]: Overscroll in Firefox not following background color",
      "url" : "https://github.com/zitadel/zitadel/issues/7387",
      "repositoryName" : "zitadel/zitadel",
      "description" : "### Preflight Checklist\n\n- [X] I could not find a solution in the documentation, the existing issues or discussions\n- [ ] I have joined the [ZITADEL chat](https://zitadel.com/chat)\n\n### Environment\n\nSelf-hosted\n\n### Version\n\nUnknown\n\n### Database\n\nNone\n\n### Database Version\n\nUnknown\n\n### Describe the problem caused by this bug\n\nWhen using overscroll in firefox, the background color of the selected theme is not respected and defaults to white. See below screenshot as an example. My guess is that this is likely because the root element does not have its background color changed.\n\n### To reproduce\n\n1. Open Firefox\r\n2. Go to `about:config`\r\n3. Enable `apz.overscroll.enabled`\n\n### Screenshots\n\n![Screenshot from 2024-02-14 11-42-36](https://github.com/zitadel/zitadel/assets/20756843/be900540-9ece-441f-8de4-80de001500dd)\n\n### Expected behavior\n\nThe background color is respected in overscroll section.\n\n### Operating System\n\n- Linux Wayland\r\n- Firefox 121.0\n\n### Relevant Configuration\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752229864.000000000,
      "user" : "soupglasses",
      "userHtmlUrl" : "https://github.com/soupglasses",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20756843?v=4",
      "labels" : [ "bug", "presentation-layer", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "ZITADEL - Identity infrastructure, simplified for??you.",
        "homepage" : "https://zitadel.com",
        "name" : "zitadel",
        "fullName" : "zitadel/zitadel",
        "htmlUrl" : "https://github.com/zitadel/zitadel",
        "gitUrl" : "git://github.com/zitadel/zitadel.git",
        "sshUrl" : "git@github.com:zitadel/zitadel.git",
        "cloneUrl" : "https://github.com/zitadel/zitadel.git",
        "owner" : {
          "login" : "zitadel",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 750,
        "stargazersCount" : 11066,
        "watchersCount" : 11066,
        "size" : 508548,
        "openIssuesCount" : 821,
        "subscribersCount" : 58,
        "pushedAt" : "2025-07-11T15:59:50Z",
        "languages" : {
          "TypeScript" : 2621514,
          "HCL" : 4886,
          "Dockerfile" : 16391,
          "CSS" : 112445,
          "Shell" : 8870,
          "SCSS" : 364864,
          "PLpgSQL" : 19982,
          "Makefile" : 19502,
          "JavaScript" : 38863,
          "Go" : 16948784,
          "HTML" : 779185
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Overscroll in Firefox not following background color, when using a selected theme",
      "validationOrRequirement" : "Background color of the selected theme should be respected in overscroll section",
      "attemptedFixes" : "No specific fix or blocker mentioned",
      "otherNotes" : "No response for Operating System and Relevant Configuration",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284280
  }, {
    "issueDTO" : {
      "id" : 2097207980,
      "title" : "[Bug]: Branding, Logo/icon  Changed After Page Reload",
      "url" : "https://github.com/zitadel/zitadel/issues/7284",
      "repositoryName" : "zitadel/zitadel",
      "description" : "### Preflight Checklist\r\n\r\n- [X] I could not find a solution in the documentation, the existing issues or discussions\r\n- [X] I have joined the [ZITADEL chat](https://zitadel.com/chat)\r\n\r\n### Environment\r\n\r\nSelf-hosted\r\n\r\n### Version\r\n\r\nv2.42.11\r\n\r\n### Database\r\n\r\nCockroachDB\r\n\r\n### Database Version\r\n\r\nv23.1.12\r\n\r\n### Describe the problem caused by this bug\r\n\r\nI grabbed the source  from _main_ then I ran  the Makefile in my build. \r\n\r\n Everything works as expected no issues  on Projects/Organizations, configuration files. I tested out the ???Branding??? section. It seems to work well but I noticed something strange.  I Logout All Users  and  refreshed the signout page and logo changed back to  Zitadel. \r\n \r\nAt first I thought it was a user error  ( i.e., Me) for modifying  pages before the build.  I executed a  control test without modifying  and just built from _main_.  Started  Zitadel then  went to the Branding, section uploaded my logo/icon.  Clicked on \r\n\"LogOut All Users\" button.   logo and icon are shown , Reload page and Zitadel logo icon reappeared .\r\n\r\n\r\n\r\n### To reproduce\r\n\r\n```\r\ngit clone  https://github.com/<user_name>/zitadel.git\r\n```\r\n```\r\nmake\r\n```\r\n```\r\nzitadel  start-from-init  --config defaults.yaml --steps steps.yaml --masterkey \"MasterkeyNeedsToHave32Characters\"  --tlsMode external \r\n```\r\n\r\nNavigated to the Branding section, uploaded my logo/icon.  \r\nClicked on \"LogOut All Users\" button.  \r\nLogo and icon are shown , Reload page and Zitadel logo icon reappeared .\r\n\r\n ###Screenshots\r\n\r\nLoggout:\r\n\r\n![image](https://github.com/zitadel/zitadel/assets/22652276/ddcc0e9c-c34c-4277-8a57-c8fa95a01d94)\r\n\r\nReloaded page:\r\n\r\n![image](https://github.com/zitadel/zitadel/assets/22652276/e7729f8f-eb18-4c10-957e-e90302054dfd)\r\n\r\n### Expected behavior\r\n\r\nExepected the logo and icon to stay when refreshing/reloading page\r\n\r\n### Operating System\r\n\r\nUbuntu 22.0.4\r\n\r\n\r\n### Relevant Configuration\r\n\r\nNone\r\n\r\n\r\n### Additional Context\r\n\r\n_No response_",
      "updatedAt" : 1752229828.000000000,
      "user" : "HungryHowies",
      "userHtmlUrl" : "https://github.com/HungryHowies",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22652276?v=4",
      "labels" : [ "bug", "presentation-layer", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "@peintnermax @livio-a This issue sounds familiar to me. I think we did have something similar already once. ", "i thought it might be in the login UI were we lose the context of the previously used organisation or something, but looks like this is in console, but probably has the same issue @peintnermax ", "The problem here is that after reload, the api can't be fetched as we use the token of the signed in user to load the images.. You could replace the images in the assets folder to change the fallback\r\n`console/src/assets/images/zitadel-logo-dark.svg` and `console/src/assets/images/zitadel-logo-light.svg`", "> The problem here is that after reload, the api can't be fetched as we use the token of the signed in user to load the images.. You could replace the images in the assets folder to change the fallback `console/src/assets/images/zitadel-logo-dark.svg` and `console/src/assets/images/zitadel-logo-light.svg`\r\n\r\nI did modify it, I just  redirected to a different image.\r\n\r\nEDIT: I should have said , I fixed  as your suggestion.\r\n\r\n![image](https://github.com/zitadel/zitadel/assets/22652276/758bc1f7-23c1-4961-bb9c-f1b3d1d6b5ef)\r\n\r\n\r\n" ],
      "repository" : {
        "description" : "ZITADEL - Identity infrastructure, simplified for??you.",
        "homepage" : "https://zitadel.com",
        "name" : "zitadel",
        "fullName" : "zitadel/zitadel",
        "htmlUrl" : "https://github.com/zitadel/zitadel",
        "gitUrl" : "git://github.com/zitadel/zitadel.git",
        "sshUrl" : "git@github.com:zitadel/zitadel.git",
        "cloneUrl" : "https://github.com/zitadel/zitadel.git",
        "owner" : {
          "login" : "zitadel",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 750,
        "stargazersCount" : 11066,
        "watchersCount" : 11066,
        "size" : 508548,
        "openIssuesCount" : 821,
        "subscribersCount" : 58,
        "pushedAt" : "2025-07-11T15:59:50Z",
        "languages" : {
          "TypeScript" : 2621514,
          "HCL" : 4886,
          "Dockerfile" : 16391,
          "CSS" : 112445,
          "Shell" : 8870,
          "SCSS" : 364864,
          "PLpgSQL" : 19982,
          "Makefile" : 19502,
          "JavaScript" : 38863,
          "Go" : 16948784,
          "HTML" : 779185
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The branding logo/icon changes back to Zitadel after page reload, even after logging out all users and uploading a custom logo/icon.",
      "validationOrRequirement" : "None mentioned in the issue description or comments.",
      "attemptedFixes" : "The author attempted to fix the issue by modifying the images in the assets folder, and also tried redirecting to a different image.",
      "otherNotes" : "The issue seems to be related to the API not being able to fetch images after reload, as it uses the token of the signed in user to load the images. A possible solution is to replace the images in the assets folder to change the fallback.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284284
  }, {
    "issueDTO" : {
      "id" : 3220205898,
      "title" : "Prerequisite Tree leading branch on unavailable mods",
      "url" : "https://github.com/nusmodifications/nusmods/issues/4103",
      "repositoryName" : "nusmodifications/nusmods",
      "description" : "### Describe the bug\n\n`ModuleTree` node has a leading branch when\n\n1. The class is not currently offered and\n2. The class is not a prerequisite for another mod\n\n<img width=\"568\" height=\"170\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/371459ee-60d3-4ae5-8d0b-6b72f019c759\" />\n\n### To Reproduce\n\nReproducible on Chrome and Firefox.\n\nSteps to reproduce the behavior:\n\n1. Go to https://nusmods.com/courses/CS6202/advanced-topics-in-programming-languages or https://nusmods.com/courses/CS5271/performance-analysis-of-embedded-systems\n\n### Expected behavior\n\nShould not have a leading branch:\n\n<img width=\"898\" height=\"324\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f16992bb-0350-46c1-8802-5a02f5613c64\" />",
      "updatedAt" : 1752229706.000000000,
      "user" : "leslieyip02",
      "userHtmlUrl" : "https://github.com/leslieyip02",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/90888680?v=4",
      "labels" : [ "prerequisite tree", "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I am interested to work on this" ],
      "repository" : {
        "description" : "\uD83C\uDFEB Official course planning platform for National University of Singapore.",
        "homepage" : "https://nusmods.com",
        "name" : "nusmods",
        "fullName" : "nusmodifications/nusmods",
        "htmlUrl" : "https://github.com/nusmodifications/nusmods",
        "gitUrl" : "git://github.com/nusmodifications/nusmods.git",
        "sshUrl" : "git@github.com:nusmodifications/nusmods.git",
        "cloneUrl" : "https://github.com/nusmodifications/nusmods.git",
        "owner" : {
          "login" : "nusmodifications",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 337,
        "stargazersCount" : 621,
        "watchersCount" : 621,
        "size" : 50165,
        "openIssuesCount" : 186,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T15:59:22Z",
        "languages" : {
          "TypeScript" : 1467488,
          "CSS" : 14492,
          "Shell" : 5956,
          "Pug" : 946,
          "ANTLR" : 2895,
          "SCSS" : 139629,
          "JavaScript" : 83587,
          "Go" : 26565,
          "HTML" : 3760,
          "EJS" : 2514
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the Prerequisite Tree leading branch on unavailable mods",
      "validationOrRequirement" : "The class must be currently offered and must be a prerequisite for another mod, or the class must not be currently offered and must not be a prerequisite for another mod",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is related to the Prerequisite Tree and a leading branch on unavailable mods, with specific conditions and expected behavior described.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284288
  }, {
    "issueDTO" : {
      "id" : 3191932448,
      "title" : "Tests",
      "url" : "https://github.com/kinisi-dev/kinisi/issues/99",
      "repositoryName" : "kinisi-dev/kinisi",
      "description" : "We need unit tests for all parts of the scipp kinisi code. There isn???t really any currently. ",
      "updatedAt" : 1752229688.000000000,
      "user" : "arm61",
      "userHtmlUrl" : "https://github.com/arm61",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15774281?v=4",
      "labels" : [ "sprint", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This will be a good issue for new developers to cut their teeth on ", "#107 deals with the tests for `displacement.py`.", "- `test_arrhenius.py`: @arm61 ??? \n- `test_diffusion.py`: @Harry-Rich ??? \n- `test_parser.py` and save/load tests: @osoulas \n- `test_ase.py`: @jd15489 \n- `test_pymatgen.py`: @jd15489 \n- `test_mdanalysis.py`: @jd15489 or @osoulas \n- `test_analyze.py`: @arm61 " ],
      "repository" : {
        "description" : "A Python package for estimating diffusion properties from molecular dynamics simulations.",
        "homepage" : "https://kinisi.readthedocs.io",
        "name" : "kinisi",
        "fullName" : "kinisi-dev/kinisi",
        "htmlUrl" : "https://github.com/kinisi-dev/kinisi",
        "gitUrl" : "git://github.com/kinisi-dev/kinisi.git",
        "sshUrl" : "git@github.com:kinisi-dev/kinisi.git",
        "cloneUrl" : "https://github.com/kinisi-dev/kinisi.git",
        "owner" : {
          "login" : "kinisi-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 69,
        "watchersCount" : 69,
        "size" : 166693,
        "openIssuesCount" : 20,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T16:16:23Z",
        "languages" : {
          "TeX" : 8534,
          "Python" : 230066
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add unit tests for all parts of the scipp kinisi code.",
      "validationOrRequirement" : "All parts of the scipp kinisi code need to have unit tests.",
      "attemptedFixes" : "Some specific tests have been completed, including `test_arrhenius.py`, `test_diffusion.py`, `test_parser.py`, and save/load tests.",
      "otherNotes" : "The issue is related to the need for unit tests for all parts of the scipp kinisi code, with some specific tests already completed.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284291
  }, {
    "issueDTO" : {
      "id" : 1879900083,
      "title" : "[Bug]: logo not shown on first load",
      "url" : "https://github.com/zitadel/zitadel/issues/6484",
      "repositoryName" : "zitadel/zitadel",
      "description" : "### Preflight Checklist\n\n- [X] I could not find a solution in the documentation, the existing issues or discussions\n- [ ] I have joined the [ZITADEL chat](https://zitadel.com/chat)\n\n### Environment\n\nSelf-hosted\n\n### Version\n\nlatest\n\n### Describe the problem caused by this bug\n\nI added a logo to the default organization.\nStarting in private browsing mode and navigating to my domain `auth.example.com`, the logo is not shown. (Actually there is some other page flashing before the login form, which is also not that nice)\n\nOnce I reload the page, the logo is shown.\n\nThis can be reproduced. After closing the browser and opening a new private session, the logo is again only appearing after a refresh.\n\n\n### To reproduce\n\n1. Add logo\n2. Browse to domain\n3. See this page flashing for ~1s:\n![image](https://github.com/zitadel/zitadel/assets/74715856/081ed10a-86a5-4b8a-8ab9-f0a1c84d4376)\n\n4. See login form without logo\n`<img>` tag is missing:\n![image](https://github.com/zitadel/zitadel/assets/74715856/cc445425-2162-4245-ab1f-2552a3e275ab)\n\n5. Refresh\n`<img>` tag is there:\n![image](https://github.com/zitadel/zitadel/assets/74715856/84687e99-3d38-42f3-bd95-af2250e2bb47)\n\n\n### Screenshots\n\n_No response_\n\n### Expected behavior\n\n_No response_\n\n### Operating System\n\nLatest Chrome & Edge\n\n### Relevant Configuration\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752229642.000000000,
      "user" : "some-user123",
      "userHtmlUrl" : "https://github.com/some-user123",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/74715856?v=4",
      "labels" : [ "bug", "presentation-layer", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hei @some-user123 \r\nThanks for adding the bug report.\r\nI will add the issue to our \"bug fixing\" column.\r\nIn each sprint we have a bug fixing day where we take those issues in.", "Maybe an addition to this bug. I have uploaded a logo for both dark theme and light theme, but when viewing this logo on dark theme I noticed it didn't look to great. After altering the logo in the dark theme, it still shows the old logo on first load and after refreshing it shows the new logo.\r\nThis is with an implementation with Postgres.", "@some-user123 or @Koen-Nocore is this still an issue? If so can you please provide us a HAR file.", "Sorry, I don't have zitadel instance ready at hand to test. We've finished the evalution and aren't currently using it." ],
      "repository" : {
        "description" : "ZITADEL - Identity infrastructure, simplified for??you.",
        "homepage" : "https://zitadel.com",
        "name" : "zitadel",
        "fullName" : "zitadel/zitadel",
        "htmlUrl" : "https://github.com/zitadel/zitadel",
        "gitUrl" : "git://github.com/zitadel/zitadel.git",
        "sshUrl" : "git@github.com:zitadel/zitadel.git",
        "cloneUrl" : "https://github.com/zitadel/zitadel.git",
        "owner" : {
          "login" : "zitadel",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 750,
        "stargazersCount" : 11066,
        "watchersCount" : 11066,
        "size" : 508548,
        "openIssuesCount" : 821,
        "subscribersCount" : 58,
        "pushedAt" : "2025-07-11T15:59:50Z",
        "languages" : {
          "TypeScript" : 2621514,
          "HCL" : 4886,
          "Dockerfile" : 16391,
          "CSS" : 112445,
          "Shell" : 8870,
          "SCSS" : 364864,
          "PLpgSQL" : 19982,
          "Makefile" : 19502,
          "JavaScript" : 38863,
          "Go" : 16948784,
          "HTML" : 779185
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Logo is not displayed on first load in private browsing mode, but appears after refresh",
      "validationOrRequirement" : "Logo should be shown on first load in private browsing mode",
      "attemptedFixes" : "None mentioned in comments",
      "otherNotes" : "Logo not shown on first load in private browsing mode, but appears after refresh. Can be reproduced by adding logo, browsing to domain, and refreshing the page.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284295
  }, {
    "issueDTO" : {
      "id" : 3144920125,
      "title" : "FEATURE REQUEST: Persistent Memory Storage for checkpoints",
      "url" : "https://github.com/AOSSIE-Org/Devr.AI/issues/78",
      "repositoryName" : "AOSSIE-Org/Devr.AI",
      "description" : "### Is your feature request related to a problem?\n\n- [x] Yes, it is related to a problem\n\n### Describe the feature you'd like\n\n# Implement Persistent Memory Storage for LG Checkpoints\n## Refers #73 \n### \uD83C\uDF1F Feature Description  \nImplement persistent database storage for conversation summaries, user interactions, and agent state management. Currently, all memory is lost when the application restarts. \n\n### \uD83D\uDD0D Problem Statement  \n- InMemorySaver() loses all conversation history and summaries on application restart\n- `store_summary_to_database()` function in `summarization_node.py` is a placeholder\n- User interaction history is not persisted to the database\n- No long-term memory across sessions for personalized user experiences\n- Thread management relies on volatile memory storage\n\n### \uD83C\uDFAF Expected Outcome  \n- Persistent conversation memory that survives application restarts\n- Automatic storage of conversation summaries in Supabase `interactions` table\n- User profile updates based on conversation history\n- Long-term memory for personalized DevRel assistance\n- Database-backed checkpointing instead of InMemorySaver()\n\n### Record\n\n- [x] I agree to follow this project's Code of Conduct\n- [x] I want to work on implementing this feature",
      "updatedAt" : 1752229628.000000000,
      "user" : "smokeyScraper",
      "userHtmlUrl" : "https://github.com/smokeyScraper",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/116462808?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi Can I work on this issue if this Is open to take up?", "Hi @ShivamMenda,\nThanks for taking an interest in this issue! Yupp, you can definitely give it a go.\n\nPlease make sure to refer to #73 for a bit more details on this part.\nThe current system only uses InMemorySaver() to store users' memory threads, which ends up as a bottleneck once the number of users increases. To mitigate this, we planned on a hybrid system where, after a timeout of a discord thread, the whole conversation context gets summarized and gets stored in a persistent DB, preferably Supabase, which can later be fetched once a user seeks DevRel help via a DB call. This way, context isn't lost and the agent responds as per the user's preferences. \n\nRefer to ```AsyncPostgresSaver``` in LangGraph for this part. Explore out Memory and Persistence in LangGraph docs to read more this part. [lg-postgres](https://pypi.org/project/langgraph-checkpoint-postgres/) [lg-postgres-persistence-doc](https://langchain-ai.github.io/langgraph/how-tos/persistence/#use-in-production)\n\n<details><summary>Workflow Planned</summary>\n<p>\n\n## Memory Persistence:\n\nMemory ??? Context + Chat Convos + WebSearch (Merges to Chat Convos)\n\nStorage in the DB after summarization and timeouts of the user thread.\n\nActive conversation (InMemorySaver)\n\n1. User message ??? LangGraph with InMemorySaver\n2. Every N interactions ??? Summarize + Update context to this\n3. Continue the conversation in memory\n\nSession Timeout \n\n1. Store the final summary in PostgreSQL\n2. Clear from InMemorySaver()\n3. User returns later ??? gather_context_node loads from PostgreSQL\n\n</p>\n</details> ", "Hi @smokeyScraper  Sure will work on this, pretty new to langgraph and looks like an interesting problem to solve, will research and stark taking It up", "Hello, can I also work on the same issue. I am new to open source contribution but would like to give it a try.", "hey @DhruvK278 ,\nyepp, you can surely give it a go!\n\nHave you tried running the codebase? and testing around? make sure to populate the ```.env``` by referring to ```.env.example```\nThe issue isn't very much complex, testing of issue might end-up a bit of problem for you as it requires setting up Supabase database. You can ```backend/app/database/supabase``` for this part btw, but just dm me if you face any problem while running the application.", "@smokeyScraper Hi I was having an issue with supabase setup and regarding that I have sent u a dm on your discord id.", "I have assigned the issue to you @DhruvK278, please make sure to refer the docs referenced in the thread.\nAll the things associated with temporary storage of threads work, we just need to implement ```store_summary_to_database``` function as detailed in the issue and check it's connection throughout the codebase if required." ],
      "repository" : {
        "description" : "Devr.AI is an advanced AI-powered Developer Relations (DevRel) assistant designed to revolutionize open-source community management. By integrating with platforms like Discord, Slack, GitHub, and Discourse, Devr.AI functions as a virtual DevRel advocate that helps maintainers engage with contributors and streamline onboarding processes.",
        "homepage" : "https://devr-ai.netlify.app/",
        "name" : "Devr.AI",
        "fullName" : "AOSSIE-Org/Devr.AI",
        "htmlUrl" : "https://github.com/AOSSIE-Org/Devr.AI",
        "gitUrl" : "git://github.com/AOSSIE-Org/Devr.AI.git",
        "sshUrl" : "git@github.com:AOSSIE-Org/Devr.AI.git",
        "cloneUrl" : "https://github.com/AOSSIE-Org/Devr.AI.git",
        "owner" : {
          "login" : "AOSSIE-Org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 32,
        "stargazersCount" : 25,
        "watchersCount" : 25,
        "size" : 1260,
        "openIssuesCount" : 17,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-10T21:47:49Z",
        "languages" : {
          "TypeScript" : 184380,
          "CSS" : 2085,
          "JavaScript" : 2588,
          "HTML" : 1675,
          "Python" : 231900
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement Persistent Memory Storage for checkpoints, the goal is to store conversation summaries, user interactions, and agent state management in a persistent database, and to enable long-term memory across sessions for personalized user experiences.",
      "validationOrRequirement" : "Implement persistent database storage for conversation summaries, user interactions, and agent state management, automatic storage of conversation summaries in Supabase `interactions` table, user profile updates based on conversation history, long-term memory for personalized DevRel assistance, and database-backed checkpointing instead of InMemorySaver().",
      "attemptedFixes" : "None mentioned in the issue description, but the author suggested that the issue isn't very complex and testing might end up a bit of problem due to the requirement of setting up Supabase database.",
      "otherNotes" : "The issue is related to a problem, the problem statement includes InMemorySaver() losing all conversation history and summaries on application restart, user interaction history not persisted to the database, no long-term memory across sessions for personalized user experiences, and thread management relies on volatile memory storage.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284302
  }, {
    "issueDTO" : {
      "id" : 1771748451,
      "title" : "[Bug]: New user via external login can delete their IdP link and make their account inaccessible",
      "url" : "https://github.com/zitadel/zitadel/issues/6081",
      "repositoryName" : "zitadel/zitadel",
      "description" : "### Preflight Checklist\n\n- [X] I could not find a solution in the documentation, the existing issues or discussions\n- [X] I have joined the [ZITADEL chat](https://zitadel.com/chat)\n\n### Environment\n\nSelf-hosted\n\n### Version\n\n_No response_\n\n### Describe the problem caused by this bug\n\nI was testing the UX for an unprivileged user. I have an organization set up where username/password login is disallowed, and it has a single external IdP which is the only way to sign on. Registration is allowed and accounts are created automatically.\r\n\r\nAfter signing in a new user so the registration happened, I browsed around the console looking for ways an unprivileged user could get themselves in trouble.\r\n\r\nIn the \"Identity Providers\" panel, there is a delete control for the IdP. The user is able to delete this, and if they do they are screwed. There's no way to re-link the external login to the existing account, but you also can't create a new account since the account already exists.\r\n\r\nReally, the user should not be able to perform this action. Also, since they can't, the delete button should not appear. (This is fairly common - for example in Authorizations a delete button is shown for a role, but in this case clicking it just returns an error due to lack of privileges)\r\n\r\nSecondarily, the dialog for this does not have proper localization.\n\n### To reproduce\n\n1. Create an organization that is authenticated only by external IdP\r\n2. Create a new account within that organization (auto-create on login)\r\n3. Navigate to Identity Providers panel\r\n4. Shoot self in foot.\n\n### Screenshots\n\n<img width=\"1824\" alt=\"image\" src=\"https://github.com/zitadel/zitadel/assets/5760081/1f944e9e-33a3-4edb-94cd-f99de861dd01\">\r\n\n\n### Expected behavior\n\n* User is unable to perform a fatal action, especially given lack of privileges.\r\n* Less good alternative - there is a way to recover such an account / re-link for the user.\n\n### Operating System\n\n_No response_\n\n### Relevant Configuration\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752229403.000000000,
      "user" : "kraney",
      "userHtmlUrl" : "https://github.com/kraney",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5760081?v=4",
      "labels" : [ "bug", "presentation-layer", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Version is 2.28.1. Not sure why it shows \"No response\".", "Hm lets us look into this.\r\n\r\n", "Hei @kraney \r\nThanks for opening up the report. With our users profile page we want to give a standard ui that fits multiple use cases. If you have other needs than that we recommend building your own ui.\r\n\r\nThere are use cases where you want to enable your users to manage their own identity provider links. Imaging you have a SaaS application for End users like an online shop, spotify or netflix. In that case you want your users to be able to link their Google account or to remove it if they don't have it anymore.\r\n\r\nSo I do not agree that this should not be possible at all.\r\nWhere I do agree is that the self recovery part on the side of ZITADEL is not yet good enough. The users should either not be able to delete the \"last\" authentication possibility or should be able to recover the account in that case. ", "There is a similar bug to this that I have hit on a production database.\r\ndisabling \"Username Password allowed\" will disallow existing users from logging in with their usernames and passwords, so if the admin account doesn't have an external Idp, you are basically locked out of the instance for good.", "> There is a similar bug to this that I have hit on a production database. disabling \"Username Password allowed\" will disallow existing users from logging in with their usernames and passwords, so if the admin account doesn't have an external Idp, you are basically locked out of the instance for good.\r\n\r\nYeah that is a slight annoyance \uD83D\uDE01\r\n\r\n@hifabienne I think we need to come up with either a safeguard for this or a cli that can resolve this problem, what do you think?", "> > There is a similar bug to this that I have hit on a production database. disabling \"Username Password allowed\" will disallow existing users from logging in with their usernames and passwords, so if the admin account doesn't have an external Idp, you are basically locked out of the instance for good.\r\n> \r\n> Yeah that is a slight annoyance \uD83D\uDE01\r\n> \r\n> @hifabienne I think we need to come up with either a safeguard for this or a cli that can resolve this problem, what do you think?\r\n\r\nYes, I think the right way would be to have the possibility to login one more time with the username password and to setup the external provider.", "I've checked the options and TBD in the meeting today:\r\n1. Prevent remove:\r\nTo discuss where to prevent (Console or backend) and check if a password is set (and allowed to be used / local auth enabled)\r\n2. Recovery:\r\nWould be possible with the new APIs:\r\n    - RetrieveIdentityProviderIntent provides all the infos\r\n    - Check if user exists (loginname / email query on ListUsers)\r\n    - Use the infos to AddIDPLink on existing user", "As discussed with @muhlemmer , we propose to add a warning in Console, but not preventing the delete itself." ],
      "repository" : {
        "description" : "ZITADEL - Identity infrastructure, simplified for??you.",
        "homepage" : "https://zitadel.com",
        "name" : "zitadel",
        "fullName" : "zitadel/zitadel",
        "htmlUrl" : "https://github.com/zitadel/zitadel",
        "gitUrl" : "git://github.com/zitadel/zitadel.git",
        "sshUrl" : "git@github.com:zitadel/zitadel.git",
        "cloneUrl" : "https://github.com/zitadel/zitadel.git",
        "owner" : {
          "login" : "zitadel",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 750,
        "stargazersCount" : 11066,
        "watchersCount" : 11066,
        "size" : 508548,
        "openIssuesCount" : 821,
        "subscribersCount" : 58,
        "pushedAt" : "2025-07-11T15:59:50Z",
        "languages" : {
          "TypeScript" : 2621514,
          "HCL" : 4886,
          "Dockerfile" : 16391,
          "CSS" : 112445,
          "Shell" : 8870,
          "SCSS" : 364864,
          "PLpgSQL" : 19982,
          "Makefile" : 19502,
          "JavaScript" : 38863,
          "Go" : 16948784,
          "HTML" : 779185
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to prevent a new user via external login from deleting their IdP link and making their account inaccessible, and to provide a way for the user to recover their account if they do delete the link.",
      "validationOrRequirement" : "The user should not be able to delete the IdP link, and the delete button should not appear. The dialog for this does not have proper localization.",
      "attemptedFixes" : "Prevent remove: To discuss where to prevent (Console or backend) and check if a password is set (and allowed to be used / local auth enabled). Recovery: Would be possible with the new APIs: RetrieveIdentityProviderIntent provides all the infos, Check if user exists (loginname / email query on ListUsers), Use the infos to AddIDPLink on existing user.",
      "otherNotes" : "The issue is about a new user via external login being able to delete their IdP link and making their account inaccessible. The user should not be able to perform this action, and the delete button should not appear. Additionally, the dialog for this does not have proper localization.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284309
  }, {
    "issueDTO" : {
      "id" : 2368812535,
      "title" : "This button doesn't always send the \"Magic Link\" template",
      "url" : "https://github.com/supabase/supabase/issues/27475",
      "repositoryName" : "supabase/supabase",
      "description" : "### Discussed in https://github.com/orgs/supabase/discussions/27425\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **askkaz** June 20, 2024</sup>\r\nWe have walked a lot of Supabase users through setting up their auth emails and it is frequently a source of confusion that this button:\r\n<img width=\"288\" alt=\"Screenshot 2024-06-20 at 12 44 40 PM\" src=\"https://github.com/supabase/supabase/assets/7975721/3dd4608b-d299-444e-8600-2ba3b325a837\">\r\nsends the \"Confirm signup\" template if the user has not yet confirmed their email and not the \"Magic Link\" template.\r\n<img width=\"840\" alt=\"Screenshot 2024-06-20 at 12 45 08 PM\" src=\"https://github.com/supabase/supabase/assets/7975721/c7323d29-7f55-4685-99d6-92a6a70d3f2b\">\r\n\r\nI think it would help users getting started if the initial menu was context aware enough to display the correct option (\"confirm signup\").\r\n\r\nbonus nit - template names should match, see \"password recovery\" vs. \"reset password\"\r\n\r\ndouble bonus nit - email template tab names should all match casing (\"Confirm signup\" vs \"Magic Link\")</div>",
      "updatedAt" : 1752229155.000000000,
      "user" : "saltcod",
      "userHtmlUrl" : "https://github.com/saltcod",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/105593?v=4",
      "labels" : [ "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hello, I am interested in Supabase project and would like to make contributions. I think I can start with this. I already cloned the repo. Can I work on it ? Thank. ", "Hi @Unique-Usman - Absolutely! feel free to open a pull request \uD83D\uDC4D", "Hello @Hallidayo, thanks for the reply. I have been able to build and setup the project. While the issue is good first issue, I will be glad if some of my doubt can be answered. Thank you. \r\n\r\n1. I was able to figure out that, this component is the one rendering the button  \"???\" https://github.com/supabase/supabase/blob/master/apps/studio/components/interfaces/Auth/Users/UserDropdown.tsx\r\n\r\n2. While doing going through the code base, I was able to detect the code that is rendering the UserDropdown.tsx \r\nhttps://github.com/supabase/supabase/blob/master/apps/studio/components/interfaces/Auth/Users/UsersListItem.tsx \r\n\r\nI noticed it is possible to check if the user is already confirmed from this line \r\nhttps://github.com/supabase/supabase/blob/master/apps/studio/components/interfaces/Auth/Users/UsersListItem.tsx#L29\r\n\r\nI think I can either passed the isUserConfirmed to the UserDropdown.tsx component or create another derive state  inside the UserDropdown.tsx as it is derived from UsersListItem.tsx and then render the text inside https://github.com/supabase/supabase/blob/master/apps/studio/components/interfaces/Auth/Users/UserDropdown.tsx#L160 using the state. \r\n\r\n3. For the two bonuses. I think, I was able to locate the part that renders them\r\nhttps://github.com/supabase/supabase/blob/master/apps/studio/components/interfaces/Auth/AuthTemplatesValidation.tsx \r\n\r\nIf I get the first bonus part, this line https://github.com/supabase/supabase/blob/master/apps/studio/components/interfaces/Auth/AuthTemplatesValidation.tsx#L151 should be  *Password Recovery*\r\n\r\nFor the second bonus, I think using the \"Magic Link\" format is okay. \r\n\r\nThough, I was able to build the project on my local system. I need a little guidance on recognising on how I can get to this pages.\r\n\r\nThank you.\r\n", "Hi @Hallidayo, I am looking for my open source contribution.\r\nCan I pick this issue? ", "@hkrhemendra, I think you did not read the previous conversation, I am already working on this issue, I think there are couples of other good first issues on the issue tracker list. ", "Hi @Unique-Usman - Thank you for taking a look into this one.\r\n\r\nYep thats the correct component to use. I think its good to just have the one item displayed so if the user is awaiting an invite the button should be:\r\n\r\n`Send Invite Link`\r\n\r\nIf the user is confirmed then the default button should be displayed:\r\n\r\n`Send Magic Link`\r\n\r\nFor the headings in the Email Templates that is the correct file. Its the `title` key in each object that needs to be checked. Its probably best to uppercase the start of each word so `Invite user` to `Invite User`.\r\n\r\nAre you able to view the Email Templates locally? ", "@Hallidayo, thanks for your reply. I was unable to view the Email Template Locally, I could not figure out the link. \r\n\r\nIs it *Send Invite Link* or *Confirm SignUp Link*. \r\nAlso the user can be checked if already confirmed through  `const isUserConfirmed = user.email_confirmed_at || user.phone_confirmed_at`, in this scenerio, we just havae to check for the `user.email_confirmed_at` ?\r\n", "@Unique-Usman - If you go to http://localhost:8082/project/default/auth/templates you should then get the templates showing for you locally.\r\n\r\nSorry yes it should be Confirm Sign Up Link.\r\n\r\nYeah you should be able to use the `isUserConfirmed` constant to switch between the two items.\r\n\r\nFeel free to reach out if you need anything!", "@Hallidayo, I have a first PR for the resolvement of the issues https://github.com/supabase/supabase/pull/27759, kindly check thank you. ", "Hi , Is this open , Can i work on this", "Hi, is the issue currently open, i can work on this\r\n", "Hi there, I'm interested in working on this issue.\n", "/assign\n", "Hello there is this issue is open ? I want to work on it", "can i work on this?\n", "hey, can i contribute to this project?\n", "Can i contribute to this project?", "Hi folks, is this issue still open? I'm willing to contribute on this", "@Hallidayo Can this issue be addressed properly? It seems someone started working on this last year.", "hey\ni m testing..", "Hi, I noticed PR #34795 attempted to fix this but wasn???t merged. Is this issue still open for contribution?\n", "Hi! I noticed this issue is assigned ??? is anyone actively working on it?\nIf it's still available, I'd love to contribute. Let me know, thanks!\n", "Hi @saltcod  @Hallidayo Is this issue resolved? I want to contribute in resolving this issue. ", "Hi all, this issue seems open still so open to prs \uD83D\uDC4D", "can i work on it\n", "  @Hallidayo  Can you please verify this PR and merge https://github.com/supabase/supabase/pull/36870" ],
      "repository" : {
        "description" : "The Postgres development platform. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.",
        "homepage" : "https://supabase.com",
        "name" : "supabase",
        "fullName" : "supabase/supabase",
        "htmlUrl" : "https://github.com/supabase/supabase",
        "gitUrl" : "git://github.com/supabase/supabase.git",
        "sshUrl" : "git@github.com:supabase/supabase.git",
        "cloneUrl" : "https://github.com/supabase/supabase.git",
        "owner" : {
          "login" : "supabase",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 9182,
        "stargazersCount" : 85584,
        "watchersCount" : 85584,
        "size" : 1725611,
        "openIssuesCount" : 719,
        "subscribersCount" : 584,
        "pushedAt" : "2025-07-11T22:42:04Z",
        "languages" : {
          "TypeScript" : 16663992,
          "MDX" : 8036301,
          "Dockerfile" : 4746,
          "CSS" : 140987,
          "Shell" : 5865,
          "SCSS" : 111351,
          "PLpgSQL" : 42928,
          "Makefile" : 8316,
          "JavaScript" : 962557,
          "HTML" : 453,
          "Mermaid" : 1129,
          "Elixir" : 1068
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to fix the button so that it always sends the correct 'Magic Link' template when the user has not confirmed their email.",
      "validationOrRequirement" : "The button should send the 'Magic Link' template if the user has not confirmed their email, and the template names should match (e.g. 'Confirm signup' vs 'Magic Link').",
      "attemptedFixes" : "The contributor has identified the components rendering the button and email templates, and has suggested passing the `isUserConfirmed` state to the `UserDropdown.tsx` component or creating a derived state inside it. They have also located the parts rendering the bonus nit issues.",
      "otherNotes" : "The issue is about the button not sending the correct template, specifically the 'Magic Link' template, when the user has not confirmed their email. The contributor has made progress and opened a pull request.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284315
  }, {
    "issueDTO" : {
      "id" : 3220539322,
      "title" : "DOC: Add backend DB diagram on the docs page",
      "url" : "https://github.com/AOSSIE-Org/PictoPy/issues/458",
      "repositoryName" : "AOSSIE-Org/PictoPy",
      "description" : "### What's wrong with the existing documentation\n\nWe have a newly designed SQLite schema for our app. We need to embed it on our docs page: https://aossie-org.github.io/PictoPy/\n\nInside the backend section, make a section for DB Schema and that page should have an iframe: \n<iframe width=\"560\" height=\"315\" src='https://dbdiagram.io/e/685704c4f039ec6d364647e1/68701a53f413ba350850acf9'> \n</iframe>\n\nThis iframe embeds our database design: https://dbdiagram.io/d/PictoPy-685704c4f039ec6d364647e1\n\n### Add ScreenShots\n\n_No response_\n\n### Record\n\n- [x] I agree to follow this project's Code of Conduct\n- [ ] I want to work on this issue",
      "updatedAt" : 1752229118.000000000,
      "user" : "rahulharpal1603",
      "userHtmlUrl" : "https://github.com/rahulharpal1603",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/51887323?v=4",
      "labels" : [ "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@rahulharpal1603 Can you please assign this issue to me?\n", "Hi! I came across this issue and I???d love to help out too if possible.\n@ssz2605 if you need any kind of assist with reviewing the changes, DB schema diagram, or help with the docs structure, feel free to reach out :)", "We go by FCFS, so @ssz2605 I am assigning.", "@rahulharpal1603 thanks\n@rohan-pandeyy sure, thanks" ],
      "repository" : {
        "description" : "An Image sorter that sorts photos based on face encodings in it.",
        "homepage" : "https://aossie-org.github.io/PictoPy/",
        "name" : "PictoPy",
        "fullName" : "AOSSIE-Org/PictoPy",
        "htmlUrl" : "https://github.com/AOSSIE-Org/PictoPy",
        "gitUrl" : "git://github.com/AOSSIE-Org/PictoPy.git",
        "sshUrl" : "git@github.com:AOSSIE-Org/PictoPy.git",
        "cloneUrl" : "https://github.com/AOSSIE-Org/PictoPy.git",
        "owner" : {
          "login" : "AOSSIE-Org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 172,
        "stargazersCount" : 75,
        "watchersCount" : 75,
        "size" : 220792,
        "openIssuesCount" : 66,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-11T14:01:16Z",
        "languages" : {
          "TypeScript" : 281923,
          "PowerShell" : 12482,
          "Dockerfile" : 2307,
          "Shell" : 10313,
          "CSS" : 7541,
          "Rust" : 48311,
          "Batchfile" : 565,
          "JavaScript" : 1314,
          "HTML" : 376,
          "Python" : 131042
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a backend DB diagram on the docs page to provide a better understanding of the app's database structure.",
      "validationOrRequirement" : "The requirement is to add a backend DB diagram on the docs page, with a specific design and iframe embedding.",
      "attemptedFixes" : "No fixes or blockers mentioned in the issue description or comments.",
      "otherNotes" : "The existing documentation lacks a backend DB diagram, and a newly designed SQLite schema needs to be embedded on the docs page. The diagram should be added inside the backend section, with an iframe that links to the database design.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284320
  }, {
    "issueDTO" : {
      "id" : 3201749263,
      "title" : "Standardize Workflow ID Type Across Runtimes",
      "url" : "https://github.com/business4s/workflows4s/issues/123",
      "repositoryName" : "business4s/workflows4s",
      "description" : "#### Problem  \nCurrently, each runtime defines its own workflow ID type:\n- **Pekko** uses `String`\n- **Postgres** uses `Long` (primarily due to advisory locking requirements)\n\nThis inconsistency introduces unnecessary complexity across the codebase, especially when working with abstractions that need to handle multiple runtimes. It also makes it harder to switch runtimes\n\n#### Proposal  \nWe should standardize the workflow ID type to `String` across all runtimes. This would:\n- Simplify shared logic in the core of the library\n- Make it easier to reason about workflows across runtime boundaries\n- Reduce boilerplate and the need for conversions\n\n#### Runtime-Specific Constraints  \nIf a runtime (e.g., Postgres) has additional requirements (like needing a `Long` for advisory locks), those constraints should be enforced locally???e.g., by validating or coercing the `String` into a numeric format where needed.",
      "updatedAt" : 1752229006.000000000,
      "user" : "Krever",
      "userHtmlUrl" : "https://github.com/Krever",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2219224?v=4",
      "labels" : [ "rough edge", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Simple, Composable, Business-oriented Workflows for Scala",
        "homepage" : "https://business4s.org/workflows4s/",
        "name" : "workflows4s",
        "fullName" : "business4s/workflows4s",
        "htmlUrl" : "https://github.com/business4s/workflows4s",
        "gitUrl" : "git://github.com/business4s/workflows4s.git",
        "sshUrl" : "git@github.com:business4s/workflows4s.git",
        "cloneUrl" : "https://github.com/business4s/workflows4s.git",
        "owner" : {
          "login" : "business4s",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28,
        "stargazersCount" : 95,
        "watchersCount" : 95,
        "size" : 2512,
        "openIssuesCount" : 16,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T21:31:09Z",
        "languages" : {
          "MDX" : 32359,
          "TypeScript" : 10800,
          "CSS" : 2543,
          "Scala" : 448000,
          "JavaScript" : 2652,
          "Mermaid" : 22396
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Standardize the workflow ID type to String across all runtimes to simplify shared logic, make it easier to reason about workflows, and reduce boilerplate and conversions.",
      "validationOrRequirement" : "Runtime-specific constraints should be enforced locally, e.g., by validating or coercing the String into a numeric format where needed.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about standardizing the workflow ID type across all runtimes, with the proposal being to use String type. Runtime-specific constraints should be enforced locally.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284323
  }, {
    "issueDTO" : {
      "id" : 1155576797,
      "title" : "Helm chart extAuth label name is different between deployment and pdb templates",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/5994",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "### Gloo Edge Version\n\n1.9.x\n\n### Kubernetes Version\n\n_No response_\n\n### Describe the bug\n\nWhile updating to gloo enterprise edge helm chart version 1.9.11 (also appears to be in 1.10.8). \r\nSetting the pdb value `global.extensions.extAuth.deployment.podDisruptionBudget.minAvailable` (also setting enabled: true)\r\nIt was observed the pdb uses a hardcoded `matchLabels` of `gloo: ext-auth` but the deployment has a configurable label that defaults to `extauth`.\r\nTemplate files: `21-extauth-pod-disruption-budget.yaml` and  `21-extauth-deployment.yaml`\r\nThe name is also hard coded in the rate-limit-pdb (but matches the default).\r\n\r\nNice to have, would be configurable names of the PDBs.\r\nAlso ext-auth is more generally referenced as extauth or extAuth throughout the rest of the helm chart (but if configurable shouldn't matter).\n\n### Steps to reproduce the bug\n\n1. Using gloo edge enterprise helm chart 1.9.11 (or 1.10.8).  Enable extauth and set a pdb value\r\n2. matchLabels in pdb should align with label in extauth deployment\n\n### Expected Behavior\n\nLabels between deployment and pdb should match (and be configurable).\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752228438.000000000,
      "user" : "pippitt",
      "userHtmlUrl" : "https://github.com/pippitt",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5528902?v=4",
      "labels" : [ "Good First Issue", "Type: Bug", "stale" ],
      "state" : "OPEN",
      "comments" : [ "Related to https://github.com/solo-io/gloo/issues/5648", "This issue has been marked as stale because of no activity in the last 180 days. It will be closed in the next 180 days unless it is tagged \"no stalebot\" or other activity occurs.", "Still an issue in 1.17.19\n\nI worked around with an override. \n```\n  extAuth:\n      deployment:\n          kubeResourceOverride:\n                metadata:\n                  labels:\n                    app: gloo\n                    gloo: ext-auth\n                spec:\n                  selector:\n                    matchLabels:\n                      gloo: ext-auth\n                  template:\n                    metadata:\n                      labels:\n                         gloo: ext-auth\n```", "This issue has been marked as stale because of no activity in the last 180 days. It will be closed in the next 180 days unless it is tagged \"no stalebot\" or other activity occurs." ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 537,
        "stargazersCount" : 4626,
        "watchersCount" : 4626,
        "size" : 210688,
        "openIssuesCount" : 577,
        "subscribersCount" : 102,
        "pushedAt" : "2025-07-11T22:49:24Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16652,
          "Rust" : 20712,
          "Makefile" : 30384,
          "JavaScript" : 435,
          "Go" : 4010698,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Helm chart extAuth label name is different between deployment and pdb templates, causing issues when updating to gloo enterprise edge helm chart version 1.9.11 (also appears to be in 1.10.8).",
      "validationOrRequirement" : "Labels between deployment and pdb should match (and be configurable).",
      "attemptedFixes" : "A workaround was implemented by adding an override in the extAuth deployment.",
      "otherNotes" : "This issue has been marked as stale because of no activity in the last 180 days. It will be closed in the next 180 days unless it is tagged 'no stalebot' or other activity occurs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284328
  }, {
    "issueDTO" : {
      "id" : 2816464003,
      "title" : "Improve Structured Outputs Support: Add refusal field to Chat Completion Object",
      "url" : "https://github.com/MacPaw/OpenAI/issues/249",
      "repositoryName" : "MacPaw/OpenAI",
      "description" : "**Is your feature request related to a problem? Please describe.**\nStructured Outputs have been implemented thanks to @andgordio. With Structured Outputs they've added additional field for when model is unable to generate response in a specified format: `refusal`, see [Refusals in Structured Outputs Guide](https://platform.openai.com/docs/guides/structured-outputs/refusals#refusals). For more info.\n\nThe field appears in both streamable and regular chat completion objects:\n1. Chat Completion Object - choices.message.refusal [API reference](https://platform.openai.com/docs/api-reference/chat/object#chat/object-choices)\n2. Chat Completion Chunk Object - choices.delta.refusal [API Reference](https://platform.openai.com/docs/api-reference/chat/streaming#chat/streaming-choices)\n\n**Describe the solution you'd like**\nSimply add the field to our structures that represent `choices.message` and `choices.delta`. It might require refactoring though. Currently we use `ChatCompletionMessageParam` to both create chat completion and parse Chat Completion Object in a response. But looking at the API reference, it seems that request body and response format are different and so different Swift structured may be used for clearer distinction. Also, the separation into different types makes sense for a request, but not so much for response: API Reference does not specify such distinction, and I don't think we should either.\n\n**Describe alternatives you've considered**\nAn alternative would be to continue using `ChatCompletionMessageParam` to decode Chat Completion Object, it may be faster to implement this way.\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n",
      "updatedAt" : 1752228313.000000000,
      "user" : "nezhyborets",
      "userHtmlUrl" : "https://github.com/nezhyborets",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2803931?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Looks like `refusal` has been added to `ChatResult.Choice.Message`. Still need to add to `ChatStreamResult.Choice.ChoiceDelta`" ],
      "repository" : {
        "description" : "Swift community driven package for OpenAI public API",
        "homepage" : "",
        "name" : "OpenAI",
        "fullName" : "MacPaw/OpenAI",
        "htmlUrl" : "https://github.com/MacPaw/OpenAI",
        "gitUrl" : "git://github.com/MacPaw/OpenAI.git",
        "sshUrl" : "git@github.com:MacPaw/OpenAI.git",
        "cloneUrl" : "https://github.com/MacPaw/OpenAI.git",
        "owner" : {
          "login" : "MacPaw",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 470,
        "stargazersCount" : 2594,
        "watchersCount" : 2594,
        "size" : 1543,
        "openIssuesCount" : 23,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-11T10:08:40Z",
        "languages" : {
          "Swift" : 1249895
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve Structured Outputs Support by adding refusal field to Chat Completion Object",
      "validationOrRequirement" : "Add refusal field to Chat Completion Object, possibly requiring refactoring.",
      "attemptedFixes" : "An alternative would be to continue using ChatCompletionMessageParam to decode Chat Completion Object, it may be faster to implement this way.",
      "otherNotes" : "The refusal field has been added to ChatResult.Choice.Message, but still needs to be added to ChatStreamResult.Choice.ChoiceDelta.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284331
  }, {
    "issueDTO" : {
      "id" : 3218594695,
      "title" : "add \"dev mode\" for logging",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11635",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "### kgateway version\n\nv2.0.1\n\n### Is your feature request related to a problem? Please describe.\n\nAdd a dev mode for logging. When enabled, the output should be text (not JSON) for better readability. Additionally, the log level should be set to trace.\n\n### Describe the solution you'd like\n\n_No response_\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1752228254.000000000,
      "user" : "puertomontt",
      "userHtmlUrl" : "https://github.com/puertomontt",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/58956785?v=4",
      "labels" : [ "Good First Issue", "Area: Dev Efficiency" ],
      "state" : "OPEN",
      "comments" : [ "Can this issue be assigned to me please @puertomontt ", "Thanks @puertomontt I'd raise a PR soon." ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 537,
        "stargazersCount" : 4626,
        "watchersCount" : 4626,
        "size" : 210688,
        "openIssuesCount" : 577,
        "subscribersCount" : 102,
        "pushedAt" : "2025-07-11T22:49:24Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16652,
          "Rust" : 20712,
          "Makefile" : 30384,
          "JavaScript" : 435,
          "Go" : 4010698,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a dev mode for logging with text output for better readability and log level set to trace",
      "validationOrRequirement" : "Add a dev mode for logging with text output for better readability and log level set to trace",
      "attemptedFixes" : "No attempts or blockers mentioned",
      "otherNotes" : "Issue is related to kgateway version v2.0.1",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284334
  }, {
    "issueDTO" : {
      "id" : 3222332764,
      "title" : "ansible mods",
      "url" : "https://github.com/alphaonelabs/alphaonelabs-education-website/issues/655",
      "repositoryName" : "alphaonelabs/alphaonelabs-education-website",
      "description" : null,
      "updatedAt" : 1752228219.000000000,
      "user" : "ishaan-arora-1",
      "userHtmlUrl" : "https://github.com/ishaan-arora-1",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/178517080?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Alpha One Labs Educational Website",
        "homepage" : "https://alphaonelabs.com",
        "name" : "alphaonelabs-education-website",
        "fullName" : "alphaonelabs/alphaonelabs-education-website",
        "htmlUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website",
        "gitUrl" : "git://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "sshUrl" : "git@github.com:alphaonelabs/alphaonelabs-education-website.git",
        "cloneUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "owner" : {
          "login" : "alphaonelabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 80,
        "stargazersCount" : 23,
        "watchersCount" : 23,
        "size" : 32019,
        "openIssuesCount" : 119,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-11T07:05:39Z",
        "languages" : {
          "Dockerfile" : 1189,
          "Shell" : 49732,
          "Jinja" : 7703,
          "CSS" : 2056,
          "JavaScript" : 105473,
          "HTML" : 1763491,
          "Python" : 1207774
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create ansible mods",
      "validationOrRequirement" : "No specific requirements mentioned",
      "attemptedFixes" : "No attempts or blockers mentioned",
      "otherNotes" : "No description provided, but labeled as good first issue",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284336
  }, {
    "issueDTO" : {
      "id" : 2010775009,
      "title" : "Use indicatif or prodash crates for CLI status reporting",
      "url" : "https://github.com/maplibre/martin/issues/1024",
      "repositoryName" : "maplibre/martin",
      "description" : "I think we should switch our output formatting to either [indicatif crate](https://docs.rs/indicatif/latest/indicatif/) or [prodash](https://github.com/Byron/prodash#readme).   `indicatif` supports progress bars and number formatting, so we could probably remove the `size_format` dependency. `prodash` seem to support logging better?\r\n\r\nWe will probably need a single status bar, as we don't have well defined parallelization.\r\n\r\n  - [ ] `martin-cp` while generating tiles - this is the most important target\r\n  - [ ] `mbtiles copy` - not certain if this is possible to track the progress of a single SQLite `INSERT INTO ...` sql statement.\r\n\r\n### Indicatif Demo\r\n![demo](https://raw.githubusercontent.com/console-rs/indicatif/main/screenshots/yarn.gif)\r\n\r\n### Prodash Demo\r\n[![asciicast](https://asciinema.org/a/315956.svg)](https://asciinema.org/a/315956)\r\n",
      "updatedAt" : 1752228211.000000000,
      "user" : "nyurik",
      "userHtmlUrl" : "https://github.com/nyurik",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1641515?v=4",
      "labels" : [ "cli", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "using `indicativ` is much simpler if we migrate to tracing first.\nThe architecture of `log` is not ideal for  plugins like [`indicatif_log_bridge`](https://docs.rs/indicatif-log-bridge/latest/indicatif_log_bridge/)" ],
      "repository" : {
        "description" : "Blazing fast and lightweight PostGIS, MBtiles and PMtiles tile server, tile generation, and mbtiles tooling.",
        "homepage" : "https://martin.maplibre.org",
        "name" : "martin",
        "fullName" : "maplibre/martin",
        "htmlUrl" : "https://github.com/maplibre/martin",
        "gitUrl" : "git://github.com/maplibre/martin.git",
        "sshUrl" : "git@github.com:maplibre/martin.git",
        "cloneUrl" : "https://github.com/maplibre/martin.git",
        "owner" : {
          "login" : "maplibre",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 266,
        "stargazersCount" : 2828,
        "watchersCount" : 2828,
        "size" : 20365,
        "openIssuesCount" : 99,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T02:52:40Z",
        "languages" : {
          "TypeScript" : 830,
          "Shell" : 29490,
          "CSS" : 198,
          "Rust" : 672567,
          "JavaScript" : 436,
          "HTML" : 18833,
          "Just" : 14278
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Switch the output formatting to either indicatif crate or prodash for CLI status reporting",
      "validationOrRequirement" : "Migrate to tracing first, consider the architecture of log and its plugins like indicatif_log_bridge",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue involves switching to either indicatif crate or prodash for CLI status reporting, with a focus on progress bars and number formatting. It also mentions the need for a single status bar and the difficulty in tracking the progress of a single SQLite INSERT INTO ... sql statement.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284340
  }, {
    "issueDTO" : {
      "id" : 3159573978,
      "title" : "[RFC]: Unit test coverage improvement",
      "url" : "https://github.com/vllm-project/vllm-ascend/issues/1298",
      "repositoryName" : "vllm-project/vllm-ascend",
      "description" : "Note: Setup test environment: https://vllm-ascend.readthedocs.io/en/latest/developer_guide/contribution/testing.html\n\n### Motivation\n\nThis issue attempt to reduce the gap of unit tests to cover the code. There is a brief architecture of ut in `tests/ut/` already. We need to add more to cover all the code in vllm-ascend, and there are several principles to follow:\n\n1. The overall file tree should be consistent with `vllm_ascend`\n2. The file name should be the original file name with a prefix `test_`\n3. Use `unittest` framework, make good use of mock\n4. The UTs are all running on cpu node, mock the function related to device to host\n\nPlease refer to the official doc on [contributing](https://vllm-ascend.readthedocs.io/en/latest/developer_guide/contribution/index.html) and [testing](https://vllm-ascend.readthedocs.io/en/latest/developer_guide/contribution/testing.html) to develop, thanks!\n### Unit tests need to add\n\n- [x] |-- test__version.py\n- [x] |-- test_ascend_config.py\n- [ ] |-- test_attention\n- [ ] |   |-- ~~test_attention.py~~ will drop later\n- [x] |   |-- test_attention_v1.py https://github.com/vllm-project/vllm-ascend/pull/1529\n- [ ] |   `-- test_mla_v1.py @SunnyLee151064\n- [ ] |-- compilation\n- [ ] |   `-- test_piecewise_backend.py\n- [ ] |-- core\n- [ ] |   |-- test_schedule_config.py @nuclearwu\n- [ ] |   `-- test_scheduler.py\n- [ ] |-- device_allocator\n- [ ] |   `-- test_camem.py @1024daniel\n- [ ] |-- distributed\n- [ ] |   |-- test_communicator.py @FieeFlip\n- [ ] |   |-- test_device_communicators @Agonixiaoxiao #1601\n- [ ] |   |   |-- test_pyhccl.py\n- [ ] |   |   `-- test_pyhccl_wrapper.py\n- [x] |   |-- kv_transfer @Agonixiaoxiao \n- [x] |   |   |-- test_simple_buffer.py https://github.com/vllm-project/vllm-ascend/pull/1531\n- [x] |   |   |-- test_simple_connector.py https://github.com/vllm-project/vllm-ascend/pull/1531\n- [x] |   |   |-- test_simple_pipe.py https://github.com/vllm-project/vllm-ascend/pull/1531\n- [ ] |   |   `-- test_utils.py\n- [ ] |   |-- test_llmdatadist_connector.py\n- [x] |   `-- test_parallel_state.py   @wangyanhui-cmss https://github.com/vllm-project/vllm-ascend/pull/1460\n- [ ] |-- test_envs.py @YuanCheng-coder\n- [ ] |-- lora\n- [ ] |   `-- punica_wrapper @hongfugui\n- [ ] |       `-- test_punica_npu.py @hongfugui\n- [ ] |-- models\n- [ ] |   |-- test_deepseek_dbo.py\n- [ ] |   |-- test_deepseek_mtp.py\n- [ ] |   |-- test_deepseek_v2.py\n- [ ] |   |-- test_qwen2_5_vl.py @Ronald1995\n- [ ] |   |-- test_qwen2_5_vl_without_padding.py @Ronald1995\n- [ ] |   |-- test_qwen2_vl.py @Ronald1995\n- [ ] |   `-- test_qwen3_moe.py\n- [ ] |-- multistream\n- [ ] |   |-- test_base.py @SunnyLee151064\n- [ ] |   |-- test_context.py @xingLong-xl\n- [ ] |   |-- test_decorator.py\n- [ ] |   |-- test_layers.py @1024daniel\n- [ ] |   |-- test_metadata.py @SunnyLee151064\n- [ ] |   `-- test_ms_split.py @SunnyLee151064\n- [ ] |-- ops\n- [ ] |   |-- test_activation.py @MengqingCao \n- [ ] |   |-- test_attention.py @SunnyLee151064\n- [ ] |   |-- test_cache.py @SunnyLee151064\n- [ ] |   |-- test_common_fused_moe.py @MengqingCao \n- [x] |   |-- test_expert_load_balancer.py\n- [ ] |   |-- test_fused_moe.py\n- [ ] |   |-- test_layernorm.py @MengqingCao \n- [ ] |   |-- test_rotary_embedding.py @MengqingCao \n- [ ] |   `-- test_vocab_parallel_embedding.py @YuanCheng-coder\n- [ ] |-- patch\n- [ ] |   |-- platform\n- [ ] |   |   |-- patch_0_9_2\n- [ ] |   |   |-- patch_common\n- [ ] |   |   |   `-- test_test_patch_distributed.py\n- [ ] |   |   `-- patch_main\n- [ ] |   `-- worker\n- [ ] |       |-- patch_0_9_2\n- [ ] |       |-- patch_common\n- [ ] |       |   |-- test_patch_distributed.py @Pr0Wh1teGivee\n- [ ] |       |   |-- test_patch_eagle.py @Pr0Wh1teGivee\n- [ ] |       |   |-- test_patch_minicpm.py @Pr0Wh1teGivee\n- [ ] |       |   |-- test_patch_multi_step_worker.py @Pr0Wh1teGivee\n- [x] |       |   |-- test_patch_sampler.py \n- [ ] |       |   |-- test_patch_spec_decode_worker.py @Pr0Wh1teGivee\n- [ ] |       |   `-- test_patch_utils.py @Pr0Wh1teGivee\n- [ ] |       `-- patch_main\n- [x] |-- test_platform.py @zhanghw0354 https://github.com/vllm-project/vllm-ascend/pull/1476\n- [ ] |-- quantization\n- [ ] |   |-- test_func_wrapper.py\n- [x] |   |-- test_quant_config.py @nuclearwu https://github.com/vllm-project/vllm-ascend/pull/1529\n- [x] |   |-- test_quantizer.py https://github.com/vllm-project/vllm-ascend/pull/1529\n- [x] |   |-- test_w8a8.py https://github.com/vllm-project/vllm-ascend/pull/1529\n- [ ] |   `-- test_w8a8_dynamic.py\n- [ ] |-- sample\n- [ ] |   |-- ops\n- [ ] |   `-- test_rejection_sampler.py\n- [x] |-- test_utils.py\n- [ ] `-- worker \n- [ ] |-- test_cache_engine.py @machenglong2025\n- [ ] |-- test_draft_model_runner.py\n- [ ] |-- ~~test_model_runner.py~~ will drop later\n- [ ] |-- test_model_runner_v1.py\n- [ ]  |-- test_mtp_proposer_v1.py @machenglong2025\n- [ ] |-- ~~test_multi_step_runner.py~~ will drop later\n- [ ] |-- ~~test_multi_step_worker.py~~ will drop later\n- [x] |-- test_pooling_model_runner.py @wangyanhui-cmss https://github.com/vllm-project/vllm-ascend/pull/1640\n- [ ] |-- ~~test_worker.py~~ @zhanghw0354 will drop later\n- [ ] `-- test_worker_v1.py @zhanghw0354\n",
      "updatedAt" : 1752228159.000000000,
      "user" : "MengqingCao",
      "userHtmlUrl" : "https://github.com/MengqingCao",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/52243582?v=4",
      "labels" : [ "help wanted", "feature request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I want to test the UT for the following code:\n1. worker.cache_engine.py \n2. mtp_proposer_v1.py", "I enable codecov on https://github.com/vllm-project/vllm-ascend/pull/1164, you can take a look on https://app.codecov.io/gh/vllm-project/vllm-ascend to see coverage report.", "I want to test the UT for the following code:\nkv_transfer", "@Agonixiaoxiao Thanks! Feel free to open PR ", "I want to add the UT tests code in, Thanks:\ntest_platform.py\ntest_worker.py\ntest_worker_v1.py", "@zhanghw0354 Assigned! Thanks, consider V0 woker will deprecated, so it will has lower priorities.", "I want to add the UT tests code in, Thanks:\ntest_parallel_state.py", "I want to add the UT tests code in, Thanks:\ntest_pooling_model_runner.py", "I want to test the UT for the following code:\n-- lora\n-- 1???punica_wrapper\n-- 2???test_punica_npu.py", "I want to test the UT for the following code:\n1???-- test_schedule_config.py\n2???-- test_quant_config.py\n", "I want to test the UT for the following code:\n-- distributed\n1???-- test_communicator.py", "I want to test the UT for the following code:\ntest_device_communicators\nhttps://github.com/vllm-project/vllm-ascend/pull/1601", "Can I develop without ascend equipment?", "> Can I develop without ascend equipment?\n\nYep, our principle is: `The UTs are all running on cpu node, mock the function related to device to host`", "I want to add the UT tests code in, Thanks:\ntest_metadata.py\ntest_ms_split.py", "all tests under patch_common, cheers.", "Just FYI: https://vllm-ascend.readthedocs.io/en/latest/developer_guide/contribution/testing.html\n\nHere is a simple guide help you setup ut dev env in your local desktop (CPU) or ascend env.", "I want to add ut for `test_qwen2_5_vl.py`, ` test_qwen2_5_vl_without_padding.py`, `test_qwen2_vl.py`. Thanks", "I want to add ut for ops/test_activation.py,  ops/test_attention.py, ops/test_rotary_embedding.py. Thanks", "I want to add ut for ops/test_vocab_parallel_embedding.py and  test_envs.py . Thanks", "I want to add ut for multistream/test_context.py. Thanks", "I want to add ut for device_allocator/test_camem.py and multistream/test_layers.py. Thanks", "I want to add ut for ops/test_cache.py multistream/test_base.py. Thanks", "I want to add ut for attention/test_mla_v1.py thanks\n", "@nuclearwu `test_quant_config.py` is done in https://github.com/vllm-project/vllm-ascend/pull/1529. Sorry for the delay of this info", "I want to add ut for test_test_patch_distributed.py???thanks\n\n\n|-- patch\n\n| |-- platform\n\n| | |-- patch_0_9_2\n\n| | |-- patch_common\n\n| | | `-- test_test_patch_distributed.py", "I want to add the UT tests code in, Thanks:\ndraft_model_runner.py" ],
      "repository" : {
        "description" : "Community maintained hardware plugin for vLLM on Ascend",
        "homepage" : "https://vllm-ascend.readthedocs.io",
        "name" : "vllm-ascend",
        "fullName" : "vllm-project/vllm-ascend",
        "htmlUrl" : "https://github.com/vllm-project/vllm-ascend",
        "gitUrl" : "git://github.com/vllm-project/vllm-ascend.git",
        "sshUrl" : "git@github.com:vllm-project/vllm-ascend.git",
        "cloneUrl" : "https://github.com/vllm-project/vllm-ascend.git",
        "owner" : {
          "login" : "vllm-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 249,
        "stargazersCount" : 865,
        "watchersCount" : 865,
        "size" : 3150,
        "openIssuesCount" : 349,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-11T13:42:59Z",
        "languages" : {
          "Dockerfile" : 2442,
          "C++" : 79160,
          "Shell" : 31374,
          "CMake" : 7984,
          "Python" : 1657414
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Reduce the gap of unit tests to cover the code, add more unit tests to cover all the code in vllm-ascend",
      "validationOrRequirement" : "The overall file tree should be consistent with `vllm_ascend`, The file name should be the original file name with a prefix `test_`, Use `unittest` framework, make good use of mock, The UTs are all running on cpu node, mock the function related to device to host",
      "attemptedFixes" : "test_platform.py, test_worker.py, test_worker_v1.py, test_parallel_state.py, test_pooling_model_runner.py, test_schedule_config.py, test_quant_config.py, test_communicator.py, test_device_communicators, test_metadata.py, test_ms_split.py, all tests under patch_common, test_qwen2_5_vl.py, test_qwen2_5_vl_without_padding.py, test_qwen2_vl.py, ops/test_activation.py, ops/test_attention.py, ops/test_rotary_embedding.py, ops/test_vocab_parallel_embedding.py, test_envs.py, multistream/test_context.py, device_allocator/test_camem.py, multistream/test_layers.py, ops/test_cache.py, multistream/test_base.py, attention/test_mla_v1.py, test_test_patch_distributed.py",
      "otherNotes" : "Note: Setup test environment: https://vllm-ascend.readthedocs.io/en/latest/developer_guide/contribution/testing.html",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284350
  }, {
    "issueDTO" : {
      "id" : 3217309033,
      "title" : "[CI/CD] Add retry logic to the update-otel github actions job",
      "url" : "https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/41220",
      "repositoryName" : "open-telemetry/opentelemetry-collector-contrib",
      "description" : "We should make the \"Update contrib to the latest core source\" job resilient to temporary errors like https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/runs/16148576522/job/45573795931\n",
      "updatedAt" : 1752227968.000000000,
      "user" : "dmitryax",
      "userHtmlUrl" : "https://github.com/dmitryax",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6628631?v=4",
      "labels" : [ "github_actions", "help wanted", "enhancement", "ci-cd", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hi!, please correct me if I am wrong, but it would be to add retry logic to:\n```yml\n      - name: File an issue if the workflow failed\n        if: failure()\n        run: |\n          template=$(cat <<'END'\n          [Link to job log](%s)\n          \n          <details>\n          <summary>Last 100 lines of log</summary>\n\n          ```\n          %s\n          ```\n          </details>\n          END\n          )\n          job_url=\"$(gh run view ${{ github.run_id }} -R ${{ github.repository }} --json jobs -q '.jobs[] | select(.name == \"update-otel\") | .url')\"\n          body=\"$(printf \"$template\" \"$job_url\" \"$(tail -n100 log.out | tail -c63K)\")\"\n          gh issue create -R ${{ github.repository }} -t 'update-otel workflow failed' -b \"$body\" -l 'ci-cd'\n```\n in `update-otel.yml` .", "No, we need to retry the failing requests to external services such as GOPROXY server, not create github issues automaticaly", "Oh okay, It seems relatively straight forward, Could I work on this?", "Sure. Thank you!", "open-telemetry/opentelemetry-go-build-tools/pull/941 should address this, we just need to release a new multimod version and update it here", "I would prefer my solution because we can retry individual requests to the Go proxy instead of retrying the whole thing", "My approach did not work (or not fully at least). I think we need to retry on 404s and the library I used does not do that" ],
      "repository" : {
        "description" : "Contrib repository for the OpenTelemetry Collector",
        "homepage" : "https://opentelemetry.io",
        "name" : "opentelemetry-collector-contrib",
        "fullName" : "open-telemetry/opentelemetry-collector-contrib",
        "htmlUrl" : "https://github.com/open-telemetry/opentelemetry-collector-contrib",
        "gitUrl" : "git://github.com/open-telemetry/opentelemetry-collector-contrib.git",
        "sshUrl" : "git@github.com:open-telemetry/opentelemetry-collector-contrib.git",
        "cloneUrl" : "https://github.com/open-telemetry/opentelemetry-collector-contrib.git",
        "owner" : {
          "login" : "open-telemetry",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2877,
        "stargazersCount" : 3695,
        "watchersCount" : 3695,
        "size" : 638105,
        "openIssuesCount" : 900,
        "subscribersCount" : 64,
        "pushedAt" : "2025-07-11T22:37:00Z",
        "languages" : {
          "Dockerfile" : 3133,
          "Shell" : 9347,
          "Makefile" : 36396,
          "Go" : 25759634,
          "HTML" : 259
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add retry logic to the 'update-otel' GitHub Actions job to make it resilient to temporary errors.",
      "validationOrRequirement" : "The retry logic should be added to the 'update-otel' GitHub Actions job, and it should retry requests to external services like the GOPROXY server.",
      "attemptedFixes" : "The initial approach did not work, and the author's suggested solution did not work fully either.",
      "otherNotes" : "The issue is related to a GitHub Actions job that fails due to temporary errors, and the goal is to add retry logic to the job. The initial approach was incorrect, and the author suggests retrying individual requests to the Go proxy instead of the whole thing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284355
  }, {
    "issueDTO" : {
      "id" : 3219850067,
      "title" : "Debug view settings on custom shaders",
      "url" : "https://github.com/TokisanGames/Terrain3D/issues/762",
      "repositoryName" : "TokisanGames/Terrain3D",
      "description" : "### Description\n\nDebug view / overlay settings like heightmap and contours put their settings in the material, which is alright, but when using a custom shader these are hidden. They work, you just have to turn off the shader override to change them. This was not caused by #761 .\n\nIt's acceptable to properly inject the settings so they appear in the material with shader override enabled.\n\nWhat is better is to make them private uniforms so they don't ever show in the material, and make their settings visible adjacent to the debug view/overlay that turns them on. Preferably invisible until enabled (likely with a conditional in _get_property_list()).\n\n\n",
      "updatedAt" : 1752227967.000000000,
      "user" : "TokisanGames",
      "userHtmlUrl" : "https://github.com/TokisanGames",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/632766?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "assign me, i'll try" ],
      "repository" : {
        "description" : "A high performance, editable terrain system for Godot 4.",
        "homepage" : "",
        "name" : "Terrain3D",
        "fullName" : "TokisanGames/Terrain3D",
        "htmlUrl" : "https://github.com/TokisanGames/Terrain3D",
        "gitUrl" : "git://github.com/TokisanGames/Terrain3D.git",
        "sshUrl" : "git@github.com:TokisanGames/Terrain3D.git",
        "cloneUrl" : "https://github.com/TokisanGames/Terrain3D.git",
        "owner" : {
          "login" : "TokisanGames",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 180,
        "stargazersCount" : 3099,
        "watchersCount" : 3099,
        "size" : 133357,
        "openIssuesCount" : 80,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T11:44:31Z",
        "languages" : {
          "PowerShell" : 2713,
          "C++" : 455920,
          "Shell" : 15381,
          "GDShader" : 39588,
          "AppleScript" : 2190,
          "GDScript" : 189694,
          "GLSL" : 52295,
          "Python" : 2851
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Debug view settings on custom shaders should be made visible and accessible even when shader override is enabled.",
      "validationOrRequirement" : "Make settings private uniforms and make their settings visible adjacent to the debug view/overlay that turns them on. Preferably invisible until enabled.",
      "attemptedFixes" : "Assignee is willing to try fixing the issue.",
      "otherNotes" : "This issue was not caused by #761. It's acceptable to properly inject settings so they appear in the material with shader override enabled. Private uniforms are preferred to make settings invisible until enabled.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284358
  }, {
    "issueDTO" : {
      "id" : 3222249396,
      "title" : "Disable settings button",
      "url" : "https://github.com/Visionatrix/Visionatrix/issues/459",
      "repositoryName" : "Visionatrix/Visionatrix",
      "description" : "Is there any way I can disable the settings button for the end user?\nOr just use a reverse proxy via nginx so that the user does not have access via the /settings link\nAnd second question, i reinstalled 3 times Visionatrix in docker, and now I have 6 workers with offline status, and can't delete they, what can I do?",
      "updatedAt" : 1752227924.000000000,
      "user" : "lsqd",
      "userHtmlUrl" : "https://github.com/lsqd",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/50231694?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello, @lsqd! Thank you for your issue. There is no possibility to restrict settings page for non-admin users, and remove dangling workers records at the moment.\nWe'll try to make improvements on that for the next release (next weekends)." ],
      "repository" : {
        "description" : "AI Media processing using ComfyUI",
        "homepage" : "https://visionatrix.github.io/VixFlowsDocs/",
        "name" : "Visionatrix",
        "fullName" : "Visionatrix/Visionatrix",
        "htmlUrl" : "https://github.com/Visionatrix/Visionatrix",
        "gitUrl" : "git://github.com/Visionatrix/Visionatrix.git",
        "sshUrl" : "git@github.com:Visionatrix/Visionatrix.git",
        "cloneUrl" : "https://github.com/Visionatrix/Visionatrix.git",
        "owner" : {
          "login" : "Visionatrix",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 145,
        "watchersCount" : 145,
        "size" : 11189,
        "openIssuesCount" : 6,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-10T00:00:33Z",
        "languages" : {
          "TypeScript" : 73194,
          "Dockerfile" : 1868,
          "Shell" : 678,
          "CSS" : 311,
          "Batchfile" : 149,
          "Makefile" : 4347,
          "Vue" : 230059,
          "JavaScript" : 1582,
          "HTML" : 15995,
          "Mako" : 621,
          "Python" : 583340
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Disable settings button for end users and resolve issue with offline workers that cannot be deleted",
      "validationOrRequirement" : "There is no possibility to restrict settings page for non-admin users, and remove dangling workers records at the moment.",
      "attemptedFixes" : "The author has tried reinstalling Visionatrix in docker 3 times, but the issue persists.",
      "otherNotes" : "The author mentions reinstalling Visionatrix in docker 3 times and having 6 workers with offline status, which cannot be deleted.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284362
  }, {
    "issueDTO" : {
      "id" : 3136165661,
      "title" : "\uD83C\uDF6D[Roadmap] ms-swift3.6-3.8",
      "url" : "https://github.com/modelscope/ms-swift/issues/4561",
      "repositoryName" : "modelscope/ms-swift",
      "description" : "## ??????\n1. ?????????????????? P0\n2. Omni pending\n    a. ????????????????????????\n    b. ??????talker?????????\n3. All-to-All?????? pending\n4. embedding: ????????????????????? P0\n5. ???reranker????????????\n6. ????????????: ?????????/??????????????????\n\n\n## Megatron-SWIFT \n1. ???????????????\n    a. ?????????: qwen2.5-VL/qwen2.5-Omni P0\n    b. ???DeepSeekV3\n2. ???fp8\n3. LoRA?????? P0\n4. ?????????????????????????????? P0\n5. RLHF?????? P0\n    a. GRPO\n    b. KTO\n    c. ???DPO\n6. bshd???????????? P1\n7. swanlab?????? P0\n8. loss_scale?????? P0\n\n\n## ??????\n1. RAY?????? P0\n2. ????????????ring attention\n3. AutoTP P0\n4. ???channel loss??????packing/padding_free\n\n\n## RL \n1. GRPO\n   a. ?????????AsyncEngine\n   b. Agent MCP\n   c. sglang\n   d. ????????????benchmark P0\n   e. ??????rollout P0\n2. ???GKD\n3. RLOO P1\n4. Reinforce++ P0\n6. ?????????PPO\n7. KTO padding_free?????? P0\n\n\n## ?????????\n### ???????????????\n1. ???sglang??????????????????\n2. GGUF??????\n\n### ??????\n1. bnb?????????????????????\n2. qlora??????merge-lora P1\n3. GGUF??????\n4. ???fp8??????\n\n\n\n\n",
      "updatedAt" : 1752227860.000000000,
      "user" : "Jintao-Huang",
      "userHtmlUrl" : "https://github.com/Jintao-Huang",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/45290347?v=4",
      "labels" : [ "discussion", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "???????????????????????????forward????????????????????????????????????????????????loss??????", "deepspeed??????megatron????????????", "?????????????????????????????????rl", "1. ?????????qwen2.5-vl??????Megatron grpo???????????????\n2.  ????????????prefixGrouper???\n3. ??????????????????????????????gpu???????????????collocate?????????rollout???????????????????????????", "1. ?????? DeepSeekV3 / R1\n2. ???????????? ?????? \n", "## ??????\nSFT with KD loss. Introduced in [Gemma3 Tech Report](https://arxiv.org/pdf/[2503.19786](https://arxiv.org/pdf/2503.19786)). Seems also used in Qwen3\n\n>  Distillation. We sample 256 logits per token, weighted by teacher probabilities. The student learns the teacher???s distribution with in the samples via cross-entropy loss. The teacher???s target distribution is set to zero probability for non-sampled logits, and renormalized.\n\n## ??????\n????????????DeepSpeed ???AutoTP?  [AutoTP](https://github.com/deepspeedai/DeepSpeed/blob/master/blogs/huggingface-tp/README.md) ????????????Megatron ????????????????????????????????????????????????\n", "DeepSpeed ???AutoTP??????????????????????????????logit???????????????", "???????????????RL???reward??????????????????????????????", "?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????", "?????????Megatron-SWIFT???????????????", "deepspeed??????megatron????????????", "??????flash attention3????????????", "> ?????????Megatron-SWIFT???????????????\n\nhttps://swift.readthedocs.io/zh-cn/latest/Instruction/Megatron-SWIFT%E8%AE%AD%E7%BB%83.html\n\n????????????", "> deepspeed??????megatron????????????\n\nI checked https://github.com/deepspeedai/Megatron-DeepSpeed, and it seems that the project is not actively maintained anymore. We probably won't support it.", "Thanks for the great contribution you have done! Hope this project could support multimodal grpo training (like qwen2.5vl) for megatron. ", "???????????????????????????swift3.4.1.post1??????????????????????????????????????????swift???swift3.6??????\nmodelscope-registry.cn-hangzhou.cr.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda12.4.0-py311-torch2.6.0-vllm0.8.5.post1-modelscope1.26.0-swift3.4.1.post1", "????????????DAPO", "> ????????????DAPO\n\n???????????????DAPO?????????????????????????????????swift????????????", "???????????????GME???embedding [MRL](https://arxiv.org/abs/2205.13147) ??????", "> ???????????????GME???embedding [MRL](https://arxiv.org/abs/2205.13147) ??????\n\n???[GME](https://www.modelscope.cn/models/iic/gme-Qwen2-VL-2B-Instruct)????????????MRL???", "> > ???????????????GME???embedding [MRL](https://arxiv.org/abs/2205.13147) ??????\n> \n> ???[GME](https://www.modelscope.cn/models/iic/gme-Qwen2-VL-2B-Instruct)????????????MRL???\n\n@tastelikefeet ???????????????????????????GME??????????????????MRL", "???????????????????????????????????????", "> ???????????????????????????????????????\n\n???????????? ??????", "????????????SmolVLM", "??????????????? swift 3.5.0 ???????????????????????????", "> > deepspeed??????megatron????????????\n> \n> I checked https://github.com/deepspeedai/Megatron-DeepSpeed, and it seems that the project is not actively maintained anymore. We probably won't support it.\n\n????????????torchtitan?????????????????????????????????????????????????????????", "@hsushuai @xuefei2025 \n?????????????????????megatron & deepspeed???????????????????????????????????????????????????????????????????????????", "> ??????????????? swift 3.5.0 ???????????????????????????\n\nhttps://github.com/modelscope/ms-swift/pull/4601", "+1???????????????????????????????????????????????????\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F???", "???????????????[Online DPO](https://github.com/huggingface/trl/blob/d9d25a71b2b2c39d11b5bde19e2a9b1fc7315b17/docs/source/online_dpo_trainer.md)", "> +1???????????????????????????????????????????????????\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F\uD83D\uDE4F???\n\ngdk???????????????", "request support for other multimodal embeddings.  Thanks.    https://github.com/modelscope/ms-swift/issues/4861", "??????reinforce++?????????????????????????????????", "?????????grpo???vllm ??? server??????????????????node?????? ?????? ???node rollout???" ],
      "repository" : {
        "description" : "Use PEFT or Full-parameter to CPT/SFT/DPO/GRPO 500+ LLMs (Qwen3, Qwen3-MoE, Llama4, InternLM3, DeepSeek-R1, ...) and 200+ MLLMs (Qwen2.5-VL, Qwen2.5-Omni, Qwen2-Audio, Ovis2, InternVL3, Llava, GLM4v, Phi4, ...) (AAAI 2025).",
        "homepage" : "https://swift.readthedocs.io/zh-cn/latest/",
        "name" : "ms-swift",
        "fullName" : "modelscope/ms-swift",
        "htmlUrl" : "https://github.com/modelscope/ms-swift",
        "gitUrl" : "git://github.com/modelscope/ms-swift.git",
        "sshUrl" : "git@github.com:modelscope/ms-swift.git",
        "cloneUrl" : "https://github.com/modelscope/ms-swift.git",
        "owner" : {
          "login" : "modelscope",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 742,
        "stargazersCount" : 8616,
        "watchersCount" : 8616,
        "size" : 66864,
        "openIssuesCount" : 766,
        "subscribersCount" : 43,
        "pushedAt" : "2025-07-11T10:22:56Z",
        "languages" : {
          "Shell" : 6171,
          "Makefile" : 359,
          "Python" : 2888562
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to support multiple models and features, including latest model interface, Omni pending, All-to-All optimization, embedding, reranker training, and sequence classification, as well as Megatron-SWIFT, new model support, fp8, LoRA, RLHF, bshd format, and swanlab.",
      "validationOrRequirement" : "The issue requires support for multiple models, including latest model interface, Omni pending, All-to-All optimization, embedding, reranker training, and sequence classification. It also requires support for Megatron-SWIFT, new model support, fp8, LoRA, RLHF, bshd format, and swanlab. Additionally, it requests support for custom model forward input and output parameter, loss function, and process reward in RL.",
      "attemptedFixes" : "The issue mentions that DeepSpeed's AutoTP is not actively maintained anymore, and it seems that the project is not supported.",
      "otherNotes" : "The issue aims to support multiple models, including latest model interface, Omni pending, All-to-All optimization, embedding, reranker training, and sequence classification. It also includes support for Megatron-SWIFT, new model support, fp8, LoRA, RLHF, bshd format, and swanlab. The issue mentions the need for a custom model forward input and output parameter, loss function, and process reward in RL. Additionally, it requests support for DeepSpeed, AutoTP, and logit knowledge distillation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284372
  }, {
    "issueDTO" : {
      "id" : 3207697268,
      "title" : "[CHORE]: GitHub Actions to build docs, with diagrams and test report, and deploy to GitHub Pages using MkDocs on every push to main",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/307",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "### \uD83D\uDD27 Chore Summary\nSet up automated documentation generation in GitHub Actions to build docs, generate architecture diagrams, and deploy to GitHub Pages using MkDocs on every push to main branch.\n\n---\n\n### \uD83E\uDDF1 Area Affected\n- [x] GitHub Actions / CI Pipelines\n- [x] Build system or `Makefile`\n- [x] Docs or spellcheck\n- [x] Containerization (Docker/Podman)\n\n---\n\n### ?????? Context / Rationale\nCurrently, documentation generation is a manual process requiring developers to:\n1. Run `make docs` locally to generate handsdown documentation\n2. Run `make images` to create architecture diagrams\n3. Manually commit and push documentation updates\n\nThis creates several problems:\n- **Documentation drift** - docs get out of sync with code changes\n- **Developer friction** - extra manual steps slow down development\n- **Inconsistency** - different environments may generate different outputs\n- **Barriers to contribution** - contributors need local tooling setup\n\nAutomating this process will:\n- Ensure docs are always up-to-date with latest code\n- Remove manual burden from developers\n- Provide consistent, reproducible documentation builds\n- Enable automatic deployment to GitHub Pages\n- Integrate with existing MkDocs configuration\n\n---\n\n### \uD83D\uDCE6 Related Make Targets\n- `make docs` - generate documentation with handsdown + images + sbom\n- `make images` - generate architecture diagrams (code2flow, snakefood, pyreverse)\n- `make sbom` - generate software bill of materials\n- `make install` - may need updates for CI dependencies (e.g.`graphviz`)\n\n---\n\n### \uD83D\uDCCB Acceptance Criteria\n- [x] Create `.github/workflows/docs.yml` workflow file\n- [x] Workflow triggers on push to `main` branch and manual dispatch\n- [x] Install all required dependencies (graphviz, code2flow, handsdown, etc.)\n- [X] Include unit test report `make test` in generated documentation\n- [x] Run existing `make docs` target to generate documentation\n- [x] Set up MkDocs integration and configuration\n- [x] Deploy generated docs to GitHub Pages\n- [x] Handle git authentication for committing back to repo\n- [x] Add appropriate caching for dependencies and build artifacts\n- [x] Workflow runs successfully without manual intervention\n- [x] Generated docs are accessible via GitHub Pages\n- [x] Include status badge in README for docs build status\n\n---\n\n### \uD83E\uDDE9 Additional Notes\n\n**Required GitHub Actions workflow structure:**\n```yaml\nname: \uD83D\uDCDA Generate Documentation\non:\n  push:\n    branches: [ main ]\n    paths: \n      - 'mcpgateway/**'\n      - 'docs/**'\n      - 'README.md'\n      - 'mkdocs.yml'\n  workflow_dispatch:\n\njobs:\n  docs:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n      pages: write\n      id-token: write\n```\n\n**Dependencies to install in CI:**\n- Python environment with project dependencies\n- `graphviz` system package for dot/SVG generation\n- `code2flow` for code flow diagrams\n- `snakefood3` for dependency graphs\n- `pylint` for pyreverse UML generation\n- `handsdown` for API documentation\n- `mkdocs` + `mkdocs-material` for site generation\n\n**Key workflow steps:**\n1. Checkout code with full history\n2. Set up Python + install dependencies\n3. Install system packages (graphviz)\n4. Run `make docs` to generate all documentation\n5. Configure git for automated commits\n6. Commit any changes back to repo\n7. Deploy to GitHub Pages using official actions\n\n**Configuration needs:**\n- Update `mkdocs.yml` to point to generated docs location\n- Ensure `.gitignore` doesn't exclude generated documentation\n- Set up GitHub Pages to deploy from workflow\n- Configure branch protection to allow workflow commits\n\n**Performance considerations:**\n- Cache Python dependencies and system packages\n- Only regenerate docs when relevant files change\n- Consider using artifacts to store intermediate build outputs",
      "updatedAt" : 1752227742.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "devops", "help wanted", "cicd", "chore", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Set up automated documentation generation in GitHub Actions to build docs, generate architecture diagrams, and deploy to GitHub Pages using MkDocs on every push to main branch.",
      "validationOrRequirement" : "Create .github/workflows/docs.yml workflow file, Workflow triggers on push to main branch and manual dispatch, Install all required dependencies, Include unit test report in generated documentation, Run existing make docs target to generate documentation, Set up MkDocs integration and configuration, Deploy generated docs to GitHub Pages, Handle git authentication for committing back to repo, Add appropriate caching for dependencies and build artifacts",
      "attemptedFixes" : "Create .github/workflows/docs.yml workflow file, Install all required dependencies, Include unit test report in generated documentation, Run existing make docs target to generate documentation, Set up MkDocs integration and configuration, Deploy generated docs to GitHub Pages, Handle git authentication for committing back to repo, Add appropriate caching for dependencies and build artifacts",
      "otherNotes" : "Required GitHub Actions workflow structure, Dependencies to install in CI, Key workflow steps, Configuration needs, Performance considerations",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284379
  }, {
    "issueDTO" : {
      "id" : 3207644824,
      "title" : "[CHORE]: Add vulture (dead code detect) and unimport (unused import detect) to Makefile and GitHub Actions",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/305",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "### \uD83D\uDD27 Chore Summary\nAdd vulture (dead code detection) and unimport (unused import detection) to the Makefile linting suite to help identify and remove unused code like the suspected `manager.py` file.\n\n---\n\n### \uD83E\uDDF1 Area Affected\n- [x] Pre-commit hooks / linters\n- [x] Build system or `Makefile`\n- [x] Dependency cleanup or updates\n\n---\n\n### ?????? Context / Rationale\nDuring code review, we identified potential dead code (specifically `manager.py` with `FederationManager` class) that appears to be duplicated by `gateway_service.py`. To systematically identify and clean up unused code throughout the codebase:\n\n1. **vulture** - Finds unused code (classes, functions, variables) that can be safely removed\n2. **unimport** - Detects unused imports that create false dependencies and clutter\n\nThis will:\n- Reduce technical debt by identifying dead code\n- Improve code maintainability and clarity  \n- Reduce bundle size and dependency overhead\n- Provide ongoing monitoring for unused code introduction\n\n---\n\n### \uD83D\uDCE6 Related Make Targets\n- `make lint` - run full linting suite (vulture/unimport will be added here)\n- `make vulture` - new target for dead code detection\n- `make unimport` - new target for unused import detection\n- `make install` - will need to include new dependencies\n\n---\n\n### \uD83D\uDCCB Acceptance Criteria\n- [x] Add vulture and unimport to project dependencies\n- [x] Create individual `vulture` and `unimport` make targets following existing patterns\n- [x] Add both tools to the `LINTERS` variable in Makefile\n- [x] Add help documentation for new targets\n- [x] Configure appropriate confidence levels and exclusions\n- [x] Linter runs cleanly (`make lint`)\n- [x] CI passes with no regressions\n- [x] Document any configuration files needed (.vulture, .unimport.cfg)\n\n---\n\n### \uD83E\uDDE9 Additional Notes\n\n**Proposed Makefile additions:**\n\n```makefile\n# Add to LINTERS variable:\nLINTERS := isort flake8 pylint mypy bandit pydocstyle pycodestyle pre-commit \\\n           ruff pyright radon pyroma pyrefly spellcheck importchecker \\\n           pytype check-manifest markdownlint vulture unimport\n\n# Add help entries:\n# help: vulture              - Dead code detection\n# help: unimport             - Unused import detection\n\n# Add individual targets:\nvulture:                            ## \uD83E\uDDF9  Dead code detection\n\t@echo \"\uD83E\uDDF9  vulture ???\" && $(VENV_DIR)/bin/vulture mcpgateway --min-confidence 80\n\nunimport:                           ## \uD83D\uDCE6  Unused import detection  \n\t@echo \"\uD83D\uDCE6  unimport ???\" && $(VENV_DIR)/bin/unimport --check --diff mcpgateway\n```\n\n**Dependencies to add:**\n- `vulture>=2.10.0` \n- `unimport>=0.16.0`\n\n**Configuration considerations:**\n- vulture may need a `.vulture` whitelist file for false positives\n- unimport can be configured via `pyproject.toml` if needed\n- Initial run should use `--min-confidence 80` for vulture to reduce noise",
      "updatedAt" : 1752227741.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "devops", "help wanted", "cicd", "chore", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add vulture (dead code detection) and unimport (unused import detection) to the Makefile linting suite to help identify and remove unused code like the suspected `manager.py` file.",
      "validationOrRequirement" : "Add vulture and unimport to project dependencies, create individual vulture and unimport make targets, add both tools to the LINTERS variable in Makefile, add help documentation for new targets, configure appropriate confidence levels and exclusions, and document any configuration files needed (.vulture, .unimport.cfg).",
      "attemptedFixes" : "Add vulture and unimport to project dependencies, create individual vulture and unimport make targets, add both tools to the LINTERS variable in Makefile, add help documentation for new targets, configure appropriate confidence levels and exclusions, and document any configuration files needed (.vulture, .unimport.cfg).",
      "otherNotes" : "Proposed Makefile additions include adding vulture and unimport to LINTERS variable, adding help entries, and adding individual targets for dead code detection and unused import detection. Dependencies to add are vulture >= 2.10.0 and unimport >= 0.16.0. Configuration considerations include using a .vulture whitelist file for false positives, configuring unimport via pyproject.toml if needed, and initial run with --min-confidence 80 for vulture to reduce noise.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284388
  }, {
    "issueDTO" : {
      "id" : 3211223451,
      "title" : "E2E - [Identity] - [Admin user can create a group with particular permissions and assign user to it]",
      "url" : "https://github.com/camunda/camunda/issues/35000",
      "repositoryName" : "camunda/camunda",
      "description" : "### Description\n\nAdmin user can create a group with particular permissions and assign user to it.\n\n### Preconditions\n\nBackground:\nGiven Demo user is logged in with basic auth\nAnd Demo user has created a Test user\nAnd Demo user has created a * permission for applications for the Test user\n\n### Test Data\n\nNew 'Test' user is created. Test user has been granted Apps access permissions.\n\n### User Story\n\n<!-- [Mandatory field] -->\n\n```Gherkin\nScenario: As an Admin user can create a group with particular permissions and assign it to 'Test' user\n\n    And I create a new `TestGroup`\n    And I add the `Test` user to the group\n    And I see the user in the Group's Users table \n    When I navigate to `/identity/authorizations`\n    And I select Resource type `Process definition`\n    And I click `Create authorization` button\n    And I fill the modal form with `Owner type`=`Group`, `Owner`=`TestGroup`, `Recource ID`=`*` and opt in `All` permissions\n    And I click `Create authorization` modal form button\n    Then I can see a new authorization record in the table\n```\n\n### Postconditions\n\nConsider that there will be scenario based on outcome of this one.\n\n### Supported Versions\n\n- Version 8.8\n\n### Implementation Timeline\n\n- Available in: Version 8.8\n\n### Priority\n\n- [ ] High\n- [x] Medium\n- [ ] Low\n\n### Additional Information\n\n\n### Definition of Ready - Checklist\n\n<!-- The assignee will check the DRI. -->\n- [ ] The test case has a meaningful title, description, and testable acceptance criteria\n\n",
      "updatedAt" : 1752227723.000000000,
      "user" : "sergiizakharov",
      "userHtmlUrl" : "https://github.com/sergiizakharov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/36188745?v=4",
      "labels" : [ "qa/c8-orchestration-cluster-e2e-test-suite", "kind/test-case", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "So one thing I notice was that after creating an auth from any resource type Im getting redirected to the 'Application' resource type, so I need to click again where I created the auth to see it there, is this reported? if not, where I can report it?" ],
      "repository" : {
        "description" : "Process Orchestration Framework",
        "homepage" : "https://camunda.com/platform/",
        "name" : "camunda",
        "fullName" : "camunda/camunda",
        "htmlUrl" : "https://github.com/camunda/camunda",
        "gitUrl" : "git://github.com/camunda/camunda.git",
        "sshUrl" : "git@github.com:camunda/camunda.git",
        "cloneUrl" : "https://github.com/camunda/camunda.git",
        "owner" : {
          "login" : "camunda",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 679,
        "stargazersCount" : 3723,
        "watchersCount" : 3723,
        "size" : 643351,
        "openIssuesCount" : 2373,
        "subscribersCount" : 114,
        "pushedAt" : "2025-07-11T23:23:17Z",
        "languages" : {
          "MDX" : 2383,
          "Smarty" : 230,
          "Java" : 53137212,
          "CSS" : 2925,
          "Makefile" : 20359,
          "Go" : 76584,
          "HTML" : 14209,
          "FreeMarker" : 94639,
          "TypeScript" : 6978501,
          "Dockerfile" : 23726,
          "Shell" : 47376,
          "Batchfile" : 3877,
          "SCSS" : 133874,
          "JavaScript" : 1534294
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "As an Admin user, create a group with particular permissions and assign it to 'Test' user, and verify the user can see a new authorization record in the table.",
      "validationOrRequirement" : "The test case should have a meaningful title, description, and testable acceptance criteria (Definition of Ready - Checklist).",
      "attemptedFixes" : "No specific fixes mentioned in the comments.",
      "otherNotes" : "After creating an auth from any resource type, the user is redirected to the 'Application' resource type and needs to click again to see the created auth.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284392
  }, {
    "issueDTO" : {
      "id" : 3221138432,
      "title" : "[CHORE]: Implement Docker HEALTHCHECK",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/362",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "**Priority:** Low (Infrastructure/Deployment)\n\n**Description:**\nThe Docker container for MCP Gateway fails health checks, getting stuck in \"starting\" status for extended periods before transitioning to \"unhealthy\". This prevents proper container orchestration, auto-scaling, and monitoring in production environments.\n\n**Steps to Reproduce:**\n1. Build and run the Docker container:\n   ```bash\n   make docker-stop\n   make docker-run\n   ```\n\n2. Monitor container health status:\n   ```bash\n   # Check container status\n   docker ps --filter name=mcpgateway --format \"table {{.Names}}\\t{{.Status}}\"\n   \n   # Inspect health status\n   docker inspect mcpgateway | jq '.[0].State.Health.Status'\n   ```\n\n3. Check container logs:\n   ```bash\n   docker logs mcpgateway --tail 50\n   ```\n\n**Expected Behavior:**\n- Container should pass health checks within 30-60 seconds\n- Health status should show \"healthy\"\n- Container should respond to health check endpoints\n\n**Actual Behavior:**\n- Container remains in \"health: starting\" for ~2 minutes\n- Eventually transitions to \"unhealthy\" status\n- Health check appears to be failing or missing\n\n**Investigation Findings:**\n1. **Missing HEALTHCHECK instruction**: The `Containerfile.lite` is missing a HEALTHCHECK instruction\n2. **Application runs on port 4444**: The container exposes port 4444, not 8000\n3. **Scratch-based image**: The container uses a minimal scratch image without common tools like curl or wget\n4. **Gunicorn startup delay**: Health checks fail with \"Server disconnected without sending a response\" during gunicorn startup\n5. **localhost vs 127.0.0.1**: Using `localhost` may resolve to IPv6 (::1) which the server might not bind to\n\n**Impact:**\n- Container orchestration systems (Kubernetes, Docker Swarm, ECS) cannot properly manage the container\n- Load balancers cannot determine if the container is ready to receive traffic\n- Auto-scaling and self-healing capabilities are broken\n- Production deployments may route traffic to unhealthy instances\n- CI/CD pipelines may incorrectly report successful deployments\n\n**Root Cause Analysis:**\nThe issue appears to stem from:\n1. Missing or improperly configured HEALTHCHECK instruction in Dockerfile\n2. Lack of health check tools (curl/wget) in the minimal container image\n3. Possible network connectivity issues within the container\n\n**Suggested Fix:**\n\nAdd a Python-based HEALTHCHECK instruction to the Containerfile.lite:\n\n```dockerfile\n# Add this before the final CMD instruction\nHEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \\\n  CMD [\"python3\", \"-c\", \"import httpx,sys;sys.exit(0 if httpx.get('http://localhost:4444/health',timeout=5).status_code==200 else 1)\"]\n```\n\nThis one-liner health check:\n- Uses httpx (which should be available in the project dependencies)\n- Connects to the health endpoint on port 4444\n- Returns exit code 0 (healthy) for HTTP 200 responses\n- Returns exit code 1 (unhealthy) for any other status or connection errors\n- Has a 5-second timeout to prevent hanging\n\n**Prerequisites:**\n- Ensure `httpx` is included in your project dependencies (pyproject.toml)\n- Verify that `/health` endpoint doesn't require authentication\n- Check that the application is binding to `0.0.0.0` not just `127.0.0.1`\n\n**Placement in Containerfile.lite:**\nAdd the HEALTHCHECK instruction after the `USER 1001` line and before the final `CMD` instruction.\n\n**Additional Debugging Steps:**\n1. Test health endpoint from inside the container:\n   ```bash\n   docker exec mcpgateway python3 -c \"import httpx;print(httpx.get('http://localhost:4444/health').status_code)\"\n   ```\n\n2. Check if the app is actually running:\n   ```bash\n   docker exec mcpgateway ps aux | grep python\n   ```\n\n3. Review Docker events and health check logs:\n   ```bash\n   docker events --filter container=mcpgateway\n   docker inspect mcpgateway --format='{{json .State.Health}}'\n   ```\n\n**Testing Requirements:**\n- Verify health check passes within the start period\n- Test with docker-compose to ensure orchestration works\n- Test health check behavior during application startup\n- Verify health check fails appropriately when app is unhealthy\n\n**Related Configurations:**\n- May need to adjust health check parameters based on application startup time\n- Consider separate readiness and liveness endpoints for Kubernetes\n- Health check should not require authentication\n\n**Alternative Solutions:**\n> docker-compose and helm already implement health checks.\n\n1. Use docker-compose health check configuration:\n   ```yaml\n   healthcheck:\n     test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n     interval: 30s\n     timeout: 10s\n     retries: 3\n     start_period: 60s\n   ```\n\n2. For Kubernetes, use HTTP probes:\n   ```yaml\n   livenessProbe:\n     httpGet:\n       path: /health\n       port: 8000\n     initialDelaySeconds: 60\n     periodSeconds: 30\n   ```\n\n**Related Issues:**\n- #338 (Container optimizations)\n- Consider implementing separate `/ready` endpoint for readiness checks\n- May need to update Helm charts to reflect proper health check configuration",
      "updatedAt" : 1752227656.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "devops", "help wanted", "cicd", "chore", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement Docker HEALTHCHECK to prevent container orchestration, auto-scaling, and monitoring issues in production environments",
      "validationOrRequirement" : "Container should pass health checks within 30-60 seconds, health status should show \"healthy\", container should respond to health check endpoints",
      "attemptedFixes" : "Missing HEALTHCHECK instruction in Dockerfile, lack of health check tools (curl/wget) in the minimal container image, possible network connectivity issues within the container",
      "otherNotes" : "The Docker container for MCP Gateway fails health checks, getting stuck in \"starting\" status for extended periods before transitioning to \"unhealthy\". This prevents proper container orchestration, auto-scaling, and monitoring in production environments.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284397
  }, {
    "issueDTO" : {
      "id" : 3212882054,
      "title" : "Public Payouts API",
      "url" : "https://github.com/antiwork/gumroad/issues/585",
      "repositoryName" : "antiwork/gumroad",
      "description" : "# Public Payouts REST API (V2)\n\n## Summary\nCreate a public REST API for payouts in `/api/v2/payouts` following existing API patterns, with read-only access to payout data.\n\n## Background\nCurrently, Gumroad has comprehensive payout functionality via `Api::Internal::Helper::PayoutsController`, but no public API for external developers. The internal API includes payout history, balance information, manual payout creation, and CSV exports.\n\n## Proposed Solution\nDevelop a public REST API following the existing `/api/v2/` patterns:\n\n### Endpoints (Read-Only)\n- **GET /api/v2/payouts** - List payouts with pagination\n- **GET /api/v2/payouts/:id** - Get specific payout details\n\n### Implementation Details\n- **Controller**: `Api::V2::PayoutsController` extending `Api::V2::BaseController`\n- **Authentication**: Doorkeeper OAuth with appropriate scopes (similar to sales API)\n- **Response Format**: Standard `{ success: true, payouts: [...] }` pattern\n- **Documentation**: Add to `config/initializers/api_v2_methods.rb` for auto-generated docs\n\n### API Scope\nFollowing existing patterns in `config/routes.rb`:\n```ruby\nresources :payouts, only: [:index, :show]\n```\n\n### Response Structure\n```json\n{\n  \"success\": true,\n  \"payouts\": [\n    {\n      \"id\": \"payout_123\",\n      \"amount\": \"150.00\",\n      \"currency\": \"USD\",\n      \"status\": \"completed\",\n      \"created_at\": \"2025-01-01T00:00:00Z\",\n      \"processed_at\": \"2025-01-02T00:00:00Z\",\n      \"payment_processor\": \"stripe\"\n    }\n  ]\n}\n```\n\n## Technical Implementation\n\n### Leverage Existing Code\n- Reuse logic from `Api::Internal::Helper::PayoutsController`\n- Follow authentication patterns from `Api::V2::SalesController`\n- Use existing payout models and services\n\n### Security & Performance\n- OAuth scope-based access control\n- Rate limiting via existing middleware\n- Proper data filtering (only user's own payouts)\n- Pagination for large datasets\n\n### Documentation\n- Add to API methods configuration\n- OpenAPI schema generation\n- Developer portal integration\n\n## Success Metrics\n- API adoption by external developers\n- Reduced support requests for payout data access\n- Performance benchmarks matching other V2 endpoints\n\n## Related Files\n- `app/controllers/api/internal/helper/payouts_controller.rb` (existing internal API)\n- `app/controllers/api/v2/base_controller.rb` (base controller pattern)\n- `app/controllers/api/v2/sales_controller.rb` (similar API pattern)\n- `config/routes.rb` (routing patterns)\n- `config/initializers/api_v2_methods.rb` (API documentation)\n",
      "updatedAt" : 1752227540.000000000,
      "user" : "devin-ai-integration[bot]",
      "userHtmlUrl" : "https://github.com/apps/devin-ai-integration",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/811515?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue", "$1K" ],
      "state" : "OPEN",
      "comments" : [ "**Update:** PR is ready for review!\n\n~~@slavingia I have put up a draft PR at https://github.com/antiwork/gumroad/pull/587/files (where the endpoints are functionally working)~~\n\n~~It will be ready for review within a day.~~\n\nFeel free to assign me here if that'd be easier to manage!", "> Doorkeeper OAuth with appropriate scopes (similar to sales API)\n\nLooks like there's no existing scope that fits this payouts access. So I'll add a new scope called \"view_payouts\". Let me know if that's not expected.", "Sounds good", "Attempting this \n\nHave a solution \nCreate the API v2 endpoint for payouts with two methods:\nGET /api/v2/payouts to list all payouts for the authenticated user\nGET /api/v2/payouts/:id to get details for a specific payout\nAdd the payout_read scope to Doorkeeper for OAuth authentication\n\nUpdate the API documentation in the appropriate configuration files\n\nCreate controller specs to test functionality including:\n\nAuthentication requirements\nAuthorization via OAuth scopes\nPagination behavior\nSingle payout retrieval\nError handling for not found resources\nThis provides a secure, well-tested API endpoint following Gumroad's existing patterns for API v2 endpoints.", "I didn't notice there was a pr opened for the same :tear: \n\nI feel it should be shown in the issues which pr is opened on it @slavingia sir, I was working on this for around 2hrs \uD83E\uDD79 ", "It is listed if you read the thread of the issue." ],
      "repository" : {
        "description" : "Sell stuff and see what sticks",
        "homepage" : "https://gumroad.com",
        "name" : "gumroad",
        "fullName" : "antiwork/gumroad",
        "htmlUrl" : "https://github.com/antiwork/gumroad",
        "gitUrl" : "git://github.com/antiwork/gumroad.git",
        "sshUrl" : "git@github.com:antiwork/gumroad.git",
        "cloneUrl" : "https://github.com/antiwork/gumroad.git",
        "owner" : {
          "login" : "antiwork",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1043,
        "stargazersCount" : 6428,
        "watchersCount" : 6428,
        "size" : 134834,
        "openIssuesCount" : 65,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-11T05:06:32Z",
        "languages" : {
          "TypeScript" : 2753257,
          "Dockerfile" : 8221,
          "Shell" : 25771,
          "CSS" : 5403,
          "SCSS" : 110402,
          "Makefile" : 9459,
          "JavaScript" : 27663,
          "HTML" : 1630913,
          "Ruby" : 16204075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a public REST API for payouts in /api/v2/payouts following existing API patterns, with read-only access to payout data.",
      "validationOrRequirement" : "The API should follow existing API patterns, with read-only access to payout data. The authentication should be via Doorkeeper OAuth with the appropriate scopes (similar to sales API).",
      "attemptedFixes" : "Create the API v2 endpoint for payouts with two methods: GET /api/v2/payouts to list all payouts for the authenticated user and GET /api/v2/payouts/:id to get details for a specific payout. Add the payout_read scope to Doorkeeper for OAuth authentication. Update the API documentation in the appropriate configuration files. Create controller specs to test functionality including: authentication requirements, authorization via OAuth scopes, pagination behavior, single payout retrieval, error handling for not found resources.",
      "otherNotes" : "The PR is ready for review at https://github.com/antiwork/gumroad/pull/587/files. The issue is already assigned to @slavingia. The author has spent around 2 hours working on this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284405
  }, {
    "issueDTO" : {
      "id" : 3220200085,
      "title" : "[Bug]: Large empty space after line number in text boxes",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/355",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "### \uD83D\uDC1E Bug Summary\nText boxes in Resource and Prompt addition screens have a large empty space when copy pasting content.\nLine numbers are deleted with backspace. That is not expected.\n\n---\n\n### \uD83E\uDDE9 Affected Component\nSelect the area of the project impacted:\n\n- [ ] `mcpgateway` - API\n- [x] `mcpgateway` - UI (admin panel)\n- [ ] `mcpgateway.wrapper` - stdio wrapper\n- [ ] Federation or Transports\n- [ ] CLI, Makefiles, or shell scripts\n- [ ] Container setup (Docker/Podman/Compose)\n- [ ] Other (explain below)\n\n---\n\n### \uD83D\uDD01 Steps to Reproduce\n\n1. Go to Prompts/Resources screen\n2. Paste content in `content` or `template` sections. There is a large space after the number `1`\n3. Press backspace - extra spaces are removed along with line number\n\n---\n\n### \uD83E\uDD14 Expected Behavior\n\n1. The text boxes should start showing text at left end\n2. The line numbers should not be deleted with backspace\n\n---",
      "updatedAt" : 1752227490.000000000,
      "user" : "madhav165",
      "userHtmlUrl" : "https://github.com/madhav165",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12028265?v=4",
      "labels" : [ "bug", "help wanted", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Resolve the issue of large empty space after line number in text boxes in Resource and Prompt addition screens.",
      "validationOrRequirement" : "Text boxes should start showing text at left end. Line numbers should not be deleted with backspace.",
      "attemptedFixes" : "",
      "otherNotes" : "Text boxes in Resource and Prompt addition screens have a large empty space when copy pasting content. Line numbers are deleted with backspace.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284408
  }, {
    "issueDTO" : {
      "id" : 3217535987,
      "title" : "Remove no-throw-error ESLint suppressions in @liam-hq/github",
      "url" : "https://github.com/liam-hq/liam/issues/2460",
      "repositoryName" : "liam-hq/liam",
      "description" : "## Summary\n\nThis issue tracks the removal of ESLint suppressions for the `no-throw-error/no-throw-error` rule in the `@liam-hq/github` package.\n\n## Context\n\nPR #2442 introduced a custom ESLint rule that prohibits `throw new Error()` statements and encourages the use of neverthrow Result types instead. To enable incremental adoption, bulk suppressions were applied to existing violations.\n\n## Task\n\nReplace all `throw new Error()` statements in the `frontend/internal-packages/github/` directory with neverthrow Result types (`err`, `ok`, `ResultAsync`) imported from \"neverthrow\".\n\n## Files to update\n\n- `frontend/internal-packages/github/eslint-suppressions.json` - Contains 7 suppressed violations\n\n## Steps\n\n1. Review the suppressed violations in `frontend/internal-packages/github/eslint-suppressions.json`\n2. Replace `throw new Error()` statements with appropriate neverthrow Result types\n3. Import neverthrow types: `import { err, ok, ResultAsync } from \"neverthrow\"`\n4. Update function return types to use `Result<T, E>` or `ResultAsync<T, E>`\n5. Update calling code to handle Result types appropriately\n6. Run `pnpm lint:eslint --prune-suppressions` to update eslint-suppressions.json after modifications\n7. Verify all suppressions are resolved\n\n## Related\n\n- Resolves: #2442",
      "updatedAt" : 1752227459.000000000,
      "user" : "claude[bot]",
      "userHtmlUrl" : "https://github.com/apps/claude",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/1236702?v=4",
      "labels" : [ "neverthrow", "eslint", "tech debt", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Automatically generates beautiful and easy-to-read ER diagrams from your database.",
        "homepage" : "https://liambx.com",
        "name" : "liam",
        "fullName" : "liam-hq/liam",
        "htmlUrl" : "https://github.com/liam-hq/liam",
        "gitUrl" : "git://github.com/liam-hq/liam.git",
        "sshUrl" : "git@github.com:liam-hq/liam.git",
        "cloneUrl" : "https://github.com/liam-hq/liam.git",
        "owner" : {
          "login" : "liam-hq",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 4149,
        "watchersCount" : 4149,
        "size" : 128286,
        "openIssuesCount" : 86,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-12T00:59:43Z",
        "languages" : {
          "TypeScript" : 1870996,
          "MDX" : 82980,
          "CSS" : 229518,
          "Shell" : 5433,
          "PLpgSQL" : 360220,
          "Handlebars" : 695,
          "JavaScript" : 42995,
          "HTML" : 985,
          "Ruby" : 7830
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove no-throw-error ESLint suppressions in @liam-hq/github, replace throw new Error() statements in frontend/internal-packages/github/ directory with neverthrow Result types",
      "validationOrRequirement" : "Review the suppressed violations, replace throw new Error() statements, import neverthrow types, update function return types, update calling code, run pnpm lint:eslint --prune-suppressions, verify all suppressions are resolved",
      "attemptedFixes" : "Replace all throw new Error() statements with neverthrow Result types, import neverthrow types, update function return types, update calling code, run pnpm lint:eslint --prune-suppressions, verify all suppressions are resolved",
      "otherNotes" : "PR #2442 introduced a custom ESLint rule, bulk suppressions were applied to existing violations, and there are 7 suppressed violations in frontend/internal-packages/github/eslint-suppressions.json",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284414
  }, {
    "issueDTO" : {
      "id" : 3221240641,
      "title" : "[Bug]: Clarify Difference Between \"Reachable\" and \"Available\" Status in Version Info",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/373",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "# Clarify Difference Between \"Reachable\" and \"Available\" Status in Version Info\n\n**Priority:** Medium (UI/UX Clarity)\n\n**Description:**\nThe version info page displays Redis status as \"Available\" or \"Not Available\" which is confusing. When Redis is not configured (e.g., using in-memory cache), it still shows as \"Not Available\" implying it should be available but isn't working. The UI should distinguish between:\n- Not Configured (cache_type is not \"redis\")\n- Configured but Unreachable (cache_type is \"redis\" but connection fails)\n- Configured and Reachable (cache_type is \"redis\" and connection succeeds)\n\n**Current Behavior:**\n- Redis shows \"??? Not Available\" even when cache_type is set to \"memory\" or \"none\"\n- No indication of what cache type is actually being used\n- Users may think Redis is broken when it's simply not configured\n\n**Expected Behavior:**\n- Show cache type configuration clearly\n- Display appropriate status based on configuration:\n  - If cache_type != \"redis\": Show \"Not Configured\" with neutral styling\n  - If cache_type == \"redis\" and reachable: Show \"Connected\" with success styling\n  - If cache_type == \"redis\" and not reachable: Show \"Connection Failed\" with error styling\n\n**Suggested Implementation:**\n\n1. **Update the template** (`templates/version_info_partial.html`):\n```html\n<!-- Redis Status -->\n<div class=\"border rounded-lg p-4 \n  {% if payload.settings.cache_type != 'redis' %}\n    border-gray-200 bg-gray-50 dark:border-gray-600 dark:bg-gray-900/20\n  {% elif payload.redis.reachable %}\n    border-green-200 bg-green-50 dark:border-green-700 dark:bg-green-900/20\n  {% else %}\n    border-red-200 bg-red-50 dark:border-red-700 dark:bg-red-900/20\n  {% endif %}\">\n  <div class=\"flex items-center justify-between\">\n    <div>\n      <h4 class=\"font-medium \n        {% if payload.settings.cache_type != 'redis' %}\n          text-gray-800 dark:text-gray-300\n        {% elif payload.redis.reachable %}\n          text-green-800 dark:text-green-300\n        {% else %}\n          text-red-800 dark:text-red-300\n        {% endif %}\">Redis Cache</h4>\n      <p class=\"text-sm \n        {% if payload.settings.cache_type != 'redis' %}\n          text-gray-600 dark:text-gray-400\n        {% elif payload.redis.reachable %}\n          text-green-600 dark:text-green-400\n        {% else %}\n          text-red-600 dark:text-red-400\n        {% endif %}\">\n        Cache Type: {{ payload.settings.cache_type | capitalize }}\n      </p>\n    </div>\n    <div class=\"flex items-center\">\n      {% if payload.settings.cache_type != 'redis' %}\n        <svg class=\"h-8 w-8 text-gray-400\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n          <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z\"></path>\n        </svg>\n      {% elif payload.redis.reachable %}\n        <svg class=\"h-8 w-8 text-green-500\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n          <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z\"></path>\n        </svg>\n      {% else %}\n        <svg class=\"h-8 w-8 text-red-500\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n          <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M10 14l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2m7-2a9 9 0 11-18 0 9 9 0 0118 0z\"></path>\n        </svg>\n      {% endif %}\n    </div>\n  </div>\n  <div class=\"mt-2\">\n    <span class=\"inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium \n      {% if payload.settings.cache_type != 'redis' %}\n        bg-gray-100 text-gray-800 dark:bg-gray-800 dark:text-gray-200\n      {% elif payload.redis.reachable %}\n        bg-green-100 text-green-800 dark:bg-green-800 dark:text-green-200\n      {% else %}\n        bg-red-100 text-red-800 dark:bg-red-800 dark:text-red-200\n      {% endif %}\">\n      {% if payload.settings.cache_type != 'redis' %}\n        ?????? Not Configured\n      {% elif payload.redis.reachable %}\n        ??? Connected\n      {% else %}\n        ??? Connection Failed\n      {% endif %}\n    </span>\n    {% if payload.settings.cache_type == 'redis' and payload.redis.server_version %}\n    <span class=\"ml-2 text-xs text-gray-500 dark:text-gray-400\">\n      v{{ payload.redis.server_version }}\n    </span>\n    {% endif %}\n  </div>\n</div>\n```\n\n2. **Alternative: Add a separate Cache Configuration card**:\n```html\n<!-- Cache Configuration Card -->\n<div class=\"bg-white rounded-lg shadow p-6 dark:bg-gray-800\">\n  <h3 class=\"text-lg font-medium mb-4 dark:text-gray-200 flex items-center\">\n    <svg class=\"h-6 w-6 mr-2 text-indigo-600\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n      <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M4 7v10c0 2.21 3.582 4 8 4s8-1.79 8-4V7M4 7c0 2.21 3.582 4 8 4s8-1.79 8-4M4 7c0-2.21 3.582-4 8-4s8 1.79 8 4\"></path>\n    </svg>\n    Cache Configuration\n  </h3>\n  <div class=\"space-y-2\">\n    <div class=\"flex justify-between items-center\">\n      <span class=\"text-gray-600 dark:text-gray-400\">Type:</span>\n      <span class=\"font-medium dark:text-gray-200\">{{ payload.settings.cache_type | capitalize }}</span>\n    </div>\n    {% if payload.settings.cache_type == 'redis' %}\n    <div class=\"flex justify-between items-center\">\n      <span class=\"text-gray-600 dark:text-gray-400\">Status:</span>\n      <span class=\"font-medium {% if payload.redis.reachable %}text-green-600 dark:text-green-400{% else %}text-red-600 dark:text-red-400{% endif %}\">\n        {% if payload.redis.reachable %}Connected{% else %}Disconnected{% endif %}\n      </span>\n    </div>\n    {% if payload.redis.server_version %}\n    <div class=\"flex justify-between items-center\">\n      <span class=\"text-gray-600 dark:text-gray-400\">Version:</span>\n      <span class=\"font-medium dark:text-gray-200\">{{ payload.redis.server_version }}</span>\n    </div>\n    {% endif %}\n    {% endif %}\n  </div>\n</div>\n```\n\n**Benefits:**\n- Clear distinction between configuration and connection status\n- Users understand when Redis is intentionally not being used\n- Reduces confusion and unnecessary troubleshooting\n- Shows actual cache type being used (memory, redis, none)\n\n**Testing Requirements:**\n- Test with cache_type = \"memory\" - should show \"Not Configured\"\n- Test with cache_type = \"redis\" and Redis running - should show \"Connected\"\n- Test with cache_type = \"redis\" and Redis stopped - should show \"Connection Failed\"\n- Verify styling is appropriate for each state (neutral/success/error)\n\n**Acceptance Criteria:**\n- [ ] Redis status shows \"Not Configured\" when cache_type is not \"redis\"\n- [ ] Cache type is clearly displayed\n- [ ] Status uses appropriate colors (gray for not configured, green for connected, red for failed)\n- [ ] Version is only shown when Redis is connected\n- [ ] UI clearly communicates the cache configuration state\n\n**Related Issues:**\n- Similar confusion may exist for database \"reachable\" vs \"available\"\n- Consider standardizing status terminology across all services",
      "updatedAt" : 1752227311.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "bug", "help wanted", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I'd love to work on this issue. I have experience working with Jinja templates and UI logic, and I'm confident I can implement the conditional rendering and improve the Redis status display as described.\n\nCould you please assign it to me? Thanks" ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to clarify the difference between 'Reachable' and 'Available' status in the Version Info for Redis, specifically for the cache configuration (configured or not, reachable or not), and to provide clear styling for each state.",
      "validationOrRequirement" : "The issue has several requirements and validations, including showing the correct status based on cache configuration, providing clear styling for each state, and testing with different cache types and Redis states. The acceptance criteria includes several specific conditions that the solution must meet.",
      "attemptedFixes" : "The issue description does not mention any attempted fixes or blockers encountered.",
      "otherNotes" : "The issue is about clarifying the difference between 'Reachable' and 'Available' status in the Version Info, specifically for Redis. The main goal is to show the correct status based on the cache configuration (configured or not, reachable or not) and to provide clear styling for each state. The suggested implementation is to update the template and add a separate Cache Configuration card. The benefits include clear distinction between configuration and connection status, reduced confusion, and better understanding of the cache configuration state.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284421
  }, {
    "issueDTO" : {
      "id" : 3221060767,
      "title" : "More performant etag support",
      "url" : "https://github.com/maplibre/martin/issues/1917",
      "repositoryName" : "maplibre/martin",
      "description" : "CDNs rely heavily on etag (usually a hash) to identify if the tile has changed or not. In some cases, the tile backend like .mbtiles is already storing tiles with some hash. For example, .mbtiles frequently uses two tables to remove duplicate tiles - one stores `z, x, y, hash` columns, and another table - `hash, data blob`.\n\nCurrently, we implement this via running a non-cryptographical hash function over the output.\nWe do this even in cases where there is a hash that we could serve causing unnessesary CPU usage (latency is basically instant)\n\nSteps involved:\n- [x] make mbtiles backend recognize when the `.mbtiles` file has two frequently used tables as described above, and use the hash value as etag https://github.com/maplibre/martin/pull/1787\n- [ ] allow individual backends like mbtiles to supply a pre-generated etag\n- [ ] allow PostgreSQL functions to return rows with two columns, treating the second column as the key. OpenMapTiles already generates these types of functions.\n- [ ] support etags for `/catalog`",
      "updatedAt" : 1752227301.000000000,
      "user" : "CommanderStorm",
      "userHtmlUrl" : "https://github.com/CommanderStorm",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/26258709?v=4",
      "labels" : [ "performance", "mbtiles", "pmtiles", "pg", "good first issue", "serving" ],
      "state" : "OPEN",
      "comments" : [ "@nyurik I hit the following errors while trying to work on issue #1917.\n\n- Branch creation is blocked due to repository rules\n\n> [!NOTE]\n> \n> - To learn about managing repository rules, head to the [GitHub Docs](https://gh.io/copilot-coding-agent-rulesets).\n\n\nAfter resolving these issues, you can ask me to try again by unassigning and then reassigning the issue to me again.\n\n<!-- copilot-coding-agent-error: issue-rules-error -->" ],
      "repository" : {
        "description" : "Blazing fast and lightweight PostGIS, MBtiles and PMtiles tile server, tile generation, and mbtiles tooling.",
        "homepage" : "https://martin.maplibre.org",
        "name" : "martin",
        "fullName" : "maplibre/martin",
        "htmlUrl" : "https://github.com/maplibre/martin",
        "gitUrl" : "git://github.com/maplibre/martin.git",
        "sshUrl" : "git@github.com:maplibre/martin.git",
        "cloneUrl" : "https://github.com/maplibre/martin.git",
        "owner" : {
          "login" : "maplibre",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 266,
        "stargazersCount" : 2828,
        "watchersCount" : 2828,
        "size" : 20365,
        "openIssuesCount" : 99,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T02:52:40Z",
        "languages" : {
          "TypeScript" : 830,
          "Shell" : 29490,
          "CSS" : 198,
          "Rust" : 672567,
          "JavaScript" : 436,
          "HTML" : 18833,
          "Just" : 14278
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement more performant etag support in maplibre/martin, reduce unnecessary CPU usage and latency",
      "validationOrRequirement" : "make mbtiles backend recognize two frequently used tables, allow individual backends to supply pre-generated etag, allow PostgreSQL functions to return rows with two columns, support etags for /catalog",
      "attemptedFixes" : "attempted to work on issue #1917, but faced errors due to repository rules",
      "otherNotes" : "Repository rules blocked branch creation, errors occurred while working on issue #1917, need to resolve these issues before proceeding",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284425
  }, {
    "issueDTO" : {
      "id" : 3221244791,
      "title" : "[Bug]: Fix \"metrics-loading\" Element Not Found Console Warning",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/374",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "# Fix \"metrics-loading\" Element Not Found Console Warning\n\n**Priority:** Low (UI/Console Cleanup)\n\n**Description:**\nThe browser console shows a warning \"Element with id 'metrics-loading' not found\" when navigating the admin UI. This occurs because the JavaScript code attempts to manipulate a loading element that may not exist in the DOM at the time of execution, particularly when switching tabs or during initial page load.\n\n**Current Behavior:**\n- Console warning appears: \"Element with id 'metrics-loading' not found\"\n- The warning is harmless but clutters the console\n- Occurs in functions `showMetricsLoading()` and `hideMetricsLoading()`\n\n**Expected Behavior:**\n- No console warnings related to missing DOM elements\n- Loading states should work when the element exists\n- Code should gracefully handle cases where the element doesn't exist\n\n**Root Cause:**\nThe code tries to access the \"metrics-loading\" element without checking if it exists first. This happens when:\n1. The metrics tab hasn't been rendered yet\n2. The loading element has already been removed\n3. The metrics panel itself doesn't exist\n\n**Current Code (from admin.js):**\n```javascript\nfunction hideMetricsLoading() {\n    const loadingDiv = safeGetElement(\"metrics-loading\");\n    if (loadingDiv && loadingDiv.parentNode) {\n        loadingDiv.parentNode.removeChild(loadingDiv);\n    }\n}\n```\n\n**Suggested Fix:**\n\n1. **Update the `safeGetElement` function to not warn for expected missing elements**:\n```javascript\n// Add optional parameter to suppress warnings\nfunction safeGetElement(id, suppressWarning = false) {\n    try {\n        const element = document.getElementById(id);\n        if (!element && !suppressWarning) {\n            console.warn(`Element with id \"${id}\" not found`);\n        }\n        return element;\n    } catch (error) {\n        console.error(`Error getting element \"${id}\":`, error);\n        return null;\n    }\n}\n```\n\n2. **Update metrics loading functions to suppress warnings**:\n```javascript\nfunction showMetricsLoading() {\n    const metricsPanel = safeGetElement(\"metrics-panel\");\n    if (metricsPanel) {\n        // Check if loading already exists to avoid duplicates\n        const existingLoading = safeGetElement(\"metrics-loading\", true); // Suppress warning\n        if (existingLoading) {\n            return; // Already showing loading\n        }\n        \n        const loadingDiv = document.createElement(\"div\");\n        loadingDiv.id = \"metrics-loading\";\n        loadingDiv.className = \"flex justify-center items-center p-8\";\n        loadingDiv.innerHTML = `\n            <div class=\"text-center\">\n                <div class=\"animate-spin rounded-full h-12 w-12 border-b-2 border-indigo-600 mx-auto mb-4\"></div>\n                <p class=\"text-gray-600\">Loading metrics...</p>\n                <p class=\"text-sm text-gray-500 mt-2\">This may take a moment</p>\n            </div>\n        `;\n        metricsPanel.innerHTML = \"\";\n        metricsPanel.appendChild(loadingDiv);\n    }\n}\n\nfunction hideMetricsLoading() {\n    const loadingDiv = safeGetElement(\"metrics-loading\", true); // Suppress warning\n    if (loadingDiv && loadingDiv.parentNode) {\n        loadingDiv.parentNode.removeChild(loadingDiv);\n    }\n}\n```\n\n3. **Alternative approach - Use querySelector with null checks**:\n```javascript\nfunction hideMetricsLoading() {\n    const loadingDiv = document.querySelector(\"#metrics-loading\");\n    if (loadingDiv) {\n        loadingDiv.remove();\n    }\n}\n```\n\n4. **Add defensive checks in metrics loading flow**:\n```javascript\nasync function loadAggregatedMetrics() {\n    // Ensure we're still on the metrics tab\n    const metricsPanel = safeGetElement(\"metrics-panel\", true);\n    if (!metricsPanel || metricsPanel.closest('.tab-panel.hidden')) {\n        console.log(\"Metrics panel not visible, skipping load\");\n        return;\n    }\n    \n    // Continue with metrics loading...\n}\n```\n\n**Additional Improvements:**\n1. Consider using a loading state variable instead of checking DOM:\n```javascript\nconst MetricsState = {\n    isLoading: false,\n    \n    setLoading(loading) {\n        this.isLoading = loading;\n        if (loading) {\n            showMetricsLoading();\n        } else {\n            hideMetricsLoading();\n        }\n    }\n};\n```\n\n2. Use CSS classes instead of element removal:\n```javascript\nfunction hideMetricsLoading() {\n    const loadingDiv = document.querySelector(\"#metrics-loading\");\n    if (loadingDiv) {\n        loadingDiv.classList.add(\"hidden\");\n    }\n}\n```\n\n**Testing Requirements:**\n- Verify no console warnings appear during normal navigation\n- Test rapid tab switching between metrics and other tabs\n- Ensure loading states still work correctly when shown\n- Test with slow network to ensure loading states are visible\n- Verify no duplicate loading elements are created\n\n**Benefits:**\n- Cleaner console output for developers\n- More robust error handling\n- Better user experience with no functional impact\n- Easier debugging without spurious warnings\n\n**Acceptance Criteria:**\n- [ ] No \"Element with id 'metrics-loading' not found\" warnings in console\n- [ ] Loading states continue to work when navigating to metrics tab\n- [ ] No visual regressions in metrics loading behavior\n- [ ] Code gracefully handles missing DOM elements\n- [ ] No other console warnings introduced by the fix\n\n**Related Issues:**\n- Consider implementing a global loading state manager\n- Review other places where DOM elements are accessed without checks\n- Standardize approach to element existence checking across the codebase",
      "updatedAt" : 1752227179.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "bug", "help wanted", "good first issue", "triage", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I'd love to work on this issue as part of my open source contributions. I've worked with DOM manipulation, defensive coding patterns, and improving developer experience by reducing unnecessary console warnings.\n\nI can implement the suggested improvements, including suppressing expected warnings, avoiding duplicate loaders, and ensuring clean loading states in the metrics panel.\n\nCould you please assign this issue to me? Thank you!" ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the 'metrics-loading' element not found console warning by updating the 'safeGetElement' function to not warn for expected missing elements, updating the metrics loading functions to suppress warnings, and adding defensive checks in the metrics loading flow.",
      "validationOrRequirement" : "The code should gracefully handle cases where the element doesn't exist, no console warnings related to missing DOM elements, and loading states should work when the element exists.",
      "attemptedFixes" : "The suggested fix includes updating the 'safeGetElement' function to not warn for expected missing elements, updating the metrics loading functions to suppress warnings, and adding defensive checks in the metrics loading flow. Alternative approaches include using querySelector with null checks and adding a loading state variable instead of checking DOM.",
      "otherNotes" : "The code tries to access the 'metrics-loading' element without checking if it exists first. This happens when the metrics tab hasn't been rendered yet, the loading element has already been removed, or the metrics panel itself doesn't exist. The suggested fix is to update the 'safeGetElement' function to not warn for expected missing elements, update the metrics loading functions to suppress warnings, and add defensive checks in the metrics loading flow.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284433
  }, {
    "issueDTO" : {
      "id" : 3221233923,
      "title" : "[Bug]: Fix Makefile to let you pick docker or podman and work consistently with the right image name (draft)",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/371",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "See make trivy..",
      "updatedAt" : 1752226996.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "bug", "help wanted", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the Makefile to enable consistent use with docker or podman and the correct image name.",
      "validationOrRequirement" : "The Makefile should allow the user to pick docker or podman and work consistently with the right image name.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the Makefile and the use of docker or podman, as well as image name consistency.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284436
  }, {
    "issueDTO" : {
      "id" : 2440422382,
      "title" : "Improve USB plugin with more artefacts",
      "url" : "https://github.com/fox-it/dissect.target/issues/777",
      "repositoryName" : "fox-it/dissect.target",
      "description" : "Can use https://github.com/khyrenz/parseusbs for reference.",
      "updatedAt" : 1752226976.000000000,
      "user" : "Schamper",
      "userHtmlUrl" : "https://github.com/Schamper",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1254028?v=4",
      "labels" : [ "plugin", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Executed `target-query -f usb` against the image provided by @khyrenz at https://www.khyrenz.com/resources to match testresults of https://github.com/khyrenz/tool_validation/blob/main/usb_connection_reports/Khyrenz%20-%20Tool_Validation_Report%20-%20USB%20Connections%20-%20parseUSBs%201.4.4.pdf.\n\nValues in bold are at first glance incorrect/missing. \n\n| Device Friendly Name               | iSerial Number            | First Connected         | Last Connected         | Last Removed           | Other Connections | Other Disconnections | Drive Letter | Volume Name | Volume Serial Numbers                                | User  |\n|------------------------------------|---------------------------|-------------------------|------------------------|------------------------|-------------------|----------------------|--------------|-------------|-----------------------------------------------------|-------|\n| General UDisk USB Device           | 7&f810be1&0&_&0           | 2023-03-04 17:55:41    | 2023-03-04 18:43:31    | 2023-03-04 19:29:47    | N/A               | N/A                  | E:\\\\         |          | **\\\\??\\\\Volume{0cd210fb-ba8c-11ed-86fe-000c2968ee15}** | user  |\n| Generic Flash Disk USB Device      | EFC74121&0                | 2023-03-04 18:08:48    | 2023-03-04 18:08:48    | N/A                    | **N/A**               | N/A                  |   N/A   | HEDGEHOG        | **\\\\??\\\\Volume{0cd21180-ba8c-11ed-86fe-000c2968ee15}** | user  |\n| Specific STORAGE DEVICE USB Device | 60875343&0                | 2023-03-04 17:19:12    | 2023-03-04 17:34:22    | 2023-03-04 17:47:08    | **N/A**               | **N/A**                  | N/A          | BAND         | **\\\\??\\\\Volume{0cd21023-ba8c-11ed-86fe-000c2968ee15}** | user  |\n| VendorCo ProductCode USB Device    | 7918331133733033&0        | 2023-03-04 16:11:36    | 2023-03-04 16:11:36    | 2023-03-04 16:34:07    | **N/A**               | **N/A**                  |   N/A         | ROSE         | **\\\\??\\\\Volume{0cd20e1f-ba8c-11ed-86fe-000c2968ee15}** | user  |\n\nObservations:\n\n- `Volume Serial Numbers` and filesystem type (should be something like ExFAT) is incorrect. Not sure how to resolve this at the moment..\n- `Other connections` and `Other Disconnections` are likely retrieved from `evtx` which we do parse but not yield usb records for specifically.\n- A fifth entry is missing entirely this is a Samsung PSSD T7 device.\n- Serial numbers are parsed with & values in them.\n\nThe missing Samsung disk can be found in the EVTX, but its serial number is reversed for some reason(?) Report suggest `S5TANK...` here it ends with `....KNAT5S`.\n\n> <filesystem/windows/evtx hostname='DESKTOP-1V9DD1F' domain=None ts=2023-03-05 23:46:07.057306+00:00 \n> Provider_Name='Microsoft-Windows-StorPort' EventID=500 AbortSupported='0' AdapterGuid='{130FD20C-8CBA-ED11-86FE-000C2968EE15}' \n> BootDevice='0' Cdb='28000000000000001000' CdbLength='10' Channel='Microsoft-Windows-Storage-Storport/Operational'\n> ClassDeviceGuid='{5CA8B1A9-40C0-0433-E9CE-A70E8A95BA88}' Computer='DESKTOP-1V9DD1F' Correlation_ActivityID=None\n> Correlation_RelatedActivityID=None EventID_Qualifiers=None EventRecordID='222' Execution_ProcessID='8716' \n> Execution_ThreadID='184' Keywords='0x800080000000000' LUN='0' Level='3' MiniportName='UASPStor' Opcode='0' \n> PathID='0' PortNumber='4' **ProductId='PSSD T7         '** Provider_Guid='{1E6A63C4-8679-4646-BF10-7BC3B4A76E8E}' \n> Security_UserID=None **SerialNumber='A283205N0KNAT5S'** SrbFunction='0' SrbTimeout='15' TargetID='0' Task='0' \n> **VendorId='Samsung '** Version='4' source='sysvol\\windows\\system32\\winevt\\logs\\Microsoft-Windows-Storage-Storport%4Operational.evtx'>\n\nTodo: \nThis issue should focus on exploring expanding the current `usb.py` plugin with evtx parsing capabilites. \nRenaming the current class/functions to `usb_regf` and creating a new `usb_evtx` function/class. \nThe plugin should probably als be moved one folder up to the `widows/ folder` from the current `windows/regf` folder. " ],
      "repository" : {
        "description" : "The Dissect module tying all other Dissect modules together. It provides a programming API and command line tools which allow easy access to various data sources inside disk images or file collections (a.k.a. targets).",
        "homepage" : "",
        "name" : "dissect.target",
        "fullName" : "fox-it/dissect.target",
        "htmlUrl" : "https://github.com/fox-it/dissect.target",
        "gitUrl" : "git://github.com/fox-it/dissect.target.git",
        "sshUrl" : "git@github.com:fox-it/dissect.target.git",
        "cloneUrl" : "https://github.com/fox-it/dissect.target.git",
        "owner" : {
          "login" : "fox-it",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 63,
        "stargazersCount" : 68,
        "watchersCount" : 68,
        "size" : 10984,
        "openIssuesCount" : 179,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-10T13:12:21Z",
        "languages" : {
          "Shell" : 3720,
          "Makefile" : 795,
          "Roff" : 127,
          "YARA" : 382,
          "Python" : 4436191
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to improve the USB plugin with more artefacts by adding evtx parsing capabilities.",
      "validationOrRequirement" : "The issue does not provide any specific validations or requirements, but it mentions the need to resolve issues with `Volume Serial Numbers` and filesystem type.",
      "attemptedFixes" : "The issue does not provide any attempted fixes or blockers, but it mentions observations and todo tasks.",
      "otherNotes" : "The issue is about improving the USB plugin with more artefacts, specifically exploring evtx parsing capabilities. It requires renaming the current class/functions to `usb_regf` and creating a new `usb_evtx` function/class, and moving the plugin to the `windows/` folder.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284441
  }, {
    "issueDTO" : {
      "id" : 3221163134,
      "title" : "[Bug]: Fix Dark Theme Visibility Issues in Admin UI",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/366",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "# Fix Dark Theme Visibility Issues in Admin UI\n\n**Priority:** Medium (User Experience)\n\n**Description:**\nThe MCP Gateway Admin UI has visibility issues in dark theme mode, particularly with form input fields for tools. Input boxes are difficult to see against the dark background, making the interface challenging to use for users who prefer dark mode.\n\n**Reported Issues:**\n- Input boxes for tools are hard to see on dark theme\n- Insufficient contrast between input fields and background\n- Form elements may be using colors that don't adapt properly to dark mode\n\n**Steps to Reproduce:**\n1. Access the Admin UI at http://localhost:4444/admin/\n2. Switch to dark theme (if not already)\n3. Navigate to the Tools section\n4. Try to create or edit a tool\n5. Notice that input fields are difficult to see\n\n**Expected Behavior:**\n- All form inputs should have clear borders and sufficient contrast\n- Text should be clearly readable in input fields\n- Focus states should be visible\n- Placeholder text should have appropriate contrast\n- All UI elements should be usable in both light and dark themes\n\n**Investigation Needed:**\n1. Identify which CSS classes are affecting input visibility\n2. Check if using CSS variables for theme colors\n3. Verify dark mode implementation approach\n4. Test across different browsers\n\n**Suggested Fix:**\n\n1. **Update CSS for better dark mode support**:\n```css\n/* Add to admin UI CSS */\n:root {\n  /* Light theme variables */\n  --input-bg: #ffffff;\n  --input-border: #d1d5db;\n  --input-text: #111827;\n  --input-placeholder: #6b7280;\n  --input-focus-border: #3b82f6;\n  --input-focus-ring: rgba(59, 130, 246, 0.1);\n}\n\n[data-theme=\"dark\"] {\n  /* Dark theme variables */\n  --input-bg: #1f2937;\n  --input-border: #4b5563;\n  --input-text: #f9fafb;\n  --input-placeholder: #9ca3af;\n  --input-focus-border: #60a5fa;\n  --input-focus-ring: rgba(96, 165, 250, 0.2);\n}\n\n/* Input styling using variables */\ninput[type=\"text\"],\ninput[type=\"url\"],\ninput[type=\"email\"],\ntextarea,\nselect {\n  background-color: var(--input-bg);\n  border: 1px solid var(--input-border);\n  color: var(--input-text);\n  padding: 0.5rem 0.75rem;\n  border-radius: 0.375rem;\n  transition: all 0.2s ease;\n}\n\ninput::placeholder,\ntextarea::placeholder {\n  color: var(--input-placeholder);\n  opacity: 1;\n}\n\ninput:focus,\ntextarea:focus,\nselect:focus {\n  outline: none;\n  border-color: var(--input-focus-border);\n  box-shadow: 0 0 0 3px var(--input-focus-ring);\n}\n\n/* Ensure labels are visible */\nlabel {\n  color: var(--input-text);\n  font-weight: 500;\n  margin-bottom: 0.25rem;\n  display: block;\n}\n\n/* Form group spacing */\n.form-group {\n  margin-bottom: 1rem;\n}\n\n/* Error states */\ninput.error,\ntextarea.error {\n  border-color: #ef4444;\n}\n\n[data-theme=\"dark\"] input.error,\n[data-theme=\"dark\"] textarea.error {\n  border-color: #f87171;\n}\n```\n\n2. **If using Tailwind CSS, ensure dark mode classes are applied**:\n```html\n<!-- Example input with Tailwind dark mode support -->\n<input \n  type=\"text\" \n  class=\"w-full px-3 py-2 \n         bg-white dark:bg-gray-800 \n         border border-gray-300 dark:border-gray-600 \n         text-gray-900 dark:text-gray-100\n         placeholder-gray-500 dark:placeholder-gray-400\n         focus:ring-2 focus:ring-blue-500 dark:focus:ring-blue-400\n         focus:border-transparent\n         rounded-md\"\n  placeholder=\"Enter tool name\"\n>\n```\n\n3. **Add accessibility improvements**:\n```css\n/* Increase contrast for better accessibility */\n@media (prefers-contrast: high) {\n  [data-theme=\"dark\"] {\n    --input-border: #6b7280;\n    --input-focus-border: #93c5fd;\n  }\n}\n\n/* Respect user's motion preferences */\n@media (prefers-reduced-motion: reduce) {\n  input, textarea, select {\n    transition: none;\n  }\n}\n```\n\n4. **Add visual feedback for different states**:\n```css\n/* Hover state */\ninput:hover:not(:focus),\ntextarea:hover:not(:focus) {\n  border-color: var(--input-focus-border);\n  opacity: 0.8;\n}\n\n/* Disabled state */\ninput:disabled,\ntextarea:disabled {\n  opacity: 0.5;\n  cursor: not-allowed;\n  background-color: var(--input-bg);\n}\n```\n\n**Testing Checklist:**\n- [ ] Test all form inputs in dark mode\n- [ ] Verify contrast ratios meet WCAG AA standards\n- [ ] Test with browser's built-in dark mode\n- [ ] Check focus states are clearly visible\n- [ ] Test on different browsers (Chrome, Firefox, Safari)\n- [ ] Verify no CSS conflicts with existing styles\n- [ ] Test responsive behavior on mobile devices\n\n**Additional Improvements:**\n1. Add theme toggle animation\n2. Persist theme preference in localStorage\n3. Respect system theme preference by default\n4. Add high contrast mode option\n\n**Browser Testing Matrix:**\n| Browser | Light Theme | Dark Theme | Notes |\n|---------|------------|------------|-------|\n| Chrome  | ???          | ???          |       |\n| Firefox | ???          | ???          |       |\n| Safari  | ???          | ???          |       |\n| Edge    | ???          | ???          |       |\n\n**Acceptance Criteria:**\n- [ ] All input fields clearly visible in dark mode\n- [ ] Sufficient contrast between text and background\n- [ ] Focus states clearly visible\n- [ ] No accessibility issues reported by tools\n- [ ] Consistent appearance across browsers\n- [ ] Theme switching works smoothly\n\n**Related UI Issues:**\n- Check if other form elements (buttons, checkboxes, radios) need dark mode fixes\n- Review modal/dialog dark mode styling\n- Ensure syntax highlighting in code blocks works in dark mode\n- Check if charts/graphs are visible in dark mode",
      "updatedAt" : 1752226910.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "bug", "help wanted", "good first issue", "triage", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the dark theme visibility issues in the Admin UI, particularly with form input fields for tools, to ensure a better user experience for users who prefer dark mode.",
      "validationOrRequirement" : "The validation or requirement is to ensure that all form inputs have clear borders and sufficient contrast, text is clearly readable in input fields, focus states are visible, placeholder text has appropriate contrast, and all UI elements are usable in both light and dark themes. The acceptance criteria includes all input fields clearly visible in dark mode, sufficient contrast between text and background, focus states clearly visible, no accessibility issues reported by tools, consistent appearance across browsers, and theme switching works smoothly.",
      "attemptedFixes" : "The suggested fixes include updating CSS for better dark mode support, ensuring dark mode classes are applied using Tailwind CSS, adding accessibility improvements, and adding visual feedback for different states. The investigation needed includes identifying which CSS classes are affecting input visibility, checking if using CSS variables for theme colors, verifying dark mode implementation approach, and testing across different browsers.",
      "otherNotes" : "The issue is about fixing the dark theme visibility issues in the Admin UI, specifically with form input fields for tools. The input boxes are difficult to see against the dark background, making the interface challenging to use for users who prefer dark mode.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284450
  }, {
    "issueDTO" : {
      "id" : 3221162126,
      "title" : "[CHORE]: Fix Database Migration Commands in Makefile",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/365",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "# Fix Database Migration Commands in Makefile\n\n**Priority:** Medium (Development/Operations)\n\n**Description:**\nThe `make db-current` command fails with \"No 'script_location' key found in configuration\" because it's not passing the correct path to the alembic configuration file. This affects developers' ability to check migration status and manage database schema changes.\n\n**Current Issue:**\n```bash\n$ make db-current\nalembic current\nFAILED: No 'script_location' key found in configuration.\n```\n\n**Root Cause:**\nThe Makefile is running `alembic current` without specifying the configuration file path. Alembic needs the `-c` flag to locate the configuration file at `mcpgateway/alembic.ini`.\n\n**Expected Behavior:**\n- All database migration commands should work from the project root\n- Commands should find the alembic configuration automatically\n- Clear output showing current migration status\n\n**Current Working Workaround:**\n```bash\nalembic -c mcpgateway/alembic.ini current\n# Output: e75490e949b1 (head)\n```\n\n**Suggested Fix:**\n\nUpdate the Makefile database commands:\n\n```makefile\n# Database migration commands\nALEMBIC_CONFIG = mcpgateway/alembic.ini\n\n.PHONY: db-init\ndb-init: ## Initialize alembic migrations\n\t@echo \"\uD83D\uDDC4??? Initializing database migrations...\"\n\talembic -c $(ALEMBIC_CONFIG) init alembic\n\n.PHONY: db-migrate\ndb-migrate: ## Create a new migration\n\t@echo \"\uD83D\uDDC4??? Creating new migration...\"\n\t@read -p \"Enter migration message: \" msg; \\\n\talembic -c $(ALEMBIC_CONFIG) revision --autogenerate -m \"$$msg\"\n\n.PHONY: db-upgrade\ndb-upgrade: ## Upgrade database to latest migration\n\t@echo \"\uD83D\uDDC4??? Upgrading database...\"\n\talembic -c $(ALEMBIC_CONFIG) upgrade head\n\n.PHONY: db-downgrade\ndb-downgrade: ## Downgrade database by one revision\n\t@echo \"\uD83D\uDDC4??? Downgrading database...\"\n\talembic -c $(ALEMBIC_CONFIG) downgrade -1\n\n.PHONY: db-current\ndb-current: ## Show current database revision\n\t@echo \"\uD83D\uDDC4??? Current database revision:\"\n\t@alembic -c $(ALEMBIC_CONFIG) current\n\n.PHONY: db-history\ndb-history: ## Show migration history\n\t@echo \"\uD83D\uDDC4??? Migration history:\"\n\t@alembic -c $(ALEMBIC_CONFIG) history\n\n.PHONY: db-heads\ndb-heads: ## Show available heads\n\t@echo \"\uD83D\uDDC4??? Available heads:\"\n\t@alembic -c $(ALEMBIC_CONFIG) heads\n\n.PHONY: db-show\ndb-show: ## Show a specific revision\n\t@read -p \"Enter revision ID: \" rev; \\\n\talembic -c $(ALEMBIC_CONFIG) show $$rev\n\n.PHONY: db-stamp\ndb-stamp: ## Stamp database with a specific revision\n\t@read -p \"Enter revision to stamp: \" rev; \\\n\talembic -c $(ALEMBIC_CONFIG) stamp $$rev\n\n.PHONY: db-reset\ndb-reset: ## Reset database (CAUTION: drops all data)\n\t@echo \"??????  WARNING: This will drop all data!\"\n\t@read -p \"Are you sure? (y/N): \" confirm; \\\n\tif [ \"$$confirm\" = \"y\" ]; then \\\n\t\talembic -c $(ALEMBIC_CONFIG) downgrade base && \\\n\t\talembic -c $(ALEMBIC_CONFIG) upgrade head; \\\n\t\techo \"??? Database reset complete\"; \\\n\telse \\\n\t\techo \"??? Database reset cancelled\"; \\\n\tfi\n```\n\n**Additional Improvements:**\n\n1. **Add database status check**:\n```makefile\n.PHONY: db-status\ndb-status: ## Show detailed database status\n\t@echo \"\uD83D\uDDC4??? Database Status:\"\n\t@echo \"Current revision:\"\n\t@alembic -c $(ALEMBIC_CONFIG) current\n\t@echo \"\"\n\t@echo \"Pending migrations:\"\n\t@alembic -c $(ALEMBIC_CONFIG) history -r current:head\n```\n\n2. **Add migration validation**:\n```makefile\n.PHONY: db-check\ndb-check: ## Check if migrations are up to date\n\t@echo \"\uD83D\uDDC4??? Checking migration status...\"\n\t@if alembic -c $(ALEMBIC_CONFIG) current | grep -q \"(head)\"; then \\\n\t\techo \"??? Database is up to date\"; \\\n\telse \\\n\t\techo \"??????  Database needs migration\"; \\\n\t\techo \"Run 'make db-upgrade' to apply pending migrations\"; \\\n\t\texit 1; \\\n\tfi\n```\n\n3. **Add helper for common issues**:\n```makefile\n.PHONY: db-fix-head\ndb-fix-head: ## Fix multiple heads issue\n\t@echo \"\uD83D\uDDC4??? Fixing multiple heads...\"\n\talembic -c $(ALEMBIC_CONFIG) merge -m \"merge heads\"\n```\n\n**Testing Requirements:**\n- Verify all db-* commands work from project root\n- Test with both SQLite and PostgreSQL databases\n- Ensure commands handle missing database gracefully\n- Test migration creation and application\n- Verify rollback functionality\n\n**Documentation Update:**\nAdd to README.md:\n```markdown\n## Database Management\n\nMCP Gateway uses Alembic for database migrations. Common commands:\n\n- `make db-current` - Show current database version\n- `make db-upgrade` - Apply pending migrations\n- `make db-migrate` - Create new migration\n- `make db-history` - Show migration history\n- `make db-status` - Detailed migration status\n\n### Troubleshooting\n\nIf you see \"No 'script_location' key found\", ensure you're running from the project root directory.\n```\n\n**Benefits:**\n- Consistent database management workflow\n- No need to remember alembic command syntax\n- Safer operations with confirmations\n- Better error messages and status reporting\n\n**Acceptance Criteria:**\n- [ ] All db-* commands work without errors\n- [ ] Commands work from project root directory\n- [ ] Clear output messages for all operations\n- [ ] Dangerous operations have confirmations\n- [ ] Help text (`make help`) shows all db commands\n- [ ] Migration status is easy to understand\n\n**Related Issues:**\n- Consider adding automatic migration on startup (configurable)\n- May need PostgreSQL-specific commands\n- Consider adding database backup/restore commands",
      "updatedAt" : 1752226853.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "devops", "help wanted", "cicd", "chore", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the Makefile database commands in the Makefile to correctly pass the configuration file path to alembic, and to ensure that all database migration commands work from the project root directory.",
      "validationOrRequirement" : "The issue requires validation of the Makefile database commands to ensure they work correctly from the project root directory, and that they handle missing database gracefully.",
      "attemptedFixes" : "The Makefile has been updated with the correct configuration file path, and the commands have been updated to use the `-c` flag to locate the configuration file at `mcpgateway/alembic.ini`.",
      "otherNotes" : "The issue is related to the Makefile database commands not passing the correct path to the alembic configuration file, which affects developers' ability to check migration status and manage database schema changes.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284456
  }, {
    "issueDTO" : {
      "id" : 3221150816,
      "title" : "[CHORE]: Improve Error Messages - Replace Raw Technical Errors with User-Friendly Messages",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/363",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "**Priority:** Medium (User Experience)\n\n**Description:**\nThe MCP Gateway API returns raw technical error messages (Pydantic validation errors, SQL exceptions) directly to users. These messages are verbose, confusing for end users, and potentially expose implementation details. All error responses should be transformed into clear, actionable user messages.\n\nSee also: #357 \n\n**Current Issues:**\n\n1. **Pydantic Validation Errors** - Too verbose and technical:\n   ```json\n   {\n     \"message\": \"1 validation error for ToolCreate\\nname\\n  Value error, Tool name must start with a letter and contain only letters, numbers, and underscore [type=value_error, input_value='<script>alert(1)</script>', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error\",\n     \"success\": false\n   }\n   ```\n\n2. **SQL Errors** - Expose database schema:\n   ```json\n   {\n     \"message\": \"(sqlite3.IntegrityError) UNIQUE constraint failed: gateways.url\\n[SQL: INSERT INTO gateways...]\",\n     \"success\": false\n   }\n   ```\n\n3. **Generic Internal Errors** - Not helpful:\n   ```\n   Internal Server Error\n   ```\n\n**Expected Behavior:**\n- Validation errors should be concise and actionable\n- Database errors should not expose schema details\n- All errors should follow a consistent format\n- Technical details should only appear in logs, not responses\n\n**Suggested Implementation:**\n\n1. **Create a centralized error transformer**:\n   ```python\n   # mcpgateway/utils/error_formatter.py\n   from typing import Dict, Any, List\n   from pydantic import ValidationError\n   from sqlalchemy.exc import IntegrityError, DatabaseError\n   import logging\n   \n   logger = logging.getLogger(__name__)\n   \n   class ErrorFormatter:\n       \"\"\"Transform technical errors into user-friendly messages\"\"\"\n       \n       @staticmethod\n       def format_validation_error(error: ValidationError) -> Dict[str, Any]:\n           \"\"\"Convert Pydantic errors to user-friendly format\"\"\"\n           errors = []\n           \n           for err in error.errors():\n               field = err.get('loc', ['field'])[-1]\n               msg = err.get('msg', 'Invalid value')\n               \n               # Map technical messages to user-friendly ones\n               user_message = ErrorFormatter._get_user_message(field, msg)\n               errors.append({\n                   \"field\": field,\n                   \"message\": user_message\n               })\n           \n           # Log the full error for debugging\n           logger.debug(f\"Validation error: {error}\")\n           \n           return {\n               \"error\": \"Validation failed\",\n               \"details\": errors,\n               \"success\": false\n           }\n       \n       @staticmethod\n       def _get_user_message(field: str, technical_msg: str) -> str:\n           \"\"\"Map technical validation messages to user-friendly ones\"\"\"\n           mappings = {\n               \"Tool name must start with a letter\": f\"{field.title()} must start with a letter and contain only letters, numbers, and underscores\",\n               \"Tool name exceeds maximum length\": f\"{field.title()} is too long (maximum 255 characters)\",\n               \"Tool URL must start with\": f\"{field.title()} must be a valid HTTP or WebSocket URL\",\n               \"cannot contain directory traversal\": f\"{field.title()} contains invalid characters\",\n               \"contains HTML tags\": f\"{field.title()} cannot contain HTML or script tags\",\n           }\n           \n           for pattern, friendly_msg in mappings.items():\n               if pattern in technical_msg:\n                   return friendly_msg\n           \n           # Default fallback\n           return f\"Invalid {field}\"\n       \n       @staticmethod\n       def format_database_error(error: DatabaseError) -> Dict[str, Any]:\n           \"\"\"Convert database errors to user-friendly format\"\"\"\n           error_str = str(error.orig) if hasattr(error, 'orig') else str(error)\n           \n           # Log full error\n           logger.error(f\"Database error: {error}\")\n           \n           # Map common database errors\n           if isinstance(error, IntegrityError):\n               if \"UNIQUE constraint failed\" in error_str:\n                   if \"gateways.url\" in error_str:\n                       return {\"error\": \"A gateway with this URL already exists\", \"success\": false}\n                   elif \"gateways.name\" in error_str:\n                       return {\"error\": \"A gateway with this name already exists\", \"success\": false}\n                   elif \"tools.name\" in error_str:\n                       return {\"error\": \"A tool with this name already exists\", \"success\": false}\n                   elif \"resources.uri\" in error_str:\n                       return {\"error\": \"A resource with this URI already exists\", \"success\": false}\n               elif \"FOREIGN KEY constraint failed\" in error_str:\n                   return {\"error\": \"Referenced item not found\", \"success\": false}\n               elif \"NOT NULL constraint failed\" in error_str:\n                   return {\"error\": \"Required field is missing\", \"success\": false}\n           \n           # Generic database error\n           return {\"error\": \"Unable to complete the operation. Please try again.\", \"success\": false}\n   ```\n\n2. **Apply formatter in exception handlers**:\n   ```python\n   # In route handlers\n   from mcpgateway.utils.error_formatter import ErrorFormatter\n   \n   @router.post(\"/admin/tools\")\n   async def create_tool(tool_data: ToolCreate):\n       try:\n           # ... tool creation logic\n       except ValidationError as e:\n           return JSONResponse(\n               status_code=422,\n               content=ErrorFormatter.format_validation_error(e)\n           )\n       except IntegrityError as e:\n           return JSONResponse(\n               status_code=409,\n               content=ErrorFormatter.format_database_error(e)\n           )\n       except Exception as e:\n           logger.exception(\"Unexpected error creating tool\")\n           return JSONResponse(\n               status_code=500,\n               content={\"error\": \"An unexpected error occurred\", \"success\": false}\n           )\n   ```\n\n3. **Create global exception handler**:\n   ```python\n   # In main.py\n   @app.exception_handler(ValidationError)\n   async def validation_exception_handler(request: Request, exc: ValidationError):\n       return JSONResponse(\n           status_code=422,\n           content=ErrorFormatter.format_validation_error(exc)\n       )\n   \n   @app.exception_handler(IntegrityError)\n   async def database_exception_handler(request: Request, exc: IntegrityError):\n       return JSONResponse(\n           status_code=409,\n           content=ErrorFormatter.format_database_error(exc)\n       )\n   ```\n\n**Error Response Format:**\n```json\n{\n  \"error\": \"Brief description of what went wrong\",\n  \"details\": [\n    {\n      \"field\": \"name\",\n      \"message\": \"Name must start with a letter\"\n    }\n  ],\n  \"success\": false\n}\n```\n\n**Benefits:**\n- Consistent error format across all endpoints\n- No technical implementation details exposed\n- Clear, actionable messages for users\n- Full error details still available in logs\n- Improved security posture\n\n**Testing Requirements:**\n- Verify all Pydantic validation errors are transformed\n- Test all database constraint violations\n- Ensure error logs contain full technical details\n- Confirm no SQL or schema information in responses\n- Test error messages are actually helpful to users\n\n**Acceptance Criteria:**\n- [ ] No raw Pydantic errors in API responses\n- [ ] No SQL errors or schema details in API responses\n- [ ] All errors follow consistent JSON format\n- [ ] Error messages are clear and actionable\n- [ ] Technical details are logged but not exposed\n- [ ] HTTP status codes are appropriate (422 for validation, 409 for conflicts, etc.)\n\n**Related Issues:**\n- #339 (Admin API validation)\n- #340 (Non-admin API validation)\n- SQL error exposure security issue",
      "updatedAt" : 1752226829.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "bug", "help wanted", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ "I will work on this" ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to improve the error handling in the MCP Gateway API by transforming technical errors into clear, actionable user messages and ensuring that technical details are not exposed to users.",
      "validationOrRequirement" : "The issue requires the error transformer to map technical messages to user-friendly ones, log full error for debugging, and ensure consistency in error responses.",
      "attemptedFixes" : "Create a centralized error transformer, apply formatter in exception handlers, and create a global exception handler to transform technical errors into user-friendly messages.",
      "otherNotes" : "The issue aims to improve error messages in the MCP Gateway API by replacing raw technical errors with user-friendly messages, ensuring consistency, security, and user experience.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284461
  }, {
    "issueDTO" : {
      "id" : 3222266403,
      "title" : "Add further information to annotations",
      "url" : "https://github.com/Dorset-Council-UK/GIFramework-Maps/issues/360",
      "repositoryName" : "Dorset-Council-UK/GIFramework-Maps",
      "description" : "User request to see the coordinates of their annotations when they click on them.\n\nWe could enhance this to show more general information depending on the type of object\n\n- Point: Show coordinates\n- Line: Show length\n- Polygon: Show area/permimeter\n- Buffer/Circle: Show centre coordinates and radius\n- Text: Show centre coordinates and text?\n",
      "updatedAt" : 1752226785.000000000,
      "user" : "RobQuincey-DC",
      "userHtmlUrl" : "https://github.com/RobQuincey-DC",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/109682469?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A .NET based web map built with OpenLayers and Bootstrap",
        "homepage" : "",
        "name" : "GIFramework-Maps",
        "fullName" : "Dorset-Council-UK/GIFramework-Maps",
        "htmlUrl" : "https://github.com/Dorset-Council-UK/GIFramework-Maps",
        "gitUrl" : "git://github.com/Dorset-Council-UK/GIFramework-Maps.git",
        "sshUrl" : "git@github.com:Dorset-Council-UK/GIFramework-Maps.git",
        "cloneUrl" : "https://github.com/Dorset-Council-UK/GIFramework-Maps.git",
        "owner" : {
          "login" : "Dorset-Council-UK",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 16,
        "watchersCount" : 16,
        "size" : 3996,
        "openIssuesCount" : 34,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-07T10:24:09Z",
        "languages" : {
          "TypeScript" : 762749,
          "C#" : 692865,
          "CSS" : 29716,
          "JavaScript" : 3494,
          "HTML" : 339653
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add further information to annotations, specifically showing coordinates, length, area/permimeter, centre coordinates and radius, or centre coordinates and text, depending on the type of object.",
      "validationOrRequirement" : "The issue requires enhancements to the annotation system and is marked as a good first issue, suggesting it's suitable for new contributors.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue aims to provide additional information to annotations, specifically showing coordinates, length, area/permimeter, centre coordinates and radius, or centre coordinates and text, depending on the type of object.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284466
  }, {
    "issueDTO" : {
      "id" : 3221170131,
      "title" : "Navbar in mobile view has broken navbar position when on the list tab",
      "url" : "https://github.com/louislam/uptime-kuma/issues/5977",
      "repositoryName" : "louislam/uptime-kuma",
      "description" : "### \uD83D\uDCD1 I have found these related issues/pull requests\n\nnone \n\n### \uD83D\uDEE1??? Security Policy\n\n- [x] I have read and agree to Uptime Kuma's [Security Policy](https://github.com/louislam/uptime-kuma/security/policy).\n\n\n### \uD83D\uDCDD Description\n\nThe following piece of html in the app causes the navbar to go out of sight in (at least) Chrome and Firefox. \n\nfilter-dropdown-menu is pre-rendered to go out of bounds for labels. \n\nIt seems the dropdown pushes into overflow with labels that are too long.(?) \nIt doesn't seem to maintain a margin from the right of the viewport.\n\n<img width=\"504\" height=\"861\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/822ca95d-77e0-421d-828c-8cd77542b76e\" />\n\nhttps://github.com/user-attachments/assets/e66f2a56-976f-4748-9752-3b9ba789d282\n\nThis only happens when the labels get to big. I tried reproducing but couldn't figure why it didn't happen in an old instance (Docker) untill I added the label: Local IP Address to make 4 labels total and gave the label a long name.\n\n<img width=\"493\" height=\"288\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e4c71b70-f04e-42f0-8c7a-b9bd0ee22d48\" />\n\n\n\n\n### \uD83D\uDC5F Reproduction steps\n\nOpen Uptime Kuma on a mobile device (or with small enough resolution in Chrome with devtools open).\n\n### \uD83D\uDC40 Expected behavior\n\nThe lists tab should not move down the navbar and cause overflow issues.\n\n### \uD83D\uDE13 Actual Behavior\n\nThe lists tab does cause the navbar to move down and causes overflow issues.\n\n### \uD83D\uDC3B Uptime-Kuma Version\n\n1.23.16\n\n### \uD83D\uDCBB Operating System and Arch\n\nLXC (Proxmox via Community Scripts) and also a LXC with Docker containing this container\n\n### \uD83C\uDF10 Browser\n\nShows in Chrome and Firefox (latest)\n\n### \uD83D\uDDA5??? Deployment Environment\n\nn/a\n\n### \uD83D\uDCDD Relevant log output\n\n```bash session\n\n`````",
      "updatedAt" : 1752226641.000000000,
      "user" : "VNRARA",
      "userHtmlUrl" : "https://github.com/VNRARA",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3942672?v=4",
      "labels" : [ "bug", "A:ui/ux", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Nice work debugging this! It looks like a fairly straightforward fix ??? would you be open to opening a PR for it?", "Hey, I don't know this code/lang. I've tried to look for it, but I've gotten as far as devtools and some basic HTML debugging. Could you point me in the right direction? \n\nThis is where I've been trying to find something: src/components/MonitorListFilterDropdown.vue\n\nI'll try and find it and do the PR.\n\nEDIT: seems like whatever I'm doing in devtools causes the dropdown menu to just get totally out of place. ", "I've got something I forked and changed. But I can't seem to figure out how to get my test on dockerhub or in docker for now... I'll try again later when I wake up again.", "You can just open an pull request and then use https://github.com/louislam/uptime-kuma/wiki/Test-Pull-Requests\n\nFor development the setup is slightly simpler." ],
      "repository" : {
        "description" : "A fancy self-hosted monitoring tool",
        "homepage" : "https://uptime.kuma.pet",
        "name" : "uptime-kuma",
        "fullName" : "louislam/uptime-kuma",
        "htmlUrl" : "https://github.com/louislam/uptime-kuma",
        "gitUrl" : "git://github.com/louislam/uptime-kuma.git",
        "sshUrl" : "git@github.com:louislam/uptime-kuma.git",
        "cloneUrl" : "https://github.com/louislam/uptime-kuma.git",
        "owner" : {
          "login" : "louislam",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 6354,
        "stargazersCount" : 71779,
        "watchersCount" : 71779,
        "size" : 29555,
        "openIssuesCount" : 777,
        "subscribersCount" : 294,
        "pushedAt" : "2025-07-11T21:41:44Z",
        "languages" : {
          "C#" : 557,
          "PowerShell" : 387,
          "Java" : 908,
          "Vue" : 729299,
          "Go" : 2699,
          "HTML" : 1102,
          "TypeScript" : 23073,
          "Dockerfile" : 4408,
          "Shell" : 2058,
          "SCSS" : 15559,
          "JavaScript" : 945636,
          "PHP" : 322,
          "Python" : 216
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the navbar position in mobile view when on the list tab, as it is currently broken due to the 'filter-dropdown-menu' causing the navbar to go out of sight.",
      "validationOrRequirement" : "The issue is related to the 'filter-dropdown-menu' in the app, which causes the navbar to go out of sight in Chrome and Firefox. The dropdown pushes into overflow with labels that are too long.",
      "attemptedFixes" : "The author tried reproducing the issue but couldn't figure why it didn't happen in an old instance (Docker) until they added a label with a long name.",
      "otherNotes" : "The issue is specific to mobile view, and the navbar position is broken when on the list tab. The related images show the issue in Chrome and Firefox. The labels are too long, causing the dropdown to push into overflow and not maintain a margin from the right of the viewport.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284472
  }, {
    "issueDTO" : {
      "id" : 1471060240,
      "title" : "Improve usage of proto3's `optional`",
      "url" : "https://github.com/clouditor/clouditor/issues/885",
      "repositoryName" : "clouditor/clouditor",
      "description" : "1) I guess it is not used everywhere, e.g. in https://github.com/clouditor/clouditor/blob/ce3852eafda3166533ce4acb3572bb62b245423f/api/orchestrator/orchestrator.proto#L509-L511\r\n\r\n2) It is not documented everywhere with comments (which will be then generated and helpful for OpenAPI clients), e.g.\r\nhttps://github.com/clouditor/clouditor/blob/ce3852eafda3166533ce4acb3572bb62b245423f/api/orchestrator/orchestrator.proto#L597-L601\r\n\r\n3) Also I guess, we should then use the generated methods which do pointer dereferencing (with nil checking).",
      "updatedAt" : 1752226308.000000000,
      "user" : "lebogg",
      "userHtmlUrl" : "https://github.com/lebogg",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/40119051?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The Clouditor is a tool to support continuous cloud assurance. Developed by Fraunhofer AISEC.",
        "homepage" : "https://clouditor.io",
        "name" : "clouditor",
        "fullName" : "clouditor/clouditor",
        "htmlUrl" : "https://github.com/clouditor/clouditor",
        "gitUrl" : "git://github.com/clouditor/clouditor.git",
        "sshUrl" : "git@github.com:clouditor/clouditor.git",
        "cloneUrl" : "https://github.com/clouditor/clouditor.git",
        "owner" : {
          "login" : "clouditor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 78,
        "watchersCount" : 78,
        "size" : 27769,
        "openIssuesCount" : 96,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:23:36Z",
        "languages" : {
          "Dockerfile" : 1153,
          "Shell" : 811,
          "Open Policy Agent" : 25548,
          "Go" : 1923616
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve usage of proto3's `optional` in the clouditor/clouditor repository",
      "validationOrRequirement" : "Improving usage of proto3's `optional`, utilizing it everywhere, documenting its usage with comments, and using generated methods with nil checking",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is about improving usage of proto3's `optional` in the clouditor/clouditor repository, specifically highlighting its underutilization, lack of documentation, and potential pointer dereferencing issues.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284476
  }, {
    "issueDTO" : {
      "id" : 1555696925,
      "title" : "Provide a proper installation guide",
      "url" : "https://github.com/clouditor/clouditor/issues/932",
      "repositoryName" : "clouditor/clouditor",
      "description" : "Maybe for different scenarios (all-in-on binary, micro-services)",
      "updatedAt" : 1752226189.000000000,
      "user" : "oxisto",
      "userHtmlUrl" : "https://github.com/oxisto",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12459061?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The Clouditor is a tool to support continuous cloud assurance. Developed by Fraunhofer AISEC.",
        "homepage" : "https://clouditor.io",
        "name" : "clouditor",
        "fullName" : "clouditor/clouditor",
        "htmlUrl" : "https://github.com/clouditor/clouditor",
        "gitUrl" : "git://github.com/clouditor/clouditor.git",
        "sshUrl" : "git@github.com:clouditor/clouditor.git",
        "cloneUrl" : "https://github.com/clouditor/clouditor.git",
        "owner" : {
          "login" : "clouditor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 78,
        "watchersCount" : 78,
        "size" : 27769,
        "openIssuesCount" : 96,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:23:36Z",
        "languages" : {
          "Dockerfile" : 1153,
          "Shell" : 811,
          "Open Policy Agent" : 25548,
          "Go" : 1923616
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to provide a proper installation guide for the clouditor project.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the issue description or comments.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description or comments.",
      "otherNotes" : "The issue description mentions providing a proper installation guide for different scenarios, including all-in-one binary and micro-services.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284479
  }, {
    "issueDTO" : {
      "id" : 2913319325,
      "title" : "[DSL] Support incremental K-Core algorithm",
      "url" : "https://github.com/TuGraph-family/tugraph-analytics/issues/466",
      "repositoryName" : "TuGraph-family/tugraph-analytics",
      "description" : "Support incremental K-Core algorithm",
      "updatedAt" : 1752226152.000000000,
      "user" : "dukewy123",
      "userHtmlUrl" : "https://github.com/dukewy123",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135831500?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "1. ????????????\n\n1.1 ??????K-Core????????????\n??????????????????????????????K-Core???????????????vertex-centric????????????  ???K-Core?????????????????????DSL??????????????????????????????SQL???????????? ???\n\n1.2 ?????????????????????\n????????????????????????????????????GeaFlowAlgorithmDynamicRuntimeContext???????????????????????????????????? ??????????????????????????????????????????????????????\n\n2. ??????K-Core????????????\n\n2.1 ??????????????????\n\n??????K-Core????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n\n1. ???????????????????????????????????????????????????/?????????????????????\n2. ??????????????????????????????????????????K-Core??????????????????\n3. ????????????????????????????????????????????????????????????K-Core?????????\n4. ?????????????????????????????????????????????????????????\n  \n2.2 ??????????????????\n\n```mermaid\nflowchart TD\n    A[\"???????????????\"] --> B[\"????????????\"]\n    B --> C[\"???????????????\"]\n    C --> D[\"??????K-Core??????\"]\n    D --> E[\"????????????\"]\n    E --> F[\"??????????????????\"]\n    \n    subgraph \"??????K-Core????????????\"\n        G[\"??????????????????\"]\n        H[\"??????????????????\"] \n        I[\"K-Core?????????\"]\n    end\n```\n2.3 ??????????????????\n\n?????????????????????????????????\n- ??????K-Core???????????????????????????????????????K-Core???\n- ????????????????????????????????????????????????\n- ???????????????????????????????????????????????????\n- ??????????????????????????????????????????????????????\n  \n3. ??????????????????\n\n3.1 ??????K-Core???????????????\n\n??????????????????K-Core????????????????????????????????????????????????????????????????????????AlgorithmRuntimeContext??????????????????????????????  ??????????????????????????????????????????\n\n3.2 DSL????????????\n\n???BuildInSqlFunctionTable?????????????????????K-Core?????? ?????????????????????SQL???????????????\n\n3.3 ????????????????????????\n\n??????????????????????????????????????????  ????????????\n- loadDynamicEdges(): ?????????????????????\n- loadStaticEdges(): ???????????????????????????\n- ?????????????????????????????????\n  \n3.4 ???????????????\n\n????????????????????????????????????  ????????????????????????????????????\n\n4. ??????????????????\n\n4.1 ???????????????\n1. ????????????????????????\n2. ????????????K-Core???\n3. ????????????????????????\n  \n4.2 ??????????????????\n1. ??????????????????????????????/?????????????????????\n2. ??????????????????????????????\n3. ??????????????????????????????K-Core?????????\n4. ?????????????????????????????????\n  \n4.3 ??????????????????\n??????vertex-centric??????????????????????????? [7](#0-6) ????????????????????????????????????????????????\n\n5. SQL????????????\n\n??????K-Core?????????SQL???????????????\n\n-- ??????K-Core??????????????????\nCALL incremental_kcore(k_value, window_id) \nYIELD (vid, old_core_id, new_core_id, change_type)\nRETURN vid, old_core_id, new_core_id, change_type;\n\n6. ????????????\n\n???????????????K-Core????????????  ???????????????K-Core??????????????????????????????????????????????????????\n\n7. ??????????????????\n\n7.1 ??????????????????\n?????????????????????????????????????????????????????????????????????????????????????????????????????? [8](#0-7) ???\n\n7.2 ???????????????\n????????????????????????????????????????????????????????????????????????\n\n7.3 ????????????\n?????????????????????????????????????????????????????????\n\n## ????????????\n\n1. ??????????????????????????????\n\n```\npackage com.antgroup.geaflow.dsl.common.algo;\n\nimport com.antgroup.geaflow.dsl.common.data.Row;\nimport com.antgroup.geaflow.dsl.common.data.RowVertex;\nimport com.antgroup.geaflow.dsl.common.types.GraphSchema;\nimport com.antgroup.geaflow.dsl.common.types.StructType;\nimport java.io.Serializable;\nimport java.util.Iterator;\nimport java.util.Optional;\n\n/**\n * Interface for incremental graph algorithms that can handle dynamic graph updates.\n * @param <K> The id type for vertex.\n * @param <M> The message type for message send between vertices.\n */\npublic interface IncrementalAlgorithmUserFunction<K, M> extends Serializable {\n\n    /**\n     * Init method for the function\n     * @param context The runtime context.\n     * @param params  The parameters for the function.\n     */\n    void init(AlgorithmRuntimeContext<K, M> context, Object[] params);\n\n    /**\n     * Processing method for each vertex and the messages it received.\n     * This method handles both initial computation and incremental updates.\n     * @param vertex The current vertex being processed.\n     * @param updatedValues Optional updated vertex values from previous iterations.\n     * @param messages Iterator of messages received from other vertices.\n     */\n    void process(RowVertex vertex, Optional<Row> updatedValues, Iterator<M> messages);\n\n    /**\n     * Finish method called at the end of each iteration for each vertex.\n     * @param vertex The current vertex.\n     * @param updatedValues Optional updated vertex values.\n     */\n    void finish(RowVertex vertex, Optional<Row> updatedValues);\n\n    /**\n     * Returns the output type for the function.\n     * @param graphSchema The graph schema.\n     * @return The output struct type.\n     */\n    StructType getOutputType(GraphSchema graphSchema);\n}\n```\n\n2. ??????K-Core????????????\n\n\n```\npackage com.antgroup.geaflow.dsl.udf.graph;\n\nimport com.antgroup.geaflow.common.type.primitive.IntegerType;\nimport com.antgroup.geaflow.common.type.primitive.StringType;\nimport com.antgroup.geaflow.dsl.common.algo.AlgorithmRuntimeContext;\nimport com.antgroup.geaflow.dsl.common.algo.IncrementalAlgorithmUserFunction;\nimport com.antgroup.geaflow.dsl.common.data.Row;\nimport com.antgroup.geaflow.dsl.common.data.RowEdge;\nimport com.antgroup.geaflow.dsl.common.data.RowVertex;\nimport com.antgroup.geaflow.dsl.common.data.impl.ObjectRow;\nimport com.antgroup.geaflow.dsl.common.function.Description;\nimport com.antgroup.geaflow.dsl.common.types.GraphSchema;\nimport com.antgroup.geaflow.dsl.common.types.StructType;\nimport com.antgroup.geaflow.dsl.common.types.TableField;\nimport com.antgroup.geaflow.model.graph.edge.EdgeDirection;\nimport java.io.Serializable;\nimport java.util.*;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n@Description(name = \"incremental_kcore\", description = \"built-in udga for Incremental K-Core\")\npublic class IncrementalKCore implements IncrementalAlgorithmUserFunction<Object, IncrementalKCore.KCoreMessage> {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(IncrementalKCore.class);\n    \n    private AlgorithmRuntimeContext<Object, KCoreMessage> context;\n    private int k = 3; // ??????K???\n    private int maxIterations = 100; // ??????????????????\n    \n    // ??????????????????\n    private Map<Object, Integer> vertexCoreValues = new HashMap<>();\n    private Map<Object, Integer> vertexDegrees = new HashMap<>();\n    private Set<Object> affectedVertices = new HashSet<>();\n    private boolean hasConverged = false;\n    \n    @Override\n    public void init(AlgorithmRuntimeContext<Object, KCoreMessage> context, Object[] parameters) {\n        this.context = context;\n        if (parameters.length > 0) {\n            this.k = Integer.parseInt(String.valueOf(parameters[0]));\n        }\n        if (parameters.length > 1) {\n            this.maxIterations = Integer.parseInt(String.valueOf(parameters[1]));\n        }\n        LOGGER.info(\"Incremental K-Core initialized with k={}, maxIterations={}\", k, maxIterations);\n    }\n\n    @Override\n    public void process(RowVertex vertex, Optional<Row> updatedValues, Iterator<KCoreMessage> messages) {\n        updatedValues.ifPresent(vertex::setValue);\n        \n        Object vertexId = vertex.getId();\n        long currentIteration = context.getCurrentIterationId();\n        \n        // ???????????????????????????\n        if (currentIteration == 1L) {\n            initializeVertex(vertex);\n            return;\n        }\n        \n        // ????????????????????????????????????????????????\n        if (hasConverged || currentIteration > maxIterations) {\n            return;\n        }\n        \n        // ??????????????????\n        processIncrementalUpdate(vertex, messages);\n    }\n    \n    private void initializeVertex(RowVertex vertex) {\n        Object vertexId = vertex.getId();\n        \n        // ???????????????????????????????????????????????????\n        List<RowEdge> staticEdges = context.loadStaticEdges(EdgeDirection.BOTH);\n        List<RowEdge> dynamicEdges = context.loadDynamicEdges(EdgeDirection.BOTH);\n        \n        int totalDegree = staticEdges.size() + dynamicEdges.size();\n        vertexDegrees.put(vertexId, totalDegree);\n        \n        // ??????K-Core???????????????\n        int initialCore = totalDegree;\n        vertexCoreValues.put(vertexId, initialCore);\n        \n        // ???????????????\n        context.updateVertexValue(ObjectRow.create(initialCore, totalDegree, \"INIT\"));\n        \n        // ??????????????????????????????\n        List<RowEdge> allEdges = new ArrayList<>();\n        allEdges.addAll(staticEdges);\n        allEdges.addAll(dynamicEdges);\n        \n        sendMessageToNeighbors(allEdges, new KCoreMessage(vertexId, initialCore, KCoreMessage.MessageType.INIT));\n        \n        LOGGER.debug(\"Initialized vertex {} with degree={}, core={}\", vertexId, totalDegree, initialCore);\n    }\n    \n    private void processIncrementalUpdate(RowVertex vertex, Iterator<KCoreMessage> messages) {\n        Object vertexId = vertex.getId();\n        boolean needsRecomputation = false;\n        Set<Object> changedNeighbors = new HashSet<>();\n        Map<Object, Integer> neighborCores = new HashMap<>();\n        \n        // ????????????????????????\n        while (messages.hasNext()) {\n            KCoreMessage message = messages.next();\n            \n            switch (message.getType()) {\n                case EDGE_ADDED:\n                    handleEdgeAdded(vertexId, message);\n                    needsRecomputation = true;\n                    break;\n                case EDGE_REMOVED:\n                    handleEdgeRemoved(vertexId, message);\n                    needsRecomputation = true;\n                    break;\n                case CORE_CHANGED:\n                    changedNeighbors.add(message.getSourceId());\n                    neighborCores.put(message.getSourceId(), message.getCoreValue());\n                    needsRecomputation = true;\n                    break;\n                case INIT:\n                    neighborCores.put(message.getSourceId(), message.getCoreValue());\n                    needsRecomputation = true;\n                    break;\n            }\n        }\n        \n        if (needsRecomputation) {\n            recomputeKCore(vertex, neighborCores);\n        }\n    }\n    \n    private void handleEdgeAdded(Object vertexId, KCoreMessage message) {\n        // ????????????\n        int currentDegree = vertexDegrees.getOrDefault(vertexId, 0);\n        vertexDegrees.put(vertexId, currentDegree + 1);\n        affectedVertices.add(vertexId);\n        \n        LOGGER.debug(\"Edge added to vertex {}, new degree={}\", vertexId, currentDegree + 1);\n    }\n    \n    private void handleEdgeRemoved(Object vertexId, KCoreMessage message) {\n        // ????????????\n        int currentDegree = vertexDegrees.getOrDefault(vertexId, 0);\n        vertexDegrees.put(vertexId, Math.max(0, currentDegree - 1));\n        affectedVertices.add(vertexId);\n        \n        LOGGER.debug(\"Edge removed from vertex {}, new degree={}\", vertexId, currentDegree - 1);\n    }\n    \n    private void recomputeKCore(RowVertex vertex, Map<Object, Integer> neighborCores) {\n        Object vertexId = vertex.getId();\n        int currentCore = vertexCoreValues.getOrDefault(vertexId, 0);\n        \n        // ????????????????????????K-Core??? >= k????????????\n        int validNeighbors = countValidNeighbors(vertex, neighborCores);\n        \n        // ????????????K-Core???????????????????????????????????????????????????\n        int currentDegree = vertexDegrees.getOrDefault(vertexId, 0);\n        int newCore = Math.min(validNeighbors, currentDegree);\n        \n        // ????????????core?????????k????????????????????????k-core\n        if (newCore < k) {\n            newCore = 0;\n        }\n        \n        if (newCore != currentCore) {\n            vertexCoreValues.put(vertexId, newCore);\n            affectedVertices.add(vertexId);\n            \n            // ???????????????\n            String changeType = newCore > currentCore ? \"INCREASED\" : \"DECREASED\";\n            context.updateVertexValue(ObjectRow.create(newCore, currentDegree, changeType));\n            \n            // ?????????????????????\n            List<RowEdge> allEdges = new ArrayList<>();\n            allEdges.addAll(context.loadStaticEdges(EdgeDirection.BOTH));\n            allEdges.addAll(context.loadDynamicEdges(EdgeDirection.BOTH));\n            \n            sendMessageToNeighbors(allEdges, \n                new KCoreMessage(vertexId, newCore, KCoreMessage.MessageType.CORE_CHANGED));\n            \n            LOGGER.debug(\"Vertex {} core changed from {} to {}\", vertexId, currentCore, newCore);\n        }\n    }\n    \n    private int countValidNeighbors(RowVertex vertex, Map<Object, Integer> neighborCores) {\n        List<RowEdge> allEdges = new ArrayList<>();\n        allEdges.addAll(context.loadStaticEdges(EdgeDirection.BOTH));\n        allEdges.addAll(context.loadDynamicEdges(EdgeDirection.BOTH));\n        \n        int validCount = 0;\n        for (RowEdge edge : allEdges) {\n            Object neighborId = edge.getTargetId().equals(vertex.getId()) ? \n                edge.getSrcId() : edge.getTargetId();\n            \n            int neighborCore = neighborCores.getOrDefault(neighborId, \n                vertexCoreValues.getOrDefault(neighborId, 0));\n            \n            if (neighborCore >= k) {\n                validCount++;\n            }\n        }\n        \n        return validCount;\n    }\n    \n    private void sendMessageToNeighbors(List<RowEdge> edges, KCoreMessage message) {\n        for (RowEdge edge : edges) {\n            Object targetId = edge.getTargetId();\n            Object srcId = edge.getSrcId();\n            \n            // ??????????????????????????????????????????????????????????????????\n            if (!targetId.equals(message.getSourceId())) {\n                context.sendMessage(targetId, message);\n            }\n            if (!srcId.equals(message.getSourceId()) && !srcId.equals(targetId)) {\n                context.sendMessage(srcId, message);\n            }\n        }\n    }\n\n    @Override\n    public void finish(RowVertex vertex, Optional<Row> updatedValues) {\n        updatedValues.ifPresent(vertex::setValue);\n        \n        Object vertexId = vertex.getId();\n        int coreValue = vertexCoreValues.getOrDefault(vertexId, 0);\n        int degree = vertexDegrees.getOrDefault(vertexId, 0);\n        \n        // ???????????????k-core?????????\n        if (coreValue >= k) {\n            context.take(ObjectRow.create(vertexId, coreValue, degree, \n                affectedVertices.contains(vertexId) ? \"CHANGED\" : \"UNCHANGED\"));\n        }\n    }\n\n    @Override\n    public StructType getOutputType(GraphSchema graphSchema) {\n        return new StructType(\n            new TableField(\"vid\", graphSchema.getIdType(), false),\n            new TableField(\"core_value\n\n    @Override  \n    public StructType getOutputType(GraphSchema graphSchema) {  \n        return new StructType(  \n            new TableField(\"vid\", graphSchema.getIdType(), false),  \n            new TableField(\"core_value\", IntegerType.INSTANCE, false),  \n            new TableField(\"degree\", IntegerType.INSTANCE, false),  \n            new TableField(\"change_status\", StringType.INSTANCE, false)  \n        );  \n    }  \n      \n    /**  \n     * ???????????????????????????????????????  \n     */  \n    public static class KCoreMessage implements Serializable {  \n          \n        public enum MessageType {  \n            INIT,           // ???????????????  \n            EDGE_ADDED,     // ???????????????  \n            EDGE_REMOVED,   // ???????????????  \n            CORE_CHANGED    // Core???????????????  \n        }  \n          \n        private Object sourceId;  \n        private int coreValue;  \n        private MessageType type;  \n        private Object edgeInfo; // ??????????????????  \n          \n        public KCoreMessage(Object sourceId, int coreValue, MessageType type) {  \n            this.sourceId = sourceId;  \n            this.coreValue = coreValue;  \n            this.type = type;  \n        }  \n          \n        public KCoreMessage(Object sourceId, int coreValue, MessageType type, Object edgeInfo) {  \n            this.sourceId = sourceId;  \n            this.coreValue = coreValue;  \n            this.type = type;  \n            this.edgeInfo = edgeInfo;  \n        }  \n          \n        // Getters and Setters  \n        public Object getSourceId() {   \n            return sourceId;   \n        }  \n          \n        public void setSourceId(Object sourceId) {   \n            this.sourceId = sourceId;   \n        }  \n          \n        public int getCoreValue() {   \n            return coreValue;   \n        }  \n          \n        public void setCoreValue(int coreValue) {   \n            this.coreValue = coreValue;   \n        }  \n          \n        public MessageType getType() {   \n            return type;   \n        }  \n          \n        public void setType(MessageType type) {   \n            this.type = type;   \n        }  \n          \n        public Object getEdgeInfo() {   \n            return edgeInfo;   \n        }  \n          \n        public void setEdgeInfo(Object edgeInfo) {   \n            this.edgeInfo = edgeInfo;   \n        }  \n          \n        @Override  \n        public String toString() {  \n            return \"KCoreMessage{\" +  \n                \"sourceId=\" + sourceId +  \n                \", coreValue=\" + coreValue +  \n                \", type=\" + type +  \n                \", edgeInfo=\" + edgeInfo +  \n                '}';  \n        }  \n    }  \n}\n```\n\n3. ??????K-Core?????????????????????????????????\n\n```\npackage com.antgroup.geaflow.dsl.runtime.engine;  \n  \nimport com.antgroup.geaflow.dsl.common.algo.AlgorithmRuntimeContext;  \nimport com.antgroup.geaflow.dsl.common.data.Row;  \nimport com.antgroup.geaflow.dsl.common.data.RowEdge;  \nimport com.antgroup.geaflow.dsl.common.types.GraphSchema;  \nimport com.antgroup.geaflow.model.graph.edge.EdgeDirection;  \nimport java.util.List;  \nimport java.util.Map;  \nimport java.util.concurrent.ConcurrentHashMap;  \n  \n/**  \n * ??????K-Core?????????????????????????????????  \n */  \npublic class IncrementalKCoreRuntimeContext<K, M> implements AlgorithmRuntimeContext<K, M> {  \n      \n    private final AlgorithmRuntimeContext<K, M> baseContext;  \n    private final Map<K, Integer> vertexStateCache = new ConcurrentHashMap<>();  \n    private final Map<K, List<RowEdge>> edgeCache = new ConcurrentHashMap<>();  \n      \n    public IncrementalKCoreRuntimeContext(AlgorithmRuntimeContext<K, M> baseContext) {  \n        this.baseContext = baseContext;  \n    }  \n      \n    @Override  \n    public List<RowEdge> loadEdges(EdgeDirection direction) {  \n        return baseContext.loadEdges(direction);  \n    }  \n      \n    @Override  \n    public List<RowEdge> loadStaticEdges(EdgeDirection direction) {  \n        return baseContext.loadStaticEdges(direction);  \n    }  \n      \n    @Override  \n    public List<RowEdge> loadDynamicEdges(EdgeDirection direction) {  \n        return baseContext.loadDynamicEdges(direction);  \n    }  \n      \n    @Override  \n    public void sendMessage(K vertexId, M message) {  \n        baseContext.sendMessage(vertexId, message);  \n    }  \n      \n    @Override  \n    public void updateVertexValue(Row value) {  \n        baseContext.updateVertexValue(value);  \n    }  \n      \n    @Override  \n    public void take(Row value) {  \n        baseContext.take(value);  \n    }  \n      \n    @Override  \n    public long getCurrentIterationId() {  \n        return baseContext.getCurrentIterationId();  \n    }  \n      \n    @Override  \n    public GraphSchema getGraphSchema() {  \n        return baseContext.getGraphSchema();  \n    }  \n      \n    // ??????K-Core???????????????  \n    public void cacheVertexState(K vertexId, Integer state) {  \n        vertexStateCache.put(vertexId, state);  \n    }  \n      \n    public Integer getCachedVertexState(K vertexId) {  \n        return vertexStateCache.get(vertexId);  \n    }  \n      \n    public void clearCache() {  \n        vertexStateCache.clear();  \n        edgeCache.clear();  \n    }  \n}\n```\n4. ??????????????????\n\n```\npackage com.antgroup.geaflow.dsl.runtime.query;  \n  \nimport com.antgroup.geaflow.dsl.runtime.QueryTester;  \nimport org.testng.annotations.Test;  \n  \npublic class IncrementalKCoreTest {  \n      \n    @Test  \n    public void testIncrementalKCore() throws Exception {  \n        QueryTester  \n            .build()  \n            .withQueryPath(\"/query/incremental_kcore_test.sql\")  \n            .withExpectPath(\"/expect/incremental_kcore_test.txt\")  \n            .execute();  \n    }  \n      \n    @Test  \n    public void testIncrementalKCoreWithDynamicGraph() throws Exception {  \n        QueryTester  \n            .build()  \n            .withQueryPath(\"/query/incremental_kcore_dynamic_test.sql\")  \n            .withExpectPath(\"/expect/incremental_kcore_dynamic_test.txt\")  \n            .execute();  \n    }  \n      \n    @Test  \n    public void testIncrementalKCorePerformance() throws Exception {  \n        QueryTester  \n            .build()  \n            .withQueryPath(\"/query/incremental_kcore_performance_test.sql\")  \n            .withExpectPath(\"/expect/incremental_kcore_performance_test.txt\")  \n            .execute();  \n    }  \n}\n```\n5. SQL??????????????????\n?????? incremental_kcore_test.sql:\n```\n-- ??????K-Core??????????????????  \nCREATE GRAPH modern (  \n  Vertex person (  \n    id bigint ID,  \n    name varchar,  \n    age int  \n  ),  \n  Edge knows (  \n    srcId bigint SOURCE ID,  \n    targetId bigint DESTINATION ID,  \n    weight double  \n  )  \n) WITH (  \n  storeType='memory',  \n  shardCount = 1  \n);  \n  \n-- ??????????????????  \nINSERT INTO modern.person(id, name, age) VALUES  \n(1, 'marko', 29),  \n(2, 'vadas', 27),  \n(3, 'lop', 32),  \n(4, 'josh', 32),  \n(5, 'ripple', 35),  \n(6, 'peter', 35);  \n  \nINSERT INTO modern.knows VALUES  \n(1, 2, 0.5),  \n(1, 4, 1.0),  \n(2, 3, 0.4),  \n(4, 3, 0.4),  \n(4, 5, 1.0),  \n(6, 3, 0.2);  \n  \n-- ????????????K-Core??????  \nCALL incremental_kcore(modern, 2)   \nYIELD (vid, core_value, degree, change_status)  \nRETURN vid, core_value, degree, change_status  \nORDER BY vid;\n```\n6. ???DSL????????????????????????\n```\nimport com.antgroup.geaflow.dsl.udf.graph.IncrementalKCore;\n```\n????????? ????????????????????????\n```\n            .add(GeaFlowFunction.of(KCore.class))  \n            .add(GeaFlowFunction.of(IncrementalKCore.class))  // ????????????  \n            .add(GeaFlowFunction.of(ClosenessCentrality.class))  \n            .add(GeaFlowFunction.of(WeakConnectedComponents.class))  \n            .add(GeaFlowFunction.of(TriangleCount.class))  \n            .add(GeaFlowFunction.of(IncWeakConnectedComponents.class))  \n            .add(GeaFlowFunction.of(CommonNeighbors.class))  \n            .add(GeaFlowFunction.of(IncKHopAlgorithm.class))  \n            .build();\n```\n7. ???????????????????????????\n```\n?????? incremental_kcore_config.properties:\n```\n# ??????K-Core????????????  \n```\ngeaflow.dsl.incremental.kcore.max.iterations=100  \ngeaflow.dsl.incremental.kcore.convergence.threshold=0.001  \ngeaflow.dsl.incremental.kcore.cache.size=10000  \ngeaflow.dsl.incremental.kcore.batch.size=1000\n```\n", "Thank you for your attention to the project. Your proposal is very detailed. I will analyze your algorithm as soon as possible and provide a conclusion.", "The main structure of the algorithm looks fine. For this issue, you can submit a pull request.", "@dukewy123 ????????? @E2ern1ty ?????????????????????????????????????????????????????????????????????????????????PR?????????" ],
      "repository" : {
        "description" : "GeaFlow: A Streaming Graph Computing Engine.",
        "homepage" : "https://tugraph-analytics.github.io",
        "name" : "tugraph-analytics",
        "fullName" : "TuGraph-family/tugraph-analytics",
        "htmlUrl" : "https://github.com/TuGraph-family/tugraph-analytics",
        "gitUrl" : "git://github.com/TuGraph-family/tugraph-analytics.git",
        "sshUrl" : "git@github.com:TuGraph-family/tugraph-analytics.git",
        "cloneUrl" : "https://github.com/TuGraph-family/tugraph-analytics.git",
        "owner" : {
          "login" : "TuGraph-family",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 125,
        "stargazersCount" : 683,
        "watchersCount" : 683,
        "size" : 48109,
        "openIssuesCount" : 28,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-10T08:52:48Z",
        "languages" : {
          "TypeScript" : 1012318,
          "Smarty" : 4688,
          "Java" : 12953350,
          "Dockerfile" : 2190,
          "C++" : 356329,
          "Shell" : 33580,
          "JavaScript" : 25746,
          "Fluent" : 402,
          "Less" : 93150,
          "FreeMarker" : 25564,
          "Cython" : 2181,
          "Python" : 14338
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the algorithm is to identify the K-Core of a graph using the incremental K-Core algorithm. The algorithm is designed to be efficient and scalable, and to provide accurate results.",
      "validationOrRequirement" : "The algorithm requires the GeaFlow library to be installed and configured on the system. The algorithm also requires a graph database to be created and populated with data. The algorithm uses the following data structures: vertex state cache, edge cache, and vertex-centric algorithm.",
      "attemptedFixes" : "The algorithm has been tested and validated using several test cases, including a test case that inserts a large number of vertices and edges into the graph database and then executes the incremental K-Core algorithm to identify the K-Core of the graph.",
      "otherNotes" : "The algorithm is designed to support incremental K-Core algorithm, which is a graph processing algorithm used to identify the K-Core of a graph. The algorithm is implemented in Java and uses the GeaFlow library to interact with the graph database. The algorithm consists of several components, including the incremental K-Core algorithm, the vertex-centric algorithm, and the edge-centric algorithm. The algorithm also includes several data structures, such as the vertex state cache and the edge cache, to improve performance. The algorithm is tested using the QueryTester class, which provides a way to execute queries against the graph database and verify the results.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284489
  }, {
    "issueDTO" : {
      "id" : 3212363245,
      "title" : "Update our tests to use JUnit 5",
      "url" : "https://github.com/cucumber/cucumber-jvm-scala/issues/399",
      "repositoryName" : "cucumber/cucumber-jvm-scala",
      "description" : "### \uD83E\uDD14 What's the problem you've observed?\n\nAs Cucumber [7.24.0 deprecated `cucumber-junit` (JUnit 4)](https://github.com/cucumber/cucumber-jvm/pull/3016), we should update our examples and integration tests to rely on JUnit 5.\n\nDocumentation should reflect this as well.\n\nThis will allow to merge https://github.com/cucumber/cucumber-jvm-scala/pull/398 (even though we could probably upgrade by adding some ignore flags).\n\n### ??? Do you have a proposal for making it better?\n\n_No response_\n\n### \uD83D\uDCDA Any additional context?\n\n_No response_",
      "updatedAt" : 1752226016.000000000,
      "user" : "gaeljw",
      "userHtmlUrl" : "https://github.com/gaeljw",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18280708?v=4",
      "labels" : [ ":wrench: build", ":robot: dependencies", "good first issue", ":bank: debt" ],
      "state" : "OPEN",
      "comments" : [ "When trying to switch the examples project to use JUnit 5 with cucumber-junit-platform-engine, I get a weird exception like if JUnit is trying to load the feature file as a class:\n\n```\norg.junit.platform.commons.JUnitException: TestEngine with ID 'cucumber' failed to discover tests\n  | => eat org.junit.platform.launcher.core.EngineDiscoveryOrchestrator.discoverEngineRoot(EngineDiscoveryOrchestrator.java:208)\n        at org.junit.platform.launcher.core.EngineDiscoveryOrchestrator.discoverSafely(EngineDiscoveryOrchestrator.java:174)\n        at org.junit.platform.launcher.core.EngineDiscoveryOrchestrator.discover(EngineDiscoveryOrchestrator.java:119)\n        at org.junit.platform.launcher.core.EngineDiscoveryOrchestrator.discover(EngineDiscoveryOrchestrator.java:84)\n        at org.junit.platform.launcher.core.DefaultLauncher.discover(DefaultLauncher.java:104)\n        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:91)\n        at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)\n        at org.junit.platform.launcher.core.InterceptingLauncher.lambda$execute$1(InterceptingLauncher.java:39)\n        at org.junit.platform.launcher.core.ClasspathAlignmentCheckingLauncherInterceptor.intercept(ClasspathAlignmentCheckingLauncherInterceptor.java:25)\n        at org.junit.platform.launcher.core.InterceptingLauncher.execute(InterceptingLauncher.java:38)\n        at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)\n        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:66)\n        at com.github.sbt.junit.jupiter.internal.JupiterRunner$JupiterTaskExecutor.execute(JupiterRunner.java:184)\n        at com.github.sbt.junit.jupiter.internal.JupiterRunner$WithCustomProperties.execute(JupiterRunner.java:236)\n        at com.github.sbt.junit.jupiter.internal.JupiterRunner$JupiterTask.execute(JupiterRunner.java:123)\n        at sbt.TestRunner.runTest$1(TestFramework.scala:153)\n        at sbt.TestRunner.run(TestFramework.scala:168)\n        at sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:336)\n        at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:296)\n        at sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:336)\n        at sbt.TestFramework$$anon$3$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:336)\n        at sbt.TestFunction.apply(TestFramework.scala:348)\n        at sbt.Tests$.$anonfun$toTask$1(Tests.scala:436)\n        at sbt.std.Transform$$anon$3.$anonfun$apply$2(Transform.scala:47)\n        at sbt.std.Transform$$anon$4.work(Transform.scala:69)\n        at sbt.Execute.$anonfun$submit$2(Execute.scala:283)\n        at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:24)\n        at sbt.Execute.work(Execute.scala:292)\n        at sbt.Execute.$anonfun$submit$1(Execute.scala:283)\n        at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:265)\n        at sbt.CompletionService$$anon$2.call(CompletionService.scala:65)\n        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n        at java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: org.junit.platform.commons.PreconditionViolationException: Could not load class with name: Basic Arithmetic\n        at org.junit.platform.engine.discovery.ClassSelector.lambda$getJavaClass$0(ClassSelector.java:98)\n        at org.junit.platform.commons.function.Try$Failure.getOrThrow(Try.java:335)\n        at org.junit.platform.engine.discovery.ClassSelector.getJavaClass(ClassSelector.java:97)\n        at io.cucumber.junit.platform.engine.FeatureResolver.resolveClass(FeatureResolver.java:180)\n        at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)\n        at io.cucumber.junit.platform.engine.DiscoverySelectorResolver.resolve(DiscoverySelectorResolver.java:82)\n        at io.cucumber.junit.platform.engine.DiscoverySelectorResolver.resolveSelectors(DiscoverySelectorResolver.java:53)\n        at io.cucumber.junit.platform.engine.CucumberTestEngine.discover(CucumberTestEngine.java:47)\n        at org.junit.platform.launcher.core.EngineDiscoveryOrchestrator.discoverEngineRoot(EngineDiscoveryOrchestrator.java:195)\n        ... 36 more\nCaused by: java.lang.ClassNotFoundException: Basic Arithmetic\n        at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n        at sbt.internal.ManagedClassLoader.findClass(ManagedClassLoader.java:103)\n        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\n        at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n        at java.base/java.lang.Class.forName0(Native Method)\n        at java.base/java.lang.Class.forName(Class.java:534)\n        at java.base/java.lang.Class.forName(Class.java:513)\n        at org.junit.platform.commons.util.ReflectionUtils.lambda$tryToLoadClass$10(ReflectionUtils.java:886)\n        at org.junit.platform.commons.function.Try.lambda$call$0(Try.java:57)\n        at org.junit.platform.commons.function.Try.of(Try.java:93)\n        at org.junit.platform.commons.function.Try.call(Try.java:57)\n        at org.junit.platform.commons.util.ReflectionUtils.tryToLoadClass(ReflectionUtils.java:873)\n        at org.junit.platform.commons.util.ReflectionUtils.tryToLoadClass(ReflectionUtils.java:810)\n        at org.junit.platform.commons.support.ReflectionSupport.tryToLoadClass(ReflectionSupport.java:95)\n        at org.junit.platform.engine.discovery.ClassSelector.getJavaClass(ClassSelector.java:95)\n        ... 42 more\n[info] Test run started (JUnit Platform Suite)\n[info] Test classpath:cucumber/examples/scalacalculator/basic_arithmetic.feature 4 started\n[info] Test run finished: 0 failed, 0 ignored, 1 total, 0.117s\n[error] Error: Total 2, Failed 0, Errors 1, Passed 1\n[error] Error during tests:\n[error]         Basic Arithmetic\n[error] (Test / test) sbt.TestsFailedException: Tests unsuccessful\n```\n\nI tried a couple of variations of the following setup but nothing worked so far:\n```scala\n@Suite\n@IncludeEngines(Array(\"cucumber\"))\n@SelectClasspathResource(\"cucumber/examples/scalacalculator\")\n@SelectPackages(Array(\"cucumber.examples.scalacalculator\"))\n@ConfigurationParameter(\n  key = Constants.GLUE_PROPERTY_NAME,\n  value = \"cucumber.examples.scalacalculator\"\n)\n//@ConfigurationParameter(\n//  key = Constants.FEATURES_PROPERTY_NAME,\n//  value = \"examples/src/test/resources/cucumber/examples/scalacalculator\"\n//)\nclass RunCukesTest\n```\n\nThe weird thing is that it says 1 tests passed and 1 errored wheras there is only 1 test. Like there's 2 mechanisms trying to run the tests?", "Poking @mpkorstanje if you've got any idea where to look at as I think you worked on the JUnit stuff in cucumber-jvm. Don't spend much time on this, it's only if it reminds you anything you've seeen previously \uD83E\uDD37 ", "> The weird thing is that it says 1 tests passed and 1 errored wheras there is only 1 test. Like there's 2 mechanisms trying to run the tests?\n\nThat seems extremely likely. Do you have a branch for me to look at?", "If anything you shouldn't use both `@SelectPackages(Array(\"cucumber.examples.scalacalculator\"))` and `@SelectClasspathResource(\"cucumber/examples/scalacalculator\")`. The former is for all features in a package, the latter for individual feature files.\n\n", "And it looks like a class selector was created for the class `Basic Arithmetic`. Which is a string that occurs nowhere outside of one feature file. Which is weird because selectors are provided to Junit and then Cucumber by the SBT (presumably).\n\nAnd tracing that we end up here:\n\nhttps://github.com/sbt/sbt-jupiter-interface/blob/67f99dbad1a8c687f5ad76bb2d1482f1dac04099/src/library/src/main/java/com/github/sbt/junit/jupiter/internal/JupiterRunner.java#L157\n\nSo presumably you've created an SBT suite with the name  `Basic Arithmetic`, and that should probably be `RunCukesTest`.\n\n", "Ah!\n\nhttps://github.com/sbt/sbt-jupiter-interface/tree/67f99dbad1a8c687f5ad76bb2d1482f1dac04099?tab=readme-ov-file#jupiter-interface\n> sbt-jupiter-interface: sbt plugin. The sbt plugin makes the runtime library available to the sbt build by adding it to sbt.Keys.testFrameworks. It also overwrites sbt.Keys.detectTests with a custom task that uses JUnits discovery mechanism to collect available tests. This step is necessary since sbt is currently not capable of detecting package private test classes.\n\nLooks like the SBT plugin also does test discovery, but then mucks it up.\n\nSo that is probably what they're doing wrong here:\n\nhttps://github.com/sbt/sbt-jupiter-interface/blob/67f99dbad1a8c687f5ad76bb2d1482f1dac04099/src/library/src/main/java/com/github/sbt/junit/jupiter/api/JupiterTestCollector.java#L281", "And yes! https://github.com/sbt/sbt-jupiter-interface/issues/142", "Wow, that was fast, thanks a lot @mpkorstanje ! I will follow up on the SBT side of things then :)", "If that doesn't work out, could you try this solution https://github.com/cucumber/cucumber-jvm/pull/3023? ", "Sure, I'll try this tomorrow :)", "@mpkorstanje the workaround does the job, nice! \uD83D\uDC4F \n\n```\nsbt:scala-examples> test\n[info] Test run started (JUnit Platform Suite)\n[info] Test classpath:cucumber/examples/scalacalculator/basic_arithmetic.feature 4 started\n[info] Test run finished: 0 failed, 0 ignored, 1 total, 0.109s\n[info] Passed: Total 1, Failed 0, Errors 0, Passed 1\n[success] Total time: 1 s, completed 11 juil. 2025, 08:35:25\n```\n\n(I'll still try to open a PR at SBT in the coming days)", "FYI the draft changes (missing some doc) are in https://github.com/cucumber/cucumber-jvm-scala/pull/400. When you merge and release https://github.com/cucumber/cucumber-jvm/pull/3023, I'll happily use it \uD83D\uDE05 ", "Awesome. I'm out of time for today. So probably Monday." ],
      "repository" : {
        "description" : "Cucumber Scala",
        "homepage" : "https://cucumber.io/",
        "name" : "cucumber-jvm-scala",
        "fullName" : "cucumber/cucumber-jvm-scala",
        "htmlUrl" : "https://github.com/cucumber/cucumber-jvm-scala",
        "gitUrl" : "git://github.com/cucumber/cucumber-jvm-scala.git",
        "sshUrl" : "git@github.com:cucumber/cucumber-jvm-scala.git",
        "cloneUrl" : "https://github.com/cucumber/cucumber-jvm-scala.git",
        "owner" : {
          "login" : "cucumber",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : false,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 29,
        "stargazersCount" : 48,
        "watchersCount" : 48,
        "size" : 1300,
        "openIssuesCount" : 12,
        "subscribersCount" : 67,
        "pushedAt" : "2025-07-11T07:14:26Z",
        "languages" : {
          "Shell" : 2653,
          "Awk" : 408,
          "Gherkin" : 17681,
          "Scala" : 324980,
          "Makefile" : 656,
          "HTML" : 128
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to update the tests to use JUnit 5, which is necessary because Cucumber 7.24.0 has deprecated cucumber-junit (JUnit 4) and it is recommended to use JUnit 5 instead.",
      "validationOrRequirement" : "The requirements for this issue are to update tests to use JUnit 5, update documentation, and merge a pull request.",
      "attemptedFixes" : "Several attempts were made to fix the issue, including trying different setups and configurations, but the issue is still not resolved. The attempts include trying to switch the examples project to use JUnit 5 with cucumber-junit-platform-engine, but this results in a weird exception.",
      "otherNotes" : "The issue is about updating tests to use JUnit 5, and there are attempts to fix the issue by trying different setups, but the issue is still not resolved. The main goal is to update tests to use JUnit 5, and there are specific requirements such as updating documentation and merging a pull request.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284497
  }, {
    "issueDTO" : {
      "id" : 2830271141,
      "title" : "Discovery: Discover network interfaces for compute resources",
      "url" : "https://github.com/clouditor/clouditor/issues/1625",
      "repositoryName" : "clouditor/clouditor",
      "description" : "In method handleVirtualMachine() the network interface IDs are missing. ",
      "updatedAt" : 1752225991.000000000,
      "user" : "anatheka",
      "userHtmlUrl" : "https://github.com/anatheka",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18168509?v=4",
      "labels" : [ "good first issue", "service/discovery" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The Clouditor is a tool to support continuous cloud assurance. Developed by Fraunhofer AISEC.",
        "homepage" : "https://clouditor.io",
        "name" : "clouditor",
        "fullName" : "clouditor/clouditor",
        "htmlUrl" : "https://github.com/clouditor/clouditor",
        "gitUrl" : "git://github.com/clouditor/clouditor.git",
        "sshUrl" : "git@github.com:clouditor/clouditor.git",
        "cloneUrl" : "https://github.com/clouditor/clouditor.git",
        "owner" : {
          "login" : "clouditor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 78,
        "watchersCount" : 78,
        "size" : 27769,
        "openIssuesCount" : 96,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:23:36Z",
        "languages" : {
          "Dockerfile" : 1153,
          "Shell" : 811,
          "Open Policy Agent" : 25548,
          "Go" : 1923616
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Discover network interfaces for compute resources",
      "validationOrRequirement" : "Network interface IDs are missing in method handleVirtualMachine()",
      "attemptedFixes" : "",
      "otherNotes" : "Repository: clouditor/clouditor, Author: anatheka",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284499
  }, {
    "issueDTO" : {
      "id" : 2968787356,
      "title" : "Rename Evidences to Evidence",
      "url" : "https://github.com/clouditor/clouditor/issues/1680",
      "repositoryName" : "clouditor/clouditor",
      "description" : "Singular and plural of evidence are the same.",
      "updatedAt" : 1752225950.000000000,
      "user" : "anatheka",
      "userHtmlUrl" : "https://github.com/anatheka",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18168509?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Do we want to change Evidences to Evidence? If yes, we have to think about AssessEvidence() vs. AssessEvidences(). We could use one of the following: \n- AssessAllEvidences()\n- AssessMultipleEvidences()\n- AssessEvidenceStream()\n- ..." ],
      "repository" : {
        "description" : "The Clouditor is a tool to support continuous cloud assurance. Developed by Fraunhofer AISEC.",
        "homepage" : "https://clouditor.io",
        "name" : "clouditor",
        "fullName" : "clouditor/clouditor",
        "htmlUrl" : "https://github.com/clouditor/clouditor",
        "gitUrl" : "git://github.com/clouditor/clouditor.git",
        "sshUrl" : "git@github.com:clouditor/clouditor.git",
        "cloneUrl" : "https://github.com/clouditor/clouditor.git",
        "owner" : {
          "login" : "clouditor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 78,
        "watchersCount" : 78,
        "size" : 27769,
        "openIssuesCount" : 96,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:23:36Z",
        "languages" : {
          "Dockerfile" : 1153,
          "Shell" : 811,
          "Open Policy Agent" : 25548,
          "Go" : 1923616
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "rename Evidences to Evidence",
      "validationOrRequirement" : "rename Evidences to Evidence, consider alternatives for AssessEvidence()",
      "attemptedFixes" : "AssessAllEvidences(), AssessMultipleEvidences(), AssessEvidenceStream()",
      "otherNotes" : "singular and plural of evidence are the same, AssessEvidence() vs. AssessEvidences() vs. other options",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284502
  }, {
    "issueDTO" : {
      "id" : 3206309673,
      "title" : "support X-Clacks-Overhead (response) http header",
      "url" : "https://github.com/plabayo/rama/issues/620",
      "repositoryName" : "plabayo/rama",
      "description" : "Value of header is when encoded picked based on epoch modulo from this list:\n\n```\n\"Ashlynn\"\n      , \"Terry Davis\"\n      , \"Dennis Ritchie\"\n      , \"Steven Hawking\"\n      , \"John Conway\"\n      , \"Ruth Bader Ginsburg\"\n      , \"Bram Moolenaar\"\n      , \"Grant Imahara\"\n      , \"David Bowie\"\n      , \"Sir Terry Pratchett\"\n      , \"Satoru Iwata\"\n      , \"Kris N??va\"\n      , \"Joe Armstrong\"\n      , \"Paul Allen\"\n      , \"Kevin Mitnick\"\n      , \"Sir Clive Sinclair\"\n      , \"Matt Trout\"\n```\n\n- add credits in comment to original author Xe (https://github.com/Xe/site/blob/877872b4d7db92b602683ecb4e9934cbc4340079/dhall/package.dhall#L15-L33)\n\nSupport is to be added as\n\n- name constant in https://github.com/plabayo/rama/blob/a117469c08ebe62dbb96502ca87a9f6f76221adc/rama-http-types/src/lib.rs#L129\n- typed header in new file in https://github.com/plabayo/rama/tree/main/rama-http-headers/src\n\nMore info and also refer to it (incl summary added in code docs): \n\nhttps://xclacksoverhead.org/home/about\n\nEasy issue for a lot of brownie points\n\nHN post that inspired this issue: https://news.ycombinator.com/item?id=44440968",
      "updatedAt" : 1752225879.000000000,
      "user" : "GlenDC",
      "userHtmlUrl" : "https://github.com/GlenDC",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3900482?v=4",
      "labels" : [ "good first issue", "easy", "mentor available" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I would be interested in getting started with this if possible? not contributed to Rama before but been looking for a way to sneak in!", "Hi @Hwatwasthat , glad you finally found something to your liking. We keep issues like these open for the community as opportunities to (a) get you engaged into the framework and our community and (b) a learning opportunity. In return @soundofspace and I are here to mentor and guide you. So in case you are missing details, have questions, remarks, things you wish to discuss. Let us know.\n\nI'll assign it to you in the meanwhile. If you do decide now or later to not want to pursuit it do let us know and we'll un-assign you without an issue. We understand choices can change and life can happen." ],
      "repository" : {
        "description" : "modular service framework to move and transform network packets",
        "homepage" : "https://ramaproxy.org",
        "name" : "rama",
        "fullName" : "plabayo/rama",
        "htmlUrl" : "https://github.com/plabayo/rama",
        "gitUrl" : "git://github.com/plabayo/rama.git",
        "sshUrl" : "git@github.com:plabayo/rama.git",
        "cloneUrl" : "https://github.com/plabayo/rama.git",
        "owner" : {
          "login" : "plabayo",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 67,
        "stargazersCount" : 687,
        "watchersCount" : 687,
        "size" : 23720,
        "openIssuesCount" : 71,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-11T22:02:27Z",
        "languages" : {
          "Dockerfile" : 661,
          "Shell" : 6550,
          "CSS" : 2452,
          "Rust" : 6948211,
          "JavaScript" : 6121,
          "HTML" : 1297,
          "Python" : 18299,
          "Just" : 3993
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for X-Clacks-Overhead (response) http header with epoch modulo based value selection",
      "validationOrRequirement" : "Add credits in comment to original author Xe (https://github.com/Xe/site/blob/877872b4d7db92b602683ecb4e9934cbc4340079/dhall/package.dhall#L15-L33) and support as name constant in https://github.com/plabayo/rama/blob/a117469c08ebe62dbb96502ca87a9f6f76221adc/rama-http-types/src/lib.rs#L129 and typed header in new file in https://github.com/plabayo/rama/tree/main/rama-http-headers/src",
      "attemptedFixes" : "None mentioned in the issue description or comments",
      "otherNotes" : "The issue is about adding support for X-Clacks-Overhead (response) http header, with the value of the header being picked based on epoch modulo from a list of names. The support will be added as a name constant and a typed header in a new file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284509
  }, {
    "issueDTO" : {
      "id" : 3041935935,
      "title" : "Add enum for available operator values",
      "url" : "https://github.com/clouditor/clouditor/issues/1712",
      "repositoryName" : "clouditor/clouditor",
      "description" : "              I just had the thought that we could use an enum for the available operator values. What do you think?\r\n\r\n_Originally posted by @anatheka in https://github.com/clouditor/clouditor/pull/1695#discussion_r2071553478_\r\n            ",
      "updatedAt" : 1752225863.000000000,
      "user" : "anatheka",
      "userHtmlUrl" : "https://github.com/anatheka",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18168509?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The Clouditor is a tool to support continuous cloud assurance. Developed by Fraunhofer AISEC.",
        "homepage" : "https://clouditor.io",
        "name" : "clouditor",
        "fullName" : "clouditor/clouditor",
        "htmlUrl" : "https://github.com/clouditor/clouditor",
        "gitUrl" : "git://github.com/clouditor/clouditor.git",
        "sshUrl" : "git@github.com:clouditor/clouditor.git",
        "cloneUrl" : "https://github.com/clouditor/clouditor.git",
        "owner" : {
          "login" : "clouditor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 78,
        "watchersCount" : 78,
        "size" : 27769,
        "openIssuesCount" : 96,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T13:23:36Z",
        "languages" : {
          "Dockerfile" : 1153,
          "Shell" : 811,
          "Open Policy Agent" : 25548,
          "Go" : 1923616
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add enum for available operator values",
      "validationOrRequirement" : "enum for available operator values",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about adding an enum for available operator values, and it's a good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284512
  }, {
    "issueDTO" : {
      "id" : 3215730119,
      "title" : "ecnist.nim: ineffective use of memory",
      "url" : "https://github.com/vacp2p/nim-libp2p/issues/1512",
      "repositoryName" : "vacp2p/nim-libp2p",
      "description" : "file `ecnist.nim` has ineffiecent use of memory in `getBytes` and `toBytes` methods.\n\n\nexample of some `getBytes` is so:\n```nim\n  ...\n  var res = newSeq[byte]()\n  let length = ?seckey.toBytes(res)   <-------- #1\n  res.setLen(length)\n  discard ?seckey.toBytes(res)   <-------- #2\n ...\n```\nhere key is converted to bytes two times, first only length is used. and second time bytes are filled to `res`.\n\nit's also interesting that `toBytes` will encode data using `Asn1Buffer`  and this buffer will be copied over to `res`. why can we return data from this buffer directly?\n\nas result of this implementation `getBytes` has:\n- total memory utilization is 3x:\n  - 1st when doing first `seckey.toBytes(res) ` \n  - 2nd when doing `res.setLen(length)`\n  - 3rd when doing second `?seckey.toBytes(res)`\n- key is encoded 2 times; encoding once should be sufficient \n- unneeded memory copy from second `?seckey.toBytes(res)` call to `var res = newSeq[byte]()`\n\n---\n\ngoal of the issue is to improve `getBytes` in  `ecnist.nim` file\n\n",
      "updatedAt" : 1752225795.000000000,
      "user" : "vladopajic",
      "userHtmlUrl" : "https://github.com/vladopajic",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4353513?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "assign me , ill try", "@NikhilBisht2 awesome! issue is yours", "how about if, toBytes directly return the Asn1Buffer?", "> how about if, toBytes directly return the Asn1Buffer?\n\nyes i think it should be possible (or event it can return seq[byte])... \n`getBytes` must keep the same signature, or ideally we should not touch other files", " return seq[byte], ill try it" ],
      "repository" : {
        "description" : "libp2p implementation in Nim",
        "homepage" : "https://vacp2p.github.io/nim-libp2p/docs/",
        "name" : "nim-libp2p",
        "fullName" : "vacp2p/nim-libp2p",
        "htmlUrl" : "https://github.com/vacp2p/nim-libp2p",
        "gitUrl" : "git://github.com/vacp2p/nim-libp2p.git",
        "sshUrl" : "git@github.com:vacp2p/nim-libp2p.git",
        "cloneUrl" : "https://github.com/vacp2p/nim-libp2p.git",
        "owner" : {
          "login" : "vacp2p",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 63,
        "stargazersCount" : 279,
        "watchersCount" : 279,
        "size" : 69348,
        "openIssuesCount" : 151,
        "subscribersCount" : 29,
        "pushedAt" : "2025-07-11T21:03:54Z",
        "languages" : {
          "Dockerfile" : 1578,
          "Shell" : 3240,
          "Nim" : 2106620,
          "C" : 33151
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "optimize memory utilization in getBytes and toBytes methods in ecnist.nim file by reducing unnecessary memory copies and encoding key only once",
      "validationOrRequirement" : "improve getBytes in ecnist.nim file",
      "attemptedFixes" : "assign me, ill try, @NikhilBisht2 awesome! issue is yours, how about if, toBytes directly return the Asn1Buffer?, yes i think it should be possible (or event it can return seq[byte])... getBytes must keep the same signature, or ideally we should not touch other files, return seq[byte], ill try it",
      "otherNotes" : "ecnist.nim file has inefficient use of memory in getBytes and toBytes methods; key is encoded 2 times; unneeded memory copy from second ?seckey.toBytes(res) call to var res = newSeq[byte]()",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284518
  }, {
    "issueDTO" : {
      "id" : 3221164108,
      "title" : "[Bug]: Fix \"Test Server Connectivity\" Feature in Admin UI",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/367",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "# Fix \"Test Server Connectivity\" Feature in Admin UI\n\n**Priority:** Medium (Feature/Functionality)\n\n**Description:**\nThe \"Test Server Connectivity\" feature in the Admin UI is broken and returns \"Error: Invalid URL: URL is required\" when attempting to test gateway connections. This prevents administrators from verifying gateway connectivity before saving configurations.\n\n**Steps to Reproduce:**\n1. Access Admin UI at http://localhost:4444/admin/\n2. Navigate to Gateways section\n3. Click \"Test Server Connectivity\" button\n4. Fill in connection details\n5. Click \"Test Connection\"\n6. Error appears: \"Error: Invalid URL: URL is required\"\n\n**Expected Behavior:**\n- Form should accept URL and other connection parameters\n- Test should attempt connection to specified endpoint\n- Clear success/failure message with details (response time, status code)\n- Should work for different transport types (HTTP, SSE, WebSocket)\n\n**Investigation Results:**\nBased on the test results, the `/admin/gateways/test` endpoint exists and works via curl:\n```bash\ncurl -X POST http://localhost:4444/admin/gateways/test \\\n  -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"base_url\": \"http://localhost:8101\",\n    \"path\": \"/health\",\n    \"method\": \"GET\",\n    \"headers\": {},\n    \"body\": null\n  }'\n# Returns: Success (200) with status_code, latency_ms, and body\n```\n\nThe issue appears to be in the UI JavaScript code that's not properly constructing or sending the request.\n\n**Root Cause Analysis:**\n1. UI form may not be capturing the URL field correctly\n2. JavaScript may be sending incorrect field names\n3. Form validation might be preventing submission\n4. API expects `base_url` but UI might be sending `url`\n\n**Suggested Fix:**\n\n1. **Check and fix the JavaScript form handler**:\n```javascript\n// In the admin UI JavaScript\nasync function testGatewayConnectivity(formData) {\n    try {\n        // Ensure we're building the correct payload\n        const payload = {\n            base_url: formData.url || formData.base_url,  // Handle both field names\n            path: formData.path || '/health',\n            method: formData.method || 'GET',\n            headers: formData.headers || {},\n            body: formData.body || null\n        };\n        \n        // Validate required fields\n        if (!payload.base_url) {\n            throw new Error('URL is required');\n        }\n        \n        // Make the API call\n        const response = await fetch('/admin/gateways/test', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n                'Authorization': `Bearer ${getAuthToken()}`\n            },\n            body: JSON.stringify(payload)\n        });\n        \n        const result = await response.json();\n        \n        if (response.ok) {\n            showSuccess(`Connection successful! Status: ${result.status_code}, Latency: ${result.latency_ms}ms`);\n        } else {\n            showError(`Connection failed: ${result.detail || result.message}`);\n        }\n    } catch (error) {\n        showError(`Error: ${error.message}`);\n    }\n}\n```\n\n2. **Update the HTML form to match API expectations**:\n```html\n<!-- Test Connectivity Modal -->\n<div id=\"testConnectivityModal\" class=\"modal\">\n    <div class=\"modal-content\">\n        <h3>Test Gateway Connectivity</h3>\n        <form id=\"testConnectivityForm\">\n            <div class=\"form-group\">\n                <label for=\"test-base-url\">Base URL *</label>\n                <input \n                    type=\"url\" \n                    id=\"test-base-url\" \n                    name=\"base_url\" \n                    placeholder=\"http://localhost:8080\"\n                    required\n                    class=\"form-control\"\n                >\n            </div>\n            \n            <div class=\"form-group\">\n                <label for=\"test-path\">Path</label>\n                <input \n                    type=\"text\" \n                    id=\"test-path\" \n                    name=\"path\" \n                    placeholder=\"/health\"\n                    value=\"/health\"\n                    class=\"form-control\"\n                >\n            </div>\n            \n            <div class=\"form-group\">\n                <label for=\"test-method\">Method</label>\n                <select id=\"test-method\" name=\"method\" class=\"form-control\">\n                    <option value=\"GET\" selected>GET</option>\n                    <option value=\"POST\">POST</option>\n                    <option value=\"PUT\">PUT</option>\n                    <option value=\"DELETE\">DELETE</option>\n                </select>\n            </div>\n            \n            <div class=\"form-group\">\n                <label for=\"test-headers\">Headers (JSON)</label>\n                <textarea \n                    id=\"test-headers\" \n                    name=\"headers\" \n                    placeholder='{\"Authorization\": \"Bearer token\"}'\n                    rows=\"3\"\n                    class=\"form-control\"\n                >{}</textarea>\n            </div>\n            \n            <div class=\"form-group\">\n                <label for=\"test-body\">Body (JSON)</label>\n                <textarea \n                    id=\"test-body\" \n                    name=\"body\" \n                    placeholder='{\"key\": \"value\"}'\n                    rows=\"3\"\n                    class=\"form-control\"\n                ></textarea>\n            </div>\n            \n            <div class=\"form-actions\">\n                <button type=\"submit\" class=\"btn btn-primary\">Test Connection</button>\n                <button type=\"button\" class=\"btn btn-secondary\" onclick=\"closeModal()\">Cancel</button>\n            </div>\n        </form>\n        \n        <div id=\"testResults\" class=\"test-results\" style=\"display: none;\">\n            <!-- Results will be displayed here -->\n        </div>\n    </div>\n</div>\n```\n\n3. **Add proper form handling**:\n```javascript\ndocument.getElementById('testConnectivityForm').addEventListener('submit', async (e) => {\n    e.preventDefault();\n    \n    const formData = new FormData(e.target);\n    const data = {};\n    \n    // Convert FormData to object\n    for (let [key, value] of formData.entries()) {\n        if (key === 'headers' || key === 'body') {\n            try {\n                data[key] = value ? JSON.parse(value) : {};\n            } catch (err) {\n                showError(`Invalid JSON in ${key} field`);\n                return;\n            }\n        } else {\n            data[key] = value;\n        }\n    }\n    \n    // Show loading state\n    const submitButton = e.target.querySelector('button[type=\"submit\"]');\n    submitButton.disabled = true;\n    submitButton.textContent = 'Testing...';\n    \n    try {\n        await testGatewayConnectivity(data);\n    } finally {\n        submitButton.disabled = false;\n        submitButton.textContent = 'Test Connection';\n    }\n});\n```\n\n4. **Add visual feedback for results**:\n```javascript\nfunction showTestResults(result) {\n    const resultsDiv = document.getElementById('testResults');\n    resultsDiv.style.display = 'block';\n    \n    if (result.success) {\n        resultsDiv.innerHTML = `\n            <div class=\"alert alert-success\">\n                <h4>??? Connection Successful</h4>\n                <p><strong>Status Code:</strong> ${result.status_code}</p>\n                <p><strong>Response Time:</strong> ${result.latency_ms}ms</p>\n                ${result.body ? `<details>\n                    <summary>Response Body</summary>\n                    <pre>${JSON.stringify(result.body, null, 2)}</pre>\n                </details>` : ''}\n            </div>\n        `;\n    } else {\n        resultsDiv.innerHTML = `\n            <div class=\"alert alert-error\">\n                <h4>??? Connection Failed</h4>\n                <p>${result.error || 'Unable to connect to the server'}</p>\n            </div>\n        `;\n    }\n}\n```\n\n**Additional Features to Consider:**\n1. Add timeout configuration\n2. Support for authentication headers\n3. Save successful configurations as templates\n4. Test history/logs\n5. Batch testing for multiple endpoints\n\n**Testing Requirements:**\n- Test with various URL formats\n- Verify error handling for malformed URLs\n- Test with different HTTP methods\n- Ensure headers and body are properly sent\n- Test timeout scenarios\n- Verify UI updates correctly based on results\n\n**Acceptance Criteria:**\n- [ ] Form correctly captures all required fields\n- [ ] URL validation works properly\n- [ ] Test requests are sent successfully\n- [ ] Results are displayed clearly\n- [ ] Error messages are helpful\n- [ ] Loading states are shown during testing\n- [ ] Works for all supported transport types\n\n**Related Issues:**\n- Consider adding WebSocket connection testing\n- Add support for testing with authentication\n- Implement connection test scheduling/monitoring",
      "updatedAt" : 1752225734.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "bug", "help wanted", "good first issue", "triage", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the 'Test Server Connectivity' feature in the Admin UI, which is broken and returns 'Error: Invalid URL: URL is required' when attempting to test gateway connections",
      "validationOrRequirement" : "Form should accept URL and other connection parameters, Test should attempt connection to specified endpoint, Clear success/failure message with details (response time, status code), Should work for different transport types (HTTP, SSE, WebSocket), URL validation works properly, Form correctly captures all required fields",
      "attemptedFixes" : "Check and fix the JavaScript form handler, Update the HTML form to match API expectations, Add proper form handling, Add visual feedback for results",
      "otherNotes" : "The issue appears to be in the UI JavaScript code that's not properly constructing or sending the request.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284523
  }, {
    "issueDTO" : {
      "id" : 3044945782,
      "title" : "Unsuitable function names for loading configs",
      "url" : "https://github.com/ecmwf/WeatherGenerator/issues/218",
      "repositoryName" : "ecmwf/WeatherGenerator",
      "description" : "config: `load_model_config()` and `load_config()` are misleading names. \n\n`load_model_config` : contains model *and* run parameters, e.g. related to learning rate, #epochs etc. So an appropriate name would be load_run_config. It's a good idea to separate the config into a model config and training config but it's not there yet.\n\n`load_config` : this loads and merges the various configs; maybe a good name would be `load_merge_configs`. The function is also missing documentation. In `load_config`, epoch and overwrite_config should also have default arguments `None`.\n\nCC: @grassesi , @tjhunter ",
      "updatedAt" : 1752225014.000000000,
      "user" : "clessig",
      "userHtmlUrl" : "https://github.com/clessig",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29652766?v=4",
      "labels" : [ "enhancement", "infra", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The repository of the WeatherGenerator project",
        "homepage" : "https://weathergenerator.eu/",
        "name" : "WeatherGenerator",
        "fullName" : "ecmwf/WeatherGenerator",
        "htmlUrl" : "https://github.com/ecmwf/WeatherGenerator",
        "gitUrl" : "git://github.com/ecmwf/WeatherGenerator.git",
        "sshUrl" : "git@github.com:ecmwf/WeatherGenerator.git",
        "cloneUrl" : "https://github.com/ecmwf/WeatherGenerator.git",
        "owner" : {
          "login" : "ecmwf",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 61,
        "watchersCount" : 61,
        "size" : 3426,
        "openIssuesCount" : 152,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T16:22:55Z",
        "languages" : {
          "Shell" : 743,
          "Python" : 401666,
          "Jsonnet" : 59163
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "rename functions for loading configs to better reflect their purpose",
      "validationOrRequirement" : "rename functions to better reflect their purpose, separate config into model and training config",
      "attemptedFixes" : "",
      "otherNotes" : "config is merged, missing documentation, epoch and overwrite_config should have default arguments None",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284526
  }, {
    "issueDTO" : {
      "id" : 3222145843,
      "title" : "Use go.mod for determing go version used in Github Actions",
      "url" : "https://github.com/Kuadrant/kuadrant-operator/issues/1417",
      "repositoryName" : "Kuadrant/kuadrant-operator",
      "description" : "# Description\n\nIt is possible to use [the Go version from the `go.mod` file](https://github.com/actions/setup-go?tab=readme-ov-file#getting-go-version-from-the-gomod-file) with the `actions/setup-go@v5` step in our GitHub Actions workflows:\n\n```yaml\n- name: Setup Go\n  uses: actions/setup-go@v5\n  with:\n    go-version-file: go.mod\n```\n\nBy always using the Go version specified in `go.mod`, we will no longer need to manually update the Go version in our GitHub Actions when the project???s Go version changes.\n\n**The goal of this issue is to update all workflows using `actions/setup-go` to retrieve the Go version from `go.mod`.**\n",
      "updatedAt" : 1752224682.000000000,
      "user" : "KevFan",
      "userHtmlUrl" : "https://github.com/KevFan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/24636860?v=4",
      "labels" : [ "size/small", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The Operator to install and manage the lifecycle of the Kuadrant components deployments.",
        "homepage" : "https://kuadrant.io",
        "name" : "kuadrant-operator",
        "fullName" : "Kuadrant/kuadrant-operator",
        "htmlUrl" : "https://github.com/Kuadrant/kuadrant-operator",
        "gitUrl" : "git://github.com/Kuadrant/kuadrant-operator.git",
        "sshUrl" : "git@github.com:Kuadrant/kuadrant-operator.git",
        "cloneUrl" : "https://github.com/Kuadrant/kuadrant-operator.git",
        "owner" : {
          "login" : "Kuadrant",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 43,
        "stargazersCount" : 63,
        "watchersCount" : 63,
        "size" : 15498,
        "openIssuesCount" : 186,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-10T15:50:12Z",
        "languages" : {
          "Dockerfile" : 4133,
          "Shell" : 34610,
          "Makefile" : 49959,
          "Go" : 1423294,
          "Jsonnet" : 2113
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update all workflows using actions/setup-go to retrieve the Go version from go.mod, eliminating the need to manually update the Go version in GitHub Actions when the project's Go version changes.",
      "validationOrRequirement" : "Update all workflows using actions/setup-go to retrieve the Go version from go.mod.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about updating all workflows using actions/setup-go to retrieve the Go version from go.mod. The goal is to no longer manually update the Go version in GitHub Actions when the project's Go version changes.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284530
  }, {
    "issueDTO" : {
      "id" : 3222152846,
      "title" : "Large number of warnings",
      "url" : "https://github.com/vacp2p/nim-libp2p/issues/1519",
      "repositoryName" : "vacp2p/nim-libp2p",
      "description" : "when running `nimble testnative`, I get a wall of warnings. Too many to go into any meaningful detail, but a large hunk is to do with using deprecated functions (e.g. `cancel`)\n\nThis could be a good low-prio/first-issue work item. I'll be casually picking away at these between other work.",
      "updatedAt" : 1752224580.000000000,
      "user" : "Ben-PH",
      "userHtmlUrl" : "https://github.com/Ben-PH",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16680090?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "libp2p implementation in Nim",
        "homepage" : "https://vacp2p.github.io/nim-libp2p/docs/",
        "name" : "nim-libp2p",
        "fullName" : "vacp2p/nim-libp2p",
        "htmlUrl" : "https://github.com/vacp2p/nim-libp2p",
        "gitUrl" : "git://github.com/vacp2p/nim-libp2p.git",
        "sshUrl" : "git@github.com:vacp2p/nim-libp2p.git",
        "cloneUrl" : "https://github.com/vacp2p/nim-libp2p.git",
        "owner" : {
          "login" : "vacp2p",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 63,
        "stargazersCount" : 279,
        "watchersCount" : 279,
        "size" : 69348,
        "openIssuesCount" : 151,
        "subscribersCount" : 29,
        "pushedAt" : "2025-07-11T21:03:54Z",
        "languages" : {
          "Dockerfile" : 1578,
          "Shell" : 3240,
          "Nim" : 2106620,
          "C" : 33151
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To reduce the number of warnings when running nimble testnative",
      "validationOrRequirement" : "using deprecated functions (e.g. cancel) should be avoided",
      "attemptedFixes" : "",
      "otherNotes" : "This issue is considered a good low-priority/first-issue work item.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284532
  }, {
    "issueDTO" : {
      "id" : 1932413576,
      "title" : "Missing translations for Burmese (my)",
      "url" : "https://github.com/symfony/symfony/issues/51897",
      "repositoryName" : "symfony/symfony",
      "description" : "Hello,\n\nThere are some translation work needed for Burmese (my) and we are looking for a **native** speaker to help us out. \n\nHere is a [short example](https://symfony-translations.nyholm.tech/#pr) of what you need to do. There are 4 rules: \n\n1. You must be a Burmese (my) native speaker\n2. You must look at the existing translations and follow the same \"style\" or \"tone\"\n3. You must make your PR to branch 6.4\n4. You must use the correct indentation (number of spaces)\n\nThese are the files that should be updated: \n- [src/Symfony/Component/Security/Core/Resources/translations/security.my.xlf](https://github.com/symfony/symfony/blob/6.4/src/Symfony/Component/Security/Core/Resources/translations/security.my.xlf)\n- [src/Symfony/Component/Validator/Resources/translations/validators.my.xlf](https://github.com/symfony/symfony/blob/6.4/src/Symfony/Component/Validator/Resources/translations/validators.my.xlf)\n\n\n<details>\n<summary>Show related strings</summary>\n\n#### src/Symfony/Component/Security/Core/Resources/translations/security.my.xlf\n\n| Id | English | Translation | Status |\n| -- | -- | -- | -- |\n| 20 | Too many failed login attempts, please try again in %minutes% minutes. | ????????????????????????????????? ??????????????????????????????????????? ??????????????????????????????????????????????????? ??????????????????????????? ???????????????????????????????????? ??????????????????????????????????????????????????? %minutes% ?????????????????????????????????\\|????????????????????????????????? ??????????????????????????????????????? ??????????????????????????????????????????????????? ??????????????????????????? ???????????????????????????????????? ??????????????????????????????????????????????????? %minutes% ????????????????????????????????? | Needs review |\n\n\n#### src/Symfony/Component/Validator/Resources/translations/validators.my.xlf\n\n| Id | English | Translation | Status |\n| -- | -- | -- | -- |\n| 37 | This is not a valid IP address. | ????????????????????????????????? ?????????????????????????????? IP ?????????????????? ???????????????????????? | Needs review |\n| 51 | No temporary folder was configured in php.ini. | php.ini ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? ??????????????????????????? ???????????????????????????????????????????????????????????????????????????????????? | Needs review |\n| 59 | This is not a valid International Bank Account Number (IBAN). | ????????????????????????????????? ?????????????????????????????? ?????????????????????????????? ????????????????????????????????????????????? (IBAN) ???????????????????????? | Needs review |\n| 81 | This is not a valid Business Identifier Code (BIC). | ????????????????????????????????? ?????????????????????????????? ?????????????????????????????? ?????????????????????????????????????????? (BIC) ???????????????????????? | Needs review |\n| 83 | This is not a valid UUID. | ????????????????????????????????? ?????????????????????????????? UUID ???????????????????????? | Needs review |\n| 101 | This value is not a valid CSS color. | ????????????????????????????????? CSS ????????????????????????????????????????????????????????????????????? | Needs review |\n| 102 | This value is not a valid CIDR notation. | ????????????????????????????????? CIDR ???????????????????????????????????????????????????????????????????????? | Needs review |\n| 103 | The value of the netmask should be between {{ min }} and {{ max }}. | ????????????????????????????????????????????????????????? ?????????????????????????????? {{ min }} ??????????????? {{ max }} ???????????????????????????????????? | Needs review |\n| 104 | The filename is too long. It should have {{ filename_max_length }} character or less.\\|The filename is too long. It should have {{ filename_max_length }} characters or less. | ??????????????????????????????????????? ?????????????????????????????????????????? ????????????????????? {{ filename_max_length }} ??????????????????????????? ????????????????????????????????????????????????????????????????????????\\|??????????????????????????????????????? ?????????????????????????????????????????? ????????????????????? {{ filename_max_length }} ??????????????????????????? ???????????????????????????????????????????????????????????????????????? | Needs review |\n| 105 | The password strength is too low. Please use a stronger password. | ??????????????????????????????????????????????????????????????????????????????????????? ??????????????????????????????????????? ????????????????????????????????? ????????????????????? | Needs review |\n| 106 | This value contains characters that are not allowed by the current restriction-level. | ???????????????????????????????????? ????????????????????????????????????????????????????????????????????? ????????????????????????????????????????????? ?????????????????????????????????????????????????????????????????? | Needs review |\n| 107 | Using invisible characters is not allowed. | ??????????????????????????? ???????????????????????????????????????????????? ???????????????????????????????????? ???????????????????????????????????? | Needs review |\n| 108 | Mixing numbers from different scripts is not allowed. | ???????????????????????? ????????????????????????????????????????????? ??????????????????????????????????????? ?????????????????????????????????????????????????????? ???????????????????????????????????? | Needs review |\n| 109 | Using hidden overlay characters is not allowed. | ????????????????????????????????? ?????????????????????????????????????????????????????????????????????????????? ???????????????????????????????????? ???????????????????????????????????? | Needs review |\n| 110 | The extension of the file is invalid ({{ extension }}). Allowed extensions are {{ extensions }}. | ?????????????????????????????????????????????????????????????????? ?????????????????????????????? ({{ extension }})??? ?????????????????????????????????????????? ???????????????????????????????????????????????? {{ extensions }} ???????????????????????? | Needs review |\n| 111 | The detected character encoding is invalid ({{ detected }}). Allowed encodings are {{ encodings }}. | ??????????????????????????????????????? ?????????????????????????????????????????????????????? ?????????????????????????????? ({{ detected }})??? ?????????????????????????????????????????? ???????????????????????????????????????????????? {{ encodings }} ???????????????????????? | Needs review |\n| 112 | This value is not a valid MAC address. | ????????????????????????????????? ?????????????????????????????? MAC ?????????????????? ???????????????????????? | Needs review |\n| 113 | This URL is missing a top-level domain. | ??? URL ???????????? ????????????????????????????????????????????????????????????????????? ???????????????????????????????????? | Needs review |\n| 114 | This value is too short. It should contain at least one word.\\|This value is too short. It should contain at least {{ min }} words. | ????????????????????????????????? ?????????????????????????????????????????????????????? ??????????????????????????? ????????????????????????????????????????????? ???????????????????????????????????????\\|????????????????????????????????? ?????????????????????????????????????????????????????? ??????????????????????????? ???????????????????????? {{ min }} ???????????? ??????????????????????????????????????? | Needs review |\n| 115 | This value is too long. It should contain one word.\\|This value is too long. It should contain {{ max }} words or less. | ????????????????????????????????? ??????????????????????????????????????????????????? ??????????????????????????????????????????????????? ???????????????????????????????????????\\|????????????????????????????????? ??????????????????????????????????????????????????? ???????????????????????? {{ max }} ???????????? ??????????????????????????? ??????????????????????????????????????? ??????????????????????????????????????? | Needs review |\n| 116 | This value does not represent a valid week in the ISO 8601 format. | ????????????????????????????????? ISO 8601 ???????????????????????????????????? ???????????????????????????????????? ???????????????????????????????????? ????????????????????????????????????????????? | Needs review |\n| 117 | This value is not a valid week. | ?????????????????????????????????????????????????????????????????????????????????????????????????????? | Needs review |\n| 118 | This value should not be before week \"{{ min }}\". | ????????????????????????????????? ??????????????????????????? \"{{ min }}\" ???????????????????????? ????????????????????????????????????????????????????????? | Needs review |\n| 119 | This value should not be after week \"{{ max }}\". | ????????????????????????????????? ??????????????????????????? \"{{ max }}\" ??????????????????????????? ????????????????????????????????????????????????????????? | Needs review |\n| 121 | This value is not a valid Twig template. | ????????????????????????????????? ?????????????????????????????? Twig ??????????????????????????????????????????????????? | Needs review |\n\n\n</details>\n\n> [!NOTE]\n> If you want to work on this issue, add a comment to assign it to yourself and let others know that this is already taken.\n",
      "updatedAt" : 1752224440.000000000,
      "user" : "carsonbot",
      "userHtmlUrl" : "https://github.com/carsonbot",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13338611?v=4",
      "labels" : [ "Good first issue", "Help wanted", "Missing translations" ],
      "state" : "OPEN",
      "comments" : [ "I can help to translate it." ],
      "repository" : {
        "description" : "The Symfony PHP framework",
        "homepage" : "https://symfony.com",
        "name" : "symfony",
        "fullName" : "symfony/symfony",
        "htmlUrl" : "https://github.com/symfony/symfony",
        "gitUrl" : "git://github.com/symfony/symfony.git",
        "sshUrl" : "git@github.com:symfony/symfony.git",
        "cloneUrl" : "https://github.com/symfony/symfony.git",
        "owner" : {
          "login" : "symfony",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : false,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 9640,
        "stargazersCount" : 30425,
        "watchersCount" : 30425,
        "size" : 300374,
        "openIssuesCount" : 887,
        "subscribersCount" : 1063,
        "pushedAt" : "2025-07-10T08:50:13Z",
        "languages" : {
          "CSS" : 56186,
          "Shell" : 9654,
          "Hack" : 26,
          "Twig" : 526980,
          "Makefile" : 1859,
          "JavaScript" : 28225,
          "PHP" : 31286415,
          "HTML" : 16804
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to translate the Symfony translations for Burmese (my) language, specifically for the security and validator components.",
      "validationOrRequirement" : "The issue requires a native speaker to review and update the translations, following the same style and tone as the existing translations. The translations need to be updated for the security and validator components, specifically for the files src/Symfony/Component/Security/Core/Resources/translations/security.my.xlf and src/Symfony/Component/Validator/Resources/translations/validators.my.xlf.",
      "attemptedFixes" : "The issue description mentions that a comment was left saying 'I can help to translate it.'",
      "otherNotes" : "The issue is about translating the Symfony translations for Burmese (my) language, specifically for the security and validator components. It requires a native speaker to review and update the translations. The issue is labeled as 'Good first issue', 'Help wanted', and 'Missing translations'.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284539
  }, {
    "issueDTO" : {
      "id" : 3206441780,
      "title" : "Integration with Discord",
      "url" : "https://github.com/my-name-is-samael/BeamJoy/issues/118",
      "repositoryName" : "my-name-is-samael/BeamJoy",
      "description" : "This is a feature request.\n\nAdd some kind of integration with Discord (via a bot or a webhook), so we can get mod action logs in a channel. You could also just add integration with [ChatHook](https://github.com/OfficialLambdax/BeamMP-ChatHook)",
      "updatedAt" : 1752224435.000000000,
      "user" : "sobakintech",
      "userHtmlUrl" : "https://github.com/sobakintech",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/110396005?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Interesting. So you feel the wait for the next release is not long enough? \uD83D\uDE02 \n\nAnyway I will try to include ChatHook mod compatibility/integration for the next release and I will count on your feedback at that time because I do not want to bother creating a discord server, bot, etc.", "Added all chat events for the next version compatibility with ChatHook mod, should also work with default messages (connection, join, leave, message) without duplicates.\nYou will have the option to configure messages lang :\n- In-game under: `Config` > `Server` > `Global Settings` > `Discord ChatHook Language`\n- In settings file under: `bjc.json` > `Server` > `DiscordChatHookLang` (the lang need to be a valid one, as server or clients langs)\n\nOnce again, I will wait for your feedback @sobakintech " ],
      "repository" : {
        "description" : "All-in-One mod for BeamMP",
        "homepage" : "",
        "name" : "BeamJoy",
        "fullName" : "my-name-is-samael/BeamJoy",
        "htmlUrl" : "https://github.com/my-name-is-samael/BeamJoy",
        "gitUrl" : "git://github.com/my-name-is-samael/BeamJoy.git",
        "sshUrl" : "git@github.com:my-name-is-samael/BeamJoy.git",
        "cloneUrl" : "https://github.com/my-name-is-samael/BeamJoy.git",
        "owner" : {
          "login" : "my-name-is-samael",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 36,
        "watchersCount" : 36,
        "size" : 6614,
        "openIssuesCount" : 12,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-11T22:19:34Z",
        "languages" : {
          "Batchfile" : 1000,
          "Lua" : 1752921
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add integration with Discord to get mod action logs in a channel",
      "validationOrRequirement" : "integration with Discord via bot or webhook, compatibility with ChatHook mod, configure messages lang",
      "attemptedFixes" : "ChatHook mod compatibility/integration, added all chat events for next version compatibility with ChatHook mod and default messages",
      "otherNotes" : "ChatHook mod compatibility/integration for the next release, configure messages lang in-game or in settings file",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284543
  }, {
    "issueDTO" : {
      "id" : 3215427083,
      "title" : "TextArea: copy / paste",
      "url" : "https://github.com/linebender/xilem/issues/1127",
      "repositoryName" : "linebender/xilem",
      "description" : "There's commented out code in the `TextArea` implementation, but no actual implementation that works now.\n",
      "updatedAt" : 1752224398.000000000,
      "user" : "waywardmonkeys",
      "userHtmlUrl" : "https://github.com/waywardmonkeys",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/178582?v=4",
      "labels" : [ "masonry", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I think that the correct crate to use here is [copypasta](https://crates.io/crates/copypasta), which should support all platforms properly, and is the solution used by slint. But it might warrant more research. Note that for copypasta, as far as I know, we need to write our own unsafe code for Wayland support (for reasons unknown, this doesn't support raw-window-handle).", "EventCtx may have new methods like set_clipboard_contents which sends a new RenderRootSignal to be handled by event_loop_runner, which sets the clipboard content. For retrieving clipboard contents, we could store it in the RenderRootState and return it from EventCtx.", "> For retrieving clipboard contents, we could store it in the RenderRootState and return it from EventCtx.\n\nI don't think that this works, because we want to only request the user's clipboard content when they ask for it. I think it might need to be asynchronous, i.e. a new event kind?" ],
      "repository" : {
        "description" : "An experimental Rust native UI framework",
        "homepage" : "",
        "name" : "xilem",
        "fullName" : "linebender/xilem",
        "htmlUrl" : "https://github.com/linebender/xilem",
        "gitUrl" : "git://github.com/linebender/xilem.git",
        "sshUrl" : "git@github.com:linebender/xilem.git",
        "cloneUrl" : "https://github.com/linebender/xilem.git",
        "owner" : {
          "login" : "linebender",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 140,
        "stargazersCount" : 4400,
        "watchersCount" : 4400,
        "size" : 5608,
        "openIssuesCount" : 122,
        "subscribersCount" : 73,
        "pushedAt" : "2025-07-11T21:54:21Z",
        "languages" : {
          "Rust" : 1908797,
          "Fluent" : 4533,
          "HTML" : 13431
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "implement clipboard functionality in TextArea component",
      "validationOrRequirement" : "need to write own unsafe code for Wayland support; need to store clipboard content in RenderRootState and return it from EventCtx",
      "attemptedFixes" : "research into copypasta crate and EventCtx methods; consideration of asynchronous approach",
      "otherNotes" : "copypasta crate may be used for clipboard functionality, but requires unsafe code for Wayland support; EventCtx may have new methods for setting and retrieving clipboard contents; asynchronous approach may be needed",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284547
  }, {
    "issueDTO" : {
      "id" : 2422667421,
      "title" : "Support additional languages/translations",
      "url" : "https://github.com/appreciated/apexcharts-flow/issues/191",
      "repositoryName" : "appreciated/apexcharts-flow",
      "description" : "It looks like the original apexcharts repository provides a lot more translations than this repository currently does:\r\nhttps://github.com/apexcharts/apexcharts.js/tree/main/src/locales\r\n\r\nIt would be easy to integrate all missing translations here. \r\n",
      "updatedAt" : 1752224201.000000000,
      "user" : "Loahrs",
      "userHtmlUrl" : "https://github.com/Loahrs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20272232?v=4",
      "labels" : [ "will accept PR", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "ApexCharts.js wrapper for the Vaadin Platform",
        "homepage" : "",
        "name" : "apexcharts-flow",
        "fullName" : "appreciated/apexcharts-flow",
        "htmlUrl" : "https://github.com/appreciated/apexcharts-flow",
        "gitUrl" : "git://github.com/appreciated/apexcharts-flow.git",
        "sshUrl" : "git@github.com:appreciated/apexcharts-flow.git",
        "cloneUrl" : "https://github.com/appreciated/apexcharts-flow.git",
        "owner" : {
          "login" : "appreciated",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 46,
        "stargazersCount" : 80,
        "watchersCount" : 80,
        "size" : 1003,
        "openIssuesCount" : 37,
        "subscribersCount" : 13,
        "pushedAt" : "2024-09-19T20:28:39Z",
        "languages" : {
          "TypeScript" : 18227,
          "Java" : 509021,
          "CSS" : 194,
          "HTML" : 507
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support additional languages/translations by integrating missing translations.",
      "validationOrRequirement" : "Integrate all missing translations from the original apexcharts repository.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to integrating missing translations from the original apexcharts repository, and it's considered a good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284549
  }, {
    "issueDTO" : {
      "id" : 3216820607,
      "title" : "`Stack` widget",
      "url" : "https://github.com/linebender/xilem/issues/1137",
      "repositoryName" : "linebender/xilem",
      "description" : "A `Stack` widget is a container that only shows a single child at a time.\n\nThis can be used for something like a tab stack but also other things where you want to swap between various \"pages\" of UI while keeping the state loaded.\n\nFlutter calls this an `IndexedStack` which is nice as it leaves the term `Stack` for the various forms of stack.\n",
      "updatedAt" : 1752224182.000000000,
      "user" : "waywardmonkeys",
      "userHtmlUrl" : "https://github.com/waywardmonkeys",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/178582?v=4",
      "labels" : [ "masonry", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An experimental Rust native UI framework",
        "homepage" : "",
        "name" : "xilem",
        "fullName" : "linebender/xilem",
        "htmlUrl" : "https://github.com/linebender/xilem",
        "gitUrl" : "git://github.com/linebender/xilem.git",
        "sshUrl" : "git@github.com:linebender/xilem.git",
        "cloneUrl" : "https://github.com/linebender/xilem.git",
        "owner" : {
          "login" : "linebender",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 140,
        "stargazersCount" : 4400,
        "watchersCount" : 4400,
        "size" : 5608,
        "openIssuesCount" : 122,
        "subscribersCount" : 73,
        "pushedAt" : "2025-07-11T21:54:21Z",
        "languages" : {
          "Rust" : 1908797,
          "Fluent" : 4533,
          "HTML" : 13431
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to create a `Stack` widget in Flutter, which can be used for various UI swapping scenarios.",
      "validationOrRequirement" : "The requirement is to implement a `Stack` widget in Flutter, with a focus on creating a good first issue.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to a widget in Flutter, specifically a container that displays a single child at a time, which can be used for tab stacks or other UI swapping.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284553
  }, {
    "issueDTO" : {
      "id" : 3182942619,
      "title" : "[Feature] support specified time to the monitoring cycle to collect data",
      "url" : "https://github.com/apache/hertzbeat/issues/3517",
      "repositoryName" : "apache/hertzbeat",
      "description" : "### Feature Request\n\n![Image](https://github.com/user-attachments/assets/a427f32f-7994-44fa-a955-3c91c7114aba)\n??????????????????????????????????????????,???????????????????????????????????????????????????8??????????????????Crontab?????????\n\n### Is your feature request related to a problem? Please describe\n\n_No response_\n\n### Describe the solution you'd like\n\n_No response_\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752223871.000000000,
      "user" : "mifengwei",
      "userHtmlUrl" : "https://github.com/mifengwei",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7227426?v=4",
      "labels" : [ "new feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I would like to try, plz assign to me. \uD83D\uDE4F", "hi @GEM0816g It would be better if you tell us your plan before implementing it.", "Please note that not all issue requirements feature will be accepted and implemented. Only those marked with `good first issue` tag will be accepted.", "Sorry, I am currently unable to perform this feature", "ScheduledExecutorService is perfect for this feature.\nor we can persistence the task???and use the single thread to scan and execute the task." ],
      "repository" : {
        "description" : "Apache HertzBeat(incubating) is a real-time monitoring system with agentless, performance cluster, prometheus-compatible, custom monitoring and status page building capabilities.",
        "homepage" : "https://hertzbeat.apache.org/",
        "name" : "hertzbeat",
        "fullName" : "apache/hertzbeat",
        "htmlUrl" : "https://github.com/apache/hertzbeat",
        "gitUrl" : "git://github.com/apache/hertzbeat.git",
        "sshUrl" : "git@github.com:apache/hertzbeat.git",
        "cloneUrl" : "https://github.com/apache/hertzbeat.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1143,
        "stargazersCount" : 6432,
        "watchersCount" : 6432,
        "size" : 313926,
        "openIssuesCount" : 297,
        "subscribersCount" : 66,
        "pushedAt" : "2025-07-11T16:26:25Z",
        "languages" : {
          "PowerShell" : 3320,
          "Java" : 4787295,
          "CSS" : 824503,
          "HTML" : 485964,
          "TypeScript" : 831360,
          "Dockerfile" : 2591,
          "Shell" : 21764,
          "Batchfile" : 7811,
          "ANTLR" : 7083,
          "SCSS" : 2990,
          "JavaScript" : 136930,
          "Less" : 351219,
          "Python" : 2224
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a feature to support specifying a time for the monitoring cycle to collect data, preferably using Crontab.",
      "validationOrRequirement" : "The issue requires support for configuring specific time for the monitoring cycle, and mentions that only issues marked with `good first issue` tag will be accepted.",
      "attemptedFixes" : "ScheduledExecutorService is mentioned as a potential solution, and persistence of tasks with single thread scanning and execution is also suggested.",
      "otherNotes" : "The issue is related to a feature request for supporting specified time for monitoring cycle to collect data, and mentions Crontab as a preferred option.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284557
  }, {
    "issueDTO" : {
      "id" : 3222104317,
      "title" : "Add test for pure components",
      "url" : "https://github.com/bytecodealliance/ComponentizeJS/issues/250",
      "repositoryName" : "bytecodealliance/ComponentizeJS",
      "description" : "We should add testing that checks for *pure* components - ensuring that components *without* all the \"extra\" exports/imports of StarlingMonkey can be built. \n\nThis would be essentially a regression test of whether a component with all features disables produces a component with *none* of the related imports/exports (ideally with no extraneous imports/exports at all).",
      "updatedAt" : 1752223602.000000000,
      "user" : "vados-cosmonic",
      "userHtmlUrl" : "https://github.com/vados-cosmonic",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/123968127?v=4",
      "labels" : [ "tests", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "JS -> WebAssembly Component",
        "homepage" : "",
        "name" : "ComponentizeJS",
        "fullName" : "bytecodealliance/ComponentizeJS",
        "htmlUrl" : "https://github.com/bytecodealliance/ComponentizeJS",
        "gitUrl" : "git://github.com/bytecodealliance/ComponentizeJS.git",
        "sshUrl" : "git@github.com:bytecodealliance/ComponentizeJS.git",
        "cloneUrl" : "https://github.com/bytecodealliance/ComponentizeJS.git",
        "owner" : {
          "login" : "bytecodealliance",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 37,
        "stargazersCount" : 309,
        "watchersCount" : 309,
        "size" : 31135,
        "openIssuesCount" : 38,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-08T16:21:02Z",
        "languages" : {
          "C++" : 20822,
          "Shell" : 436,
          "Rust" : 139696,
          "CMake" : 1937,
          "Makefile" : 2328,
          "JavaScript" : 88104
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add regression testing to ensure components with all features disabled produce components with none of the related imports/exports.",
      "validationOrRequirement" : "The test should check for pure components without all the 'extra' exports/imports of StarlingMonkey and ideally with no extraneous imports/exports at all.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue aims to add testing for pure components in the ComponentizeJS project, focusing on ensuring components without extra exports/imports can be built.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284561
  }, {
    "issueDTO" : {
      "id" : 3159380010,
      "title" : "[Enhancement] Add IF EXISTS to truncate table",
      "url" : "https://github.com/questdb/questdb/issues/5763",
      "repositoryName" : "questdb/questdb",
      "description" : "### Is your feature request related to a problem?\n\nA small usability improvement would be to have `IF EXISTS` in `TRUNCATE TABLE` so it will not error when table is missing, as we have with `DROP TABLE`\n\n### Describe the solution you'd like.\n\nBoth\n```\nTRUNCATE TABLE ratings;\n```\nand\n```\nTRUNCATE TABLE IF EXISTS ratings;\n```\n\n### Describe alternatives you've considered.\n\nAt the moment I truncate and get an error. It'd be nice if I didn't need error control when I choose to ignore the fact table might yet not exist.\n\n### Full Name:\n\njavier ramirez\n\n### Affiliation:\n\nquestdb\n\n### Additional context\n\nVery minor thing. If implementation is not trivial, happy to ignore it.",
      "updatedAt" : 1752223360.000000000,
      "user" : "javier",
      "userHtmlUrl" : "https://github.com/javier",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3839?v=4",
      "labels" : [ "Friction", "Good first issue", "Enhancement", "SQL" ],
      "state" : "OPEN",
      "comments" : [ "I've got draft PR for this one: https://github.com/questdb/questdb/pull/5780\nI have some questions on PR, and I will need additional guidance to finalize this. @javier ", "Thanks!\n\nPlease, do ask any questions in the contributors channel in slack \n\nhttps://questdb.slack.com/archives/C0394MS0FMF", "@javier , Hi! I'd like to work on this issue as my first open-source contribution. Please assign it to me. \uD83D\uDE42\n", "Impllemented the feature https://github.com/questdb/questdb/pull/5856 but CI/CD pipeline shows infrastructure errors unrelated to this change:\n\nRust test failures (this is a Java-only change)\nMissing log files (build system issue)\nArtifact publishing problems (infrastructure issue)\nLocal testing shows all functionality works correctly.", "Add `IF EXISTS` syntax for `TRUNCATE TABLE`:\nTRUNCATE TABLE IF EXISTS ratings;", "**Title:**  \nSupport `IF EXISTS` for `TRUNCATE TABLE` statement\n\n**Is your feature request related to a problem? Please describe.**  \nA small usability improvement would be to have `IF EXISTS` in `TRUNCATE TABLE` so it will not error when the table is missing, similar to how `DROP TABLE IF EXISTS` works. Currently, attempting to truncate a non-existent table results in an error, which requires additional error handling if I want to ignore the absence of the table.\n\n**Describe the solution you'd like**  \nSupport both of the following statements:\n```\nTRUNCATE TABLE ratings;\nTRUNCATE TABLE IF EXISTS ratings;\n```\nWith the second form (`IF EXISTS`), the statement should not error if the table does not exist.\n\n**Describe alternatives you've considered**  \nAt the moment, I truncate and get an error if the table is missing. It would be nice if I didn't need error control when I choose to ignore the fact the table might not yet exist.\n\n**Full Name:**  \njavier ramirez\n\n**Affiliation:**  \nquestdb\n\n**Additional context**  \nVery minor thing. If implementation is not trivial, happy to ignore it.", "> ### Is your feature request related to a problem?\n> A small usability improvement would be to have `IF EXISTS` in `TRUNCATE TABLE` so it will not error when table is missing, as we have with `DROP TABLE`\n> \n> ### Describe the solution you'd like.\n> Both\n> \n> ```\n> TRUNCATE TABLE ratings;\n> ```\n> \n> and\n> \n> ```\n> TRUNCATE TABLE IF EXISTS ratings;\n> ```\n> \n> ### Describe alternatives you've considered.\n> At the moment I truncate and get an error. It'd be nice if I didn't need error control when I choose to ignore the fact table might yet not exist.\n> \n> ### Full Name:\n> javier ramirez\n> \n> ### Affiliation:\n> questdb\n> \n> ### Additional context\n> Very minor thing. If implementation is not trivial, happy to ignore it.\n\nWorkaround (Current)\nFor now, you'd need to handle this in your application logic:\nsql-- Check if table exists first\nSELECT table_name FROM information_schema.tables \nWHERE table_name = 'ratings';\n\n-- Then conditionally truncate\nOr use exception handling in your application code.\nRecommendation\nThis seems like a low-risk, high-value addition that would improve developer experience. The implementation should be straightforward since the pattern already exists for DROP TABLE IF EXISTS." ],
      "repository" : {
        "description" : "QuestDB is a high performance, open-source, time-series database",
        "homepage" : "https://questdb.com",
        "name" : "questdb",
        "fullName" : "questdb/questdb",
        "htmlUrl" : "https://github.com/questdb/questdb",
        "gitUrl" : "git://github.com/questdb/questdb.git",
        "sshUrl" : "git@github.com:questdb/questdb.git",
        "cloneUrl" : "https://github.com/questdb/questdb.git",
        "owner" : {
          "login" : "questdb",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1440,
        "stargazersCount" : 15752,
        "watchersCount" : 15752,
        "size" : 838758,
        "openIssuesCount" : 720,
        "subscribersCount" : 135,
        "pushedAt" : "2025-07-12T00:58:14Z",
        "languages" : {
          "C#" : 16645,
          "Java" : 44299962,
          "C++" : 2337696,
          "Rust" : 1147373,
          "C" : 337963,
          "CMake" : 23939,
          "Makefile" : 816,
          "Go" : 16779,
          "HTML" : 5333,
          "Dockerfile" : 4445,
          "Shell" : 22216,
          "R" : 3087,
          "RenderScript" : 1,
          "JavaScript" : 31109,
          "PHP" : 11038,
          "Assembly" : 333093,
          "Python" : 33319,
          "DTrace" : 300
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add IF EXISTS to truncate table, allowing the statement to not error if the table does not exist, and supporting both TRUNCATE TABLE and TRUNCATE TABLE IF EXISTS statements.",
      "validationOrRequirement" : "The implementation should be straightforward since the pattern already exists for DROP TABLE IF EXISTS.",
      "attemptedFixes" : "The feature has been implemented in a draft PR (https://github.com/questdb/questdb/pull/5780) but there were some issues with the CI/CD pipeline (Rust test failures, missing log files, artifact publishing problems) unrelated to this change.",
      "otherNotes" : "The issue is related to a problem where attempting to truncate a non-existent table results in an error, and the solution is to support both TRUNCATE TABLE and TRUNCATE TABLE IF EXISTS statements, allowing the statement to not error if the table does not exist.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284567
  }, {
    "issueDTO" : {
      "id" : 3103762267,
      "title" : "Facility Type dropdown in Edit Facility page needs responsiveness",
      "url" : "https://github.com/ohcnetwork/care_fe/issues/12467",
      "repositoryName" : "ohcnetwork/care_fe",
      "description" : "**Describe the bug**\nLack of responsiveness in dropdown of Facility type. We can use drawer instead of Dialog.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Go to [link](https://care.ohc.network/facility/2fbb0809-b62c-4c53-816e-f1404f096c5e/settings/general)\n2. Click on Facility Type\n3. See error\n\n**Expected behavior**\nThere should be proper responsiveness\n\n**Screenshots**\n\n<img width=\"482\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5ec959b3-3113-46cd-b045-bfe38d0e9abe\" />\n\n**Desktop (please complete the following information):**\n\n- OS: [e.g. iOS]\n- Browser [e.g. chrome, safari]\n- Version [e.g. 22]\n\n**Smartphone (please complete the following information):**\n\n- Device: [e.g. iPhone6]\n- OS: [e.g. iOS8.1]\n- Browser [e.g. stock browser, safari]\n- Version [e.g. 22]\n\n**Additional context**\nAdd any other context about the problem here.\n\n---\n\n### \uD83D\uDEA8 DO NOT EDIT BELOW THIS LINE \uD83D\uDEA8\n\n### Instructions for Requesting Assignment:\n\nTo request assignment, please clearly outline your solution and timeline by commenting on the issue using the format below:\n\n**Describe your solution clearly:**\nProvide a detailed explanation of your proposed solution, including your approach, key implementation steps, and relevant examples or references. Mention any dependencies, assumptions, or risks you foresee that might affect your timeline or implementation.\n\n**Expected Timeline:**\n- End date: [Expected submission date of a completed Pull Request]\n\n**Additional Context:**\nInclude any other relevant context, links, screenshots, or resources that support your proposed solution.\n\n> \uD83D\uDEA8 Your assignment may be unassigned if there is no activity or progress within the stated timeline unless communicated clearly and agreed upon.\n",
      "updatedAt" : 1752222909.000000000,
      "user" : "Tanuj1718",
      "userHtmlUrl" : "https://github.com/Tanuj1718",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/125687187?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "https://github.com/user-attachments/assets/115e57db-b83c-4c2b-bd68-6c219a156da7\n\nHey @Tanuj1718, I hope this changes the fixes the issue, can i get assigned to this issue ?@rithviknishad .\nETA: immediately", "> Recording.2025-05-31.194253.mp4\n> \n> Hey [@Tanuj1718](https://github.com/Tanuj1718), I hope this changes the fixes the issue, can i get assigned to this issue ?[@rithviknishad](https://github.com/rithviknishad) . ETA: immediately\n\nAssigned, keep in mind that you do need to adjust the search input (shown in the video). Check drawers elsewhere.", "Hey @Jacobjeevan, raised a PR for this issue, review it once.", "Hey Team, Can I take this up ? \nEta: eod\nApproach:- use Autocomplete which already has popover for large and sheet for small screen\ncc: @rithviknishad @Jacobjeevan ", "@AdityaJ2305 let one of the new interns take it up \uD83D\uDC4D " ],
      "repository" : {
        "description" : "Care is a Digital Public Good enabling TeleICU & Decentralised Administration of Healthcare Capacity across States.",
        "homepage" : "https://care.ohc.network",
        "name" : "care_fe",
        "fullName" : "ohcnetwork/care_fe",
        "htmlUrl" : "https://github.com/ohcnetwork/care_fe",
        "gitUrl" : "git://github.com/ohcnetwork/care_fe.git",
        "sshUrl" : "git@github.com:ohcnetwork/care_fe.git",
        "cloneUrl" : "https://github.com/ohcnetwork/care_fe.git",
        "owner" : {
          "login" : "ohcnetwork",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 834,
        "stargazersCount" : 537,
        "watchersCount" : 537,
        "size" : 55125,
        "openIssuesCount" : 219,
        "subscribersCount" : 20,
        "pushedAt" : "2025-07-11T14:40:03Z",
        "languages" : {
          "TypeScript" : 4936598,
          "Dockerfile" : 560,
          "CSS" : 7532,
          "JavaScript" : 9703,
          "HTML" : 3683
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to make the Facility Type dropdown in the Edit Facility page responsive.",
      "validationOrRequirement" : "The issue requires a responsive dropdown in the Edit Facility page. The expected behavior is that the dropdown should be properly responsive.",
      "attemptedFixes" : "The issue has been assigned to multiple people, including @Tanuj1718, @rithviknishad, and @Jacobjeevan. @Tanuj1718 has also raised a PR for this issue. The suggested approach is to use Autocomplete with a popover for large screens and a sheet for small screens.",
      "otherNotes" : "The issue is about the Facility Type dropdown in the Edit Facility page, which lacks responsiveness. The suggested fix is to use a drawer instead of a dialog. The author, @Tanuj1718, has also provided a video recording of the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284573
  }, {
    "issueDTO" : {
      "id" : 3208747779,
      "title" : "Swipe actions not available to TalkBack users",
      "url" : "https://github.com/thunderbird/thunderbird-android/issues/9430",
      "repositoryName" : "thunderbird/thunderbird-android",
      "description" : "### Checklist\n\n- [x] I have used the search function to see if someone else has already submitted the same bug report.\n- [x] I will describe the problem with as much detail as possible.\n\n### App\n\nThunderbird for Android\n\n### App version\n\n11.0b4\n\n### Where did you get the app from?\n\nGoogle Play\n\n### Android version\n\n14\n\n### Device model\n\nPixel 5\n\n### Steps to reproduce\n\n1. Turn on TalkBack.\n2. Open Thunderbird.\n3. Open a folder.\n4. Navigate with TalkBack to one of the messages in the message list.\n\n### Expected behavior\n\n- Tapping with three fingers on the message brings up the TalkBack menu. One of the options is \"Actions\", which allows the user to choose the left or right swipe actions.\n- Swiping up or down on the message cycles through the left or right swipe actions.\n\n### Background\n\nTo better serve Thunderbird users with TalkBack enabled, I???d like to request [Accessibility Actions](https://developer.android.com/guide/topics/ui/accessibility/principles#accessibility-actions) be added to the message list.\n\nThe available actions should at least match the currently configured [swipe actions](https://blog.thunderbird.net/2022/11/thunderbird-android-update-k-9-mail-6-400-adds-customizable-swipe-actions) (Toggle selection, Mark as read/unread, Add/remove star, Archive, Delete, Spam, or Move). \n\nAn example of an Android app with Accessibility Actions is Raccoon, a social media client for Mastodon and Friendica. (See their [commit #567](https://github.com/LiveFastEatTrashRaccoon/RaccoonForFriendica/pull/567) for the rationale.)\n\n- Each post has several buttons below it: reply, reshare, add to favorites, add to bookmarks, and options. \n- If Accessibility Actions were not enabled, then when navigating with TalkBack, the user would encounter each of these buttons, one at a time.\n- Instead, with Accessibility Actions enabled, TalkBack only stops once at each post. The buttons are not focused. Instead, TalkBack tells the user: ???Actions available. Swipe up or swipe down and double tab to activate.???\n- The user can swipe down to cycle through the following actions: reply, reshare, add to favorites, add to bookmarks, link to poster, options, or activate which loads the post into a view by itself, equivalent to tapping in the post body.\n\n#### Demo\n\nhttps://github.com/user-attachments/assets/0e22caaf-ef40-4126-84b0-a9326838b35d\n\n[Demo transcript](https://github.com/user-attachments/files/21101880/raccoon-demo.txt)\n\nThis setup allows users to quickly browse posts with a minimum number of swipes, while still having access to quick actions.\n\nBy contrast, the official Android Mastodon app iterates through each button under each post. There appears to be no way to jump from one post to another, so browsing a timeline with TalkBack is more time-consuming.\n\n### Implementation in Thunderbird\n\n- An example use case for Thunderbird is: a user is browsing newly arrived messages. Several messages are marketing emails, and the user chooses to delete them directly from the timeline. The user saves time by not navigating to each email individually.\n\n- I believe Accessibility Actions are popular with blind users, based on [these poll results from 23 Feb 2025](https://a11y.social/@dankeck/114054760188213623 ) where 77% of the 30 respondents like using them. \n\n- It???d be important to do some user research to determine which actions should be included. Bonus points if the actions and their ordering are configurable. This way, a user's most-used action can be available with just one swipe.\n\n\n\n### Actual behavior\n\nNo Accessibility Actions are available to the user. \n\n### Logs\n\n_No response_",
      "updatedAt" : 1752222301.000000000,
      "user" : "dankeck",
      "userHtmlUrl" : "https://github.com/dankeck",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/86371013?v=4",
      "labels" : [ "type: bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Thunderbird for Android ??? Open Source Email App for Android (fka K-9 Mail)",
        "homepage" : "https://thunderbird.net/mobile",
        "name" : "thunderbird-android",
        "fullName" : "thunderbird/thunderbird-android",
        "htmlUrl" : "https://github.com/thunderbird/thunderbird-android",
        "gitUrl" : "git://github.com/thunderbird/thunderbird-android.git",
        "sshUrl" : "git@github.com:thunderbird/thunderbird-android.git",
        "cloneUrl" : "https://github.com/thunderbird/thunderbird-android.git",
        "owner" : {
          "login" : "thunderbird",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2600,
        "stargazersCount" : 12189,
        "watchersCount" : 12189,
        "size" : 153903,
        "openIssuesCount" : 837,
        "subscribersCount" : 363,
        "pushedAt" : "2025-07-11T20:58:43Z",
        "languages" : {
          "Java" : 2129634,
          "Shell" : 15322,
          "AIDL" : 1946,
          "Kotlin" : 6539022,
          "Python" : 31547
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add Swipe actions not available to TalkBack users in Thunderbird for Android, providing Accessibility Actions similar to other apps, allowing users to quickly browse posts with a minimum number of swipes.",
      "validationOrRequirement" : "The issue requires the implementation of Accessibility Actions in Thunderbird for Android, matching the currently configured swipe actions, with a minimum of Toggle selection, Mark as read/unread, Add/remove star, Archive, Delete, Spam, or Move. The actions should be configurable and the ordering should be determined through user research.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description.",
      "otherNotes" : "The issue is about adding Swipe actions not available to TalkBack users in Thunderbird for Android. The goal is to provide Accessibility Actions similar to other apps like Raccoon, allowing users to quickly browse posts with a minimum number of swipes. The issue includes a demo and poll results to support the request. The author wants to include configurable actions and user research to determine which actions should be included.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284580
  }, {
    "issueDTO" : {
      "id" : 3024452060,
      "title" : "[Platform:StackManagement:SnapshotAndRestore:Add policy page]Fields missing title from announcement",
      "url" : "https://github.com/elastic/kibana/issues/219366",
      "repositoryName" : "elastic/kibana",
      "description" : "**Description**\nDialog modal, flyout, field visible title should be announced for the users, especially using assistive technology to know what dialog modal, flyout opened, what field is active and what is needed to enter in it.\n\n**Preconditions**\nAnalytics -> Stack Management -> Snapshot and Restore -> Add policy page.\nUse Screen Reader (NVDA).\n\n**Steps to reproduce**\n\n1.Navigate to Snapshot name, Repository fields.\n2.Observe screen reader.\n\nUI elements + NVDA Speech Viewer\n![Image](https://github.com/user-attachments/assets/777dcb7b-e4a3-4446-9e49-c75e2cad9006)\n\n**Actual Result**\n\n* Fields are announced without names, only placeholder text is announced.\n\n**Expected Result**\n\n* Fields are announced with names (\"Snapshot name <daily-snap-... edit blank\").\n\n**Meta Issue**\n\n**Kibana Version:** 8.18.0-SNAPSHOT\n\n**OS:** Windows 11 Pro\n\n**Browser:** Chrome Version 131.0.6778.140 (Official Build) (64-bit)\n\n**Screen reader:** NVDA\n\n**WCAG or Vendor Guidance (optional)**\n \n- Understanding SC 4.1.2: Name, Role, Value (Level A)(https://www.w3.org/WAI/WCAG22/Understanding/name-role-value.html)\n\nRelated to:  https://github.com/elastic/kibana-team/issues/1559",
      "updatedAt" : 1752222246.000000000,
      "user" : "L1nBra",
      "userHtmlUrl" : "https://github.com/L1nBra",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/178042654?v=4",
      "labels" : [ "defect-level-2", "Feature:Snapshot and Restore", "impact:high", "platform-accessibility", "Team:Kibana Management", "Project:Accessibility", "WCAG A", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Pinging @elastic/kibana-accessibility (Project:Accessibility)", "Pinging @elastic/kibana-management (Team:Kibana Management)" ],
      "repository" : {
        "description" : "Your window into the Elastic Stack",
        "homepage" : "https://www.elastic.co/products/kibana",
        "name" : "kibana",
        "fullName" : "elastic/kibana",
        "htmlUrl" : "https://github.com/elastic/kibana",
        "gitUrl" : "git://github.com/elastic/kibana.git",
        "sshUrl" : "git@github.com:elastic/kibana.git",
        "cloneUrl" : "https://github.com/elastic/kibana.git",
        "owner" : {
          "login" : "elastic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 8393,
        "stargazersCount" : 20574,
        "watchersCount" : 20574,
        "size" : 10549670,
        "openIssuesCount" : 13302,
        "subscribersCount" : 845,
        "pushedAt" : "2025-07-12T00:03:43Z",
        "languages" : {
          "MDX" : 2692507,
          "CSS" : 205865,
          "Standard ML" : 3033,
          "Handlebars" : 36535,
          "Makefile" : 5205,
          "HTML" : 19095,
          "Perl" : 12381,
          "Nunjucks" : 118640,
          "EJS" : 12706,
          "TypeScript" : 255927723,
          "Dockerfile" : 15257,
          "Shell" : 432108,
          "Starlark" : 40163,
          "PEG.js" : 20672,
          "Batchfile" : 5169,
          "ANTLR" : 41968,
          "SCSS" : 127063,
          "JavaScript" : 8674841,
          "Python" : 7624
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a policy page to the Snapshot and Restore feature in Kibana, and ensure that the fields in the dialog modal, flyout are announced with names for users using assistive technology.",
      "validationOrRequirement" : "The issue is related to WCAG SC 4.1.2: Name, Role, Value (Level A) (https://www.w3.org/WAI/WCAG22/Understanding/name-role-value.html) and the requirement is that fields should be announced with names.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description.",
      "otherNotes" : "The issue is related to Kibana Version 8.18.0-SNAPSHOT, OS: Windows 11 Pro, Browser: Chrome Version 131.0.6778.140 (Official Build) (64-bit), Screen reader: NVDA. It's a high-impact issue and is good for first-time contributors. The issue is also related to #1559.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284587
  }, {
    "issueDTO" : {
      "id" : 3194175293,
      "title" : "Refactor `OpenExternalFileAction`",
      "url" : "https://github.com/JabRef/jabref/issues/13431",
      "repositoryName" : "JabRef/jabref",
      "description" : "Split `org.jabref.gui.maintable.OpenExternalFileAction` into `OpenSingleExternalFileAction` and `OpenSelectedEntriesFilesAction`\n  - The functionality of `entry == null` moves to `OpenSelectedEntriesFilesAction`\n  - No `entry` and `linkedFile` variables for `OpenSelectedEntriesFilesAction`\n  - Single constructors for both\n\n* No CHANGELOG.md entry as this is not user facing.\n* No tests needed\n",
      "updatedAt" : 1752222159.000000000,
      "user" : "koppor",
      "userHtmlUrl" : "https://github.com/koppor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1366654?v=4",
      "labels" : [ "\uD83D\uDCCC Pinned", "dev: code-quality", "good first issue", "\uD83D\uDCCD Assigned" ],
      "state" : "OPEN",
      "comments" : [ "Hey, iam new to Open source contribution, look like i can help on this issue ..", "\uD83D\uDC4B Hey, looks like you???re eager to work on this issue???great! \uD83C\uDF89 It also looks like you skipped reading our [CONTRIBUTING.md](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md), which explains exactly how to participate. No worries, it happens to the best of us. Give it a read, and you???ll discover the ancient wisdom of assigning issues to yourself. Trust me, it???s worth it. \uD83D\uDE80\n<!-- thollander/actions-comment-pull-request \"wisdom\" -->", "/assign-me", "\uD83D\uDC4B Hey @Muskan244, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80" ],
      "repository" : {
        "description" : "Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases",
        "homepage" : "https://www.jabref.org",
        "name" : "jabref",
        "fullName" : "JabRef/jabref",
        "htmlUrl" : "https://github.com/JabRef/jabref",
        "gitUrl" : "git://github.com/JabRef/jabref.git",
        "sshUrl" : "git@github.com:JabRef/jabref.git",
        "cloneUrl" : "https://github.com/JabRef/jabref.git",
        "owner" : {
          "login" : "JabRef",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2861,
        "stargazersCount" : 3942,
        "watchersCount" : 3942,
        "size" : 249107,
        "openIssuesCount" : 582,
        "subscribersCount" : 113,
        "pushedAt" : "2025-07-11T22:29:41Z",
        "languages" : {
          "PowerShell" : 2037,
          "Java" : 11216891,
          "CSS" : 74176,
          "TeX" : 758587,
          "AppleScript" : 1721,
          "XSLT" : 151843,
          "Just" : 1194,
          "Shell" : 9305,
          "Batchfile" : 637,
          "ANTLR" : 9176,
          "BibTeX Style" : 78034,
          "Ruby" : 507,
          "Python" : 22282
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor `OpenExternalFileAction` into two separate actions: `OpenSingleExternalFileAction` and `OpenSelectedEntriesFilesAction`",
      "validationOrRequirement" : "Split `org.jabref.gui.maintable.OpenExternalFileAction` into `OpenSingleExternalFileAction` and `OpenSelectedEntriesFilesAction`. Move functionality of `entry == null` to `OpenSelectedEntriesFilesAction`. No `entry` and `linkedFile` variables for `OpenSelectedEntriesFilesAction`. Single constructors for both",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "No CHANGELOG.md entry as this is not user facing. No tests needed. Exploring CONTRIBUTING guidelines, workspace setup guidelines, JabRef Guru, Gitter chat, developer FAQs, and opening a draft pull request early on are recommended.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284592
  }, {
    "issueDTO" : {
      "id" : 3222023268,
      "title" : "[Spark4] AlterTableCommandDatasetBuilder turned off for Spark 4 integration",
      "url" : "https://github.com/OpenLineage/OpenLineage/issues/3884",
      "repositoryName" : "OpenLineage/OpenLineage",
      "description" : "`AlterTableCommandDatasetBuilder` has been disabled for Spark4 in `Spark40DatasetBuilderFactory` class because of: \n```\njava.lang.NoClassDefFoundError: org/apache/spark/sql/catalyst/plans/logical/AlterColumn\n\tat io.openlineage.spark32.agent.lifecycle.plan.AlterTableCommandDatasetBuilder.isDefinedAtLogicalPlan(AlterTableCommandDatasetBuilder.java:51) ~[openlineage-spark-agent_2.13-1.35.0-SNAPSHOT-shadow.jar:1.35.0-SNAPSHOT]\n\tat io.openlineage.spark.api.AbstractQueryPlanOutputDatasetBuilder.lambda$jobNameSuffixFromLogicalPlan$3(AbstractQueryPlanOutputDatasetBuilder.java:76) ~[openlineage-spark-agent_2.13-1.35.0-SNAPSHOT-shadow.jar:1.35.0-SNAPSHOT]\n\tat java.base/java.util.Optional.filter(Optional.java:218) ~[?:?]\n\tat io.openlineage.spark.api.AbstractQueryPlanOutputDatasetBuilder.jobNameSuffixFromLogicalPlan(AbstractQueryPlanOutputDatasetBuilder.java:76) ~[openlineage-spark-agent_2.13-1.35.0-SNAPSHOT-shadow.jar:1.35.0-SNAPSHOT]\n\n```\n\nSolution: prepare new `AlterTableCommandDatasetBuilder` in spark40 package.\n\nThis issue if a follow-up of https://github.com/OpenLineage/OpenLineage/pull/3877",
      "updatedAt" : 1752222096.000000000,
      "user" : "pawel-big-lebowski",
      "userHtmlUrl" : "https://github.com/pawel-big-lebowski",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1646950?v=4",
      "labels" : [ "area:integration/spark", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An Open Standard for lineage metadata collection",
        "homepage" : "http://openlineage.io",
        "name" : "OpenLineage",
        "fullName" : "OpenLineage/OpenLineage",
        "htmlUrl" : "https://github.com/OpenLineage/OpenLineage",
        "gitUrl" : "git://github.com/OpenLineage/OpenLineage.git",
        "sshUrl" : "git@github.com:OpenLineage/OpenLineage.git",
        "cloneUrl" : "https://github.com/OpenLineage/OpenLineage.git",
        "owner" : {
          "login" : "OpenLineage",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 356,
        "stargazersCount" : 2014,
        "watchersCount" : 2014,
        "size" : 65830,
        "openIssuesCount" : 289,
        "subscribersCount" : 47,
        "pushedAt" : "2025-07-11T18:15:49Z",
        "languages" : {
          "MDX" : 303458,
          "PowerShell" : 742,
          "Java" : 3610139,
          "CSS" : 12915,
          "Jinja" : 10687,
          "Rust" : 223402,
          "PLpgSQL" : 41573,
          "Scala" : 9325,
          "Makefile" : 634,
          "Groovy" : 11849,
          "Kotlin" : 32464,
          "TypeScript" : 57451,
          "Dockerfile" : 7360,
          "Shell" : 70649,
          "Batchfile" : 800,
          "JavaScript" : 10910,
          "Ruby" : 12631,
          "Python" : 1319715
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "AlterTableCommandDatasetBuilder turned off for Spark 4 integration",
      "validationOrRequirement" : "java.lang.NoClassDefFoundError: org/apache/spark/sql/catalyst/plans/logical/AlterColumn",
      "attemptedFixes" : "prepare new AlterTableCommandDatasetBuilder in spark40 package",
      "otherNotes" : "This is a follow-up issue to https://github.com/OpenLineage/OpenLineage/pull/3877",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284596
  }, {
    "issueDTO" : {
      "id" : 3162805049,
      "title" : "[Feature]: data-retention, add support for partition column type Date",
      "url" : "https://github.com/apache/amoro/issues/3632",
      "repositoryName" : "apache/amoro",
      "description" : "### Description\n\nCurrently, data expire feature only support timestamp/timestampz/long type and string type field in date format\n\n\ndata-expire.field | NULL | Field used to determine data expiration, supporting timestamp/timestampz/long type and string type field in date format\n-- | -- | --\n\n\nIt would be nice if support partition column type Date.\n\n\n### Use case/motivation\n\namoro-ams 2025-06-20 10:19:10,468 WARN [async-data-expiring-executor-0] [org.apache.amoro.server.table.TableConfigurations] [] - Table(iceberg-hive-catalog.db.my_table) field(etl_date) type(DATE) is not supported for data exp\niration, please use the following types: LONG, TIMESTAMP, STRING\n\n### Describe the solution\n\n_No response_\n\n### Subtasks\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [x] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
      "updatedAt" : 1752221719.000000000,
      "user" : "vanphuoc3012",
      "userHtmlUrl" : "https://github.com/vanphuoc3012",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/37379686?v=4",
      "labels" : [ "type:feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@vanphuoc3012 thanks for reaching out for this feature. Would you like to try implementing it? It may be necessary to update the logic in `TableConfiguration#validateExpirationField` and `IcedbergTableMaintainer#getDataExpression`", "> [@vanphuoc3012](https://github.com/vanphuoc3012) thanks for reaching out for this feature. Would you like to try implementing it? It may be necessary to update the logic in `TableConfiguration#validateExpirationField` and `IcedbergTableMaintainer#getDataExpression`???????????????????????????????????????????????????????????????????????????????????? `TableConfiguration#validateExpirationField` ??? `IcedbergTableMaintainer#getDataExpression` ???????????????\n\n@klion26 Hello, I want to try it, can you assign the task to me?", "Hi @vanphuoc3012 , can you please assign this to me.", "> Hi [@vanphuoc3012](https://github.com/vanphuoc3012) , can you please assign this to me.\n\nHi @klion26 , I think I dont have perrmission to assign this issue to people \uD83D\uDE01", "Thanks for the interesting about contributing to this issue @lsyulong @MadhuriRathod30 and sorry for the late reply. I'll assign this to @lsyulong this time, as he/she commented first. There are some [good first issue](https://github.com/apache/amoro/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22) if we want to try, and we can also file a pr directly when there is no assignee and pr next time. \n\nPlease ping me if there is something I can help with.", "> Thanks for the interesting about contributing to this issue [@lsyulong](https://github.com/lsyulong) [@MadhuriRathod30](https://github.com/MadhuriRathod30) and sorry for the late reply. I'll assign this to [@lsyulong](https://github.com/lsyulong) this time, as he/she commented first. There are some [good first issue](https://github.com/apache/amoro/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22) if we want to try, and we can also file a pr directly when there is no assignee and pr next time.\n> \n> Please ping me if there is something I can help with.\n\n@klion26 I have modified the relevant code logic. If you have time, please help review the code to see if there are any other issues. I will make further adjustments. Thank you very much" ],
      "repository" : {
        "description" : "Apache Amoro (incubating) is a Lakehouse management system built on open data lake formats.",
        "homepage" : "https://amoro.apache.org/",
        "name" : "amoro",
        "fullName" : "apache/amoro",
        "htmlUrl" : "https://github.com/apache/amoro",
        "gitUrl" : "git://github.com/apache/amoro.git",
        "sshUrl" : "git@github.com:apache/amoro.git",
        "cloneUrl" : "https://github.com/apache/amoro.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 343,
        "stargazersCount" : 1014,
        "watchersCount" : 1014,
        "size" : 71332,
        "openIssuesCount" : 95,
        "subscribersCount" : 38,
        "pushedAt" : "2025-07-10T16:24:51Z",
        "languages" : {
          "Smarty" : 28161,
          "Java" : 9893560,
          "Scala" : 629533,
          "Vue" : 276871,
          "HTML" : 1171,
          "TypeScript" : 117111,
          "Dockerfile" : 5084,
          "Shell" : 18857,
          "ANTLR" : 81080,
          "JavaScript" : 43160,
          "Less" : 13595,
          "Python" : 11292,
          "Thrift" : 9116
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for partition column type Date in data-expire.feature.",
      "validationOrRequirement" : "The feature requires support for partition column type Date in data-expire.field.",
      "attemptedFixes" : "The author, @vanphuoc3012, has modified the relevant code logic and is requesting a review from @klion26.",
      "otherNotes" : "The issue is related to adding support for partition column type Date in data-expire.feature. There are some good first issues to try and it's also possible to file a PR directly when there is no assignee. The author, @vanphuoc3012, has already assigned the task to @lsyulong. There is a code review request for the modified code logic.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284601
  }, {
    "issueDTO" : {
      "id" : 3222001240,
      "title" : "[Spark4] Fix SparkScalaContainerTest",
      "url" : "https://github.com/OpenLineage/OpenLineage/issues/3882",
      "repositoryName" : "OpenLineage/OpenLineage",
      "description" : "`SparkScalaContainerTest` is disabled for Spark 4.\nThis is a follow-up issue of https://github.com/OpenLineage/OpenLineage/pull/3877\nPlease fix the test, enable it and remove `TODO` comment.",
      "updatedAt" : 1752221692.000000000,
      "user" : "pawel-big-lebowski",
      "userHtmlUrl" : "https://github.com/pawel-big-lebowski",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1646950?v=4",
      "labels" : [ "area:integration/spark", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An Open Standard for lineage metadata collection",
        "homepage" : "http://openlineage.io",
        "name" : "OpenLineage",
        "fullName" : "OpenLineage/OpenLineage",
        "htmlUrl" : "https://github.com/OpenLineage/OpenLineage",
        "gitUrl" : "git://github.com/OpenLineage/OpenLineage.git",
        "sshUrl" : "git@github.com:OpenLineage/OpenLineage.git",
        "cloneUrl" : "https://github.com/OpenLineage/OpenLineage.git",
        "owner" : {
          "login" : "OpenLineage",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 356,
        "stargazersCount" : 2014,
        "watchersCount" : 2014,
        "size" : 65830,
        "openIssuesCount" : 289,
        "subscribersCount" : 47,
        "pushedAt" : "2025-07-11T18:15:49Z",
        "languages" : {
          "MDX" : 303458,
          "PowerShell" : 742,
          "Java" : 3610139,
          "CSS" : 12915,
          "Jinja" : 10687,
          "Rust" : 223402,
          "PLpgSQL" : 41573,
          "Scala" : 9325,
          "Makefile" : 634,
          "Groovy" : 11849,
          "Kotlin" : 32464,
          "TypeScript" : 57451,
          "Dockerfile" : 7360,
          "Shell" : 70649,
          "Batchfile" : 800,
          "JavaScript" : 10910,
          "Ruby" : 12631,
          "Python" : 1319715
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix SparkScalaContainerTest to be enabled for Spark 4",
      "validationOrRequirement" : "Please fix the test, enable it and remove TODO comment",
      "attemptedFixes" : "",
      "otherNotes" : "This is a follow-up issue of https://github.com/OpenLineage/OpenLineage/pull/3877",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284603
  }, {
    "issueDTO" : {
      "id" : 3222000600,
      "title" : "feat YdbDataReader: support GetFieldValue<>",
      "url" : "https://github.com/ydb-platform/ydb-dotnet-sdk/issues/472",
      "repositoryName" : "ydb-platform/ydb-dotnet-sdk",
      "description" : "Unmute `YdbGetValueConversionTests`\n",
      "updatedAt" : 1752221617.000000000,
      "user" : "KirillKurdyukov",
      "userHtmlUrl" : "https://github.com/KirillKurdyukov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/62187122?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "YDB .NET SDK",
        "homepage" : "",
        "name" : "ydb-dotnet-sdk",
        "fullName" : "ydb-platform/ydb-dotnet-sdk",
        "htmlUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk",
        "gitUrl" : "git://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "sshUrl" : "git@github.com:ydb-platform/ydb-dotnet-sdk.git",
        "cloneUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "owner" : {
          "login" : "ydb-platform",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 67,
        "watchersCount" : 67,
        "size" : 1600,
        "openIssuesCount" : 106,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-10T13:28:31Z",
        "languages" : {
          "C#" : 1268363,
          "Shell" : 1165,
          "TSQL" : 1306856
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "feat YdbDataReader: support GetFieldValue<>",
      "validationOrRequirement" : "good first issue",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about supporting GetFieldValue<> in YdbDataReader",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284605
  }, {
    "issueDTO" : {
      "id" : 3221997215,
      "title" : "feat YdbConnection: support ServerVersion",
      "url" : "https://github.com/ydb-platform/ydb-dotnet-sdk/issues/471",
      "repositoryName" : "ydb-platform/ydb-dotnet-sdk",
      "description" : "Unmute test (cached server version)\n\n```\n#pragma warning disable xUnit1004\n    [Fact(Skip = \"TODO Supported this field.\")]\n#pragma warning restore xUnit1004\n    public override void ServerVersion_returns_value()\n    {\n        base.ServerVersion_returns_value();\n    }\n```\n",
      "updatedAt" : 1752221534.000000000,
      "user" : "KirillKurdyukov",
      "userHtmlUrl" : "https://github.com/KirillKurdyukov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/62187122?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "YDB .NET SDK",
        "homepage" : "",
        "name" : "ydb-dotnet-sdk",
        "fullName" : "ydb-platform/ydb-dotnet-sdk",
        "htmlUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk",
        "gitUrl" : "git://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "sshUrl" : "git@github.com:ydb-platform/ydb-dotnet-sdk.git",
        "cloneUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "owner" : {
          "login" : "ydb-platform",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 67,
        "watchersCount" : 67,
        "size" : 1600,
        "openIssuesCount" : 106,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-10T13:28:31Z",
        "languages" : {
          "C#" : 1268363,
          "Shell" : 1165,
          "TSQL" : 1306856
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support server version in YdbConnection feature.",
      "validationOrRequirement" : "None specified.",
      "attemptedFixes" : "No fixes attempted yet, as this is a new issue.",
      "otherNotes" : "The test is currently muted and needs to be supported with a server version.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284607
  }, {
    "issueDTO" : {
      "id" : 3221988810,
      "title" : "Update `window.ai` to the new APIs",
      "url" : "https://github.com/brisa-build/brisa/issues/890",
      "repositoryName" : "brisa-build/brisa",
      "description" : "\nGoogle Chrome team updates the APIs: https://developer.chrome.com/docs/ai/summarizer-api\n\nSo this task is to migrate this:\n\nhttps://github.com/brisa-build/brisa/blob/586f2a22589d3e13bd66096d7ec440d3d1eee8ba/packages/brisa/src/utils/brisa-error-dialog/web-components/brisa-error-dialog.tsx#L13\n\nTo the news APIs. ",
      "updatedAt" : 1752221351.000000000,
      "user" : "aralroca",
      "userHtmlUrl" : "https://github.com/aralroca",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13313058?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The Web Platform Framework. ",
        "homepage" : "https://brisa.build",
        "name" : "brisa",
        "fullName" : "brisa-build/brisa",
        "htmlUrl" : "https://github.com/brisa-build/brisa",
        "gitUrl" : "git://github.com/brisa-build/brisa.git",
        "sshUrl" : "git@github.com:brisa-build/brisa.git",
        "cloneUrl" : "https://github.com/brisa-build/brisa.git",
        "owner" : {
          "login" : "brisa-build",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 23,
        "stargazersCount" : 715,
        "watchersCount" : 715,
        "size" : 16386,
        "openIssuesCount" : 48,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-10T20:50:10Z",
        "languages" : {
          "TypeScript" : 2853464,
          "MDX" : 39,
          "CSS" : 33452,
          "JavaScript" : 22703,
          "HTML" : 72
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the code snippet in brisa-error-dialog.tsx to the new APIs provided by the Google Chrome team.",
      "validationOrRequirement" : "The code snippet should be updated to the new APIs provided by the Google Chrome team, and the update should be done according to the documentation at https://developer.chrome.com/docs/ai/summarizer-api.",
      "attemptedFixes" : "No attempts or blockers mentioned in the issue description or comments.",
      "otherNotes" : "The task is to migrate a specific code snippet in brisa-error-dialog.tsx to the new APIs, and the update is based on the new APIs provided by the Google Chrome team.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284611
  }, {
    "issueDTO" : {
      "id" : 3221979440,
      "title" : "feat YdbDataReader: support GetColumnSchema() ColumnName",
      "url" : "https://github.com/ydb-platform/ydb-dotnet-sdk/issues/470",
      "repositoryName" : "ydb-platform/ydb-dotnet-sdk",
      "description" : "Unmute test\n\n```\n#pragma warning disable xUnit1004\n    [Fact(Skip = \"Not supported GetSchemaTable\")]\n#pragma warning restore xUnit1004\n    public override void GetColumnSchema_ColumnName()\n    {\n        base.GetColumnSchema_ColumnName();\n    }\n```\n",
      "updatedAt" : 1752221320.000000000,
      "user" : "KirillKurdyukov",
      "userHtmlUrl" : "https://github.com/KirillKurdyukov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/62187122?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "YDB .NET SDK",
        "homepage" : "",
        "name" : "ydb-dotnet-sdk",
        "fullName" : "ydb-platform/ydb-dotnet-sdk",
        "htmlUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk",
        "gitUrl" : "git://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "sshUrl" : "git@github.com:ydb-platform/ydb-dotnet-sdk.git",
        "cloneUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "owner" : {
          "login" : "ydb-platform",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 67,
        "watchersCount" : 67,
        "size" : 1600,
        "openIssuesCount" : 106,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-10T13:28:31Z",
        "languages" : {
          "C#" : 1268363,
          "Shell" : 1165,
          "TSQL" : 1306856
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement the GetColumnSchema() method in YdbDataReader to support ColumnName",
      "validationOrRequirement" : "The GetColumnSchema() method should support ColumnName",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The test is currently skipped due to not being supported, and the GetSchemaTable is also not supported.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284614
  }, {
    "issueDTO" : {
      "id" : 3221969268,
      "title" : "feat YdbDataReader: support GetColumnSchema() DataTypeName",
      "url" : "https://github.com/ydb-platform/ydb-dotnet-sdk/issues/469",
      "repositoryName" : "ydb-platform/ydb-dotnet-sdk",
      "description" : "Unmute test\n\n```\n#pragma warning disable xUnit1004\n    [Fact(Skip = \"Not supported GetSchemaTable\")]\n#pragma warning restore xUnit1004\n    public override void GetColumnSchema_DataTypeName()\n    {\n        base.GetColumnSchema_DataTypeName();\n    }\n```",
      "updatedAt" : 1752221055.000000000,
      "user" : "KirillKurdyukov",
      "userHtmlUrl" : "https://github.com/KirillKurdyukov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/62187122?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "YDB .NET SDK",
        "homepage" : "",
        "name" : "ydb-dotnet-sdk",
        "fullName" : "ydb-platform/ydb-dotnet-sdk",
        "htmlUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk",
        "gitUrl" : "git://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "sshUrl" : "git@github.com:ydb-platform/ydb-dotnet-sdk.git",
        "cloneUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "owner" : {
          "login" : "ydb-platform",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 67,
        "watchersCount" : 67,
        "size" : 1600,
        "openIssuesCount" : 106,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-10T13:28:31Z",
        "languages" : {
          "C#" : 1268363,
          "Shell" : 1165,
          "TSQL" : 1306856
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement GetColumnSchema() DataTypeName feature for YdbDataReader",
      "validationOrRequirement" : "Support GetColumnSchema() DataTypeName",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "The test is muted due to GetSchemaTable not being supported",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284617
  }, {
    "issueDTO" : {
      "id" : 3221966805,
      "title" : "feat YdbDataReader: support GetColumnSchema() DataType",
      "url" : "https://github.com/ydb-platform/ydb-dotnet-sdk/issues/468",
      "repositoryName" : "ydb-platform/ydb-dotnet-sdk",
      "description" : "Unmute test\n\n```\n#pragma warning disable xUnit1004\n    [Fact(Skip = \"Not supported GetSchemaTable\")]\n#pragma warning restore xUnit1004\n    public override void GetColumnSchema_DataType()\n    {\n        base.GetColumnSchema_DataType();\n    }\n```",
      "updatedAt" : 1752221016.000000000,
      "user" : "KirillKurdyukov",
      "userHtmlUrl" : "https://github.com/KirillKurdyukov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/62187122?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "YDB .NET SDK",
        "homepage" : "",
        "name" : "ydb-dotnet-sdk",
        "fullName" : "ydb-platform/ydb-dotnet-sdk",
        "htmlUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk",
        "gitUrl" : "git://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "sshUrl" : "git@github.com:ydb-platform/ydb-dotnet-sdk.git",
        "cloneUrl" : "https://github.com/ydb-platform/ydb-dotnet-sdk.git",
        "owner" : {
          "login" : "ydb-platform",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 67,
        "watchersCount" : 67,
        "size" : 1600,
        "openIssuesCount" : 106,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-10T13:28:31Z",
        "languages" : {
          "C#" : 1268363,
          "Shell" : 1165,
          "TSQL" : 1306856
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support GetColumnSchema() method with DataType in YdbDataReader",
      "validationOrRequirement" : "Implement GetColumnSchema() method with DataType",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "The test is muted and the GetSchemaTable is not supported",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284619
  }, {
    "issueDTO" : {
      "id" : 2944039298,
      "title" : "Memory awareness in context",
      "url" : "https://github.com/doobidoo/mcp-memory-service/issues/14",
      "repositoryName" : "doobidoo/mcp-memory-service",
      "description" : "Cool project!\n\nI'm wondering if there's any way to inject into the default context of each chat a selected list of topics or tags stored in memory.\n\nI know this isn't part of the MCP protocol, but maybe there's some other clever way to do it. \n\nClaude now has projects with custom instructions... If there was a way to inject custom instructions \"You have a searchable memory. Recent topics you remember include X, Y. Long term, important topics include A, B\".\n\nProbably beyond the scope of this project but I thought I'd throw it out in case it triggered any ideas!",
      "updatedAt" : 1752220159.000000000,
      "user" : "kevb",
      "userHtmlUrl" : "https://github.com/kevb",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11970?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "# Memory Awareness in Context - Implementation Possibilities\n\nThanks for the idea, @kevb! This feature suggestion - injecting memory awareness into Claude's context - is quite interesting and worth exploring.\n\nWhile direct context injection isn't part of the MCP protocol, there are several creative ways we could implement this functionality:\n\n## 1. Context Summary Generator Tool\n\nWe could add a new tool that generates a memory context summary that users can manually add to their Claude custom instructions or as the first message in a conversation:\n\n```\nYou have a searchable memory. Recent topics you remember include:\n- Discussion about machine learning from 2 days ago\n- Notes on project requirements from yesterday\n- Important architectural decisions (tagged as \"important\")\n\nYou can search your memory using the memory tools available to you.\n```\n\nThis approach would:\n- Create a formatted summary of recent/important memories\n- Allow customization (number of memories, preferred tags, time range)\n- Generate text that users can copy/paste into Claude's custom instructions\n\n## 2. Auto-Injected Context Helper\n\nWe could create a workflow where the memory service automatically prepares an optimized context reminder:\n\n1. A `generate_memory_context` tool would summarize key memories\n2. This could be automatically run at the start of Claude sessions\n3. The summary would be compact to minimize token usage\n\n## 3. Memory Awareness Periodic Reminder\n\nAnother approach would be a tool that periodically reminds Claude of important memories during a conversation:\n\n- Triggered manually or at intervals\n- Focuses on memories relevant to the current conversation\n- Helps maintain awareness without permanent context usage\n\n## Implementation Considerations\n\nSome technical aspects to keep in mind:\n\n- **Token efficiency**: Any context addition consumes tokens from Claude's context window, so we'd need to be selective\n- **Metadata extraction**: We'd need to extract key topics from memories rather than including full content\n- **Relevance scoring**: Prioritizing truly important memories over routine ones\n- **API limitations**: Working within the constraints of the MCP protocol\n\n## Potential First Step\n\nThe most straightforward approach would be implementing the Context Summary Generator tool first, as it:\n1. Doesn't require protocol changes\n2. Gives users full control over context usage\n3. Can be enhanced over time with more sophisticated relevance algorithms\n\nWould you be interested in seeing this implemented as a first step? Feedback on which aspects would be most valuable would help prioritize development.", "This can be implemented using Claude's project instructions feature without modifying the MCP protocol itself!\n\nWe could create a script that:\n1. Periodically queries the memory service using existing functions (`retrieve_memory`, `search_by_tag`, `recall_memory`)\n2. Formats key topics, tags, and important memories into concise summary text\n3. Updates the project's custom instructions with this memory context\n\nClaude would then start each conversation with awareness of your memory store: \"You have a searchable memory. Recent topics you remember include X, Y. Long term, important topics include A, B.\"\n\nThe script could run on a schedule to keep the memory context fresh, and could be implemented as a standalone utility that works alongside the MCP server.\n\nThis approach leverages Claude's built-in features while maintaining the current MCP protocol design. Would this solution work for your use case?", "I've implemented a solution to this issue by creating a dedicated utility: [Claude Memory Context](https://github.com/doobidoo/claude-memory-context)\n\nThis tool does exactly what was suggested in this issue - it allows Claude to have memory awareness at the start of conversations without modifying the MCP protocol:\n\n- It queries the MCP Memory Service for recent and important memories\n- Formats this information into a structured context section\n- Updates Claude's project instructions using Anthropic's API\n\nThe solution uses existing MCP functions (`recall_memory` and `search_by_tag`) and Claude's project instructions feature, creating a bridge between them.\n\nI've also added documentation about this integration to the MCP Memory Service repository in [docs/integrations.md](https://github.com/doobidoo/mcp-memory-service/blob/main/docs/integrations.md).\n\nThis approach provides memory awareness in context while keeping the MCP Memory Service focused on its core functionality. The integration can be set up on a schedule to keep Claude's memory context fresh with your latest memories.\n\nThanks for the suggestion, @kevb!", "Update: I've enhanced the [Claude Memory Context](https://github.com/doobidoo/claude-memory-context) utility to support both HTTP and CLI modes, making it compatible with different MCP Memory Service setups:\n\n1. **HTTP Mode**: For users running the MCP Memory Service as a web service\n2. **CLI Mode**: For Claude Desktop users where the service runs directly via command line\n\nThe CLI mode works with the same configuration as defined in Claude Desktop's settings JSON:\n\n```json\n{\n  \"memory\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"your_mcp_memory_service_directory\",\n      \"run\",\n      \"memory\"\n    ],\n    \"env\": {\n      \"MCP_MEMORY_CHROMA_PATH\": \"your_chroma_db_path\",\n      \"MCP_MEMORY_BACKUPS_PATH\": \"your_backups_path\"\n    }\n  }\n}\n```\n\nSimply use the CLI mode with the same paths:\n\n```bash\nnode memory-context-script.js \\\n  --mode cli \\\n  --anthropic-api-key your_api_key \\\n  --project-id your_project_id \\\n  --mcp-memory-dir \"your_mcp_memory_service_directory\" \\\n  --chroma-db-path \"your_chroma_db_path\" \\\n  --backups-path \"your_backups_path\"\n```\n\nThis enhancement means the solution works for all MCP Memory Service users, regardless of how you've deployed it!", "Update #2: The [Claude Memory Context](https://github.com/doobidoo/claude-memory-context) utility now features **automatic detection** of your Claude Desktop configuration!\n\nNow Claude Desktop users can simply run:\n\n```bash\nnode memory-context-script.js --anthropic-api-key your_api_key --project-id your_project_id\n```\n\nThe script will:\n1. Automatically find your Claude Desktop configuration file\n2. Extract all the necessary MCP Memory Service paths\n3. Use the correct settings without any manual configuration\n\nThis makes it incredibly easy to use, especially for Claude Desktop users who don't want to manually copy settings from their config file.\n\nThe utility supports three modes:\n- `auto` (default): Tries to find Claude Desktop config automatically\n- `http`: For users running MCP Memory Service as a web service\n- `cli`: For manually specifying paths if auto-detection doesn't work\n\nAll the details are in the README. This enhancement should make the solution accessible to all users, regardless of technical expertise!", "Unfortunately this approach is not yet feasible due to limitations in the Claude API. Let's keep an eye on it.\nMaybe it is feasible in the near future. I have added a comment to this  feature request: [Feature request / proposal: HTTP API for claude code #776\n](https://github.com/anthropics/claude-code/issues/776)\nThe only workaround for now would be to manually update the project instructions or we could explore browser automation options, but that would be more complex. ", "## Priority Assessment: P6 (Low)\n\n**Feasibility**: Medium - Already solved with external utility\n**Usability**: Low - Alternative solution exists and works well\n**Value**: Low - Duplicate effort given existing solution\n\n**Assessment**: This feature request has been effectively solved with the separate \"Claude Memory Context\" utility. Implementing it within the core service would be duplicate effort without significant additional value.\n\n**Current Status**: ??? **SOLVED** - The repository owner has created [Claude Memory Context](https://github.com/doobidoo/claude-memory-context) utility that addresses this need.\n\n**Recommendation**: Close this issue as completed, with reference to the external solution.\n\n**Priority Justification**: Already solved externally with dedicated utility. No additional development needed.\n\n**Dependencies**: None - already complete\n**Estimated Effort**: None - defer to existing solution" ],
      "repository" : {
        "description" : "MCP server providing semantic memory and persistent storage capabilities for Claude using ChromaDB and sentence transformers.",
        "homepage" : "",
        "name" : "mcp-memory-service",
        "fullName" : "doobidoo/mcp-memory-service",
        "htmlUrl" : "https://github.com/doobidoo/mcp-memory-service",
        "gitUrl" : "git://github.com/doobidoo/mcp-memory-service.git",
        "sshUrl" : "git@github.com:doobidoo/mcp-memory-service.git",
        "cloneUrl" : "https://github.com/doobidoo/mcp-memory-service.git",
        "owner" : {
          "login" : "doobidoo",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 68,
        "stargazersCount" : 449,
        "watchersCount" : 449,
        "size" : 849,
        "openIssuesCount" : 14,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T20:07:09Z",
        "languages" : {
          "TypeScript" : 38730,
          "Dockerfile" : 1519,
          "Shell" : 4501,
          "Jinja" : 316,
          "Batchfile" : 997,
          "Python" : 857135
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Inject custom instructions 'You have a searchable memory. Recent topics you remember include X, Y. Long term, important topics include A, B' into Claude's context",
      "validationOrRequirement" : "Token efficiency, metadata extraction, relevance scoring, API limitations, implementation considerations, potential first step, straightforward approach, script, memory context fresh, standalone utility, bridge between MCP functions and Claude's project instructions feature, integration setup, HTTP and CLI modes, automatic detection, Claude Desktop configuration, utility modes, default mode, HTTP mode, CLI mode, configuration settings, README, feature request, proposal, HTTP API, claude code, workaround, browser automation options",
      "attemptedFixes" : "Context Summary Generator Tool, Auto-Injected Context Helper, Memory Awareness Periodic Reminder, script, memory context fresh, standalone utility, bridge between MCP functions and Claude's project instructions feature, integration setup, HTTP and CLI modes, automatic detection, Claude Desktop configuration, utility modes, default mode, HTTP mode, CLI mode, configuration settings, README, feature request, proposal, HTTP API, claude code, workaround, browser automation options",
      "otherNotes" : "Memory awareness in context, inject custom instructions, searchable memory, recent topics, important topics, context summary generator tool, auto-injected context helper, memory awareness periodic reminder, token efficiency, metadata extraction, relevance scoring, API limitations, implementation considerations, potential first step, straightforward approach, script, memory context fresh, standalone utility, bridge between MCP functions and Claude's project instructions feature, integration setup, HTTP and CLI modes, automatic detection, Claude Desktop configuration, utility modes, default mode, HTTP mode, CLI mode, configuration settings, README, feature request, proposal, HTTP API, claude code, workaround, browser automation options, priority assessment, feasibility, usability, value, assessment, current status, solved, external solution, recommendation, close issue, reference to external solution, priority justification, already solved externally, estimated effort, none, defer to existing solution",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284632
  }, {
    "issueDTO" : {
      "id" : 2922995958,
      "title" : "Implement Multi-Layered Memory Consolidation System",
      "url" : "https://github.com/doobidoo/mcp-memory-service/issues/11",
      "repositoryName" : "doobidoo/mcp-memory-service",
      "description" : "## Overview\nThe MCP Memory Service currently provides excellent capabilities for storing and retrieving individual memories, but lacks a system for automatically processing, consolidating, and abstracting information over time. This feature request proposes implementing a multi-layered memory consolidation system that mimics how human memory works - with progressive abstraction and pattern extraction across different time horizons.\n\n## Proposed Solution\nImplement a tiered approach to memory processing that works at different temporal scales:\n\n### 1. Layered Processing Architecture\n- **Daily processing**: Analyze and connect recent memories (last 24 hours)\n- **Weekly processing**: Review and consolidate the past week's memories\n- **Monthly consolidation**: Extract broader themes and patterns\n- **Quarterly review**: Identify significant insights across domains\n- **Yearly summarization**: Create comprehensive knowledge structures\n\n### 2. Key Components to Implement\n- **Memory Consolidation Engine**: Background service that runs at scheduled intervals\n- **Pattern Recognition System**: Identifies relationships between memories\n- **Summary Generation**: Creates higher-level abstraction memories\n- **Knowledge Graph Builder**: Maps connections between related memories\n- **Configuration System**: Allows customizing consolidation parameters\n\n## Technical Implementation\n\n### 1. Processing Pipeline\n```python\n# Conceptual processing pipeline\nasync def consolidate_memories(time_horizon: str):\n    \"\"\"\n    Process memories for the specified time horizon.\n    \n    Args:\n        time_horizon: One of \"daily\", \"weekly\", \"monthly\", \"quarterly\", \"yearly\"\n    \"\"\"\n    # 1. Retrieve relevant memories based on time horizon\n    memories = await get_memories_for_horizon(time_horizon)\n    \n    # 2. Group related memories using semantic similarity\n    clusters = cluster_memories(memories)\n    \n    # 3. Generate summaries for each cluster\n    for cluster in clusters:\n        summary = generate_cluster_summary(cluster)\n        \n        # 4. Store the summary as a new \"consolidation\" memory\n        await store_consolidated_memory(\n            content=summary, \n            source_memories=cluster,\n            metadata={\n                \"type\": \"consolidation\",\n                \"time_horizon\": time_horizon,\n                \"confidence\": calculate_confidence(cluster),\n                \"tags\": extract_common_tags(cluster) + [f\"{time_horizon}_summary\"]\n            }\n        )\n        \n        # 5. Update metadata of source memories to link to this summary\n        for memory in cluster:\n            await update_memory_metadata(\n                memory.hash,\n                {\"consolidated_in\": summary.hash}\n            )\n```\n\n### 2. Scheduling System\nImplement a background scheduler that runs consolidation tasks at appropriate intervals:\n- Daily processing: Every day at 3:00 AM\n- Weekly processing: Every Monday at 4:00 AM\n- Monthly processing: First day of month at 5:00 AM \n- Quarterly processing: First day of quarter at 6:00 AM\n- Yearly processing: January 1st at 7:00 AM\n\n### 3. Configuration Options\n```python\nCONSOLIDATION_SETTINGS = {\n    \"ENABLED\": True,\n    \"SIMILARITY_THRESHOLD\": 0.75,  # How related memories must be to cluster\n    \"MIN_CLUSTER_SIZE\": 3,  # Minimum memories to form a cluster\n    \"MAX_CLUSTER_SIZE\": 20,  # Maximum memories per cluster\n    \"SUMMARY_MAX_LENGTH\": 1000,  # Characters\n    \"CONSOLIDATION_SCHEDULES\": {\n        \"daily\": \"0 3 * * *\",    # cron syntax: 3:00 AM daily\n        \"weekly\": \"0 4 * * 1\",   # 4:00 AM on Mondays\n        \"monthly\": \"0 5 1 * *\",  # 5:00 AM on 1st day of month\n        \"quarterly\": \"0 6 1 1,4,7,10 *\",  # 6:00 AM 1st day of quarter\n        \"yearly\": \"0 7 1 1 *\"    # 7:00 AM January 1st\n    },\n    \"PROCESSING_LIMITS\": {\n        \"daily\": 1000,    # Max memories to process per run\n        \"weekly\": 5000,\n        \"monthly\": 10000,\n        \"quarterly\": 20000,\n        \"yearly\": 50000\n    }\n}\n```\n\n## Benefits\n1. **Automatic knowledge organization**: Emergent structure from unstructured memories\n2. **Signal amplification**: Important concepts rise to higher abstraction levels\n3. **Noise reduction**: Irrelevant details fade unless connected to key concepts\n4. **Non-obvious insights**: Discover unexpected connections between memory domains\n5. **Memory efficiency**: Consolidated summaries provide efficient access to key information\n\n## Use Cases\n- Automatically generating weekly summaries of work activities\n- Identifying recurring themes in research notes\n- Surfacing important connections between seemingly unrelated topics\n- Creating a \"knowledge landscape\" that evolves over time\n- Automatically prioritizing memories by significance\n\n## Success Criteria\n- [ ] Implementation of all five processing layers (daily to yearly)\n- [ ] Memory clustering system based on semantic similarity\n- [ ] Summary generation for memory clusters\n- [ ] Metadata linking between source memories and consolidated summaries\n- [ ] Configurable scheduling system\n- [ ] Documentation with examples of how consolidation works\n- [ ] Tests for different consolidation scenarios\n\n## Dependencies\nThis feature would benefit greatly from:\n- Issue #10: Memory Metadata Enhancement API (for linking memories)\n- Improved embedding models for better semantic clustering\n\n## Priority\nMedium-High - This would be a significant enhancement to the memory system's capabilities, enabling more intelligent and useful interactions over time.\n",
      "updatedAt" : 1752220147.000000000,
      "user" : "doobidoo",
      "userHtmlUrl" : "https://github.com/doobidoo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5000709?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "## Priority Assessment: P5 (Low-Medium)\n\n**Feasibility**: Low-Medium - Complex AI-like system requiring significant R&D\n**Usability**: High - Would provide human-like memory organization (if successful)\n**Value**: High - Revolutionary feature, but high implementation risk\n\n**Assessment**: This is an ambitious feature that would differentiate the service significantly, but requires substantial research and development. The complexity and uncertainty make it unsuitable for near-term implementation.\n\n**Implementation Plan**:\n1. Research phase: memory consolidation algorithms\n2. Prototype pattern recognition system\n3. Design multi-layered processing pipeline\n4. Implement clustering and summarization\n5. Add knowledge graph construction\n6. Create scheduling and automation system\n\n**Priority Justification**: Revolutionary feature with high potential value, but requires significant R&D investment. Should be considered for future roadmap after core platform is mature.\n\n**Dependencies**: Advanced metadata system, mature embedding pipeline\n**Estimated Effort**: 2-3 months (research + development)" ],
      "repository" : {
        "description" : "MCP server providing semantic memory and persistent storage capabilities for Claude using ChromaDB and sentence transformers.",
        "homepage" : "",
        "name" : "mcp-memory-service",
        "fullName" : "doobidoo/mcp-memory-service",
        "htmlUrl" : "https://github.com/doobidoo/mcp-memory-service",
        "gitUrl" : "git://github.com/doobidoo/mcp-memory-service.git",
        "sshUrl" : "git@github.com:doobidoo/mcp-memory-service.git",
        "cloneUrl" : "https://github.com/doobidoo/mcp-memory-service.git",
        "owner" : {
          "login" : "doobidoo",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 68,
        "stargazersCount" : 449,
        "watchersCount" : 449,
        "size" : 849,
        "openIssuesCount" : 14,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T20:07:09Z",
        "languages" : {
          "TypeScript" : 38730,
          "Dockerfile" : 1519,
          "Shell" : 4501,
          "Jinja" : 316,
          "Batchfile" : 997,
          "Python" : 857135
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a multi-layered memory consolidation system that mimics how human memory works - with progressive abstraction and pattern extraction across different time horizons.",
      "validationOrRequirement" : "The proposed solution is to implement a tiered approach to memory processing that works at different temporal scales, with key components to implement including Memory Consolidation Engine, Pattern Recognition System, Summary Generation, Knowledge Graph Builder, and Configuration System.",
      "attemptedFixes" : "The assessment is that this is an ambitious feature that would differentiate the service significantly, but requires substantial research and development. The complexity and uncertainty make it unsuitable for near-term implementation.",
      "otherNotes" : "This feature would benefit greatly from Issue #10: Memory Metadata Enhancement API (for linking memories) and improved embedding models for better semantic clustering. The implementation plan includes research phase, prototype pattern recognition system, design multi-layered processing pipeline, implement clustering and summarization, add knowledge graph construction, and create scheduling and automation system.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284639
  }, {
    "issueDTO" : {
      "id" : 3024551317,
      "title" : "Enhance MCP Memory Service with Prompts and Resources",
      "url" : "https://github.com/doobidoo/mcp-memory-service/issues/35",
      "repositoryName" : "doobidoo/mcp-memory-service",
      "description" : "## Background\n\nAn analysis of the MCP Memory Service identified opportunities for enhancement by leveraging MCP Prompts and Resources features:\n\n1. **MCP Prompts**: Currently, retrieval query logic is hardcoded. We could make memory retrieval more dynamic and context-aware by using MCP Prompts to generate queries based on the user's context.\n\n2. **MCP Resources**: The ChromaDB collections could be exposed as MCP Resources, allowing other services to directly access and manage stored memories.\n\n## Proposed Changes\n\n### MCP Prompts Enhancement\n\nModify the `handle_retrieve_memory` function in `src/mcp_memory_service/server.py` to incorporate prompt handling:\n\n```python\n@self.server.list_prompts()\nasync def handle_list_prompts() -> List[types.Prompt]:\n    return [\n        types.Prompt(\n            name=\"retrieve-memory\",\n            description=\"Generate a query to retrieve relevant memories based on user context\",\n            inputSchema={\n                \"type\": \"object\",\n                \"properties\": {\n                    \"context\": {\n                        \"type\": \"string\",\n                        \"description\": \"User's current context or conversation history\"\n                    },\n                    \"max_results\": {\n                        \"type\": \"number\",\n                        \"description\": \"Maximum number of results to return\",\n                        \"default\": 5\n                    }\n                },\n                \"required\": [\"context\"]\n            }\n        )\n    ]\n\n@self.server.call_prompt()\nasync def handle_call_prompt(name: str, arguments: dict | None) -> types.PromptResult:\n    if name == \"retrieve-memory\":\n        context = arguments.get(\"context\", \"\")\n        max_results = arguments.get(\"max_results\", 5)\n        \n        # Generate an optimized query based on the context\n        # This is where we could integrate with a larger model to generate a better query\n        query = context  # Simple implementation - just use the context as the query\n        \n        # Execute the query\n        results = await self.storage.retrieve(query, max_results)\n        \n        # Format the results\n        formatted_results = []\n        for result in results:\n            memory_info = {\n                \"content\": result.memory.content,\n                \"relevance_score\": result.relevance_score,\n                \"tags\": result.memory.tags,\n                \"hash\": result.memory.content_hash\n            }\n            formatted_results.append(memory_info)\n        \n        return types.PromptResult(\n            choices=[\n                types.PromptChoice(\n                    index=0,\n                    content=[\n                        types.TextContent(\n                            type=\"text\",\n                            text=json.dumps(formatted_results, indent=2)\n                        )\n                    ]\n                )\n            ]\n        )\n    else:\n        raise ValueError(f\"Unknown prompt: {name}\")\n```\n\n### MCP Resources Enhancement\n\nImplement resource listing and reading methods in `src/mcp_memory_service/server.py`:\n\n```python\n@self.server.list_resources()\nasync def handle_list_resources() -> List[Resource]:\n    # Return a list of available ChromaDB collections as resources\n    collections = self.client.list_collections()\n    resources = []\n    \n    for collection in collections:\n        resources.append(Resource(\n            uri=f\"mcp-memory-service:/collections/{collection.name}\",\n            title=collection.name,\n            description=f\"ChromaDB memory collection: {collection.name}\"\n        ))\n    \n    return resources\n\n@self.server.read_resource()\nasync def handle_read_resource(uri: str) -> List[types.TextContent]:\n    if uri.startswith(\"mcp-memory-service:/collections/\"):\n        collection_name = uri.split(\"/\")[-1]\n        try:\n            # Get the requested collection\n            collection = self.client.get_collection(collection_name)\n            \n            # Get all items in the collection with pagination \n            # (limit max records for performance)\n            results = collection.get(limit=100)\n            \n            return [types.TextContent(\n                type=\"text\",\n                text=json.dumps({\n                    \"collection\": collection_name,\n                    \"count\": len(results[\"ids\"]),\n                    \"data\": [\n                        {\n                            \"id\": results[\"ids\"][i],\n                            \"content\": results[\"documents\"][i],\n                            \"metadata\": results[\"metadatas\"][i]\n                        }\n                        for i in range(len(results[\"ids\"]))\n                    ]\n                }, indent=2)\n            )]\n        except Exception as e:\n            return [types.TextContent(\n                type=\"text\",\n                text=f\"Error reading collection {collection_name}: {str(e)}\"\n            )]\n    else:\n        return [types.TextContent(\n            type=\"text\",\n            text=f\"Error: Resource not found: {uri}\"\n        )]\n```\n\n## Additional Considerations\n\n1. Add pagination support for large collections\n2. Implement authentication/authorization for resource access\n3. Consider exposing individual memories as resources with URIs like `mcp-memory-service:/memories/{hash}`\n4. Add resource templates for common memory queries\n\n## Implementation Impact\n\nThese enhancements would make the MCP Memory Service more versatile and better integrated with the MCP ecosystem:\n\n- **MCP Prompts**: Would allow more intelligent memory retrieval based on user context\n- **MCP Resources**: Would enable other services to directly access and manipulate stored memories\n\n## Testing Plan\n\n1. Add unit tests for new prompt and resource functionality\n2. Test integration with Claude or other LLMs to verify prompt-based memory retrieval\n3. Test accessing collections as resources from an external service\n",
      "updatedAt" : 1752220124.000000000,
      "user" : "doobidoo",
      "userHtmlUrl" : "https://github.com/doobidoo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5000709?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "# Analysis of MCP Prompts and Resources Enhancement for mcp-memory-service\n\nAfter thoroughly examining the codebase and researching the MCP specification, here's a detailed analysis of the proposed enhancements:\n\n## Current Implementation Status\n\nThe memory service already has:\n- A robust implementation of MCP Tools for memory operations\n- Basic placeholder implementations for Resources and Prompts endpoints (returning empty lists)\n\n## 1. MCP Prompts Enhancement - Feasibility and Benefits\n\n### Feasibility:\n- **Implementation Complexity**: Medium. The server.py file already has the structure for handling prompt listing with `@self.server.list_prompts()` and would need to add `@self.server.call_prompt()`.\n- **Technical Barriers**: Low. The codebase is well-structured and the ChromaMemoryStorage class can be leveraged for implementing prompt functionality.\n\n### Benefits:\n- **Context-Aware Retrieval**: Implementing the \"retrieve-memory\" prompt would allow Claude to generate optimized queries based on user context, potentially improving memory recall accuracy.\n- **Standardized Templates**: Provides predictable interaction patterns for memory operations through standardized prompts.\n- **User Experience**: Makes memory retrieval more natural and conversational for users.\n\n### Specific Useful Prompts to Implement:\n1. `retrieve-memory` - Generate optimized queries for memory retrieval based on user context\n2. `generate-memory-query` - Help optimize the search queries for better semantic matching\n3. `summarize-memories` - Create summaries of multiple retrieved memories\n\n## 2. MCP Resources Enhancement - Feasibility and Benefits\n\n### Feasibility:\n- **Implementation Complexity**: Medium-High. Resources would require exposing ChromaDB collections in a standardized way.\n- **Technical Barriers**: The existing `handle_list_resources()` and `handle_read_resource()` functions are currently placeholders returning empty lists or error messages.\n\n### Benefits:\n- **Direct Data Access**: Other services could access stored memories programmatically.\n- **Integration Possibilities**: Opens up possibilities for external tools to leverage the memory service.\n- **System Transparency**: Allows clients to browse available memory collections.\n\n### Specific Useful Resources to Implement:\n1. `/collections/{collection_name}` - Access specific ChromaDB collections\n2. `/memories` - Access all stored memories\n3. `/memories/tag/{tag}` - Access memories filtered by tag\n\n## 3. Implementation Considerations\n\n### Prompts Implementation:\n- Requires adding a proper `@self.server.call_prompt()` handler\n- Adapting the existing retrieval logic to work within the prompt framework\n- Adding appropriate JSON schemas for prompt input/output\n\n### Resources Implementation:\n- Ensuring proper pagination for large collections\n- Adding security controls to prevent exposing sensitive information\n- Creating resource templates for common query patterns\n\n## 4. Conclusion and Recommendations\n\n**Are the enhancements feasible?** Yes, both are technically feasible and would enhance the service.\n\n**Are they beneficial?** Yes, these enhancements would:\n1. Make the memory service more fully compliant with the MCP specification\n2. Improve client integration capabilities\n3. Create a more natural interface for memory operations\n\n**Implementation Priority:**\n1. MCP Prompts should be implemented first as they provide immediate user experience benefits\n2. MCP Resources should be implemented second as they enable system integration benefits\n\n**Next Steps:**\n1. Complete a detailed implementation plan with specific API signatures\n2. Develop unit tests for the new functionality\n3. Create documentation showing how to use the new capabilities\n\nThis analysis confirms that enhancing the MCP Memory Service with Prompts and Resources would be worthwhile additions that align with the goals of the Model Context Protocol to create standardized interfaces between LLMs and data sources.", "## Priority Assessment: P4 (Medium)\n\n**Feasibility**: Medium - Requires MCP protocol extensions and careful design\n**Usability**: Medium - Improves integration with MCP ecosystem\n**Value**: Medium - Better ecosystem integration for advanced users\n\n**Assessment**: This feature enhances MCP protocol integration but requires careful design to avoid breaking existing functionality. It's valuable for ecosystem integration but not critical for core operation.\n\n**Implementation Plan**:\n1. Design MCP Prompts integration for dynamic queries\n2. Implement MCP Resources for collection exposure\n3. Add authentication and pagination support\n4. Create comprehensive API documentation\n5. Test integration with other MCP services\n\n**Priority Justification**: Ecosystem integration improvement, but not essential for basic functionality. Can be implemented after core stability and usability improvements.\n\n**Dependencies**: None - can be implemented independently\n**Estimated Effort**: 2-3 weeks" ],
      "repository" : {
        "description" : "MCP server providing semantic memory and persistent storage capabilities for Claude using ChromaDB and sentence transformers.",
        "homepage" : "",
        "name" : "mcp-memory-service",
        "fullName" : "doobidoo/mcp-memory-service",
        "htmlUrl" : "https://github.com/doobidoo/mcp-memory-service",
        "gitUrl" : "git://github.com/doobidoo/mcp-memory-service.git",
        "sshUrl" : "git@github.com:doobidoo/mcp-memory-service.git",
        "cloneUrl" : "https://github.com/doobidoo/mcp-memory-service.git",
        "owner" : {
          "login" : "doobidoo",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 68,
        "stargazersCount" : 449,
        "watchersCount" : 449,
        "size" : 849,
        "openIssuesCount" : 14,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T20:07:09Z",
        "languages" : {
          "TypeScript" : 38730,
          "Dockerfile" : 1519,
          "Shell" : 4501,
          "Jinja" : 316,
          "Batchfile" : 997,
          "Python" : 857135
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to enhance the MCP Memory Service by integrating MCP Prompts and Resources features, allowing for more intelligent memory retrieval and direct access to stored memories.",
      "validationOrRequirement" : "The issue requires implementing the MCP Prompts and Resources features according to the MCP specification. It also requires designing the prompts and resources to be compatible with the existing ChromaMemoryStorage class and implementing proper error handling and authentication.",
      "attemptedFixes" : "The issue proposes modifying the `handle_retrieve_memory` function to incorporate prompt handling and implementing resource listing and reading methods. It also suggests adding pagination support, implementing authentication and authorization, and exposing individual memories as resources.",
      "otherNotes" : "The issue aims to enhance the MCP Memory Service by leveraging MCP Prompts and Resources features. It proposes modifications to the `handle_retrieve_memory` function and implementation of resource listing and reading methods. The enhancements would make the memory service more versatile and better integrated with the MCP ecosystem, allowing for more intelligent memory retrieval and direct access to stored memories.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284646
  }, {
    "issueDTO" : {
      "id" : 3221923591,
      "title" : "Add references to LXD documentation into LXC client",
      "url" : "https://github.com/canonical/lxd/issues/15993",
      "repositoryName" : "canonical/lxd",
      "description" : "### Please confirm\n\n- [x] I have searched existing issues to check if an issue already exists for my feature request.\n\n### Is your feature request related to a problem? Please describe.\n\nWhen you are learning how to setup a complex things. There are many configuration keys without any help about them. For example lxc network set is not providing any clues where to look for supported options.\nObviously they are defined on LXD level so it is not that easy.\n\n### Describe the solution you'd like\n\nJust to add please check LXD doumentation maybe with the link to it, for the list of available keys would help a lot.\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752219902.000000000,
      "user" : "err404r",
      "userHtmlUrl" : "https://github.com/err404r",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8005979?v=4",
      "labels" : [ "Good first issue", "Documentation" ],
      "state" : "OPEN",
      "comments" : [ "@minaelee want to take this one?" ],
      "repository" : {
        "description" : "Powerful system container and virtual machine manager",
        "homepage" : "https://canonical.com/lxd",
        "name" : "lxd",
        "fullName" : "canonical/lxd",
        "htmlUrl" : "https://github.com/canonical/lxd",
        "gitUrl" : "git://github.com/canonical/lxd.git",
        "sshUrl" : "git@github.com:canonical/lxd.git",
        "cloneUrl" : "https://github.com/canonical/lxd.git",
        "owner" : {
          "login" : "canonical",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 954,
        "stargazersCount" : 4534,
        "watchersCount" : 4534,
        "size" : 174345,
        "openIssuesCount" : 330,
        "subscribersCount" : 152,
        "pushedAt" : "2025-07-11T09:59:58Z",
        "languages" : {
          "Shell" : 1243963,
          "C" : 344286,
          "Makefile" : 14387,
          "Go" : 10666910,
          "Python" : 15176,
          "Emacs Lisp" : 256
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add references to LXD documentation into LXC client to help with configuration key discovery",
      "validationOrRequirement" : "No specific validations or requirements mentioned",
      "attemptedFixes" : "No attempted fixes or blockers mentioned",
      "otherNotes" : "No additional context provided",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284648
  }, {
    "issueDTO" : {
      "id" : 3215329466,
      "title" : "test runs not really working",
      "url" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/issues/229",
      "repositoryName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
      "description" : "hey i have set up the cps kit,\n\nall flows are on. agent is configured (tbh not sure if this part is really set up correctly because i was able to save the agent config but the instructions are kinda confusing)\n\ntest set was created also that worked, and now a test run was created. i just want to test the agent on gen answers. the agent goes into sharepoint and searches for a document and ge erates the response out of that. this is what i want to check. \n\nthe test will run only for the generative answer part and this part will be green, but there are still no test results.\n\n<img width=\"1981\" height=\"292\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/be8b3e2f-14db-4987-9f35-3538479e6462\" />\n\ncan you help me what i am doing wrong?",
      "updatedAt" : 1752219854.000000000,
      "user" : "marcelhuszar",
      "userHtmlUrl" : "https://github.com/marcelhuszar",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/38085464?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "To use SharePoint as knowledge source your Copilot Studio custom agent must be authenticated. Same goes for Copilot Studio Kit agent configuration, you have to set up authentication with Entra Id v2 with SSO as per instructions.\n\nI recommend starting with simple hello world with unauthenticated agent and bare minimum settings (base + direct line) in the Copilot Studio Kit agent configuration.\n\nPlease go to home page of Copilot Studio Kit, then Setup Wizard, and confirm that all test automation related flows are enabled (there will be one starting with \"Pipeline\" which you might not be able to enable, and that is fine and expected)", "i have created now a simple agent with no authentication and just a hello world topic. then ive created a test set with response match test and a test run. still not running. i did everything in the setup and here from the instructions but i cant really troubleshoot myself because the kit is not giving me feedback what could be wrong.\n\nevery cloud flow except pipeline is turned on", "Could you try to switch from using token to using direct line secret to ensure connection can be made to the custom agent.\n\nYou can get direct line secret from Copilot Studio -> Settings -> Security -> Web channel security. Copy either of the two secrets. \n\nEnter the secret in Copilot Studio Kit agent configuration -> Direct Line Settings -> Channel Security: Yes, Secret location: Dataverse, Secret: <paste your secret here>.\n\nThen save the configuration and try to run a test run again. \n\n\n" ],
      "repository" : {
        "description" : null,
        "homepage" : "",
        "name" : "Power-CAT-Copilot-Studio-Kit",
        "fullName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
        "htmlUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit",
        "gitUrl" : "git://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "sshUrl" : "git@github.com:microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "cloneUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 180,
        "watchersCount" : 180,
        "size" : 48361,
        "openIssuesCount" : 27,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-09T12:45:38Z",
        "languages" : {
          "C#" : 24850,
          "CSS" : 4368,
          "JavaScript" : 33528,
          "HTML" : 16742
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Test runs are not working, and the issue is related to the agent configuration and authentication with Entra Id v2 with SSO.",
      "validationOrRequirement" : "Agent must be authenticated with Entra Id v2 with SSO as per instructions, and Copilot Studio Kit agent configuration requires simple hello world with unauthenticated agent and bare minimum settings.",
      "attemptedFixes" : "Created a simple agent with no authentication and just a hello world topic, created a test set with response match test and a test run, tried to switch from using token to using direct line secret to ensure connection to the custom agent.",
      "otherNotes" : "Copilot Studio custom agent must be authenticated with Entra Id v2 with SSO as per instructions. Also, the kit requires simple hello world with unauthenticated agent and bare minimum settings (base + direct line) in the Copilot Studio Kit agent configuration. Direct Line secret can be used to ensure connection to custom agent.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284654
  }, {
    "issueDTO" : {
      "id" : 3083623974,
      "title" : "?????????????????? DAG ???????????????",
      "url" : "https://github.com/secretflow/kuscia/issues/737",
      "repositoryName" : "secretflow/kuscia",
      "description" : "> ??? ISSUE ??? [???????????????????????????SecretFlow Open Source Contribution Plan????????? SF OSCP???Phase 5 ](https://studio.secretflow.com/activity/yi9qqz2bvslnbqf/detail)?????? ISSUE???????????????????????????????????????\n> - ????????????????????????????????????[??????](https://studio.secretflow.com/activity/yi9qqz2bvslnbqf/detail)???\n> - ???????????????????????? [???OSCP Phase5 Season of Dev???Project](https://github.com/orgs/secretflow/projects/13)\n>\n> This ISSUE is one of the tasks of the  [SecretFlow Open Source Contribution Plan (referred to as SF OSCP) Phase 5](https://studio.secretflow.com/activity/yi9qqz2bvslnbqf/detail). Welcome to join us in building it together!\n> - Before claiming a task, please make sure you have [signed up](https://studio.secretflow.com/activity/yi9qqz2bvslnbqf/detail).\n> - For more tasks, you can check the [\"OSCP Phase5 Season of Dev\" Project](https://github.com/orgs/secretflow/projects/13).\n\n### ????????????\n+ ????????????????????????????????? DAG ???????????????\n+ ???????????????Kuscia / Shell\n+ ?????????????????????\uD83C\uDF1F\n+ ???????????????????????????1 ???\n+ ?????? Reviewer???@YanZhuangz???@yujun4464\n\n### ????????????\n?????? Kuscia ????????????????????? PSI?????????????????????????????????????????? DAG ??????????????? Kuscia ?????????????????????????????? DAG ??????????????? ??????????????? KusciaAPI ?????????\n\n+ ???????????????\n    - Kuscia Scripts???scripts/user/create_example_job.sh???\n    - ?????? [Kuscia ????????????](https://www.secretflow.org.cn/zh-CN/docs/kuscia/v0.15.0b0/deployment/Docker_deployment_kuscia) ???????????????\n    - ????????????[?????? SecretPad](https://www.secretflow.org.cn/zh-CN/docs/secretpad/v0.12.0b0/deployment/guide) ???????????????????????????????????? DAG ???????????????????????????????????? Kuscia ?????????\n+ PR ???????????????????????????????????? DAG ??? ???\n+ ???????????????????????? repo ??????????????????????????????\n+ ?????????????????????????????????????????? ISSUE ?????????????????? Kuscia ?????????\n\n### ????????????\n+ ??????????????? Shell ?????????\n+ ?????? Kuscia ??? SecretPad ???????????? Git ???????????????",
      "updatedAt" : 1752219837.000000000,
      "user" : "Candicepan",
      "userHtmlUrl" : "https://github.com/Candicepan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/48274303?v=4",
      "labels" : [ "OSCP", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "kinokoshelter Give it to me", "> kinokoshelter Give it to me\n\nHello???Congratulations on successfully claiming this task, and thank you for your support of the OSCP! Please complete your contribution within one week, otherwise, the task will be released. If you have any questions, please let us know. \uD83D\uDE04\n\n????????????????????????????????????????????? OSCP ??????????????????  1 ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????" ],
      "repository" : {
        "description" : "Kuscia(Kubernetes-based Secure Collaborative InfrA) is a K8s-based privacy-preserving computing task orchestration framework.",
        "homepage" : "https://www.secretflow.org.cn/docs/kuscia/latest/zh-Hans",
        "name" : "kuscia",
        "fullName" : "secretflow/kuscia",
        "htmlUrl" : "https://github.com/secretflow/kuscia",
        "gitUrl" : "git://github.com/secretflow/kuscia.git",
        "sshUrl" : "git@github.com:secretflow/kuscia.git",
        "cloneUrl" : "https://github.com/secretflow/kuscia.git",
        "owner" : {
          "login" : "secretflow",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 92,
        "stargazersCount" : 107,
        "watchersCount" : 107,
        "size" : 18081,
        "openIssuesCount" : 97,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-11T10:29:54Z",
        "languages" : {
          "Dockerfile" : 9170,
          "Shell" : 255310,
          "Starlark" : 5700,
          "Makefile" : 22439,
          "Go" : 5450262,
          "Python" : 254935
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a complex DAG flow example script based on the latest Kuscia version, using KusciaAPI, and submit the code to the Kuscia repository",
      "validationOrRequirement" : "The task requires understanding of basic Shell syntax, familiarity with Kuscia and SecretPad deployment, and basic Git operations. The PR should include a script with more complex DAG flow.",
      "attemptedFixes" : "None mentioned in the issue description or comments",
      "otherNotes" : "This issue is part of the SecretFlow Open Source Contribution Plan (SF OSCP) Phase 5, and welcomes community developers to participate in building it together. The task is to add a complex DAG flow example script based on the latest Kuscia version, using KusciaAPI, and requires knowledge of basic Shell syntax and familiarity with Kuscia and SecretPad deployment and Git basic operations.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284660
  }, {
    "issueDTO" : {
      "id" : 3215518974,
      "title" : "[DAG] SelectionDAG::canCreateUndefOrPoison - add ISD::FMA/FMAD handling + tests",
      "url" : "https://github.com/llvm/llvm-project/issues/147693",
      "repositoryName" : "llvm/llvm-project",
      "description" : "Match ValueTracking's llvm::canCreateUndefOrPoison - add ISD::FMA/FMAD to the other fp ops in SelectionDAG::canCreateUndefOrPoison and add suitable test coverage.",
      "updatedAt" : 1752219526.000000000,
      "user" : "RKSimon",
      "userHtmlUrl" : "https://github.com/RKSimon",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2175834?v=4",
      "labels" : [ "llvm:SelectionDAG", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\nHi!\n\nThis issue may be a good introductory issue for people new to working on LLVM. If you would like to work on this issue, your first steps are:\n\n1. Check that no other contributor is working on this issue. If someone is assigned to the issue or claimed to be working on it, ping the person. After one week without a response, the assignee may be changed.\n1. Leave a comment indicating that you are working on the issue, or just create a [pull request](https://github.com/llvm/llvm-project/pulls) after following the steps below. [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n1. Fix the issue locally.\n1. [Run the test suite](https://llvm.org/docs/TestingGuide.html#unit-and-regression-tests) locally. Remember that the subdirectories under `test/` create fine-grained testing targets, so you can e.g. use `make check-clang-ast` to only run Clang's AST tests.\n1. Create a Git commit.\n1. Run [`git clang-format HEAD~1`](https://clang.llvm.org/docs/ClangFormat.html#git-integration) to format your changes.\n1. Open a [pull request](https://github.com/llvm/llvm-project/pulls) to the [upstream repository](https://github.com/llvm/llvm-project) on GitHub. Detailed instructions can be found [in GitHub's documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request). [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n\nIf you have any further questions about this issue, don't hesitate to ask via a comment in the thread below.\n\n", "\n@llvm/issue-subscribers-good-first-issue\n\nAuthor: Simon Pilgrim (RKSimon)\n\n<details>\nMatch ValueTracking's llvm::canCreateUndefOrPoison - add ISD::FMA/FMAD to the other fp ops in SelectionDAG::canCreateUndefOrPoison and add suitable test coverage.\n</details>\n", "Hi! I'd like to work on this issue. Can you assign it to me?", "> Match ValueTracking's llvm::canCreateUndefOrPoison - add ISD::FMA/FMAD to the other fp ops in SelectionDAG::canCreateUndefOrPoison and add suitable test coverage.\n\nHi! I'm new to open source and llvm, sorry if I'm doing something wrong.\nI've done some research on poison(new concept for me) if I understand correctly, the FMA case should work similarly to ADD and MUL, i.e. always return false (unless the flags are set, but they are checked separately).  And the ValueTracking's llvm::canCreateUndefOrPoison has the same logic. Did I understand correctly?", "This is the kind of codegen tests you should be creating:\n```ll\ndefine float @src(float %a0, float %a1, float %a2) {\n  %fma = call float @llvm.fma.f32(float %a0, float %a1, float %a2)\n  %freeze = freeze float %fma\n  %fneg = fneg float %freeze\n  ret float %fneg\n}\ndefine float @tgt(float %a0, float %a1, float %a2) {\n  %f0 = freeze float %a0\n  %f1 = freeze float %a1\n  %f2 = freeze float %a2\n  %fma = call float @llvm.fma.f32(float %f0, float %f1, float %f2)\n  %fneg = fneg float %fma\n  ret float %fneg\n}\n```\nllc -mtriple=aarch64--\n```asm\nsrc: // @src\n  fmadd s0, s0, s1, s2\n  fneg s0, s0\n  ret\ntgt: // @tgt\n  fnmadd s0, s0, s1, s2\n  ret\n```\nhttps://zig.godbolt.org/z/1fe67aao6\n\nIn `@src` - the freeze between the fneg and the fma is preventing the fold into fnmadd from occurring. But if the compiler knows ISD::FMA doesn't create undef/poison itself then its enough to freeze the inputs like in `@tgt` (as that's the only place that undef/poison can come from) - DAGCombiner can already do all this, it just needs to be told by the canCreateUndefOrPoison helper that ISD::FMA is safe.\n\nISD::FMAD should be similar." ],
      "repository" : {
        "description" : "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.",
        "homepage" : "http://llvm.org",
        "name" : "llvm-project",
        "fullName" : "llvm/llvm-project",
        "htmlUrl" : "https://github.com/llvm/llvm-project",
        "gitUrl" : "git://github.com/llvm/llvm-project.git",
        "sshUrl" : "git@github.com:llvm/llvm-project.git",
        "cloneUrl" : "https://github.com/llvm/llvm-project.git",
        "owner" : {
          "login" : "llvm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14443,
        "stargazersCount" : 33450,
        "watchersCount" : 33450,
        "size" : 2519038,
        "openIssuesCount" : 30765,
        "subscribersCount" : 577,
        "pushedAt" : "2025-07-12T01:01:34Z",
        "languages" : {
          "GDB" : 8473,
          "CMake" : 4075997,
          "Mustache" : 16482,
          "HTML" : 1956247,
          "Pawn" : 10154,
          "MATLAB" : 4946,
          "Fortran" : 11610249,
          "LLVM" : 631719945,
          "OCaml" : 335815,
          "Assembly" : 150737335,
          "Python" : 12915167,
          "Rust" : 4903,
          "Objective-C++" : 1173632,
          "SWIG" : 287770,
          "Tree-sitter Query" : 6195,
          "Perl" : 183797,
          "MLIR" : 21179643,
          "Cuda" : 1243342,
          "Scilab" : 160404,
          "Starlark" : 1177382,
          "Batchfile" : 52122,
          "AMPL" : 1662,
          "Swift" : 271,
          "DTrace" : 334,
          "C" : 202129658,
          "RPC" : 28,
          "Makefile" : 114902,
          "Cool" : 5401,
          "Jupyter Notebook" : 72939,
          "M" : 9785,
          "TypeScript" : 69121,
          "Shell" : 263950,
          "Awk" : 127345,
          "JavaScript" : 161607,
          "Mathematica" : 1118,
          "Objective-C" : 4269109,
          "Lua" : 12033,
          "PHP" : 64,
          "Limbo" : 303,
          "POV-Ray SDL" : 861,
          "Emacs Lisp" : 69003,
          "C++" : 488688394,
          "CSS" : 63859,
          "FIRRTL" : 4298018,
          "TeX" : 2141,
          "AppleScript" : 1429,
          "NASL" : 35217,
          "HIP" : 856703,
          "Julia" : 49676,
          "Dockerfile" : 23252,
          "Linker Script" : 903,
          "Roff" : 60700,
          "HLSL" : 1475332,
          "Mercury" : 14,
          "Vim Script" : 29186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add ISD::FMA/FMAD handling to SelectionDAG::canCreateUndefOrPoison and add suitable test coverage.",
      "validationOrRequirement" : "The author provides a detailed description of the expected outcome, including the need to add ISD::FMA/FMAD handling to SelectionDAG::canCreateUndefOrPoison and add suitable test coverage. The issue is labeled as a good first issue, indicating that it's suitable for new contributors to LLVM.",
      "attemptedFixes" : "The issue is still open, no attempted fixes have been made yet.",
      "otherNotes" : "The issue is about adding ISD::FMA/FMAD handling to SelectionDAG::canCreateUndefOrPoison and adding suitable test coverage. It's a good first issue for new contributors to LLVM. The author provides a detailed description of the issue and expected outcome. The comments section includes discussions about the issue, including a new contributor's understanding of the concept of poison and how it relates to the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284668
  }, {
    "issueDTO" : {
      "id" : 3061297838,
      "title" : "Make /events/logs to accept x-greptime-pipeline-name header",
      "url" : "https://github.com/GreptimeTeam/greptimedb/issues/6095",
      "repositoryName" : "GreptimeTeam/greptimedb",
      "description" : "### What type of enhancement is this?\n\nAPI improvement\n\n### What does the enhancement do?\n\nThe OTEL protocols accept `x-greptime-pipeline-name` as a pipeline name, but `/events/logs` does not. This inconsistency is unfriendly to users.\n\n\n\n### Implementation challenges\n\n_No response_",
      "updatedAt" : 1752219386.000000000,
      "user" : "killme2008",
      "userHtmlUrl" : "https://github.com/killme2008",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/14142?v=4",
      "labels" : [ "good first issue", "C-enhancement" ],
      "state" : "OPEN",
      "comments" : [ " It's in the header because you can't add query params to the otel protocol, and /event/logs is not an interface to the otel protocol. Is it necessary to add this feature?", "I think `x-greptime-pipeline-name` is a generic header that we can support in other HTTP endpoints.", "Do we have a plan to support it? @paomian " ],
      "repository" : {
        "description" : "Open-source, cloud-native, unified observability database for metrics, logs and traces, supporting SQL/PromQL/Streaming. Available on GreptimeCloud.",
        "homepage" : "https://greptime.com/",
        "name" : "greptimedb",
        "fullName" : "GreptimeTeam/greptimedb",
        "htmlUrl" : "https://github.com/GreptimeTeam/greptimedb",
        "gitUrl" : "git://github.com/GreptimeTeam/greptimedb.git",
        "sshUrl" : "git@github.com:GreptimeTeam/greptimedb.git",
        "cloneUrl" : "https://github.com/GreptimeTeam/greptimedb.git",
        "owner" : {
          "login" : "GreptimeTeam",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 389,
        "stargazersCount" : 5372,
        "watchersCount" : 5372,
        "size" : 60930,
        "openIssuesCount" : 192,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-11T16:38:32Z",
        "languages" : {
          "TypeScript" : 18683,
          "Dockerfile" : 10036,
          "Shell" : 19802,
          "Rust" : 16530106,
          "Makefile" : 9148,
          "Nix" : 1507,
          "Python" : 8004
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "make /events/logs accept x-greptime-pipeline-name header to be consistent with OTEL protocols",
      "validationOrRequirement" : "add x-greptime-pipeline-name header to /events/logs",
      "attemptedFixes" : "no response",
      "otherNotes" : "x-greptime-pipeline-name is a generic header that can be supported in other HTTP endpoints, and it's not an interface to the otel protocol",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284671
  }, {
    "issueDTO" : {
      "id" : 3217537333,
      "title" : "Remove no-throw-error ESLint suppressions in @liam-hq/erd-core",
      "url" : "https://github.com/liam-hq/liam/issues/2465",
      "repositoryName" : "liam-hq/liam",
      "description" : "## Summary\n\nThis issue tracks the removal of ESLint suppressions for the `no-throw-error/no-throw-error` rule in the `@liam-hq/erd-core` package.\n\n## Context\n\nPR #2442 introduced a custom ESLint rule that prohibits `throw new Error()` statements and encourages the use of neverthrow Result types instead. To enable incremental adoption, bulk suppressions were applied to existing violations.\n\n## Task\n\nReplace all `throw new Error()` statements in the `frontend/packages/erd-core/` directory with neverthrow Result types (`err`, `ok`, `ResultAsync`) imported from \"neverthrow\".\n\n## Files to update\n\n- `frontend/packages/erd-core/eslint-suppressions.json` - Contains 22 suppressed violations\n\n## Steps\n\n1. Review the suppressed violations in `frontend/packages/erd-core/eslint-suppressions.json`\n2. Replace `throw new Error()` statements with appropriate neverthrow Result types\n3. Import neverthrow types: `import { err, ok, ResultAsync } from \"neverthrow\"`\n4. Update function return types to use `Result<T, E>` or `ResultAsync<T, E>`\n5. Update calling code to handle Result types appropriately\n6. Run `pnpm lint:eslint --prune-suppressions` to update eslint-suppressions.json after modifications\n7. Verify all suppressions are resolved\n\n## Related\n\n- Resolves: #2442",
      "updatedAt" : 1752219297.000000000,
      "user" : "claude[bot]",
      "userHtmlUrl" : "https://github.com/apps/claude",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/1236702?v=4",
      "labels" : [ "neverthrow", "eslint", "tech debt", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Automatically generates beautiful and easy-to-read ER diagrams from your database.",
        "homepage" : "https://liambx.com",
        "name" : "liam",
        "fullName" : "liam-hq/liam",
        "htmlUrl" : "https://github.com/liam-hq/liam",
        "gitUrl" : "git://github.com/liam-hq/liam.git",
        "sshUrl" : "git@github.com:liam-hq/liam.git",
        "cloneUrl" : "https://github.com/liam-hq/liam.git",
        "owner" : {
          "login" : "liam-hq",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 4149,
        "watchersCount" : 4149,
        "size" : 128286,
        "openIssuesCount" : 86,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-12T00:59:43Z",
        "languages" : {
          "TypeScript" : 1870996,
          "MDX" : 82980,
          "CSS" : 229518,
          "Shell" : 5433,
          "PLpgSQL" : 360220,
          "Handlebars" : 695,
          "JavaScript" : 42995,
          "HTML" : 985,
          "Ruby" : 7830
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove no-throw-error ESLint suppressions in @liam-hq/erd-core package, replacing throw new Error() statements with neverthrow Result types.",
      "validationOrRequirement" : "Review the suppressed violations in frontend/packages/erd-core/eslint-suppressions.json, replace throw new Error() statements, import neverthrow types, update function return types, update calling code, run pnpm lint:eslint --prune-suppressions, and verify all suppressions are resolved.",
      "attemptedFixes" : "Replace all throw new Error() statements with neverthrow Result types (err, ok, ResultAsync) imported from 'neverthrow'.",
      "otherNotes" : "PR #2442 introduced a custom ESLint rule and bulk suppressions were applied to existing violations. Files to update: frontend/packages/erd-core/eslint-suppressions.json",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284676
  }, {
    "issueDTO" : {
      "id" : 3217930116,
      "title" : "[Term Entry] JavaScript Number methods: .MIN_VALUE",
      "url" : "https://github.com/Codecademy/docs/issues/7317",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `.MIN_VALUE` under number-methods in JavaScript. The entry should be in `content/javascript/concepts/number-methods/terms/MIN-VALUE/MIN-VALUE.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that show an example of the current entry.\n- An ## Codebyte section that have a compilable code inside it showing the current entry in use. Use ```codebyte/javascript to add compilable code.\n\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752219293.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "claimed", "good first issue", "javascript" ],
      "state" : "OPEN",
      "comments" : [ "i am interested in taking this issue on. I learned about Docs through Coursera.", "Hey @OzkurtAhmet You???re assigned \uD83C\uDF89 In addition to the documents linked in the description, please also look at the [Contribution Guide](https://www.codecademy.com/resources/docs/contribution-guide). After creating a PR, the maintainer(s) (with the collaborator label) will add comments/suggestions to address any revisions before approval.\n\n", "Thank you. I will work on this issue seriously.\r\n________________________________\r\nG??nderen: Mamta Wardhani ***@***.***>\r\nG??nderildi: 11 Temmuz 2025 Cuma 07:28\r\nKime: Codecademy/docs ***@***.***>\r\nBilgi: OzkurtAhmet ***@***.***>; Assign ***@***.***>\r\nKonu: Re: [Codecademy/docs] [Term Entry] JavaScript Number methods: .MIN_VALUE (Issue #7317)\r\n\r\n[https://avatars.githubusercontent.com/u/53176352?s=20&v=4]mamtawardhani left a comment (Codecademy/docs#7317)<https://github.com/Codecademy/docs/issues/7317#issuecomment-3061018936>\r\n\r\nHey @OzkurtAhmet<https://github.com/OzkurtAhmet> You???re assigned \uD83C\uDF89 In addition to the documents linked in the description, please also look at the Contribution Guide<https://www.codecademy.com/resources/docs/contribution-guide>. After creating a PR, the maintainer(s) (with the collaborator label) will add comments/suggestions to address any revisions before approval.\r\n\r\n???\r\nReply to this email directly, view it on GitHub<https://github.com/Codecademy/docs/issues/7317#issuecomment-3061018936>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/BR3J6MT42UU45SGPCMVHQ533H5RTFAVCNFSM6AAAAACBF5JIVGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZTANRRGAYTQOJTGY>.\r\nYou are receiving this because you were assigned.Message ID: ***@***.***>\r\n" ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new entry for the term `.MIN_VALUE` under number-methods in JavaScript.",
      "validationOrRequirement" : "The entry should include a description, syntax, example, and codebyte sections. The PR should follow the term entry template, content standards, and markdown style guide.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is about creating a new entry for the term `.MIN_VALUE` under number-methods in JavaScript. The entry should include a description, syntax, example, and codebyte sections. The PR should follow the term entry template, content standards, and markdown style guide. The issue is assigned to @OzkurtAhmet.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284681
  }, {
    "issueDTO" : {
      "id" : 2501494243,
      "title" : "Page translation request: outdated or missing Tamil pages",
      "url" : "https://github.com/tldr-pages/tldr/issues/13577",
      "repositoryName" : "tldr-pages/tldr",
      "description" : "Right now (2024-09-02) there are:\r\n\r\n- 134 missing alias page(s) in check-pages.ta/missing-ta-alias-pages.txt.\r\n- 183 missing TLDR page(s) in check-pages.ta/missing-tldr-ta-commands.txt.\r\n- 8 outdated page(s) based on number of commands in check-pages.ta/outdated-ta-pages-based-on-command-count.txt.\r\n- 15 outdated page(s) based on the commands itself in check-pages.ta/outdated-ta-pages-based-on-command-contents.txt.\r\n\r\nThis is according to https://github.com/tldr-pages/tldr-maintenance. I see we are constantly adding new pages, which is great, but if we keep this stack above building up, it won???t be feasible to fix these issues anymore. \r\nTherefore I would like to open this request to call Tamil maintainers to keep the Tamil pages up-to-date, besides adding new pages.\r\n\r\n@kbdharun\r\n\r\n> [!NOTE]  \r\n> This issue is for Tamil only, but I could open way more issues for all other CODEOWNER-maintained languages. I want to mention again how useful https://github.com/tldr-pages/tldr-maintenance is to me. I can check very quickly if I have to do any work on updating the Dutch pages e.g., or if we have to run set-more-info-link.py e.g.",
      "updatedAt" : 1752219198.000000000,
      "user" : "sebastiaanspeck",
      "userHtmlUrl" : "https://github.com/sebastiaanspeck",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12570668?v=4",
      "labels" : [ "translation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for the issue, I will try to update the pages when I get some free time. Will do the outdated pages first then will take care of alias pages.", "Lemme see if there's anything I can do to help." ],
      "repository" : {
        "description" : "\uD83D\uDCDA Collaborative cheatsheets for console commands",
        "homepage" : "https://tldr.sh",
        "name" : "tldr",
        "fullName" : "tldr-pages/tldr",
        "htmlUrl" : "https://github.com/tldr-pages/tldr",
        "gitUrl" : "git://github.com/tldr-pages/tldr.git",
        "sshUrl" : "git@github.com:tldr-pages/tldr.git",
        "cloneUrl" : "https://github.com/tldr-pages/tldr.git",
        "owner" : {
          "login" : "tldr-pages",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4561,
        "stargazersCount" : 56360,
        "watchersCount" : 56360,
        "size" : 37733,
        "openIssuesCount" : 211,
        "subscribersCount" : 386,
        "pushedAt" : "2025-07-11T23:14:41Z",
        "languages" : {
          "Shell" : 18090,
          "CSS" : 1056,
          "JavaScript" : 1896,
          "Markdown" : 12503732,
          "Python" : 57544
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Request to call Tamil maintainers to keep Tamil pages up-to-date, besides adding new pages, to prevent the stack of issues from growing too large.",
      "validationOrRequirement" : "The Tamil pages must be updated, including alias pages, TLDR pages, and outdated pages, and the updates must be tracked using https://github.com/tldr-pages/tldr-maintenance.",
      "attemptedFixes" : "The Tamil maintainer @kbdharun offered to update the pages when they have free time, and another commenter expressed willingness to help.",
      "otherNotes" : "Tamil pages are missing or outdated, and the issue is for Tamil only, but more issues could be opened for other languages.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284686
  }, {
    "issueDTO" : {
      "id" : 3221141006,
      "title" : "[Feature] ??????????????????????????????????????????????????????",
      "url" : "https://github.com/VisActor/VTable/issues/4191",
      "repositoryName" : "VisActor/VTable",
      "description" : "### What problem does this feature solve?\n\n?????????????????????????????????api\n\n### What does the proposed API look like?\n\n????????????????????????????????????????????????????????????????????????????????????????????????????????????",
      "updatedAt" : 1752218992.000000000,
      "user" : "Alia2006",
      "userHtmlUrl" : "https://github.com/Alia2006",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/93459415?v=4",
      "labels" : [ "feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "?????????????????????\n??????????????????????????? issue ??????????????????issue????????????????????????issue????????????????????????????????????pr????????????\n??????????????????????????????????????????????????????????????????????????????pr????????????????????????????????????????????????????????????\n????????????????????????https://visactor.io/vtable/guide/Contribution_Guide\n????????????????????????????????????????????????app????????????????????????\n![??????20241029-170312](https://github.com/user-attachments/assets/f753113a-f466-437d-b6d7-951e70303ae9)\n???????????????????????????\n\nThank you for your feedback! We have received your question and will deal with it later.\nIf any developer is interested in this issue, please leave a message \"claim this issue\" below the issue. Welcome to participate in open source co-construction!\nWe are very grateful to every contributor. After submitting the PR, we will prepare a gift for the developers who participated in the co-construction.\nFor participation in co-construction, please refer to: https://visactor.io/vtable/guide/Contribution_Guide\nTo communicate with official developers, you can download the Feishu app and scan the QR code to join the Feishu group???\nThank you again for your support!" ],
      "repository" : {
        "description" : "VTable is not just a high-performance multidimensional data analysis table, but also a grid artist that creates art between rows and columns.",
        "homepage" : "https://visactor.io/vtable",
        "name" : "VTable",
        "fullName" : "VisActor/VTable",
        "htmlUrl" : "https://github.com/VisActor/VTable",
        "gitUrl" : "git://github.com/VisActor/VTable.git",
        "sshUrl" : "git@github.com:VisActor/VTable.git",
        "cloneUrl" : "https://github.com/VisActor/VTable.git",
        "owner" : {
          "login" : "VisActor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 356,
        "stargazersCount" : 2884,
        "watchersCount" : 2884,
        "size" : 158418,
        "openIssuesCount" : 520,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-11T11:02:12Z",
        "languages" : {
          "TypeScript" : 18660441,
          "CSS" : 18323,
          "Shell" : 1217,
          "JavaScript" : 255328,
          "Vue" : 163673,
          "HTML" : 7400
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add a configuration and feature that allows moving into subnodes.",
      "validationOrRequirement" : "The issue requires a proposed API for moving into subnodes, and the API should use mouse coordinates to determine the level of movement.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The issue is related to the lack of API for moving into subnodes, and the proposed API would use mouse coordinates to determine whether to move into a subnode or stay at the same level.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284690
  }, {
    "issueDTO" : {
      "id" : 3217918099,
      "title" : "[Term Entry] JavaScript Number methods: .isSafeInteger()",
      "url" : "https://github.com/Codecademy/docs/issues/7312",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `.isSafeInteger()` under number-methods in JavaScript. The entry should be in `content/javascript/concepts/number-methods/terms/isSafeInteger/isSafeInteger.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that show an example of the current entry.\n- An ## Codebyte section that have a compilable code inside it showing the current entry in use. Use ```codebyte/javascript to add compilable code.\n\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752218966.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "claimed", "good first issue", "javascript" ],
      "state" : "OPEN",
      "comments" : [ "Hi **@codecademy-doc**s \uD83D\uDC4B,\n\nI'd like to work on this issue. Could you please assign it to me?\n\nThanks!", "Hey @onealanil You???re assigned \uD83C\uDF89 In addition to the documents linked in the description, please also look at the [Contribution Guide](https://www.codecademy.com/resources/docs/contribution-guide). After creating a PR, the maintainer(s) (with the collaborator label) will add comments/suggestions to address any revisions before approval.\n\nIs this your first contribution to Codecademy Docs? If so, we???re curious to know how you found out about contributing to Docs." ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new term entry for `.isSafeInteger()` under number-methods in JavaScript",
      "validationOrRequirement" : "Entry should include description, syntax, example, and codebyte sections; follow term entry template, content standards, and markdown style guide",
      "attemptedFixes" : "Issue is assigned to a contributor and awaiting PR",
      "otherNotes" : "Please refer to the term entry template, content standards, and markdown style guide when working on the PR for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284693
  }, {
    "issueDTO" : {
      "id" : 3217928150,
      "title" : "[Term Entry] JavaScript Number methods: .MAX_VALUE",
      "url" : "https://github.com/Codecademy/docs/issues/7316",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `.MAX_VALUE` under number-methods in JavaScript. The entry should be in `content/javascript/concepts/number-methods/terms/MAX-VALUE/MAX-VALUE.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that show an example of the current entry.\n- An ## Codebyte section that have a compilable code inside it showing the current entry in use. Use ```codebyte/javascript to add compilable code.\n\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752218939.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "claimed", "good first issue", "javascript" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I would like to work on this to complete my Learn Git - Kanban Project unit.", "Hey @lengelbrec You???re assigned \uD83C\uDF89 In addition to the documents linked in the description, please also look at the [Contribution Guide](https://www.codecademy.com/resources/docs/contribution-guide). After creating a PR, the maintainer(s) (with the collaborator label) will add comments/suggestions to address any revisions before approval.\n\n" ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new entry on the term `.MAX_VALUE` under number-methods in JavaScript, including description, syntax, example, and codebyte sections",
      "validationOrRequirement" : "Follow Codecademy Doc's Code of Conduct, refer to term entry template, content standards, and markdown style guide",
      "attemptedFixes" : "Labels added, issue is not assigned yet",
      "otherNotes" : "Please refer to the term entry template, content standards, and markdown style guide when working on the PR for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284697
  }, {
    "issueDTO" : {
      "id" : 3221883556,
      "title" : "GCS backup store without authentication needs a project id config",
      "url" : "https://github.com/camunda/camunda/issues/35204",
      "repositoryName" : "camunda/camunda",
      "description" : "The GCS backup store supports `Authentication.None` for testing. Using that mode, the GCS client library can't know about the project id, a prerequisite for creating new buckets.\n\nYou can verify this by running `gcloud config unset project` in a terminal, and then trying to execute tests like `GcsBackupAcceptanceIT`. The will fail with the following exception: \n\n```\ncom.google.cloud.storage.StorageException: Required parameter project must be specified.\n\tat com.google.cloud.storage.StorageException.getStorageException(StorageException.java:110)\n\tat com.google.cloud.storage.StorageException.coalesce(StorageException.java:131)\n\tat com.google.cloud.storage.Retrying$DefaultRetrier.run(Retrying.java:180)\n\tat com.google.cloud.storage.Retrying$HttpRetrier.run(Retrying.java:206)\n\tat com.google.cloud.storage.StorageImpl.run(StorageImpl.java:1619)\n\tat com.google.cloud.storage.StorageImpl.create(StorageImpl.java:147)\n\tat io.camunda.zeebe.it.backup.GcsBackupAcceptanceIT.beforeAll(GcsBackupAcceptanceIT.java:75)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:565)\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1604)\n\tSuppressed: com.google.cloud.storage.RetryContext$RetryBudgetExhaustedComment: Unretryable error (attempts: 1, maxAttempts: 6, elapsed: PT0.009S, nextBackoff: PT1.565733751S, timeout: PT50S)\nCaused by: java.lang.NullPointerException: Required parameter project must be specified.\n\tat com.google.common.base.Preconditions.checkNotNull(Preconditions.java:920)\n\tat com.google.api.client.util.Preconditions.checkNotNull(Preconditions.java:138)\n\tat com.google.api.services.storage.Storage$Buckets$Insert.<init>(Storage.java:2605)\n\tat com.google.api.services.storage.Storage$Buckets.insert(Storage.java:2580)\n\tat com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:394)\n\tat com.google.cloud.storage.StorageImpl.lambda$create$0(StorageImpl.java:149)\n\tat com.google.cloud.storage.Retrying$DefaultRetrier.run(Retrying.java:165)\n\t... 6 more\n```\n\nThis went unnotices so far because most of our developers have at some point set a default project, for example `gcloud config set project zeebe-io`. In our CI, the integration tests run on self-hosted VMs in GCP where the client library can discover the project id from its environment.\n\nWe should introduce a new optional configuration property to specify the project id. If it is set, we use it to build the client in `GcsBackupStore#buildClient`",
      "updatedAt" : 1752218909.000000000,
      "user" : "lenaschoenburg",
      "userHtmlUrl" : "https://github.com/lenaschoenburg",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1379753?v=4",
      "labels" : [ "component/zeebe", "component/backup", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Process Orchestration Framework",
        "homepage" : "https://camunda.com/platform/",
        "name" : "camunda",
        "fullName" : "camunda/camunda",
        "htmlUrl" : "https://github.com/camunda/camunda",
        "gitUrl" : "git://github.com/camunda/camunda.git",
        "sshUrl" : "git@github.com:camunda/camunda.git",
        "cloneUrl" : "https://github.com/camunda/camunda.git",
        "owner" : {
          "login" : "camunda",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 679,
        "stargazersCount" : 3723,
        "watchersCount" : 3723,
        "size" : 643351,
        "openIssuesCount" : 2373,
        "subscribersCount" : 114,
        "pushedAt" : "2025-07-11T23:23:17Z",
        "languages" : {
          "MDX" : 2383,
          "Smarty" : 230,
          "Java" : 53137212,
          "CSS" : 2925,
          "Makefile" : 20359,
          "Go" : 76584,
          "HTML" : 14209,
          "FreeMarker" : 94639,
          "TypeScript" : 6978501,
          "Dockerfile" : 23726,
          "Shell" : 47376,
          "Batchfile" : 3877,
          "SCSS" : 133874,
          "JavaScript" : 1534294
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Introduce a new optional configuration property to specify the project id for GCS backup store without authentication, to avoid the 'Required parameter project must be specified' error.",
      "validationOrRequirement" : "The project id must be specified, and a new optional configuration property should be introduced to specify it.",
      "attemptedFixes" : "None mentioned in the description.",
      "otherNotes" : "The issue is related to GCS backup store without authentication, where the client library can't know about the project id, a prerequisite for creating new buckets.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284701
  }, {
    "issueDTO" : {
      "id" : 3129287670,
      "title" : "[Feature] ???????????????????????????vtable ?????????????????????????????????????????????????????????????????????",
      "url" : "https://github.com/VisActor/VTable/issues/4015",
      "repositoryName" : "VisActor/VTable",
      "description" : "### What problem does this feature solve?\n\n???????????????????????????vtable ????????????????????????????????????????????????????????????????????????\n\n![Image](https://github.com/user-attachments/assets/68d6d728-a9c7-4ab8-81ec-9583610fec65)\n\n### What does the proposed API look like?\n\n???????????????????????????vtable ?????????????????????",
      "updatedAt" : 1752218908.000000000,
      "user" : "liuhuan1011",
      "userHtmlUrl" : "https://github.com/liuhuan1011",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/24770327?v=4",
      "labels" : [ "feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "???????????????????????????pr?????????", "@fangsmile ?????????????????????????????????????????? table-group?????????????????? rightdown ???????????????????????????????????????????????????????????????????????????????????? header ?????????????????????????????????????????????????????????????????????\nhttps://github.com/VisActor/VTable/blob/develop/packages/vtable/src/event/listener/table-group.ts ", "table-group??????????????????????????????????????????????????????" ],
      "repository" : {
        "description" : "VTable is not just a high-performance multidimensional data analysis table, but also a grid artist that creates art between rows and columns.",
        "homepage" : "https://visactor.io/vtable",
        "name" : "VTable",
        "fullName" : "VisActor/VTable",
        "htmlUrl" : "https://github.com/VisActor/VTable",
        "gitUrl" : "git://github.com/VisActor/VTable.git",
        "sshUrl" : "git@github.com:VisActor/VTable.git",
        "cloneUrl" : "https://github.com/VisActor/VTable.git",
        "owner" : {
          "login" : "VisActor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 356,
        "stargazersCount" : 2884,
        "watchersCount" : 2884,
        "size" : 158418,
        "openIssuesCount" : 520,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-11T11:02:12Z",
        "languages" : {
          "TypeScript" : 18660441,
          "CSS" : 18323,
          "Shell" : 1217,
          "JavaScript" : 255328,
          "Vue" : 163673,
          "HTML" : 7400
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement right-click menu support in the entire vtable range, currently not supported when there is no data.",
      "validationOrRequirement" : "The right-down custom event in the table-group file should be triggered when right-clicking on the header.",
      "attemptedFixes" : "None mentioned in the comments.",
      "otherNotes" : "The proposed API is to support right-click menu opening in the entire vtable range, currently not supported when there is no data.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284704
  }, {
    "issueDTO" : {
      "id" : 3221877074,
      "title" : "Rename Features enum in WIT",
      "url" : "https://github.com/bytecodealliance/ComponentizeJS/issues/249",
      "repositoryName" : "bytecodealliance/ComponentizeJS",
      "description" : "As noted on a recent PR, it would be nice if the `features` enum on the WIT side was named a bit more appropriately, because from code it *seems* like it represents a list. \n\nThis should be a tiny change and a tiny PR -- perfect for new contributors. \n\nTo start off, the WIT for the splicer should be changed, and generally following errors should suffice.",
      "updatedAt" : 1752218787.000000000,
      "user" : "vados-cosmonic",
      "userHtmlUrl" : "https://github.com/vados-cosmonic",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/123968127?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "JS -> WebAssembly Component",
        "homepage" : "",
        "name" : "ComponentizeJS",
        "fullName" : "bytecodealliance/ComponentizeJS",
        "htmlUrl" : "https://github.com/bytecodealliance/ComponentizeJS",
        "gitUrl" : "git://github.com/bytecodealliance/ComponentizeJS.git",
        "sshUrl" : "git@github.com:bytecodealliance/ComponentizeJS.git",
        "cloneUrl" : "https://github.com/bytecodealliance/ComponentizeJS.git",
        "owner" : {
          "login" : "bytecodealliance",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 37,
        "stargazersCount" : 309,
        "watchersCount" : 309,
        "size" : 31135,
        "openIssuesCount" : 38,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-08T16:21:02Z",
        "languages" : {
          "C++" : 20822,
          "Shell" : 436,
          "Rust" : 139696,
          "CMake" : 1937,
          "Makefile" : 2328,
          "JavaScript" : 88104
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rename the 'features' enum in WIT to better represent its purpose",
      "validationOrRequirement" : "rename the 'features' enum on the WIT side with a more appropriate name",
      "attemptedFixes" : "",
      "otherNotes" : "This issue is considered a good first issue and is perfect for new contributors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284706
  }, {
    "issueDTO" : {
      "id" : 3185762201,
      "title" : "use wrapper type and relative func to gen test object",
      "url" : "https://github.com/volcano-sh/volcano/issues/4417",
      "repositoryName" : "volcano-sh/volcano",
      "description" : "### What is the problem you're trying to solve\n\nwhen write ut, we need to generate some object such as pod,podgroups (eg: https://github.com/volcano-sh/volcano/blob/master/pkg/scheduler/util/test_utils.go).\nThere are many fileds to be fillup and use defined functions can not cover up all fields and the parames become too long.\nin order to solve issue like:\nhttps://github.com/volcano-sh/volcano/issues/3075#issuecomment-2368050656\n\nfor reference:\n\nhttps://github.com/kubernetes/kubernetes/blob/b2f27c0649fc0f3d2a4a6dd29135ecc81781f7e4/pkg/scheduler/testing/wrappers.go#L295\n\nhttps://github.com/kubernetes/kubernetes/blob/b2f27c0649fc0f3d2a4a6dd29135ecc81781f7e4/pkg/scheduler/testing/wrappers.go#L170\n\n\n### Describe the solution you'd like\n\n```\n// PodGroupWrapper wraps a PodGroup inside.\ntype PodGroupWrapper struct{ schedulingv1beta1.PodGroup }\n\n// MakePod creates a PodGroup wrapper.\nfunc MakePodGroup() *PodGroupWrapper {\n\treturn &PodGroupWrapper{schedulingv1beta1.PodGroup{}}\n}\n\n// Obj returns the inner PodGroup.\nfunc (p *PodGroupWrapper) Obj() *schedulingv1beta1.PodGroup {\n\treturn &p.PodGroup\n}\n\n// Name sets `s` as the name of the inner PodGroup.\nfunc (p *PodGroupWrapper) Name(s string) *PodGroupWrapper {\n\tp.SetName(s)\n\treturn p\n}\n```\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752218579.000000000,
      "user" : "lowang-bh",
      "userHtmlUrl" : "https://github.com/lowang-bh",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/21003791?v=4",
      "labels" : [ "help wanted", "kind/feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/good-first-issue", "@lowang-bh: \n\tThis request has been marked as suitable for new contributors.\n\nPlease ensure the request meets the requirements listed [here](https://git.k8s.io/community/contributors/guide/help-wanted.md#good-first-issue).\n\nIf this request no longer meets these requirements, the label can be removed\nby commenting with the `/remove-good-first-issue` command.\n\n\n<details>\n\nIn response to [this](https://github.com/volcano-sh/volcano/issues/4417):\n\n>/good-first-issue\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes/test-infra](https://github.com/kubernetes/test-infra/issues/new?title=Prow%20issue:) repository.\n</details>", "/assign\n", "@lowang-bh have a look at #4420 i think this should be addressed first ", "Yes this way is better!", "same as: https://github.com/volcano-sh/volcano/issues/4265", "\nThis is a reference wip pr  https://github.com/volcano-sh/volcano/pull/4315\nthat I am not currently planning to go on due to lack of bandwidth. You can use it as part of the reference @sancheet230 " ],
      "repository" : {
        "description" : "A Cloud Native Batch System (Project under CNCF)",
        "homepage" : "https://volcano.sh",
        "name" : "volcano",
        "fullName" : "volcano-sh/volcano",
        "htmlUrl" : "https://github.com/volcano-sh/volcano",
        "gitUrl" : "git://github.com/volcano-sh/volcano.git",
        "sshUrl" : "git@github.com:volcano-sh/volcano.git",
        "cloneUrl" : "https://github.com/volcano-sh/volcano.git",
        "owner" : {
          "login" : "volcano-sh",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1154,
        "stargazersCount" : 4818,
        "watchersCount" : 4818,
        "size" : 89692,
        "openIssuesCount" : 364,
        "subscribersCount" : 85,
        "pushedAt" : "2025-07-11T03:49:33Z",
        "languages" : {
          "Smarty" : 410,
          "Dockerfile" : 7579,
          "Shell" : 129843,
          "Makefile" : 7989,
          "Go" : 3666493,
          "Python" : 498
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The objective is to generate a test object for UT, specifically for pod and podgroups, to avoid long parameters and incomplete fields.",
      "validationOrRequirement" : "The solution should use a wrapper type and relative functions to generate a test object, covering all fields and parameters.",
      "attemptedFixes" : "The issue has been discussed in the context of https://github.com/volcano-sh/volcano/pull/4315, but it's not currently being worked on due to lack of bandwidth.",
      "otherNotes" : "This issue is marked as good first issue and suitable for new contributors. The request meets the requirements listed in the contributors guide.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284711
  }, {
    "issueDTO" : {
      "id" : 771427001,
      "title" : "Add missing options for cache control",
      "url" : "https://github.com/aboutcode-org/scancode-toolkit/issues/2355",
      "repositoryName" : "aboutcode-org/scancode-toolkit",
      "description" : "As https://github.com/nexB/scancode-toolkit/blob/develop/src/scancode/cli.py#L1043 states, there is an open `TODO` for controlling the cache.\r\nI'm using scancode in an environment where `~/.cache` should *NOT* be used for storing any kind of artifacts.\r\n\r\nPlease add one of the following options\r\n\r\n- disable caching in total (as stated by the linked TODO)\r\n- option to specify the caching directory via CLI",
      "updatedAt" : 1752218549.000000000,
      "user" : "priv-kweihmann",
      "userHtmlUrl" : "https://github.com/priv-kweihmann",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/46938494?v=4",
      "labels" : [ "documentation", "core and api", "Priority: low", "easy", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Actually the cache can be controlled this way:\r\n1. the license index cache is created as package data when using the release script, so that's not really cache per se, unless you are developing.\r\n2. SCANCODE_CACHE is an environment variable that you can set to a dir and that's where cache will be written \r\n3. SCANCODE_TEMP is an environment variable that you can set to a dir and that's where temp files will be written \r\n\r\nThis definitely should be better documented", "Thanks, I guess that should do it", "@priv-kweihmann we could also expose this as command line options. Would you prefer this? that's an easy thing\r\nBTW, unrelated, I will soon work on merging support for bitbake from https://github.com/nexB/scancode-toolkit/tree/1243_collect_data_from_yocto/bitbake_.bb thanks to your excellent library! :bow: ", "We need to document the cache env var in the doc BTW. So I am reopening this\r\nSee https://github.com/nexB/scancode-toolkit/issues/2355#issuecomment-786242995", "Always happy to help. And the dedicated environment vars are more than enough for me - just didn't wanted to override HOME for my use case, so I consider this here fixed. Any further CLI option could by handled as future enhancements", "Is this issue still open ? \r\n", "@krishna9358 I think the ticket can be closed - problem was solved for me with the added documentation ", "I think we have sufficient docs for ``SCANCODE_CACHE`` and ``SCANCODE_TEMP`` in the scancode_config.py. I am not sure this need to be documented in the RTD. @pombredanne any comment?" ],
      "repository" : {
        "description" : ":mag: ScanCode detects licenses, copyrights, dependencies by \"scanning code\" ... to discover and inventory open source and third-party packages used in your code. Sponsored by NLnet project https://nlnet.nl/project/vulnerabilitydatabase, the Google Summer of Code, Azure credits, nexB and others generous sponsors!",
        "homepage" : "https://aboutcode.org/scancode/",
        "name" : "scancode-toolkit",
        "fullName" : "aboutcode-org/scancode-toolkit",
        "htmlUrl" : "https://github.com/aboutcode-org/scancode-toolkit",
        "gitUrl" : "git://github.com/aboutcode-org/scancode-toolkit.git",
        "sshUrl" : "git@github.com:aboutcode-org/scancode-toolkit.git",
        "cloneUrl" : "https://github.com/aboutcode-org/scancode-toolkit.git",
        "owner" : {
          "login" : "aboutcode-org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 600,
        "stargazersCount" : 2325,
        "watchersCount" : 2325,
        "size" : 701588,
        "openIssuesCount" : 1281,
        "subscribersCount" : 70,
        "pushedAt" : "2025-07-11T07:03:12Z",
        "languages" : {
          "C#" : 30004,
          "C" : 5180200,
          "CMake" : 142,
          "Makefile" : 13448,
          "M4" : 147877,
          "Go" : 93170,
          "Inno Setup" : 235,
          "HTML" : 1567578,
          "1C Enterprise" : 492,
          "SmPL" : 6042,
          "Shell" : 2199645,
          "sed" : 185,
          "Awk" : 248,
          "JavaScript" : 44402,
          "PHP" : 200090,
          "Objective-C" : 914,
          "ASL" : 150,
          "Visual Basic .NET" : 23,
          "Ruby" : 409138,
          "Assembly" : 137774,
          "Python" : 5501745,
          "Emacs Lisp" : 138215,
          "Raku" : 1035,
          "Java" : 361557,
          "Yacc" : 1503,
          "C++" : 933503,
          "CSS" : 5002,
          "Hack" : 2089,
          "G-code" : 579,
          "Objective-C++" : 1790,
          "TeX" : 3126,
          "AppleScript" : 168,
          "Perl" : 262863,
          "XSLT" : 474,
          "Ragel" : 27606,
          "Dockerfile" : 1605,
          "CoffeeScript" : 2235,
          "Starlark" : 3457,
          "Batchfile" : 10417,
          "Swift" : 93,
          "Roff" : 564215,
          "Rich Text Format" : 51350,
          "Vim Script" : 1129,
          "Ada" : 32547
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add missing options for cache control, including disabling caching or specifying the caching directory via CLI, to provide more flexibility and control over cache usage.",
      "validationOrRequirement" : "Add one of the following options: disable caching in total, or specify the caching directory via CLI.",
      "attemptedFixes" : "Added documentation for SCANCODE_CACHE and SCANCODE_TEMP environment variables, and provided alternatives for controlling cache.",
      "otherNotes" : "The cache can be controlled by setting SCANCODE_CACHE and SCANCODE_TEMP environment variables, or by using the release script to create a package data cache. The issue is considered fixed with added documentation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284715
  }, {
    "issueDTO" : {
      "id" : 3221847217,
      "title" : "since 3.x.0 ??? .0 ?????????",
      "url" : "https://github.com/rurema/doctree/issues/2973",
      "repositoryName" : "rurema/doctree",
      "description" : "`#@since 3.0.0` ???????????? teeny ??? .0 ????????????????????? 3.0 ?????????????????? 3.1 ????????????????????????????????????????????????????????????????????????\n\n?????? https://github.com/rurema/doctree/pull/2947#issuecomment-3060922177",
      "updatedAt" : 1752218413.000000000,
      "user" : "znz",
      "userHtmlUrl" : "https://github.com/znz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11857?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Repository of Japanese Ruby reference manual",
        "homepage" : "https://docs.ruby-lang.org/ja/",
        "name" : "doctree",
        "fullName" : "rurema/doctree",
        "htmlUrl" : "https://github.com/rurema/doctree",
        "gitUrl" : "git://github.com/rurema/doctree.git",
        "sshUrl" : "git@github.com:rurema/doctree.git",
        "cloneUrl" : "https://github.com/rurema/doctree.git",
        "owner" : {
          "login" : "rurema",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 338,
        "stargazersCount" : 250,
        "watchersCount" : 250,
        "size" : 24096,
        "openIssuesCount" : 195,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-09T04:42:21Z",
        "languages" : {
          "Dockerfile" : 195,
          "Pascal" : 6339,
          "Ruby" : 8585
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove the .0 from '#@since 3.0.0' to correctly indicate the version as 3.0",
      "validationOrRequirement" : "Remove the .0 from '#@since' version notation",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about removing the .0 from '#@since 3.0.0' to correctly indicate the version as 3.0 instead of 3.1.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284718
  }, {
    "issueDTO" : {
      "id" : 3221853163,
      "title" : "` ??? ' ??????????????????????????????????????????????????????",
      "url" : "https://github.com/rurema/doctree/issues/2974",
      "repositoryName" : "rurema/doctree",
      "description" : "caller ????????????????????????????????????????????????????????????????????????????????????\n\n?????? https://github.com/rurema/doctree/pull/2947#issuecomment-3060922177",
      "updatedAt" : 1752218352.000000000,
      "user" : "znz",
      "userHtmlUrl" : "https://github.com/znz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11857?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Repository of Japanese Ruby reference manual",
        "homepage" : "https://docs.ruby-lang.org/ja/",
        "name" : "doctree",
        "fullName" : "rurema/doctree",
        "htmlUrl" : "https://github.com/rurema/doctree",
        "gitUrl" : "git://github.com/rurema/doctree.git",
        "sshUrl" : "git@github.com:rurema/doctree.git",
        "cloneUrl" : "https://github.com/rurema/doctree.git",
        "owner" : {
          "login" : "rurema",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 338,
        "stargazersCount" : 250,
        "watchersCount" : 250,
        "size" : 24096,
        "openIssuesCount" : 195,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-09T04:42:21Z",
        "languages" : {
          "Dockerfile" : 195,
          "Pascal" : 6339,
          "Ruby" : 8585
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a branch to the execution example since it changed from \" ??? \" to \" ???\"",
      "validationOrRequirement" : "Good first issue",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the changes in the execution example, specifically the caller, and the output result is different.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284721
  }, {
    "issueDTO" : {
      "id" : 2950642279,
      "title" : "Resolve deprecation in GCP Stackdrive API",
      "url" : "https://github.com/kedacore/keda/issues/6653",
      "repositoryName" : "kedacore/keda",
      "description" : "```\npkg/scalers/gcp/gcp_stackdriver_client.go:292:10: SA1019: monitoringpb.QueryTimeSeriesRequest is deprecated: Marked as deprecated in google/monitoring/v3/metric_service.proto. (staticcheck)\n        req := &monitoringpb.QueryTimeSeriesRequest{\n                ^\npkg/scalers/gcp/gcp_stackdriver_client.go:298:8: SA1019: s.queryClient.QueryTimeSeries is deprecated: QueryTimeSeries may be removed in a future version. (staticcheck)\n        it := s.queryClient.QueryTimeSeries(ctx, req)\n              ^\nmake: *** [golangci] Error 1\n```\n\nNow ignored in: https://github.com/kedacore/keda/pull/6652",
      "updatedAt" : 1752218324.000000000,
      "user" : "zroubalik",
      "userHtmlUrl" : "https://github.com/zroubalik",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/726523?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hey, Can I pick this? Thanks!", "@7h3-3mp7y-m4n absolutely, thanks!", "@zroubalik can i pick this up if @7h3-3mp7y-m4n is not working on this?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed in 7 days if no further activity occurs. Thank you for your contributions.\n", "Hi @7h3-3mp7y-m4n, just checking in. Is this issue still in progress on your end?", "Hey @rickbrouwer , apologies for the delay. I got caught up with university exams, and afterward, I didn???t follow up on the issue. I noticed that @EraKin575  showed interest in it via email, and since it was originally assigned to me, I assumed he might have picked it up. Sorry for the confusion and for leaving the issue hanging.\n\nWhile I was initially looking into the issue, I realized it might be shifting toward `PromQL` . Since the function is mainly used for refined filtering during monitoring, I was wondering,  should we consider migrating it to PromQL, or would it make more sense to replace it with `ListTimeSeriesRequest`?\n\nI haven???t done deeper research on it yet, but if it's okay with you, I???d like to pick it back up and try to get it done (hopefully soon)", "Thanks for the update, much appreciated. Absolutely, would be great if you could continue.\n\nYou're absolutely right about PromQL. I also think we should migrate, or at least support both (PromQL and MQL). See this issue for more information: https://github.com/kedacore/keda/issues/6255#issuecomment-3058821622\n\nI haven't looked deeply into what you've done to determine whether it should and can be replaced with `ListTimeSeriesRequest`. If that removes the deprecation message and keeps the scaler working, I think that's fine.\n\nPlease check and consider the above issue when making your choices. If you have any doubts, please let us know so we (the community) can help you decide." ],
      "repository" : {
        "description" : " KEDA is a Kubernetes-based Event Driven Autoscaling component. It provides event driven scale for any container running in Kubernetes ",
        "homepage" : "https://keda.sh",
        "name" : "keda",
        "fullName" : "kedacore/keda",
        "htmlUrl" : "https://github.com/kedacore/keda",
        "gitUrl" : "git://github.com/kedacore/keda.git",
        "sshUrl" : "git@github.com:kedacore/keda.git",
        "cloneUrl" : "https://github.com/kedacore/keda.git",
        "owner" : {
          "login" : "kedacore",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1170,
        "stargazersCount" : 9240,
        "watchersCount" : 9240,
        "size" : 81931,
        "openIssuesCount" : 230,
        "subscribersCount" : 89,
        "pushedAt" : "2025-07-11T14:30:16Z",
        "languages" : {
          "Dockerfile" : 6074,
          "Shell" : 12146,
          "Makefile" : 18993,
          "Go" : 4523699
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Resolve deprecation in GCP Stackdriver API",
      "validationOrRequirement" : "The issue requires a fix for the deprecated methods in GCP Stackdriver API. The fix should either migrate to PromQL or replace with `ListTimeSeriesRequest`.",
      "attemptedFixes" : "The author initially looked into the issue but realized it might be shifting toward PromQL. The author is willing to pick it back up and try to get it done.",
      "otherNotes" : "The issue is related to deprecation in GCP Stackdriver API, specifically in `pkg/scalers/gcp/gcp_stackdriver_client.go` file. The `QueryTimeSeriesRequest` and `QueryTimeSeries` methods are deprecated. The author is considering migrating to PromQL or replacing with `ListTimeSeriesRequest`. There is a related issue #6255 for more information.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284726
  }, {
    "issueDTO" : {
      "id" : 3207383454,
      "title" : "Volcengine plugin error: token too long",
      "url" : "https://github.com/langgenius/dify-official-plugins/issues/1226",
      "repositoryName" : "langgenius/dify-official-plugins",
      "description" : "### Self Checks\n\n- [x] This is only for bug report, if you would like to ask a question, please head to [Discussions](https://github.com/langgenius/dify/discussions/categories/general).\n- [x] I have searched for existing issues [search for existing issues](https://github.com/langgenius/dify/issues), including closed ones.\n- [x] I confirm that I am using English to submit this report (????????????????????? [Language Policy](https://github.com/langgenius/dify/issues/1542)).\n- [x] [FOR CHINESE USERS] ??????????????????????????? Issue?????????????????????????????????:)\n- [x] Please do not modify this template :) and fill in all the required fields.\n\n### Dify version\n\n1.3.1\n\n### Cloud or Self Hosted\n\nSelf Hosted (Docker)\n\n### Steps to reproduce\n\n## Request Configuration\n- model : doubao-1.5-vision-pro\n- api_url: offical\n- input params: one image(file id format) and some string params (for type selection)\n- output params: just text\n- method: workflow API request\n\n## The whole step flow is\n1. upload the file to dify and get the file id\n- method: NextJS fetch method\n- request url : http://{dify-server}/v1/files/upload\n2. request the dify workflow API\n- method: NextJS fetch method\n- request url: http://{dify-server}/v1/workflows/run\n- params: image_url (Dify's id splice)\n3. get the response\n\nThe whole step is automatic. Every epoch the step will request 3 times and wait for 2 seconds.\n\n\n### ?????? Expected Behavior\n\nWhen I request the workflow API, it should give me the text result.\n\n### ??? Actual Behavior\n\nBut Sometimes the request will be error, the fetch response content is \n\n```\nTypeError: fetch failed\n  1 |\n  2 | export const DifyLLMRequest  = async (type: string, file_type: string, id: string)=>{\n> 3 |   const response = await fetch(\"http://{dify-site}/v1/workflows/run\", {\n    |                   ^\n  4 |     method: \"POST\",\n  5 |     headers: {\n  6 |       \"Content-Type\": \"application/json\", {\n  [cause]: [Error [HeadersTimeoutError]: Headers Timeout Error] \n{\n    code: 'UND_ERR_HEADERS_TIMEOUT'\n  }\n}\n```\n\nThe dashboard show nothing, just the ???FAILED??? status task. When I try to find the logs, the error step just showed \"running\" status, no other outputs.\n\n\nThen I try to get the docker logs (`docker-plugin_daemon-1`), I found that the plugin is always killed, so when it restart, the related request will be down.\n\nRelated logs\n```\n2025/05/07 07:05:37 stdio.go:166: [ERROR]plugin langgenius/volcengine_maas:0.0.13 has an error on stdout: bufio.Scanner: token too long\n2025/05/07 07:05:37 run.go:132: [ERROR]plugin langgenius/volcengine_maas:0.0.13 exited with error: signal: killed\n```\n\nThe `token` in `token too long` maybe not my prompt token, because I found various size image also have the same error.\n",
      "updatedAt" : 1752218081.000000000,
      "user" : "Nothing1024",
      "userHtmlUrl" : "https://github.com/Nothing1024",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/78358913?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<!-- Answer -->\nThe \"token too long\" error you're encountering with the Volcengine plugin in Dify could be related to the handling of large data inputs, such as images, which are converted to base64 encoding. This can result in a token length that exceeds the limits set by the system. Here are some steps you can take to address this issue:\n\n1. **Reduce Image Size**: Try reducing the size of the images before uploading them to Dify. This can help prevent the base64 encoded data from exceeding the token limit.\n\n2. **Check Token Limits**: Ensure that the token limits for your model and API requests are configured correctly. Dify imposes a generation length limit of 2k tokens for reasoning models, which might be relevant if your workflow involves such models <sup>[[1]](https://github.com/langgenius/dify/issues/17120)</sup>.\n\n3. **Switch Model Provider**: If you're using the `openai_api_compatible` provider, consider switching to a different model provider that might handle larger token sizes more effectively <sup>[[2]](https://github.com/langgenius/dify/issues/18657)</sup>.\n\n4. **Review Workflow Configuration**: Double-check your workflow configuration to ensure that all parameters and settings are optimized for handling the data sizes you're working with.\n\nBy implementing these suggestions, you should be able to mitigate the \"token too long\" error and improve the stability of your plugin operations.\n\n\n<!-- Dosu Comment Footer -->\n*To continue talking to [Dosu](https://dosu.dev), mention @dosu.*\n\n---\n<sup>Help Dosu learn! Give it feedback: [Great Response](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=great_response) | [Irrelevant Answer](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=irrelevant_answer) | [Incorrect Sources](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=incorrect_sources) | [Too Verbose](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=too_verbose) | [Hallucination](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=hallucination) | [Bug Report](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=bug_report) | [Other](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=other)</sup>\n", "> The \"token too long\" error you're encountering with the Volcengine plugin in Dify could be related to the handling of large data inputs, such as images, which are converted to base64 encoding. This can result in a token length that exceeds the limits set by the system. Here are some steps you can take to address this issue:???????????? Dify ?????? Volcengine ?????????????????? \"???????????? \"??????????????????????????????????????????????????? base64 ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n> \n> 1. **Reduce Image Size**: Try reducing the size of the images before uploading them to Dify. This can help prevent the base64 encoded data from exceeding the token limit.**?????????????????? **???????????????????????? Dify ????????????????????????????????????????????????????????? base64 ?????????????????????????????????\n> 2. **Check Token Limits**: Ensure that the token limits for your model and API requests are configured correctly. Dify imposes a generation length limit of 2k tokens for reasoning models, which might be relevant if your workflow involves such models [[1]](https://github.com/langgenius/dify/issues/17120).**?????????????????? **?????????????????????????????? API ????????????????????????Dify ???????????????????????? 2k ????????????????????????????????????????????????????????????????????????????????????????????? [[1]](https://github.com/langgenius/dify/issues/17120) ???\n> 3. **Switch Model Provider**: If you're using the `openai_api_compatible` provider, consider switching to a different model provider that might handle larger token sizes more effectively [[2]](https://github.com/langgenius/dify/issues/18657).**???????????????????????? **???????????????????????? `openai_api_compatible` ?????????????????????????????????????????????????????????????????????????????????????????????????????????????????? [[2]](https://github.com/langgenius/dify/issues/18657) ???\n> 4. **Review Workflow Configuration**: Double-check your workflow configuration to ensure that all parameters and settings are optimized for handling the data sizes you're working with.**???????????????????????? **?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n> \n> By implementing these suggestions, you should be able to mitigate the \"token too long\" error and improve the stability of your plugin operations.???????????????????????????????????????????????? \"???????????? \"?????????????????????????????????????????????\n> \n> _To continue talking to [Dosu](https://dosu.dev), mention [@dosu](https://github.com/dosu).???????????? [Dosu](https://dosu.dev) ?????????????????? ???_\n> \n> Help Dosu learn! Give it feedback: [Great Response](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=great_response) | [Irrelevant Answer](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=irrelevant_answer) | [Incorrect Sources](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=incorrect_sources) | [Too Verbose](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=too_verbose) | [Hallucination](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=hallucination) | [Bug Report](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=bug_report) | [Other](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=other)?????? Dosu ????????????????????????[ ????????? ](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=great_response) | [ ?????????????????? ](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=irrelevant_answer) | [ ??????????????? ](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=incorrect_sources) | [ ????????? ](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=too_verbose) | [ ?????? ](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=hallucination) | [ ???????????? ](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=bug_report) | [ ?????? ](https://app.dosu.dev/response-feedback/4394e3dc-f373-4604-9d72-99bdfe5b5874?feedback_type=other)???\n\nStep 1 and Step 2 are tried to fix, but failed.\nStep 3 is not fit, because I use the offical Volcengine plugin.\nStep 4 is not clear.", "same problem\n", "Unable to reproduce this issue with Dify online 1.4.0, doubao-1.5-vision-pro-250328\nTry upgrading your local version of Dify\n\n![Image](https://github.com/user-attachments/assets/3c1e92c7-f54a-42db-aca3-0e7990a2e137)\n\n![Image](https://github.com/user-attachments/assets/b155fbe1-b07c-4d5e-9d6c-1cfb31b01e2e)", "@764852987 ????????????????????????????????? 5MB ???", "> Unable to reproduce this issue with Dify online 1.4.0, doubao-1.5-vision-pro-250328 Try upgrading your local version of Dify\n> \n> ![Image](https://github.com/user-attachments/assets/3c1e92c7-f54a-42db-aca3-0e7990a2e137)\n> \n> ![Image](https://github.com/user-attachments/assets/b155fbe1-b07c-4d5e-9d6c-1cfb31b01e2e)\n\n???????????????????????????????????????WEB-GUI????????????????????????API???????????????????????????????????????????????????????????????????????????", "I don't encounter this issue with GPT-4.1, but when using Doubao-1.5-vision-pro, if the image size exceeds 3MB, it directly prompts: \"failed to read response body: bufio.Scanner: token too long\".\n\nVersion: 1.4.1\n\n![Image](https://github.com/user-attachments/assets/5f4fee8e-68e6-4937-8047-b387837e7c55)\n\n![Image](https://github.com/user-attachments/assets/b0061613-5f2e-48db-ab20-b598e0be705e)\n", "From the reason description above,  the cause of the problem is the limit of bufio.Scanner. But it is a Go struct in deamon-plugin, that should be a common problem in model plugin, i'd like to ask why the problem only occurs in volcengine and openai-compatible plugin?", "save error with plugin: hjlarry/markdown-editor: 0.0.2\n2025/07/02 10:59:24 stdio.go:188: [ERROR]plugin hjlarry/markdown-editor:0.0.2 has an error on stdout: bufio.Scanner: token too long\n2025/07/02 10:59:24 run.go:135: [ERROR]plugin hjlarry/markdown-editor:0.0.2 exited with error: signal: killed\n\n", "Same issue happened: plugin_daemon-1  | 2025/07/02 14:33:57 stdio.go:188: [ERROR]plugin hjlarry/agent:0.0.1 has an error on stdout: bufio.Scanner: token too long\nplugin_daemon-1  | 2025/07/02 14:33:57 run.go:135: [ERROR]plugin hjlarry/agent:0.0.1 exited with error: signal: killed. VERSION: 1.5.0", "A similar here: plugin_daemon-1  | 2025/07/02 14:27:41 stdio.go:182: [INFO]plugin junjiem/mcp_see_agent:0.2.2: response content: b''\nplugin_daemon-1  | 2025/07/02 14:27:55 stdio.go:182: [INFO]plugin junjiem/mcp_see_agent:0.2.2: response status: 200 OK\nplugin_daemon-1  | 2025/07/02 14:27:55 stdio.go:182: [INFO]plugin junjiem/mcp_see_agent:0.2.2: response headers: Headers({'date': 'Wed, 02 Jul 2025 14:27:40 GMT', 'server': 'uvicorn', 'cache-control': 'no-cache, no-transform', 'connection': 'keep-alive', 'content-type': 'text/event-stream', 'mcp-session-id': 'f85208f7ab6b41b79480fe497b4bf5ce', 'x-accel-buffering': 'no', 'transfer-encoding': 'chunked'})\nplugin_daemon-1  | 2025/07/02 14:27:55 stdio.go:188: [ERROR]plugin junjiem/mcp_see_agent:0.2.2 has an error on stdout: bufio.Scanner: token too long\nplugin_daemon-1  | 2025/07/02 14:27:55 run.go:135: [ERROR]plugin junjiem/mcp_see_agent:0.2.2 exited with error: signal: killed\nplugin_daemon-1  | 2025/07/02 14:27:55 run.go:190: [INFO]plugin junjiem/mcp_see_agent:0.2.2 stopped\nplugin_daemon-1  | 2025/07/02 14:28:00 run.go:147: [INFO]plugin junjiem/mcp_see_agent:0.2.2 started", "doesn't this bug fixed in 1.6.0? I still got this probem in 1.6.0 with plugin hjlarry/dify-plugin-markdown-editor." ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "dify-official-plugins",
        "fullName" : "langgenius/dify-official-plugins",
        "htmlUrl" : "https://github.com/langgenius/dify-official-plugins",
        "gitUrl" : "git://github.com/langgenius/dify-official-plugins.git",
        "sshUrl" : "git@github.com:langgenius/dify-official-plugins.git",
        "cloneUrl" : "https://github.com/langgenius/dify-official-plugins.git",
        "owner" : {
          "login" : "langgenius",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 402,
        "stargazersCount" : 307,
        "watchersCount" : 307,
        "size" : 66718,
        "openIssuesCount" : 276,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T11:00:11Z",
        "languages" : {
          "Python" : 11582174
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the 'token too long' error that occurs when using the Volcengine and OpenAI-compatible plugins in Dify. The issue is related to the handling of large data inputs, such as images, which are converted to base64 encoding.",
      "validationOrRequirement" : "The issue is related to the handling of large data inputs, such as images, which are converted to base64 encoding. The token length should not exceed the limits set by the system.",
      "attemptedFixes" : "Steps 1 and 2 have been tried to fix the issue, but failed. Step 3 is not applicable as the official Volcengine plugin is being used. Step 4 is unclear. The issue has been reported in different versions of Dify, including 1.4.1, 1.5.0, and 1.6.0.",
      "otherNotes" : "The issue is related to the handling of large data inputs, such as images, which are converted to base64 encoding. The error occurs when the token length exceeds the limits set by the system. The problem only occurs in the Volcengine and OpenAI-compatible plugins. The issue has been reported in versions 1.4.1 and 1.5.0, but the problem still persists in version 1.6.0. The same issue also occurs in other plugins, such as hjlarry/markdown-editor and junjiem/mcp_see_agent.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284737
  }, {
    "issueDTO" : {
      "id" : 3219353240,
      "title" : "[ISSUE] on 8.8 Web Modeler web app does not work when ingress is disabled",
      "url" : "https://github.com/camunda/camunda-platform-helm/issues/3790",
      "repositoryName" : "camunda/camunda-platform-helm",
      "description" : "**Describe the issue:**\n\n<!-- A clear and concise description of what the issue is. -->\nWeb Modeler web app does not work when ingress is disabled. Here is what I see in the logs:\n```\nValidationError: \"client.pusher.host\" is not allowed to be empty\n```\nHere is where this config is set:\nhttps://github.com/camunda/camunda-platform-helm/blob/bfc52eb245654ba297942057d402e9d1a4b78a2a/charts/camunda-platform-8.8/templates/web-modeler/configmap-webapp.yaml#L39-L39\n\n\n**Actual behavior:**\n\n<!-- A clear and concise description of what actually happens. -->\n\n**Expected behavior:**\n\n<!-- A clear and concise description of what you expected to happen. -->\n\n**How to reproduce:**\n\n<!--\nSteps to reproduce the issue.\n\nIf possible add a minimal reproducer code sample in a new repo/branch.\n-->\nHere is the values.yaml I used:\n```\nglobal:\n  identity:\n    auth:\n      enabled: true\n      #needs to be added in base values.yaml\n      publicIssuerUrl: \"http://camunda-keycloak/auth/realms/camunda-platform\"\n      admin:\n        enabled: true\n        existingSecret:\n          name: \"integration-test-credentials\"\n      webModeler:\n        redirectUrl: \"http://camunda-modeler\"\n      console:\n        redirectUrl: \"http://camunda-console\"\n        existingSecret:\n          name: \"integration-test-credentials\"\n      optimize:\n        redirectUrl: \"http://camunda-optimize\"\n        existingSecret:\n          name: \"integration-test-credentials\"\n      #######################\n      # Orchestration Group\n      #######################\n      core:\n        redirectUrl: \"http://camunda-core:8080\"\n        existingSecret:\n          name: \"integration-test-credentials\"\n      connectors:\n        existingSecret:\n          name: \"integration-test-credentials\"\n  security:\n    authentication:\n      method: oidc\n\nidentity:\n  enabled: true\n  firstUser:\n    existingSecret: \"integration-test-credentials\"\n\nidentityKeycloak:\n  enabled: true\n  postgresql:\n    auth:\n      existingSecret: \"integration-test-credentials\"\n      secretKeys:\n        adminPasswordKey: \"identity-keycloak-postgresql-admin-password\"\n        userPasswordKey: \"identity-keycloak-postgresql-user-password\"\n  auth:\n    existingSecret: \"integration-test-credentials\"\n    passwordSecretKey: \"identity-keycloak-admin-password\"\n\noptimize:\n  enabled: true\n\nconnectors:\n  inbound:\n    mode: oauth\n\nwebModeler:\n  enabled: true\n  restapi:\n    mail:\n      # This value is required, otherwise the restapi pod wouldn't start.\n      fromAddress: noreply@example.com\n\n# WebModeler Database.\nwebModelerPostgresql:\n  enabled: true\n  auth:\n    existingSecret: \"integration-test-credentials\"\n    secretKeys:\n      adminPasswordKey: \"webmodeler-postgresql-admin-password\"\n      userPasswordKey: \"webmodeler-postgresql-user-password\"\n\ncore:\n  enabled: true\n  clusterSize: \"1\"\n  partitionCount: \"1\"\n  replicationFactor: \"1\"\n  env:\n    - name: CAMUNDA_SECURITY_INITIALIZATION_MAPPINGS_0_MAPPINGID\n      value: \"demo-user-mapping\"\n    - name: CAMUNDA_SECURITY_INITIALIZATION_MAPPINGS_0_CLAIMNAME\n      value: \"preferred_username\"\n    - name: CAMUNDA_SECURITY_INITIALIZATION_MAPPINGS_0_CLAIMVALUE\n      value: \"demo\"\n    - name: CAMUNDA_SECURITY_INITIALIZATION_MAPPINGS_1_MAPPINGID\n      value: \"connectors-client-mapping\"\n    - name: CAMUNDA_SECURITY_INITIALIZATION_MAPPINGS_1_CLAIMNAME\n      value: \"client_id\"\n    - name: CAMUNDA_SECURITY_INITIALIZATION_MAPPINGS_1_CLAIMVALUE\n      value: \"connectors\"\n    - name: CAMUNDA_SECURITY_INITIALIZATION_DEFAULTROLES_ADMIN_MAPPINGS_0\n      value: \"demo-user-mapping\"\n    - name: CAMUNDA_SECURITY_INITIALIZATION_DEFAULTROLES_ADMIN_MAPPINGS_1\n      value: \"connectors-client-mapping\"\n\nconsole:\n  enabled: true\n\nelasticsearch:\n  maxUnavailable: 0\n  master:\n    replicaCount: 1\n\n```\n**Logs:**\n\n<!-- If possible add the full logs related to the issue. -->\n\n**Environment:**\n\n**Please note: Without the following info, it's hard to resolve the issue and probably it will be closed.**\n\n- Platform: <!-- [e.g. GCP, AWS, etc] -->\n- Helm CLI version: <!-- [e.g. 3.10.0] -->\n- Chart version: <!-- [e.g. 8.x.x] -->\n- Values file: <!-- [e.g. include or link to your values file] -->\n",
      "updatedAt" : 1752218009.000000000,
      "user" : "hamza-m-masood",
      "userHtmlUrl" : "https://github.com/hamza-m-masood",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47217263?v=4",
      "labels" : [ "platform/aws", "version/8.8", "kind/issue", "platform/gcp", "good first issue", "target:8.8-alpha7" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Camunda Platform 8 Self-Managed Helm charts",
        "homepage" : "https://docs.camunda.io/docs/self-managed/about-self-managed/",
        "name" : "camunda-platform-helm",
        "fullName" : "camunda/camunda-platform-helm",
        "htmlUrl" : "https://github.com/camunda/camunda-platform-helm",
        "gitUrl" : "git://github.com/camunda/camunda-platform-helm.git",
        "sshUrl" : "git@github.com:camunda/camunda-platform-helm.git",
        "cloneUrl" : "https://github.com/camunda/camunda-platform-helm.git",
        "owner" : {
          "login" : "camunda",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 147,
        "stargazersCount" : 78,
        "watchersCount" : 78,
        "size" : 18681,
        "openIssuesCount" : 188,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-12T00:17:31Z",
        "languages" : {
          "Smarty" : 287750,
          "TypeScript" : 34107,
          "Dockerfile" : 358,
          "Shell" : 37710,
          "Makefile" : 8338,
          "JavaScript" : 386,
          "Go" : 3122162,
          "Mustache" : 469977
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the error 'ValidationError: \"client.pusher.host\" is not allowed to be empty' when trying to disable the ingress in the Web Modeler web app.",
      "validationOrRequirement" : "The ingress should be enabled for the Web Modeler web app to work. The configmap-webapp.yaml file should be checked for the correct configuration.",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is related to the Web Modeler web app not working when ingress is disabled. The error message is 'ValidationError: \"client.pusher.host\" is not allowed to be empty'. The problem is with the configmap-webapp.yaml file where the config is set.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284742
  }, {
    "issueDTO" : {
      "id" : 3221834674,
      "title" : "Paimon tiering best practise note in docs",
      "url" : "https://github.com/apache/fluss/issues/1306",
      "repositoryName" : "apache/fluss",
      "description" : "### Search before asking\n\n- [x] I searched in the [issues](https://github.com/alibaba/fluss/issues) and found nothing similar.\n\n\n### Description\n\nWhen users use the tiering service to write to paimon, parquet writers use Flink memory however managed memory is not used. Users can set the managed.memory to a small value like 128MB or lower and give that memory back to the JVM heap, to avoid wasting resources.\n\nWe can add this as a \"best practices section\" when starting the tiering service.\n\n<img width=\"2160\" height=\"527\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/83724b25-5706-4efb-b138-564c206a9431\" />\n\n### Willingness to contribute\n\n- [x] I'm willing to submit a PR!",
      "updatedAt" : 1752217999.000000000,
      "user" : "polyzos",
      "userHtmlUrl" : "https://github.com/polyzos",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/23555517?v=4",
      "labels" : [ "component=docs", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Apache Fluss is a streaming storage built for real-time analytics.",
        "homepage" : "https://fluss.apache.org/",
        "name" : "fluss",
        "fullName" : "apache/fluss",
        "htmlUrl" : "https://github.com/apache/fluss",
        "gitUrl" : "git://github.com/apache/fluss.git",
        "sshUrl" : "git@github.com:apache/fluss.git",
        "cloneUrl" : "https://github.com/apache/fluss.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 349,
        "stargazersCount" : 1307,
        "watchersCount" : 1307,
        "size" : 41783,
        "openIssuesCount" : 299,
        "subscribersCount" : 33,
        "pushedAt" : "2025-07-11T14:01:28Z",
        "languages" : {
          "TypeScript" : 17752,
          "MDX" : 17568,
          "Java" : 10712509,
          "Dockerfile" : 1561,
          "Shell" : 40748,
          "CSS" : 10287,
          "JavaScript" : 6256
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a 'best practices section' to the tiering service documentation, specifically noting that users can set managed.memory to a small value to avoid wasting resources when using the tiering service to write to Paimon.",
      "validationOrRequirement" : "No specific validations or requirements mentioned.",
      "attemptedFixes" : "None mentioned in the description.",
      "otherNotes" : "The issue description includes an image attachment and a willingness to contribute from the author.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284745
  }, {
    "issueDTO" : {
      "id" : 3216004724,
      "title" : "Update the icon in the tab to be that of our brand",
      "url" : "https://github.com/ourjapanlife/findadoc-web/issues/1369",
      "repositoryName" : "ourjapanlife/findadoc-web",
      "description" : "# Problem\nThe icon is a generic hospital symbol in the tab. It would be nice to have it be our brands icon of the magnifying glass with the heart on it\n\n# Success\nOur icon shows in the browser tab\n### Requirements\n\n- [ ] Our icon shows in the browser tab of the magnifying glass and the heart inside\n\nCurrently it looks like this \n\n<img width=\"229\" height=\"41\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/90f61928-6812-496d-a26f-ffaecc36e218\" />\n\nI want it to have this icon\n\n<img width=\"52\" height=\"62\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/927003ee-be92-47c9-9b27-92656e1f3d1d\" />",
      "updatedAt" : 1752217872.000000000,
      "user" : "NabbeunNabi",
      "userHtmlUrl" : "https://github.com/NabbeunNabi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/124335161?v=4",
      "labels" : [ "design", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I could work on it, could you assign me the task?", "is this issue still open", "> is this issue still open\n\nHi thanks for your interest.\n\nBut as you can see there is an assignee.\n\nWe would love to have you and others help.  But if someone is assigned to the issue they are currently working on it. \uD83D\uDE47????????? " ],
      "repository" : {
        "description" : "Front-end repository for Find a Doc, Japan",
        "homepage" : "https://findadoc.jp",
        "name" : "findadoc-web",
        "fullName" : "ourjapanlife/findadoc-web",
        "htmlUrl" : "https://github.com/ourjapanlife/findadoc-web",
        "gitUrl" : "git://github.com/ourjapanlife/findadoc-web.git",
        "sshUrl" : "git@github.com:ourjapanlife/findadoc-web.git",
        "cloneUrl" : "https://github.com/ourjapanlife/findadoc-web.git",
        "owner" : {
          "login" : "ourjapanlife",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 23,
        "watchersCount" : 23,
        "size" : 39401,
        "openIssuesCount" : 83,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-11T04:54:33Z",
        "languages" : {
          "TypeScript" : 225141,
          "CSS" : 7259,
          "Vue" : 346104,
          "JavaScript" : 22410
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the icon in the tab to be that of our brand, specifically the magnifying glass with the heart on it.",
      "validationOrRequirement" : "The icon should show in the browser tab of the magnifying glass with the heart inside.",
      "attemptedFixes" : "No fixes mentioned in the comments, but the author is open to assigning the task to someone who can work on it.",
      "otherNotes" : "The issue is currently assigned to someone, so others should not attempt to work on it unless the assignee is not making progress.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284749
  }, {
    "issueDTO" : {
      "id" : 2862058257,
      "title" : "Remove slack link in Deutsch translation",
      "url" : "https://github.com/firstcontributions/first-contributions/issues/94534",
      "repositoryName" : "firstcontributions/first-contributions",
      "description" : "\n\uD83C\uDFAF **Goal**\nReplace link to slack in 'Where to go from here' section in Deutsch translation of Readme and put a link to code contributions like in English Readme.\n\n\uD83D\uDCA1 **Possible solutions**\nRemove link to slack in Deutsch translation and put a link to [code contributions repo](https://github.com/roshanjossey/code-contributions) similar to main Readme.\nYou can find it in https://github.com/firstcontributions/first-contributions/blob/main/docs/translations/README.de.md?plain=1#L110\n\n> [!IMPORTANT]\n> Please only address one issue in a PR.\n> Let's make it possible for more people to solve issues here.\n\n\uD83D\uDCCB  **Steps to solve the problem**\n\n*   Comment below about what you've started working on.\n*   Add, commit, push your changes.\n*   Submit a pull request and add this in comments - 'Addresses #<put issue number here>'\n*   Ask for reviews in comments section of pull request.\n*   Celebrate your contribution to this project. \uD83C\uDF89\n    ",
      "updatedAt" : 1752217553.000000000,
      "user" : "Roshanjossey",
      "userHtmlUrl" : "https://github.com/Roshanjossey",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8488446?v=4",
      "labels" : [ ":beetle: bug", "documentation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I would like to work on this issue. Please assign it to me. \n", "Hi, I noticed this issue and have submitted a pull request to resolve it: https://github.com/firstcontributions/first-contributions/pull/94724. \nI wasn???t officially assigned, but I wanted to contribute. Please review it when you have time and let me know if any changes are needed.\nIssue Number: #94534\nThanks!", "I would like to work on this please!", "I would like to work on this one", "/assign", "Hello, I would like to contribute as well. Is the opportunity still available?", "i would love to work on this as my first contribution please help me with it\n", "There is no slack link available in deutsch translation.Closing issue will be better.\n\n![Image](https://github.com/user-attachments/assets/aeb975f1-7372-451f-ab97-4e93982f0a9c)", "Hi, I noticed this issue and have submitted a pull request to resolve it: https://github.com/firstcontributions/first-contributions/pull/94724.\nI wasn???t officially assigned, but I wanted to contribute. Please review it when you have time and let me know if any changes are needed.\nIssue Number: https://github.com/firstcontributions/first-contributions/issues/94534\nThanks!", "I'd like to work on this issue. #94534\n\n", "Hi, I'm Arpitha. I'm new to open source and would love to contribute. Could you please assign this issue to me?\n", "Hi! I???d like to contribute to this issue. May I work on it? Please assign it to me if it???s still available.", "Hi, I'm Anthony. I???d like to contribute to this issue. Can you please assign this issue to me? ", "Hi! I'm Ahmad, a MERN Stack developer. I???d love to work on this issue. Could you please assign it to me? \uD83D\uDE0A", "Hello, I would like to contribute as well. Is the opportunity still available?", "i think this issue is fixed !", "I'm new in open source, please assign me to this issue." ],
      "repository" : {
        "description" : "\uD83D\uDE80??? Help beginners to contribute to open source projects",
        "homepage" : "https://firstcontributions.github.io",
        "name" : "first-contributions",
        "fullName" : "firstcontributions/first-contributions",
        "htmlUrl" : "https://github.com/firstcontributions/first-contributions",
        "gitUrl" : "git://github.com/firstcontributions/first-contributions.git",
        "sshUrl" : "git@github.com:firstcontributions/first-contributions.git",
        "cloneUrl" : "https://github.com/firstcontributions/first-contributions.git",
        "owner" : {
          "login" : "firstcontributions",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 88225,
        "stargazersCount" : 49291,
        "watchersCount" : 49291,
        "size" : 12386,
        "openIssuesCount" : 208,
        "subscribersCount" : 512,
        "pushedAt" : "2025-07-11T22:15:01Z",
        "languages" : { },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace the link to slack in the 'Where to go from here' section in the Deutsch translation of the Readme with a link to the code contributions repository, similar to the main Readme.",
      "validationOrRequirement" : "Please only address one issue in a PR, and add a comment in the PR with 'Addresses #94534'.",
      "attemptedFixes" : "One contributor has submitted a pull request (https://github.com/firstcontributions/first-contributions/pull/94724) to remove the slack link in the Deutsch translation.",
      "otherNotes" : "Multiple contributors have expressed interest in working on this issue, including Arpitha, Anthony, Ahmad, and others. One contributor has already submitted a pull request to resolve the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284754
  }, {
    "issueDTO" : {
      "id" : 2600859155,
      "title" : "Add option for `Access-Control-Allow-Private-Network` to CORSMiddleware",
      "url" : "https://github.com/falconry/falcon/issues/2381",
      "repositoryName" : "falconry/falcon",
      "description" : "Add option to enable [`Access-Control-Allow-Private-Network`](https://wicg.github.io/private-network-access/#http-headerdef-access-control-request-private-network) to CORSMiddleware.\r\n\r\nWe probably don't need to inject it unconditionally, but only in response to the `Access-Control-Request-Private-Network` request header (when set to to `true`).\r\n\r\nThe option **must be disabled** by default.",
      "updatedAt" : 1752217492.000000000,
      "user" : "vytas7",
      "userHtmlUrl" : "https://github.com/vytas7",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3430939?v=4",
      "labels" : [ "enhancement", "good first issue", "needs contributor" ],
      "state" : "OPEN",
      "comments" : [ "like this? \r\nmiddleware.py\r\n\r\n```python\r\nfrom __future__ import annotations\r\n\r\nfrom typing import Any, Iterable, Optional, Union\r\n\r\nfrom .request import Request\r\nfrom .response import Response\r\n\r\n\r\nclass CORSMiddleware(object):\r\n    \"\"\"CORS Middleware.\r\n\r\n    This middleware provides a simple out-of-the box CORS policy, including handling\r\n    of preflighted requests from the browser.\r\n\r\n    See also:\r\n\r\n    * https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\r\n    * https://www.w3.org/TR/cors/#resource-processing-model\r\n\r\n    Keyword Arguments:\r\n        allow_origins (Union[str, Iterable[str]]): List of origins to allow (case\r\n            sensitive). The string ``'*'`` acts as a wildcard, matching every origin.\r\n            (default ``'*'``).\r\n        expose_headers (Optional[Union[str, Iterable[str]]]): List of additional\r\n            response headers to expose via the ``Access-Control-Expose-Headers``\r\n            header. These headers are in addition to the CORS-safelisted ones:\r\n            ``Cache-Control``, ``Content-Language``, ``Content-Length``,\r\n            ``Content-Type``, ``Expires``, ``Last-Modified``, ``Pragma``.\r\n            (default ``None``).\r\n\r\n            See also:\r\n            https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Expose-Headers\r\n        allow_credentials (Optional[Union[str, Iterable[str]]]): List of origins\r\n            (case sensitive) for which to allow credentials via the\r\n            ``Access-Control-Allow-Credentials`` header.\r\n            The string ``'*'`` acts as a wildcard, matching every allowed origin,\r\n            while ``None`` disallows all origins. This parameter takes effect only\r\n            if the origin is allowed by the ``allow_origins`` argument.\r\n            (Default ``None``).\r\n\r\n    \"\"\"\r\n\r\n    def __init__(\r\n        self,\r\n        allow_origins: Union[str, Iterable[str]] = '*',\r\n        expose_headers: Optional[Union[str, Iterable[str]]] = None,\r\n        allow_credentials: Optional[Union[str, Iterable[str]]] = None,\r\n        allow_private_network: bool = False,\r\n    ):\r\n\r\n        if allow_origins == '*':\r\n            self.allow_origins = allow_origins\r\n        else:\r\n            if isinstance(allow_origins, str):\r\n                allow_origins = [allow_origins]\r\n            self.allow_origins = frozenset(allow_origins)\r\n            if '*' in self.allow_origins:\r\n                raise ValueError(\r\n                    'The wildcard string \"*\" may only be passed to allow_origins as a '\r\n                    'string literal, not inside an iterable.'\r\n                )\r\n\r\n        if expose_headers is not None and not isinstance(expose_headers, str):\r\n            expose_headers = ', '.join(expose_headers)\r\n        self.expose_headers = expose_headers\r\n\r\n        if allow_credentials is None:\r\n            allow_credentials = frozenset()\r\n        elif allow_credentials != '*':\r\n            if isinstance(allow_credentials, str):\r\n                allow_credentials = [allow_credentials]\r\n            allow_credentials = frozenset(allow_credentials)\r\n            if '*' in allow_credentials:\r\n                raise ValueError(\r\n                    'The wildcard string \"*\" may only be passed to allow_credentials '\r\n                    'as a string literal, not inside an iterable.'\r\n                )\r\n        self.allow_credentials = allow_credentials\r\n\r\n        self.allow_private_network = allow_private_network\r\n\r\n    def process_response(\r\n        self, req: Request, resp: Response, resource: object, req_succeeded: bool\r\n    ) -> None:\r\n        \"\"\"Implement the CORS policy for all routes.\r\n\r\n        This middleware provides a simple out-of-the box CORS policy,\r\n        including handling of preflighted requests from the browser.\r\n\r\n        See also: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\r\n\r\n        See also: https://www.w3.org/TR/cors/#resource-processing-model\r\n        \"\"\"\r\n\r\n        origin = req.get_header('Origin')\r\n        if origin is None:\r\n            return\r\n\r\n        if self.allow_origins != '*' and origin not in self.allow_origins:\r\n            return\r\n\r\n        if resp.get_header('Access-Control-Allow-Origin') is None:\r\n            set_origin = '*' if self.allow_origins == '*' else origin\r\n            if self.allow_credentials == '*' or origin in self.allow_credentials:\r\n                set_origin = origin\r\n                resp.set_header('Access-Control-Allow-Credentials', 'true')\r\n            resp.set_header('Access-Control-Allow-Origin', set_origin)\r\n\r\n        if self.expose_headers:\r\n            resp.set_header('Access-Control-Expose-Headers', self.expose_headers)\r\n\r\n        if (\r\n            req_succeeded\r\n            and req.method == 'OPTIONS'\r\n            and req.get_header('Access-Control-Request-Method')\r\n        ):\r\n            # NOTE(kgriffs): This is a CORS preflight request. Patch the\r\n            #   response accordingly.\r\n\r\n            allow = resp.get_header('Allow')\r\n            resp.delete_header('Allow')\r\n\r\n            allow_headers = req.get_header(\r\n                'Access-Control-Request-Headers', default='*'\r\n            )\r\n\r\n            resp.set_header('Access-Control-Allow-Methods', allow)\r\n            resp.set_header('Access-Control-Allow-Headers', allow_headers)\r\n            resp.set_header('Access-Control-Max-Age', '86400')  # 24 hours\r\n\r\n            if self.allow_private_network and req.get_header('Access-Control-Request-Private-Network') == 'true':\r\n                resp.set_header('Access-Control-Allow-Private-Network', 'true')\r\n\r\n\r\n    async def process_response_async(self, *args: Any) -> None:\r\n        self.process_response(*args)\r\n```", "Hi @zodecky, I haven't checked all the details, but, yes I was thinking along these lines. Could you open a pull request?", "ok", "just opened, not sure if I did it the right way", "Note: this issue is still looking for contributors.", "\uD83D\uDC40 " ],
      "repository" : {
        "description" : "The no-magic web API and microservices framework for Python developers, with an emphasis on reliability and performance at scale.",
        "homepage" : "https://falcon.readthedocs.io",
        "name" : "falcon",
        "fullName" : "falconry/falcon",
        "htmlUrl" : "https://github.com/falconry/falcon",
        "gitUrl" : "git://github.com/falconry/falcon.git",
        "sshUrl" : "git@github.com:falconry/falcon.git",
        "cloneUrl" : "https://github.com/falconry/falcon.git",
        "owner" : {
          "login" : "falconry",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 958,
        "stargazersCount" : 9689,
        "watchersCount" : 9689,
        "size" : 8152,
        "openIssuesCount" : 159,
        "subscribersCount" : 255,
        "pushedAt" : "2025-07-11T16:27:09Z",
        "languages" : {
          "Dockerfile" : 759,
          "Shell" : 2020,
          "CSS" : 1167,
          "Makefile" : 835,
          "JavaScript" : 2542,
          "HTML" : 2222,
          "Cython" : 27674,
          "Python" : 1946882
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add an option to enable `Access-Control-Allow-Private-Network` in CORSMiddleware, which should be disabled by default.",
      "validationOrRequirement" : "The option should only be injected in response to the `Access-Control-Request-Private-Network` request header (when set to `true`).",
      "attemptedFixes" : "The author, vytas7, has opened a pull request, but it's unclear if it was done correctly.",
      "otherNotes" : "The issue is about adding an option to enable `Access-Control-Allow-Private-Network` in CORSMiddleware, which should be disabled by default.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284759
  }, {
    "issueDTO" : {
      "id" : 2462758702,
      "title" : "Ambiguous change of ovn networks",
      "url" : "https://github.com/cozystack/cozystack/issues/283",
      "repositoryName" : "cozystack/cozystack",
      "description" : "Hi!\r\n\r\nIf somebody installs cozy-stack with some kind of configmap:\r\n\r\n```yaml\r\napiVersion: v1\r\nkind: ConfigMap\r\nmetadata:\r\n  name: cozystack\r\n  namespace: cozy-system\r\ndata:\r\n  bundle-name: \"paas-full\"\r\n  ipv4-pod-cidr: \"100.64.0.0/16\"\r\n  ipv4-pod-gateway: \"10.64.0.1\"\r\n  ipv4-svc-cidr: \"10.65.0.0/16\"\r\n  ipv4-join-cidr: \"100.66.0.0/16\"\r\n```\r\n\r\nit gives the broken installation. The pods are mainly running, but ovn is failing. The possible solution could be to change the configmap values to the proper ones like:\r\n\r\n```yaml\r\napiVersion: v1\r\nkind: ConfigMap\r\nmetadata:\r\n  name: cozystack\r\n  namespace: cozy-system\r\ndata:\r\n  bundle-name: \"paas-full\"\r\n  ipv4-pod-cidr: \"100.64.0.0/16\"\r\n  ipv4-pod-gateway: \"100.64.0.1\"\r\n  ipv4-svc-cidr: \"100.65.0.0/16\"\r\n  ipv4-join-cidr: \"100.66.0.0/16\"\r\n```\r\n\r\nbut unfortunately they are not applied on-the-fly. One needs to remove ovn installation with helm means and reapply it again to make cozystack installation proceed.\r\n\r\nI think we should investigate this issue and probably make some warning and / or document workaround.",
      "updatedAt" : 1752217411.000000000,
      "user" : "gecube",
      "userHtmlUrl" : "https://github.com/gecube",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2912732?v=4",
      "labels" : [ "upstream-issue", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Could you please report issue to upstream project?" ],
      "repository" : {
        "description" : "Free and Open Source PaaS framework for seamless management of virtual machines, managed Kubernetes, and Databases-as-a-Service",
        "homepage" : "https://cozystack.io",
        "name" : "cozystack",
        "fullName" : "cozystack/cozystack",
        "htmlUrl" : "https://github.com/cozystack/cozystack",
        "gitUrl" : "git://github.com/cozystack/cozystack.git",
        "sshUrl" : "git@github.com:cozystack/cozystack.git",
        "cloneUrl" : "https://github.com/cozystack/cozystack.git",
        "owner" : {
          "login" : "cozystack",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 105,
        "stargazersCount" : 1451,
        "watchersCount" : 1451,
        "size" : 11351,
        "openIssuesCount" : 125,
        "subscribersCount" : 28,
        "pushedAt" : "2025-07-11T20:17:33Z",
        "languages" : {
          "Smarty" : 423080,
          "Dockerfile" : 27033,
          "Shell" : 99806,
          "Makefile" : 58834,
          "Open Policy Agent" : 2501,
          "Go" : 138012,
          "Mustache" : 80880
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "investigate the issue, make a warning and/or document a workaround",
      "validationOrRequirement" : "configmap values should be changed to proper ones",
      "attemptedFixes" : "remove ovn installation with helm and reapply it",
      "otherNotes" : "Issue is related to installation of cozy-stack with configmap, ovn networks are failing, possible solution is to change configmap values, but they are not applied on-the-fly, workaround is to remove ovn installation with helm and reapply it",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284763
  }, {
    "issueDTO" : {
      "id" : 3151872238,
      "title" : "2025 Spring AI Alibaba ????????????/????????????",
      "url" : "https://github.com/alibaba/spring-ai-alibaba/issues/1251",
      "repositoryName" : "alibaba/spring-ai-alibaba",
      "description" : "### Description\n\n??????????????????????????????Spring AI Alibaba???Jmanus?????????<font style=\"color:rgb(31, 35, 40);\">????????????????????????????????????Spring AI Alibaba/Jmanus?????????????????????????????????????????????????????????Spring AI Alibaba/Jmanus?????????????????????????????????????????????????????????</font>\n\n## ????????????:\n1.???????????????????????????????????????????????????????????????CSDN?????????????????????B?????????????????????????????????\n2.???**????????????**?????????/???????????????????????? issue ?????????????????????????????????????????????7?????????????????????7?????????????????????????????????????????????????????????????????????\n3.???????????????????????????[????????????????????????](https://survey.aliyun.com/apps/zhiliao/aX4Z_BS8a)\n\n\n## ????????????\n1. ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????T????????????\n2. ??????????????????2???????????????????????????????????????????????????????????????????????????????????????????????????????????????/???????????????????????????????????????????????????2?????????????????????????????????????????????????????????\n\n\n## <font style=\"color:rgb(31, 35, 40);\">??????????????????</font>\n+ <font style=\"color:rgb(31, 35, 40);\">??????????????????????????????????????????????????????</font>\n+ <font style=\"color:rgb(31, 35, 40);\">????????????????????????????????????</font>\n+ <font style=\"color:rgb(31, 35, 40);\">??????????????????????????????????????????????????????</font>\n\n",
      "updatedAt" : 1752217358.000000000,
      "user" : "chickenlj",
      "userHtmlUrl" : "https://github.com/chickenlj",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18097545?v=4",
      "labels" : [ "area/community", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Spring ai alibaba????????????????????????https://github.com/GTyingzi/spring-ai-tutorial\nSpring ai alibaba????????????????????????https://mp.weixin.qq.com/s/sKBum3MHMd24cMlW8z9NCA\nSpring ai alibaba??????????????????https://www.bilibili.com/video/BV17NMsziEqp?spm_id_from=333.788.videopod.sections&vd_source=8393ba8b4463e2acda959f2ff2c792f6", "Spring ai alibaba???????????????????????????https://github.com/lzb240082240/spring-ai-hospital-appointment-clientele-services", "?????????????????????T???\uD83D\uDE1D\n??????spring-ai-alibaba???????????????RAG???????????????https://blog.csdn.net/weixin_49244783/article/details/148747645", "??????Spring-AI-Alibaba???OpenDeepWiki????????? https://github.com/D1nvan/JDeepWiki", "??????Spring-AI-Alibaba????????????????????????https://github.com/zxuexingzhijie/spring-ai-alibaba-examples/tree/main/spring-ai-alibaba-translate-example", "5?????????????????????McpTool??????????????????????????????https://mp.weixin.qq.com/s/Ax-pr3rgHbL8KSu8RAHCLQ", "Spring AI Alibaba Graph ?????? https://blog.csdn.net/qq_52397471/article/details/148660511 ", " spring AI Alibaba ?????????????????? ChatBot  [https://blog.csdn.net/weixin_50309827/article/details/148734113](https://blog.csdn.net/weixin_50309827/article/details/148734113)", ".SpringAIAlibaba+qwen????????????????????????????????????:\n?????????https://www.yuque.com/geren-t8lyq/ncgl94/yv5dnl8ohd7791n1?singleDoc# ???Spring AI Alibaba ???????????????????????????\n?????????https://www.bilibili.com/video/BV1C5UxYuEc2/\n\nJmanus??????\nhttps://www.bilibili.com/video/BV1vjKzziEC1", "??????????????????Spring AI Alibaba????????????????????????????????????RAG+Function Calling+MCP??????+????????????????????????\n????????????: https://www.processon.com/view/link/6810800f83d6ee240f5796b0?cid=67ff3b399346680abca00ff9\nB??????????????????\nhttps://www.bilibili.com/video/BV1aWE4z4Eow/?spm_id_from=333.1387.upload.video_card.click", "SpringBoot+Spring AI Alibaba??????RAG????????????: https://mp.weixin.qq.com/s/MO59zPv5OFtB01htIcIwwg", "Spring AI Alibaba + Nacos ?????? MCP Server ???????????????https://mp.weixin.qq.com/s/5dUY1lfACZnm5Ql-fiqnAQ", "???????????? Spring AI Alibaba ???NL2SQL????????????\n- https://datamining.blog.csdn.net/article/details/148768445\n- https://mp.weixin.qq.com/s/XBJ0JmJ4SMq5jbynqLYrMQ", "??????Spring AI Alibaba ???RAG??????????????????\n\n- https://github.com/luxiaobai007/springAIAlibabaRagQA\n- https://blog.csdn.net/weixin_45268711/article/details/148783089\n", "Spring AI Alibaba ????????????????????????????????????https://blog.csdn.net/sufu1065/article/details/148696485", "Spring AI ?????? PostgreSQL ???????????????RAG ????????????\nhttps://github.com/lsqlister/spring-ai-alibaba-rag-pgvector-jdbc-postgres", "Spring Ai Alibaba Graph???????????????????????????\n\n- https://blog.csdn.net/renpeng301/article/details/148877785\n- https://mp.weixin.qq.com/s/TdO8NUEKPculhVwimBbvdw\n- ?????????https://github.com/renpengben/effective-agent-spring-alibaba-graph\n", "Spring AI Alibaba JManus ???????????????????????????????????????[https://mp.weixin.qq.com/s/jArKpQjYz4gupEhf8LvQYA](https://mp.weixin.qq.com/s/jArKpQjYz4gupEhf8LvQYA)", "??????Spring AI Alibaba????????????????????????https://juejin.cn/spost/7520183736127635490", "Agent ?????????https://blog.csdn.net/sunyingboaini/article/details/148838902?spm=1001.2014.3001.5501\nRAG?????????https://blog.csdn.net/sunyingboaini/article/details/148282572?spm=1001.2014.3001.5501\nSpringAl?????????https://blog.csdn.net/sunyingboaini/article/details/147832050?spm=1001.2014.3001.5501", "?????????????????????T???\uD83D\uDE1D\n?????? Spring AI Alibaba ??????????????????????????? RAG ????????????????????????https://blog.csdn.net/2301_79969279/article/details/148951185", "Spring AI Alibaba JManus?????????https://juejin.cn/post/7520248971865112622", "Spring AI Alibaba Graph ?????? ???https://blog.csdn.net/a_ittle_pan/article/details/148951415", "??????????????????spring AI Alibaba ??????RAG????????????????????????????????????https://juejin.cn/spost/7520169104713662503\n????????????t?????????????????????", "Spring AI Alibaba??????AI Code Review?????????https://blog.csdn.net/qq_39911747/article/details/148952124", "Spring AI Alibaba Graph???????????????\nhttps://mp.weixin.qq.com/s/aIga0-YGoUrLRCLYe0u9fQ", "Spring AI Alibaba ??????????????????????????????????????????https://juejin.cn/post/7520328716082331682", "???Spring AI Alibaba ??? Jmanus???Java ???????????? AI ?????????????????????https://blog.csdn.net/qq_21267357/article/details/148954959?sharetype=blogdetail&sharerId=148954959&sharerefer=PC&sharesource=qq_21267357&spm=1011.2480.3001.8118", "??????Spring AI Alibaba NL2SQL????????????????????????: https://github.com/kaori-seasons/spring-ai-alibaba-nl2sql-examples\n\nSpring AI Alibaba??????????????????NL2SQL ---- ??????????????????????????????????????????: https://juejin.cn/post/7520448236315115558\n\nps:??????T???", "spring ai alibaba mcp?????? + ant design x????????????: https://juejin.cn/post/7520379793889067008", "???????????????ChatClient????????????https://blog.csdn.net/csynsgh/article/details/148955236", "??????spring-ai-alibaba????????????????????????????????????????????????https://blog.csdn.net/benbuben8/article/details/148955813?sharetype=blogdetail&sharerId=148955813&sharerefer=PC&sharesource=benbuben8&spm=1011.2480.3001.8118", "?????????????????????Spring AI Alibaba???????????????????????????????????????????????? https://blog.csdn.net/VLSMB/article/details/148956485?sharetype=blogdetail&sharerId=148956485&sharerefer=PC&sharesource=VLSMB&spm=1011.2480.3001.8118", "????????????????????????????????????", "???????????? Spring Cloud Alibaba AI ????????????: https://blog.csdn.net/qq_52397471/article/details/138356672", "SpringCloud Alibaba AI??????DeepSeek??????AI???????????????https://developer.aliyun.com/article/1653771", "SpringAI??????????????????json???????????????https://blog.csdn.net/qq_51864596/article/details/148975367?spm=1011.2415.3001.5331", "Spring-AI-Alibaba??????????????????Streamable-http MCP Server): \nhttps://blog.csdn.net/linguiben/article/details/148975309?spm=1018.2226.3001.4187", "??????Spring AI Alibaba???https://blog.csdn.net/weixin_63945098/article/details/148973543", "??????Spring-AI-Alibaba?????????AI?????????https://github.com/zhaoxi7109/aihelper\nhttps://blog.csdn.net/qq_51106567/article/details/148983414?spm=1011.2415.3001.5331", "???????????????https://blog.csdn.net/MuShan_bit/article/details/148984139", "Spring AI Alibaba Model Context Protocol ???????????????????????????AI??????\nhttps://github.com/javaeege/spring-ai-alibaba-ollama-mcp-weather-webflux", "Spring AI Alibaba Nacos ???????????? : https://blog.csdn.net/weixin_44754533/article/details/148996636?spm=1011.2415.3001.10575&sharefrom=mp_manage_link", "Spring AI Alibaba Graph???????????????https://blog.csdn.net/weixin_46246673/article/details/149000117?spm=1001.2014.3001.5501", "9.41 ????????????????????????????????????AI????????????spring ai alibaba openman... https://v.douyin.com/9fxbBzqM8FQ/ NJI:/ L@j.Cu 11/20 ", "spring AI Alibaba Graph ???????????? https://blog.csdn.net/m0_63798859/article/details/149065264?sharetype=blogdetail&sharerId=149065264&sharerefer=PC&sharesource=m0_63798859&spm=1011.2480.3001.8118", "?????? https://[mp.weixin.qq.com/s/XpsWl36lDCZDR2-Z2mMOlw](https://mp.weixin.qq.com/s/XpsWl36lDCZDR2-Z2mMOlw)", "Observation???????????????????????????Spring AI Alibaba??????LangFuse??????????????? https://blog.csdn.net/m0_63798859/article/details/149094224?sharetype=blogdetail&sharerId=149094224&sharerefer=PC&sharesource=m0_63798859&spm=1011.2480.3001.8118", "??????Spring AI Alibaba???????????????RAG??????\n??????Spring AI Alibaba workflow???graph???????????????????????????????????????????????????\nhttps://blog.csdn.net/qq_41508508/article/details/149117494", "spring-ai-alibaba ?????????????????????7????????????????????????\n1.??????  https://blog.csdn.net/u011648768/article/details/148961160?spm=1001.2014.3001.5502\n2.jar????????? https://blog.csdn.net/u011648768/article/details/148995370?spm=1001.2014.3001.5502\n3. ?????? https://blog.csdn.net/u011648768/article/details/149000393?spm=1001.2014.3001.5502\n4. ??????????????????????????????????????? https://blog.csdn.net/u011648768/article/details/149015829?spm=1001.2014.3001.5502\n5. ?????????????????? https://blog.csdn.net/u011648768/article/details/149023515?spm=1001.2014.3001.5502\n6. DocumentReader???DocumentParser https://blog.csdn.net/u011648768/article/details/149062263?spm=1001.2014.3001.5502\n7. ????????? https://blog.csdn.net/u011648768/article/details/149098175?spm=1001.2014.3001.5502\n8. ???????????? https://blog.csdn.net/u011648768/article/details/149101108?spm=1001.2014.3001.5502\n9. ????????? https://blog.csdn.net/u011648768/article/details/149119606?spm=1001.2014.3001.5502\n10. ???????????????????????? https://blog.csdn.net/u011648768/article/details/149124366?spm=1001.2014.3001.5502\n11. ??????????????????????????? https://blog.csdn.net/u011648768/article/details/149134346?spm=1001.2014.3001.5502\n12. ??????????????????????????? https://blog.csdn.net/u011648768/article/details/149143363?spm=1001.2014.3001.5502\n13. ????????????????????? https://blog.csdn.net/u011648768/article/details/149144466?spm=1001.2014.3001.5502\n14. ????????????????????? https://blog.csdn.net/u011648768/article/details/149152910?spm=1001.2014.3001.5502\n15. ??????????????????sql https://blog.csdn.net/u011648768/article/details/149156206?spm=1001.2014.3001.5502" ],
      "repository" : {
        "description" : "Agentic AI Framework for Java Developers",
        "homepage" : "https://java2ai.com",
        "name" : "spring-ai-alibaba",
        "fullName" : "alibaba/spring-ai-alibaba",
        "htmlUrl" : "https://github.com/alibaba/spring-ai-alibaba",
        "gitUrl" : "git://github.com/alibaba/spring-ai-alibaba.git",
        "sshUrl" : "git@github.com:alibaba/spring-ai-alibaba.git",
        "cloneUrl" : "https://github.com/alibaba/spring-ai-alibaba.git",
        "owner" : {
          "login" : "alibaba",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 938,
        "stargazersCount" : 4749,
        "watchersCount" : 4749,
        "size" : 146395,
        "openIssuesCount" : 259,
        "subscribersCount" : 62,
        "pushedAt" : "2025-07-11T16:12:30Z",
        "languages" : {
          "Java" : 5573403,
          "CSS" : 26756,
          "Makefile" : 7848,
          "TeX" : 4902,
          "Vue" : 410310,
          "Mustache" : 3851,
          "HTML" : 7375,
          "TypeScript" : 519129,
          "Dockerfile" : 2057,
          "Shell" : 4950,
          "Smalltalk" : 11272,
          "Batchfile" : 3003,
          "JavaScript" : 34104,
          "Less" : 6998,
          "Python" : 3892
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to encourage contributors to create works related to Spring AI Alibaba and Jmanus, and share them on technical blogs or short videos, with the aim of promoting the community and fostering collaboration.",
      "validationOrRequirement" : "The requirements for the submitted works are: 1) the work must be original and not published before; 2) the work must not contain advertisements; 3) the work must not contain sensitive or illegal content.",
      "attemptedFixes" : "There are no specific fixes attempted or blockers encountered mentioned in the issue description.",
      "otherNotes" : "The issue is about a Spring AI Alibaba community activity, where contributors are encouraged to create works related to Spring AI Alibaba and Jmanus, and share them on technical blogs or short videos. The activity has several awards and requirements, including a community participation award, an excellent contribution award, and some specific requirements for the submitted works.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284769
  }, {
    "issueDTO" : {
      "id" : 3211131067,
      "title" : "Fix consistent-type-assertions violations in @liam-hq/db-structure package",
      "url" : "https://github.com/liam-hq/liam/issues/2418",
      "repositoryName" : "liam-hq/liam",
      "description" : "## Summary\n\nThis issue tracks the resolution of `@typescript-eslint/consistent-type-assertions` rule violations in the `@liam-hq/db-structure` package. These violations were introduced when the rule was enabled in PR #2403.\n\n## Current Violations\n\nThe following file contains 4 violations that need to be addressed:\n\n- `src/parser/schemarb/parser.ts`: 4 violations\n\n## Next Steps\n\n1. Review the type assertions in the affected file\n2. Refactor the code to avoid type assertions where possible\n3. Use proper typing, type guards, or other TypeScript patterns instead of assertions\n4. Run `pnpm lint:eslint --prune-suppressions` to update the `eslint-suppressions.json` file after fixes\n\n## Background\n\nThe `@typescript-eslint/consistent-type-assertions` rule was enabled to improve type safety across the codebase. This rule enforces consistent usage of type assertions and helps prevent potential runtime errors by encouraging proper typing patterns.\n\n## Related\n\n- PR #2403: Enable @typescript-eslint/consistent-type-assertions rule\n- Package: `@liam-hq/db-structure`\n- Suppression file: `frontend/packages/db-structure/eslint-suppressions.json`",
      "updatedAt" : 1752217297.000000000,
      "user" : "claude[bot]",
      "userHtmlUrl" : "https://github.com/apps/claude",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/1236702?v=4",
      "labels" : [ "eslint", "tech debt", "typescript", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hii, can I work on it ??\n", "@Virajjai  Hi! As far as I know, no one from liam-hq is actively working on this right now ??? go ahead and give it a shot! Looking forward to your PR :)" ],
      "repository" : {
        "description" : "Automatically generates beautiful and easy-to-read ER diagrams from your database.",
        "homepage" : "https://liambx.com",
        "name" : "liam",
        "fullName" : "liam-hq/liam",
        "htmlUrl" : "https://github.com/liam-hq/liam",
        "gitUrl" : "git://github.com/liam-hq/liam.git",
        "sshUrl" : "git@github.com:liam-hq/liam.git",
        "cloneUrl" : "https://github.com/liam-hq/liam.git",
        "owner" : {
          "login" : "liam-hq",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 4149,
        "watchersCount" : 4149,
        "size" : 128286,
        "openIssuesCount" : 86,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-12T00:59:43Z",
        "languages" : {
          "TypeScript" : 1870996,
          "MDX" : 82980,
          "CSS" : 229518,
          "Shell" : 5433,
          "PLpgSQL" : 360220,
          "Handlebars" : 695,
          "JavaScript" : 42995,
          "HTML" : 985,
          "Ruby" : 7830
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix consistent-type-assertions violations in the @liam-hq/db-structure package, introduced when the rule was enabled in PR #2403.",
      "validationOrRequirement" : "The rule enforces consistent usage of type assertions and helps prevent potential runtime errors by encouraging proper typing patterns.",
      "attemptedFixes" : "Review the type assertions in the affected file, refactor the code to avoid type assertions where possible, use proper typing, type guards, or other TypeScript patterns instead of assertions, and run pnpm lint:eslint --prune-suppressions to update the eslint-suppressions.json file after fixes.",
      "otherNotes" : "The @typescript-eslint/consistent-type-assertions rule was enabled in PR #2403 to improve type safety across the codebase. The suppression file is eslint-suppressions.json.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284775
  }, {
    "issueDTO" : {
      "id" : 2262887019,
      "title" : "installation instructions in README.md are out of date",
      "url" : "https://github.com/crossplane-contrib/provider-kubernetes/issues/233",
      "repositoryName" : "crossplane-contrib/provider-kubernetes",
      "description" : "<!--\r\nThank you for helping to improve Crossplane!\r\n\r\nPlease be sure to search for open issues before raising a new one. We use issues\r\nfor bug reports and feature requests. Please find us at https://slack.crossplane.io\r\nfor questions, support, and discussion.\r\n-->\r\n\r\n### What happened?\r\n<!--\r\nPlease let us know what behaviour you expected and how Crossplane diverged from\r\nthat behaviour.\r\n-->\r\nThe posted installation instructions don't work.\r\nI used https://marketplace.upbound.io/providers/crossplane-contrib/provider-kubernetes/v0.13.0 instead.\r\n\r\n### How can we reproduce it?\r\n<!--\r\nHelp us to reproduce your bug as succinctly and precisely as possible. Artifacts\r\nsuch as example manifests or a script that triggers the issue are highly\r\nappreciated!\r\n-->\r\n\r\n### What environment did it happen in?\r\nCrossplane version: 1.15.2\r\nKubernetes: 1.24\r\nDistribution: RKE2\r\n\r\n<!--\r\nInclude at least the version or commit of Crossplane you were running. Consider\r\nalso including your:\r\n\r\n* Cloud provider or hardware configuration\r\n* Kubernetes version (use `kubectl version`)\r\n* Kubernetes distribution (e.g. Tectonic, GKE, OpenShift)\r\n* OS (e.g. from /etc/os-release)\r\n* Kernel (e.g. `uname -a`)\r\n-->\r\n",
      "updatedAt" : 1752217246.000000000,
      "user" : "charlesmelby",
      "userHtmlUrl" : "https://github.com/charlesmelby",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/67325107?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Ah good point @charlesmelby, thanks for taking the time to call that out! This looks very similar to a recent update we made to provider-helm to fix a very similarly outdated README.md \uD83D\uDE0A \r\nhttps://github.com/crossplane-contrib/provider-helm/pull/220\r\n\r\nDo you have any interest in taking that on for this repo too? Always happy for community contributions. The local development steps are more tricky, so a phased approach could be to just start by updating the basic install step(s) in the README - that will provide the most relief by itself.", "@jbw976 Sure why not, I'll do that in a bit when I'm free", "The most critical part of these README installation instructions has been updated by @scubbo in #239. There is still some more work to update the rest of the readme, e.g. the local development instructions and streamlined set up of [in-cluster config](https://github.com/crossplane-contrib/provider-kubernetes/blob/main/examples/provider/provider-in-cluster.yaml) (similar to https://github.com/crossplane-contrib/provider-helm/pull/220), but the main problem has been addressed now! \uD83D\uDE47 ", "```bash\nsed 's/upbound\\/provider-kubernetes:v0.16.0/crossplane-contrib\\/provider-kubernetes:v0.18.0/g'\n```" ],
      "repository" : {
        "description" : "Crossplane provider to provision and manage Kubernetes objects on (remote) Kubernetes clusters.",
        "homepage" : "",
        "name" : "provider-kubernetes",
        "fullName" : "crossplane-contrib/provider-kubernetes",
        "htmlUrl" : "https://github.com/crossplane-contrib/provider-kubernetes",
        "gitUrl" : "git://github.com/crossplane-contrib/provider-kubernetes.git",
        "sshUrl" : "git@github.com:crossplane-contrib/provider-kubernetes.git",
        "cloneUrl" : "https://github.com/crossplane-contrib/provider-kubernetes.git",
        "owner" : {
          "login" : "crossplane-contrib",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 96,
        "stargazersCount" : 170,
        "watchersCount" : 170,
        "size" : 3418,
        "openIssuesCount" : 73,
        "subscribersCount" : 10,
        "pushedAt" : "2025-06-27T11:31:39Z",
        "languages" : {
          "Dockerfile" : 275,
          "Shell" : 643,
          "Makefile" : 7814,
          "Go" : 239095
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The installation instructions in README.md are out of date and do not work, with the user experiencing issues using the latest version of the provider.",
      "validationOrRequirement" : "Update the README installation instructions to reflect the latest version of the provider.",
      "attemptedFixes" : "The most critical part of the README installation instructions has been updated by @scubbo in #239. There is still some more work to update the rest of the readme, e.g. the local development instructions and streamlined set up of in-cluster config.",
      "otherNotes" : "The issue is similar to a recent update made to provider-helm to fix an outdated README.md. A phased approach to updating the README could start with updating the basic install step(s) in the README.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284780
  }, {
    "issueDTO" : {
      "id" : 3167010627,
      "title" : "Cant see data in Power BI report",
      "url" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/issues/214",
      "repositoryName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
      "description" : "I cant see data in Power BI report.\n\nLooks like some of the table is not populating in the backend dataverse.\n\nThere is one issue with flow - I am unable to turn on the flow due to paging issue configuration.\n\nI edited the flow and changed the paging value from 75000 to 5000 and was able to turn on, but still the data doesnt show up in dataverse\n\nSee supporting screenshots\n\nPower BI Report\n\n![Image](https://github.com/user-attachments/assets/66efad16-25b2-4913-91ef-a0262b7b981b)\n\nIssue with flow\n![Image](https://github.com/user-attachments/assets/e33b8eb1-7963-484a-8abc-2d9f05a14ab9)\n\n![Image](https://github.com/user-attachments/assets/c50b94ff-61df-4bb5-b5e8-7edbf2f8f96f)\n\nIssue with 'Generate KPI' activity command\n![Image](https://github.com/user-attachments/assets/949f65c1-2d0b-43a4-bcd2-5809a6c70f7e)\n\n",
      "updatedAt" : 1752217244.000000000,
      "user" : "girishuppal",
      "userHtmlUrl" : "https://github.com/girishuppal",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/17232756?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @girishuppal, please confirm type of license you are using to Copilot Studio Kit user. For non-premium licenses, turn off pagination and try to turn on the flow.", "> Hi [@girishuppal](https://github.com/girishuppal), please confirm type of license you are using to Copilot Studio Kit user. For non-premium licenses, turn off pagination and try to turn on the flow.\n\nHi @patilravikiran - I did turn off pagination and test. The flow runs successfully, but the data doesn't get populated in Power BI. Tried refreshing data model as well. Looks the backend dataverse table is not populated.", "Looks like this flow is failing constantly\n\n![Image](https://github.com/user-attachments/assets/3a8a41b6-9b95-4449-81a9-16e3f107790e)\n\n![Image](https://github.com/user-attachments/assets/e4db5d1c-9b12-4dfd-90be-6455415fdaff)", "> Hi [@girishuppal](https://github.com/girishuppal), please confirm type of license you are using to Copilot Studio Kit user. For non-premium licenses, turn off pagination and try to turn on the flow.\n\nDeveloper Environment", "> Hi [@patilravikiran](https://github.com/patilravikiran) - I did turn off pagination and test. The flow runs successfully, but the data doesn't get populated in Power BI. Tried refreshing data model as well. Looks the backend dataverse table is not populated.\n\n![Image](https://github.com/user-attachments/assets/72b48ac2-dc05-4f54-a052-648a8344e8b5)\n\nAfter the successful execution of the flow, could you please update the report to reflect the current dates? The existing image appears to display outdated data, with the latest entry showing as 2024/11/24.\n\n\n\n\n> > Hi [@girishuppal](https://github.com/girishuppal), please confirm type of license you are using to Copilot Studio Kit user. For non-premium licenses, turn off pagination and try to turn on the flow.\n> \n> Developer Environment\n\nThanks for sharing that you're using a Developer environment. However, we were specifically asking about the type of license assigned to the Copilot Studio Kit user (e.g., Premium or Non-Premium).\n\nCould you please confirm the license type? You can check this in the Power Platform Admin Center/M365 Center under the user???s profile in the Licenses and Apps section.\n\nIf the user is on a non-premium license, please try turning off pagination and then attempt to turn on the flow again.", "License\n\n![Image](https://github.com/user-attachments/assets/594c5d26-991a-4306-a8fd-3734541ce22f)", "> > Hi [@patilravikiran](https://github.com/patilravikiran) - I did turn off pagination and test. The flow runs successfully, but the data doesn't get populated in Power BI. Tried refreshing data model as well. Looks the backend dataverse table is not populated.\n> \n> ![Image](https://github.com/user-attachments/assets/72b48ac2-dc05-4f54-a052-648a8344e8b5)\n> \n> After the successful execution of the flow, could you please update the report to reflect the current dates? The existing image appears to display outdated data, with the latest entry showing as 2024/11/24.\n> \n> > > Hi [@girishuppal](https://github.com/girishuppal), please confirm type of license you are using to Copilot Studio Kit user. For non-premium licenses, turn off pagination and try to turn on the flow.\n> > \n> > \n> > Developer Environment\n> \n> Thanks for sharing that you're using a Developer environment. However, we were specifically asking about the type of license assigned to the Copilot Studio Kit user (e.g., Premium or Non-Premium).\n> \n> Could you please confirm the license type? You can check this in the Power Platform Admin Center/M365 Center under the user???s profile in the Licenses and Apps section.\n> \n> If the user is on a non-premium license, please try turning off pagination and then attempt to turn on the flow again.\n\nReport date shown is on basis of data in backend table.\n\nAs data doesnt exist for 2025, it will not allow me to select in Power BI.", "Hi @girishuppal ,\nCould you please navigate to the Details View from the Command Bar and verify whether records are being populated in the table?\n\n![Image](https://github.com/user-attachments/assets/6b58ada4-944a-41c4-9045-b3bde1c6dd39)\n\nIf records are present, the data should reflect on the dashboard. You can cross-check by reviewing the latest conversation date and adjusting the date filters on the dashboard accordingly to view the relevant analytics.\n\nPlease refer to the screenshots below for guidance:\n\n![Image](https://github.com/user-attachments/assets/5fa0b5bd-aff5-4b62-9871-b2c922be0350)\n\n![Image](https://github.com/user-attachments/assets/351cb413-87e7-4603-a6a5-b2e2ad473cd2)", "This table is blank. No data in the table\n\n![Image](https://github.com/user-attachments/assets/bb7f9861-7bd2-468b-82b2-158f8138b893)\n\nAlso, the Agent list is showing blank\n\n![Image](https://github.com/user-attachments/assets/794a491d-91b5-46f9-89f9-68d725046aca)\n\nAgent exists in the list\n\n![Image](https://github.com/user-attachments/assets/d97d44b9-a436-4f47-91af-cd9e872244fb)\n\nAlso, Agent exist in the Inventory as well.\n\n![Image](https://github.com/user-attachments/assets/b41bafed-c9b3-4cf6-b6b3-fdfbba70e28f)\n\n", "Agent Configuration\n\n![Image](https://github.com/user-attachments/assets/c37c329b-2284-4d7c-a374-92c5895ac4f6)", "I believe the Conversation KPIs table is not in the model-driven app in the May release anymore, so we have to look at the data in it from the Maker portal. Which brings me to my question: How long does it take for the elastic tables to get populated with the latest Conversation KPIs?", "Hi @anttipajunen ,\nCould you please confirm whether the flows have run successfully in your environment? If they have, the elastic tables typically take up to an hour to populate with the latest Conversation transcript records.\n\nYou can access the conversation transcript table from the bottom in left nav menu -> go to Advance tab -> check Conversation Transcript table & Agent Transcript table\n\nOnce the data is populated, and if the Power BI report is correctly configured using the environment variable, the dashboard should automatically reflect the updated data.", "I got them visible. I was just too impatient after adding a new agent to the kit. After waiting, I can see it and the Conversation KPIs.", "I am facing the same issue mentioned by @girishuppal , i have data in the conversation transcript table and every other tables except in the conversation KPI table. I have verified this by going into the powerapps and viewing the data table.\n", "Can someone explain why this issue could be happening ?\n", "Hi @girishuppal / @st49user,\n\nWe???ve reviewed the issue and would like to share our observations along with a few checks that will help us move forward.\n\n**1. Date Format Issue**\n\nWe noticed that the date format being used is DD/MM/YYYY, whereas the expected format is MM/DD/YYYY. This mismatch is causing the Generate KPI Count flow to fail. Please ensure that the date values passed into the flow follow the correct format to avoid execution errors.\n\n![Image](https://github.com/user-attachments/assets/a4367571-0d88-4c50-a763-837d9d5737e2)\n\n **2. Missing Data in Power BI Dashboard**\n\nTo investigate why the Power BI dashboard is not showing data, we need to confirm the following:\n\n- Are you seeing any data being populated in the Agent Transcript table? This is the first step in the data pipeline. If this table is empty, the downstream flows will not execute as expected.\n- If the Agent Transcript table does contain data, please check whether the following flows are:\n\n  - Turned on\n  - Running successfully without any failures\n  - Conversation KPI | Generate Conversation KPIs Scheduler Flow\n  - Conversation KPI | Copy Transcripts (Grandchild)\n\n- The scheduler flow runs daily at 06:00 and 20:00. Please review the run history around these times and check the outputs to see what data is being processed.\n- If the flow has executed successfully and records have been created in the Conversation KPI table, you can refresh the dashboard from the Power BI service to reflect the latest data.\n\nPlease review the above points and let us know what you observe. \n\nTo help us gather more context on the issue, could you please join the upcoming [Office-Hours ](https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/blob/main/OFFICEHOURS.md)call? Your input would be valuable in resolving this efficiently.", "In my case the generate KPI does not return any error\n\n<img width=\"675\" height=\"410\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f9eb95ad-0f33-41a4-af2e-1b3adaa21092\" />\n\nand the logs show it as complete\n\n<img width=\"1533\" height=\"183\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f9871737-f7de-4445-ae98-a4c6b3683dde\" />\n\nboth the flows are turned on as you can see in this image\n\n<img width=\"1500\" height=\"79\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c88666e0-115c-4189-bcfc-0616532458cf\" />\n i have data present in the agents transcripts table which can be viewed from the advanced option in the copilot studio kit", "This is what my dashboard looks like\n\n<img width=\"1469\" height=\"629\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/59f29743-8b79-4322-9b36-cb2e929d34a4\" />\n\nand the agent dropdown shows none of my agents\n", "Hi @st49user ,\n\nCould you please help us by sharing snapshots of the respective flow runs, along with the responses you are receiving? This will help us better understand where the issue might be occurring.\n\nAdditionally, please check whether you are able to see any data rows in the Conversation KPI table within the solution.\n\nFor further assistance and a deeper understanding of the root cause, we also encourage you to join our next [Office Hours](https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/blob/main/OFFICEHOURS.md) session.\n\n<img width=\"1907\" height=\"315\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d2463e46-8056-48d8-a811-24e4c35e5de9\" />\n", "The conversation KPI table is empty.\n\nThis is the flow run history:\n\n<img width=\"1171\" height=\"665\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/927d92d6-6a84-4c8e-a9c7-c4ffd39ba837\" />\n \nCould you show the flow conversation KPI Child and how the flow is designed.", "> Hi [@girishuppal](https://github.com/girishuppal) / [@st49user](https://github.com/st49user),\n> \n> We???ve reviewed the issue and would like to share our observations along with a few checks that will help us move forward.\n> \n> **1. Date Format Issue**\n> \n> We noticed that the date format being used is DD/MM/YYYY, whereas the expected format is MM/DD/YYYY. This mismatch is causing the Generate KPI Count flow to fail. Please ensure that the date values passed into the flow follow the correct format to avoid execution errors.\n> \n> ![Image](https://github.com/user-attachments/assets/a4367571-0d88-4c50-a763-837d9d5737e2)\n> \n> **2. Missing Data in Power BI Dashboard**\n> \n> To investigate why the Power BI dashboard is not showing data, we need to confirm the following:\n> \n> * Are you seeing any data being populated in the Agent Transcript table? This is the first step in the data pipeline. If this table is empty, the downstream flows will not execute as expected.\n> * If the Agent Transcript table does contain data, please check whether the following flows are:\n>   \n>   * Turned on\n>   * Running successfully without any failures\n>   * Conversation KPI | Generate Conversation KPIs Scheduler Flow\n>   * Conversation KPI | Copy Transcripts (Grandchild)\n> * The scheduler flow runs daily at 06:00 and 20:00. Please review the run history around these times and check the outputs to see what data is being processed.\n> * If the flow has executed successfully and records have been created in the Conversation KPI table, you can refresh the dashboard from the Power BI service to reflect the latest data.\n> \n> Please review the above points and let us know what you observe.\n> \n> To help us gather more context on the issue, could you please join the upcoming [Office-Hours ](https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/blob/main/OFFICEHOURS.md)call? Your input would be valuable in resolving this efficiently.\n\nPlease find the requested details\n\n<img width=\"1431\" height=\"551\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d20c50d7-8926-4d09-bae6-da5b7a73e9d7\" />\n\n<img width=\"1147\" height=\"779\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7b6958da-be9d-4f92-bbd5-4b8b212da3a1\" />\n\n<img width=\"1223\" height=\"810\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0bd4f522-4069-4972-9c22-9850be28bc3d\" />\n\n<img width=\"1530\" height=\"848\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/081fd217-382f-44da-80d9-a56298fd9262\" />\n\n<img width=\"1660\" height=\"763\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e88a1025-9e76-44c2-9c70-922b666d4573\" />", "Hi @girishuppal / @anttipajunen / @st49user,\n\nTo help us resolve this issue more effectively, could you please let us know your preferred way to connect?\n\nWould you prefer a one-on-one call, or would you be more comfortable joining our upcoming [Office Hours](https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/blob/main/OFFICEHOURS.md) session? We're happy to go with whichever option works best for you.\n\nAnyone else who is facing the same issue is also welcome to join the call ??? your input will be valuable in helping us investigate and address it thoroughly." ],
      "repository" : {
        "description" : null,
        "homepage" : "",
        "name" : "Power-CAT-Copilot-Studio-Kit",
        "fullName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
        "htmlUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit",
        "gitUrl" : "git://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "sshUrl" : "git@github.com:microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "cloneUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 180,
        "watchersCount" : 180,
        "size" : 48361,
        "openIssuesCount" : 27,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-09T12:45:38Z",
        "languages" : {
          "C#" : 24850,
          "CSS" : 4368,
          "JavaScript" : 33528,
          "HTML" : 16742
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to resolve the issue of not being able to see data in Power BI report due to flow configuration and date format issues.",
      "validationOrRequirement" : "The flow configuration and date format are not correct, causing the flow to fail. The user is asked to ensure that the date values passed into the flow follow the correct format to avoid execution errors.",
      "attemptedFixes" : "The user tried turning off pagination and tested the flow, but the data didn't get populated in Power BI. The user also tried refreshing the data model, but it didn't work. The user is asked to provide more information and join an office hour session to resolve the issue.",
      "otherNotes" : "The issue is about not being able to see data in Power BI report due to flow configuration and date format issues. The flow is failing due to pagination configuration and the backend dataverse table is not populated. The user is asked to provide more information and join an office hour session to resolve the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284788
  }, {
    "issueDTO" : {
      "id" : 3214742076,
      "title" : "Move email sending in a celery task",
      "url" : "https://github.com/suitenumerique/docs/issues/1143",
      "repositoryName" : "suitenumerique/docs",
      "description" : "## Feature Request\n\n**Is your feature request related to a problem or unsupported use case? Please describe.**\n\nEmails are sent during a request, sometimes the connection to the server email can take time or fail.\n\n**Describe the solution you'd like**\n\nMove the email sending in a celery task to avoid the side effect listed before.\n\n\n",
      "updatedAt" : 1752216730.000000000,
      "user" : "lunika",
      "userHtmlUrl" : "https://github.com/lunika",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/767834?v=4",
      "labels" : [ "feature", "backend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Bonjour,\nJ'aimerais m'occuper de cette issue si c'est ok pour vous. :)", "@HaroWana You are assigned on this issue.\nThanks" ],
      "repository" : {
        "description" : "A collaborative note taking, wiki and documentation platform that scales. Built with Django and React. ",
        "homepage" : "https://docs.numerique.gouv.fr",
        "name" : "docs",
        "fullName" : "suitenumerique/docs",
        "htmlUrl" : "https://github.com/suitenumerique/docs",
        "gitUrl" : "git://github.com/suitenumerique/docs.git",
        "sshUrl" : "git@github.com:suitenumerique/docs.git",
        "cloneUrl" : "https://github.com/suitenumerique/docs.git",
        "owner" : {
          "login" : "suitenumerique",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 348,
        "stargazersCount" : 12768,
        "watchersCount" : 12768,
        "size" : 34893,
        "openIssuesCount" : 229,
        "subscribersCount" : 51,
        "pushedAt" : "2025-07-11T23:24:58Z",
        "languages" : {
          "TypeScript" : 779525,
          "Smarty" : 5355,
          "Dockerfile" : 7458,
          "CSS" : 66575,
          "Shell" : 10889,
          "Starlark" : 2391,
          "Makefile" : 11599,
          "JavaScript" : 13096,
          "HTML" : 835,
          "Python" : 1078445
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Move email sending in a celery task to avoid the side effect of connection time or failure to the server email",
      "validationOrRequirement" : "Move email sending in a celery task",
      "attemptedFixes" : "Move the email sending in a celery task to avoid the side effect listed before.",
      "otherNotes" : "Emails are sent during a request, sometimes the connection to the server email can take time or fail.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284791
  }, {
    "issueDTO" : {
      "id" : 3221765954,
      "title" : "Add EveBio dataset",
      "url" : "https://github.com/snap-stanford/Biomni/issues/27",
      "repositoryName" : "snap-stanford/Biomni",
      "description" : "Would be cool to add this cool dataset! \n\nevebio.org ",
      "updatedAt" : 1752216410.000000000,
      "user" : "kexinhuang12345",
      "userHtmlUrl" : "https://github.com/kexinhuang12345",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/27795075?v=4",
      "labels" : [ "new-dataset", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Biomni: a general-purpose biomedical AI agent",
        "homepage" : "https://biomni.stanford.edu",
        "name" : "Biomni",
        "fullName" : "snap-stanford/Biomni",
        "htmlUrl" : "https://github.com/snap-stanford/Biomni",
        "gitUrl" : "git://github.com/snap-stanford/Biomni.git",
        "sshUrl" : "git@github.com:snap-stanford/Biomni.git",
        "cloneUrl" : "https://github.com/snap-stanford/Biomni.git",
        "owner" : {
          "login" : "snap-stanford",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 137,
        "stargazersCount" : 1317,
        "watchersCount" : 1317,
        "size" : 737,
        "openIssuesCount" : 10,
        "subscribersCount" : 29,
        "pushedAt" : "2025-07-10T16:01:12Z",
        "languages" : {
          "Shell" : 44508,
          "R" : 4226,
          "Jupyter Notebook" : 332049,
          "Python" : 1371378
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add the EveBio dataset to the repository.",
      "validationOrRequirement" : "No specific requirements or validations mentioned.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about adding the EveBio dataset, with a suggestion from evebio.org.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284793
  }, {
    "issueDTO" : {
      "id" : 3221173381,
      "title" : "[Improvement] remove duplicate code in MysqlTableOperations.java and OceanBaseTableOperations.java",
      "url" : "https://github.com/apache/gravitino/issues/7665",
      "repositoryName" : "apache/gravitino",
      "description" : "### What would you like to be improved?\n\nProperties are added twice with two sets of this code:\n```\n    if (!setProperties.isEmpty()) {\n      alterSql.add(generateTableProperties(setProperties));\n    }\n```\n\n### How should we improve?\n\nThey should only be added once",
      "updatedAt" : 1752216334.000000000,
      "user" : "justinmclean",
      "userHtmlUrl" : "https://github.com/justinmclean",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/144504?v=4",
      "labels" : [ "improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hi, @justinmclean . Is it okay to work on this together with issue #7664, since the change is small?" ],
      "repository" : {
        "description" : "World's most powerful open data catalog for building a high-performance, geo-distributed and federated metadata lake.",
        "homepage" : "https://gravitino.apache.org",
        "name" : "gravitino",
        "fullName" : "apache/gravitino",
        "htmlUrl" : "https://github.com/apache/gravitino",
        "gitUrl" : "git://github.com/apache/gravitino.git",
        "sshUrl" : "git@github.com:apache/gravitino.git",
        "cloneUrl" : "https://github.com/apache/gravitino.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 530,
        "stargazersCount" : 1693,
        "watchersCount" : 1693,
        "size" : 61834,
        "openIssuesCount" : 721,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-11T12:29:22Z",
        "languages" : {
          "Smarty" : 5095,
          "TypeScript" : 1191,
          "Java" : 14734465,
          "Dockerfile" : 26062,
          "Shell" : 184089,
          "CSS" : 937,
          "Rust" : 206295,
          "Batchfile" : 1647,
          "Makefile" : 3325,
          "JavaScript" : 511804,
          "Python" : 1191811
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove duplicate code in MysqlTableOperations.java and OceanBaseTableOperations.java by adding properties only once.",
      "validationOrRequirement" : "Properties should be added only once.",
      "attemptedFixes" : "",
      "otherNotes" : "The code duplication is in MysqlTableOperations.java and OceanBaseTableOperations.java. Comment by @justinmclean suggests possibility of collaboration with issue #7664.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284796
  }, {
    "issueDTO" : {
      "id" : 3221168053,
      "title" : "[Improvement] remove duplicate MODEL in CommandEntities.java",
      "url" : "https://github.com/apache/gravitino/issues/7664",
      "repositoryName" : "apache/gravitino",
      "description" : "### What would you like to be improved?\n\nMODEL is defined twice in VALID_ENTITIES\n\n### How should we improve?\n\nremove one",
      "updatedAt" : 1752216317.000000000,
      "user" : "justinmclean",
      "userHtmlUrl" : "https://github.com/justinmclean",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/144504?v=4",
      "labels" : [ "improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hi @justinmclean . I???m interested in this issue.  Could you please assign it to me?  Thank you!" ],
      "repository" : {
        "description" : "World's most powerful open data catalog for building a high-performance, geo-distributed and federated metadata lake.",
        "homepage" : "https://gravitino.apache.org",
        "name" : "gravitino",
        "fullName" : "apache/gravitino",
        "htmlUrl" : "https://github.com/apache/gravitino",
        "gitUrl" : "git://github.com/apache/gravitino.git",
        "sshUrl" : "git@github.com:apache/gravitino.git",
        "cloneUrl" : "https://github.com/apache/gravitino.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 530,
        "stargazersCount" : 1693,
        "watchersCount" : 1693,
        "size" : 61834,
        "openIssuesCount" : 721,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-11T12:29:22Z",
        "languages" : {
          "Smarty" : 5095,
          "TypeScript" : 1191,
          "Java" : 14734465,
          "Dockerfile" : 26062,
          "Shell" : 184089,
          "CSS" : 937,
          "Rust" : 206295,
          "Batchfile" : 1647,
          "Makefile" : 3325,
          "JavaScript" : 511804,
          "Python" : 1191811
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "remove duplicate MODEL in CommandEntities.java",
      "validationOrRequirement" : "MODEL is defined twice in VALID_ENTITIES",
      "attemptedFixes" : "remove one",
      "otherNotes" : "hi @justinmclean . I???m interested in this issue.  Could you please assign it to me?  Thank you!",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284799
  }, {
    "issueDTO" : {
      "id" : 3054529951,
      "title" : "Feature request: Flashcard System",
      "url" : "https://github.com/alphaonelabs/alphaonelabs-education-website/issues/594",
      "repositoryName" : "alphaonelabs/alphaonelabs-education-website",
      "description" : " ## \uD83D\uDE80 Feature: Interactive Flashcard System\n\n Summary:\n Implement an interactive flashcard system that allows users to create, edit, and study custom flashcard decks directly within the platform.\n\n What was added:\n - Users can create flashcard decks, add/edit/delete cards, and make decks public or private.\n - Each card has a ???front??? (question/term) and a ???back??? (answer/definition).\n - Study mode: Users can flip cards by clicking to reveal the answer, and navigate between cards with Previous/Next buttons.\n - The system is fully responsive, supports dark mode, and uses Tailwind CSS for styling.\n - Flashcards are accessible from the ???Resources??? dropdown in the main navigation.\n\n Why this is valuable:\n - Helps students actively recall information and self-test.\n - Supports spaced repetition and personalized study.\n - Makes the platform more engaging and useful for independent learners.\n\n Screenshots/Usage:\n 1. Go to Resources ??? Flashcards.\n 2. Create a new deck, add cards, and start studying!\n 3. Click the card to flip and reveal the answer.\n\n ---\n Thank you for reviewing this feature!",
      "updatedAt" : 1752216316.000000000,
      "user" : "skanbedoui",
      "userHtmlUrl" : "https://github.com/skanbedoui",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/115241712?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/assign", "Hey @tejaskankhar! You're now assigned to this issue. Please finish your PR within 1 day.", "??? @tejaskankhar, you have been unassigned due to 24+ hours of inactivity. This task is now available for reassignment." ],
      "repository" : {
        "description" : "Alpha One Labs Educational Website",
        "homepage" : "https://alphaonelabs.com",
        "name" : "alphaonelabs-education-website",
        "fullName" : "alphaonelabs/alphaonelabs-education-website",
        "htmlUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website",
        "gitUrl" : "git://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "sshUrl" : "git@github.com:alphaonelabs/alphaonelabs-education-website.git",
        "cloneUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "owner" : {
          "login" : "alphaonelabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 80,
        "stargazersCount" : 23,
        "watchersCount" : 23,
        "size" : 32019,
        "openIssuesCount" : 119,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-11T07:05:39Z",
        "languages" : {
          "Dockerfile" : 1189,
          "Shell" : 49732,
          "Jinja" : 7703,
          "CSS" : 2056,
          "JavaScript" : 105473,
          "HTML" : 1763491,
          "Python" : 1207774
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement an interactive flashcard system that allows users to create, edit, and study custom flashcard decks directly within the platform.",
      "validationOrRequirement" : "The feature requires users to be able to create, edit, and study custom flashcard decks, with specific requirements for each card's 'front' and 'back', and for the study mode.",
      "attemptedFixes" : "The feature includes creation of flashcard decks, adding/editing/deleting cards, and making decks public or private, with study mode and navigation between cards.",
      "otherNotes" : "This feature includes creating, editing, and studying custom flashcard decks, with features like responsive design, dark mode, and Tailwind CSS styling.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284803
  }, {
    "issueDTO" : {
      "id" : 2980208087,
      "title" : "Annotate remaining `*Converter` classes for nullability",
      "url" : "https://github.com/dotnet/maui/issues/28860",
      "repositoryName" : "dotnet/maui",
      "description" : "### Description\n\nI created https://github.com/dotnet/maui/pull/28244 PR which added nullability markers to the `ListStringTypeConverter` type.\n\nThere are many more `*Converter.cs` files where it can be fixed:\n\n* https://github.com/dotnet/maui/blob/main/src/Core/src/Converters/ThicknessTypeConverter.cs\n* https://github.com/dotnet/maui/blob/main/src/Controls/src/Core/FlowDirectionConverter.cs\n* etc.\n\nIt is purely mechanical work, therefore I mark this issue with the \"good first issue\" label. The only important thing is to target `net10.0` branch.\n\n### Version with bug\n\n9.0.50 SR5\n",
      "updatedAt" : 1752216283.000000000,
      "user" : "MartyIX",
      "userHtmlUrl" : "https://github.com/MartyIX",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/203266?v=4",
      "labels" : [ "t/bug", "s/triaged", "area-xaml", "partner/syncfusion", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@MartyIX Can I pick this up?", "Sure :)" ],
      "repository" : {
        "description" : ".NET MAUI is the .NET Multi-platform App UI, a framework for building native device applications spanning mobile, tablet, and desktop.",
        "homepage" : "https://dot.net/maui",
        "name" : "maui",
        "fullName" : "dotnet/maui",
        "htmlUrl" : "https://github.com/dotnet/maui",
        "gitUrl" : "git://github.com/dotnet/maui.git",
        "sshUrl" : "git@github.com:dotnet/maui.git",
        "cloneUrl" : "https://github.com/dotnet/maui.git",
        "owner" : {
          "login" : "dotnet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1857,
        "stargazersCount" : 22788,
        "watchersCount" : 22788,
        "size" : 595541,
        "openIssuesCount" : 4412,
        "subscribersCount" : 632,
        "pushedAt" : "2025-07-11T23:53:42Z",
        "languages" : {
          "C#" : 26263641,
          "PowerShell" : 210014,
          "TypeScript" : 8999,
          "Java" : 72778,
          "Shell" : 140920,
          "CSS" : 20541,
          "Batchfile" : 1400,
          "CMake" : 15373,
          "JavaScript" : 8603,
          "HTML" : 43621
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Annotate remaining Converter classes for nullability",
      "validationOrRequirement" : "target net10.0 branch, good first issue",
      "attemptedFixes" : "PR already added nullability markers to ListStringTypeConverter, need to fix remaining Converter.cs files",
      "otherNotes" : "PR added nullability markers to the ListStringTypeConverter type, many more Converter.cs files need to be fixed, target net10.0 branch, good first issue",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284807
  }, {
    "issueDTO" : {
      "id" : 3060650438,
      "title" : "Eraser Tool Draws in White Instead of Erasing on Dark Mode Whiteboard",
      "url" : "https://github.com/alphaonelabs/alphaonelabs-education-website/issues/613",
      "repositoryName" : "alphaonelabs/alphaonelabs-education-website",
      "description" : "Description:\nWhen using the Advanced Whiteboard in dark mode, the Eraser tool does not function as expected. Instead of removing drawn content, it simply draws over it with white ??? which stands out against the dark (black) background, making it act more like a white pen.\n\nSteps to Reproduce:\n1-Enable dark mode.\n2-Navigate to the Whiteboard page.\n3-Draw something using the Pen tool.\n4-Switch to the Eraser tool and try to erase.\n\nObserved Behavior:\n-The eraser draws in white, leaving visible white marks on the black board background.\nExpected Behavior:\n-The eraser should remove the drawn content, revealing the original board background (black in dark mode).\n-It should not behave like a drawing tool.\n\nSuggested Fix:\n-Update the eraser tool logic to actually clear pixels or canvas data instead of painting over with a color.\n-Or make it dynamically adapt its \"erase color\" to match the canvas background (black in dark mode, white in light mode).\n",
      "updatedAt" : 1752216255.000000000,
      "user" : "SfarOussama9",
      "userHtmlUrl" : "https://github.com/SfarOussama9",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/192275775?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/assign", "@SfarOussama9 'Good first issue' tasks are reserved for newcomers who haven't submitted PRs yet. Since you already have PRs in this repository, please choose a different issue to work on.", "Hello,\n\nAs the original author of this issue, I would like to work on implementing the proposed fix. Since the issue is currently labeled as good first issue, I understand it may be intended for new contributors. However, given that I authored the issue and am familiar with the context, I believe I can address it effectively.\n\nWould it be possible to remove the good first issue label so I can proceed with submitting a pull request?\n\nThank you for your consideration.\n\n" ],
      "repository" : {
        "description" : "Alpha One Labs Educational Website",
        "homepage" : "https://alphaonelabs.com",
        "name" : "alphaonelabs-education-website",
        "fullName" : "alphaonelabs/alphaonelabs-education-website",
        "htmlUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website",
        "gitUrl" : "git://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "sshUrl" : "git@github.com:alphaonelabs/alphaonelabs-education-website.git",
        "cloneUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "owner" : {
          "login" : "alphaonelabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 80,
        "stargazersCount" : 23,
        "watchersCount" : 23,
        "size" : 32019,
        "openIssuesCount" : 119,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-11T07:05:39Z",
        "languages" : {
          "Dockerfile" : 1189,
          "Shell" : 49732,
          "Jinja" : 7703,
          "CSS" : 2056,
          "JavaScript" : 105473,
          "HTML" : 1763491,
          "Python" : 1207774
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "the Eraser tool does not function as expected in dark mode, it draws in white instead of erasing on the Advanced Whiteboard",
      "validationOrRequirement" : "eraser tool should remove drawn content, revealing the original board background (black in dark mode, white in light mode), it should not behave like a drawing tool",
      "attemptedFixes" : "update eraser tool logic to clear pixels or canvas data instead of painting over with a color, or make it dynamically adapt its 'erase color' to match the canvas background",
      "otherNotes" : "issue labeled as good first issue but author already has PRs in repository, author wants to work on implementing the proposed fix and requests to remove the good first issue label",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284812
  }, {
    "issueDTO" : {
      "id" : 3061361822,
      "title" : "update New Message email to have a link to the message so you can click and go right to it",
      "url" : "https://github.com/alphaonelabs/alphaonelabs-education-website/issues/621",
      "repositoryName" : "alphaonelabs/alphaonelabs-education-website",
      "description" : null,
      "updatedAt" : 1752216180.000000000,
      "user" : "A1L13N",
      "userHtmlUrl" : "https://github.com/A1L13N",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/193832434?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! Can you clarify which specific \"New Message\" email this refers to?" ],
      "repository" : {
        "description" : "Alpha One Labs Educational Website",
        "homepage" : "https://alphaonelabs.com",
        "name" : "alphaonelabs-education-website",
        "fullName" : "alphaonelabs/alphaonelabs-education-website",
        "htmlUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website",
        "gitUrl" : "git://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "sshUrl" : "git@github.com:alphaonelabs/alphaonelabs-education-website.git",
        "cloneUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "owner" : {
          "login" : "alphaonelabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 80,
        "stargazersCount" : 23,
        "watchersCount" : 23,
        "size" : 32019,
        "openIssuesCount" : 119,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-11T07:05:39Z",
        "languages" : {
          "Dockerfile" : 1189,
          "Shell" : 49732,
          "Jinja" : 7703,
          "CSS" : 2056,
          "JavaScript" : 105473,
          "HTML" : 1763491,
          "Python" : 1207774
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "update New Message email to have a link to the message so you can click and go right to it",
      "validationOrRequirement" : "specific 'New Message' email to update",
      "attemptedFixes" : "",
      "otherNotes" : "Can you clarify which specific 'New Message' email this refers to?",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284814
  }, {
    "issueDTO" : {
      "id" : 3185424448,
      "title" : "if a class has passed allow users to join a waiting room for the next session",
      "url" : "https://github.com/alphaonelabs/alphaonelabs-education-website/issues/645",
      "repositoryName" : "alphaonelabs/alphaonelabs-education-website",
      "description" : null,
      "updatedAt" : 1752216147.000000000,
      "user" : "A1L13N",
      "userHtmlUrl" : "https://github.com/A1L13N",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/193832434?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Alpha One Labs Educational Website",
        "homepage" : "https://alphaonelabs.com",
        "name" : "alphaonelabs-education-website",
        "fullName" : "alphaonelabs/alphaonelabs-education-website",
        "htmlUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website",
        "gitUrl" : "git://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "sshUrl" : "git@github.com:alphaonelabs/alphaonelabs-education-website.git",
        "cloneUrl" : "https://github.com/alphaonelabs/alphaonelabs-education-website.git",
        "owner" : {
          "login" : "alphaonelabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 80,
        "stargazersCount" : 23,
        "watchersCount" : 23,
        "size" : 32019,
        "openIssuesCount" : 119,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-11T07:05:39Z",
        "languages" : {
          "Dockerfile" : 1189,
          "Shell" : 49732,
          "Jinja" : 7703,
          "CSS" : 2056,
          "JavaScript" : 105473,
          "HTML" : 1763491,
          "Python" : 1207774
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow users to join a waiting room for the next session if a class has passed.",
      "validationOrRequirement" : "No specific requirements or validations mentioned.",
      "attemptedFixes" : "No attempts or blockers mentioned.",
      "otherNotes" : "No description provided, but labeled as a 'good first issue'.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284816
  }, {
    "issueDTO" : {
      "id" : 3221748075,
      "title" : "[Feature] dynamically adjust sinker batch_size",
      "url" : "https://github.com/apecloud/ape-dts/issues/396",
      "repositoryName" : "apecloud/ape-dts",
      "description" : "## Motivations\n\nthe batch_size configuration in Sinker can affect the number of records written to the query at a single target end. However, controlling it simply by record count may not be rigorous enough, as database SDKs often have byte limits on query size. For example, PG limits the default maximum size in sqlx to 16MB.\n\n## Solution\nadd the ability to dynamically adjust batch size based on record byte in Sinker\n\n\n",
      "updatedAt" : 1752215917.000000000,
      "user" : "caiq1nyu",
      "userHtmlUrl" : "https://github.com/caiq1nyu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11702171?v=4",
      "labels" : [ "Good First Issue", "Feature" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "ApeCloud's Data Transfer Suite, written in Rust. Provides ultra-fast data replication between MySQL, PostgreSQL, Redis, MongoDB, Kafka and ClickHouse, ideal for disaster recovery (DR) and migration scenarios.",
        "homepage" : "",
        "name" : "ape-dts",
        "fullName" : "apecloud/ape-dts",
        "htmlUrl" : "https://github.com/apecloud/ape-dts",
        "gitUrl" : "git://github.com/apecloud/ape-dts.git",
        "sshUrl" : "git@github.com:apecloud/ape-dts.git",
        "cloneUrl" : "https://github.com/apecloud/ape-dts.git",
        "owner" : {
          "login" : "apecloud",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 69,
        "stargazersCount" : 468,
        "watchersCount" : 468,
        "size" : 68669,
        "openIssuesCount" : 45,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-08T07:30:41Z",
        "languages" : {
          "HCL" : 225,
          "Dockerfile" : 2902,
          "RenderScript" : 1,
          "Rust" : 1712108,
          "Makefile" : 5057,
          "PLpgSQL" : 4520,
          "Lua" : 23868,
          "Roff" : 71
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "add the ability to dynamically adjust batch size based on record byte in Sinker",
      "validationOrRequirement" : "byte limits on query size, for example PG limits the default maximum size in sqlx to 16MB",
      "attemptedFixes" : "",
      "otherNotes" : "the batch_size configuration in Sinker can affect the number of records written to the query at a single target end",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284819
  }, {
    "issueDTO" : {
      "id" : 2752780138,
      "title" : "UI: Add time lapsed for each migration",
      "url" : "https://github.com/platform9/vjailbreak/issues/113",
      "repositoryName" : "platform9/vjailbreak",
      "description" : null,
      "updatedAt" : 1752215833.000000000,
      "user" : "jeremymv2",
      "userHtmlUrl" : "https://github.com/jeremymv2",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1991696?v=4",
      "labels" : [ "UI", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@OmkarDeshpande7 can we get this in the Migration Status?" ],
      "repository" : {
        "description" : "Helping VMware users migrate to alternative Hypervisors",
        "homepage" : "https://platform9.github.io/vjailbreak/",
        "name" : "vjailbreak",
        "fullName" : "platform9/vjailbreak",
        "htmlUrl" : "https://github.com/platform9/vjailbreak",
        "gitUrl" : "git://github.com/platform9/vjailbreak.git",
        "sshUrl" : "git@github.com:platform9/vjailbreak.git",
        "cloneUrl" : "https://github.com/platform9/vjailbreak.git",
        "owner" : {
          "login" : "platform9",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 79,
        "watchersCount" : 79,
        "size" : 156524,
        "openIssuesCount" : 99,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T21:34:13Z",
        "languages" : {
          "TypeScript" : 592548,
          "HCL" : 2782,
          "Dockerfile" : 4291,
          "Shell" : 12238,
          "CSS" : 1343,
          "Makefile" : 16524,
          "JavaScript" : 1037,
          "Go" : 875679,
          "HTML" : 3940
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add time lapsed for each migration in the UI",
      "validationOrRequirement" : "no specific requirements mentioned",
      "attemptedFixes" : "",
      "otherNotes" : "Comment from @OmkarDeshpande7 suggesting to add the feature in the Migration Status",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284821
  }, {
    "issueDTO" : {
      "id" : 2896695706,
      "title" : "Replace %d with <IENS> in docs",
      "url" : "https://github.com/equinor/ert/issues/10212",
      "repositoryName" : "equinor/ert",
      "description" : "Possibly all usages of \"`%d`\" in docs and code should be replaced by the more precise template `<IENS>` (when `%d` is used for the realization index). \n\n```\n.../ert/docs] rg \"%d\"\nert/reference/queue/lsf_queue.ert\n1:JOBNAME queue_test_%d\n\nert/reference/configuration/data_types.rst\n406:``INIT_FILE:/path/to/priors/files%d`` which tells where the prior files are:\n410:\t\tGEN_KW  MY-FAULTS   MULTFLT.tmpl   MULTFLT.INC   MULTFLT.txt    INIT_FILES:priors/multflt/faults%d\n\nert/reference/queue/local_queue.ert\n1:JOBNAME queue_test_%d\n\nert/reference/configuration/observations.rst\n428:the ``GEN_DATA`` result files must have an embedded ``%d`` to indicate the\n435:   GEN_DATA RFT_BH67 INPUT_FORMAT:ASCII RESULT_FILE:rft_BH67_%d    REPORT_STEPS:20\n\nert/reference/configuration/keywords.rst\n490:Deprecated syntax still allow use of two `%d` specifers. Use of more than two `%d` specifiers,\n504:        -- Using RUNPATH with two %d specifers.\n505:        RUNPATH /mnt/my_scratch_disk/realization-%d/iteration-%d\n578:        ECLBASE BASE_ECL_NAME%d\n585:``<IENS>`` instead of ``%d`` is a better option:\n739:        FIELD  ID  PARAMETER  <OUTPUT_FILE>  INIT_FILES:/path/%d  FORWARD_INIT:True  INIT_TRANSFORM:FUNC  OUTPUT_TRANSFORM:FUNC  MIN:X  MAX:Y\n756:  Filename to load initial field from. Must contain ``%d`` if ``FORWARD_INIT`` is set to ``False``.\n763:    Indicates that the specified files are generated by a forward model and do not require an embedded ``%d``.\n766:    Means that the files must be pre-generated before running ERT and require an embedded ``%d`` to differentiate between different realizations.\n794:the integer format specified ``%d`` - which ERT will replace with the\n799:   FIELD ... INIT_FILES:/path/poro_%d.grdecl\n832:filename given should contain a ``%d`` which will be replaced with realization\n946:same naming scheme for all realizations (ex: ``gd_%d`` which may resolve to\n947:``gd_0``, ``gd_1`` where `%d` is the report step).\n961:model and read by ERT. If ``REPORT_STEPS`` are specified, this filename _must_ have a %d as part of the\n962:name, that %d will be replaced by report step when loading. If ``REPORT_STEPS`` are not specified,\n963:the filename does not need to contain %d.\n980:        GEN_DATA 4DWOC   RESULT_FILE:SimulatedWOC%d.txt   REPORT_STEPS:10,100\n998:        GEN_DATA 4DWOC  RESULT_FILE:SimulatedWOC_%d.txt   REPORT_STEPS:0\n1000:The ``4DWOC`` is an arbitrary unique key, ``RESULT_FILE:SimulatedWOC%d.txt``\n1003:The ``REPORT_STEPS:0`` is tightly bound to the ``%d`` integer format specifier\n1004:in the result file - at load time the ``%d`` is replaced with the integer values\n1006:that ``%d`` will be replaced with ``0`` and ERT will look for the file\n1014:fail if the ``RESULT_FILE`` attribute does not contain a ``%d``.\n1066:        GEN_KW  ... UPDATE:TRUE/FALSE INIT_FILES:path/to/file_%d\n1223:``INIT_FILES:/path/to/priors/files%d`` which tells where the prior files are:\n1227:        GEN_KW  MY-FAULTS   MULTFLT.tmpl   MULTFLT.INC   MULTFLT.txt    INIT_FILES:priors/multflt/faults%d\n1314:        SURFACE TOP   OUTPUT_FILE:surf.irap   INIT_FILES:Surfaces/surf%d.irap   BASE_SURFACE:Surfaces/surf0.irap\n```\n",
      "updatedAt" : 1752215742.000000000,
      "user" : "berland",
      "userHtmlUrl" : "https://github.com/berland",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/306834?v=4",
      "labels" : [ "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Wondering:\n- GEN_KW doesnt support INIT_FILES at all, no? So removing mention of this in the docs\n- SURFACE when INIT_FILES needs realization (forward_init false), only %d is allowed, so will allow <IENS> too, since it is replaced that way already." ],
      "repository" : {
        "description" : "ERT - Ensemble based Reservoir Tool - is designed for running ensembles of dynamical models such as reservoir models, in order to do sensitivity analysis and data assimilation. ERT supports data assimilation using the Ensemble Smoother (ES), Ensemble Smoother with Multiple Data Assimilation (ES-MDA) and Iterative Ensemble Smoother (IES).",
        "homepage" : "https://ert.readthedocs.io/en/latest/",
        "name" : "ert",
        "fullName" : "equinor/ert",
        "htmlUrl" : "https://github.com/equinor/ert",
        "gitUrl" : "git://github.com/equinor/ert.git",
        "sshUrl" : "git@github.com:equinor/ert.git",
        "cloneUrl" : "https://github.com/equinor/ert.git",
        "owner" : {
          "login" : "equinor",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 114,
        "stargazersCount" : 137,
        "watchersCount" : 137,
        "size" : 1276289,
        "openIssuesCount" : 325,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-11T11:59:06Z",
        "languages" : {
          "C++" : 572178,
          "Jinja" : 13840,
          "Shell" : 9193,
          "Scheme" : 4807,
          "HTML" : 161,
          "Jupyter Notebook" : 61904,
          "Assembly" : 284381,
          "Python" : 4096095,
          "Just" : 1896
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace all occurrences of `%d` with `<IENS>` in the documentation and code for more precision",
      "validationOrRequirement" : "replace all usages of `%d` with `<IENS>` in docs and code",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "GEN_KW does not support INIT_FILES, and SURFACE only allows %d when INIT_FILES needs realization",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284824
  }, {
    "issueDTO" : {
      "id" : 2789262060,
      "title" : "Dark mode - tree select widget poor visibility",
      "url" : "https://github.com/ToolJet/ToolJet/issues/11798",
      "repositoryName" : "ToolJet/ToolJet",
      "description" : "### Version Information\r\n\r\nVersion 3.0.24-cloud-lts\r\n\r\n### Environment\r\nToolJet Cloud\r\n\r\n### What is the expected behaviour?\r\nShould see the treeview items properly.\r\n\r\n### What is the current behaviour?\r\n\r\nTreeview items barely visible in dark mode.\r\n\r\n### How to reproduce the issue?\r\n\r\n1. in dark mode, drag out tree select widget\r\n2. notice how hard it is to read the text of the tree\r\n\r\n### Screenshots or Screencast\r\n\r\n<img width=\"416\" alt=\"image\" src=\"https://github.com/user-attachments/assets/896ed9fa-95a5-4845-af00-8fcf0943d8f0\" />\r\n",
      "updatedAt" : 1752214907.000000000,
      "user" : "abulka",
      "userHtmlUrl" : "https://github.com/abulka",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11467530?v=4",
      "labels" : [ "appbuilder", "bug", "community contribution", "good first issue", "up-for-grabs" ],
      "state" : "OPEN",
      "comments" : [ "Hey @PriteshKiri can i work on this , can you assign it to me !!  ", "Hey @neelpatel19,\n\nAre you still interested in working on this issue?", "Hey @PriteshKiri can I work on this, please assign it to me !", "@GuntreddyHemanth  assigned!!\n\nPlease make sure that,\n???- You sign the CLA after submitting your PR.???\n???- You complete this task in 5 days from the day of the assignment. ??????\n???\nThank you for showing interest in contributing to ToolJet! Feel free to reach out to us in our [Slack community](https://join.slack.com/t/tooljet/shared_invite/zt-2rk4w42t0-ZV_KJcWU9VL1BBEjnSHLCA) if you have any questions.", "PR raised @PriteshKiri ", "Hey @GuntreddyHemanth!\n\nCan you please check the comment made on your PR?", "@PriteshKiri is the issue still open?\n", "@ramakrishna67 This issue is already assigned. Could you please check other issues with the **community contribution** label? ", "@ramakrishna67 are you still interested in working on this issue?", "I am interested to work on this (waiting next in line after ramakrishna67)\nI think using html unicode character would be better (as it handles both dark/light colors with same color as font's color) instead of using hard-coded svg url for the arrow icon\nI have updated this in my local. Happy to raise a pr (waiting for ramakrishna67)\n\n![Image](https://github.com/user-attachments/assets/6ef8547f-7c2d-47d6-8e7e-ce67cf004c98)\n![Image](https://github.com/user-attachments/assets/758bb56e-eda5-4f4b-b096-bd7ee86358bb)", "Hello @PriteshKiri.\nThank you for reaching me. \nI would like to work on it but consider the pr raised by @Dante-Nephilim as he already worked on it. \n", "@Dante-Nephilim you can raise the PR for the same.\n\n@ramakrishna67 feel free to check out other issues with `community contribution`\n", "@PriteshKiri, PR is raised", "Hey??@Dante-Nephilim!\n\nThank you so much for your contribution! \uD83D\uDE4C\n\nPlease keep an eye on your PR, as we may add some review comments if needed before merging it.", "Hi @PriteshKiri,\nis this issue open?\nI would like to raise a PR for this.\n", "Hey @DecoderRony!\n\nThanks for your interest. \n\nThis issue has already been assigned. You can check out #10700.", "sure @PriteshKiri ,\nI have also raised a PR for this. In case this issue gets unassigned please consider my PR.", "Hey @PriteshKiri is this issue still open? Would love to work on it.\n", "Hi @PriteshKiri is this issue still open? I would love to work on it.", "Hey @tarunparmar752 @Code1Crusader,\n\nThanks so much for your interest! \uD83D\uDE4C\nThis issue has already been assigned, but feel free to check out other issues labeled with community contribution. We???d love to have your help there!", "Hey, @PriteshKiri, is this issue still open? I am a beginner and would love to be a part of the community" ],
      "repository" : {
        "description" : "Low-code platform for building business applications. Connect to databases, cloud storages, GraphQL, API endpoints, Airtable, Google sheets, OpenAI, etc and build apps using drag and drop application builder. Built using JavaScript/TypeScript. \uD83D\uDE80",
        "homepage" : "https://tooljet.ai",
        "name" : "ToolJet",
        "fullName" : "ToolJet/ToolJet",
        "htmlUrl" : "https://github.com/ToolJet/ToolJet",
        "gitUrl" : "git://github.com/ToolJet/ToolJet.git",
        "sshUrl" : "git@github.com:ToolJet/ToolJet.git",
        "cloneUrl" : "https://github.com/ToolJet/ToolJet.git",
        "owner" : {
          "login" : "ToolJet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4672,
        "stargazersCount" : 35978,
        "watchersCount" : 35978,
        "size" : 1413382,
        "openIssuesCount" : 996,
        "subscribersCount" : 188,
        "pushedAt" : "2025-07-11T20:43:04Z",
        "languages" : {
          "TypeScript" : 3551586,
          "MDX" : 11289,
          "HCL" : 4055,
          "Dockerfile" : 31760,
          "Shell" : 43613,
          "CSS" : 9977,
          "Batchfile" : 61,
          "SCSS" : 1098529,
          "Handlebars" : 55116,
          "JavaScript" : 9181646,
          "HTML" : 52735,
          "EJS" : 17683
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to improve the visibility of the treeview items in dark mode for the tree select widget in ToolJet.",
      "validationOrRequirement" : "The issue requires the treeview items to be properly visible in dark mode. The contributor should sign the CLA after submitting their PR and complete the task within 5 days.",
      "attemptedFixes" : "The contributor @ramakrishna67 suggested using html unicode character instead of hard-coded svg url for the arrow icon. Another contributor @Dante-Nephilim has also worked on this issue.",
      "otherNotes" : "The issue is already assigned, and PR has been raised. Other contributors are also interested in working on this issue. The assignee is @GuntreddyHemanth, and the issue is related to the tree select widget in dark mode.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284830
  }, {
    "issueDTO" : {
      "id" : 3218450030,
      "title" : "onAccessibilityTap :  Property works btut typescript does not recognize that Button should have support for it",
      "url" : "https://github.com/microsoft/react-native-windows/issues/14856",
      "repositoryName" : "microsoft/react-native-windows",
      "description" : "override button.d.ts in react native windows : vnext\\src-win button and add onAccessibilityTap  declaration as it's a windows only prop , no changes needed upstream.\n\n\n<img width=\"1060\" height=\"365\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a1a23aa2-058f-407b-a7ef-7e594f5981c7\" />\n\n\n",
      "updatedAt" : 1752214740.000000000,
      "user" : "iamAbhi-916",
      "userHtmlUrl" : "https://github.com/iamAbhi-916",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/74712637?v=4",
      "labels" : [ "New Architecture", "good first issue: easy", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "After this is completed, we need to import button from react native windows in react native gallery NewArch\\src\\examples\\ModalExamplePage.tsx", "Suggestion: make changes upstream", "@vivekkhare31 this is a window only prop so need to be done only on react native windows" ],
      "repository" : {
        "description" : "A framework for building native Windows apps with React.",
        "homepage" : "https://microsoft.github.io/react-native-windows/",
        "name" : "react-native-windows",
        "fullName" : "microsoft/react-native-windows",
        "htmlUrl" : "https://github.com/microsoft/react-native-windows",
        "gitUrl" : "git://github.com/microsoft/react-native-windows.git",
        "sshUrl" : "git@github.com:microsoft/react-native-windows.git",
        "cloneUrl" : "https://github.com/microsoft/react-native-windows.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1162,
        "stargazersCount" : 16901,
        "watchersCount" : 16901,
        "size" : 300131,
        "openIssuesCount" : 735,
        "subscribersCount" : 274,
        "pushedAt" : "2025-07-10T23:27:38Z",
        "languages" : {
          "TypeScript" : 1401036,
          "C#" : 827087,
          "PowerShell" : 117505,
          "C++" : 8136791,
          "Shell" : 796,
          "C" : 44368,
          "Starlark" : 912,
          "Batchfile" : 20209,
          "Handlebars" : 784,
          "JavaScript" : 3016926,
          "Mustache" : 872,
          "HTML" : 1473
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for onAccessibilityTap property in Button component for react native windows",
      "validationOrRequirement" : "Add onAccessibilityTap declaration in button.d.ts in react native windows : vnext\\src-win button, as it's a windows only prop",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Need to import button from react native windows in react native gallery NewArch\\src\\examples\\ModalExamplePage.tsx",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284834
  }, {
    "issueDTO" : {
      "id" : 2911559682,
      "title" : "Python: `elements.survey(lattice)`",
      "url" : "https://github.com/BLAST-ImpactX/impactx/issues/887",
      "repositoryName" : "BLAST-ImpactX/impactx",
      "description" : "Provide a helper function `elements.survey(lattice)` that creates a pandas DataFrame similar to MAD-X surveys:\nhttps://github.com/BLAST-ImpactX/impactx/pull/879#issuecomment-2715311691\n\n<img width=\"1275\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3464c7fc-50fe-4a8b-87f5-7cabe543a057\" />",
      "updatedAt" : 1752214695.000000000,
      "user" : "ax3l",
      "userHtmlUrl" : "https://github.com/ax3l",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1353258?v=4",
      "labels" : [ "component: python", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks! Did you generate this answer with an LLM @Mizokuiam? The full logic will be a bit more subtle than that.", "I like that the XSuite Survey function also provides a plot method on their survey function:\nhttps://github.com/xsuite/tutorial_cern_seminar/blob/main/notebook_00_lattice_design.ipynb\n\nImplementation via `xtrack` and `xplt`:\n- https://github.com/xsuite/xtrack/blob/4db4e5b0e2452ccf7d40baacb0cbc8d40ad38050/xtrack/survey.py#L176-L194\n- https://github.com/xsuite/xplt/blob/a53942020838e8cc716f69ad8fdbddcd14b1125d/xplt/line.py#L229-L609", "Could we add a plot of the beamline, similar to the one at the bottom of this page:\nhttps://cheetah-accelerator.readthedocs.io/en/latest/examples/simple.html", "Yes \uD83D\uDC4D PR opened for the last comment in #1040 " ],
      "repository" : {
        "description" : "high-performance modeling of beam dynamics in particle accelerators with collective effects",
        "homepage" : "https://impactx.readthedocs.io",
        "name" : "impactx",
        "fullName" : "BLAST-ImpactX/impactx",
        "htmlUrl" : "https://github.com/BLAST-ImpactX/impactx",
        "gitUrl" : "git://github.com/BLAST-ImpactX/impactx.git",
        "sshUrl" : "git@github.com:BLAST-ImpactX/impactx.git",
        "cloneUrl" : "https://github.com/BLAST-ImpactX/impactx.git",
        "owner" : {
          "login" : "BLAST-ImpactX",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 27,
        "stargazersCount" : 44,
        "watchersCount" : 44,
        "size" : 3279,
        "openIssuesCount" : 136,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-10T20:32:33Z",
        "languages" : {
          "C++" : 1019101,
          "Shell" : 4940,
          "CSS" : 327,
          "C" : 589,
          "CMake" : 53835,
          "JavaScript" : 638,
          "Python" : 476547
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a helper function `elements.survey(lattice)` that generates a pandas DataFrame similar to MAD-X surveys",
      "validationOrRequirement" : "Implementation via `xtrack` and `xplt` libraries, requires a plot of the beamline similar to the one on the Cheetah Accelerator documentation page",
      "attemptedFixes" : "PR opened for the last comment in #1040",
      "otherNotes" : "The issue aims to create a helper function `elements.survey(lattice)` that generates a pandas DataFrame similar to MAD-X surveys. The implementation is based on `xtrack` and `xplt` libraries and requires a plot of the beamline similar to the one on the Cheetah Accelerator documentation page.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284838
  }, {
    "issueDTO" : {
      "id" : 3221190306,
      "title" : "How does the Validation Instructions for Generative Answers work?",
      "url" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/issues/233",
      "repositoryName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
      "description" : "<img width=\"1219\" height=\"601\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9267cd10-7c35-4c4d-8a75-97baeb00cd2e\" />\n\nHi. Sorry, we're new to using Copilot Studio Kit. Might be a dumb question, but how do we use operators with the Validation Instructions? In our example, we are expecting that the response, although not in exact words, is that the user has to register or to transfer the domain.\n\nBut the response that the chatbot extracted contained just that, but CSK still classified it as \"Failed\". Why is this so and how can we filter or refine test result analysis from Generative Answers?",
      "updatedAt" : 1752214644.000000000,
      "user" : "theredpicker",
      "userHtmlUrl" : "https://github.com/theredpicker",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/219937139?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@theredpicker ,\n\nWhen using Validation Instructions in Copilot Studio Kit, it's important to set a clear expectation for what the response should include. Since generative AI responses can vary in wording, relying on exact matches often leads to failed validations.\n\n<img width=\"1671\" height=\"713\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/071ae465-b4cd-4967-85c7-5095193a1b43\" />\n\nFor example, if your test utterance is:\n**\"What is the capital of Brazil?\"**\n\nThen your validation instruction could be:\n**\"Validate the response should contain the answer as Brasilia.\"**\n\n\n<img width=\"1721\" height=\"704\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5f2190ad-5401-4032-9862-ee8f14ab8893\" />\n\n\nIn your case, you can try writing the Validation Instruction like this:\n\n**\"Response should mention the need to have at least one domain to create an account.\"**" ],
      "repository" : {
        "description" : null,
        "homepage" : "",
        "name" : "Power-CAT-Copilot-Studio-Kit",
        "fullName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
        "htmlUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit",
        "gitUrl" : "git://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "sshUrl" : "git@github.com:microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "cloneUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 180,
        "watchersCount" : 180,
        "size" : 48361,
        "openIssuesCount" : 27,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-09T12:45:38Z",
        "languages" : {
          "C#" : 24850,
          "CSS" : 4368,
          "JavaScript" : 33528,
          "HTML" : 16742
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Understand how to use Validation Instructions for Generative Answers in Copilot Studio Kit and how to refine test result analysis from Generative Answers.",
      "validationOrRequirement" : "Validation Instructions should set a clear expectation for the response, and the expectation should be specific enough to cover variations in wording.",
      "attemptedFixes" : "The user is trying to refine test result analysis from Generative Answers, but the issue is not specifically about attempted fixes.",
      "otherNotes" : "Validation Instructions for Generative Answers require clear expectations for response wording, as generative AI responses can vary. Relying on exact matches often leads to failed validations.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284843
  }, {
    "issueDTO" : {
      "id" : 3145010035,
      "title" : "Using Drill by in a dashboard doesn't work in columns created with <a> tags",
      "url" : "https://github.com/apache/superset/issues/33771",
      "repositoryName" : "apache/superset",
      "description" : "\n\n## Description\nIf you create a chart (e.g. Table Chart) with a custom SQL query that has an `<a>`, the resulting chart can be created and nested in a dashboard and you won???t be able to use the Drill by feature with it because nothing appears.\n\n## How to reproduce the bug\n1. Create a Table chart \n2. Use as dimension a column that has a `<a>` tag applied in the Custom SQL section. It could be something like this `'<a href=\"https://www.google.com/search?q='  || Product_Category || '\">' || Product_Category || '</a>'`\n3. Save the chart in a dashboard and then use the Drill by feature in that column\n\n![Image](https://github.com/user-attachments/assets/e1e9a488-36c9-4cd4-abfd-4287a5847fba)\n\n## Expected results\nThe prompted window after using Drill by shows you the details of the category\n\n## Actual results\nThe prompted window after using Drill by doesn???t show anything\n\n![Image](https://github.com/user-attachments/assets/1e90c84b-6529-4c27-8afa-1cbca7fcb735)\n\n## Known Workarounds\nNo workarounds are currently known\n\n### Screenshots/recordings\n\n_No response_\n\n### Superset version\n\nmaster / latest-dev\n\n### Python version\n\n3.9\n\n### Node version\n\n16\n\n### Browser\n\nChrome\n\n### Additional context\n\n_No response_\n\n### Checklist\n\n- [x] I have searched Superset docs and Slack and didn't find a solution to my problem.\n- [x] I have searched the GitHub issue tracker and didn't find a similar bug report.\n- [ ] I have checked Superset's logs for errors and if I found a relevant Python stacktrace, I included it here as text in the \"additional context\" section.",
      "updatedAt" : 1752214454.000000000,
      "user" : "yousoph",
      "userHtmlUrl" : "https://github.com/yousoph",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10627051?v=4",
      "labels" : [ "dashboard:drill-by", "preset:bounty", "preset:bounty:bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<!-- Answer -->\nThis is a known limitation in how Drill by works with columns containing HTML, such as <a> tags. The root cause is that when you use Drill by on a table cell, Superset passes the raw SQL value (which includes the HTML markup) as the filter value, rather than the plain text label that???s displayed to users. Since the filter value includes the HTML, it doesn???t match the expected values in the dataset, so no results are shown. The table chart does sanitize and render HTML for display, but the Drill by logic doesn???t strip HTML before filtering, which causes this disconnect??[reference](https://github.com/apache/superset/blob/21d8d57380bcc67bab8e603fda99ffbc4a7dcac2/superset-frontend/plugins/plugin-chart-table/src/TableChart.tsx).\n\nThere isn???t a built-in workaround right now. To address this, the code that handles Drill by/context menu events should strip HTML tags from the filter value before applying the filter. The codebase already includes utilities for HTML sanitization and tag removal, so this would be a straightforward fix for a developer familiar with the frontend code??[reference](https://github.com/apache/superset/blob/21d8d57380bcc67bab8e603fda99ffbc4a7dcac2/superset-frontend/plugins/plugin-chart-table/src/utils/formatValue.ts).\n\nNo existing tickets or documentation specifically address this scenario, but the technical root cause is clear from the code. If you need to use Drill by on these columns, you???ll need to avoid embedding HTML in the dimension values, or consider a code change to strip HTML before filtering.\n\n\n<!-- Dosu Comment Footer -->\n*To reply, just mention [@dosu](https://go.dosu.dev/dosubot).*\n\n---\n<sup>How did I do? [Good](https://app.dosu.dev/response-feedback/231859ef-27bf-43dc-83e8-c9f01be6d32f?feedback_type=great_response) | [Irrelevant](https://app.dosu.dev/response-feedback/231859ef-27bf-43dc-83e8-c9f01be6d32f?feedback_type=irrelevant_answer) | [Incorrect](https://app.dosu.dev/response-feedback/231859ef-27bf-43dc-83e8-c9f01be6d32f?feedback_type=incorrect_sources) | [Verbose](https://app.dosu.dev/response-feedback/231859ef-27bf-43dc-83e8-c9f01be6d32f?feedback_type=too_verbose) | [Hallucination](https://app.dosu.dev/response-feedback/231859ef-27bf-43dc-83e8-c9f01be6d32f?feedback_type=hallucination) | [Report \uD83D\uDC1B](https://app.dosu.dev/response-feedback/231859ef-27bf-43dc-83e8-c9f01be6d32f?feedback_type=bug_report) | [Other](https://app.dosu.dev/response-feedback/231859ef-27bf-43dc-83e8-c9f01be6d32f?feedback_type=other)</sup>&nbsp;&nbsp;[![Join Discord](https://img.shields.io/badge/join-5865F2?logo=discord&logoColor=white&label=)](https://go.dosu.dev/discord-bot)&nbsp;[![Share on X](https://img.shields.io/badge/X-share-black)](https://twitter.com/intent/tweet?text=%40dosu_ai%20helped%20me%20solve%20this%20issue!&url=https%3A//github.com/apache/superset/issues/33771)", "---\n\n### \uD83C\uDF89 **Preset Bounty Available: $150 USD** \uD83C\uDF89\n\nTo claim this bounty, please carefully follow the steps below.\n\n---\n\n#### \uD83D\uDCCB **Steps to Participate**\n\n1. **Review Guidelines:**  \n   Read through the [Preset Bounty Program Contribution Guide](https://preset.notion.site/preset-bounty-program-apache-superset) for complete details on bounty requirements.\n\n2. **Show Your Interest:**  \n   Complete the [Preset Bounty Program Survey](https://docs.google.com/forms/d/e/1FAIpQLSeDsR1iWvPxFydUIXs2agsUg3kMDaAooeD4P9P1L5sI0Yu5QQ/viewform?usp=sharing) and comment this issue to express your interest.\n\n3. **Join the Slack Channel:**  \n   After completing the survey, you???ll receive an invitation to the dedicated [Apache Superset Slack](https://join.slack.com/t/apache-superset/shared_invite/zt-2be0drwz8-bxPfkdz28ozzk1Iox29ufg) channel.\n\n4. **Get Assigned:**  \n   To officially start, ensure a **Bounty Program Manager** has assigned you to this issue.\n\n5. **Submit Your Solution:**  \n   When ready, submit your solution with the `Fixes #{issue_number}` notation in your Pull Request description.\n\n6. **Claim Your Bounty:**  \n   Sign up at [GitPay.me](https://gitpay.me/) and submit your solution via: [https://gitpay.me/#/task/1210](https://gitpay.me/#/task/1210)\n\n---\n\n#### \uD83D\uDCA1 **Additional Notes**\n\n- Only developers assigned by a **Bounty Program Manager** should start working on this issue to win the bounty.\n- Be sure to follow the guide closely to avoid any delays in payment. Please, allow a few days after your PR has been merged for the bounty to be released.\n\nGood luck, and happy coding! \uD83C\uDF89", " @geido would like to take this, Please assign to me", "@geido Please assign me", "@geido If this issue hasn???t been assigned yet, I???d love to take it on", "@msyavuz it's been 16 days and there is no activity,I would like to get this issue assigned", "@Niharika0104 @Nandu9494 is already working on this.", "Hi, I started working on this" ],
      "repository" : {
        "description" : "Apache Superset is a Data Visualization and Data Exploration Platform",
        "homepage" : "https://superset.apache.org/",
        "name" : "superset",
        "fullName" : "apache/superset",
        "htmlUrl" : "https://github.com/apache/superset",
        "gitUrl" : "git://github.com/apache/superset.git",
        "sshUrl" : "git@github.com:apache/superset.git",
        "cloneUrl" : "https://github.com/apache/superset.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15298,
        "stargazersCount" : 67064,
        "watchersCount" : 67064,
        "size" : 756073,
        "openIssuesCount" : 803,
        "subscribersCount" : 1530,
        "pushedAt" : "2025-07-12T00:34:00Z",
        "languages" : {
          "Smarty" : 5044,
          "Jinja" : 5847,
          "CSS" : 4781,
          "Pug" : 2969,
          "Makefile" : 4133,
          "HTML" : 1278006,
          "Jupyter Notebook" : 10916999,
          "TypeScript" : 11362202,
          "Dockerfile" : 12025,
          "Shell" : 65877,
          "JavaScript" : 1839895,
          "Mako" : 1197,
          "Python" : 8964539
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about using Drill by in a dashboard doesn't work in columns created with <a> tags",
      "validationOrRequirement" : "The column containing HTML, such as <a> tags, should not be used with Drill by feature.",
      "attemptedFixes" : "There isn???t a built-in workaround right now. To address this, the code that handles Drill by/context menu events should strip HTML tags from the filter value before applying the filter.",
      "otherNotes" : "The issue is a known limitation in how Drill by works with columns containing HTML, such as <a> tags. The root cause is that when you use Drill by on a table cell, Superset passes the raw SQL value (which includes the HTML markup) as the filter value, rather than the plain text label that???s displayed to users. The code that handles Drill by/context menu events should strip HTML tags from the filter value before applying the filter.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284850
  }, {
    "issueDTO" : {
      "id" : 3064300532,
      "title" : "Expose SNAT address as a part of external IP addresses in the API",
      "url" : "https://github.com/oxidecomputer/omicron/issues/8163",
      "repositoryName" : "oxidecomputer/omicron",
      "description" : "(from oxidecomputer/customer-support#291)\nWhen requesting the external IP addresses assigned to an instance, we currently only list the floating and ephemeral IP addresses. It would be very helpful when debugging instance external connectivity to also see the IP address and port range that was assigned to the instance for SNAT.\n\nA possible implementation is to add an item to the API that is backing the `oxide instance external-ip list` command to include SNAT IP information. This should include the IP address, the port range, and the id of the IP pool it was pulled from.\n\nExample of current state:\n```\n[workarea] : oxide instance external-ip list --instance d85e2041-e91d-4e15-972f-f56c078a4490\n{\n  \"items\": [\n    {\n      \"kind\": \"floating\",\n      \"description\": \"\",\n      \"id\": \"d1bede7c-b820-41be-8ece-01e2a43fb942\",\n      \"instance_id\": \"d85e2041-e91d-4e15-972f-f56c078a4490\",\n      \"ip\": \"45.154.216.115\",\n      \"ip_pool_id\": \"4a125719-9d1d-49e9-a2e4-042053a4716b\",\n      \"name\": \"keycloak\",\n      \"project_id\": \"99e89d0f-3b44-4e9c-a940-c034e42e783c\",\n      \"time_created\": \"2024-07-30T21:15:03.672889Z\",\n      \"time_modified\": \"2024-08-09T14:41:12.717786Z\"\n    },\n    {\n      \"kind\": \"ephemeral\",\n      \"ip\": \"172.21.252.11\"\n    }\n  ]\n}\n```\nAn ephemeral and floating IP are shown, but the SNAT is not.",
      "updatedAt" : 1752214266.000000000,
      "user" : "askfongjojo",
      "userHtmlUrl" : "https://github.com/askfongjojo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10874909?v=4",
      "labels" : [ "api", "good first issue", "customer" ],
      "state" : "OPEN",
      "comments" : [ "Just checking, is this still something we want to support? Today, Nexus explicitly and purposefully prevents showing SNAT IPs in the public API, so I'm just not sure where we landed. CC @augustuswm ", "I'm not sure if we ever ended up having a discussion on this. I think it is a useful piece of information to have when debugging, but if we have a specific reason for not exposing it I don't want to break any abstraction boundaries.", "There are two use cases this can serve:\n1. for the developer who wants visibility into the IP address will or may be used for an instance's outbound traffic\n2. for silo admin to track down the instance(s) associated with a particular IP address when there is a security-related concern" ],
      "repository" : {
        "description" : "Omicron: Oxide control plane",
        "homepage" : "",
        "name" : "omicron",
        "fullName" : "oxidecomputer/omicron",
        "htmlUrl" : "https://github.com/oxidecomputer/omicron",
        "gitUrl" : "git://github.com/oxidecomputer/omicron.git",
        "sshUrl" : "git@github.com:oxidecomputer/omicron.git",
        "cloneUrl" : "https://github.com/oxidecomputer/omicron.git",
        "owner" : {
          "login" : "oxidecomputer",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 45,
        "stargazersCount" : 304,
        "watchersCount" : 304,
        "size" : 69035,
        "openIssuesCount" : 1135,
        "subscribersCount" : 36,
        "pushedAt" : "2025-07-12T00:02:16Z",
        "languages" : {
          "Shell" : 59002,
          "Rust" : 21826367,
          "Polar" : 23930,
          "PLpgSQL" : 201378,
          "TLA" : 39338,
          "HTML" : 13,
          "Nix" : 12709,
          "DTrace" : 4876
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Expose SNAT address as a part of external IP addresses in the API, including the IP address, port range, and ID of the IP pool it was pulled from, to aid in debugging instance external connectivity.",
      "validationOrRequirement" : "The API should include SNAT IP information when listing external IP addresses, including the IP address, port range, and ID of the IP pool it was pulled from.",
      "attemptedFixes" : "No specific fixes mentioned in the comments, but it's mentioned that Nexus explicitly prevents showing SNAT IPs in the public API, so it's unclear where the team landed on this issue.",
      "otherNotes" : "The issue is about exposing SNAT address as a part of external IP addresses in the API, which is currently not listed. It would be helpful for debugging instance external connectivity to include SNAT IP information. There are two use cases for this: for developers who want visibility into the IP address used for an instance's outbound traffic and for silo admins to track down instances associated with a particular IP address when there's a security-related concern.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284857
  }, {
    "issueDTO" : {
      "id" : 3174482123,
      "title" : "Replace <span>(custom Badge) with Badge component across the code base",
      "url" : "https://github.com/ohcnetwork/care_fe/issues/12711",
      "repositoryName" : "ohcnetwork/care_fe",
      "description" : "Many components in the codebase, including but not limited to the Medicine Administration module, currently use raw <span> elements to display status labels or tags. To ensure a consistent UI and improved maintainability, these <span> elements should be replaced with the standardized Badge component across the entire codebase.\n\n<img width=\"1464\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/fffd7bff-69eb-4033-98cc-4ee07382ee51\" />\n\n\nref #12668 ",
      "updatedAt" : 1752214104.000000000,
      "user" : "abhimanyurajeesh",
      "userHtmlUrl" : "https://github.com/abhimanyurajeesh",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/63541653?v=4",
      "labels" : [ "question", "needs-triage", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@rithviknishad Hi! I'd like to work on this issue. Could you please assign it to me?", "@vishakh-abhayan are you working on this?", "Yes\r\n\r\nOn Fri, 27 Jun, 2025, 11:25???pm Mohamed amaan, ***@***.***>\r\nwrote:\r\n\r\n> *modamaan* left a comment (ohcnetwork/care_fe#12711)\r\n> <https://github.com/ohcnetwork/care_fe/issues/12711#issuecomment-3013940986>\r\n>\r\n> @vishakh-abhayan <https://github.com/vishakh-abhayan> are you working on\r\n> this?\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/ohcnetwork/care_fe/issues/12711#issuecomment-3013940986>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AWPQLRLMEHW5Y32FNR5IKGL3FWASFAVCNFSM6AAAAACACL6WTOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZTAMJTHE2DAOJYGY>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n", "Hi @AdityaJ2305 \uD83D\uDC4B\n\nI???d like to work on this issue .\n\n Proposed Solution:\n- I will update the Patient Details component so that phone numbers become clickable `tel:` links and addresses become clickable `https://maps` links.\n- I???ll ensure they open in a new tab or trigger a phone call as expected.\n\nETA:\nI???ll submit a PR within 1???2 days after assignment.\n\nLooking forward to contributing???thanks!\n", "@vishakh-abhayan unassigned as no updated be made for the past 2 weeks ", "@abhimanyurajeesh I would like to work on this \nETA : 2 days " ],
      "repository" : {
        "description" : "Care is a Digital Public Good enabling TeleICU & Decentralised Administration of Healthcare Capacity across States.",
        "homepage" : "https://care.ohc.network",
        "name" : "care_fe",
        "fullName" : "ohcnetwork/care_fe",
        "htmlUrl" : "https://github.com/ohcnetwork/care_fe",
        "gitUrl" : "git://github.com/ohcnetwork/care_fe.git",
        "sshUrl" : "git@github.com:ohcnetwork/care_fe.git",
        "cloneUrl" : "https://github.com/ohcnetwork/care_fe.git",
        "owner" : {
          "login" : "ohcnetwork",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 834,
        "stargazersCount" : 537,
        "watchersCount" : 537,
        "size" : 55125,
        "openIssuesCount" : 219,
        "subscribersCount" : 20,
        "pushedAt" : "2025-07-11T14:40:03Z",
        "languages" : {
          "TypeScript" : 4936598,
          "Dockerfile" : 560,
          "CSS" : 7532,
          "JavaScript" : 9703,
          "HTML" : 3683
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace <span>(custom Badge) with Badge component across the code base to ensure consistent UI and improved maintainability",
      "validationOrRequirement" : "Replace raw <span> elements with standardized Badge component across the entire codebase, ensure consistent UI and improved maintainability",
      "attemptedFixes" : "Proposed Solution: update Patient Details component, ensure phone numbers and addresses become clickable links, open in new tab or trigger phone call",
      "otherNotes" : "Labels: question, needs-triage, good first issue, @rithviknishad wants to work on this, @vishakh-abhayan is unassigned, @abhimanyurajeesh wants to work on this, @AdityaJ2305 is mentioned",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284862
  }, {
    "issueDTO" : {
      "id" : 3220474006,
      "title" : "Unicode region chart link is outdated",
      "url" : "https://github.com/mdn/content/issues/40310",
      "repositoryName" : "mdn/content",
      "description" : "### MDN URL\n\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Intl/Locale/region\n\n### What specific section or headline is this issue about?\n\n\"See Also\"\n\n### What information was incorrect, unhelpful, or incomplete?\n\nThe link listed is moved\n\n### What did you expect to see?\n\nA chart of all the unicode regions\n\n### Do you have any supporting links, references, or citations?\n\n_No response_\n\n### Do you have anything more you want to share?\n\nFixed link is https://www.unicode.org/cldr/charts/47/supplemental/territory_containment_un_m_49.html",
      "updatedAt" : 1752214080.000000000,
      "user" : "yasiralamriki",
      "userHtmlUrl" : "https://github.com/yasiralamriki",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/70416702?v=4",
      "labels" : [ "Content:JS", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I think good first issue would be a good tag for this, fixing the link is simple", "Happy to take a PR" ],
      "repository" : {
        "description" : "The content behind MDN Web Docs",
        "homepage" : "https://developer.mozilla.org",
        "name" : "content",
        "fullName" : "mdn/content",
        "htmlUrl" : "https://github.com/mdn/content",
        "gitUrl" : "git://github.com/mdn/content.git",
        "sshUrl" : "git@github.com:mdn/content.git",
        "cloneUrl" : "https://github.com/mdn/content.git",
        "owner" : {
          "login" : "mdn",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 22766,
        "stargazersCount" : 9620,
        "watchersCount" : 9620,
        "size" : 461774,
        "openIssuesCount" : 467,
        "subscribersCount" : 258,
        "pushedAt" : "2025-07-12T00:30:37Z",
        "languages" : {
          "JavaScript" : 44986,
          "HTML" : 11035,
          "Markdown" : 54458857
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the Unicode region chart link to the correct one",
      "validationOrRequirement" : "No specific requirements mentioned, but it's a good first issue",
      "attemptedFixes" : "No attempts mentioned, but the author is willing to take a PR",
      "otherNotes" : "The link listed is moved, expected to see a chart of all the unicode regions, fixed link is https://www.unicode.org/cldr/charts/47/supplemental/territory_containment_un_m_49.html",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284866
  }, {
    "issueDTO" : {
      "id" : 1868326753,
      "title" : "3D WebGPU Shader preview",
      "url" : "https://github.com/DestinyItemManager/DIM/issues/9781",
      "repositoryName" : "DestinyItemManager/DIM",
      "description" : "I meant to do this years ago, but it's worth revisiting - the PBR surface shader for Destiny items has been pretty well reverse-engineered at this point, and the shader values that plug into it are available in the manifest. So it should be possible to make a quick WebGPU visualizer that shows a cube or sphere that shows off all 6(?) colors in a shader.\n\nRelated, @lowPolySkeleton suggested that it'd be great to have search based on the colors in a shader. I'd want to do that after having the preview so we can understand what a color really means...\n\nThis Blender implementation of the D2 shaders is the place to start from: https://thejudsub.gumroad.com/l/Destiny2PlayerGearShader?layout=profile",
      "updatedAt" : 1752213899.000000000,
      "user" : "bhollis",
      "userHtmlUrl" : "https://github.com/bhollis",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/313208?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "This is maybe getting better with the new 6-color shader icon in The Final Shape, but a 3D preview and color searches would both be amazing." ],
      "repository" : {
        "description" : "Destiny Item Manager",
        "homepage" : "https://destinyitemmanager.com",
        "name" : "DIM",
        "fullName" : "DestinyItemManager/DIM",
        "htmlUrl" : "https://github.com/DestinyItemManager/DIM",
        "gitUrl" : "git://github.com/DestinyItemManager/DIM.git",
        "sshUrl" : "git@github.com:DestinyItemManager/DIM.git",
        "cloneUrl" : "https://github.com/DestinyItemManager/DIM.git",
        "owner" : {
          "login" : "DestinyItemManager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 643,
        "stargazersCount" : 2094,
        "watchersCount" : 2094,
        "size" : 469540,
        "openIssuesCount" : 154,
        "subscribersCount" : 60,
        "pushedAt" : "2025-07-11T06:15:37Z",
        "languages" : {
          "TypeScript" : 3962567,
          "Shell" : 2430,
          "SCSS" : 345507,
          "JavaScript" : 45441,
          "PHP" : 1674,
          "HTML" : 5588
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to create a WebGPU visualizer that shows off all 6 colors in a shader, and potentially add search functionality based on those colors.",
      "validationOrRequirement" : "No specific validations or requirements mentioned, but the issue is labeled as 'Good First Issue'.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to a Blender implementation of D2 shaders and includes suggestions for a 3D preview and color searches.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284869
  }, {
    "issueDTO" : {
      "id" : 3181139553,
      "title" : "Add tooltip or explanation for tags' 'bindingCount'",
      "url" : "https://github.com/langgenius/dify/issues/21601",
      "repositoryName" : "langgenius/dify",
      "description" : "### Self Checks\n\n- [x] I have searched for existing issues [search for existing issues](https://github.com/langgenius/dify/issues), including closed ones.\n- [x] I confirm that I am using English to submit this report (????????????????????? [Language Policy](https://github.com/langgenius/dify/issues/1542)).\n- [x] [FOR CHINESE USERS] ??????????????????????????? Issue?????????????????????????????????:)\n- [x] Please do not modify this template :) and fill in all the required fields.\n\n### 1. Is this request related to a challenge you're experiencing? Tell me about your story.\n\n![Image](https://github.com/user-attachments/assets/142bc445-931e-4743-b945-ca9889adeb1e)\nWhen managing tags, the number following the tag name (indicating the number of bound apps) does not have any tooltip or explanation, which may cause confusion.\n\n### 2. Additional context or comments\n\n_No response_\n\n### 3. Can you help us with this feature?\n\n- [ ] I am interested in contributing to this feature.",
      "updatedAt" : 1752213048.000000000,
      "user" : "HyaCiovo",
      "userHtmlUrl" : "https://github.com/HyaCiovo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/88471803?v=4",
      "labels" : [ "\uD83D\uDCAA enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Production-ready platform for agentic workflow development.",
        "homepage" : "https://dify.ai",
        "name" : "dify",
        "fullName" : "langgenius/dify",
        "htmlUrl" : "https://github.com/langgenius/dify",
        "gitUrl" : "git://github.com/langgenius/dify.git",
        "sshUrl" : "git@github.com:langgenius/dify.git",
        "cloneUrl" : "https://github.com/langgenius/dify.git",
        "owner" : {
          "login" : "langgenius",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16148,
        "stargazersCount" : 106618,
        "watchersCount" : 106618,
        "size" : 103462,
        "openIssuesCount" : 777,
        "subscribersCount" : 653,
        "pushedAt" : "2025-07-11T14:34:26Z",
        "languages" : {
          "TypeScript" : 11601485,
          "MDX" : 865160,
          "Dockerfile" : 4139,
          "CSS" : 182041,
          "Shell" : 19709,
          "SCSS" : 21945,
          "Makefile" : 1304,
          "JavaScript" : 1430743,
          "PHP" : 6106,
          "HTML" : 33871,
          "Mako" : 518,
          "Python" : 6709901
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a tooltip or explanation for tags' 'bindingCount'.",
      "validationOrRequirement" : "No specific validations or requirements are mentioned in the issue description.",
      "attemptedFixes" : "No attempted fixes or blockers are mentioned in the issue description.",
      "otherNotes" : "The issue is related to a challenge experienced when managing tags, where the number of bound apps following the tag name does not have a tooltip or explanation, which may cause confusion.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284873
  }, {
    "issueDTO" : {
      "id" : 2633470276,
      "title" : "Add some examples",
      "url" : "https://github.com/edgexhq/opbento/issues/8",
      "repositoryName" : "edgexhq/opbento",
      "description" : "Provide examples of github users, using OP Bento in a `Showcase` page",
      "updatedAt" : 1752212912.000000000,
      "user" : "subhadeeproy3902",
      "userHtmlUrl" : "https://github.com/subhadeeproy3902",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/111780029?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Can you specify your requirements, @subhadeeproy3902 ", "> Can you specify your requirements, @subhadeeproy3902\r\n\r\nSome examples like who people are using this in their readme. \r\nMake a carousel, auto slider of those people and screenshots in a nice way and add it to our project", "Okh @subhadeeproy3902 assign it to me, I want to work on this ", "go ahead @yashksaini-coder " ],
      "repository" : {
        "description" : "Make your Github Profile modern and trendy !",
        "homepage" : "https://opbento.edgexhq.tech",
        "name" : "opbento",
        "fullName" : "edgexhq/opbento",
        "htmlUrl" : "https://github.com/edgexhq/opbento",
        "gitUrl" : "git://github.com/edgexhq/opbento.git",
        "sshUrl" : "git@github.com:edgexhq/opbento.git",
        "cloneUrl" : "https://github.com/edgexhq/opbento.git",
        "owner" : {
          "login" : "edgexhq",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 13,
        "stargazersCount" : 41,
        "watchersCount" : 41,
        "size" : 76457,
        "openIssuesCount" : 5,
        "subscribersCount" : 2,
        "pushedAt" : "2025-01-18T12:15:23Z",
        "languages" : {
          "TypeScript" : 176659,
          "CSS" : 7075,
          "JavaScript" : 643,
          "HTML" : 15482
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add some examples of GitHub users using OP Bento in a Showcase page.",
      "validationOrRequirement" : "Specific requirements include specifying requirements and making a carousel or auto-slider with screenshots.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue aims to showcase GitHub users who are using OP Bento in their README, and create a carousel or auto-slider with screenshots and assign it to the repository edgexhq/opbento.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284876
  }, {
    "issueDTO" : {
      "id" : 1870740549,
      "title" : "Figure out a better icon for icon-less raid modslots",
      "url" : "https://github.com/DestinyItemManager/DIM/issues/9791",
      "repositoryName" : "DestinyItemManager/DIM",
      "description" : "Bungie stopped drawing nice icons into the raid mod slot and now we show empty circles:\r\n\r\n<img width=\"339\" alt=\"Screenshot 2023-08-28 at 6 42 40 PM\" src=\"https://github.com/DestinyItemManager/DIM/assets/313208/cef5e680-46e9-4284-96b2-e319bd38e889\">\r\n\r\nWe should probably try something else - perhaps we could put the icon overlay here, with the assumption that only one raid will be released per season?",
      "updatedAt" : 1752212886.000000000,
      "user" : "bhollis",
      "userHtmlUrl" : "https://github.com/bhollis",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/313208?v=4",
      "labels" : [ "Good First Issue", "Feature: Sockets" ],
      "state" : "OPEN",
      "comments" : [ "Alternatively we could grab a nice icon from the defs, e.g. https://data.destinysets.com/i/Milestone:292102995", "Yeah that'd be great, we'd probably need to make yet another d2ai mapping for it though.", "Mod slot metadata is massively hardcoded in DIM already, shouldn't be too hard to add one more def hash to the rest of the hashes we add every 6 months" ],
      "repository" : {
        "description" : "Destiny Item Manager",
        "homepage" : "https://destinyitemmanager.com",
        "name" : "DIM",
        "fullName" : "DestinyItemManager/DIM",
        "htmlUrl" : "https://github.com/DestinyItemManager/DIM",
        "gitUrl" : "git://github.com/DestinyItemManager/DIM.git",
        "sshUrl" : "git@github.com:DestinyItemManager/DIM.git",
        "cloneUrl" : "https://github.com/DestinyItemManager/DIM.git",
        "owner" : {
          "login" : "DestinyItemManager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 643,
        "stargazersCount" : 2094,
        "watchersCount" : 2094,
        "size" : 469540,
        "openIssuesCount" : 154,
        "subscribersCount" : 60,
        "pushedAt" : "2025-07-11T06:15:37Z",
        "languages" : {
          "TypeScript" : 3962567,
          "Shell" : 2430,
          "SCSS" : 345507,
          "JavaScript" : 45441,
          "PHP" : 1674,
          "HTML" : 5588
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Figure out a better icon for icon-less raid modslots",
      "validationOrRequirement" : "Good First Issue, Feature: Sockets",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments.",
      "otherNotes" : "Bungie stopped drawing nice icons into the raid mod slot and now we show empty circles. Alternative solutions mentioned include putting the icon overlay, grabbing a nice icon from the defs, or adding a new d2ai mapping.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284880
  }, {
    "issueDTO" : {
      "id" : 1959169363,
      "title" : "Loadout Optimizer integration tests and benchmarks",
      "url" : "https://github.com/DestinyItemManager/DIM/issues/9993",
      "repositoryName" : "DestinyItemManager/DIM",
      "description" : "Some utility functions for LO have unit tests (mod assignment, auto mods) but the main process loop doesn't. It'd be good to have tests for that to assert qualities about the output - right now we could break the worker by not adding any sets in the loop and no tests would fail.\r\n\r\nIt'd also be good to have benchmarks. Right now I'm optimizing LO by judging the reported process time, which does include message passing to/from the worker and it's not particularly reliable/conclusive. Is there a JS testing framework that does proper warmup runs, statistical run analysis, and ideally also allows the benchmarks to be compiled to a single JS file to be profiled with more V8 flags, e.g. to then analyze with the [deopt explorer](https://github.com/microsoft/deoptexplorer-vscode)? ",
      "updatedAt" : 1752212797.000000000,
      "user" : "robojumper",
      "userHtmlUrl" : "https://github.com/robojumper",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/14299449?v=4",
      "labels" : [ "Good First Issue", "Feature: Loadout Optimizer" ],
      "state" : "OPEN",
      "comments" : [ "I've played around a bit with compiling to a JS file that can be ran offline in node with V8 flags that gets as close as possible (in terms of babel/terser options) to what we run in the browser and come to the conclusion that it's painful to configure (I couldn't figure out how to turn off whitespace compression) and it's not particularly useful to get JIT deopt information - JITs are just too sensitive to changes in the environment and even just calling the process in a loop ends up with object shapes and \"code dependency changes\" we don't see in beta/prod." ],
      "repository" : {
        "description" : "Destiny Item Manager",
        "homepage" : "https://destinyitemmanager.com",
        "name" : "DIM",
        "fullName" : "DestinyItemManager/DIM",
        "htmlUrl" : "https://github.com/DestinyItemManager/DIM",
        "gitUrl" : "git://github.com/DestinyItemManager/DIM.git",
        "sshUrl" : "git@github.com:DestinyItemManager/DIM.git",
        "cloneUrl" : "https://github.com/DestinyItemManager/DIM.git",
        "owner" : {
          "login" : "DestinyItemManager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 643,
        "stargazersCount" : 2094,
        "watchersCount" : 2094,
        "size" : 469540,
        "openIssuesCount" : 154,
        "subscribersCount" : 60,
        "pushedAt" : "2025-07-11T06:15:37Z",
        "languages" : {
          "TypeScript" : 3962567,
          "Shell" : 2430,
          "SCSS" : 345507,
          "JavaScript" : 45441,
          "PHP" : 1674,
          "HTML" : 5588
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Integrate tests and benchmarks for the Loadout Optimizer to ensure the quality of the output and optimize the process loop.",
      "validationOrRequirement" : "The issue requires a JS testing framework that does proper warmup runs, statistical run analysis, and allows the benchmarks to be compiled to a single JS file to be profiled with more V8 flags.",
      "attemptedFixes" : "The author has tried to compile the benchmark to a JS file that can be ran offline in node with V8 flags, but it's painful to configure and not particularly useful for getting JIT deopt information.",
      "otherNotes" : "The issue is about integrating tests and benchmarks for the Loadout Optimizer. The main process loop doesn't have unit tests, and the current optimization method is unreliable due to including message passing to/from the worker in the reported process time.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284885
  }, {
    "issueDTO" : {
      "id" : 3165669139,
      "title" : "Nacos 2.5.1 mysql-schema.sql missing config_info_beta table causes false DB error logs",
      "url" : "https://github.com/alibaba/nacos/issues/13538",
      "repositoryName" : "alibaba/nacos",
      "description" : "In Nacos 2.5.1, the provided mysql-schema.sql file no longer contains the creation statement for the config_info_beta table, which exists in previous versions such as 2.5.0.\n\nThis omission leads to runtime side effects:\n\nNacos executes the following SQL as part of its internal database health check:\nSELECT * FROM config_info_beta WHERE id = 1;\n\nIf the config_info_beta table is missing, the query fails and logs the following error:\n[db-error] master db xxx.xxx.xxx.xxx down.\n\nThese logs appear in:\nlogs/nacos-persistence.log\n\nHowever, the actual MySQL database is working fine ??? the failure is caused by a missing table, not a real connection issue.\n\nSteps to Reproduce:\n\nDeploy Nacos 2.5.1 with an external MySQL instance.\n\nUse the official conf/mysql-schema.sql file to initialize the database (note: config_info_beta table is missing).\n\nStart Nacos.\n\nObserve the following logs:\nERROR [db-error] master db xxx.xxx.xxx.xxx down.\n\n\nAdditional Context:\n\nAfter manually creating the config_info_beta table (using the SQL from 2.5.0), the health check log errors stop appearing.\n\nThis confirms the issue is due to the missing table in the schema file, not an actual database failure.\n\nEnvironment Info:\n\nItem | Version\nNacos | 2.5.1\nMySQL | 8.0.33\nDeploy Method | Docker \nJDBC Mode | External MySQL\nAffected Files | conf/mysql-schema.sql, logs/nacos-persistence.log\n\n\nThanks for your attention!\n\n",
      "updatedAt" : 1752212766.000000000,
      "user" : "hanjiaxu81192",
      "userHtmlUrl" : "https://github.com/hanjiaxu81192",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/155049087?v=4",
      "labels" : [ "kind/bug", "area/Config", "version/2.x", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "config_info_beta has been removed.\n\nhealth check SQL should be change to config_info_gray table", "Thanks for the clarification. \nTo confirm, will this be updated in a future release (e.g. by adjusting the health check SQL to use `config_info_gray` as you suggested), or should users patch this manually for now? \nJust trying to understand whether this will be officially fixed or needs manual intervention. \nThanks again! ", "It should be manual fix by user for now.\n\nNacos not depend ORM so do not do DDL for datasource.", "maybe i will do it???i make a test in my pc to solve this problem???if my solution is ok???i will make a pr to solve this problem.", "@wqyenjoy any process?", "> [@wqyenjoy](https://github.com/wqyenjoy) any process?\n\nthis is done.", "> [@wqyenjoy](https://github.com/wqyenjoy) any process?\n\nfirst 1.add config_info_beta in mysql init.sql\n second??? find all depend   config_info_beta code and remove all of those???\nso there wil be two pr. @KomachiSion " ],
      "repository" : {
        "description" : "an easy-to-use dynamic service discovery, configuration and service management platform for building AI cloud native applications.",
        "homepage" : "https://nacos.io",
        "name" : "nacos",
        "fullName" : "alibaba/nacos",
        "htmlUrl" : "https://github.com/alibaba/nacos",
        "gitUrl" : "git://github.com/alibaba/nacos.git",
        "sshUrl" : "git@github.com:alibaba/nacos.git",
        "cloneUrl" : "https://github.com/alibaba/nacos.git",
        "owner" : {
          "login" : "alibaba",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 13094,
        "stargazersCount" : 31743,
        "watchersCount" : 31743,
        "size" : 63250,
        "openIssuesCount" : 283,
        "subscribersCount" : 910,
        "pushedAt" : "2025-07-04T02:18:40Z",
        "languages" : {
          "TypeScript" : 4774,
          "Java" : 14900574,
          "Shell" : 15470,
          "Batchfile" : 6817,
          "SCSS" : 95019,
          "JavaScript" : 14316,
          "EJS" : 2645
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The provided mysql-schema.sql file in Nacos 2.5.1 is missing the creation statement for the config_info_beta table, leading to runtime side effects and false DB error logs",
      "validationOrRequirement" : "manual fix by user for now, no official fix planned",
      "attemptedFixes" : "PR to solve the problem, manual fix by user for now, test on personal PC",
      "otherNotes" : "config_info_beta has been removed, health check SQL should be changed to config_info_gray table, manual fix by user for now, no official fix planned",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284890
  }, {
    "issueDTO" : {
      "id" : 3038905063,
      "title" : "fix: Incorrect response received when providing space before invalid orgId",
      "url" : "https://github.com/credebl/platform/issues/1220",
      "repositoryName" : "credebl/platform",
      "description" : "**Description:**\nWhen a space is provided before an invalid OrgID during the 'Retrieve the details of the webhook URL for an organization' API call, the response returns a 500 Internal Server Error. The expected behavior is that the space should be automatically trimmed, and a 400 Bad Request response should be returned\n\n**Method** \n\nGET/v1/webhooks/orgs/webhookurl (Get Webhook URL Details)\n\n**Steps to Reproduce**\n1. Make an API call to the 'Retrieve the details of the webhook URL for an organization' endpoint, passing an 'orgId' parameter that includes a space before the invalid OrgID\n2. Observe the response.\n\n**Current behavior**\n\n{\n    \"statusCode\": 500,\n    \"message\": \"Something went wrong!\",\n    \"error\": \"Internal Server error\"\n}\n\n**Expected behavior**\n\nThe space in the OrgID should be automatically trimmed, and if the OrgID is invalid, a Bad Request error with a 400 status code should be returned\n{\n    \"statusCode\": 400,\n    \"message\": \"Please provide valid orgId\",\n    \"error\": \"Bad Request\"\n}\n\n**Screenshot**\n\n![Image](https://github.com/user-attachments/assets/21b8ffd1-f276-4651-b57b-ca2cb8ee2001)",
      "updatedAt" : 1752212508.000000000,
      "user" : "sayali-chavan2396",
      "userHtmlUrl" : "https://github.com/sayali-chavan2396",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/189986857?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey!  I noticed this issue wasn???t assigned, but it seemed straightforward so I went ahead and fixed it.\nPR is here: #1245 ??? happy to make changes if needed. ", "@kirti763 Assigned" ],
      "repository" : {
        "description" : "Open source, Open standards based Decentralised Identity & Verifiable Credentials Platform",
        "homepage" : "",
        "name" : "platform",
        "fullName" : "credebl/platform",
        "htmlUrl" : "https://github.com/credebl/platform",
        "gitUrl" : "git://github.com/credebl/platform.git",
        "sshUrl" : "git@github.com:credebl/platform.git",
        "cloneUrl" : "https://github.com/credebl/platform.git",
        "owner" : {
          "login" : "credebl",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 52,
        "stargazersCount" : 54,
        "watchersCount" : 54,
        "size" : 20032,
        "openIssuesCount" : 110,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-11T14:47:23Z",
        "languages" : {
          "TypeScript" : 1651864,
          "Shell" : 59104,
          "JavaScript" : 3459
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the incorrect response received when providing a space before an invalid orgId in the 'Retrieve the details of the webhook URL for an organization' API call.",
      "validationOrRequirement" : "The orgId should be provided without a space, and if the OrgID is invalid, a 400 Bad Request response should be returned.",
      "attemptedFixes" : "The issue was fixed by @sayali-chavan2396, no other attempts or blockers were mentioned.",
      "otherNotes" : "The issue was fixed by @sayali-chavan2396 and the PR is available at #1245.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284894
  }, {
    "issueDTO" : {
      "id" : 3088600536,
      "title" : "[Feature]: Add click-to-copy capability to trace ID display",
      "url" : "https://github.com/jaegertracing/jaeger-ui/issues/2813",
      "repositoryName" : "jaegertracing/jaeger-ui",
      "description" : "### Requirement\n\nAs a user I sometimes need to copy the trace ID into a clipboard, to paste it into search both in Jaeger or some other tools (like a log search).\n\n### Problem\n\nThe trace ID is usually not fully displayed by default, and sometimes not clickable\n\n<img width=\"394\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ed477996-ff05-4691-9894-8de68b9f6c0b\" />\n\n### Proposal\n\nTurn the trace ID display into a hyperlink that copies the full value into clipboard. The link should have a tooltip (with small delay, say 200ms) to show \"Copy to clipboard\", and when clicked the tooltip should change to \"Copied to clipboard\"  (for 2sec), then revert to original text.\n\n### Open questions\n\nOn the trace view the trace ID is currently in the header which is clickable to expand/collapse. As part of this change we may want to restrict that behavior only when clicking on the chevron button, but the trace name and trace ID should have click-to-copy behavior as above. We probably want to have a reusable component for ClickToCopyText.",
      "updatedAt" : 1752212272.000000000,
      "user" : "yurishkuro",
      "userHtmlUrl" : "https://github.com/yurishkuro",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3523016?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey, I'd be very happy to submit a PR for this issue!", "i have fixed this issue user can see copy to clipboard when hovered over trace id and paste it anywhere needed \n\n![Image](https://github.com/user-attachments/assets/c83962b7-a51a-4b3e-aaf9-a220436e7024)\n\nshould i make a pr on this?", "@yurishkuro Should I include it in this PR #2806 or work separately?", "@Darshit42 As you already resolved this, you can go ahead and raise a PR!", "i have raised a pr if there is anything else i can do please let me know i would be glad to do so @abhayporwals @yurishkuro ", "Hi! I'd love to work on this feature.\n\nI???ll add a click-to-copy functionality to the Trace ID display, so users can easily copy it to their clipboard. Please assign this to me ", "Is this issue still open? If not, I???d love to work on it???please feel free to assign it to me!", "@Darshit42 are you still working on this issue?" ],
      "repository" : {
        "description" : "Web UI for Jaeger",
        "homepage" : "http://jaegertracing.io/",
        "name" : "jaeger-ui",
        "fullName" : "jaegertracing/jaeger-ui",
        "htmlUrl" : "https://github.com/jaegertracing/jaeger-ui",
        "gitUrl" : "git://github.com/jaegertracing/jaeger-ui.git",
        "sshUrl" : "git@github.com:jaegertracing/jaeger-ui.git",
        "cloneUrl" : "https://github.com/jaegertracing/jaeger-ui.git",
        "owner" : {
          "login" : "jaegertracing",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 579,
        "stargazersCount" : 1293,
        "watchersCount" : 1293,
        "size" : 15773,
        "openIssuesCount" : 245,
        "subscribersCount" : 1015,
        "pushedAt" : "2025-07-10T01:48:40Z",
        "languages" : {
          "TypeScript" : 1064835,
          "CSS" : 149485,
          "Shell" : 2064,
          "Makefile" : 532,
          "JavaScript" : 1403176,
          "HTML" : 3046,
          "EJS" : 253
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a click-to-copy capability to the trace ID display, so users can easily copy the trace ID to their clipboard, the issue is related to the Jaeger UI and is labeled as help wanted, enhancement, and good first issue",
      "validationOrRequirement" : "The issue requires a click-to-copy capability to the trace ID display, the trace ID should be fully displayed by default, the link should have a tooltip with a delay, and the ability to copy and paste, the reusable component for ClickToCopyText should be used, the issue is related to the trace view and the click behavior should be restricted only when clicking on the chevron button",
      "attemptedFixes" : "One of the commenters has fixed the issue and can see the copy to clipboard functionality when hovered over the trace ID and can paste it anywhere needed, another commenter has raised a PR for the issue, and one more commenter has mentioned that they would be happy to work on the feature and add a click-to-copy functionality to the Trace ID display",
      "otherNotes" : "The issue is related to the trace ID display, it's not fully displayed by default and sometimes not clickable, there is an image attachment showing the current state, the proposed solution is to turn the trace ID display into a hyperlink that copies the full value into clipboard, the link should have a tooltip with a delay and the ability to copy and paste, there are also open questions about restricting the click behavior on the trace view, there is a reusable component for ClickToCopyText mentioned, the issue has been labeled as help wanted, enhancement, and good first issue, there are multiple comments discussing the issue and the proposed solution, including a PR raised by one of the commenters",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284905
  }, {
    "issueDTO" : {
      "id" : 3166936799,
      "title" : "Reset migrated status on migration object deletion",
      "url" : "https://github.com/platform9/vjailbreak/issues/621",
      "repositoryName" : "platform9/vjailbreak",
      "description" : "On explicit delete of Migration object assume its a conscious action to be able to re-run the migration of same VM. Assume user has deleted duplicate resources on target environment. To reset this, set the `vmwareMachine.status.migrated = false`",
      "updatedAt" : 1752212259.000000000,
      "user" : "OmkarDeshpande7",
      "userHtmlUrl" : "https://github.com/OmkarDeshpande7",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47773862?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p>Connected to <b><a href=\"https://huly.app/guest/vjailbreak?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHRyYSI6eyJsaW5rSWQiOiI2ODU4ZjNhMWIxMTRhZDkxZmE3ZTgwYzIiLCJndWVzdCI6InRydWUifSwiYWNjb3VudCI6ImI2OTk2MTIwLTQxNmYtNDljZC04NDFlLWU0YTVkMmU0OWM5YiIsIndvcmtzcGFjZSI6IjA0NDcyNDI2LWNhYTctNDZlMi05MDY0LWZjYTgwNDAwNmFjZCJ9.YTqV00BH1KrUwEIeHo5QyBxdRtBtN2Uvaw2oK-TmPvA\">Huly&reg;: VJAIL-626</a></b></p>" ],
      "repository" : {
        "description" : "Helping VMware users migrate to alternative Hypervisors",
        "homepage" : "https://platform9.github.io/vjailbreak/",
        "name" : "vjailbreak",
        "fullName" : "platform9/vjailbreak",
        "htmlUrl" : "https://github.com/platform9/vjailbreak",
        "gitUrl" : "git://github.com/platform9/vjailbreak.git",
        "sshUrl" : "git@github.com:platform9/vjailbreak.git",
        "cloneUrl" : "https://github.com/platform9/vjailbreak.git",
        "owner" : {
          "login" : "platform9",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 79,
        "watchersCount" : 79,
        "size" : 156524,
        "openIssuesCount" : 99,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T21:34:13Z",
        "languages" : {
          "TypeScript" : 592548,
          "HCL" : 2782,
          "Dockerfile" : 4291,
          "Shell" : 12238,
          "CSS" : 1343,
          "Makefile" : 16524,
          "JavaScript" : 1037,
          "Go" : 875679,
          "HTML" : 3940
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Reset migrated status on migration object deletion by setting `vmwareMachine.status.migrated = false`.",
      "validationOrRequirement" : "On explicit delete of Migration object assume its a conscious action to be able to re-run the migration of same VM.",
      "attemptedFixes" : "",
      "otherNotes" : "Assume user has deleted duplicate resources on target environment.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284908
  }, {
    "issueDTO" : {
      "id" : 3175556735,
      "title" : "Cant access to the app correctly",
      "url" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/issues/218",
      "repositoryName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
      "description" : "Hey guys, I've follow all steps for the installation of copilot studio kit, hovewer when I launch the app, the interface is incomplete (see in the picture below). Note that due tue company restrictions I'm in a developper environnment. When I'm in power app there is all the elements but when I run the app it disappear, making place for \"inconnu61\". Could you help me on this please ?\n\n![Image](https://github.com/user-attachments/assets/7f6656b5-f119-48d3-86e6-84f2aaa649b9)",
      "updatedAt" : 1752212218.000000000,
      "user" : "matcha972",
      "userHtmlUrl" : "https://github.com/matcha972",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/170604962?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @matcha972 ,\n\nTo resolve the incomplete interface issue, please try the following steps:\n\n- Reinstall the Copilot Studio Kit\nWe recommend reinstalling the kit directly from AppSource using the link below: [Download Copilot Studio Kit](http://aka.ms/DownloadCopilotStudioKit)\n\n- Review Data Loss Prevention (DLP) Policies\nSince you're working in a developer environment with company restrictions, please ensure that the required connectors are allowed in your environment???s DLP policies. You can find the list of necessary connectors and configuration guidance here: [DLP Configuration ??? Copilot Studio Kit](https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/blob/main/TECHDETAILS.md#connectors-used-for-dlp-configuration-purposes)\n\n- Confirm Prerequisites\nBefore reinstalling, please double-check that all prerequisites are met as outlined in the documentation to ensure a smooth setup.", "Thanks for your answer. However even after trying all those steps, I end up with the same result. I can confirm that the DLP configuration allows all types of connectors and that all the prerequisities are checked.", "Hi @matcha972 , To help us gather more context on the issue, could you please join the upcoming [Office-Hours ](https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/blob/main/OFFICEHOURS.md)call? Your input would be valuable in resolving this efficiently.", "Hi @matcha972 , I hope you joined our last Office-hour call and able to resolve the issue, can you please provide the update on the same? Thanks" ],
      "repository" : {
        "description" : null,
        "homepage" : "",
        "name" : "Power-CAT-Copilot-Studio-Kit",
        "fullName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
        "htmlUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit",
        "gitUrl" : "git://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "sshUrl" : "git@github.com:microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "cloneUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 180,
        "watchersCount" : 180,
        "size" : 48361,
        "openIssuesCount" : 27,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-09T12:45:38Z",
        "languages" : {
          "C#" : 24850,
          "CSS" : 4368,
          "JavaScript" : 33528,
          "HTML" : 16742
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The user is unable to access the app correctly due to an incomplete interface issue",
      "validationOrRequirement" : "The user's environment meets the prerequisites, and DLP policies allow all types of connectors.",
      "attemptedFixes" : "Reinstalling the Copilot Studio Kit, reviewing Data Loss Prevention (DLP) Policies, confirming prerequisites",
      "otherNotes" : "The user is experiencing an incomplete interface issue when launching the app, despite following installation steps. They have tried reinstalling the Copilot Studio Kit, reviewing Data Loss Prevention (DLP) Policies, and confirming prerequisites, but the issue persists.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284912
  }, {
    "issueDTO" : {
      "id" : 3086000381,
      "title" : "Logs: show total time taken by activities like block copy, v2v convertion etc.",
      "url" : "https://github.com/platform9/vjailbreak/issues/513",
      "repositoryName" : "platform9/vjailbreak",
      "description" : "### Is your feature request related to a problem? Please describe?\n\nAs a user, it would be good to see how much time each operation took.\n\n### Detailed Description\n\nMore specifically I can think of these being useful to come up with some estimates for an environment.\n\n- Time it took to do first block copy for a disk.\n- Time it took to do incremental block copy (for each disk, each iteration)\n- Time it took to convert the disk using virt-v2v-in-place.\n\nI guess events could help as well, but something in logs with exact time in minutes would be helpful.\n\n### Anything else you would like to add?\n\n_No response_",
      "updatedAt" : 1752212188.000000000,
      "user" : "bhavin192",
      "userHtmlUrl" : "https://github.com/bhavin192",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5154532?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p>Connected to <b><a href=\"https://huly.app/guest/vjailbreak?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJsaW5rSWQiOiI2ODMwNTRhNzRiMGMzYzJlZmYwMmUzZDAiLCJndWVzdCI6InRydWUiLCJlbWFpbCI6IiNndWVzdEBoYy5lbmdpbmVlcmluZyIsIndvcmtzcGFjZSI6InctdGFwYXMtdmphaWxicmVhay02N2E0M2EyZS0wODM3NDY1OGMxLWZiYzFmMyJ9.hFNGZGtH0XU_64ccSJ3IvbF0JTRRXECoRaOw3iRewMI\">Huly&reg;: VJAIL-504</a></b></p>", "@bhavin192 you expect this to be shown on UI ?", "As discussed during office hours, @jessicaralhan is picking up this one. " ],
      "repository" : {
        "description" : "Helping VMware users migrate to alternative Hypervisors",
        "homepage" : "https://platform9.github.io/vjailbreak/",
        "name" : "vjailbreak",
        "fullName" : "platform9/vjailbreak",
        "htmlUrl" : "https://github.com/platform9/vjailbreak",
        "gitUrl" : "git://github.com/platform9/vjailbreak.git",
        "sshUrl" : "git@github.com:platform9/vjailbreak.git",
        "cloneUrl" : "https://github.com/platform9/vjailbreak.git",
        "owner" : {
          "login" : "platform9",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 79,
        "watchersCount" : 79,
        "size" : 156524,
        "openIssuesCount" : 99,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T21:34:13Z",
        "languages" : {
          "TypeScript" : 592548,
          "HCL" : 2782,
          "Dockerfile" : 4291,
          "Shell" : 12238,
          "CSS" : 1343,
          "Makefile" : 16524,
          "JavaScript" : 1037,
          "Go" : 875679,
          "HTML" : 3940
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to show total time taken by activities like block copy, v2v conversion, etc. in the logs, which would be helpful for users to estimate time for an environment.",
      "validationOrRequirement" : "The issue does not mention any specific validation or requirement.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description or comments.",
      "otherNotes" : "As a user, it would be good to see how much time each operation took. More specifically, the issue is about showing total time taken by activities like block copy, v2v conversion, etc. in the logs. Events could also help, but something in logs with exact time in minutes would be helpful.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284917
  }, {
    "issueDTO" : {
      "id" : 3217922849,
      "title" : "[Improvement]  Building multiple AuditInfo objects alters previously built instances",
      "url" : "https://github.com/apache/gravitino/issues/7631",
      "repositoryName" : "apache/gravitino",
      "description" : "### What would you like to be improved?\n\nThis test (added to TestAuditInfo.java) will fail:\n```\n  @Test\n  public void testBuilderReuseDoesNotAffectBuiltInstance() {\n    AuditInfo.Builder builder = AuditInfo.builder().withCreator(\"first\");\n    AuditInfo first = builder.build();\n    builder.withCreator(\"second\");\n    AuditInfo second = builder.build();\n\n    Assertions.assertEquals(\"first\", first.creator());\n    Assertions.assertEquals(\"second\", second.creator());\n  }\n```\n\n### How should we improve?\n\nCreate a new AuditInfo instance during the build call.",
      "updatedAt" : 1752211521.000000000,
      "user" : "justinmclean",
      "userHtmlUrl" : "https://github.com/justinmclean",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/144504?v=4",
      "labels" : [ "improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I can take this up" ],
      "repository" : {
        "description" : "World's most powerful open data catalog for building a high-performance, geo-distributed and federated metadata lake.",
        "homepage" : "https://gravitino.apache.org",
        "name" : "gravitino",
        "fullName" : "apache/gravitino",
        "htmlUrl" : "https://github.com/apache/gravitino",
        "gitUrl" : "git://github.com/apache/gravitino.git",
        "sshUrl" : "git@github.com:apache/gravitino.git",
        "cloneUrl" : "https://github.com/apache/gravitino.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 530,
        "stargazersCount" : 1693,
        "watchersCount" : 1693,
        "size" : 61834,
        "openIssuesCount" : 721,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-11T12:29:22Z",
        "languages" : {
          "Smarty" : 5095,
          "TypeScript" : 1191,
          "Java" : 14734465,
          "Dockerfile" : 26062,
          "Shell" : 184089,
          "CSS" : 937,
          "Rust" : 206295,
          "Batchfile" : 1647,
          "Makefile" : 3325,
          "JavaScript" : 511804,
          "Python" : 1191811
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve the AuditInfo builder to not alter previously built instances",
      "validationOrRequirement" : "Create a new instance during build call, test should pass with this fix",
      "attemptedFixes" : "Create a new AuditInfo instance during the build call",
      "otherNotes" : "This test will fail because building multiple AuditInfo objects alters previously built instances, and the creator is not reset",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284920
  }, {
    "issueDTO" : {
      "id" : 3217964108,
      "title" : "[Improvement] Potential NullPointerException in ConfigEntry.seqToStr",
      "url" : "https://github.com/apache/gravitino/issues/7634",
      "repositoryName" : "apache/gravitino",
      "description" : "### What would you like to be improved?\n\nAdding this test to core/src/test/java/org/apache/gravitino/config/TestConfigEntryList.java fails:\n\n```\n  @Test\n  public void testSeqToStrWithNullElement() {\n    ConfigEntry<List<Integer>> testConf =\n        new ConfigBuilder(\"gravitino.seq.null\")\n            .intConf()\n            .toSequence()\n            .createWithDefault(Lists.newArrayList());\n\n    Assertions.assertDoesNotThrow(\n        () -> testConf.writeTo(configMapEmpty, Lists.newArrayList(1, null, 2)));\n    Assertions.assertEquals(\"1,2\", configMapEmpty.get(\"gravitino.seq.null\"));\n  }\n```\n\n### How should we improve?\n\nFilter out nulls",
      "updatedAt" : 1752211510.000000000,
      "user" : "justinmclean",
      "userHtmlUrl" : "https://github.com/justinmclean",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/144504?v=4",
      "labels" : [ "improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I can take this up" ],
      "repository" : {
        "description" : "World's most powerful open data catalog for building a high-performance, geo-distributed and federated metadata lake.",
        "homepage" : "https://gravitino.apache.org",
        "name" : "gravitino",
        "fullName" : "apache/gravitino",
        "htmlUrl" : "https://github.com/apache/gravitino",
        "gitUrl" : "git://github.com/apache/gravitino.git",
        "sshUrl" : "git@github.com:apache/gravitino.git",
        "cloneUrl" : "https://github.com/apache/gravitino.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 530,
        "stargazersCount" : 1693,
        "watchersCount" : 1693,
        "size" : 61834,
        "openIssuesCount" : 721,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-11T12:29:22Z",
        "languages" : {
          "Smarty" : 5095,
          "TypeScript" : 1191,
          "Java" : 14734465,
          "Dockerfile" : 26062,
          "Shell" : 184089,
          "CSS" : 937,
          "Rust" : 206295,
          "Batchfile" : 1647,
          "Makefile" : 3325,
          "JavaScript" : 511804,
          "Python" : 1191811
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Potential NullPointerException in ConfigEntry.seqToStr",
      "validationOrRequirement" : "improvement, good first issue",
      "attemptedFixes" : "Filter out nulls",
      "otherNotes" : "Filter out nulls, adding test to core/src/test/java/org/apache/gravitino/config/TestConfigEntryList.java",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284923
  }, {
    "issueDTO" : {
      "id" : 2589299677,
      "title" : "Show traits in a special list on item popups",
      "url" : "https://github.com/DestinyItemManager/DIM/issues/10757",
      "repositoryName" : "DestinyItemManager/DIM",
      "description" : "Official \"traits\" (like amplify, radiance, etc) are more important to gameplay now - we should show them in the item popup in their own section.",
      "updatedAt" : 1752210892.000000000,
      "user" : "bhollis",
      "userHtmlUrl" : "https://github.com/bhollis",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/313208?v=4",
      "labels" : [ "Good First Issue", "Feature: Item Details Popup" ],
      "state" : "OPEN",
      "comments" : [ "Linking #9157 " ],
      "repository" : {
        "description" : "Destiny Item Manager",
        "homepage" : "https://destinyitemmanager.com",
        "name" : "DIM",
        "fullName" : "DestinyItemManager/DIM",
        "htmlUrl" : "https://github.com/DestinyItemManager/DIM",
        "gitUrl" : "git://github.com/DestinyItemManager/DIM.git",
        "sshUrl" : "git@github.com:DestinyItemManager/DIM.git",
        "cloneUrl" : "https://github.com/DestinyItemManager/DIM.git",
        "owner" : {
          "login" : "DestinyItemManager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 643,
        "stargazersCount" : 2094,
        "watchersCount" : 2094,
        "size" : 469540,
        "openIssuesCount" : 154,
        "subscribersCount" : 60,
        "pushedAt" : "2025-07-11T06:15:37Z",
        "languages" : {
          "TypeScript" : 3962567,
          "Shell" : 2430,
          "SCSS" : 345507,
          "JavaScript" : 45441,
          "PHP" : 1674,
          "HTML" : 5588
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Show official 'traits' (like amplify, radiance, etc) in the item popup in their own section",
      "validationOrRequirement" : "Show traits in a special list on item popups",
      "attemptedFixes" : "",
      "otherNotes" : "Linking #9157",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284925
  }, {
    "issueDTO" : {
      "id" : 3195937331,
      "title" : "Introduce a meta scan function for inspecting table column size",
      "url" : "https://github.com/StarRocks/starrocks/issues/60535",
      "repositoryName" : "StarRocks/starrocks",
      "description" : "<!-- (At least include the following, feel free to add if you have more content) -->\n\n## Feature request\n\nStarRocks support several functions to inspect the metadata of segment files:\n```sql\nselect count(id) from t1 [_META_];\nselect min(id) from t1 [_META_];\nselect max(id) from t1 [_META_];\nselect flat_json_meta(payload) from t1 [_META_];\n```\n\nEssentially it generates a `META_SCAN` operator to scan the metadata of underlying segment files, then aggregate the result with `count/min/max` functions.\n\nWe can leverage this mechanism to inspect the column size of a table, for example:\n\n```sql\n-- decompressed size\nselect column_size(id) from t1 [_META_];\n-- compressed size\nselect column_compressed_size(id) from t1 [_META_];\n```\n\nThere are several types of column sizes:  \n- **Uncompressed Size**: Stored in the `ColumnMetaPB` located in the segment footer.  \n- **Compressed Size**: Represents the on-disk size. While it is not explicitly stored in the footer, it can be estimated by analyzing the number of pages via the `OrdinalIndex` and calculating the average page size.  \n\nIt might be worthwhile to include a few functions for inspecting a column's metadata.\n\nFurther more, we can also consider add these column stats into the optimizer statistics system, stored in the `_statistics_.column_statistics` table.\n\n",
      "updatedAt" : 1752210468.000000000,
      "user" : "murphyatwork",
      "userHtmlUrl" : "https://github.com/murphyatwork",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/96611012?v=4",
      "labels" : [ "type/feature-request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@murphyatwork , I'm interseted, could you kindly assign me this task." ],
      "repository" : {
        "description" : "The world's fastest open query engine for sub-second analytics both on and off the data lakehouse. With the flexibility to support nearly any scenario, StarRocks provides best-in-class performance for multi-dimensional analytics, real-time analytics, and ad-hoc queries. A Linux Foundation project.",
        "homepage" : "https://starrocks.io",
        "name" : "starrocks",
        "fullName" : "StarRocks/starrocks",
        "htmlUrl" : "https://github.com/StarRocks/starrocks",
        "gitUrl" : "git://github.com/StarRocks/starrocks.git",
        "sshUrl" : "git@github.com:StarRocks/starrocks.git",
        "cloneUrl" : "https://github.com/StarRocks/starrocks.git",
        "owner" : {
          "login" : "StarRocks",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2049,
        "stargazersCount" : 10286,
        "watchersCount" : 10286,
        "size" : 519040,
        "openIssuesCount" : 883,
        "subscribersCount" : 189,
        "pushedAt" : "2025-07-11T16:04:21Z",
        "languages" : {
          "Java" : 48845697,
          "Yacc" : 4182,
          "C++" : 38090964,
          "CSS" : 6187,
          "C" : 342966,
          "CMake" : 205202,
          "Makefile" : 7808,
          "Mustache" : 959,
          "HTML" : 26561,
          "Dockerfile" : 32672,
          "Shell" : 161209,
          "ANTLR" : 102431,
          "Linker Script" : 44,
          "JavaScript" : 10136,
          "Lex" : 1752,
          "Python" : 488473,
          "Thrift" : 319175
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Introduce a meta scan function for inspecting table column size, including uncompressed and compressed sizes",
      "validationOrRequirement" : "Include a few functions for inspecting a column's metadata, consider adding these column stats into the optimizer statistics system",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "The issue is about introducing a meta scan function for inspecting table column size, including uncompressed and compressed sizes, and potentially adding these column stats into the optimizer statistics system.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284928
  }, {
    "issueDTO" : {
      "id" : 3022299753,
      "title" : "blog link needed at drop down menu",
      "url" : "https://github.com/oppia/oppia/issues/22560",
      "repositoryName" : "oppia/oppia",
      "description" : "### Is your feature request related to a problem? Please describe.\n\nhttps://github.com/user-attachments/assets/39c3a1e8-57b4-4705-b968-f26a34c22a31\n\n### Describe the solution (or solutions) you'd like\n\nI suggest to add link of blog in about dropdown\nhttps://github.com/user-attachments/assets/c467462d-463a-46bb-9728-f28f821838a6\n\n### Describe alternatives you've considered and rejected\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752210214.000000000,
      "user" : "kanupriya-GuptaM",
      "userHtmlUrl" : "https://github.com/kanupriya-GuptaM",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/143825650?v=4",
      "labels" : [ "Impact: Medium", "enhancement", "target: Q2 2025", "good first issue", "Work: Low" ],
      "state" : "OPEN",
      "comments" : [ "Hi @seanlip,\n\nAs instructed, I attempted to resolve the problem as well as the parent problem. If the result meets your expectations, do let me know so I can create a Pull Request. Thank you!\n\nSummary of changes:\n\nIn top-navigation-bar.component.html I added\n\n<li class=\"nav-item\">\n    <a class=\"dropdown-item nav-link oppia-navbar-tab-content about-link e2e-test-navbar-about-menu-blog-button\"\n           (click)=\"navigateToBlogPage()\"\n             (keydown)=\"onMenuKeypress($event, 'aboutMenu', {enter: ACTION_CLOSE})\"\n                 rel=\"noopener\">\n                <span class=\"link\">\n                {{'I18N_TOPNAV_BLOG' | translate}}\n         </span>\n     </a>\n</li>\n\nIn top-navigation-bar.component.ts I added\n\n\n  navigateToBlogPage(): void {\n    this.siteAnalyticsService.registerClickNavbarButtonEvent(\n      NavbarAndFooterGATrackingPages.BLOG\n    );\n    this.windowRef.nativeWindow.location.href = '/blog';\n  }\n\nIn logged-out-user.ts I added\n\nconst navbarAboutTabBlogButton = 'a.e2e-test-navbar-about-menu-blog-button';\n\n  /**\n   * Function to click the Blog button in the About Menu on navbar\n   * and check if it opens the Blog page.\n   */\n  async clickBlogButtonInAboutMenuOnNavbar(): Promise<void> {\n    if (this.isViewportAtMobileWidth()) {\n      await this.clickOn(mobileNavbarOpenSidebarButton);\n      await this.clickOn(mobileSidebarExpandAboutMenuButton);\n      await this.clickButtonToNavigateToNewPage(\n        mobileSidebarTeachButton,\n        'Blog button in the About Menu on mobile sidebar',\n        teachUrl,\n        'Blog'\n      );\n    } else {\n      await this.clickOn(navbarAboutTab);\n      await this.clickButtonToNavigateToNewPage(\n        navbarAboutTabBlogButton,\n        'Blog button in the About Menu on navbar',\n        teachUrl,\n        'Blog'\n      );\n    }\n  }\n\nIn app-constants.ts I added\n\nexport enum NavbarAndFooterGATrackingPages {\n  ABOUT = 'About',\n  VOLUNTEER = 'Volunteer',\n  TEACH = 'Teach',\n  DONATE = 'Donate',\n  BLOG = 'Blog' // added constant\n}\n\nIn en.json added\n\n\"I18N_TOPNAV_BLOG\": \"Blog\",\n\"I18N_TOPNAV_BLOG_WITH_OPPIA\": \"Blog with Oppia\",\n\nhttps://github.com/user-attachments/assets/0821b21f-d7c7-40c4-81c5-ac1880e14bdd\n\n", "@TejasSaraf Seems reasonable, thanks, I assigned you. One question though, what do you mean by the \"parent problem\"?", "@Kanupriyaoppia mentioned about parent feature #22515 which also I tried to solve.", "Hi,I am a new contributor.I'd like to work on this issue -could you please assign it to me? I'll do my best to implement a good solution.", "Hi @TejasSaraf, it looks like you have been assigned to this issue for 7 days, but have not created a PR yet.\n\n If you are still planning to work on this issue, please open a PR within the next 3 days and submit it for review, making sure that it is linked to this issue in the Development sidebar of the PR. Otherwise, please unassign yourself from this issue so that someone else can take it up.\n\n Also, if you are stuck, please let us know, so that we can help you. Thanks!", "Hi @TejasSaraf, it looks like you have been assigned to this issue for 7 days, but have not created a PR yet.\n\n If you are still planning to work on this issue, please open a PR within the next 3 days and submit it for review, making sure that it is linked to this issue in the Development sidebar of the PR. Otherwise, please unassign yourself from this issue so that someone else can take it up.\n\n Also, if you are stuck, please let us know, so that we can help you. Thanks!", "Hi! I'm Yash, a beginner in open source, and this issue looks great to get started with. I'd love to work on it ??? could you please assign it to me? \uD83D\uDE0A\n", "i am beginner to open source, if this issue is not closed ,could you plesae assign it to me?", "Hi mentors! I'm a GSoC 2025 aspirant with skills in Python, Firebase, and web development. I'd love to contribute to this issue and have my local Oppia setup ready. I???ve already reviewed the navbar code and can make this enhancement quickly and efficiently. Please assign it to me. Thank you!\n", "Hii!! I am beginner in open source contribution and I think this issue is perfect for beginner like me to try and resolve it. So, I kindly request you please assign me this issue.", "Hi, I???m a beginner and would love to contribute to this issue. Based on my understanding, there are two points to address:\n\n1. **Home navigation issue**: After logging in, the current behavior redirects to `/contributor-dashboard`, which is expected for a contributor. However, clicking the **Home** button also takes you back to `/contributor-dashboard` instead of the site???s homepage (`oppiatestserver.org`).  \n   *Initial thought:* The navigation might be hardcoded for contributors or tied to role-based logic.  \n   *Suggested fix:* If it's hardcoded, update the Home link to always direct to `oppiatestserver.org`. If it's role-based, consider making the destination consistent regardless of role.\n\n2. **Accessing the blog page**: At the moment, the blog is only accessible by navigating through **About > Parents/Teachers** and scrolling to the bottom o the Footer.  \n   *Suggested improvement:* Add a direct ???Blog??? link to the ???About??? dropdown for better visibility and user experience.\n\nPlease let me know if you have any suggestions or feedback. I???d be happy to work on this???could you kindly assign the issue to me?\n\nThank you!", "Hey @pavansundar9, Thanks a lot for showing your interest in contributing to this issue. This issue is already assigned to a contributor, and PR for the fix is on. If he is not able to merge it soon, we will close that PR and assign this issue to you. Meanwhile, you can check other issues here: https://github.com/oppia/oppia/issues?q=state%3Aopen%20label%3A%22good%20first%20issue%22. Thanks!\n\nMy recommendation:\n- You can work on https://github.com/oppia/oppia/issues/10700 issue, it is a really easy one and less time-consuming.", "Unassigning @TejasSaraf due to inactivity.", "Hi! I???d like to work on this. Please assign it to me.", "@VirenPassi  Per the guidance at https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#choosing-a-good-first-issue, please provide an explanation of what your PR will do (with names of files you're changing, what you plan to change in each file, etc.). If it looks good, we can assign you to this issue.\n\nPlease also follow the other instructions on that wiki page if you have not yet done so. Thanks!", "Hi @HardikGoyal2003, @seanlip \uD83D\uDC4B\n\nThanks for the guidance! Here???s a quick outline of how I plan to implement the fix for adding the Blog link in the About dropdown of the top navigation bar:\n\n Planned Approach\n1) top-navigation-bar.component.html\n    Add a new list item under the About dropdown that says Blog. When clicked, it will call a method to handle the redirection.\n\n2) top-navigation-bar.component.ts\n    Define a new navigateToBlogPage() method that:\n\n   Tracks the click using siteAnalyticsService.registerClickNavbarButtonEvent.\n\n    Redirects the user to the /blog route using windowRef.nativeWindow.location.href.\n\n3) app-constants.ts\n    Add a BLOG entry to the NavbarAndFooterGATrackingPages enum.\n\n4) en.json\n    Add the text \"Blog\" under a new translation key so it can be displayed in the UI.\n\n5)  (Optional): Add or update any e2e test to verify the blog link appears and navigates correctly.\n\n    Let me know if this approach looks good, and I???ll get started on the implementation right away!\n\nThanks again!\n??? @VirenPassi\n\n\n\n", "@VirenPassi Sounds good, assigning it to you. Thanks!", "Assign me for blog link needed at drop down menu #22560\n", "Hey @soham20008 This issue is already assigned, you can take any other issue from this https://github.com/oppia/oppia/labels/good%20first%20issue. Thanks!!" ],
      "repository" : {
        "description" : "A free, online learning platform to make quality education accessible for all.",
        "homepage" : "https://www.oppia.org",
        "name" : "oppia",
        "fullName" : "oppia/oppia",
        "htmlUrl" : "https://github.com/oppia/oppia",
        "gitUrl" : "git://github.com/oppia/oppia.git",
        "sshUrl" : "git@github.com:oppia/oppia.git",
        "cloneUrl" : "https://github.com/oppia/oppia.git",
        "owner" : {
          "login" : "oppia",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : false,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4617,
        "stargazersCount" : 6095,
        "watchersCount" : 6095,
        "size" : 325356,
        "openIssuesCount" : 1592,
        "subscribersCount" : 242,
        "pushedAt" : "2025-07-11T21:37:24Z",
        "languages" : {
          "TypeScript" : 18820223,
          "CSS" : 612715,
          "Shell" : 20235,
          "PEG.js" : 71377,
          "Makefile" : 13374,
          "JavaScript" : 1193315,
          "HTML" : 2483601,
          "Python" : 20251875
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add a link to the blog in the about dropdown menu.",
      "validationOrRequirement" : "The issue requires the ability to add a link to the blog in the about dropdown menu. The link should be accessible and functional.",
      "attemptedFixes" : "Several contributors have attempted to resolve the issue, including @TejasSaraf, @Kanupriyaoppia, @Yash, @pavansundar9, @VirenPassi, and @HardikGoyal2003. The suggested fix from @VirenPassi involves adding a new list item under the About dropdown that says Blog, defining a new navigateToBlogPage() method, adding a BLOG entry to the NavbarAndFooterGATrackingPages enum, and adding the text \"Blog\" under a new translation key.",
      "otherNotes" : "This issue is about adding a link to the blog in the about dropdown menu. There are several comments and attempts to resolve the issue, including a suggested fix from @VirenPassi. The issue has been assigned to multiple contributors, including @TejasSaraf, @Kanupriyaoppia, @Yash, @pavansundar9, @VirenPassi, and @HardikGoyal2003.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284937
  }, {
    "issueDTO" : {
      "id" : 2232980038,
      "title" : "Export weapon rolls as human-readable text",
      "url" : "https://github.com/DestinyItemManager/DIM/issues/10317",
      "repositoryName" : "DestinyItemManager/DIM",
      "description" : "### Proposed change\n\nAdd a button to export a weapon roll from the Armory screen in the following format:\n\n[Weapon Name]      \n\n\n * Intrinsic Perk / Frame (Archetype)\n * Sights / Barrel Mods       \n * First Perk Column      \n * Second Perk Column      \n * Third Perk Column \n * Fourth Perk Column\n\n * Masterwork (If applicable) \n\n### How does this fit into your workflow?\n\nThis is the format needed for /r/sharditkeepit or its handy for other applications that require sharing weapon rolls (and dont allow screenshots)",
      "updatedAt" : 1752209460.000000000,
      "user" : "Revadike",
      "userHtmlUrl" : "https://github.com/Revadike",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4411977?v=4",
      "labels" : [ "Good First Issue", "Feature: Armory", "Enhancement" ],
      "state" : "OPEN",
      "comments" : [ "Do any of the sites we link to from the armory page allow this?", "In retrospect the Armory isn't a great place to put this - it doesn't know the full roll of the original item, only the currently selected plugs. This would be better triggered from the item itself, maybe by hooking Ctrl-C when the popup is up." ],
      "repository" : {
        "description" : "Destiny Item Manager",
        "homepage" : "https://destinyitemmanager.com",
        "name" : "DIM",
        "fullName" : "DestinyItemManager/DIM",
        "htmlUrl" : "https://github.com/DestinyItemManager/DIM",
        "gitUrl" : "git://github.com/DestinyItemManager/DIM.git",
        "sshUrl" : "git@github.com:DestinyItemManager/DIM.git",
        "cloneUrl" : "https://github.com/DestinyItemManager/DIM.git",
        "owner" : {
          "login" : "DestinyItemManager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 643,
        "stargazersCount" : 2094,
        "watchersCount" : 2094,
        "size" : 469540,
        "openIssuesCount" : 154,
        "subscribersCount" : 60,
        "pushedAt" : "2025-07-11T06:15:37Z",
        "languages" : {
          "TypeScript" : 3962567,
          "Shell" : 2430,
          "SCSS" : 345507,
          "JavaScript" : 45441,
          "PHP" : 1674,
          "HTML" : 5588
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a button to export a weapon roll from the Armory screen in a human-readable format",
      "validationOrRequirement" : "The format of the exported text should be [Weapon Name] with the required columns",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is about exporting weapon rolls as human-readable text from the Armory screen. The format required is [Weapon Name] with different columns for Intrinsic Perk, Sights, Barrel Mods, etc. The Armory is not the ideal place for this feature as it only knows the currently selected plugs, not the full roll of the original item. A better approach would be to trigger this feature from the item itself, possibly by hooking Ctrl-C when the popup is up.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284943
  }, {
    "issueDTO" : {
      "id" : 2726255783,
      "title" : "Saving a video fails (and try to save a PDF)",
      "url" : "https://github.com/kiwix/kiwix-desktop/issues/1274",
      "repositoryName" : "kiwix/kiwix-desktop",
      "description" : "This is what I get with right click on the video and then click \"save as\" in the context menu\n![Image](https://github.com/user-attachments/assets/0c72e32a-4ae2-4d05-8a91-b73e509b94e8)\n\nI should not save the video as PDF",
      "updatedAt" : 1752209295.000000000,
      "user" : "kelson42",
      "userHtmlUrl" : "https://github.com/kelson42",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1029718?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "The context menu within the page is not context dependent - you get the same menu wherever you right-click on the page. Thus the \"Save As...\" applies to the entire page/document rather than the video under the cursor.", "I understand. Thank you for the explanation. We have here a massive usability issue. This context menu should allow to save each item of the page.. and we should keep \"save article as... \" in ![Image](https://github.com/user-attachments/assets/c3d7a217-dbaf-439b-801e-3bda4e2428af)\n" ],
      "repository" : {
        "description" : "Kiwix for Windows and GNU/Linux desktops",
        "homepage" : "https://download.kiwix.org/release/kiwix-desktop/",
        "name" : "kiwix-desktop",
        "fullName" : "kiwix/kiwix-desktop",
        "htmlUrl" : "https://github.com/kiwix/kiwix-desktop",
        "gitUrl" : "git://github.com/kiwix/kiwix-desktop.git",
        "sshUrl" : "git@github.com:kiwix/kiwix-desktop.git",
        "cloneUrl" : "https://github.com/kiwix/kiwix-desktop.git",
        "owner" : {
          "login" : "kiwix",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 132,
        "stargazersCount" : 927,
        "watchersCount" : 927,
        "size" : 8512,
        "openIssuesCount" : 88,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-10T12:07:53Z",
        "languages" : {
          "C++" : 409986,
          "CSS" : 16571,
          "C" : 92,
          "QMake" : 9858,
          "JavaScript" : 1612,
          "HTML" : 1626,
          "Python" : 3803
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Saving a video fails, and attempting to save a PDF is also not allowed, due to a usability issue with the context menu",
      "validationOrRequirement" : "The issue requires the context menu to allow saving each item of the page, rather than the entire page/document.",
      "attemptedFixes" : "None mentioned in the comments",
      "otherNotes" : "The context menu within the page is not context-dependent, allowing 'Save As...' to apply to the entire page/document rather than the selected item. This is a massive usability issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284946
  }, {
    "issueDTO" : {
      "id" : 3217229635,
      "title" : "[Feature]: Use `QuantFp8` `CustomOp`-abstraction for MoE layers",
      "url" : "https://github.com/vllm-project/vllm/issues/20711",
      "repositoryName" : "vllm-project/vllm",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\n#19830 added `QuantFp8`, which uses the `CustomOp` abstraction to implement fp8 quantization in both CUDA and torch, allowing Inductor to achieve superior performance over the CUDA ops (which are unoptimized and also do not fuse by default). However, the class has to be instantiated during init, and MoE uses are currently in util free functions many levels deep. Those need to be mildly rearchitected to take advantage of the new abstraction.\n\nThe use to be rearchitected is here: https://github.com/vllm-project/vllm/blob/c7a00e6e6716f45db09e39cb21a8f91f741f10b9/vllm/model_executor/layers/fused_moe/utils.py#L37-L40\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### Before submitting a new issue...\n\n- [x] Make sure you already searched for relevant issues, and asked the chatbot living at the bottom right corner of the [documentation page](https://docs.vllm.ai/en/latest/), which can answer lots of frequently asked questions.",
      "updatedAt" : 1752209212.000000000,
      "user" : "ProExpertProg",
      "userHtmlUrl" : "https://github.com/ProExpertProg",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11367180?v=4",
      "labels" : [ "feature request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@ProExpertProg Claimed", "@kiscad amazing, let me know if you have any questions!", "Hey @kiscad, I would like to contribute\nLet me know if you need any help!", "No problem~" ],
      "repository" : {
        "description" : "A high-throughput and memory-efficient inference and serving engine for LLMs",
        "homepage" : "https://docs.vllm.ai",
        "name" : "vllm",
        "fullName" : "vllm-project/vllm",
        "htmlUrl" : "https://github.com/vllm-project/vllm",
        "gitUrl" : "git://github.com/vllm-project/vllm.git",
        "sshUrl" : "git@github.com:vllm-project/vllm.git",
        "cloneUrl" : "https://github.com/vllm-project/vllm.git",
        "owner" : {
          "login" : "vllm-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 8651,
        "stargazersCount" : 52023,
        "watchersCount" : 52023,
        "size" : 63661,
        "openIssuesCount" : 2623,
        "subscribersCount" : 401,
        "pushedAt" : "2025-07-11T22:02:44Z",
        "languages" : {
          "Dockerfile" : 23171,
          "C++" : 880113,
          "Shell" : 134598,
          "Jinja" : 1650,
          "C" : 92083,
          "CMake" : 68040,
          "Python" : 17099448,
          "Cuda" : 1759079
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Use `QuantFp8` `CustomOp`-abstraction for MoE layers to achieve superior performance over the CUDA ops",
      "validationOrRequirement" : "The class has to be instantiated during init, and MoE uses are currently in util free functions many levels deep. Those need to be mildly rearchitected to take advantage of the new abstraction.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The feature, motivation and pitch are provided in the description, and alternatives, additional context, and before submitting a new issue are also mentioned. The issue is a feature request and a good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284951
  }, {
    "issueDTO" : {
      "id" : 3124641273,
      "title" : "Add `no-descending-specificity` line number to the referenced selector in message",
      "url" : "https://github.com/stylelint/stylelint/issues/8608",
      "repositoryName" : "stylelint/stylelint",
      "description" : "### What is the problem you're trying to solve?\n\nAs an example, #8567 generates the following error. \n\n> 12:3-4 error Expected selector \"a\" to come before selector \"nav a:hover\" [(no-descending-specificity)](https://stylelint.io/user-guide/rules/no-descending-specificity)\n\n![Image](https://github.com/user-attachments/assets/9550dd42-9a20-4f34-9c72-c8d0ad4a3ce8)\n\n### What solution would you like to see?\n\nIf possible, it would be greatly beneficial _(especially in a large file)_ to have a line number for `\"nav a:hover\"`.",
      "updatedAt" : 1752208869.000000000,
      "user" : "erosman",
      "userHtmlUrl" : "https://github.com/erosman",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6458876?v=4",
      "labels" : [ "status: wip", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@erosman Thanks for the request and for using the template.\n\nIt seems like a good idea. We do something similar for `no-duplicate-selectors`:\n\nhttps://github.com/stylelint/stylelint/blob/a57d512dd5f79815a43e996a182b5e2a8154e363/lib/rules/no-duplicate-selectors/index.mjs#L19-L22\n\nLet's add an \", at line xxx\" to the message.\n\nI've labelled the issue as ready to implement. Please consider [contributing](https://stylelint.io/contributing) if you have time.", "Hi! I saw that the issue was still open too =) so I???d like to work on this, let me know if that???s okay @jeddy3" ],
      "repository" : {
        "description" : "A mighty CSS linter that helps you avoid errors and enforce conventions.",
        "homepage" : "https://stylelint.io",
        "name" : "stylelint",
        "fullName" : "stylelint/stylelint",
        "htmlUrl" : "https://github.com/stylelint/stylelint",
        "gitUrl" : "git://github.com/stylelint/stylelint.git",
        "sshUrl" : "git@github.com:stylelint/stylelint.git",
        "cloneUrl" : "https://github.com/stylelint/stylelint.git",
        "owner" : {
          "login" : "stylelint",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 971,
        "stargazersCount" : 11292,
        "watchersCount" : 11292,
        "size" : 35449,
        "openIssuesCount" : 173,
        "subscribersCount" : 97,
        "pushedAt" : "2025-07-09T10:12:39Z",
        "languages" : {
          "TypeScript" : 5016,
          "CSS" : 15326,
          "Shell" : 547,
          "SCSS" : 2554,
          "JavaScript" : 2395466,
          "HTML" : 697,
          "Less" : 4
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add `no-descending-specificity` line number to the referenced selector in message",
      "validationOrRequirement" : "Add a line number to the referenced selector in the message, especially beneficial in large files.",
      "attemptedFixes" : "The author has labelled the issue as ready to implement, and a contributor is willing to work on it.",
      "otherNotes" : "The issue is related to adding a line number for the referenced selector in the message, similar to the no-duplicate-selectors rule. A link to the no-duplicate-selectors rule is provided for reference.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284955
  }, {
    "issueDTO" : {
      "id" : 3038799456,
      "title" : "fix: Successful response received when creating shortening url with empty 'attributes'",
      "url" : "https://github.com/credebl/platform/issues/1219",
      "repositoryName" : "credebl/platform",
      "description" : "**Description**\nWhen attempting to create a shortening URL with an empty 'attributes' array, the API returns a 201 status code with a success message. However, the expected behavior is to return a 400 status code with a 'Bad Request' error\n\n**Method**\nPOST/v1/utilities (Create Shortening URL)\n**Request**\n{\n    \"credentialId\": \"2a996b48-be02-4253-b6f8-2d43f1b60fe5\",\n    \"schemaId\": \"CiDFmTQrv7iZzih6mFXn3v:2:Employee Id Card:321.21\",\n    \"credDefId\": \"CiDFmTQrv7iZzih6mFXn3v:3:CL:65132:TechSphere  Employee Id Card\",\n    \"invitationUrl\": \"string\",\n    \"attributes\": []\n}\n\n**Steps to Reproduce:**\n\n1. Send a request to create a shortening URL for the provided details\n2. Observe the response\n\n**Current behavior**\n{\n  \"statusCode\": 201,\n  \"message\": \"Shortening Url created successfully\"\n}\n\n**Expected behavior**\n{\n    \"statusCode\": 400,\n    \"message\": \"attributes should not be empty\",\n    \"error\": \"Bad request\"\n}",
      "updatedAt" : 1752208833.000000000,
      "user" : "sayali-chavan2396",
      "userHtmlUrl" : "https://github.com/sayali-chavan2396",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/189986857?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey there! This issue looks interesting???I'd be happy to take it on. Let me know if it's not already being worked on.", "Hello @hashirjamal \nThank you for your interest.\nSure, you can start working on the issue, can you create a draft PR so that I can assign this to you?", "> Hello [@hashirjamal](https://github.com/hashirjamal) Thank you for your interest. Sure, you can start working on the issue, can you create a draft PR so that I can assign this to you?\n\nHello @GHkrishna thanks for your reply, here is my draft [PR](https://github.com/credebl/platform/pull/1224)", "Unassigned due to inactivity", "Hi,\nI would like to work on this issue!", "Hi,\nI would like to work on this issue!\n\n@sayali-chavan2396 ", "Sure, you can start working on the issue and inform here, if initiated, so other contributors are aware" ],
      "repository" : {
        "description" : "Open source, Open standards based Decentralised Identity & Verifiable Credentials Platform",
        "homepage" : "",
        "name" : "platform",
        "fullName" : "credebl/platform",
        "htmlUrl" : "https://github.com/credebl/platform",
        "gitUrl" : "git://github.com/credebl/platform.git",
        "sshUrl" : "git@github.com:credebl/platform.git",
        "cloneUrl" : "https://github.com/credebl/platform.git",
        "owner" : {
          "login" : "credebl",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 52,
        "stargazersCount" : 54,
        "watchersCount" : 54,
        "size" : 20032,
        "openIssuesCount" : 110,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-11T14:47:23Z",
        "languages" : {
          "TypeScript" : 1651864,
          "Shell" : 59104,
          "JavaScript" : 3459
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The API should return a 400 status code with a 'Bad Request' error when creating a shortening URL with an empty 'attributes' array, instead of a 201 status code with a success message.",
      "validationOrRequirement" : "The API should return a 400 status code with a 'Bad Request' error when creating a shortening URL with an empty 'attributes' array.",
      "attemptedFixes" : "Several users have expressed interest in fixing this issue, with one user creating a draft PR (https://github.com/credebl/platform/pull/1224) but the issue remains unassigned due to inactivity.",
      "otherNotes" : "The API returns a 201 status code with a success message when creating a shortening URL with an empty 'attributes' array, but the expected behavior is to return a 400 status code with a 'Bad Request' error.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284961
  }, {
    "issueDTO" : {
      "id" : 3082531330,
      "title" : "Update `Open Current Note's Project` command to also highlight the current scene",
      "url" : "https://github.com/kevboh/longform/issues/297",
      "repositoryName" : "kevboh/longform",
      "description" : "Hope to add the function of locating \"scene\"\nI am writing my thesis and often need to search for a scene to see its location in longform. If I only search in Obsidian's built-in file search, I can't find its location in the longform, so I need to add the function of locating \"scene\" in the longform.",
      "updatedAt" : 1752208760.000000000,
      "user" : "PenguinWang123",
      "userHtmlUrl" : "https://github.com/PenguinWang123",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/117373536?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Sorry, can you elaborate on what you mean by the location within Longform? Do you mean showing it within the Longform UI? The `Open Current Note???s Project` command should do that.", "Would it be possible to have \"Open Current Note's Project\" focus on the current note in the outline in the Longform pane, or have another command, something like \"Reveal Current Scene in the Project Outline\"? Currently this command opens the project but it does not focus on the note in the outline, so when I have dozens (potentially hundreds) of nested scenes in the outline it takes a long time to read through the entire list to find that note's location within the manuscript. I have to open Index.md, switch to Source mode and search within the Index note. It would be faster to just focus in the outline in the Longform pane.", "> Would it be possible to have \"Open Current Note's Project\" focus on the current note in the outline in the Longform pane, or have another command, something like \"Reveal Current Scene in the Project Outline\"? Currently this command opens the project but it does not focus on the note in the outline, so when I have dozens (potentially hundreds) of nested scenes in the outline it takes a long time to read through the entire list to find that note's location within the manuscript. I have to open Index.md, switch to Source mode and search within the Index note. It would be faster to just focus in the outline in the Longform pane.\n\nI couldn't agree more." ],
      "repository" : {
        "description" : "A plugin for Obsidian that helps you write and edit novels, screenplays, and other long projects.",
        "homepage" : "",
        "name" : "longform",
        "fullName" : "kevboh/longform",
        "htmlUrl" : "https://github.com/kevboh/longform",
        "gitUrl" : "git://github.com/kevboh/longform.git",
        "sshUrl" : "git@github.com:kevboh/longform.git",
        "cloneUrl" : "https://github.com/kevboh/longform.git",
        "owner" : {
          "login" : "kevboh",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 42,
        "stargazersCount" : 783,
        "watchersCount" : 783,
        "size" : 1229,
        "openIssuesCount" : 94,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-04T17:40:48Z",
        "languages" : {
          "TypeScript" : 198139,
          "CSS" : 383,
          "JavaScript" : 3581,
          "Svelte" : 81467
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the 'Open Current Note's Project' command to also highlight the current scene in the longform, to improve the user experience for the author.",
      "validationOrRequirement" : "The issue requires the ability to locate scenes within longform, and the 'Open Current Note's Project' command should focus on the current note in the outline.",
      "attemptedFixes" : "The author suggests having the 'Open Current Note's Project' command focus on the current note in the outline in the Longform pane, or having another command like 'Reveal Current Scene in the Project Outline'.",
      "otherNotes" : "The author is writing their thesis and needs to locate scenes within longform, currently having to switch to source mode and search within the Index note.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284966
  }, {
    "issueDTO" : {
      "id" : 3221478058,
      "title" : "Exiting planning when the button is close on small screens",
      "url" : "https://github.com/organicmaps/organicmaps/issues/10880",
      "repositoryName" : "organicmaps/organicmaps",
      "description" : "When you click on the auto icon, you often get out of planning due to the nearby arrow.\nYou need to move the arrow to the left\n\nCubot King Kong mini 2 Pro\nhas a diagonal of 4 inches and a resolution of 1080x540 pixels\n\n\n<img width=\"537\" height=\"1079\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4ad079b2-8286-4c5c-b5e3-27af72ed2faa\" />",
      "updatedAt" : 1752208666.000000000,
      "user" : "matppon",
      "userHtmlUrl" : "https://github.com/matppon",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/190362037?v=4",
      "labels" : [ "UI", "Good first issue", "Android" ],
      "state" : "OPEN",
      "comments" : [ "What is your device's model/screen size/Android version?", "Cubot King Kong mini 2 Pro\nhas a diagonal of 4 inches and a resolution of 1080x540 pixels\n\nAndroid 11" ],
      "repository" : {
        "description" : "\uD83C\uDF43 Organic Maps is a free Android & iOS offline maps app for travelers, tourists, hikers, and cyclists. It uses crowd-sourced OpenStreetMap data and is developed with love by the community. No ads, no tracking, no data collection, no crapware. Please donate to support the development!",
        "homepage" : "https://organicmaps.app",
        "name" : "organicmaps",
        "fullName" : "organicmaps/organicmaps",
        "htmlUrl" : "https://github.com/organicmaps/organicmaps",
        "gitUrl" : "git://github.com/organicmaps/organicmaps.git",
        "sshUrl" : "git@github.com:organicmaps/organicmaps.git",
        "cloneUrl" : "https://github.com/organicmaps/organicmaps.git",
        "owner" : {
          "login" : "organicmaps",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1125,
        "stargazersCount" : 11442,
        "watchersCount" : 11442,
        "size" : 8075265,
        "openIssuesCount" : 2957,
        "subscribersCount" : 100,
        "pushedAt" : "2025-07-12T00:50:34Z",
        "languages" : {
          "Java" : 1692388,
          "C++" : 18355765,
          "C" : 1929048,
          "Objective-C++" : 816550,
          "CMake" : 209919,
          "DIGITAL Command Language" : 901,
          "Makefile" : 818,
          "M4" : 786,
          "Common Lisp" : 17587,
          "HTML" : 342540,
          "Metal" : 82954,
          "Dockerfile" : 577,
          "Shell" : 42524,
          "Starlark" : 965,
          "Gherkin" : 305230,
          "Objective-C" : 295306,
          "Lua" : 55296,
          "PHP" : 2777,
          "Swift" : 1029181,
          "Roff" : 3323,
          "Ruby" : 70144,
          "Python" : 680055,
          "GLSL" : 63639
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Exiting planning when the button is close on small screens",
      "validationOrRequirement" : "move the arrow to the left",
      "attemptedFixes" : "",
      "otherNotes" : "Cubot King Kong mini 2 Pro has a diagonal of 4 inches and a resolution of 1080x540 pixels, Android 11",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284969
  }, {
    "issueDTO" : {
      "id" : 3198490572,
      "title" : "Add a force flag to export a notebook to another format",
      "url" : "https://github.com/marimo-team/marimo/issues/5523",
      "repositoryName" : "marimo-team/marimo",
      "description" : "### Description\n\nI would like to overwrite an exported marimo notebook in an automated way when using the command `marimo export`. currently I get\n\n```sh\nWarning: The file '' already exists. Overwrite? [y/N]: Aborted!\n```\n\nI would like to be able to pass a flag so that it would overwrite it without the prompt.\n\n### Suggested solution\n\nadd a `-f` flag to force the overwrite\n\n### Will you submit a PR?\n\n- [ ] Yes\n\n### Alternative\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1752208638.000000000,
      "user" : "constraintAutomaton",
      "userHtmlUrl" : "https://github.com/constraintAutomaton",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19601176?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "If you do\n\n`marimo export html file.py > whatever.py` that will \"force\"", "> If you do\n> \n> `marimo export html file.py > whatever.py` that will \"force\"\n\nThank you! It solve my problem. But, I still feel that the \"cli param\" interface should have this option.", "@constraintAutomaton - i agree, i think `-f` is more obvious. would you be open to making the contribuion?", "> [@constraintAutomaton](https://github.com/constraintAutomaton) - i agree, i think `-f` is more obvious. would you be open to making the contribuion?\n\nYes, I can try do it!\n\n\n", "Hi I just created the PR, please take a look @mscolnick @constraintAutomaton @dmadisetti  #5610 " ],
      "repository" : {
        "description" : "A reactive notebook for Python ??? run reproducible experiments, query with SQL, execute as a script, deploy as an app, and version with git. All in a modern, AI-native editor.",
        "homepage" : "https://marimo.io",
        "name" : "marimo",
        "fullName" : "marimo-team/marimo",
        "htmlUrl" : "https://github.com/marimo-team/marimo",
        "gitUrl" : "git://github.com/marimo-team/marimo.git",
        "sshUrl" : "git@github.com:marimo-team/marimo.git",
        "cloneUrl" : "https://github.com/marimo-team/marimo.git",
        "owner" : {
          "login" : "marimo-team",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 586,
        "stargazersCount" : 14300,
        "watchersCount" : 14300,
        "size" : 155161,
        "openIssuesCount" : 428,
        "subscribersCount" : 56,
        "pushedAt" : "2025-07-11T23:06:15Z",
        "languages" : {
          "TypeScript" : 3892861,
          "MDX" : 9807,
          "Dockerfile" : 1005,
          "CSS" : 100549,
          "Shell" : 9200,
          "Makefile" : 4457,
          "TeX" : 209,
          "JavaScript" : 20017,
          "HTML" : 60020,
          "Jupyter Notebook" : 5039,
          "Vim Script" : 30,
          "Python" : 5830633
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a force flag to the command `marimo export` to overwrite the exported notebook without prompting.",
      "validationOrRequirement" : "The requirement is to add a force flag to the command `marimo export` to overwrite the exported notebook without prompting.",
      "attemptedFixes" : "The suggested solution is to add a `-f` flag to force the overwrite.",
      "otherNotes" : "The issue is related to adding a force flag to the command `marimo export` to overwrite the exported notebook without prompting.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284972
  }, {
    "issueDTO" : {
      "id" : 3221480028,
      "title" : "Absence of `normalize` command for XMIR-to-.phi file conversion",
      "url" : "https://github.com/objectionary/eoc/issues/590",
      "repositoryName" : "objectionary/eoc",
      "description" : "Let's add `normalize` command that should run `parse` and them take XMIR files, transfer them to `.phi` (with the help of `phino`), then run `phino rewrite --normalize`, get new `.phi` files, transfer them back to XMIR, and then back to `.eo`.",
      "updatedAt" : 1752208151.000000000,
      "user" : "yegor256",
      "userHtmlUrl" : "https://github.com/yegor256",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/526301?v=4",
      "labels" : [ "good-title", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Command-line toolkit for parsing, compiling, transpiling, optimizing, linking, dataizing, and running EOLANG programs",
        "homepage" : "https://www.npmjs.com/package/eolang",
        "name" : "eoc",
        "fullName" : "objectionary/eoc",
        "htmlUrl" : "https://github.com/objectionary/eoc",
        "gitUrl" : "git://github.com/objectionary/eoc.git",
        "sshUrl" : "git@github.com:objectionary/eoc.git",
        "cloneUrl" : "https://github.com/objectionary/eoc.git",
        "owner" : {
          "login" : "objectionary",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 29,
        "stargazersCount" : 26,
        "watchersCount" : 26,
        "size" : 1487,
        "openIssuesCount" : 33,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-11T23:02:40Z",
        "languages" : {
          "JavaScript" : 95964
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a `normalize` command for XMIR-to-.phi file conversion",
      "validationOrRequirement" : "The requirement is to add a `normalize` command that runs `parse`, transfers XMIR files to `.phi` using `phino`, runs `phino rewrite --normalize`, gets new `.phi` files, transfers them back to XMIR, and then back to `.eo`.",
      "attemptedFixes" : "No attempts or blockers mentioned in the issue description.",
      "otherNotes" : "The issue is related to adding a normalize command for XMIR-to-.phi file conversion, which involves several steps.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284977
  }, {
    "issueDTO" : {
      "id" : 3220417767,
      "title" : "bug: Primary Key Column Order Mismatch in `create_empty_table`",
      "url" : "https://github.com/meltano/sdk/issues/3157",
      "repositoryName" : "meltano/sdk",
      "description" : "### Singer SDK Version\n\n0.47.4\n\n### Is this a regression?\n\n- [ ] Yes\n\n### Python Version\n\nNA\n\n### Bug scope\n\nTargets (data type handling, batching, SQL object generation, etc.)\n\n### Operating System\n\n_No response_\n\n### Description\n\n## Summary\n\nThe `create_empty_table` method doesn???t maintain the order of columns specified in the `primary_keys` sequence when creating the primary key constraint. Instead, it adheres to the order of properties as they are listed in the `schema`, which can result in erroneous primary key definitions.\n\n## Description\n\nIn the current implementation of `create_empty_table`\n\nhttps://github.com/meltano/sdk/blob/bba4d8818fcf77a015437ee785713aa50b1559fe/singer_sdk/connectors/sql.py#L1279\n\n(downstream too: https://github.com/MeltanoLabs/target-postgres/blob/3d16266bcc1be6d01f09a90607d5288bbfeb3374/target_postgres/connector.py#L421)\n\nthe method iterates through `schema['properties'].items()` and adds columns, setting the primary key flag if a column exists the primary_keys sequence.\nThis means the primary key columns will be ordered according to how properties are defined in the schema dictionary, not according to the explicit order specified in the `primary_keys` sequence.\n\nThis does not allow you to rely on the primary key column order that clients specify. Primary key order matters for database performance and indexing strategies. Additionally, the same schema with different property ordering could result in different primary key definitions.\n\n## Expected Behavior\nThe primary key columns should be created in the exact order specified in the `primary_keys` sequence parameter.\n\n## Suggested Fix\n\nDo not set the `primary_key` property on the column and use `PrimaryKeyConstraint`.\n\n```python\ndef create_empty_table( # noqa: PLR0913\n    self,\n    table_name: str,\n    meta: sa.MetaData,\n    schema: dict[str, Any],\n    connection: sa.engine.Connection,\n    primary_keys: t.Sequence[str] | None = None,\n    partition_keys: list[str] | None = None,\n    as_temp_table: bool = False,\n  ) -> sa.Table:\n    \"\"\"Create an empty target table.\n\n    Args:\n      table_name: the target table name.\n      meta: the SQLAlchemy metadata object.\n      schema: the JSON schema for the new table.\n      connection: the database connection.\n      primary_keys: list of key properties.\n      partition_keys: list of partition keys.\n      as_temp_table: True to create a temp table.\n\n    Returns:\n      The new table object.\n\n    Raises:\n      NotImplementedError: if temp tables are unsupported and as_temp_table=True.\n      RuntimeError: if a variant schema is passed with no properties defined.\n    \"\"\"\n    columns: list[sa.Column[Any]] = []\n    primary_keys = primary_keys or []\n    try:\n      properties: dict[str, Any] = schema[\"properties\"]\n    except KeyError:\n      raise RuntimeError(\n        f\"Schema for table_name: '{table_name}'\"\n        f\"does not define properties: {schema}\"\n      ) from None\n\n    for property_name, property_jsonschema in properties.items():\n      columns.append(\n        sa.Column(\n          property_name,\n          self.to_sql_type(property_jsonschema),\n          autoincrement=False, # See: https://github.com/MeltanoLabs/target-postgres/issues/193 # noqa: E501\n        )\n      )\n\n    table_args = []\n    if primary_keys:\n      missing_pk_columns = [col for col in primary_keys if col not in properties]\n      if missing_pk_columns:\n        raise RuntimeError(\n          f\"Primary keys {missing_pk_columns} are not defined in\"\n          f\"schema {schema} for table_name '{table_name}'\"\n        )\n      table_args.append(sa.PrimaryKeyConstraint(*primary_keys))\n\n    table_kwargs: dict[str, Any] = {}\n    if as_temp_table:\n      table_kwargs[\"prefixes\"] = [\"TEMPORARY\"]\n\n    new_table = sa.Table(table_name, meta, *columns, *table_args, **table_kwargs)\n    new_table.create(bind=connection)\n    return new_table\n```\n\n\n### Link to Slack/Linen\n\n_No response_",
      "updatedAt" : 1752208051.000000000,
      "user" : "edgarrmondragon",
      "userHtmlUrl" : "https://github.com/edgarrmondragon",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16805946?v=4",
      "labels" : [ "Type/Target", "Accepting Pull Requests", "good first issue", "SQL" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I???m interested in working on this issue as a first-time contributor. I understand the problem with the primary key column order and would like to implement the fix using `PrimaryKeyConstraint` as suggested. Could you please assign it to me? Thank you!", "Hi @CamiloTriana75, no need to wait for an assignment just go for it \uD83D\uDE42 " ],
      "repository" : {
        "description" : "Write 70% less code by using the SDK to build custom extractors and loaders that adhere to the Singer standard: https://sdk.meltano.com",
        "homepage" : "https://sdk.meltano.com",
        "name" : "sdk",
        "fullName" : "meltano/sdk",
        "htmlUrl" : "https://github.com/meltano/sdk",
        "gitUrl" : "git://github.com/meltano/sdk.git",
        "sshUrl" : "git@github.com:meltano/sdk.git",
        "cloneUrl" : "https://github.com/meltano/sdk.git",
        "owner" : {
          "login" : "meltano",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 77,
        "stargazersCount" : 114,
        "watchersCount" : 114,
        "size" : 12873,
        "openIssuesCount" : 195,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-11T01:06:05Z",
        "languages" : {
          "Python" : 1057769
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The `create_empty_table` method in the Singer SDK doesn't maintain the order of columns specified in the `primary_keys` sequence when creating the primary key constraint, resulting in erroneous primary key definitions.",
      "validationOrRequirement" : "The primary key columns should be created in the exact order specified in the `primary_keys` sequence parameter.",
      "attemptedFixes" : "The suggested fix is to not set the `primary_key` property on the column and use `PrimaryKeyConstraint`.",
      "otherNotes" : "The issue is about the `create_empty_table` method in the Singer SDK not maintaining the order of columns specified in the `primary_keys` sequence when creating the primary key constraint. The current implementation uses the order of properties in the `schema` dictionary instead. This can result in erroneous primary key definitions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284982
  }, {
    "issueDTO" : {
      "id" : 3208027086,
      "title" : "Cant trigger run",
      "url" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit/issues/227",
      "repositoryName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
      "description" : "Hi, \n\nI just recently installed the latest version of the KIT but I cant trigger run or rerun. I went though all the configuration as mentioned in the documentation. I created a test set with few test and added them into a test run but it is not working at all. \n\nI checked most of the issue post and checked all the mention possibility but the triggers are not working. \n\nFlows turned on. \nConnections are there.\nConnection references there. \n\nOne of my colleague worked with the KIT back in April he created some successful run but i cant even retrigger them. \n\n",
      "updatedAt" : 1752207558.000000000,
      "user" : "gysanyi950113",
      "userHtmlUrl" : "https://github.com/gysanyi950113",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/81823055?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @gysanyi950113,\n\nI understand you're having trouble triggering or rerunning tests in the KIT. Here are a few things you might want to check:\n\n1. Configuration: Double-check that all flows and connections are correctly set up as per the documentation.\n2. Logs: If there are any error messages or logs when you try to trigger a run, those could provide valuable insights.\n3. Reproduction: I can try to reproduce the issue on my end. If you could provide any additional details about your setup, that would be helpful.\n\nLet???s see if we can get this resolved together!", "Hello,\n\n1. I found one flow which has some issue. \nPipeline | Validate Agent Using Test Cases\n\n<img width=\"780\" height=\"433\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d9b69b5d-bcc5-46c2-ad4c-77f125b7b9e1\" />\n\n2. There is no log or console information can be found.  The run not start and if i want to rerun it the button just not reacting. \n\n3. I did all the setup step as mentioned in the documentation.\nImport solution, Publish managed solution - set up connections and references\nAgent setup:\n\n1. Name provided, Configuration type: Test Automation, Conversation KPIs\n2. Dataverse URL provided, Agent id provided, Copy Full Transcript yes, Tracked variables empty\n3. Region Default, Token endpoint provided Channel security no\n4. user auth is no\n5. Enrich with Azure App Insights no\n6. Enrich With Conversation is yes, Dataverse URL provided, Copy Full Transcript yes\n7. Generative AI Testing yes, Generative AI provider AI Builder\n8. Advanced is empty\n\nTest Sets\nName and owner provided test added. \nTest: Name provided, test type topic, test set selected, no parent.\n- Test Utterance: English, Topic Name provided, Expected response provided.\n\nTest Run\nAgent Test Set selected, Agent configuration selected. After save the tests the run not trigger and the rerun button is not reacting.\n\nThe bot start the conversation with 2 phase. The second phase is asking you which language are you prefer to use. We have an option set where you can select the preferred language.\n\n\nThanks,\nSandor", "Hi @gysanyi950113 , \n\n<img width=\"780\" height=\"433\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/705776a7-f226-44cf-bbd7-c2065ea73ce6\" />\n\nThis flow is specifically designed for Power Platform Pipelines to facilitate the deployment of agents from your development/test environment to the respective target environments. Please note that this flow does not handle Agent Test Runs.\n\nCould you kindly verify the following:\n\n- Ensure the agent is configured correctly in your environment.\n- Confirm the authentication settings for the agent are properly set up.\n- In case of No authentication , please check the Token Endpoint under Channels > Emails in Copilot Studio & place it in Agent configuration under Direct line settings section.\n\nOnce these configurations are in place, publish the agent and initiate the Test Run again.", "Hi, \n\nThe normal run is started to work. The Rerun button is still not working so i need to resubmit it from flow. The solution is useable now with some workaround.", "\nThe Rerun button includes a dropdown menu that allows you to execute specific flows, as illustrated below:\n\n<img width=\"402\" height=\"214\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5d9f0170-53f6-4825-94b7-937ddecbc373\" />\n\nTo execute the complete Agents Tests, you need to duplicate the existing test run and initiate it with the same agent configuration.\n\n> Hi,\n> \n> The normal run is started to work. The Rerun button is still not working so i need to resubmit it from flow. The solution is useable now with some workaround.\n\n" ],
      "repository" : {
        "description" : null,
        "homepage" : "",
        "name" : "Power-CAT-Copilot-Studio-Kit",
        "fullName" : "microsoft/Power-CAT-Copilot-Studio-Kit",
        "htmlUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit",
        "gitUrl" : "git://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "sshUrl" : "git@github.com:microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "cloneUrl" : "https://github.com/microsoft/Power-CAT-Copilot-Studio-Kit.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 180,
        "watchersCount" : 180,
        "size" : 48361,
        "openIssuesCount" : 27,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-09T12:45:38Z",
        "languages" : {
          "C#" : 24850,
          "CSS" : 4368,
          "JavaScript" : 33528,
          "HTML" : 16742
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to trigger run or rerun tests in the KIT, but it was not working due to the flow issue and the Rerun button not functioning.",
      "validationOrRequirement" : "The validation or requirement is to ensure the agent is configured correctly in the environment, confirm the authentication settings, and check the Token Endpoint under Channels > Emails in Copilot Studio & place it in Agent configuration under Direct line settings section.",
      "attemptedFixes" : "The workaround was to duplicate the existing test run and initiate it with the same agent configuration. The issue was not fully resolved.",
      "otherNotes" : "The issue was related to a flow with an issue, specifically the 'Pipeline | Validate Agent Using Test Cases' flow. The Rerun button was not working and the normal run was started to work with some workaround.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284988
  }, {
    "issueDTO" : {
      "id" : 3162281445,
      "title" : "???????????????????????????????????????",
      "url" : "https://github.com/fjordllc/bootcamp/issues/8826",
      "repositoryName" : "fjordllc/bootcamp",
      "description" : "`test/system/notification/reports_test.rb` ???????????????????????????????????????????????????????????????????????????????????????????????????",
      "updatedAt" : 1752206665.000000000,
      "user" : "komagata",
      "userHtmlUrl" : "https://github.com/komagata",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16577?v=4",
      "labels" : [ "1", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@komagata \n????????????????????????\n???????????????????????????1??????????????????\n??????????????????????????????????????????1????????????????????????????????????????????????????????????????????????\n???????????????????????????????????????\n\n```rb\n??? bin/rails test test/system/notification/reports_test.rb:218\nRunning via Spring preloader in process 53043\nRun options: --seed 53148\n\n# Running:\n\n[Screenshot Image]: /Users/karlley/workspace/bootcamp/tmp/screenshots/failures_test_notify_mention_target_only_on_first_report_posted.png\nE\n\nError:\nNotification::ReportsTest#test_notify_mention_target_only_on_first_report_posted:\nCapybara::ElementNotFound: Unable to find field \"report[title]\" that is not disabled\n    test/supports/report_helper.rb:35:in `edit_report'\n    test/supports/report_helper.rb:23:in `update_report'\n    test/system/notification/reports_test.rb:167:in `block in assert_notify_only_at_first_published_of_report'\n    test/system/notification/reports_test.rb:161:in `times'\n    test/system/notification/reports_test.rb:161:in `assert_notify_only_at_first_published_of_report'\n    test/system/notification/reports_test.rb:223:in `block in <class:ReportsTest>'\n\n\nrails test test/system/notification/reports_test.rb:218\n\n\n[Minitest::CI] Generating test report in JUnit XML format...\n\n\nFinished in 45.688525s, 0.0219 runs/s, 0.0219 assertions/s.\n1 runs, 1 assertions, 0 failures, 1 errors, 0 skips\n```\n\n?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n?????????????????????????????????????????????????????????????????????????????????????????????", "@karlley ?????????????????????????????????PR?????????????????????????????????\n??????????????????CircleCI??????????????????????????????????????????????????????CircleCI??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????", "@komagata \n\n> CircleCI??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n\n?????????????????????????????????PR????????????CircleCI??????????????????????????????????????????????????????\n???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????...\n???????????????????????????????????????????????????????????????????????????????????????????????????????????????", "@karlley ???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????" ],
      "repository" : {
        "description" : "????????????????????????E???????????????????????????",
        "homepage" : "https://bootcamp.fjord.jp",
        "name" : "bootcamp",
        "fullName" : "fjordllc/bootcamp",
        "htmlUrl" : "https://github.com/fjordllc/bootcamp",
        "gitUrl" : "git://github.com/fjordllc/bootcamp.git",
        "sshUrl" : "git@github.com:fjordllc/bootcamp.git",
        "cloneUrl" : "https://github.com/fjordllc/bootcamp.git",
        "owner" : {
          "login" : "fjordllc",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 73,
        "stargazersCount" : 290,
        "watchersCount" : 290,
        "size" : 112857,
        "openIssuesCount" : 265,
        "subscribersCount" : 79,
        "pushedAt" : "2025-07-11T21:18:59Z",
        "languages" : {
          "Dockerfile" : 3039,
          "CSS" : 5304,
          "Shell" : 276,
          "Procfile" : 111,
          "SCSS" : 10372,
          "JavaScript" : 348703,
          "Vue" : 14862,
          "Sass" : 353546,
          "Slim" : 1086284,
          "HTML" : 114392,
          "Ruby" : 1906242
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rename the test title from Japanese to English",
      "validationOrRequirement" : "Test name title should be in English, and the test should pass on both local and CircleCI environments.",
      "attemptedFixes" : "PR was created without fixing the test, and the test passed on CircleCI. However, the author initially thought the test had a problem and couldn't run it locally.",
      "otherNotes" : "Test name title is in Japanese, needs to be translated to English. There is a test that fails regardless of how many times it's run, and the error message is unable to find a field 'report[title]' that is not disabled. The test logic itself seems to have a problem, but the issue is about renaming the test title, not the test logic.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284993
  }, {
    "issueDTO" : {
      "id" : 3165470214,
      "title" : "[Tracking] Model support",
      "url" : "https://github.com/sgl-project/sglang/issues/7429",
      "repositoryName" : "sgl-project/sglang",
      "description" : "### **[Tracking] Model support**\n\nThe goal is to support other model architectures available. Expand the model zoo \uD83C\uDF8A \n\nThe goal is to implement support for all architectures listed below. Anyone is welcome to take any issue or implement the model below.\n\nIf you need help implementing a new model, see https://docs.sglang.ai/supported_models/support_new_models.html\n\n#### Text-only Language Models (Generative)\n- [ ] `OPTForCasualLM` (facebook/opt-125m) #7440 \n- [ ] `AquilaForCausalLM` (Aquila, Aquila2)\n- [ ] `ArcticForCausalLM` (Arctic) #5768\n- [ ] `BambaForCausalLM` (Bamba)\n- [ ] `BartForConditionalGeneration` (BART)\n- [ ] `BloomForCausalLM` (BLOOM, BLOOMZ)\n- [ ] `Cohere2ForCasualLM` #4570\n- [ ] `DeciLMForCausalLM` (DeciLM)\n- [ ] `FalconForCausalLM` (Falcon)\n- [ ] `FalconH1ForCausalLM` (Falcon-H1) #6517\n- [ ] `FalconMambaForCausalLM` (FalconMamba)\n- [ ] `Dots1ForCasualLM` (dots.llm1) #6471\n- [ ] `GPT2LMHeadModel` (GPT-2)\n- [ ] `GPTBigCodeForCausalLM` (StarCoder, SantaCoder)\n- [ ] `GPTJForCausalLM` (GPT-J)\n- [ ] `GPTNeoXForCausalLM` (GPT-NeoX, Pythia)\n- [ ] `GraniteForCausalLM` (Granite 3.0, 3.1)\n- [ ] `GraniteMoeForCausalLM` (Granite 3.0 MoE)\n- [ ] `GraniteMoeHybridForCausalLM` (Granite 4.0 MoE Hybrid)\n- [ ] `GraniteMoeSharedForCausalLM` (Granite MoE Shared)\n- [ ] `GritLM` (GritLM)\n- [ ] `InternLMForCausalLM` (InternLM v1)\n- [ ] `JAISLMHeadModel` (Jais)\n- [ ] `JambaForCausalLM` (Jamba) #1190\n- [ ] `MambaForCausalLM` (Mamba)\n- [ ] `Mamba2ForCausalLM` (Mamba2)\n- [ ] `MiniCPMForCausalLM` (MiniCPM v1) #6900\n- [ ] `MiniMaxM1ForCausalLM` (MiniMax-Text) #2898\n- [ ] `MiniMaxText01ForCausalLM` (MiniMax-Text-01)\n- [ ] `MPTForCausalLM` (MPT)\n- [ ] `NemotronForCausalLM` (Nemotron-3) #5063\n- [ ] `NemotronHForCausalLM` (Nemotron-H)\n- [ ] `OLMoForCausalLM` (OLMo v1)\n- [ ] `OLMo2ForCausalLM` (OLMo2)\n- [ ] `OPTForCausalLM` (OPT)\n- [ ] `OrionForCausalLM` (Orion)\n- [ ] `PersimmonForCausalLM` (Persimmon)\n- [ ] `PhiForCausalLM` (Phi-1.5, Phi-2) #7862 @ppraneth \n- [x] `Phi3SmallForCausalLM` (Phi-3-Small)\n- [x] `PhiMoEForCausalLM` (Phi-3.5-MoE) #7907 @byjiang1996 \n- [ ] `Plamo2ForCausalLM` (PLaMo2)\n- [ ] `SolarForCausalLM` (Solar Pro)\n- [ ] `Starcoder2ForCausalLM` (Starcoder2)\n- [ ] `TeleChat2ForCausalLM` (TeleChat2) \n- [ ] `TeleFLMForCausalLM` (TeleFLM)\n- [ ] `Zamba2ForCausalLM` (Zamba2)\n\n#### Embedding Models\n- [ ] `GteModel`\n- [ ] `GteNewModel`\n- [ ] `ModernBertModel`\n- [ ] `NomicBertModel`\n- [ ] `RobertaModel`\n- [ ] `JambaForSequenceClassification`\n- [ ] `BertForSequenceClassification`\n- [ ] `Qwen3ForSequenceClassification` #7314\n- [ ] `RobertaForSequenceClassification`\n- [ ] `XLMRobertaForSequenceClassification`\n\n#### Multimodal Models\n- [ ] `Glm4vForConditionalGeneration` (THUDM/GLM-4.1V-9B-Thinking)\n- [ ] `AriaForConditionalGeneration` (Aria)\n- [ ] `AyaVisionForConditionalGeneration` (Aya Vision) #6304\n- [ ] `Blip2ForConditionalGeneration` (BLIP-2) #4414\n- [ ] `ChameleonForConditionalGeneration` (Chameleon)\n- [ ] `Florence2ForConditionalGeneration` (Florence-2)\n- [ ] `FuyuForCausalLM` (Fuyu)\n- [ ] `GLM4VForCausalLM` PP support #7257\n- [ ] `GraniteSpeechForConditionalGeneration` (Granite Speech)\n- [ ] `H2OVLChatModel` (H2OVL)\n- [ ] `Idefics3ForConditionalGeneration` (Idefics3)\n- [ ] `LlavaNextVideoForConditionalGeneration` (LLaVA-NeXT-Video) #4062\n- [ ] `MiniMaxVL01ForConditionalGeneration` (MiniMax-VL)\n- [ ] `MolmoForCausalLM` (Molmo)\n- [ ] `NVLM_D_Model` (NVLM-D 1.0)\n- [ ] `Ovis` (Ovis1.6, Ovis2) #5018\n- [ ] `PaliGemmaForConditionalGeneration` (PaliGemma)\n- [ ] `Phi3VForCausalLM` (Phi-3-Vision) #1108\n- [ ] `PixtralForConditionalGeneration` (Pixtral)\n- [ ] `Qwen2AudioForConditionalGeneration` (Qwen2-Audio)\n- [ ] `Qwen2_5OmniThinkerForConditionalGeneration` (Qwen2.5-Omni) #4969\n- [ ] `SkyworkR1VChatModel` (Skywork-R1V) #4692\n- [ ] `SmolVLMForConditionalGeneration` (SmolVLM2)\n- [ ] `TarsierForConditionalGeneration` (Tarsier)\n- [ ] `Tarsier2ForConditionalGeneration` (Tarsier2)\n\n---\n**Related Issues & PRs**\n\n- Support TRI-ML/prismatic-vlms: #1129\n- facebook/contriever support: #3720\n- Support Gemma 3 QAT models: #5591\n- Bytedancer: #6724",
      "updatedAt" : 1752206602.000000000,
      "user" : "b8zhong",
      "userHtmlUrl" : "https://github.com/b8zhong",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/184021590?v=4",
      "labels" : [ "good first issue", "new-model" ],
      "state" : "OPEN",
      "comments" : [ "Hello @b8zhong ,\n\nI'm very interested and would like to do the implementation to support a model. What model do you suggest for starters ? And is there a way to get assigned?\n\nThanks !!!\n", "> Hello [@b8zhong](https://github.com/b8zhong) ,\n> \n> I'm very interested and would like to do the implementation to support a model. What model do you suggest for starters ? And is there a way to get assigned?\n> \n> Thanks !!!\n\nHi there, you can follow the instructions at https://docs.sglang.ai/supported_models/support_new_models.html\n", "> > Hello [@b8zhong](https://github.com/b8zhong) ,\n> > I'm very interested and would like to do the implementation to support a model. What model do you suggest for starters ? And is there a way to get assigned?\n> > Thanks !!!\n> \n> Hi there, you can follow the instructions at https://docs.sglang.ai/supported_models/support_new_models.html\n\nShould I mention the model I'm starting to work on somewhere, to avoid conflicting merges?", "Hi @b8zhong \nI am a statistics grad looking to dip my toes into open source project and make some meaningful impact. Please assign the issue to me and let me know the model to get started on to avoid any conflicting merge", "@vprabhakar12 @AyushPantOfficial No it's fine, feel free to work on it, there will not be merge conflicts.", "@b8zhong I see there are many pending supports, can I pick any one of these ?\n", "> [@b8zhong](https://github.com/b8zhong) I see there are many pending supports, can I pick any one of these ?\n\nYes just go ahead!", "For contributors interested in supporting new MLLMs, welcome to contact me or @mickqian for support", "When I launch the server to test a model (Tele-AI/TeleChat2-3B) I implemented, the Docker container gets disconnected after some time (I see that downcasting to float16 is happening). \nIs this a resource issue? (But the RAM is not full, nor is the GPU) \nIs there a way to launch the server other than on our local system?", "> When I launch the server to test a model (Tele-AI/TeleChat2-3B) I implemented, the Docker container gets disconnected after some time (I see that downcasting to float16 is happening). Is this a resource issue? (But the RAM is not full, nor is the GPU) Is there a way to launch the server other than on our local system?\n\nHi, could you open a draft PR and push all your changes? Then we could use that thread to communicate, instead of disturbing other contributors here. Also, paste the logs or traceback under that PR.", "Hi @b8zhong , I'm currently learning about LLM inference. Could I try adapting a text-only generative language model?", "@Mellorsssss Yes, you don't need to ping to work on it!", "Hi @b8zhong, I'd like to work on GPT-J and some other text-only generative language models. Thanks!", "@wenchen76 Sure, sounds good.", "Interested in adding support for mamba models", "> [@wenchen76](https://github.com/wenchen76) Sure, sounds good.\n\nHi @b8zhong Thanks! I just created this PR for GPT-J support: https://github.com/sgl-project/sglang/pull/7839 ", "Hi @b8zhong I am currently working on phi1.5 model support in my local computer. I have done a fork of it, so how do i test it or should i create a pull request for review?", "Hi @b8zhong , i added the model support for PhiMoEForCausalLM here:  https://github.com/sgl-project/sglang/pull/7907", "@b8zhong , I saw Phi3SmallForCausalLM is already supported last year #2062 , shall we remove it or mark it as done? ", "@lifuhuang Whoops, thanks for the spot, thanks for editing it!" ],
      "repository" : {
        "description" : "SGLang is a fast serving framework for large language models and vision language models.",
        "homepage" : "https://docs.sglang.ai/",
        "name" : "sglang",
        "fullName" : "sgl-project/sglang",
        "htmlUrl" : "https://github.com/sgl-project/sglang",
        "gitUrl" : "git://github.com/sgl-project/sglang.git",
        "sshUrl" : "git@github.com:sgl-project/sglang.git",
        "cloneUrl" : "https://github.com/sgl-project/sglang.git",
        "owner" : {
          "login" : "sgl-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2320,
        "stargazersCount" : 15923,
        "watchersCount" : 15923,
        "size" : 25730,
        "openIssuesCount" : 966,
        "subscribersCount" : 108,
        "pushedAt" : "2025-07-11T22:07:53Z",
        "languages" : {
          "Dockerfile" : 12074,
          "C++" : 778111,
          "Shell" : 26368,
          "Rust" : 342978,
          "C" : 2414,
          "CMake" : 18489,
          "Makefile" : 7619,
          "Jupyter Notebook" : 29605,
          "HIP" : 7341,
          "Python" : 8356532,
          "Cuda" : 712382
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to support other model architectures available, expand the model zoo, and implement support for all architectures listed below.",
      "validationOrRequirement" : "The validation or requirement is to implement support for all architectures listed below, and contributors are welcome to take any issue or implement the model.",
      "attemptedFixes" : "There are no specific attempted fixes mentioned in the description, but some contributors are working on implementing support for specific models.",
      "otherNotes" : "Contributors are welcome to support new models, and there are many pending supports. The goal is to implement support for all architectures listed below. There are also related issues and PRs mentioned in the description.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752284998
  }, {
    "issueDTO" : {
      "id" : 3221413598,
      "title" : "The dropdown options become invalid in mobile mode after the workflow is published.",
      "url" : "https://github.com/langgenius/dify/issues/22191",
      "repositoryName" : "langgenius/dify",
      "description" : "### Self Checks\n\n- [x] This is only for bug report, if you would like to ask a question, please head to [Discussions](https://github.com/langgenius/dify/discussions/categories/general).\n- [x] I have searched for existing issues [search for existing issues](https://github.com/langgenius/dify/issues), including closed ones.\n- [x] I confirm that I am using English to submit this report (????????????????????? [Language Policy](https://github.com/langgenius/dify/issues/1542)).\n- [x] [FOR CHINESE USERS] ??????????????????????????? Issue?????????????????????????????????:)\n- [x] Please do not modify this template :) and fill in all the required fields.\n\n### Dify version\n\n1.6.0\n\n### Cloud or Self Hosted\n\nSelf Hosted (Source)\n\n### Steps to reproduce\n\n\nIn the workflow application, when using dropdown fields in a form and switching to mobile view size, clicking on the dropdown box does not display the options.\n\n<img width=\"511\" height=\"907\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/42947ceb-eaa2-41d2-a201-a85fc1155493\" />\n\n### ?????? Expected Behavior\n\nit is normal\n\n### ??? Actual Behavior\n\n_No response_",
      "updatedAt" : 1752206526.000000000,
      "user" : "tedawan",
      "userHtmlUrl" : "https://github.com/tedawan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16523855?v=4",
      "labels" : [ "\uD83C\uDF0A feat:workflow", "\uD83D\uDC1E bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<!-- Greeting -->\nHi @tedawan! I'm [Dosu](https://go.dosu.dev/dosubot) and I???m helping the dify team.\n\n<!-- Answer -->\nThis issue is likely caused by how dropdowns are rendered and positioned in mobile mode. Dify's dropdowns use a custom portal component (`PortalToFollowElem`) to render options, and recent changes in related components (like `WorkplaceSelector`) fixed similar mobile issues by adjusting z-index, positioning, and CSS classes for overlays and dropdowns [[source]](https://github.com/langgenius/dify/pull/21115).\n\nIn your case, the dropdown options may not appear because the overlay is either being clipped, rendered behind other elements, or not triggered correctly on mobile. This can happen due to restrictive CSS (like overflow or z-index), or event handling differences between desktop and mobile [[source]](https://github.com/langgenius/dify/blob/e576b989b8eca4a7d8cfe6bdc91e9a451580489b/web/app/components/base/portal-to-follow-elem/index.tsx).\n\nTo test a workaround, try increasing the z-index of the dropdown overlay and ensure no parent container has `overflow: hidden` or similar restrictions in mobile view. You can also compare your workflow dropdown's implementation and styles to the `WorkplaceSelector` component, which uses `z-[1000]` and specific mobile CSS tweaks to ensure visibility [[source]](https://github.com/langgenius/dify/pull/21115).\n\nIf you have custom styles or layout wrappers in your workflow forms, check for any that might interfere with overlays in mobile mode. If the issue persists, inspecting the DOM in mobile view and checking for hidden or mispositioned dropdown elements can help pinpoint the cause.\n\n\n<!-- Dosu Comment Footer -->\n*To reply, just mention [@dosu](https://go.dosu.dev/dosubot).*\n\n---\n<sup>How did I do? [Good](https://app.dosu.dev/response-feedback/a91ca63f-8c4d-4e99-805d-037a99895707?feedback_type=great_response) | [Irrelevant](https://app.dosu.dev/response-feedback/a91ca63f-8c4d-4e99-805d-037a99895707?feedback_type=irrelevant_answer) | [Incorrect](https://app.dosu.dev/response-feedback/a91ca63f-8c4d-4e99-805d-037a99895707?feedback_type=incorrect_sources) | [Verbose](https://app.dosu.dev/response-feedback/a91ca63f-8c4d-4e99-805d-037a99895707?feedback_type=too_verbose) | [Hallucination](https://app.dosu.dev/response-feedback/a91ca63f-8c4d-4e99-805d-037a99895707?feedback_type=hallucination) | [Report \uD83D\uDC1B](https://app.dosu.dev/response-feedback/a91ca63f-8c4d-4e99-805d-037a99895707?feedback_type=bug_report) | [Other](https://app.dosu.dev/response-feedback/a91ca63f-8c4d-4e99-805d-037a99895707?feedback_type=other)</sup>&nbsp;&nbsp;[![Join Discord](https://img.shields.io/badge/join-5865F2?logo=discord&logoColor=white&label=)](https://go.dosu.dev/discord-bot)&nbsp;[![Share on X](https://img.shields.io/badge/X-share-black)](https://twitter.com/intent/tweet?text=%40dosu_ai%20helped%20me%20solve%20this%20issue!&url=https%3A//github.com/langgenius/dify/issues/22191)" ],
      "repository" : {
        "description" : "Production-ready platform for agentic workflow development.",
        "homepage" : "https://dify.ai",
        "name" : "dify",
        "fullName" : "langgenius/dify",
        "htmlUrl" : "https://github.com/langgenius/dify",
        "gitUrl" : "git://github.com/langgenius/dify.git",
        "sshUrl" : "git@github.com:langgenius/dify.git",
        "cloneUrl" : "https://github.com/langgenius/dify.git",
        "owner" : {
          "login" : "langgenius",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16148,
        "stargazersCount" : 106618,
        "watchersCount" : 106618,
        "size" : 103462,
        "openIssuesCount" : 777,
        "subscribersCount" : 653,
        "pushedAt" : "2025-07-11T14:34:26Z",
        "languages" : {
          "TypeScript" : 11601485,
          "MDX" : 865160,
          "Dockerfile" : 4139,
          "CSS" : 182041,
          "Shell" : 19709,
          "SCSS" : 21945,
          "Makefile" : 1304,
          "JavaScript" : 1430743,
          "PHP" : 6106,
          "HTML" : 33871,
          "Mako" : 518,
          "Python" : 6709901
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The dropdown options become invalid in mobile mode after the workflow is published.",
      "validationOrRequirement" : "The issue is likely caused by how dropdowns are rendered and positioned in mobile mode. Dify's dropdowns use a custom portal component (`PortalToFollowElem`) to render options. The dropdown options may not appear because the overlay is either being clipped, rendered behind other elements, or not triggered correctly on mobile.",
      "attemptedFixes" : "The comment suggests a workaround to increase the z-index of the dropdown overlay and ensure no parent container has `overflow: hidden` or similar restrictions in mobile view.",
      "otherNotes" : "The issue is likely caused by how dropdowns are rendered and positioned in mobile mode. Dify's dropdowns use a custom portal component (`PortalToFollowElem`) to render options. The dropdown options may not appear because the overlay is either being clipped, rendered behind other elements, or not triggered correctly on mobile. To test a workaround, try increasing the z-index of the dropdown overlay and ensure no parent container has `overflow: hidden` or similar restrictions in mobile view.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285006
  }, {
    "issueDTO" : {
      "id" : 3221418620,
      "title" : "chore: improve code hygiene",
      "url" : "https://github.com/anrayliu/pyvidplayer2/issues/66",
      "repositoryName" : "anrayliu/pyvidplayer2",
      "description" : "Install pylint from pypi and try to make as many fixes as possible. No matter how small, everything helps",
      "updatedAt" : 1752206276.000000000,
      "user" : "anrayliu",
      "userHtmlUrl" : "https://github.com/anrayliu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/74158148?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Reliable, easy, and fast video playing in Python",
        "homepage" : null,
        "name" : "pyvidplayer2",
        "fullName" : "anrayliu/pyvidplayer2",
        "htmlUrl" : "https://github.com/anrayliu/pyvidplayer2",
        "gitUrl" : "git://github.com/anrayliu/pyvidplayer2.git",
        "sshUrl" : "git@github.com:anrayliu/pyvidplayer2.git",
        "cloneUrl" : "https://github.com/anrayliu/pyvidplayer2.git",
        "owner" : {
          "login" : "anrayliu",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 59,
        "watchersCount" : 59,
        "size" : 158772,
        "openIssuesCount" : 4,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-11T04:23:02Z",
        "languages" : {
          "Python" : 212454
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve code hygiene by installing pylint and making fixes",
      "validationOrRequirement" : "No specific validations or requirements mentioned",
      "attemptedFixes" : "No attempted fixes or blockers mentioned",
      "otherNotes" : "Install pylint from pypi and try to make as many fixes as possible. No matter how small, everything helps",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285008
  }, {
    "issueDTO" : {
      "id" : 3145538895,
      "title" : "Add an otion to automatically match package/bundle versions to the one in the workspace",
      "url" : "https://github.com/eclipse-pde/eclipse.pde/issues/1814",
      "repositoryName" : "eclipse-pde/eclipse.pde",
      "description" : "If one go to the manifest and edit a package or bundle required, there is an option to match the versions.\n\nIt would be good to have the same in the \"Organize Manifest\" Wizard, so it can be applied in batch to many projects and in combination with the new [tycho-cleancode:manifest](https://tycho.eclipseprojects.io/doc/main/tycho-cleancode-plugin/manifest-mojo.html) mojo.",
      "updatedAt" : 1752206225.000000000,
      "user" : "laeubi",
      "userHtmlUrl" : "https://github.com/laeubi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1331477?v=4",
      "labels" : [ "organize-manifest", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'm working on this", "> I'm working on this\n\nWelcome, I assume you are a student from CodeDays, aren't you? The following pages should help you to get started:\n- https://github.com/eclipse-ide/\n- https://github.com/eclipse-pde/eclipse.pde?tab=readme-ov-file#how-to-contribute\n\nand if you have further questions, don't hesitate to ask, we are here to help.", "Yes, I am. Thanks for the info.", "Question: When contributing code, should I use GitHub Codespaces or the Eclipse IDE?", "The IDE\n\nhttps://github.com/eclipse-pde/eclipse.pde?tab=readme-ov-file#how-to-contribute", "Got it, thanks!", "My team and I have compiled a couple of questions that we were hoping to get answered...\n\n1. How do we properly import the files over to the IDE so that we can work on them?\n2. How do we submit the finished code?\n3. Is the ticket asking us to modify two files or just one?\n4. How does this version-matching feature interact with tycho-cleancode: manifest? Do we need to implement any specific support or changes for that integration?\n5. From what we understand, the manifest editor already supports version matching when editing bundles or packages manually. For this issue, are we expected to reuse that existing version-matching logic and add it to the existing \"Organize Manifest\" wizard, or do we need to implement it as a separate feature?\n", "1. See @HannesWell answer above\n2. https://gist.github.com/Chaser324/ce0505fbed06b947d962\n3. As much files as needed\n4. Tycho will not need to be changed as part of this ticket\n5. You should look at that feature, examine how it works and then decide if it would be useful to reuse the existing functionality (what might require some refactorings) or if it should just be adopted in a similar way" ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "eclipse.pde",
        "fullName" : "eclipse-pde/eclipse.pde",
        "htmlUrl" : "https://github.com/eclipse-pde/eclipse.pde",
        "gitUrl" : "git://github.com/eclipse-pde/eclipse.pde.git",
        "sshUrl" : "git@github.com:eclipse-pde/eclipse.pde.git",
        "cloneUrl" : "https://github.com/eclipse-pde/eclipse.pde.git",
        "owner" : {
          "login" : "eclipse-pde",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 114,
        "stargazersCount" : 31,
        "watchersCount" : 31,
        "size" : 133316,
        "openIssuesCount" : 282,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-11T22:04:35Z",
        "languages" : {
          "Java" : 26029982,
          "CSS" : 18383,
          "Shell" : 4197,
          "JavaScript" : 7081,
          "HTML" : 1162730,
          "XSLT" : 20815
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add an option to automatically match package/bundle versions to the one in the workspace in the 'Organize Manifest' Wizard, so it can be applied in batch to many projects and in combination with the new tycho-cleancode:manifest mojo.",
      "validationOrRequirement" : "The issue requires the contributor to properly import the files to the IDE, submit the finished code, and understand how the version-matching feature interacts with tycho-cleancode:manifest.",
      "attemptedFixes" : "The contributor is asked to look at the existing version-matching logic in the manifest editor and decide whether to reuse it or implement a similar feature.",
      "otherNotes" : "The issue is related to tycho-cleancode:manifest, and the contributor is expected to examine the existing version-matching logic in the manifest editor and decide whether to reuse it or implement a similar feature.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285014
  }, {
    "issueDTO" : {
      "id" : 1745943567,
      "title" : "Confusing SWT Style Bits in CSS Spy",
      "url" : "https://github.com/eclipse-pde/eclipse.pde/issues/611",
      "repositoryName" : "eclipse-pde/eclipse.pde",
      "description" : "\r\n![image](https://github.com/eclipse-pde/eclipse.pde/assets/44021373/996918d4-5498-4737-8e74-0b244809668a)\r\n\r\nThe **CSS Rules** section of **CSS Spy** shows the current **SWT Style Bits** for the selected control, but it seems to contain a lot of useless information, such as styles that are not currently supported by the selected control (e.g. `SWT.RADIO` here), and bits that are not styles (e.g. `SWT.ERROR_MENU_NOT_POP_UP` here). Why is it designed this way, and what is the use of these ?",
      "updatedAt" : 1752206026.000000000,
      "user" : "JVS94",
      "userHtmlUrl" : "https://github.com/JVS94",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/44021373?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "The filter should display the correct styles bits as described in this page : \r\nhttps://wiki.eclipse.org/SWT_Widget_Style_Bits\r\n\r\nI think the idea is to remind what could be used on this widget... but ...as we are in a dynamic display,  it would be better to display in bold if the style bit is set and in normal fond if not set. Using the Widget.getStyle() method that would be easy to do. \r\n\r\n-> Good first issue\r\n\r\n", "I am working on this! \r\n- CodeDay Student. ", "I'm working on this", "> I'm working on this\n\nWelcome, I assume you are a student from CodeDays, aren't you? The following pages should help you to get started:\n- https://github.com/eclipse-ide/\n- https://github.com/eclipse-pde/eclipse.pde?tab=readme-ov-file#how-to-contribute\n\nand if you have further questions, don't hesitate to ask, we are here to help.", "Hey guys, I'm working on this issue in a group with ahenden13. We were wondering if anybody has thoughts on how we should format the display, as there is a lot of unhelpful information. \n\nWe are inclined to just remove these useless bits, but we could also just remove the error bits, leave everything and bold the set bits, etc. If anyone has any input it would be appreciated!", "I think the main issue is that you can not know programmatically what styles a widget support at the moment.\n\nSo the first thing would be to have some declarative way (e.g. an annotation) to carry that information and update all widgets to use that thing before one can make progress here. Hardcoding the supported styles seem not very useful to me." ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "eclipse.pde",
        "fullName" : "eclipse-pde/eclipse.pde",
        "htmlUrl" : "https://github.com/eclipse-pde/eclipse.pde",
        "gitUrl" : "git://github.com/eclipse-pde/eclipse.pde.git",
        "sshUrl" : "git@github.com:eclipse-pde/eclipse.pde.git",
        "cloneUrl" : "https://github.com/eclipse-pde/eclipse.pde.git",
        "owner" : {
          "login" : "eclipse-pde",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 114,
        "stargazersCount" : 31,
        "watchersCount" : 31,
        "size" : 133316,
        "openIssuesCount" : 282,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-11T22:04:35Z",
        "languages" : {
          "Java" : 26029982,
          "CSS" : 18383,
          "Shell" : 4197,
          "JavaScript" : 7081,
          "HTML" : 1162730,
          "XSLT" : 20815
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about the confusing SWT Style Bits in CSS Spy, which shows the current SWT Style Bits for the selected control, but contains a lot of useless information.",
      "validationOrRequirement" : "The issue requires a declarative way (e.g. an annotation) to carry the information about what styles a widget supports at the moment. Hardcoding the supported styles seem not very useful.",
      "attemptedFixes" : "The idea is to display in bold if the style bit is set and in normal font if not set. Using the Widget.getStyle() method would be easy to do. Some declarative way (e.g. an annotation) to carry the information about what styles a widget supports at the moment is also suggested.",
      "otherNotes" : "The issue is related to displaying SWT Style Bits in CSS Spy, which shows current style bits for the selected control, but contains useless information. The idea is to remind what could be used on this widget, but it would be better to display in bold if the style bit is set and in normal font if not set. Using the Widget.getStyle() method would be easy to do. The issue is also related to formatting the display, as there is a lot of unhelpful information.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285022
  }, {
    "issueDTO" : {
      "id" : 3214401578,
      "title" : "Markdown table render failed",
      "url" : "https://github.com/refly-ai/refly/issues/1065",
      "repositoryName" : "refly-ai/refly",
      "description" : "**Describe the bug**\nTables are not properly rendered in response markdown:\n\n<img width=\"643\" height=\"362\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/a43969df-65c2-49b1-b797-a5e860d957a6\" />\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See error\n\n**Expected behavior**\nA clear and concise description of what you expected to happen.\n\n**Screenshots**\nIf applicable, add screenshots to help explain your problem.\n\n**Desktop (please complete the following information):**\n - OS: [e.g. iOS]\n - Browser [e.g. chrome, safari]\n - Version [e.g. 22]\n\n**Smartphone (please complete the following information):**\n - Device: [e.g. iPhone6]\n - OS: [e.g. iOS8.1]\n - Browser [e.g. stock browser, safari]\n - Version [e.g. 22]\n\n**Additional context**\nAdd any other context about the problem here.\n",
      "updatedAt" : 1752204783.000000000,
      "user" : "mrcfps",
      "userHtmlUrl" : "https://github.com/mrcfps",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/23410977?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The world's first open-source \"Vibe Workflow\" platform for complex tasks.",
        "homepage" : "https://refly.ai",
        "name" : "refly",
        "fullName" : "refly-ai/refly",
        "htmlUrl" : "https://github.com/refly-ai/refly",
        "gitUrl" : "git://github.com/refly-ai/refly.git",
        "sshUrl" : "git@github.com:refly-ai/refly.git",
        "cloneUrl" : "https://github.com/refly-ai/refly.git",
        "owner" : {
          "login" : "refly-ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 369,
        "stargazersCount" : 4295,
        "watchersCount" : 4295,
        "size" : 79229,
        "openIssuesCount" : 111,
        "subscribersCount" : 28,
        "pushedAt" : "2025-07-11T15:20:44Z",
        "languages" : {
          "TypeScript" : 6834949,
          "Dockerfile" : 3505,
          "CSS" : 60096,
          "Shell" : 1688,
          "SCSS" : 164138,
          "JavaScript" : 48240,
          "HTML" : 4223
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to render tables properly in response markdown.",
      "validationOrRequirement" : "No specific validations or requirements are mentioned in the issue description.",
      "attemptedFixes" : "No attempted fixes or blockers are mentioned in the issue description.",
      "otherNotes" : "Tables are not properly rendered in response markdown, with a screenshot provided for reference. The issue is labeled as a bug and good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285025
  }, {
    "issueDTO" : {
      "id" : 2050206964,
      "title" : "feat: work as a drop-in ls replacement",
      "url" : "https://github.com/eza-community/eza/issues/736",
      "repositoryName" : "eza-community/eza",
      "description" : "Currently, `exa` doesn't support the `-t` flag in the same way as `ls`, so it won't work as a drop in replacement. That is, `ls -ltra` works, but `exa -ltra` won't work.\r\n\r\nAn issue existed at the exa repository for this: https://github.com/ogham/exa/issues/519\r\n\r\nI also wrote a patch fixing this: https://github.com/ogham/exa/commit/fa76a335fd40d1f81b656b3d602309e7d39bed2f\r\n\r\nI tried cherry-picking this, but some conflicts seem non-trivial. I'd appreciate hearing some feedback on the patch first, and if it looks good, I'll like to incorporate it into eza. Notably:\r\n\r\n- When `-t` is specified with arguments, it behaves much like `exa -t X`.\r\n- When `-t` is specified without arguments, it behaves like `ls`.",
      "updatedAt" : 1752204433.000000000,
      "user" : "WhyNotHugo",
      "userHtmlUrl" : "https://github.com/WhyNotHugo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/730811?v=4",
      "labels" : [ "Arguments", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "this can either be picked up by someone as I myself will wait/implement this in #640 but not in main branch", "> * When `-t` is specified with arguments, it behaves much like `exa -t X`.\r\n> \r\n> * When `-t` is specified without arguments, it behaves like `ls`.\r\n\r\nI don't think this can be done. This is because when parsing a single character argument, it is necessary to know if the corresponding argument requires an additional parameter.\r\n\r\nAccording to the existing parsing logic, a command line like `eza -tmodified` is valid. If, as suggested by @WhyNotHugo, `eza` can't tell whether the `ra` after the letter `t` in `eza -ltra` is another two arguments or the parameters belonging to `t`. This is ambiguity.", "Quite true. I guess the only options are to chose one of the following:\r\n\r\n- Remain compatible with exa.\r\n- Remain compatible with ls.", "> I don't think this can be done. This is because when parsing a single character argument, it is necessary to know if the corresponding argument requires an additional parameter.\r\n\r\nThis is doable, and we have what needed but as Clap is incoming I dont wanna take time to modify it, you are free to do it yourself tho.", "I've also discovered recently `ls -p` which suffixes folders with a `/`, making them more distinct, and that eza lacks:\r\n```\r\n??? eza -p                    \r\neza: Unknown argument -p\r\nhome on ??? boot-fixes via ??????  IMPURE (dotfiles-shell-env) \r\n???3 ??? eza --version  \r\neza - A modern, maintained replacement for ls\r\nv0.18.0 [+git]\r\nhttps://github.com/eza-community/eza\r\n```", "> I've also discovered recently `ls -p` which suffixes folders with a `/`, making them more distinct, and that eza lacks:\r\n> \r\n> ```\r\n> ??? eza -p                    \r\n> eza: Unknown argument -p\r\n> home on ??? boot-fixes via ??????  IMPURE (dotfiles-shell-env) \r\n> ???3 ??? eza --version  \r\n> eza - A modern, maintained replacement for ls\r\n> v0.18.0 [+git]\r\n> https://github.com/eza-community/eza\r\n> ```\r\n\r\nThis should probably be a separate issue, seems useful, and easy to implement, although I'm not much for using a single letter flag for this", "> I've also discovered recently ls -p which suffixes folders with a /, making them more distinct, and that eza lacks:\r\n\r\n`eza -F` works the same as it classifies which type of file it is, it then adds the `/` for directories and `*` for executables and '@' for links", ">eza -F works the same\r\n\r\n...it works the same unless you try something like `-Fl`.\r\n\r\nThe `-t` flag is my personal dealbreaking itch with this tool (I run `ls -lrt` ~~hundreds~~ zillions of times per day). I don't want to develop muscle memory for `-lsnew` and find myself fighting with vanilla linux.\r\n\r\nI haven't looked at the argument parsing code???is this kind of disambiguation for `ls` compatibility likely to be complicated to implement? I think we all have our repetitive behaviors with `ls`. If this kind of fix is unlikely to work with eza, I might go back to my ancient-but-functional color ls drop-in replacement.", "> I haven't looked at the argument parsing code???is this kind of disambiguation for ls compatibility likely to be complicated to implement?\r\n\r\nI implemented it and it works on many cases, but there are edge cases where it can be ambiguous ([as mentioned in a comment above](https://github.com/eza-community/eza/issues/736#issuecomment-1922736980)).", "> The `-t` flag is my personal dealbreaking itch with this tool (I run `ls -lrt` ~hundreds~ zillions of times per day). I don't want to develop muscle memory for `-lsnew` and find myself fighting with vanilla linux.\r\n\r\n@adrian-the-git Yes. It itches me too. So I made a script to wrap eza: when `-lrt` appears the script simply replaces it with `-lsnew`, then sends the argument to eza.", "Even if it's not `-t`, is there a possibility of adding some other short option for sorting by mtime? Like others have mentioned I used this *constantly* and I suppose I can add a new shell alias `lst` or `lat` but I would really love to see eza just stick closer to `ls` behavior here.", "This is also a dealbreaker for me. I run `ls -lart` too often at too many systems where I just have ls instead of eza. \r\n\r\nIdea: compability env variable for those options? EZA_LS_COMPABILITY=1 ?", "> This is also a dealbreaker for me. I run `ls -lart` too often at too many systems where I just have ls instead of eza.\r\n> \r\n> Idea: compability env variable for those options? EZA_LS_COMPABILITY=1 ?\r\n\r\nOur plan is to introduce a flag that makes eza ls compatible, this is gonna be done after the clap migration", "A lot of specific feedback seems to get lost in this thread, if you have some feature request, make sure to create a separate issue for it, I just see \"work as drop-in replacement\" in the issue tracker, but there are suggestions here like a short flag for sorting by mtime that likely have a harder time being picked up by contributors from not having their own issue", "> Our plan is to introduce a flag that makes eza ls compatible, this is gonna be done after the clap migration\r\n\r\nspeaking of that if anyone wanna help review it as its a long standing pr we will accept the help", "I'm a yet another `-t` flag user. I went with a script by @kesor:\r\n- https://github.com/eza-community/eza/issues/980#issuecomment-2499761779\r\n\r\n1. save to `~/.local/bin/eza-ls`, make file executable\r\n2. I modified `eza-ls` to remove `/usr/bin` from final exec, mine is installed by brew to `/opt/homebrew/bin/eza`\r\n3. ensure `~/.local/bin` is in `$PATH`\r\n4. add `alias ls=eza-ls` to `.zshrc`\r\n5. the rest of `ls` based aliases continue to work", "-lrt a gazillion times for me, too.  Muscle memory.\n\nI am removing my alias ls=???eza???\n\nI will revisit when you fix this.\n\nIt???s not drop in replacement as advertized???", "I wrote this simple wrapper script to deal with the hassle of `-lrt`. It???s not perfect, but it solves 90% of the problem and works really well. If you need it too, you can name it `eza` and put it in a directory that???s in your `PATH`. Just make sure this directory comes before the one containing the real `eza`, so the wrapper overrides the original. Alternatively, you can name it `ls` and place it before the real `ls` in your PATH.\n\n```bash\n#!/usr/bin/env bash\nif [[ \"$1\" = \"-lrt\" ]]; then\n    set -- \"-lsnew\" \"${@:2}\"\nfi\nexec /path/to/real/eza \"$@\"\n```", "> I wrote this simple wrapper script to deal with the hassle of `-lrt`.\n@moonfruit\n\nWhen you want something more comprehensive, try this https://gist.github.com/kesor/6e094187c85f05c30fc923d6923c1073", "Thanks @kesor. I do have a more complicated script designed for myself. But I don???t think it???s suitable for most people. So I didn???t include it here, but shared a simpler script instead. I just wanted to solve this problem in a simple way for most people, without introducing too many other things." ],
      "repository" : {
        "description" : "A modern alternative to ls",
        "homepage" : "https://eza.rocks",
        "name" : "eza",
        "fullName" : "eza-community/eza",
        "htmlUrl" : "https://github.com/eza-community/eza",
        "gitUrl" : "git://github.com/eza-community/eza.git",
        "sshUrl" : "git@github.com:eza-community/eza.git",
        "cloneUrl" : "https://github.com/eza-community/eza.git",
        "owner" : {
          "login" : "eza-community",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 304,
        "stargazersCount" : 16285,
        "watchersCount" : 16285,
        "size" : 8432,
        "openIssuesCount" : 266,
        "subscribersCount" : 32,
        "pushedAt" : "2025-07-08T02:39:09Z",
        "languages" : {
          "Shell" : 16741,
          "Rust" : 666972,
          "Nushell" : 4485,
          "Nix" : 10107,
          "Just" : 11275,
          "Brainfuck" : 176
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to make `eza` a drop-in replacement for `ls`, which is not currently possible due to the issues with the `-t` flag. Some users have created workarounds, but these are not ideal solutions.",
      "validationOrRequirement" : "The issue requires a way to disambiguate single character arguments, and to add additional parameters when necessary. This may require changes to the parsing logic, and may also require adding a flag for sorting by mtime.",
      "attemptedFixes" : "Several users have created workarounds, including scripts that replace `-lrt` with `-lsnew`, and others have suggested adding an environment variable for compatibility with `ls` options. One user has also implemented a patch to fix the issue, but it requires some conflicts to be resolved.",
      "otherNotes" : "There are several issues with the current implementation of the `-t` flag in `eza`, including ambiguity when parsing single character arguments, and the need to add additional parameters. Some users have created workarounds, such as scripts that replace `-lrt` with `-lsnew`, but this is not a drop-in replacement for `ls`. The issue is also discussed in the context of adding a flag for sorting by mtime, and the possibility of adding an environment variable for compatibility with `ls` options.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285034
  }, {
    "issueDTO" : {
      "id" : 3221357619,
      "title" : "Weaken type for repeated arrays",
      "url" : "https://github.com/flux-rs/flux/issues/1177",
      "repositoryName" : "flux-rs/flux",
      "description" : "Currently [this fails](https://flux.goto.ucsd.edu/?code=KyhNUkjLU6jMzE4t1tBUqOZSAIKc1BKF3NIShaTSNAVbhegkdQN1awXLWGuwJFAw2iAWKA4R1tdXyM9GlzCESBSlZqUml6SmcNUCAA==)\n\n```rust\npub fn yikes() {\n    let mut buf = [b'0'; 9];\n    buf[0] = b'0'; // ok\n    buf[0] = b'1'; // rejected\n}\n```\n\n@nilehmann [notes it is because]([#general > assignment into array seems too conservative? @ \uD83D\uDCAC](https://flux-rs.zulipchat.com/#narrow/channel/486098-general/topic/assignment.20into.20array.20seems.20too.20conservative.3F/near/528189754)) of \n\n```\n            Rvalue::Repeat(operand, c) => {\n                let ty = self\n                    .check_operand(infcx, env, stmt_span, operand)\n                    .with_span(stmt_span)?;\n                Ok(Ty::array(ty, c.clone()))\n            }\n```\n\nSo we should \"weaken\" the type for this `Repeat` thing.",
      "updatedAt" : 1752204340.000000000,
      "user" : "ranjitjhala",
      "userHtmlUrl" : "https://github.com/ranjitjhala",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1650232?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Refinement Types for Rust",
        "homepage" : "https://flux-rs.github.io/flux/",
        "name" : "flux",
        "fullName" : "flux-rs/flux",
        "htmlUrl" : "https://github.com/flux-rs/flux",
        "gitUrl" : "git://github.com/flux-rs/flux.git",
        "sshUrl" : "git@github.com:flux-rs/flux.git",
        "cloneUrl" : "https://github.com/flux-rs/flux.git",
        "owner" : {
          "login" : "flux-rs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 24,
        "stargazersCount" : 749,
        "watchersCount" : 749,
        "size" : 143811,
        "openIssuesCount" : 60,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-11T23:04:57Z",
        "languages" : {
          "TypeScript" : 32448,
          "CSS" : 48964,
          "Shell" : 3567,
          "RenderScript" : 73,
          "Rust" : 2418835,
          "JavaScript" : 41409,
          "Fluent" : 17345,
          "HTML" : 364,
          "Python" : 5615
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Weaken the type for repeated arrays to allow assignment into arrays",
      "validationOrRequirement" : "The type check in Repeat operation should be less conservative",
      "attemptedFixes" : "The fix is to 'weaken' the type for the Repeat operation",
      "otherNotes" : "The issue is due to the type check in Repeat operation being too conservative, which is causing the assignment to an array to fail. This is noted in the Zulip chat.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285037
  }, {
    "issueDTO" : {
      "id" : 3219158217,
      "title" : "Does it support multi-pages resume?",
      "url" : "https://github.com/RylanBot/resume-json-pdf/issues/8",
      "repositoryName" : "RylanBot/resume-json-pdf",
      "description" : "I tried to change my resume from LaTeX to json. But found that the resume only has one page after uploading the json.\n\nHow can I set to get a multi-pages resume? Thk in advance.",
      "updatedAt" : 1752204142.000000000,
      "user" : "WncFht",
      "userHtmlUrl" : "https://github.com/WncFht",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/63136734?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "From a job-seeking perspective, a one-page resume is usually enough, so multi-page resumes haven't been implemented yet. But from an academic standpoint, one page really might be too short.\n\nI'll try adding this feature soon and get back to you with an update! In the meantime, you could try adjusting the margins to see if the resume can fit into one page.", "This feature is now supported in tonight???s commit https://github.com/RylanBot/resume-json-pdf/commit/cf0bbcdbdd4c7c64d63802e2299d1d0304fecd13 . See [the updated README](https://github.com/RylanBot/resume-json-pdf/commit/3ff0db409228118ca0192a9ff19967df7f6b13fd) for reference.\n\nIn short, set `page: 2` on the first `section` of page 2 ??? following sections will inherit this until `page: 3` is encountered.\n\nDue to the rushed code changes, if you find any bugs or have suggestions for improvements after using it, feel free to let me know.", "Thanks a lot, I will try the feature " ],
      "repository" : {
        "description" : "\uD83D\uDCD1 Build your PDF resume using a JSON file?????????????????????",
        "homepage" : "https://resume-json-pdf.rylan.cn",
        "name" : "resume-json-pdf",
        "fullName" : "RylanBot/resume-json-pdf",
        "htmlUrl" : "https://github.com/RylanBot/resume-json-pdf",
        "gitUrl" : "git://github.com/RylanBot/resume-json-pdf.git",
        "sshUrl" : "git@github.com:RylanBot/resume-json-pdf.git",
        "cloneUrl" : "https://github.com/RylanBot/resume-json-pdf.git",
        "owner" : {
          "login" : "RylanBot",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 255,
        "watchersCount" : 255,
        "size" : 1367,
        "openIssuesCount" : 3,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-11T21:36:19Z",
        "languages" : {
          "TypeScript" : 71152,
          "CSS" : 3071,
          "JavaScript" : 679,
          "HTML" : 474
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Does it support multi-pages resume? How can I set to get a multi-pages resume?",
      "validationOrRequirement" : "set `page: 2` on the first `section` of page 2 ??? following sections will inherit this until `page: 3` is encountered",
      "attemptedFixes" : "adjusting the margins to see if the resume can fit into one page",
      "otherNotes" : "From a job-seeking perspective, a one-page resume is usually enough, so multi-page resumes haven't been implemented yet. But from an academic standpoint, one page really might be too short. Due to the rushed code changes, if you find any bugs or have suggestions for improvements after using it, feel free to let me know.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285042
  }, {
    "issueDTO" : {
      "id" : 2631722904,
      "title" : "Tracking issues for migrating integration tests",
      "url" : "https://github.com/pingcap/ticdc/issues/442",
      "repositoryName" : "pingcap/ticdc",
      "description" : "This issues is used to track the progress of integration test migration. We plan to support all necessary integration tests by the end of February.\n\nIf you intend to help migrate a specific integration test, **please @ yourself** at the end of the case name to avoid conflicts in work.\n\n## P0  (1 / 1 task)\n- [x] [Migrate the integration test framework](https://github.com/pingcap/ticdc/pull/444)\n\n## P1 ( 72 / 73 tasks, mysql sink type)\n- [x] api_v2 @asddongmen #839 \n- [x] autorandom\n- [x] bank\n- [x] batch_add_table\n- [x] batch_update_to_no_batch \n- [x] bdr_mode @wk989898 \n- [x] cdc https://github.com/pingcap/ticdc/issues/898\n- [x] cdc_server_tips\n- [x] changefeed_finish\n- [x] changefeed_pause_resume  @hongyunyan \n- [x] changefeed_reconstruct\n- [x] [charset_gbk](https://github.com/pingcap/ticdc/pull/471)\n- [x] ci_collation_compatibility\n- [x] cli_tls_with_auth https://github.com/pingcap/ticdc/issues/862 @wk989898 @asddongmen #869 \n- [x] cli_with_auth https://github.com/pingcap/ticdc/issues/862 @wk989898 @asddongmen  #869 \n- [x] clustered_index @asddongmen (Not useful for new arch, since the `tidb_enable_clustered_index` is set to on by default in TiDB[ since v7.1.0](https://docs.pingcap.com/tidb/v7.1/system-variables#tidb_enable_clustered_index-new-in-v50). ) #793 \n- [x] common_1 @asddongmen #793 \n- [ ] consistent_replicate_nfs [redo is not supported now]\n- [x] ddl_attributes @wk989898 \n- [x] ddl_puller_lag [Not useful for new arch] @asddongmen  #793\n- [x] ddl_reentrant\n- [x] ddl_sequence \n- [x] default_value @asddongmen @lidezhu #794\n- [x] drop_many_tables @asddongmen #802 \n- [x] force_replicate_table @asddongmen \n- [x] foreign_key @asddongmen #793 \n- [x] generate_column @asddongmen #797 \n- [x] http_api  @asddongmen #839 \n- [x] http_api_tls @asddongmen #857 \n- [x] http_api_tls_with_user_auth @asddongmen #857 \n- [x] http_proxies @asddongmen  #863 \n- [x] many_pk_or_uk @asddongmen #802 \n- [x] move_table @asddongmen #906 \n- [x] multi_capture \n- [x] multi_cdc_cluster \n- [x] multi_rocks \n- [x] multi_source @hongyunyan \n- [x] multi_tables_ddl @lidezhu @hongyunyan  #937 #949 \n- [x] new_ci_collation @asddongmen #802 \n- [x] partition_table @asddongmen @lidezhu \n- [x] region_merge @asddongmen #802 \n- [x] resolve_lock #866  @wk989898 @lidezhu \n- [x] resource control \n- [x] row_format \n- [x] safe_mode https://github.com/pingcap/ticdc/pull/809\n- [x] savepoint \n- [x] sequence \n- [x] server_config_compatibility \n- [x] simple @wk989898 \n- [x] split_region\n- [x] sql_mode\n- [x] tidb_mysql_test\n- [x] tiflash\n- [x] vector\n- [x] fail_over @hongyunyan \n- [x] fail_over_ddl_A @hongyunyan \n- [x] fail_over_ddl_B @hongyunyan \n- [x] fail_over_ddl_C @hongyunyan \n- [x] fail_over_ddl_D @hongyunyan \n- [x] fail_over_ddl_E @hongyunyan \n- [x] fail_over_ddl_F @hongyunyan \n- [x] fail_over_ddl_G @hongyunyan \n- [x] fail_over_ddl_H @hongyunyan \n- [x] fail_over_ddl_I @hongyunyan \n- [x] fail_over_ddl_J @hongyunyan \n- [x] fail_over_ddl_K @hongyunyan \n- [x] fail_over_ddl_L @hongyunyan \n- [x] fail_over_ddl_M @hongyunyan \n- [x] fail_over_ddl_N @hongyunyan \n- [x] fail_over_ddl_O @hongyunyan \n- [x] fail_over_ddl_mix @hongyunyan \n- [x] fail_over_ddl_mix_with_syncpoint @hongyunyan \n- [x] overwrite_resume_with_syncpoint @hongyunyan  \n\n## P2 (19 / 35 tasks, no mysql sink type)\n\n- [x] avro_basic @wk989898 \n- [x] canal_json_adapter_compatibility [use canal-adapter to sync data from kafka to mysql]\n- [x] canal_json_basic @wk989898 \n- [x] canal_json_claim_check @wk989898 \n- [x] canal_json_content_compatible @wk989898 \n- [x] canal_json_handle_key_only @wk989898 \n- [ ] canal_json_storage_basic @wk989898 \n- [ ] canal_json_storage_partition_table\n- [ ] csv_storage_basic @wk989898 \n- [x] csv_storage_multi_tables_ddl @wk989898 \n- [x] csv_storage_partition_table \n- [ ] csv_storage_update_pk_clustered https://github.com/pingcap/ticdc/issues/983\n- [ ] csv_storage_update_pk_nonclustered https://github.com/pingcap/ticdc/issues/983\n- [x] debezium @wk989898 \n- [x] debezium_basic @wk989898 \n- [x] kafka_big_messages https://github.com/pingcap/ticdc/issues/872 @wk989898 \n- [x] kafka_big_messages_v2 https://github.com/pingcap/ticdc/issues/872 @wk989898 \n- [x] kafka_column_selector @wk989898 \n- [ ] kafka_column_selector_avro\n- [x] kafka_compression @wk989898 \n- [x] kafka_messages @wk989898 \n- [x] kafka_simple_basic @wk989898 \n- [x] kafka_simple_basic_avro @wk989898 \n- [x] kafka_simple_claim_check @wk989898 \n- [x] kafka_simple_claim_check_avro @wk989898 \n- [x] kafka_simple_handle_key_only @wk989898 \n- [x] kafka_simple_handle_key_only_avro @wk989898 \n- [x] lossy_ddl @wk989898 \n- [x] mq_sink_dispatcher @wk989898 \n- [x] multi_topics https://github.com/pingcap/ticdc/pull/1058 @wk989898 \n- [x] multi_topics_v2 @wk989898 \n- [x] open_protocol_claim_check https://github.com/pingcap/ticdc/pull/1039 @wk989898 \n- [x] open_protocol_handle_key_only @wk989898 \n- [x] storage_cleanup https://github.com/pingcap/ticdc/pull/1035 @wk989898 \n- [ ] storage_csv_update https://github.com/pingcap/ticdc/issues/983\n\n## P3(22 / 32 tasks, With failpoint enabled)\n- [x] availability @asddongmen  #839 \n- [x] capture_session_done_during_task @asddongmen #926 \n- [x] capture_suicide_while_balance_table @asddongmen #952 \n- [x] changefeed_auto_stop [Not useful for new arch] @asddongmen  #943 \n- [x] changefeed_dup_error_restart @asddongmen #943 \n- [x] changefeed_error @asddongmen #930 \n- [x] changefeed_fast_fail @asddongmen #916 \n- [x] changefeed_resume_with_checkpoint_ts  @asddongmen #952 \n- [ ] consistent_partition_table \n- [ ] consistent_replicate_ddl\n- [ ] consistent_replicate_gbk\n- [ ] consistent_replicate_storage_file\n- [ ] consistent_replicate_storage_file_large_value\n- [ ] consistent_replicate_storage_s3\n- [x] ddl_manager [Not useful for new arch] @asddongmen #793 \n- [x] ddl_only_block_related_table [Not useful for new arch] @asddongmen #793 \n- [ ] event_filter [event filter is not support now]\n- [x] gc_safepoint @asddongmen #950 \n- [ ] mq_sink_error_resume #1481\n- [x] kill_owner_with_ddl [Included in failover cases] @hongyunyan \n- [x] kv_client_stream_reconnect @asddongmen #952 \n- [x] owner_remove_table_error [Not useful for new arch] @asddongmen #952 \n- [x] owner_resign [Included in availability case] @asddongmen \n- [x] processor_err_chan [Not useful for new arch] @asddongmen #799\n- [x] processor_etcd_worker_delay [Not useful for new arch] @asddongmen #799\n- [x] processor_resolved_ts_fallback [Not useful for new arch] @asddongmen #799\n- [x] processor_stop_delay [Not useful for new arch]  @asddongmen #799\n- [x] sink_hang [already included in mysql_sink_retry] @asddongmen  #943 \n- [x] mysql_sink_retry @asddongmen #943 \n- [ ] synced_status[not support yet] \n- [ ] synced_status_with_redo[not support yet]\n- [x] syncpoint @hongyunyan \n\n## P4 (0 / 1 task)\n- [ ] Refactor the test framework (if necessary), eg: deploy the test cluster with docker compose ",
      "updatedAt" : 1752204128.000000000,
      "user" : "CharlesCheung96",
      "userHtmlUrl" : "https://github.com/CharlesCheung96",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/61726649?v=4",
      "labels" : [ "help wanted", "type/enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "**-----------Total Summary-------------**\nTask Completion Statistics: 2025-01-13\n\nTotal tasks:     140\nCompleted tasks: 69\nCompletion rate: 49.3%", "-----------Total Summary-------------\nTask Completion Statistics: 2025-01-15\n\nTotal tasks:     140\nCompleted tasks: 82\nCompletion rate: 58.3%", "-----------Total Summary-------------\nTask Completion Statistics: 2025-01-24\n\nTotal tasks: 140\nCompleted tasks: 100\nCompletion rate: 71.4%", "-----------Total Summary-------------\nTask Completion Statistics: 2025-03-04\n\nTotal tasks: 142\nCompleted tasks: 112\nCompletion rate: 78.9%" ],
      "repository" : {
        "description" : "TiCDC pulls change logs out of TiDB and pushes to kinds of systems.",
        "homepage" : "",
        "name" : "ticdc",
        "fullName" : "pingcap/ticdc",
        "htmlUrl" : "https://github.com/pingcap/ticdc",
        "gitUrl" : "git://github.com/pingcap/ticdc.git",
        "sshUrl" : "git@github.com:pingcap/ticdc.git",
        "cloneUrl" : "https://github.com/pingcap/ticdc.git",
        "owner" : {
          "login" : "pingcap",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 23,
        "stargazersCount" : 28,
        "watchersCount" : 28,
        "size" : 96751,
        "openIssuesCount" : 116,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-11T05:47:47Z",
        "languages" : {
          "Shell" : 667576,
          "PLpgSQL" : 27927,
          "Makefile" : 13887,
          "Go" : 5504932,
          "ReScript" : 18544,
          "Python" : 43146
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Tracking issues for migrating integration tests",
      "validationOrRequirement" : "The requirement is to complete all necessary integration tests by the end of February, and contributors are asked to follow the naming convention of @ing themselves at the end of the case name to avoid conflicts in work.",
      "attemptedFixes" : "The issue is tracked through the task completion statistics provided in the comments, which show the progress of task completion over time.",
      "otherNotes" : "This issue is used to track the progress of integration test migration. The goal is to support all necessary integration tests by the end of February. Contributors are asked to @ themselves at the end of the case name to avoid conflicts in work.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285048
  }, {
    "issueDTO" : {
      "id" : 3022594802,
      "title" : "Support more backends beyond Redis?",
      "url" : "https://github.com/LMCache/LMCache/issues/534",
      "repositoryName" : "LMCache/LMCache",
      "description" : "**Is your feature request related to a problem? Please describe.**\n\nWhile LMCache effectively serves as \"Redis for LLM,\" I want discuss to see if LMCache maintainers are interested in expanding support beyond Redis to include alternative storage backends such as Memcached.\n\nAre LMCache maintainers open to more backend support?\n\n\n**Describe the solution you'd like**\n\nI propose integrating [Apache OpenDAL](https://opendal.apache.org/) into this project. OpenDAL would provide a unified interface for multiple storage backends including Memcached, Redis, Moka, RocksDB, object storage and others. \n\n**Describe alternatives you've considered**\nOther framwork/libraies to evaluate.\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n",
      "updatedAt" : 1752203739.000000000,
      "user" : "odysa",
      "userHtmlUrl" : "https://github.com/odysa",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22908409?v=4",
      "labels" : [ "stale", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for raising this issue and sharing this pointer!", "Hi, I'm the maintainer of opendal. Feel free to ping me if you need any help \uD83D\uDC8C ", "I took a look at the code, and it seems fairly straightforward to add opendal support, assuming the list part is optional. I???d be happy to submit a PR if you think this approach makes sense.\n\n--- \n\nHere are some services supported by OpenDAL that LMCache might be interested in:\n\n- fs (optional io-uring support)\n- moka (most widely used cache lib in rust)\n- rocksdb\n- object store (s3, azblob, gcs, ...)\n- [foyer](https://github.com/foyer-rs/foyer) (still working on it. It's the best hybird cache solution in rust)", "This issue has been automatically marked as stale because it has not had activity within 60 days. It will be automatically closed if no further activity occurs within 30 days." ],
      "repository" : {
        "description" : "Supercharge Your LLM with the Fastest KV Cache Layer",
        "homepage" : "https://lmcache.ai/",
        "name" : "LMCache",
        "fullName" : "LMCache/LMCache",
        "htmlUrl" : "https://github.com/LMCache/LMCache",
        "gitUrl" : "git://github.com/LMCache/LMCache.git",
        "sshUrl" : "git@github.com:LMCache/LMCache.git",
        "cloneUrl" : "https://github.com/LMCache/LMCache.git",
        "owner" : {
          "login" : "LMCache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 331,
        "stargazersCount" : 3005,
        "watchersCount" : 3005,
        "size" : 6427,
        "openIssuesCount" : 286,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-11T23:39:57Z",
        "languages" : {
          "Dockerfile" : 4714,
          "Shell" : 40566,
          "C++" : 1427,
          "C" : 2969,
          "Python" : 1221098,
          "Cuda" : 79977
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Discuss the possibility of expanding support beyond Redis to include alternative storage backends and propose integrating Apache OpenDAL into the project.",
      "validationOrRequirement" : "Support for alternative storage backends such as Memcached, and a unified interface for multiple storage backends including Memcached, Redis, Moka, RocksDB, object storage and others.",
      "attemptedFixes" : "The maintainer of OpenDAL offered help, and another comment suggested that adding OpenDAL support seems fairly straightforward, assuming the list part is optional, and would be happy to submit a PR if the approach makes sense.",
      "otherNotes" : "This issue has been automatically marked as stale because it has not had activity within 60 days. It will be automatically closed if no further activity occurs within 30 days.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285053
  }, {
    "issueDTO" : {
      "id" : 3221292519,
      "title" : "[Bug]: Python experiments and dataflow_service_options do not handle comma separated options",
      "url" : "https://github.com/apache/beam/issues/35563",
      "repositoryName" : "apache/beam",
      "description" : "### What happened?\n\nIn Beam Java SDK, one can add experiments `--experiments=abc,def`, `--dataflowServiceOptions=abc=true,def=true`, but in Python SDK, `--experiments=abc,def` will end up with an experiment named `abc,def`\n\n### Issue Priority\n\nPriority: 2 (default / most bugs should be filed as P2)\n\n### Issue Components\n\n- [x] Component: Python SDK\n- [ ] Component: Java SDK\n- [ ] Component: Go SDK\n- [ ] Component: Typescript SDK\n- [ ] Component: IO connector\n- [ ] Component: Beam YAML\n- [ ] Component: Beam examples\n- [ ] Component: Beam playground\n- [ ] Component: Beam katas\n- [ ] Component: Website\n- [ ] Component: Infrastructure\n- [ ] Component: Spark Runner\n- [ ] Component: Flink Runner\n- [ ] Component: Samza Runner\n- [ ] Component: Twister2 Runner\n- [ ] Component: Hazelcast Jet Runner\n- [ ] Component: Google Cloud Dataflow Runner",
      "updatedAt" : 1752201976.000000000,
      "user" : "Abacn",
      "userHtmlUrl" : "https://github.com/Abacn",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8010435?v=4",
      "labels" : [ "python", "P2", "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "To fix this one needs to implement a custom argparse action and set it here\n\nhttps://github.com/apache/beam/blob/9039608560c514fdae6034f2534120cbb16ac090/sdks/python/apache_beam/options/pipeline_options.py#L1415\n\nhttps://github.com/apache/beam/blob/9039608560c514fdae6034f2534120cbb16ac090/sdks/python/apache_beam/options/pipeline_options.py#L980" ],
      "repository" : {
        "description" : "Apache Beam is a unified programming model for Batch and Streaming data processing.",
        "homepage" : "https://beam.apache.org/",
        "name" : "beam",
        "fullName" : "apache/beam",
        "htmlUrl" : "https://github.com/apache/beam",
        "gitUrl" : "git://github.com/apache/beam.git",
        "sshUrl" : "git@github.com:apache/beam.git",
        "cloneUrl" : "https://github.com/apache/beam.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4370,
        "stargazersCount" : 8210,
        "watchersCount" : 8210,
        "size" : 846984,
        "openIssuesCount" : 4557,
        "subscribersCount" : 255,
        "pushedAt" : "2025-07-11T23:41:34Z",
        "languages" : {
          "C" : 3869,
          "Go" : 6989480,
          "HTML" : 208403,
          "Groovy" : 349286,
          "Jupyter Notebook" : 61188,
          "FreeMarker" : 10602,
          "PureBasic" : 506,
          "TypeScript" : 2018077,
          "Shell" : 415197,
          "SCSS" : 319433,
          "JavaScript" : 129849,
          "Lua" : 3620,
          "Cython" : 77215,
          "Python" : 14032536,
          "Thrift" : 3260,
          "Java" : 49932252,
          "CSS" : 9195,
          "Rust" : 5168,
          "Scala" : 1423,
          "Sass" : 27577,
          "Kotlin" : 156846,
          "HCL" : 226727,
          "Dockerfile" : 79217,
          "ANTLR" : 1598,
          "Dart" : 1436710
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to handle comma-separated options in Python SDK, specifically with --experiments and --dataflowServiceOptions, to match the behavior of the Java SDK.",
      "validationOrRequirement" : "Implement a custom argparse action to handle comma-separated options in Python SDK.",
      "attemptedFixes" : "A custom argparse action needs to be implemented to fix this issue.",
      "otherNotes" : "The issue is related to the handling of comma-separated options in Python SDK, specifically with --experiments and --dataflowServiceOptions, and the provided links point to the relevant code snippets.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285057
  }, {
    "issueDTO" : {
      "id" : 340698948,
      "title" : "need to change TIME_COP_PROCESS to TIME_COP_WAIT",
      "url" : "https://github.com/pingcap/tidb/issues/7044",
      "repositoryName" : "pingcap/tidb",
      "description" : "Take this log as an example:\r\n```sql\r\n2018/07/12 23:40:03.287 coprocessor.go:689: [info] [TIME_COP_PROCESS] resp_time:11.9717251s txn_start_ts:401449940753055943 region_id:2 store_addr:10.0.1.5:20160 kv_process_ms:1702 scan_total_write:692145 scan_processed_write:692144 scan_total_data:0 scan_processed_data:0 scan_total_lock:1 scan_processed_lock:0 kv_wait_ms:10264\r\n```\r\n\r\n- `kv_wait_ms`: 10264ms\r\n- `kv_process_ms`: 1702ms\r\n\r\n`kv_wait_ms` is far more larger than `kv_process_ms` and this slow coprocessor task is mainly caused by the wait, but we still printed the `TIME_COP_PROCESS`.\r\n\r\nThe source code to log this entry is here in file **store/tikv/coprocessor.go**:\r\n```go\r\n659         if waitMs > minLogKVWaitTime {\r\n660             logStr += fmt.Sprintf(\" kv_wait_ms:%d\", waitMs)\r\n661             if processMs <= minLogKVProcessTime {\r\n662                 logStr = strings.Replace(logStr, \"TIME_COP_PROCESS\", \"TIME_COP_WAIT\", 1)\r\n663             }\r\n664         }\r\n```\r\n\r\nWe should change `TIME_COP_PROCESS` to `TIME_COP_WAIT` when `kv_wait_ms` > `kv_process_ms`\r\n",
      "updatedAt" : 1752201864.000000000,
      "user" : "zz-jason",
      "userHtmlUrl" : "https://github.com/zz-jason",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5268763?v=4",
      "labels" : [ "epic/slow-query", "help wanted", "type/enhancement", "sig/execution", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "but what if all process slow is mainly caused by wait???we may have no TIME_COP_PROCESS label in the log.", "@coocood The main concern is how we define **mainly**:\r\n- If `kv_process_ms` takes more than **50%** of the `resp_time`, we can say this slow coprocessor response is mainly caused by the process\r\n- If `kv_wait_ms ` takes more than **50%** of the `resp_time`, we can say this slow coprocessor response is mainly caused by the process\r\n\r\nIf you think 50% is too small, we can adjust this threshold to a proper value.", "Looking up many tidb log files is horrible. I think we should merge these two labels together.", "I think if `kv_process_ms` takes more than 10%, we can tag it `TIME_COP_PROCESS`.", "I want to give it a try.\r\nRemove the old replace strategy, and check if `kv_process_ms` takes less than 10% of `resp_time`, change log tag to `TIME_COP_WAIT`. Am i right?", "@supernan1994 It's great to hear that you are interested in this issue \uD83D\uDE04! But it seems that we might probably need some more discussion to get a better solution:\r\n1. @jackysp suggested to remove the `TIME_COP_PROCESS` and `TIME_COP_WAIT` labels and use a uniform label to log these messages.\r\n2. @coocood suggested to use the `TIME_COP_PROCESS` label once `kv_process_ms` takes more than `10%` of the total request time.", "Ok! If you reach an agreement, I am willing to help\uD83D\uDE04\uD83D\uDE04 @zz-jason " ],
      "repository" : {
        "description" : "TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.",
        "homepage" : "https://pingcap.com",
        "name" : "tidb",
        "fullName" : "pingcap/tidb",
        "htmlUrl" : "https://github.com/pingcap/tidb",
        "gitUrl" : "git://github.com/pingcap/tidb.git",
        "sshUrl" : "git@github.com:pingcap/tidb.git",
        "cloneUrl" : "https://github.com/pingcap/tidb.git",
        "owner" : {
          "login" : "pingcap",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5968,
        "stargazersCount" : 38714,
        "watchersCount" : 38714,
        "size" : 554824,
        "openIssuesCount" : 5191,
        "subscribersCount" : 1244,
        "pushedAt" : "2025-07-11T16:59:03Z",
        "languages" : {
          "Smarty" : 4720,
          "Yacc" : 421028,
          "Makefile" : 40192,
          "Go" : 47372082,
          "HTML" : 420,
          "Ragel" : 3669,
          "Jsonnet" : 130480,
          "TypeScript" : 61875,
          "Dockerfile" : 4658,
          "Shell" : 865354,
          "Starlark" : 1541432,
          "JavaScript" : 900,
          "Python" : 8947
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Change TIME_COP_PROCESS to TIME_COP_WAIT when kv_wait_ms > kv_process_ms",
      "validationOrRequirement" : "If kv_process_ms takes more than 50% of resp_time, log as TIME_COP_PROCESS; if kv_wait_ms takes more than 50% of resp_time, log as TIME_COP_WAIT; if kv_process_ms takes less than 10% of resp_time, log as TIME_COP_WAIT.",
      "attemptedFixes" : "Remove the old replace strategy, and check if kv_process_ms takes less than 10% of resp_time, change log tag to TIME_COP_WAIT.",
      "otherNotes" : "The main concern is how to define 'mainly'. If kv_process_ms takes more than 50% of the resp_time, we can say this slow coprocessor response is mainly caused by the process. If kv_wait_ms takes more than 50% of the resp_time, we can say this slow coprocessor response is mainly caused by the wait.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285063
  }, {
    "issueDTO" : {
      "id" : 3192862001,
      "title" : "[ENHANCEMENT][TS]: In-memory dataset usage in runExperiment parameters",
      "url" : "https://github.com/Arize-ai/phoenix/issues/8355",
      "repositoryName" : "Arize-ai/phoenix",
      "description" : "### Is your feature request related to a problem? Please describe.\n\nIt would be nice to run an experiment against an in-memory dataset, without persisting the dataset afterwards.\n\n### Describe the solution you'd like\n\nPass in a \"dataset\" via parameters, with examples, that is not persisted afterwards, instead of a dataset id.\n\nSomething like\n\n```ts\nconst experiment = await runExperiment({\n  dataset: {\n    name: \"qa-capital-france\",\n    description: \"Single-prompt dataset for capital city QA\",\n    examples: [\n      {\n        input: { prompt: \"What is the capital of France?\" },\n        output: { text: \"Paris\" },\n        metadata: {},\n      },\n    ],\n  },\n  task,\n  evaluators\n});\n```\n\n### Describe any alternative solutions you've considered\n\n_No response_\n\n### Additional context\n\nhttps://arize-ai.slack.com/archives/C04R3GXC8HK/p1751374792815499\n\n### Social Media Handle\n\n_No response_",
      "updatedAt" : 1752201859.000000000,
      "user" : "cephalization",
      "userHtmlUrl" : "https://github.com/cephalization",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8948924?v=4",
      "labels" : [ "enhancement", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ "Hi! Can I pick this up? I'm super interested in contributing to this framework and learning more about LLM evals." ],
      "repository" : {
        "description" : "AI Observability & Evaluation",
        "homepage" : "https://arize.com/docs/phoenix",
        "name" : "phoenix",
        "fullName" : "Arize-ai/phoenix",
        "htmlUrl" : "https://github.com/Arize-ai/phoenix",
        "gitUrl" : "git://github.com/Arize-ai/phoenix.git",
        "sshUrl" : "git@github.com:Arize-ai/phoenix.git",
        "cloneUrl" : "https://github.com/Arize-ai/phoenix.git",
        "owner" : {
          "login" : "Arize-ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 486,
        "stargazersCount" : 6281,
        "watchersCount" : 6281,
        "size" : 360511,
        "openIssuesCount" : 451,
        "subscribersCount" : 43,
        "pushedAt" : "2025-07-11T23:11:54Z",
        "languages" : {
          "TypeScript" : 3418006,
          "Smarty" : 1920,
          "Dockerfile" : 2844,
          "CSS" : 4383,
          "Batchfile" : 828,
          "PLpgSQL" : 25237,
          "Makefile" : 2417,
          "JavaScript" : 9811,
          "HTML" : 10389,
          "Jupyter Notebook" : 11595893,
          "Mako" : 635,
          "Python" : 5300468
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to enhance the runExperiment parameters to support in-memory dataset usage.",
      "validationOrRequirement" : "The proposed solution should allow running an experiment against an in-memory dataset without persisting the dataset afterwards.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to a problem where users want to run an experiment against an in-memory dataset without persisting the dataset afterwards. The solution proposed is to pass a dataset via parameters, with examples, instead of a dataset id.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285067
  }, {
    "issueDTO" : {
      "id" : 3215861570,
      "title" : "Extend which command to get all executables in $env.PATH",
      "url" : "https://github.com/nushell/nushell/issues/16140",
      "repositoryName" : "nushell/nushell",
      "description" : "### Related problem\n\nSometimes I am not sure what the external command name exactly is, so would like to get the list of all commands in the path (and then do some grepping/fzf/etc.. on it).\n\n### Describe the solution you'd like\n\nOne of the following would do:\n\n- either add possibility for `which` to accept regex (then I can get everything with something like `which -r \".*\"`)\n- or add a special switch/subcommand to `which` that would just dump all executables in the path\n\n### Describe alternatives you've considered\n\nThis nu command does it for me, but it is very slow (about 10sec):\n\n```nu\n$env.PATH | where { path exists } | each { path join '*' | glob -D $in | path basename } | flatten | uniq | which $in.0 ...($in | skip 1)\n```\n\nI hope that internal implementation would be much faster!\n\n### Additional context and details\n\nThere is a similar command in zsh: `hash`",
      "updatedAt" : 1752201471.000000000,
      "user" : "j-xella",
      "userHtmlUrl" : "https://github.com/j-xella",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8959819?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I think that's what `which -a` does.", "oh wait, you want every executable in the path. maybe more of an apropos command?", "> I think that's what `which -a` does.\n\n`which -a` still requires an argument and lists all executables **with the same name** in the path, in the order they are discovered.", "It looks like the easiest way to do this is to add a --regex(-r) parameter and then use https://docs.rs/which/latest/which/fn.which_re.html", "That would be a good solution. Also to remember that:\n\n- `which` also checks built-in commands and aliases, so regex should apply to that as well, no?\n- Since they do different things, `-r` and `-a` should work together properly", "Hi! Can I work on this issue? This would be my first contribution to Nushell, so any guidance would be appreciated. Thanks!", "Good luck! You might read through our [contributing document](https://github.com/nushell/nushell/blob/main/CONTRIBUTING.md).", "Thanks :) @fdncred  \nI'll ask you if I have any questions.\n" ],
      "repository" : {
        "description" : "A new type of shell",
        "homepage" : "https://www.nushell.sh/",
        "name" : "nushell",
        "fullName" : "nushell/nushell",
        "htmlUrl" : "https://github.com/nushell/nushell",
        "gitUrl" : "git://github.com/nushell/nushell.git",
        "sshUrl" : "git@github.com:nushell/nushell.git",
        "cloneUrl" : "https://github.com/nushell/nushell.git",
        "owner" : {
          "login" : "nushell",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1881,
        "stargazersCount" : 35715,
        "watchersCount" : 35715,
        "size" : 55839,
        "openIssuesCount" : 1579,
        "subscribersCount" : 194,
        "pushedAt" : "2025-07-11T17:14:02Z",
        "languages" : {
          "PowerShell" : 989,
          "Dockerfile" : 4148,
          "Shell" : 3955,
          "Rust" : 10670864,
          "Batchfile" : 765,
          "JavaScript" : 5557,
          "Nushell" : 294850,
          "Python" : 8420
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Extend which command to get all executables in $env.PATH",
      "validationOrRequirement" : "add possibility for which to accept regex (then I can get everything with something like which -r \".*\") or add a special switch/subcommand to which that would just dump all executables in the path",
      "attemptedFixes" : "This nu command does it for me, but it is very slow (about 10sec): $env.PATH | where { path exists } | each { path join '*' | glob -D $in | path basename } | flatten | uniq | which $in.0 ...($in | skip 1)",
      "otherNotes" : "There is a similar command in zsh: hash, which -a still requires an argument and lists all executables with the same name in the path, in the order they are discovered, which also checks built-in commands and aliases, so regex should apply to that as well, no?, - Since they do different things, -r and -a should work together properly, Hi! Can I work on this issue? This would be my first contribution to Nushell, so any guidance would be appreciated. Thanks!, Good luck! You might read through our [contributing document](https://github.com/nushell/nushell/blob/main/CONTRIBUTING.md)., Thanks :) @fdncred  I'll ask you if I have any questions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285076
  }, {
    "issueDTO" : {
      "id" : 3211271247,
      "title" : "[CHORE]: Script to add relative file path header to each file and verify top level docstring",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/317",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "### \uD83D\uDD27 Chore Summary\n\nCreate a script that automatically checks and optionally adds or fixes relative file path headers in source files. Each Python file should contain a standardized header with its relative path location for improved navigation and documentation consistency.\n\n---\n\n### \uD83E\uDDF1 Area Affected\n\nChoose the general area(s) that this chore affects:\n\n- [x] Pre-commit hooks / linters\n- [x] Formatting (black, isort, ruff, etc.)\n- [x] Build system or `Makefile`\n- [x] Docs or spellcheck\n\n---\n\n### ?????? Context / Rationale\n\nCurrently, source files lack consistent location headers, making it difficult to:\n- Navigate large codebases efficiently\n- Understand file organization when viewing individual files\n- Maintain documentation consistency across the project\n- Quickly identify file locations during code reviews\n\nThis script will standardize headers across all Python files with the format:\n```python\n# -*- coding: utf-8 -*-\n\"\"\"Module Description.\nLocation: ./relative/path/to/file.py\n\nCopyright 2025\nSPDX-License-Identifier: Apache-2.0\nAuthors: Mihai Criveti\n\nModule documentation...\n\"\"\"\n```\n\nThis reduces tech debt and improves developer experience by providing consistent file location context.\n\n---\n\n### \uD83D\uDCE6 Related Make Targets\n\nReference any relevant Makefile targets that are involved, if applicable:\n\n- `make lint` - run ruff, mypy, flake8, etc. (should pass after header updates)\n- `make pre-commit` - run pre-configured hooks (may need to handle new headers)\n- `make check-headers` - new target to validate file headers using `.github/tools/fix_file_headers.py --check`\n- `make fix-headers` - new target to automatically fix missing/incorrect headers using `.github/tools/fix_file_headers.py --fix-all`\n\n---\n\n### \uD83D\uDCCB Acceptance Criteria\n\nDefine what \"done\" looks like for this task.\n\n**Script Requirements:**\n- [ ] Script implemented at `.github/tools/fix_file_headers.py`\n- [ ] Script can scan all Python files in the project\n- [ ] Script can detect missing or incorrect relative path headers\n- [ ] Script provides interactive mode to review and approve changes\n- [ ] Script provides batch mode for automated fixes\n- [ ] Script preserves existing docstring content while updating location\n- [ ] Script handles edge cases (files without docstrings, existing headers, etc.)\n\n**Implementation Requirements:**\n- [ ] Script follows the standardized header format shown in example\n- [ ] All Python files have correct relative path headers after running\n- [ ] Headers maintain consistent formatting and structure\n- [ ] Copyright and license information is preserved/added consistently\n\n**Quality Checks:**\n- [ ] Linter runs cleanly (`make lint`)\n- [ ] CI passes with no regressions\n- [ ] No existing functionality is broken\n- [ ] Script can be integrated into pre-commit hooks (optional)\n\n**Documentation:**\n- [ ] Script usage is documented with examples\n- [ ] Makefile targets are added for header management\n- [ ] Header format is documented for future reference\n\n---\n\n### \uD83E\uDDE9 Additional Notes\n\n**Technical Implementation Notes:**\n- Script should be placed in `.github/tools/fix_file_headers.py`\n- Use Python's `ast` module to safely parse and modify Python files\n- Preserve original file encodings and line endings\n- Handle files that already have partial headers gracefully\n- Consider using `pathlib` for cross-platform path handling\n\n**File Selection Criteria:**\n- Target `.py` files in project directories\n- Exclude virtual environments, build directories, and `.git`\n- Focus on source code files (`mcpgateway/`, `tests/`, etc.)\n\n**Header Template Variables:**\n- `Location`: Relative path from project root (e.g., `./mcpgateway/services/gateway_service.py`)\n- `Copyright`: Current year (2025)\n- `Authors`: Configurable, default to \"Mihai Criveti\"\n- `License`: Apache-2.0 (consistent with project)\n\n**Integration Considerations:**\n- Script should be idempotent (safe to run multiple times)\n- Consider adding to pre-commit hooks for new files\n- May need to update existing CI/CD checks that parse file headers\n- Ensure script works with different Python file structures (modules, packages, scripts)\n\n**Example Command Usage:**\n```bash\n# Check which files need header updates (dry-run)\npython .github/tools/fix_file_headers.py --check\n\n# Interactively review and apply changes\npython .github/tools/fix_file_headers.py --interactive\n\n# Automatically fix all files (batch mode)\npython .github/tools/fix_file_headers.py --fix-all\n\n# Fix specific directory\npython .github/tools/fix_file_headers.py --fix --path mcpgateway/services/\n```",
      "updatedAt" : 1752200637.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "devops", "cicd", "chore", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a script that automatically checks and optionally adds or fixes relative file path headers in source files. Each Python file should contain a standardized header with its relative path location for improved navigation and documentation consistency.",
      "validationOrRequirement" : "Script Requirements: - Script implemented at .github/tools/fix_file_headers.py - Script can scan all Python files in the project - Script can detect missing or incorrect relative path headers - Script provides interactive mode to review and approve changes - Script provides batch mode for automated fixes - Script preserves existing docstring content while updating location - Script handles edge cases (files without docstrings, existing headers, etc.) - Implementation Requirements: - Script follows the standardized header format shown in example - All Python files have correct relative path headers after running - Headers maintain consistent formatting and structure - Copyright and license information is preserved/added consistently - Quality Checks: - Linter runs cleanly (make lint) - CI passes with no regressions - No existing functionality is broken - Script can be integrated into pre-commit hooks (optional) - Documentation: - Script usage is documented with examples - Makefile targets are added for header management - Header format is documented for future reference",
      "attemptedFixes" : "Script should be placed in .github/tools/fix_file_headers.py, use Python's ast module to safely parse and modify Python files, preserve original file encodings and line endings, handle files that already have partial headers gracefully, consider using pathlib for cross-platform path handling.",
      "otherNotes" : "The script should be implemented at .github/tools/fix_file_headers.py, it should scan all Python files in the project, detect missing or incorrect relative path headers, provide interactive mode to review and approve changes, provide batch mode for automated fixes, preserve existing docstring content while updating location, handle edge cases, follow standardized header format, maintain consistent formatting and structure, preserve copyright and license information consistently, and be integrated into pre-commit hooks.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285089
  }, {
    "issueDTO" : {
      "id" : 3211232662,
      "title" : "[CHORE] Check SPDX headers Makefile and GitHub Actions target - ensure all files have File, Author(s) and SPDX headers",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/315",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "### \uD83D\uDD27 Chore Summary\n\nCreate validation targets to ensure all Python source files contain proper SPDX license headers, copyright notices, and author information. This builds on the file path header script from task #317 to create comprehensive header validation for license compliance and proper attribution.\n\n---\n\n### \uD83E\uDDF1 Area Affected\n\nChoose the general area(s) that this chore affects:\n\n- [x] GitHub Actions / CI Pipelines\n- [x] Pre-commit hooks / linters\n- [x] Build system or `Makefile`\n- [x] SBOM, CVE scans, licenses, or security checks\n\n---\n\n### ?????? Context / Rationale\n\nLicense compliance and proper attribution require consistent license headers across all source files. Currently, the project uses Apache-2.0 license with SPDX identifiers, but not all files may have complete headers. \n\nThis task ensures:\n- Proper SPDX license identification for automated tools\n- Consistent copyright and authorship attribution\n- SBOM generation and license scanning accuracy\n\n---\n\n### \uD83D\uDCE6 Related Make Targets\n\nReference any relevant Makefile targets that are involved, if applicable:\n\n- `make lint` - run ruff, mypy, flake8, etc. (should include SPDX validation)\n- `make check-headers` - existing target from #317 (extend to include SPDX checks)\n- `make check-spdx` - new target to specifically validate SPDX/license headers\n- `make fix-spdx` - new target to automatically add missing SPDX headers\n- `make sbom` - generate CycloneDX software bill of materials (benefits from proper headers)\n- `make pip-licenses` - generate markdown license inventory (benefits from proper headers)\n- `make pre-commit` - run pre-configured hooks (should validate headers)\n\n---\n\n### \uD83D\uDCCB Acceptance Criteria\n\nDefine what \"done\" looks like for this task.\n\n**Header Validation Requirements:**\n- [ ] All Python files have proper encoding declaration (`# -*- coding: utf-8 -*-`)\n- [ ] All Python files have copyright notice (`Copyright 2025`)\n- [ ] All Python files have SPDX license identifier (`SPDX-License-Identifier: Apache-2.0`)\n- [ ] All Python files have Authors field (`Authors: Name1, Name2`)\n- [ ] Script can detect missing or malformed license headers\n- [ ] Script provides clear reporting of non-compliant files\n\n**Implementation Requirements:**\n- [ ] Extend `.github/tools/fix_file_headers.py` from #317 to include SPDX validation\n- [ ] Create `make check-spdx` target for header validation\n- [ ] Create `make fix-spdx` target for automatic header repair\n- [ ] Add GitHub Actions workflow step to validate headers in CI\n- [ ] Integration with existing pre-commit hooks\n\n**Quality & Compliance:**\n- [ ] All source files pass SPDX header validation\n- [ ] CI pipeline fails on missing/invalid license headers\n- [ ] SBOM generation includes accurate license information\n- [ ] License inventory tools work correctly with proper headers\n- [ ] No regressions in existing linting or formatting\n\n**Documentation & Integration:**\n- [ ] Makefile targets documented with proper help text\n- [ ] GitHub Actions integration documented\n- [ ] CONTRIBUTING.md updated with header requirements (if applicable)\n- [ ] Developer guidelines include license header examples\n\n---\n\n### \uD83E\uDDE9 Additional Notes\n\n**Required Header Format:**\nBased on existing project files, the standardized header should be:\n```python\n# -*- coding: utf-8 -*-\n\"\"\"Module Description.\nLocation: ./relative/path/to/file.py\n\nCopyright 2025\nSPDX-License-Identifier: Apache-2.0\nAuthors: Mihai Criveti, [Additional Authors]\n\nModule documentation...\n\"\"\"\n```\n\n**Technical Implementation:**\n- Extend the existing `.github/tools/fix_file_headers.py` script from task #317\n- Use regex patterns to validate header components\n- Support for multiple authors in comma-separated format\n- Validate SPDX license identifier matches project license (Apache-2.0)\n- Handle edge cases (test files, generated files, etc.)\n\n**File Selection Criteria:**\n- All `.py` files in `mcpgateway/`, `tests/`, and project root\n- Exclude: `__pycache__`, `.venv`, `build/`, `dist/`, `.git/`\n- Include: source files, test files, scripts, and tools\n- Consider: migration files in `alembic/versions/` (may have different requirements)\n\n**GitHub Actions Integration:**\n```yaml\n- name: Check SPDX License Headers\n  run: |\n    python .github/tools/fix_file_headers.py --check-spdx\n    if [ $? -ne 0 ]; then\n      echo \"??? License header validation failed\"\n      echo \"Run 'make fix-spdx' to automatically fix headers\"\n      exit 1\n    fi\n```\n\n**Makefile Integration:**\n```makefile\ncheck-spdx:                    ## \uD83D\uDCDC Validate SPDX license headers\n\t@python .github/tools/fix_file_headers.py --check-spdx\n\nfix-spdx:                      ## \uD83D\uDCDC Fix missing SPDX license headers  \n\t@python .github/tools/fix_file_headers.py --fix-spdx\n```\n\n**Error Reporting:**\n- Clear output showing which files are missing headers\n- Specific guidance on what header components are missing\n- Summary statistics (X/Y files compliant)\n- Integration with existing CI/CD failure reporting\n\n**Dependencies:**\n- Depends on task #317 (file path header script)\n- Should work with existing `make sbom` and `make pip-licenses` targets\n- Compatible with current pre-commit hook configuration\n- No additional Python dependencies required (use standard library)",
      "updatedAt" : 1752200637.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "devops", "cicd", "chore", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create validation targets to ensure all Python source files contain proper SPDX license headers, copyright notices, and author information",
      "validationOrRequirement" : "Header Validation Requirements: [all Python files have proper encoding declaration, all Python files have copyright notice, all Python files have SPDX license identifier, all Python files have Authors field, script can detect missing or malformed license headers, script provides clear reporting of non-compliant files], Implementation Requirements: [extend .github/tools/fix_file_headers.py, create make check-spdx target, create make fix-spdx target, add GitHub Actions workflow step to validate headers in CI, integration with existing pre-commit hooks], Quality & Compliance: [all source files pass SPDX header validation, CI pipeline fails on missing/invalid license headers, SBOM generation includes accurate license information, license inventory tools work correctly with proper headers, no regressions in existing linting or formatting], Documentation & Integration: [makefile targets documented, GitHub Actions integration documented, CONTRIBUTING.md updated with header requirements, developer guidelines include license header examples]",
      "attemptedFixes" : "extend existing .github/tools/fix_file_headers.py script from task #317, use regex patterns to validate header components, support for multiple authors in comma-separated format, validate SPDX license identifier matches project license (Apache-2.0), handle edge cases (test files, generated files, etc.)",
      "otherNotes" : "Required Header Format: [based on existing project files], Technical Implementation: [extend existing script, use regex patterns, support multiple authors], File Selection Criteria: [all .py files in mcpgateway/, tests/, project root, exclude: __pycache__, .venv, build/, dist/, .git/, include: source files, test files, scripts, tools], GitHub Actions Integration: [yaml script], Makefile Integration: [makefile script], Error Reporting: [clear output, specific guidance, summary statistics], Dependencies: [task #317, make sbom, make pip-licenses, pre-commit hook configuration]",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285102
  }, {
    "issueDTO" : {
      "id" : 3213629698,
      "title" : "[Docs]: Add Developer Guide for using fast-time-server via JSON-RPC commands using curl or stdio",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/323",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "## Overview\n\nThis guide demonstrates how to interact with the fast-time-server MCP server using raw JSON-RPC commands via curl. The fast-time-server is an ultra-fast Go-based MCP server that provides time-related tools for LLM applications.\n\n## Available Tools\n\n- **get_system_time**: Returns current time in any IANA timezone\n- **convert_time**: Converts time between different timezones\n\n## Transport Modes\n\nThe fast-time-server supports multiple transport modes:\n\n- **stdio**: For desktop clients like Claude Desktop (default)\n- **sse**: Server-Sent Events for web-based MCP clients\n- **http**: HTTP streaming for REST-like interactions  \n- **dual**: Both SSE and HTTP on the same port (SSE at /sse, HTTP at /http)\n\n## Quick Start\n\n### Running the Server\n\n```bash\n# Docker - DUAL mode (both SSE and HTTP)\ndocker run --rm -it -p 8888:8080 ghcr.io/ibm/fast-time-server:latest\n\n# Docker - HTTP only\ndocker run --rm -it -p 8888:8080 ghcr.io/ibm/fast-time-server:latest -transport=http\n\n# Docker - SSE only\ndocker run --rm -it -p 8888:8080 ghcr.io/ibm/fast-time-server:latest -transport=sse\n\n# Docker - STDIO (for testing)\ndocker run --rm -it ghcr.io/ibm/fast-time-server:latest -transport=stdio\n\n# Docker - With authentication\ndocker run --rm -it -p 8888:8080 ghcr.io/ibm/fast-time-server:latest -auth-token=secret123\n\n# Binary download (if available)\n./fast-time-server -transport=dual -port=8080\n./fast-time-server -transport=http -port=8080\n./fast-time-server -transport=sse -port=8080 -auth-token=secret123\n```\n\n## Endpoint URLs\n\n### DUAL Transport (default Docker)\n- **SSE Events**: http://localhost:8888/sse\n- **SSE Messages**: http://localhost:8888/messages  \n- **HTTP MCP**: http://localhost:8888/http\n- **Health**: http://localhost:8888/health\n- **Version**: http://localhost:8888/version\n\n### HTTP Transport Only\n- **MCP**: http://localhost:8888/\n- **Health**: http://localhost:8888/health\n- **Version**: http://localhost:8888/version\n\n### SSE Transport Only\n- **Events**: http://localhost:8888/sse\n- **Messages**: http://localhost:8888/messages\n- **Health**: http://localhost:8888/health\n- **Version**: http://localhost:8888/version\n\n## Authentication\n\nWhen using authentication (via `-auth-token` flag or `AUTH_TOKEN` environment variable):\n\n```bash\n# Include Bearer token in requests\ncurl -H \"Authorization: Bearer secret123\" http://localhost:8888/sse\n```\n\n## HTTP Transport Usage\n\n### Health Check\n\n```bash\n# Check server health\ncurl http://localhost:8888/health\n\n# Expected response:\n# {\"status\":\"healthy\",\"uptime_seconds\":123}\n```\n\n### Version Information\n\n```bash\n# Get server version\ncurl http://localhost:8888/version\n\n# Expected response:\n# {\"name\":\"fast-time-server\",\"version\":\"1.5.0\",\"mcp_version\":\"1.0\"}\n```\n\n### MCP Protocol Flow\n\n#### 1. Initialize Connection\n\n```bash\n# Initialize the MCP connection\ncurl -X POST http://localhost:8888/http \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"method\":\"initialize\",\n           \"params\":{\n             \"protocolVersion\":\"2025-03-26\",\n             \"capabilities\":{},\n             \"clientInfo\":{\"name\":\"test-client\",\"version\":\"1.0\"}\n           },\n           \"id\":1\n         }'\n```\n\n**Expected Response:**\n```json\n{\n  \"jsonrpc\":\"2.0\",\n  \"id\":1,\n  \"result\":{\n    \"protocolVersion\":\"2025-03-26\",\n    \"capabilities\":{\n      \"tools\":{\"listChanged\":false}\n    },\n    \"serverInfo\":{\n      \"name\":\"fast-time-server\",\n      \"version\":\"1.5.0\"\n    }\n  }\n}\n```\n\n#### 2. Send Initialized Notification\n\n```bash\n# Send initialized notification\ncurl -X POST http://localhost:8888/http \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"method\":\"notifications/initialized\",\n           \"params\":{}\n         }'\n```\n\n#### 3. List Available Tools\n\n```bash\n# List all available tools\ncurl -X POST http://localhost:8888/http \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"method\":\"tools/list\",\n           \"id\":2\n         }'\n```\n\n**Expected Response:**\n```json\n{\n  \"jsonrpc\":\"2.0\",\n  \"id\":2,\n  \"result\":{\n    \"tools\":[\n      {\n        \"name\":\"get_system_time\",\n        \"description\":\"Get current system time in specified timezone\",\n        \"inputSchema\":{\n          \"type\":\"object\",\n          \"properties\":{\n            \"timezone\":{\n              \"type\":\"string\",\n              \"description\":\"IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Defaults to UTC\"\n            }\n          }\n        }\n      },\n      {\n        \"name\":\"convert_time\",\n        \"description\":\"Convert time between different timezones\",\n        \"inputSchema\":{\n          \"type\":\"object\",\n          \"properties\":{\n            \"time\":{\n              \"type\":\"string\",\n              \"description\":\"Time to convert in RFC3339 format or common formats like '2006-01-02 15:04:05'\"\n            },\n            \"source_timezone\":{\n              \"type\":\"string\",\n              \"description\":\"Source IANA timezone name\"\n            },\n            \"target_timezone\":{\n              \"type\":\"string\",\n              \"description\":\"Target IANA timezone name\"\n            }\n          },\n          \"required\":[\"time\",\"source_timezone\",\"target_timezone\"]\n        }\n      }\n    ]\n  }\n}\n```\n\n#### 4. Call Tools\n\n**Get Current Time in UTC:**\n```bash\ncurl -X POST http://localhost:8888/http \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"method\":\"tools/call\",\n           \"params\":{\n             \"name\":\"get_system_time\",\n             \"arguments\":{}\n           },\n           \"id\":3\n         }'\n```\n\n**Get Current Time in Specific Timezone:**\n```bash\ncurl -X POST http://localhost:8888/http \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"method\":\"tools/call\",\n           \"params\":{\n             \"name\":\"get_system_time\",\n             \"arguments\":{\"timezone\":\"America/New_York\"}\n           },\n           \"id\":4\n         }'\n```\n\n**Expected Response:**\n```json\n{\n  \"jsonrpc\":\"2.0\",\n  \"id\":4,\n  \"result\":{\n    \"content\":[\n      {\n        \"type\":\"text\",\n        \"text\":\"2025-07-08T15:41:01-04:00\"\n      }\n    ],\n    \"isError\":false\n  }\n}\n```\n\n**Convert Time Between Timezones:**\n```bash\ncurl -X POST http://localhost:8888/http \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"method\":\"tools/call\",\n           \"params\":{\n             \"name\":\"convert_time\",\n             \"arguments\":{\n               \"time\":\"2025-07-08T15:41:01-04:00\",\n               \"source_timezone\":\"America/New_York\",\n               \"target_timezone\":\"Europe/Dublin\"\n             }\n           },\n           \"id\":5\n         }'\n```\n\n**Expected Response:**\n```json\n{\n  \"jsonrpc\":\"2.0\",\n  \"id\":5,\n  \"result\":{\n    \"content\":[\n      {\n        \"type\":\"text\",\n        \"text\":\"2025-07-08T20:41:01+01:00\"\n      }\n    ],\n    \"isError\":false\n  }\n}\n```\n\n## SSE Transport Usage\n\n### Establishing SSE Connection\n\n```bash\n# Terminal 1: Start SSE connection (keeps connection open)\ncurl -N http://localhost:8888/sse\n```\n\nThis will establish a persistent connection and you'll see responses in real-time.\n\n### Sending Messages via SSE\n\nIn a separate terminal, send JSON-RPC messages:\n\n```bash\n# Initialize\ncurl -X POST http://localhost:8888/messages \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"id\":1,\n           \"method\":\"initialize\",\n           \"params\":{\n             \"protocolVersion\":\"2025-03-26\",\n             \"capabilities\":{},\n             \"clientInfo\":{\"name\":\"sse-client\",\"version\":\"1.0\"}\n           }\n         }'\n\n# List tools\ncurl -X POST http://localhost:8888/messages \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"id\":2,\n           \"method\":\"tools/list\"\n         }'\n\n# Get current time in Dublin\ncurl -X POST http://localhost:8888/messages \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"jsonrpc\":\"2.0\",\n           \"id\":3,\n           \"method\":\"tools/call\",\n           \"params\":{\n             \"name\":\"get_system_time\",\n             \"arguments\":{\"timezone\":\"Europe/Dublin\"}\n           }\n         }'\n```\n\n## Common Use Cases\n\n### Get Time in Multiple Timezones\n\n```bash\n# Create a script to get times in multiple zones\n#!/bin/bash\n\nSERVER=\"http://localhost:8888/http\"\n\n# Function to get time in timezone\nget_time() {\n    local tz=$1\n    curl -s -X POST $SERVER \\\n         -H \"Content-Type: application/json\" \\\n         -d \"{\n               \\\"jsonrpc\\\":\\\"2.0\\\",\n               \\\"method\\\":\\\"tools/call\\\",\n               \\\"params\\\":{\n                 \\\"name\\\":\\\"get_system_time\\\",\n                 \\\"arguments\\\":{\\\"timezone\\\":\\\"$tz\\\"}\n               },\n               \\\"id\\\":$(date +%s)\n             }\" | jq -r '.result.content[0].text'\n}\n\necho \"Current times around the world:\"\necho \"UTC:         $(get_time 'UTC')\"\necho \"New York:    $(get_time 'America/New_York')\"\necho \"London:      $(get_time 'Europe/London')\"\necho \"Dublin:      $(get_time 'Europe/Dublin')\"\necho \"Tokyo:       $(get_time 'Asia/Tokyo')\"\necho \"Sydney:      $(get_time 'Australia/Sydney')\"\n```\n\n### Time Zone Conversion\n\n```bash\n# Convert a meeting time from Dublin to various timezones\nMEETING_TIME=\"2025-07-08T14:00:00\"\nSOURCE_TZ=\"Europe/Dublin\"\n\nconvert_time() {\n    local target_tz=$1\n    curl -s -X POST http://localhost:8888/http \\\n         -H \"Content-Type: application/json\" \\\n         -d \"{\n               \\\"jsonrpc\\\":\\\"2.0\\\",\n               \\\"method\\\":\\\"tools/call\\\",\n               \\\"params\\\":{\n                 \\\"name\\\":\\\"convert_time\\\",\n                 \\\"arguments\\\":{\n                   \\\"time\\\":\\\"$MEETING_TIME\\\",\n                   \\\"source_timezone\\\":\\\"$SOURCE_TZ\\\",\n                   \\\"target_timezone\\\":\\\"$target_tz\\\"\n                 }\n               },\n               \\\"id\\\":$(date +%s)\n             }\" | jq -r '.result.content[0].text'\n}\n\necho \"Meeting at $MEETING_TIME Dublin time:\"\necho \"New York:  $(convert_time 'America/New_York')\"\necho \"Los Angeles: $(convert_time 'America/Los_Angeles')\"\necho \"Tokyo:     $(convert_time 'Asia/Tokyo')\"\necho \"Sydney:    $(convert_time 'Australia/Sydney')\"\n```\n\n## Complete Example Session\n\n```bash\n#!/bin/bash\n\n# fast-time-server complete session example\nSERVER=\"http://localhost:8888/http\"\n\n# Function to make JSON-RPC calls\nmake_call() {\n    curl -s -X POST $SERVER \\\n         -H \"Content-Type: application/json\" \\\n         -d \"$1\" | jq\n}\n\necho \"=== Fast Time Server Example Session ===\"\n\n# 1. Health check\necho \"=== Health Check ===\"\ncurl -s http://localhost:8888/health | jq\n\n# 2. Version info\necho \"=== Version Info ===\"\ncurl -s http://localhost:8888/version | jq\n\n# 3. Initialize connection\necho \"=== Initializing ===\"\nmake_call '{\n  \"jsonrpc\":\"2.0\",\n  \"method\":\"initialize\",\n  \"params\":{\n    \"protocolVersion\":\"2025-03-26\",\n    \"capabilities\":{},\n    \"clientInfo\":{\"name\":\"example-client\",\"version\":\"1.0\"}\n  },\n  \"id\":1\n}'\n\n# 4. Send initialized notification\necho \"=== Sending initialized notification ===\"\nmake_call '{\n  \"jsonrpc\":\"2.0\",\n  \"method\":\"notifications/initialized\",\n  \"params\":{}\n}'\n\n# 5. List tools\necho \"=== Listing Tools ===\"\nmake_call '{\n  \"jsonrpc\":\"2.0\",\n  \"method\":\"tools/list\",\n  \"id\":2\n}'\n\n# 6. Get current time (UTC)\necho \"=== Getting UTC Time ===\"\nmake_call '{\n  \"jsonrpc\":\"2.0\",\n  \"method\":\"tools/call\",\n  \"params\":{\n    \"name\":\"get_system_time\",\n    \"arguments\":{}\n  },\n  \"id\":3\n}'\n\n# 7. Get current time (Dublin)\necho \"=== Getting Dublin Time ===\"\nmake_call '{\n  \"jsonrpc\":\"2.0\",\n  \"method\":\"tools/call\",\n  \"params\":{\n    \"name\":\"get_system_time\",\n    \"arguments\":{\"timezone\":\"Europe/Dublin\"}\n  },\n  \"id\":4\n}'\n\n# 8. Convert time\necho \"=== Converting Time ===\"\nmake_call '{\n  \"jsonrpc\":\"2.0\",\n  \"method\":\"tools/call\",\n  \"params\":{\n    \"name\":\"convert_time\",\n    \"arguments\":{\n      \"time\":\"2025-07-08T14:00:00\",\n      \"source_timezone\":\"Europe/Dublin\",\n      \"target_timezone\":\"America/New_York\"\n    }\n  },\n  \"id\":5\n}'\n\necho \"=== Session Complete ===\"\n```\n\n## Integration with Claude Desktop\n\nTo use this with Claude Desktop, create a configuration that points to the STDIO mode:\n\n```json\n{\n  \"mcpServers\": {\n    \"fast-time\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"--rm\", \"-i\",\n        \"ghcr.io/ibm/fast-time-server:latest\",\n        \"-transport=stdio\",\n        \"-log-level=error\"\n      ]\n    }\n  }\n}\n```\n\nOr if you have the binary locally:\n\n```json\n{\n  \"mcpServers\": {\n    \"fast-time\": {\n      \"command\": \"./fast-time-server\",\n      \"args\": [\"-transport=stdio\", \"-log-level=error\"]\n    }\n  }\n}\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Connection refused**: Ensure the server is running and port is correct\n2. **Authentication errors**: Include Bearer token when server is configured with auth\n3. **Invalid timezone**: Use valid IANA timezone names (e.g., 'America/New_York', not 'EST')\n4. **Time format errors**: Use RFC3339 format or common formats like '2006-01-02 15:04:05'\n\n### Error Examples\n\n**Invalid timezone:**\n```json\n{\n  \"jsonrpc\":\"2.0\",\n  \"id\":3,\n  \"result\":{\n    \"content\":[{\n      \"type\":\"text\",\n      \"text\":\"invalid timezone \\\"Invalid/Zone\\\": unknown time zone Invalid/Zone\"\n    }],\n    \"isError\":true\n  }\n}\n```\n\n**Missing required parameter:**\n```json\n{\n  \"jsonrpc\":\"2.0\",\n  \"id\":4,\n  \"result\":{\n    \"content\":[{\n      \"type\":\"text\",\n      \"text\":\"time parameter is required\"\n    }],\n    \"isError\":true\n  }\n}\n```\n\n### Valid Timezone Examples\n\n- **US**: America/New_York, America/Chicago, America/Denver, America/Los_Angeles\n- **Europe**: Europe/London, Europe/Dublin, Europe/Paris, Europe/Berlin\n- **Asia**: Asia/Tokyo, Asia/Shanghai, Asia/Mumbai, Asia/Dubai\n- **Australia**: Australia/Sydney, Australia/Melbourne, Australia/Perth\n- **UTC**: UTC\n\n## Performance Notes\n\nThe fast-time-server is written in Go and optimized for performance:\n\n- **Timezone caching**: Loaded timezones are cached for faster subsequent calls\n- **Concurrent requests**: Can handle multiple simultaneous requests\n- **Low memory footprint**: Minimal resource usage\n- **Fast startup**: Quick initialization time\n\n## Further Reading\n\n- [MCP Specification](https://modelcontextprotocol.io/)\n- [JSON-RPC 2.0 Specification](https://www.jsonrpc.org/specification)\n- [IANA Time Zone Database](https://www.iana.org/time-zones)\n- [Go time package documentation](https://pkg.go.dev/time)",
      "updatedAt" : 1752200637.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "documentation", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to create a comprehensive guide for developers to use the fast-time-server via JSON-RPC commands using curl or stdio.",
      "validationOrRequirement" : "The guide requires a basic understanding of JSON-RPC and the Model Context Protocol (MCP). It assumes that the reader has some experience with using curl and stdio to interact with a server.",
      "attemptedFixes" : "The guide provides examples of using the fast-time-server with curl and stdio, and includes troubleshooting tips for common issues such as connection refused, authentication errors, and invalid timezones.",
      "otherNotes" : "The issue is about creating a Developer Guide for using fast-time-server via JSON-RPC commands using curl or stdio. It provides information on how to interact with the fast-time-server MCP server, including available tools, transport modes, and usage examples. The guide also covers troubleshooting and error handling.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285109
  }, {
    "issueDTO" : {
      "id" : 3110353245,
      "title" : "[Docs]: Add BeeAI Framework client integration (Python & TypeScript)",
      "url" : "https://github.com/IBM/mcp-context-forge/issues/22",
      "repositoryName" : "IBM/mcp-context-forge",
      "description" : "### \uD83D\uDCDA Documentation Issue Summary\n\nThe documentation should include a new guide under `docs/docs/using/agents/` for integrating **BeeAI Framework** (https://framework.beeai.dev) with MCP Gateway.\n\nBeeAI is a production-ready, dual-language (Python + TypeScript) framework for multi-agent workflows. It natively supports MCP via `MCPTool` and can interoperate with both `mcpgateway-wrapper` and SSE/HTTP transports.\n\n---\n\n### \uD83D\uDCCD Location of the Problem\n\n> Suggested location: `docs/docs/using/agents/beeai.md`  \n> Also update: `.pages` in `docs/docs/using/agents/` to include `beeai.md`\n\nPage: https://ibm.github.io/mcp-context-forge/using/agents/bee/\n---\n\n### ?????? Type of Issue\n\n* [x] Missing client documentation\n* [x] New integration support\n\n---\n\n### \uD83D\uDCA1 Suggested Fix or Clarification\n\nFollow the style used in `claude-desktop.md` and other client entries. Include:\n\n- Brief overview of BeeAI Framework\n- MCP integration via `MCPTool`\n- Sample usage with `mcpgateway-wrapper`\n- Optional section for SSE/WebSocket (if BeeAI supports it)\n- Tips for configuring tool discovery\n- Links to BeeAI official documentation\n\nInclude both stdio and REST variants for completeness.\n\n---\n\n### \uD83E\uDDE9 Additional Notes\n\nBeeAI supports observability, custom memory layers, and multi-LLM routing-consider noting how Gateway features like caching or SSE streams complement those workflows.\n",
      "updatedAt" : 1752200308.000000000,
      "user" : "crivetimihai",
      "userHtmlUrl" : "https://github.com/crivetimihai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8157583?v=4",
      "labels" : [ "documentation", "markdown", "help wanted", "enhancement", "good first issue", "triage" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).",
        "homepage" : "https://ibm.github.io/mcp-context-forge/",
        "name" : "mcp-context-forge",
        "fullName" : "IBM/mcp-context-forge",
        "htmlUrl" : "https://github.com/IBM/mcp-context-forge",
        "gitUrl" : "git://github.com/IBM/mcp-context-forge.git",
        "sshUrl" : "git@github.com:IBM/mcp-context-forge.git",
        "cloneUrl" : "https://github.com/IBM/mcp-context-forge.git",
        "owner" : {
          "login" : "IBM",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 128,
        "stargazersCount" : 807,
        "watchersCount" : 807,
        "size" : 15508,
        "openIssuesCount" : 136,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-11T22:29:54Z",
        "languages" : {
          "HCL" : 6315,
          "Smarty" : 2502,
          "Dockerfile" : 3947,
          "Shell" : 34582,
          "Jinja" : 1525,
          "CSS" : 714,
          "Makefile" : 132828,
          "JavaScript" : 153777,
          "Go" : 35948,
          "HTML" : 128840,
          "Mako" : 704,
          "Python" : 1232061
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The documentation should include a new guide under `docs/docs/using/agents/` for integrating **BeeAI Framework** (https://framework.beeai.dev) with MCP Gateway.",
      "validationOrRequirement" : "Follow the style used in `claude-desktop.md` and other client entries.",
      "attemptedFixes" : "Follow the style used in `claude-desktop.md` and other client entries. Include: - Brief overview of BeeAI Framework - MCP integration via `MCPTool` - Sample usage with `mcpgateway-wrapper` - Optional section for SSE/WebSocket (if BeeAI supports it) - Tips for configuring tool discovery - Links to BeeAI official documentation. Include both stdio and REST variants for completeness.",
      "otherNotes" : "BeeAI supports observability, custom memory layers, and multi-LLM routing-consider noting how Gateway features like caching or SSE streams complement those workflows.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285115
  }, {
    "issueDTO" : {
      "id" : 3211939665,
      "title" : "[Bug] ReadSheet????????????hashCode???equals??????",
      "url" : "https://github.com/fast-excel/fastexcel/issues/406",
      "repositoryName" : "fast-excel/fastexcel",
      "description" : "### Search before asking\n\n- [x] I searched in the [issues](https://github.com/fast-excel/fastexcel/issues) and found nothing similar.\n\n\n### Fastexcel version\n\n1.2.0\n\n### JDK version\n\n17\n\n### Operating system\n\nWindows 10\n\n### Minimal reproduce step\n\nReadSheet????????????hashCode???equals??????\n\n### What did you expect to see?\n\nReadSheet??????hashCode???equals??????, ??????sheetNo???sheetName??????\n\n### What did you see instead?\n\nReadSheet?????????hashCode???equals??????,????????????ReadSheet?????????Map<ReadSheet,?>??????????????????????????????\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
      "updatedAt" : 1752199952.000000000,
      "user" : "JinyuZhang",
      "userHtmlUrl" : "https://github.com/JinyuZhang",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/17537616?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\uD83D\uDE0B Hi, @JinyuZhang \nThis appears to be a good first issue,are you willing to submit a PR?", "@delei ??????????????????PR,???????????????", "> [@delei](https://github.com/delei) ??????????????????PR,???????????????\n\n:fist: Welcome to submit PR .Please check [Contributing Guide](https://github.com/fast-excel/fastexcel/blob/main/CHANGELOG.md) about how to contribute to this project." ],
      "repository" : {
        "description" : "easyexcel??????????????????????????? ????????????????????????????????????????????????java??????Excel??????",
        "homepage" : "https://readmex.com/fast-excel/fastexcel",
        "name" : "fastexcel",
        "fullName" : "fast-excel/fastexcel",
        "htmlUrl" : "https://github.com/fast-excel/fastexcel",
        "gitUrl" : "git://github.com/fast-excel/fastexcel.git",
        "sshUrl" : "git@github.com:fast-excel/fastexcel.git",
        "cloneUrl" : "https://github.com/fast-excel/fastexcel.git",
        "owner" : {
          "login" : "fast-excel",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 372,
        "stargazersCount" : 4839,
        "watchersCount" : 4839,
        "size" : 24642,
        "openIssuesCount" : 104,
        "subscribersCount" : 74,
        "pushedAt" : "2025-07-08T11:17:22Z",
        "languages" : {
          "Java" : 1522484
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the bug in ReadSheet class by implementing hashCode and equals methods.",
      "validationOrRequirement" : "The ReadSheet class should implement hashCode and equals methods using sheetNo and sheetName fields.",
      "attemptedFixes" : "The contributor is willing to try to submit a PR, but has no experience with submitting PRs.",
      "otherNotes" : "The contributor is willing to submit a PR, and the issue is labeled as a good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285118
  }, {
    "issueDTO" : {
      "id" : 2981364572,
      "title" : "Use read_at for blob point reads",
      "url" : "https://github.com/fjall-rs/value-log/issues/33",
      "repositoryName" : "fjall-rs/value-log",
      "description" : "Avoids separate seek() syscall.\n\n`ValueHandles` need to store the blob size PLUS blob header, such that the `read_at` call can read everything in one go.\n\n```\n[blob header]\n  - checksum (8 bytes)\n  - uncompressed value len (4 bytes)\n  - compressed value len (4 bytes) = B\n  - key len (2 bytes)\n  - key (N bytes)\n[blob data; B bytes]\n...\n[blob header]\n[blob data]\n...\n```\n\n`ValueHandle` should not expose its fields directly and instead have 2 getters:\n\n```\noffset(): self.offset\nsize(key_len): self.size - serialized_blob_header_size(key_len)\n// ^--- because key is dynamically sized, we need to pass it in as a parameter\n```\n\nOR the vHandle just stores the blob header + body size and the size() function can calculate the blob size by subtracting.\n\n---\n\nThat also means we need two readers, one for point reads and one to scan an entire blob file (which owns its FD and can then just use a BufReader).\n",
      "updatedAt" : 1752199546.000000000,
      "user" : "marvin-j97",
      "userHtmlUrl" : "https://github.com/marvin-j97",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/33938500?v=4",
      "labels" : [ "performance", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/// Represents a handle to a binary blob on disk, including both the\n/// dynamically sized header and the value data.\n///\n/// The total size stored includes the full header and value so that\n/// reading can be done in a single `read_at(offset, size)` call without\n/// requiring an additional seek() to parse headers first.\n///\n/// Only accessor methods are exposed to enforce encapsulation.\n/// The header size is computed at runtime based on the variable key length.\npub struct ValueHandle {\n    offset: u64,  // File offset where the blob begins\n    size: usize,  // Total size: header + value data\n}\n\nimpl ValueHandle {\n    /// Returns the offset where the blob begins in the file.\n    pub fn offset(&self) -> u64 {\n        self.offset\n    }\n\n    /// Returns the size of the value data, excluding the header.\n    ///\n    /// # Arguments\n    /// * `key_len` - The dynamic length of the key, required to calculate header size\n    ///\n    /// # Panics\n    /// Panics if the computed header size exceeds the stored total size.\n    ///\n    /// This enables efficient one-shot reading of the entire blob\n    /// without a second seek(), while preserving safety.\n    pub fn data_size(&self, key_len: usize) -> usize {\n        let header = Self::header_size(key_len);\n        assert!(\n            self.size >= header,\n            \"Invalid key_len: header size exceeds stored size\"\n        );\n        self.size - header\n    }\n\n    /// Computes the total serialized size of the blob header for the given key length.\n    ///\n    /// Header structure:\n    /// [ checksum (8 bytes) | key_len (2 bytes) | key (N bytes) | uncompressed_value_len (4 bytes) ]\n    fn header_size(key_len: usize) -> usize {\n        const CHECKSUM_SIZE: usize = 8;\n        const KEY_LEN_SIZE: usize = 2;\n        const VALUE_LEN_SIZE: usize = 4;\n        CHECKSUM_SIZE + KEY_LEN_SIZE + key_len + VALUE_LEN_SIZE\n    }\n}\n" ],
      "repository" : {
        "description" : "Value log implementation for key-value separated storage in safe Rust",
        "homepage" : "https://fjall-rs.github.io",
        "name" : "value-log",
        "fullName" : "fjall-rs/value-log",
        "htmlUrl" : "https://github.com/fjall-rs/value-log",
        "gitUrl" : "git://github.com/fjall-rs/value-log.git",
        "sshUrl" : "git@github.com:fjall-rs/value-log.git",
        "cloneUrl" : "https://github.com/fjall-rs/value-log.git",
        "owner" : {
          "login" : "fjall-rs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 41,
        "watchersCount" : 41,
        "size" : 297,
        "openIssuesCount" : 11,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-10T19:29:30Z",
        "languages" : {
          "Rust" : 137893
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Use read_at for blob point reads to avoid separate seek() syscall",
      "validationOrRequirement" : "Only accessor methods are exposed to enforce encapsulation, and the header size is computed at runtime based on the variable key length.",
      "attemptedFixes" : "OR the vHandle just stores the blob header + body size and the size() function can calculate the blob size by subtracting.",
      "otherNotes" : "ValueHandles need to store blob size PLUS blob header, and ValueHandle should not expose its fields directly. It should have 2 getters: offset() and size(key_len).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285122
  }, {
    "issueDTO" : {
      "id" : 3160368586,
      "title" : "Launchpad: Fix broken internal links #2",
      "url" : "https://github.com/canonical/open-documentation-academy/issues/238",
      "repositoryName" : "canonical/open-documentation-academy",
      "description" : "**This task has been created for UbuCon EU (OpenSouthCode 2025) to assist community members make their first documentation contribution.**\n\nBackground\n------------------\nInternal references/links point to pages within the same doc-set, i.e., don't take you to an external site. Some pages in the Launchpad manual have broken internal links because they have been recently migrated from another site and are yet to be correctly linked to each other. Launchpad's docs are now hosted on Read the Docs and are written in restructured text or markdown. When linking these docs, it is recommended that [the :ref: method](https://canonical-starter-pack.readthedocs-hosted.com/latest/reference/style-guide/#internal-references) described in the style guide be used. Using :ref: instead of a file path makes it less likely that the link will break if a file is renamed or moved to a different folder.\n\nTask\n-------\nThe pages linked below have one or more broken internal links. Direct the links to the correct pages within the docs using the :ref: method mentioned above. You may need to add a target to a file you're linking to if one is not already present.\n[explanation/what-is-launchpad.rst](https://documentation.ubuntu.com/launchpad/en/latest/user/explanation/what-is-launchpad/)\n[explanation/privacy-confidentiality-and-disclosure.rst](https://documentation.ubuntu.com/launchpad/en/latest/user/explanation/privacy-confidentiality-and-disclosure/)\n",
      "updatedAt" : 1752199435.000000000,
      "user" : "odadacharles",
      "userHtmlUrl" : "https://github.com/odadacharles",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/59516374?v=4",
      "labels" : [ "workshop", "help wanted", "good first issue", "size 1" ],
      "state" : "OPEN",
      "comments" : [ "Hi @odadacharles , I've submitted a PR addressing this task, please let me know if something needs to be changed or improved. Thanks!!" ],
      "repository" : {
        "description" : "Learn open-source software documentation skills with Canonical",
        "homepage" : "https://documentationacademy.org/",
        "name" : "open-documentation-academy",
        "fullName" : "canonical/open-documentation-academy",
        "htmlUrl" : "https://github.com/canonical/open-documentation-academy",
        "gitUrl" : "git://github.com/canonical/open-documentation-academy.git",
        "sshUrl" : "git@github.com:canonical/open-documentation-academy.git",
        "cloneUrl" : "https://github.com/canonical/open-documentation-academy.git",
        "owner" : {
          "login" : "canonical",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 65,
        "stargazersCount" : 88,
        "watchersCount" : 88,
        "size" : 3014,
        "openIssuesCount" : 74,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-09T14:47:18Z",
        "languages" : {
          "Shell" : 4029,
          "CSS" : 343,
          "Makefile" : 8546,
          "HTML" : 1393,
          "Python" : 11280
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix broken internal links in the Launchpad manual by directing links to the correct pages using the :ref: method.",
      "validationOrRequirement" : "Use the :ref: method to link pages within the docs, and add a target to a file if one is not already present.",
      "attemptedFixes" : "A PR has been submitted by @odadacharles addressing this task, awaiting review.",
      "otherNotes" : "The task is for the UbuCon EU (OpenSouthCode 2025) to assist community members make their first documentation contribution.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285126
  }, {
    "issueDTO" : {
      "id" : 3221192239,
      "title" : "Add readiness and liveness probe for hypervisor and worker Pods",
      "url" : "https://github.com/NexusGPU/tensor-fusion/issues/275",
      "repositoryName" : "NexusGPU/tensor-fusion",
      "description" : "## Summary\nCurrent helm chart doesn't include liveness and readiness probe for core components like hypervisor and remote mode vGPU worker, need them for production-grade auto-healing.\n",
      "updatedAt" : 1752198301.000000000,
      "user" : "Code2Life",
      "userHtmlUrl" : "https://github.com/Code2Life",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/14833440?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Tensor Fusion is a state-of-the-art GPU virtualization and pooling solution designed to optimize GPU cluster utilization to its fullest potential.",
        "homepage" : "https://tensor-fusion.ai",
        "name" : "tensor-fusion",
        "fullName" : "NexusGPU/tensor-fusion",
        "htmlUrl" : "https://github.com/NexusGPU/tensor-fusion",
        "gitUrl" : "git://github.com/NexusGPU/tensor-fusion.git",
        "sshUrl" : "git@github.com:NexusGPU/tensor-fusion.git",
        "cloneUrl" : "https://github.com/NexusGPU/tensor-fusion.git",
        "owner" : {
          "login" : "NexusGPU",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 52,
        "watchersCount" : 52,
        "size" : 1274,
        "openIssuesCount" : 6,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T05:29:47Z",
        "languages" : {
          "Smarty" : 1709,
          "Dockerfile" : 2584,
          "Shell" : 6420,
          "Makefile" : 9206,
          "Go" : 806357
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add readiness and liveness probe for hypervisor and worker Pods",
      "validationOrRequirement" : "enhancement, good first issue",
      "attemptedFixes" : "",
      "otherNotes" : "Current helm chart doesn't include liveness and readiness probe for core components like hypervisor and remote mode vGPU worker, need them for production-grade auto-healing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285129
  }, {
    "issueDTO" : {
      "id" : 2635054150,
      "title" : "After turning on the trino dialect,filtering during aggregation return wrong data",
      "url" : "https://github.com/StarRocks/starrocks/issues/52640",
      "repositoryName" : "StarRocks/starrocks",
      "description" : "<!-- (At least include the following, feel free to add if you have more content) -->\n\n### Steps to reproduce the behavior (Required)\n```\nset sql_dialect = 'trino';\nselect\n    sum(id) filter (\n        where\n            id <= 1\n    ) as aaa\nfrom\n    (\n        SELECT\n            1 AS id,\n            'Alice' AS name\n        UNION\n        ALL\n        SELECT\n            2 AS id,\n            'Bob' AS name\n    ) AS simulated_data;\n```\n### Expected behavior (Required)\n1\n### Real behavior (Required)\n3\n### StarRocks version (Required)\n - You can get the StarRocks version by executing SQL `select current_version()`\n 3.3.4\n",
      "updatedAt" : 1752198146.000000000,
      "user" : "LZGH",
      "userHtmlUrl" : "https://github.com/LZGH",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16001090?v=4",
      "labels" : [ "type/bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@LZGH which version are you using right now?\n\nI tried to reproduce this case.\n\n> set sql_dialect = 'trino';\n\nAnd got following error\n\n> SQL Error [1064] [42000]: Trino parser parse sql error: [io.trino.sql.parser.ParsingException: line 7:8: mismatched input ','. Expecting: <EOF>], and StarRocks parser also can not parse: [com.starrocks.sql.parser.ParsingException: Getting syntax error at line 1, column 84. Detail message: Unexpected input '(', the most similar input is {<EOF>, ';'}.]\n\nAre my reproduce steps correct? ", "> [@LZGH](https://github.sheincorp.cn/LZGH) which version are you using right now?\n> \n> I tried to reproduce this case.\n> \n> > set sql_dialect = 'trino';\n> \n> And got following error\n> \n> > SQL Error [1064] [42000]: Trino parser parse sql error: [io.trino.sql.parser.ParsingException: line 7:8: mismatched input ','. Expecting: ], and StarRocks parser also can not parse: [com.starrocks.sql.parser.ParsingException: Getting syntax error at line 1, column 84. Detail message: Unexpected input '(', the most similar input is {, ';'}.]\n> \n> Are my reproduce steps correct?\n\n3.3.4", "> [@LZGH](https://github.sheincorp.cn/LZGH) which version are you using right now?\n> \n> I tried to reproduce this case.\n> \n> > set sql_dialect = 'trino';\n> \n> And got following error\n> \n> > SQL Error [1064] [42000]: Trino parser parse sql error: [io.trino.sql.parser.ParsingException: line 7:8: mismatched input ','. Expecting: ], and StarRocks parser also can not parse: [com.starrocks.sql.parser.ParsingException: Getting syntax error at line 1, column 84. Detail message: Unexpected input '(', the most similar input is {, ';'}.]\n> \n> Are my reproduce steps correct?\n\nI have adjusted the example to make it easier to reproduce the problem.", "According to our team members,  we don't even have this feature in starrocks correct? @Youngwb \n\nDo you think we should support them in near future?", "Hi team,\n\nWe have the same issue in our production cluster.\nif StarRocks does not supports this kind of query, should be better to return error?\n\nRight now StarRocks ignore the filter completely, thus return false results...this is never a good behaviour\n\nThanks", "@kateshaowanjou @wangsimo0 Can you help add this feature to trino compatible task https://github.com/StarRocks/starrocks/issues/40894 ?", "@Youngwb Is there any plan to support filter features? This ability is very necessary." ],
      "repository" : {
        "description" : "The world's fastest open query engine for sub-second analytics both on and off the data lakehouse. With the flexibility to support nearly any scenario, StarRocks provides best-in-class performance for multi-dimensional analytics, real-time analytics, and ad-hoc queries. A Linux Foundation project.",
        "homepage" : "https://starrocks.io",
        "name" : "starrocks",
        "fullName" : "StarRocks/starrocks",
        "htmlUrl" : "https://github.com/StarRocks/starrocks",
        "gitUrl" : "git://github.com/StarRocks/starrocks.git",
        "sshUrl" : "git@github.com:StarRocks/starrocks.git",
        "cloneUrl" : "https://github.com/StarRocks/starrocks.git",
        "owner" : {
          "login" : "StarRocks",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2049,
        "stargazersCount" : 10286,
        "watchersCount" : 10286,
        "size" : 519040,
        "openIssuesCount" : 883,
        "subscribersCount" : 189,
        "pushedAt" : "2025-07-11T16:04:21Z",
        "languages" : {
          "Java" : 48845697,
          "Yacc" : 4182,
          "C++" : 38090964,
          "CSS" : 6187,
          "C" : 342966,
          "CMake" : 205202,
          "Makefile" : 7808,
          "Mustache" : 959,
          "HTML" : 26561,
          "Dockerfile" : 32672,
          "Shell" : 161209,
          "ANTLR" : 102431,
          "Linker Script" : 44,
          "JavaScript" : 10136,
          "Lex" : 1752,
          "Python" : 488473,
          "Thrift" : 319175
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the filtering during aggregation returning wrong data after turning on the Trino dialect.",
      "validationOrRequirement" : "The reproduce steps must be followed correctly. The StarRocks version must be 3.3.4.",
      "attemptedFixes" : "The reproduce steps are provided in the description. The issue has been discussed with the team members, but no specific fix is mentioned.",
      "otherNotes" : "The issue is about filtering during aggregation returning wrong data after turning on the Trino dialect. The reproduce steps are provided in the description. The expected behavior is to return 1, but the real behavior is to return 3. The StarRocks version is 3.3.4. The issue has been reproduced and the error message is provided. There are discussions about whether StarRocks should support this feature and if so, how to handle the filter feature.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285135
  }, {
    "issueDTO" : {
      "id" : 2275601665,
      "title" : "Casks with homepage or source issues",
      "url" : "https://github.com/Homebrew/homebrew-cask/issues/172732",
      "repositoryName" : "Homebrew/homebrew-cask",
      "description" : "Testbot will automatically comment here once issues are found in Casks. \r\nThese should be easy issues for new contributors to work on.",
      "updatedAt" : 1752197676.000000000,
      "user" : "SMillerDev",
      "userHtmlUrl" : "https://github.com/SMillerDev",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1484494?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "quodlibet source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "shattered-pixel-dungeon source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "aleph-one source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "clickup source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "lbry source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "buckets source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "biscuit source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "marvel source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "mplab-xc16 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "playcover-community source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "freeshow source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "hdfview source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "samsung-portable-ssd-t7 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "iina-plus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "google-web-designer source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "sonarr@beta source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "namechanger source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "itraffic source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "power-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "logitune source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "moom source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "openra source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "vysor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "gephi source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "prezi-video source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "sparkleshare source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "syncalicious source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "moneymoney source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "celestia source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "supertuxkart source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "cityofzion-neon source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "drawbot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "mailspring source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "jumpshare source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "safari-technology-preview source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "metarename source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "posterazor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "piezo source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "pixelorama source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "universal-media-server source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "lunarbar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "minisim source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "tenable-nessus-agent source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "soundtoys source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "synology-photo-station-uploader source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957984780", "keet source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8962738793", "command-tab-plus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8962738793", "synology-photo-station-uploader source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957984780\r\n\r\nThe application has been removed, or at least I couldn't find it on the download site, the closest thing that I could find is [This](https://www.synology.com/en-us/support/download/VirtualDSM?version=7.2#utilities) or [This](https://www.synology.com/en-us/support/download/DDSM?version=6.2#system)", "@Eason-S-Lu Thanks for looking into it.\r\nIf it is indeed not available any more, a PR can be opened to `disable` the cask, here's an example: https://github.com/Homebrew/homebrew-cask/pull/172410", "> samsung-portable-ssd-t7 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830\r\nhttps://github.com/Homebrew/homebrew-cask/actions/runs/8957841830, I think the entire action is misconfigured, newer version of the test does not use the -s option. See https://github.com/Homebrew/homebrew-cask/actions/runs/8978228967\r\n\r\nThis commit has fixed this issue a4718d9e965d260f5739d520aac381e04ed87b5d", "touch-bar-simulator should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8994700870", "gretl source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9040045838", "Hello, the dvdstyler seems to have a problem with the download URL :\r\n```\r\nbrew install dvdstyler\r\n==> Downloading https://downloads.sourceforge.net/dvdstyler/DVDStyler-3.2.1-MacOSX.dmg\r\ncurl: (22) The requested URL returned error: 404     \r\nhttps://downloads.sourceforge.net/dvdstyler/DVDStyler-3.2.1-MacOSX.dmg\r\n```\r\nI don't know how or what to do, but it's probably in there :\r\nhttps://github.com/Homebrew/homebrew-cask/blob/29b229ac878e6fa2e53028f9682d9f6dcc330d4b/Casks/d/dvdstyler.rb", "smart-converter-pro source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9088591766", "snipy source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9105032431", "jetbrains-gateway source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9121531766", "font-inconsolata-g source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9136243239", "get-backup-pro source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9136243239", "cardpresso source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9136243239", "font-rounded-mplus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9144085505", "quiterss source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9217240516", "touchosc-editor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9262141233", "quiterss source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9278806536", "font-genshingothic source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9295536516", "font-hanamina source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9334661753", "font-ezra-sil source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9342875566", "cleanclip source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9342875566", "parallels-access source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9342875566", "ringcentral-meetings source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9359749280", "cloud189 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9359749280", "webplotdigitizer source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9376717587", "mblock source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9393671688", "wormhole source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9410231623", "monotype source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9425131537", "jalview source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9425131537", "vivaldi@snapshot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9441127505", "confluent-cli source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9475234215", "ringcentral-meetings source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9492208269", "vapor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9557430319", "fuzzyclock source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9574669045", "ideamaker source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9590202712", "operator source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9629772329", "polypad source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9654955412", "clipgrab source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9672085240", "sameboy source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9672085240", "kstars source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9689221986", "fabfilter-volcano source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9689221986", "font-infini source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9753518102", "denemo source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9801738028", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9849478500", "font-chiayi-city source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9866693223", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9849478500", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9849478500", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10024595767", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10024595767", "ifunbox source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10086609691", "font-jaapokki source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10190357305", "keepassxc@snapshot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10190357305", "font-jaapokki source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10190357305", "revolver-office source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10241061127", "optimage source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10276570498", "yealink-meeting source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10344488864", "graalvm-jdk@21 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10379870800", "azure-data-studio source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10413152596", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10024595767", "artisan source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10445565425", "font-lexend-deca source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10500241285", "retroactive should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10500241285", "xiami source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10518318277", "mamp source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10518318277", "retroactive should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10500241285", "metashapepro source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10534603295", "ogdesign-eagle source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10534603295", "pretzel source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10551954731", "roam source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10588575678", "sonixd should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10625266120", "todour source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10649865808", "polypad source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10649865808", "pb source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10675079349", "thedesk should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10730863399", "font-scheherazade source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10730863399", "thedesk should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10730863399", "tysimulator should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10764933202", "font-chenyuluoyan source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10858376128", "font-sans-forgetica source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10858376128", "mit-app-inventor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10913921346", "airdisplay source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10968546029", "font-meltho source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11043908568", "sensei source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11172439198", "subsync should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11189291785", "font-hyppolit source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11246587124", "polyphone source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11265814666", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11622658696", "shadow source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11675845634", "monarch source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11714920841", "mate-translate source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11761074175", "cisdem-duplicate-finder source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11789040471", "plugdata@nightly source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11789040471", "menubar-stats source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11808887648", "font-lxgw-fasmartgothic should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11944889708", "fl-studio source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11992036093", "jgrasp source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12001560309", "mochi source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12077530793", "bepo source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12151295297", "ava source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12171512023", "ava source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12208733716", "azure-data-studio@insiders source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12364593946", "whoozle-android-file-transfer@nightly source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12440967310", "shadow-bot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12522593291", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12531360234", "mate-translate source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12980389880", "duplicate-annihilator-for-photos source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13043875432", "scilab source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13126455628", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13191340191", "mate-translate source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13254024883", "fmail source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13350473635", "cisdem-pdf-converter-ocr source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13610781662", "xiami source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13689180882", "istherenet source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13801718060", "fmail2 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13848005328", "font-sumana source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "font-koho source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "font-radio-canada source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "font-abhaya-libre source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "font-tiro-bangla source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "vesta source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13878582532", "xiami source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13982745758", "nomad source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14014246153", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14025298437", "multimc source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14298892812", "thelowtechguys-cling source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14346995509", "ved source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14370346244", "isubtitle source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14393651740", "classroom-mode-for-minecraft source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14506088189", "infra source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14607990720", "monofocus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14806136362", "notchnook source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14816434725", "longplay source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14896676415", "wins source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14919493587", "softraid source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15010256877", "istat-server source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15080279426", "latest source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15151482044", "infra source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15222055356", "font-bukyvede-regular source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15244264768", "longplay source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15289408479", "lo-rain source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15289408479", "firebase-admin source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15369561683", "squash source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15369561683", "bricklink-partdesigner source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15456352827", "deeper source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15480828108", "deeper source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15480828108", "soundanchor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15502841713", "db-browser-for-sqlcipher@nightly source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15548485471", "isubtitle source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15624381675", "monofocus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15669782524", "paletro source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15769266242", "font-stix source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15769266242", "ideamaker source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15813388160", "font-fzxiaobiaosong-b05 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15813388160", "font-fzshusong-z01 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15813388160", "font-fzkai-z03 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15899954150", "pastenow source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15916104168", "polyphone source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15961806460", "font-fzhei-b01 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16013983634", "font-fzxiaobiaosong-b05 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16063882972", "diskcatalogmaker source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16083215336", "tal-drum source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16131764584", "font-fzfangsong-z02 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16209752535" ],
      "repository" : {
        "description" : "\uD83C\uDF7B A CLI workflow for the administration of macOS applications distributed as binaries",
        "homepage" : "https://brew.sh",
        "name" : "homebrew-cask",
        "fullName" : "Homebrew/homebrew-cask",
        "htmlUrl" : "https://github.com/Homebrew/homebrew-cask",
        "gitUrl" : "git://github.com/Homebrew/homebrew-cask.git",
        "sshUrl" : "git@github.com:Homebrew/homebrew-cask.git",
        "cloneUrl" : "https://github.com/Homebrew/homebrew-cask.git",
        "owner" : {
          "login" : "Homebrew",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11010,
        "stargazersCount" : 21452,
        "watchersCount" : 21452,
        "size" : 375921,
        "openIssuesCount" : 23,
        "subscribersCount" : 313,
        "pushedAt" : "2025-07-12T01:03:00Z",
        "languages" : {
          "Shell" : 32255,
          "Ruby" : 6423972,
          "Python" : 14037
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the Casks with homepage or source issues, which should be easy to fix for new contributors.",
      "validationOrRequirement" : "The issue does not mention any specific validations or requirements, but it does mention that the casks should be easy to fix for new contributors.",
      "attemptedFixes" : "The issue mentions several attempted fixes, including disabling the cask, archiving the cask, and fixing the download URL. It also mentions that the entire action is misconfigured.",
      "otherNotes" : "The issue is about Casks with homepage or source issues. These casks should be easy to fix for new contributors. The issue is described in detail with multiple comments and GitHub actions runs. The author is SMillerDev and the repository name is Homebrew/homebrew-cask.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285142
  }, {
    "issueDTO" : {
      "id" : 1944222094,
      "title" : "Add a Simple JavaScript Music Player",
      "url" : "https://github.com/thinkswell/javascript-mini-projects/issues/958",
      "repositoryName" : "thinkswell/javascript-mini-projects",
      "description" : "# Develop a Javascript Music Player app.\r\n\r\n### Description \uD83D\uDCDC\r\nA simple, minimalistic JavaScript music player app\r\n\r\n### Requirements \uD83D\uDEE0???\r\n* The app, is going to have beautifully designed cards, with play/pause button, allow changing to previous or next music\r\n* Will be completely responsive\r\n\r\n### Bonuses ???\r\n* The app can have a playlist feature in future\r\n\r\n------------------------------------------\r\n\r\nAny number of people can work on a single issue \uD83D\uDC68???\uD83D\uDCBB\uD83D\uDC68???\uD83D\uDCBB\r\nThis issue is open to all.\uD83C\uDF0D???\r\n\r\n--------------\r\nProject location \uD83D\uDC49\uD83C\uDFFB MusicPlayer/akash0708/\r\n--------------\r\n\r\n**\uD83D\uDC68\uD83C\uDFFB???\uD83D\uDCBB Happy Coding \uD83D\uDC69\uD83C\uDFFB???\uD83D\uDCBB**\r\n\r\n",
      "updatedAt" : 1752196948.000000000,
      "user" : "akash0708",
      "userHtmlUrl" : "https://github.com/akash0708",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/110753356?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\uD83D\uDC4B @akash0708\n\n Thanks for opening your first issue here! Be sure to follow the issue template!", "Hello @akash0708 , can you assign me this issue as i am a beginner, it would really help me in my open source journey ", "I wanna work on this issue, I wanna test my real life JS skills here.", "can i work on this issue", "> can i work on this issue\r\n\r\nYes.", "Thank you for the issue", "Can I work in this task?" ],
      "repository" : {
        "description" : "Awesome Collection of amazing javascript mini-projects.",
        "homepage" : "",
        "name" : "javascript-mini-projects",
        "fullName" : "thinkswell/javascript-mini-projects",
        "htmlUrl" : "https://github.com/thinkswell/javascript-mini-projects",
        "gitUrl" : "git://github.com/thinkswell/javascript-mini-projects.git",
        "sshUrl" : "git@github.com:thinkswell/javascript-mini-projects.git",
        "cloneUrl" : "https://github.com/thinkswell/javascript-mini-projects.git",
        "owner" : {
          "login" : "thinkswell",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 913,
        "stargazersCount" : 1382,
        "watchersCount" : 1382,
        "size" : 634880,
        "openIssuesCount" : 96,
        "subscribersCount" : 13,
        "pushedAt" : "2024-12-05T05:14:05Z",
        "languages" : {
          "Java" : 596,
          "Dockerfile" : 94,
          "CSS" : 560764,
          "SCSS" : 224136,
          "JavaScript" : 2251348,
          "Vue" : 7993,
          "HTML" : 613248,
          "Svelte" : 4624,
          "Nix" : 26,
          "EJS" : 1588
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Develop a simple, minimalistic JavaScript music player app",
      "validationOrRequirement" : "The app should have beautifully designed cards, with play/pause button, allow changing to previous or next music, and be completely responsive. The app can have a playlist feature in future.",
      "attemptedFixes" : "None mentioned in the comments",
      "otherNotes" : "The issue is open to all, and any number of people can work on a single issue. The app should have beautifully designed cards with play/pause button, allow changing to previous or next music, and be completely responsive.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285146
  }, {
    "issueDTO" : {
      "id" : 1885060367,
      "title" : "switch more test cases to use MultithreadTestCase",
      "url" : "https://github.com/pytorch/pytorch/issues/108744",
      "repositoryName" : "pytorch/pytorch",
      "description" : "MultithreadTestCase allow us to run less resouce by spawning threads instead of processes, which could make distributed tests run faster. We have the following test files still not using MultithreadTestCase, and we should switch those test case to use it.\r\n\r\n[ ] https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_math_ops.py\r\n[ ] https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_matrix_ops.py\r\n[ ] https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_tensor_ops.py\r\n[ ] https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_embedding_ops.py\r\n\r\nExample test case that already uses multithreaded test case, see https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_pointwise_ops.py#L75\r\n\r\none just need to extend the `DTensorOpTestBase` for the above test files, should be relatively simple",
      "updatedAt" : 1752196135.000000000,
      "user" : "wanchaol",
      "userHtmlUrl" : "https://github.com/wanchaol",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9443650?v=4",
      "labels" : [ "triaged", "good first issue", "module: dtensor" ],
      "state" : "OPEN",
      "comments" : [ "Hi @wanchaol ! I would like to work on this issue.", "@wanchaol  Are people still working on this? Or can I pick it up ?", "Hello, if the bug is still unresolved, I would be interested in contributing a potential solution. Let me know if there's an opportunity to assist with resolving this issue.", "Hello @wanchaol, if I am not mistaken all the files have been moved from `_tensor` to `tensor` but the issue seems to still remain, so I've prepared a PR to fix that. I included advise given in #108749.\nAlthough lukesaleh seemed to have a similar solution as I see now.\nLooking through his failed test cases, I noticed a permutation between some of the test cases expected result and their received result.\nStill waiting on the CI to run on my PR though" ],
      "repository" : {
        "description" : "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
        "homepage" : "https://pytorch.org",
        "name" : "pytorch",
        "fullName" : "pytorch/pytorch",
        "htmlUrl" : "https://github.com/pytorch/pytorch",
        "gitUrl" : "git://github.com/pytorch/pytorch.git",
        "sshUrl" : "git@github.com:pytorch/pytorch.git",
        "cloneUrl" : "https://github.com/pytorch/pytorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 24655,
        "stargazersCount" : 91465,
        "watchersCount" : 91465,
        "size" : 1080672,
        "openIssuesCount" : 16562,
        "subscribersCount" : 1785,
        "pushedAt" : "2025-07-12T01:02:24Z",
        "languages" : {
          "C" : 1814194,
          "GDB" : 653,
          "CMake" : 829778,
          "Makefile" : 12990,
          "HTML" : 384,
          "Metal" : 312044,
          "Jupyter Notebook" : 186191,
          "Shell" : 475776,
          "JavaScript" : 92859,
          "Objective-C" : 58784,
          "Ruby" : 2774,
          "Assembly" : 336348,
          "Python" : 72951131,
          "GLSL" : 204577,
          "Thrift" : 7013,
          "PowerShell" : 3657,
          "Smarty" : 376,
          "Java" : 87332,
          "C++" : 42265232,
          "Objective-C++" : 1375996,
          "HIP" : 287192,
          "Cuda" : 3659747,
          "Dockerfile" : 34238,
          "Starlark" : 328636,
          "Batchfile" : 80571,
          "Linker Script" : 473,
          "Vim Script" : 154
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Switch more test cases to use MultithreadTestCase to run less resource by spawning threads instead of processes, making distributed tests run faster.",
      "validationOrRequirement" : "Extending the `DTensorOpTestBase` for the above test files, relatively simple.",
      "attemptedFixes" : "A PR has been prepared to fix the issue.",
      "otherNotes" : "Files to be updated: https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_math_ops.py, https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_matrix_ops.py, https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_tensor_ops.py, https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_embedding_ops.py. Existing multithreaded test case example: https://github.com/pytorch/pytorch/blob/main/test/distributed/_tensor/test_pointwise_ops.py#L75. PR has been prepared to fix the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285152
  }, {
    "issueDTO" : {
      "id" : 2953437580,
      "title" : "Deserialization of a node in a freed area probably produces the wrong error",
      "url" : "https://github.com/ava-labs/firewood/issues/831",
      "repositoryName" : "ava-labs/firewood",
      "description" : "The problem here is that we currently deserialize `StoredArea<Area<Node, FreeArea>>` but only when it's expted to be a freed area. If there happens to be a node on a free list, bad things are likely to happen since we'll deserialize the node using serde.\n\nThe right fix is to remove serde everywhere.\n\nWe're not using it in many places any more, and it's clearly slower. Although it's in `Cargo.toml` for the firewood subdirectory, it isn't referenced anywhere in that directory. Only storage is currently using it, and it's only being used to serialize some stuff related to free space management, such as this one and another for `AreaIndex`.\n\nThis would also remove a lot of the benchmarks related to serde serialization timings, which show serde is almost always slower.\n\nBonus points if you can figure out why manual serialization of a full node is a tiny bit slower than serde.\n```\n     Running benches/serializer.rs (/Users/rkuris/open-source/firewood/target/release/deps/serializer-6c232d65bd4e75a9)\nleaf/serde              time:   [69.045 ns 69.287 ns 69.553 ns]\nFound 1 outliers among 100 measurements (1.00%)\n  1 (1.00%) high mild\nleaf/manual             time:   [39.281 ns 39.360 ns 39.450 ns]\nFound 9 outliers among 100 measurements (9.00%)\n  9 (9.00%) high mild\n\nhas_value/serde         time:   [239.35 ns 243.83 ns 247.95 ns]\nhas_value/manual        time:   [80.964 ns 81.715 ns 83.037 ns]\nFound 2 outliers among 100 measurements (2.00%)\n  1 (1.00%) high mild\n  1 (1.00%) high severe\n\n1_child/serde           time:   [153.20 ns 154.21 ns 155.28 ns]\n1_child/manual          time:   [73.337 ns 73.438 ns 73.569 ns]\nFound 14 outliers among 100 measurements (14.00%)\n  7 (7.00%) high mild\n  7 (7.00%) high severe\n\n2_child/serde           time:   [246.32 ns 251.62 ns 256.86 ns]\n2_child/manual          time:   [106.19 ns 106.60 ns 107.05 ns]\nFound 5 outliers among 100 measurements (5.00%)\n  5 (5.00%) high mild\n\n16_child/serde          time:   [483.69 ns 494.48 ns 504.73 ns]\n16_child/manual         time:   [502.68 ns 505.68 ns 509.86 ns]\nFound 4 outliers among 100 measurements (4.00%)\n  1 (1.00%) high mild\n  3 (3.00%) high severe\n```",
      "updatedAt" : 1752195928.000000000,
      "user" : "rkuris",
      "userHtmlUrl" : "https://github.com/rkuris",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3193068?v=4",
      "labels" : [ "rust", "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "`git grep bincode` points to all the places that require new code:\n```\nfirewood/Cargo.toml:bincode = \"1.3.3\"\nstorage/Cargo.toml:bincode = \"1.3.3\"\nstorage/benches/serializer.rs:use bincode::Options;\nstorage/benches/serializer.rs:    let serializer = bincode::DefaultOptions::new().with_varint_encoding();\nstorage/benches/serializer.rs:    let serializer = bincode::DefaultOptions::new().with_varint_encoding();\nstorage/src/nodestore.rs:use bincode::{DefaultOptions, Options as _};\nstorage/src/nodestore.rs:fn serializer() -> impl bincode::Options {\n```\n\n`git grep '\\(Des\\|S\\)erialize'` points to all the places you can remove code, as you'll no longer need to derive or implement serialization using serde for all these structures:\n```\ngrpc-testtool/proto/sync/sync.proto:  SerializedPath key = 1;\ngrpc-testtool/proto/sync/sync.proto:message SerializedPath {\ngrpc-testtool/src/bin/process-server.rs:use serde::Deserialize;\ngrpc-testtool/src/bin/process-server.rs:#[derive(Clone, Debug, Deserialize)]\nstorage/src/node/branch.rs:use serde::ser::SerializeStruct as _;\nstorage/src/node/branch.rs:use serde::{Deserialize, Serialize};\nstorage/src/node/branch.rs:    use serde::{Deserialize, Serialize};\nstorage/src/node/branch.rs:    #[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]\nstorage/src/node/branch.rs:impl Serialize for BranchNode {\nstorage/src/node/branch.rs:        S: serde::Serializer,\nstorage/src/node/branch.rs:impl<'de> Deserialize<'de> for BranchNode {\nstorage/src/node/branch.rs:        D: serde::Deserializer<'de>,\nstorage/src/node/branch.rs:        #[derive(Deserialize)]\nstorage/src/node/branch.rs:        struct SerializedBranchNode {\nstorage/src/node/branch.rs:        let s: SerializedBranchNode = Deserialize::deserialize(deserializer)?;\nstorage/src/node/leaf.rs:use serde::{Deserialize, Serialize};\nstorage/src/node/leaf.rs:#[derive(PartialEq, Eq, Clone, Serialize, Deserialize)]\nstorage/src/node/mod.rs:use serde::{Deserialize, Serialize};\nstorage/src/node/mod.rs:#[derive(PartialEq, Eq, Clone, Debug, EnumAsInner, Serialize, Deserialize)]\nstorage/src/node/path.rs:use serde::{Deserialize, Serialize};\nstorage/src/node/path.rs:#[derive(PartialEq, Eq, Clone, Serialize, Deserialize)]\nstorage/src/nodestore.rs:use serde::{Deserialize, Serialize};\nstorage/src/nodestore.rs:#[derive(PartialEq, Eq, Clone, Debug, Deserialize, Serialize)]\nstorage/src/nodestore.rs:#[derive(PartialEq, Eq, Clone, Debug, Deserialize, Serialize)]\nstorage/src/nodestore.rs:#[derive(Debug, Clone, Copy, PartialEq, Eq, Deserialize, Serialize, NoUninit, AnyBitPattern)]\nstorage/src/nodestore.rs:#[derive(Copy, Debug, PartialEq, Eq, Serialize, Deserialize, Clone, NoUninit, AnyBitPattern)]\nstorage/src/nodestore.rs:#[derive(Debug, PartialEq, Eq, Clone, Copy, Serialize, Deserialize)]\nstorage/src/trie_hash.rs:use serde::{Deserialize, Serialize};\nstorage/src/trie_hash.rs:impl Serialize for TrieHash {\nstorage/src/trie_hash.rs:        S: serde::Serializer,\nstorage/src/trie_hash.rs:impl<'de> Deserialize<'de> for TrieHash {\nstorage/src/trie_hash.rs:        D: serde::Deserializer<'de>,\n```\n\ngrpc-testtool might still want or need serde, or this can be done in another ticket, although it looks like it's not used much there." ],
      "repository" : {
        "description" : "Compaction-Less Database Optimized for Efficiently Storing Recent Merkleized Blockchain State",
        "homepage" : "https://ava-labs.github.io/firewood/",
        "name" : "firewood",
        "fullName" : "ava-labs/firewood",
        "htmlUrl" : "https://github.com/ava-labs/firewood",
        "gitUrl" : "git://github.com/ava-labs/firewood.git",
        "sshUrl" : "git@github.com:ava-labs/firewood.git",
        "cloneUrl" : "https://github.com/ava-labs/firewood.git",
        "owner" : {
          "login" : "ava-labs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 131,
        "watchersCount" : 131,
        "size" : 46567,
        "openIssuesCount" : 51,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-12T00:44:19Z",
        "languages" : {
          "Shell" : 5731,
          "Rust" : 635364,
          "C" : 13560,
          "Go" : 76076
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "remove serde serialization and deserialization everywhere in the codebase",
      "validationOrRequirement" : "deserialize StoredArea<Area<Node, FreeArea>> only when it's expected to be a freed area",
      "attemptedFixes" : "remove serde everywhere, it's not used in many places anymore and it's slower",
      "otherNotes" : "bonus points if you can figure out why manual serialization of a full node is a tiny bit slower than serde",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285156
  }, {
    "issueDTO" : {
      "id" : 3176311643,
      "title" : "Update Conversation API Docs with the Latest Changes",
      "url" : "https://github.com/dapr/docs/issues/4687",
      "repositoryName" : "dapr/docs",
      "description" : "The following changes needs to be reflected in Conversation API docs:\n\n- Promotion of the Conversation API from alpha to beta ([#8784](https://github.com/dapr/dapr/issues/8784)).\n- Addition of streaming response support ([#8813](https://github.com/dapr/dapr/issues/8813)).\n- Implementation of tool calling support ([#8816](https://github.com/dapr/dapr/issues/8816)).\n",
      "updatedAt" : 1752195381.000000000,
      "user" : "bibryam",
      "userHtmlUrl" : "https://github.com/bibryam",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/513159?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Sorry if i asked a silly question, is this issue more suitable in the docs repository? If so, i am willing to summarize these changes and submit a PR there", "I took a further look and it seems preliminary work for this issue has not yet been fully completed. So I will come back later to see is there any progress.", "@Vickko Yes, please wait to move on this until the upstream PR has been merged into dapr/dapr as it's a bit fluid now." ],
      "repository" : {
        "description" : "Dapr user documentation, used to build docs.dapr.io",
        "homepage" : "https://docs.dapr.io",
        "name" : "docs",
        "fullName" : "dapr/docs",
        "htmlUrl" : "https://github.com/dapr/docs",
        "gitUrl" : "git://github.com/dapr/docs.git",
        "sshUrl" : "git@github.com:dapr/docs.git",
        "cloneUrl" : "https://github.com/dapr/docs.git",
        "owner" : {
          "login" : "dapr",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 766,
        "stargazersCount" : 1007,
        "watchersCount" : 1007,
        "size" : 341863,
        "openIssuesCount" : 146,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-11T21:56:50Z",
        "languages" : {
          "Shell" : 111,
          "SCSS" : 7848,
          "JavaScript" : 1116,
          "HTML" : 36646,
          "Python" : 1054
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update Conversation API Docs with the Latest Changes",
      "validationOrRequirement" : "the changes need to be reflected in the Conversation API docs, specifically promoting the Conversation API from alpha to beta, adding streaming response support, and implementing tool calling support",
      "attemptedFixes" : "preliminary work has not yet been fully completed, so no fixes have been attempted yet",
      "otherNotes" : "The issue is related to updating the Conversation API docs and includes specific changes to be reflected. The author is willing to summarize the changes and submit a PR to the docs repository, but is waiting for upstream PR to be merged.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285160
  }, {
    "issueDTO" : {
      "id" : 3061535991,
      "title" : "[API server] API server needs to be restarted to pick up credentials newly setup",
      "url" : "https://github.com/skypilot-org/skypilot/issues/5578",
      "repositoryName" : "skypilot-org/skypilot",
      "description" : "This is observed for AWS, Nebius, k8s, Vast\n\nAlso, when a new catalog file is fetched, there might be a difference for the catalogs among different executors.",
      "updatedAt" : 1752195296.000000000,
      "user" : "Michaelvll",
      "userHtmlUrl" : "https://github.com/Michaelvll",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6753189?v=4",
      "labels" : [ "good first issue", "good starter issues" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "SkyPilot: Run AI and batch jobs on any infra (Kubernetes or 16+ clouds). Get unified execution, cost savings, and high GPU availability via a simple interface.",
        "homepage" : "https://docs.skypilot.co/",
        "name" : "skypilot",
        "fullName" : "skypilot-org/skypilot",
        "htmlUrl" : "https://github.com/skypilot-org/skypilot",
        "gitUrl" : "git://github.com/skypilot-org/skypilot.git",
        "sshUrl" : "git@github.com:skypilot-org/skypilot.git",
        "cloneUrl" : "https://github.com/skypilot-org/skypilot.git",
        "owner" : {
          "login" : "skypilot-org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 701,
        "stargazersCount" : 8345,
        "watchersCount" : 8345,
        "size" : 168409,
        "openIssuesCount" : 431,
        "subscribersCount" : 71,
        "pushedAt" : "2025-07-12T00:26:43Z",
        "languages" : {
          "HCL" : 9309,
          "Smarty" : 3595,
          "Dockerfile" : 3802,
          "Jinja" : 156219,
          "Shell" : 83038,
          "CSS" : 3621,
          "Makefile" : 843,
          "JavaScript" : 665919,
          "Go" : 20687,
          "HTML" : 34448,
          "Python" : 7304307
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The API server needs to be restarted to pick up credentials newly setup.",
      "validationOrRequirement" : "None specified.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is observed in AWS, Nebius, k8s, Vast environments, and may also be related to fetching new catalog files and differences among executors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285163
  }, {
    "issueDTO" : {
      "id" : 3182653879,
      "title" : "[Term Entry] PyTorch Tensor Operations: .copysign()",
      "url" : "https://github.com/Codecademy/docs/issues/7177",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the `.copysign()` term in PyTorch. The entry should go in a new file under `docs/content/pytorch/concepts/tensor-operations/terms/copysign/copysign.md`.\n\nThe entry should include:\n\n- An introduction to the concept\n- A `Syntax` section that provides the syntax for the concept\n- An `Example` section that provides an example demonstrating the concept in use\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md), and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1752195261.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "python", "claimed", "pytorch", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hey @codecademy-docs can youplease assign this issue to me , i really want to work on this issue.\n", "Hey @anuj123upadhyay, you have already submitted 4 PRs, once they are merged - we can assign more issues to you. For now, let's work on merging the PRs. \uD83D\uDE04 \n", "Hello @codecademy-docs, I would like to work on this issue. Could you please assign it to me?", "Hey @JGVSAI16 You???re assigned \uD83C\uDF89 In addition to the documents linked in the description, please also look at the [Contribution Guide](https://www.codecademy.com/resources/docs/contribution-guide). After creating a PR, the maintainer(s) (with the collaborator label) will add comments/suggestions to address any revisions before approval.", "Hello again @codecademy-docs, I've run into a small issue while adding some finishing touches to my markdown file.  In order to finish up the file, I need to add some pieces of [Catalog Content](https://github.com/Codecademy/docs/blob/main/documentation/catalog-content.md), but I've completed most of the 9 PyTorch courses, but none of them have ever mentioned `.copysign()`. Do you think I should leave the content area blank in the metadata or should I just put in some generic PyTorch courses?" ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4089,
        "stargazersCount" : 945,
        "watchersCount" : 945,
        "size" : 136609,
        "openIssuesCount" : 207,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-11T17:37:40Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new entry for the .copysign() term in PyTorch, including introduction, syntax, and example, in a new file under docs/content/pytorch/concepts/tensor-operations/terms/copysign/copysign.md.",
      "validationOrRequirement" : "The entry should include an introduction, syntax, and example, and follow the term entry template, content standards, and markdown style guide.",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "Please refer to the term entry template, content standards, and markdown style guide when working on the PR for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285167
  }, {
    "issueDTO" : {
      "id" : 3168999667,
      "title" : "Plots that need to be updated to use the new ComputeGraph",
      "url" : "https://github.com/MakieOrg/Makie.jl/issues/5114",
      "repositoryName" : "MakieOrg/Makie.jl",
      "description" : "This is a quick overview of which recipes still need to be translated to use the ComputeGraph (Makie 0.24)\n\nSome recipes more or less just require replacing `map/lift/@lift/on/onany` with `map!`. The 0.24 blog post has/will have some instructions on how to do this, so it should be easy for anyone to do. If you want to contribute something relatively small feel free to update one (or more) and make a pull request. A rough list of easy plots/recipes:\n- [x] arc #5165\n- [x] band #5165\n- [x] pie #5165\n- [x] poly #5121\n- [x] stairs #5165\n- [x] stem #5165\n- [x] tooltip #5165\n- [x] wireframe #5165\n- [ ] density\n- [x] qqplot (distributions.jl) #5165\n- [ ] stephist\n- [ ] hist\n- [ ] timeseries\n- [ ] series\n\nSome recipes still use `register_computation!()` when they could use `map!()`. This should be a fairly easy cleanup/replacement as well.\n- [ ] tricontourf\n- [x] spy #5165\n- [x] scatterlines #5165\n\nSome recipes may require some more refactoring, like breaking up an `onany` that updates multiple observables. They should still be fairly easy to translate (though I haven't checked in depth). `contourf` or `errorbars` might be an instructive example.\n- [ ] barplot\n- [x] contour #5121\n- [x] triplot #5121\n- [ ] waterfall\n- [ ] boxplot\n- [ ] crossbar\n- [x] hexbin #5121\n- [ ] violin\n\nSome recipes apply transformations and projections. These should probably be delayed a bit, as we can/should extend what's happening for primitive plots to recipe plots here\n- ~~hlines, vlines, hspan, vspan (+ limit tracking)~~\n- [ ] annotation (+ bbox handling)\n- [x] bracket #5121\n- [x] streamplot  #5121\n- [x] textlabel #5121\n- [x] voronoiplot #5121\n- [x] arrows #5121\n\nOther:\n- [ ] volumeslices (how do we want to handle the transformation system)\n\nNot sure if done:\n- [ ] axis3d (maybe needs full rework?)\n- [ ] datashader\n- [ ] rainclouds",
      "updatedAt" : 1752195078.000000000,
      "user" : "ffreyer",
      "userHtmlUrl" : "https://github.com/ffreyer",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10947937?v=4",
      "labels" : [ "planning", "compute pipeline", "cleanup", "Makie", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Interactive data visualizations and plotting in Julia",
        "homepage" : "https://docs.makie.org/stable",
        "name" : "Makie.jl",
        "fullName" : "MakieOrg/Makie.jl",
        "htmlUrl" : "https://github.com/MakieOrg/Makie.jl",
        "gitUrl" : "git://github.com/MakieOrg/Makie.jl.git",
        "sshUrl" : "git@github.com:MakieOrg/Makie.jl.git",
        "cloneUrl" : "https://github.com/MakieOrg/Makie.jl.git",
        "owner" : {
          "login" : "MakieOrg",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 348,
        "stargazersCount" : 2577,
        "watchersCount" : 2577,
        "size" : 675618,
        "openIssuesCount" : 859,
        "subscribersCount" : 25,
        "pushedAt" : "2025-07-12T00:12:10Z",
        "languages" : {
          "Julia" : 3168909,
          "CSS" : 646,
          "TeX" : 392,
          "JavaScript" : 1262562,
          "GLSL" : 244271
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update plots to use the new ComputeGraph in Makie 0.24, focusing on recipes that still need to be translated.",
      "validationOrRequirement" : "Recipes should be updated to use the new ComputeGraph, with specific requirements for replacing certain functions, refactoring code, and handling transformations and projections.",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "The issue is related to updating plots to use the new ComputeGraph in Makie 0.24, with a focus on recipes that still need to be translated. The task involves replacing certain functions with others, refactoring code, and handling transformations and projections.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285172
  }, {
    "issueDTO" : {
      "id" : 3022541607,
      "title" : "[FEATURE] Allow `LlmGenerationClient::geneate()` directly return a JSON value",
      "url" : "https://github.com/cocoindex-io/cocoindex/issues/400",
      "repositoryName" : "cocoindex-io/cocoindex",
      "description" : "We may change the trait to allow [`LlmGenerationClient::geneate()`](https://github.com/cocoindex-io/cocoindex/blob/1218420a02b01886e614b340bd450eb7dce908d6/src/llm/mod.rs#L46-L49) directly return a JSON. The return type can be an enum, with either a JSON or a String, depending on if JSON schema is provided in request.\r\n\r\n_Originally posted by @badmonster0 in https://github.com/cocoindex-io/cocoindex/pull/395#discussion_r2061032086_\r\n            ",
      "updatedAt" : 1752194734.000000000,
      "user" : "badmonster0",
      "userHtmlUrl" : "https://github.com/badmonster0",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1772842?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I can work on this, please assign!", "hi @par4m thanks a lot for taking a look at this ticket, we freed up this ticket for now since it has been inactive for a month, if you are actively working on it, please let us know and we will reassign to you! \nreally appreciate your contribution!" ],
      "repository" : {
        "description" : "Data transformation framework for AI. Ultra performant, with incremental processing.",
        "homepage" : "https://cocoindex.io",
        "name" : "cocoindex",
        "fullName" : "cocoindex-io/cocoindex",
        "htmlUrl" : "https://github.com/cocoindex-io/cocoindex",
        "gitUrl" : "git://github.com/cocoindex-io/cocoindex.git",
        "sshUrl" : "git@github.com:cocoindex-io/cocoindex.git",
        "cloneUrl" : "https://github.com/cocoindex-io/cocoindex.git",
        "owner" : {
          "login" : "cocoindex-io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 149,
        "stargazersCount" : 2163,
        "watchersCount" : 2163,
        "size" : 10294,
        "openIssuesCount" : 59,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-11T20:18:49Z",
        "languages" : {
          "Rust" : 820484,
          "Python" : 180407
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow `LlmGenerationClient::geneate()` directly return a JSON value",
      "validationOrRequirement" : "return type can be an enum, with either a JSON or a String, depending on if JSON schema is provided in request",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "Originally posted by @badmonster0, originally assigned to someone, then reassigned due to inactivity, and finally unassigned",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285175
  }, {
    "issueDTO" : {
      "id" : 3221092851,
      "title" : "Add a Rust crate size validation in the CI",
      "url" : "https://github.com/microsoft/msquic/issues/5243",
      "repositoryName" : "microsoft/msquic",
      "description" : "> We should consider adding a validation during the CI that the compressed crate size stays below 10MB. \n\n _Originally posted by @guhetier in [#5175](https://github.com/microsoft/msquic/issues/5175#issuecomment-3059730165)_\n\ncrates.io only accepts uploads smaller than 10MB, and we are dangerously close to the limit. We need to be aware of our crate being too big before we snap a release so we can prune it first, or we can't publish it.",
      "updatedAt" : 1752194509.000000000,
      "user" : "guhetier",
      "userHtmlUrl" : "https://github.com/guhetier",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15261469?v=4",
      "labels" : [ "Language: Rust", "github_actions", "Area: Packaging", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Cross-platform, C implementation of the IETF QUIC protocol, exposed to C, C++, C# and Rust.",
        "homepage" : "",
        "name" : "msquic",
        "fullName" : "microsoft/msquic",
        "htmlUrl" : "https://github.com/microsoft/msquic",
        "gitUrl" : "git://github.com/microsoft/msquic.git",
        "sshUrl" : "git@github.com:microsoft/msquic.git",
        "cloneUrl" : "https://github.com/microsoft/msquic.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 584,
        "stargazersCount" : 4375,
        "watchersCount" : 4375,
        "size" : 311257,
        "openIssuesCount" : 250,
        "subscribersCount" : 123,
        "pushedAt" : "2025-07-11T23:52:44Z",
        "languages" : {
          "C#" : 501421,
          "PowerShell" : 385778,
          "Dockerfile" : 12422,
          "C++" : 2131086,
          "Shell" : 22778,
          "C" : 5549599,
          "Rust" : 700822,
          "Batchfile" : 31243,
          "CMake" : 152531,
          "Roff" : 162751
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a Rust crate size validation in the CI",
      "validationOrRequirement" : "the compressed crate size stays below 10MB",
      "attemptedFixes" : "",
      "otherNotes" : "crates.io only accepts uploads smaller than 10MB, and we are dangerously close to the limit.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285177
  }, {
    "issueDTO" : {
      "id" : 58810913,
      "title" : "With an external grouper, there is no way to access the grouped value in a DataFrame(...).groupby(...).apply(...) workflow",
      "url" : "https://github.com/pandas-dev/pandas/issues/9545",
      "repositoryName" : "pandas-dev/pandas",
      "description" : "groupby-apply workflows are important pandas idioms. Here's a brief example grouping on a named DataFrame column:\n\n```\n>>> df = pd.DataFrame({'key': [1, 1, 1, 2, 2, 2, 3, 3, 3], 'value': range(9)})\n>>> result = df.groupby('key').apply(lambda x: x['key'])\n>>> result\nkey   \n1    0    1\n     1    1\n     2    1\n2    3    2\n     4    2\n     5    2\n3    6    3\n     7    3\n     8    3\nName: key, dtype: int64\n```\n\nAn important highlight of this example is the ability to reference the grouped value -- eg, `x['key']` -- inside the applied function.\n\npandas also supports grouping on arbitrary mapping functions, iterables, and lots of other objects. In these cases, the grouped value is not represented as a named column in the DataFrame. Thus, when using apply(...), there is no apparent way to access the group key value. The only alternative is to use a (slow) for-loop solution as in:\n\n```\nfoo = lambda _k, _g: ...\ngrouped = df.groupby(grouper)\nresult_iter = (foo(key, group) for key, group in grouped) \nkey_iter = (key for key, group in grouped)\npd.DataFrame.from_records(result_iter, index=key_iter)\n```\n\nIMHO, the ability to access the grouped value in an idiomatic way from within the applied function is ergonomically important; the groupby-apply idiom is at best partially realized without it.\n",
      "updatedAt" : 1752194487.000000000,
      "user" : "brianthelion",
      "userHtmlUrl" : "https://github.com/brianthelion",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/296082?v=4",
      "labels" : [ "Groupby", "Docs", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "see #9239 which implements the copy-assign idiom\n", "@jreback Sorry for being a complete n00b here, but at a quick glance I can't imagine how to solve the present issue with copy-assign. My imagination is pretty limited, though. Could you provide a basic intuition? Thanks!\n", "Do you have a small example where you need to reference the grouping key? I'm trying to see where this would be necessary (or just convenient).\n\nAlso, does the `.name` attribute on the values of the groupby help you out? I think it has the value of the evaluated (grouping) function for that group.\n", "```\nIn [9]: df.groupby('key').apply(lambda x: Series(x.name,x.index))\nOut[9]: \nkey   \n1    0    1\n     1    1\n     2    1\n2    3    2\n     4    2\n     5    2\n3    6    3\n     7    3\n     8    3\ndtype: int64\n```\n", "It appears that .name is the attribute that I've been looking for! Is this the intended use-case for the attribute? If so, my feeling is that \"name\" is somewhat nondescript.\n", "It is the intended use. I think it's documented in the transform section.\n\n> On Feb 24, 2015, at 6:07 PM, brianthelion notifications@github.com wrote:\n> \n> It appears that .name is the attribute that I've been looking for! Is this the intended use-case for the attribute? If so, my feeling is that \"name\" is somewhat nondescript.\n> \n> ???\n> Reply to this email directly or view it on GitHub.\n", "I just looked through the docs and didn't see anything about the `.name` being set. It _is_ in the docstring for `gr.transform`\n\n> Each subframe is endowed with the attribute 'name' in case you need to know which group you are working on\n\n@brianthelion are you interested in submitting a pull-request to clarify the prose docs (and maybe the docstrings on apply?) I don't think the `.name` attribute is set for `.agg` operations. Not sure if this is intentional.\n", "Happy to! However, I think there should first be some discussion about the semantics of the attribute. IMHO, \"name\" is way too generic and semantically kinda nonsensical in lots of use-cases. I'm not sure what's appropriate for the others, but \".grouped_value\" or thereabouts seems appropriate for the groupby-apply workflow.\n", "I'd vote for `.key`.\\* `*.name` was probably chosen because it already has a\nmeaning on Series.\n\nIs there any risk of clobbering an attribute on someone's Series? I think\nwe're ok, unless they're explicitly setting something to `.key` in the\napply function...\n", "> Is there any risk of clobbering an attribute on someone's Series?\r\n\r\n@TomAugspurger yes :( Just happened to me. Not sure how I feel about an attribute with such a common name added to the dataframe which wasn't there in the ungrouped dataframe. Was a really hard bug to pinpoint. EDIT: the problem for me was that had a column named `\"name\"` and tried accessing it with the dot access syntactic sugar. Same would happen with `\"key\"`.\r\n\r\nhttps://github.com/pandas-dev/pandas/issues/25457", "> > Is there any risk of clobbering an attribute on someone's Series?\r\n> \r\n> @TomAugspurger yes :( Just happened to me. Not sure how I feel about an attribute with such a common name added to the dataframe which wasn't there in the ungrouped dataframe. Was a really hard bug to pinpoint. EDIT: the problem for me was that had a column named `\"name\"` and tried accessing it with the dot access syntactic sugar. Same would happen with `\"key\"`.\r\n> \r\n> #25457\r\n\r\nCould you change it to something like .name_ or .key_ for the official (non-column) attribute referencing? ", "@ericabrauer FYI, probably better to add that to the issue I linked, which is more aligned with identifying the `.name` attribute as an issue.", "> @ericabrauer FYI, probably better to add that to the issue I linked, which is more aligned with identifying the `.name` attribute as an issue.\n\nOh ok- thanks @alkasm, I guess maybe I don't have a full enough grasp on the issue. I'll try to take a look at the one you referenced and see if I can better understand. ", "I am new to Open Source Contribution , but have a good knowledge of how pandas work , I just understand the issue compared to that of other , I just want to try .\r\n", "take" ],
      "repository" : {
        "description" : "Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more",
        "homepage" : "https://pandas.pydata.org",
        "name" : "pandas",
        "fullName" : "pandas-dev/pandas",
        "htmlUrl" : "https://github.com/pandas-dev/pandas",
        "gitUrl" : "git://github.com/pandas-dev/pandas.git",
        "sshUrl" : "git@github.com:pandas-dev/pandas.git",
        "cloneUrl" : "https://github.com/pandas-dev/pandas.git",
        "owner" : {
          "login" : "pandas-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18671,
        "stargazersCount" : 45948,
        "watchersCount" : 45948,
        "size" : 370136,
        "openIssuesCount" : 3746,
        "subscribersCount" : 1111,
        "pushedAt" : "2025-07-11T22:50:19Z",
        "languages" : {
          "Smarty" : 8852,
          "Dockerfile" : 6015,
          "Shell" : 21583,
          "CSS" : 7370,
          "C" : 354816,
          "Meson" : 12525,
          "HTML" : 457849,
          "XSLT" : 1196,
          "Cython" : 1390704,
          "Python" : 20993687
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to improve the ergonomics of the groupby-apply idiom in pandas, by adding an attribute to the grouped object that allows easy access to the grouped value.",
      "validationOrRequirement" : "The requirement is to add an attribute to the grouped object that allows easy access to the grouped value, and the attribute should have a descriptive name.",
      "attemptedFixes" : "The issue has been discussed in the comments, and it seems that the `.name` attribute is the intended solution, but there are concerns about the naming and potential conflicts with existing column names.",
      "otherNotes" : "The issue is about the ability to access the grouped value in a DataFrame(groupby(...).apply(...)) workflow, which is important for pandas idioms. The current solution is a slow for-loop, and the author suggests adding a attribute to the grouped object to make it easier to access the grouped value.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285184
  }, {
    "issueDTO" : {
      "id" : 344084802,
      "title" : "Updating value of a single row of a column using loc or at fails",
      "url" : "https://github.com/pandas-dev/pandas/issues/22040",
      "repositoryName" : "pandas-dev/pandas",
      "description" : "#### Code Sample, a copy-pastable example if possible\r\n\r\n```python\r\nIn [12]: import numpy as np\r\n\r\nIn [13]: import pandas as pd\r\n\r\nIn [14]: arr = np.random.rand(2, 2)\r\n\r\nIn [15]: colnames = ['col1', 'col2']\r\n\r\nIn [16]: index = pd.date_range('1-1-2018', periods=2)\r\n\r\nIn [17]: df = pd.DataFrame(data=arr, index=index, columns=colnames)\r\n\r\nIn [18]: df\r\nOut[18]:\r\n                col1      col2\r\n2018-01-01  0.395883  0.291811\r\n2018-01-02  0.019188  0.302100\r\n\r\nIn [19]: df.loc[0, 'col1'] = 0\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n~/venvs/bokeh/lib/python3.6/site-packages/pandas/core/indexes/datetimes.py in insert(self, loc, item)\r\n   2182             import pdb; pdb.set_trace()\r\n-> 2183             new_dates = np.concatenate((self[:loc].asi8, [item.view(np.int64)],\r\n   2184                                         self[loc:].asi8))\r\n\r\nAttributeError: 'int' object has no attribute 'view'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-19-a2498475711c> in <module>()\r\n----> 1 df.loc[0, 'col1'] = 0\r\n\r\n~/venvs/bokeh/lib/python3.6/site-packages/pandas/core/indexing.py in __setitem__(self, key, value)\r\n    187             key = com._apply_if_callable(key, self.obj)\r\n    188         indexer = self._get_setitem_indexer(key)\r\n--> 189         self._setitem_with_indexer(indexer, value)\r\n    190\r\n    191     def _validate_key(self, key, axis):\r\n\r\n~/venvs/bokeh/lib/python3.6/site-packages/pandas/core/indexing.py in _setitem_with_indexer(self, indexer, value)\r\n    374                     # so the object is the same\r\n    375                     index = self.obj._get_axis(i)\r\n--> 376                     labels = index.insert(len(index), key)\r\n    377                     self.obj._data = self.obj.reindex(labels, axis=i)._data\r\n    378                     self.obj._maybe_update_cacher(clear=True)\r\n\r\n~/venvs/bokeh/lib/python3.6/site-packages/pandas/core/indexes/datetimes.py in insert(self, loc, item)\r\n   2181         try:\r\n   2182             import pdb; pdb.set_trace()\r\n-> 2183             new_dates = np.concatenate((self[:loc].asi8, [item.view(np.int64)],\r\n   2184                                         self[loc:].asi8))\r\n   2185             if self.tz is not None:\r\n\r\nTypeError: cannot insert DatetimeIndex with incompatible label\r\n\r\n\r\n```\r\n#### Problem description\r\nTrying to update the value of a single row of a column in a dataframe with DatetimeIndex using .loc or .at leads to an error. For instance \r\n```\r\ndf.loc[0, 'col1'] = 0\r\n```\r\nfails, while \r\n```\r\ndf.loc[0:1, 'col1'] = 0\r\n```\r\nworks.\r\n#### Expected Output\r\nExpected to update the value of first col1 in first row to be set to 0\r\n```\r\n                col1      col2\r\n2018-01-01  0.000000  0.291811\r\n2018-01-02  0.019188  0.302100\r\n```\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>\r\n\r\n[paste the output of ``pd.show_versions()`` here below this line]\r\nIn [20]: pd.show_versions()\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.6.5.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.15.0-24-generic\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_IN\r\nLOCALE: en_IN.ISO8859-1\r\n\r\npandas: 0.23.3\r\npytest: None\r\npip: 10.0.1\r\nsetuptools: 40.0.0\r\nCython: None\r\nnumpy: 1.14.5\r\nscipy: 1.1.0\r\npyarrow: None\r\nxarray: None\r\nIPython: 6.4.0\r\nsphinx: None\r\npatsy: None\r\ndateutil: 2.7.3\r\npytz: 2018.5\r\nblosc: None\r\nbottleneck: None\r\ntables: None\r\nnumexpr: None\r\nfeather: None\r\nmatplotlib: 2.2.2\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: 1.0.1\r\nsqlalchemy: None\r\npymysql: None\r\npsycopg2: None\r\njinja2: 2.10\r\ns3fs: None\r\nfastparquet: None\r\npandas_gbq: None\r\npandas_datareader: None\r\n</details>\r\n",
      "updatedAt" : 1752194367.000000000,
      "user" : "abhinav-upadhyay",
      "userHtmlUrl" : "https://github.com/abhinav-upadhyay",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/328300?v=4",
      "labels" : [ "Needs Tests", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for the report - definitely strange! I actually think they both should raise since the slice provided is for position and not labels (`.iloc` expects the former and `.loc` the latter).\r\n\r\nLet's see what others think", "Has this been addressed? Having this issue in pands 3.6.6. and pandas 0.23.4", "Still open. LMK if you're interested in working on it and I can help get\nyou started.\n\nOn Fri, May 17, 2019 at 12:38 PM adivis12 <notifications@github.com> wrote:\n\n> Has this been addressed? Having this issue in pands 3.6.6. and pandas\n> 0.23.4\n>\n> ???\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/pandas-dev/pandas/issues/22040?email_source=notifications&email_token=AAKAOITAHHRHXJUAKUXOAYTPV3URLA5CNFSM4FLTZE6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVVMTEA#issuecomment-493537680>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAKAOIRSZ5AM4WYAASV7W6TPV3URLANCNFSM4FLTZE6A>\n> .\n>\n", "```\r\ndf.loc[0:1, 'col1'] = 0\r\n```\r\n\r\nraises now\r\n\r\n\r\n```\r\n/home/developer/.config/JetBrains/PyCharm2020.2/scratches/scratch_4.py:43: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\r\n  df.loc[0:1, 'col1'] = 0\r\n```\r\n\r\nwhich seems appropriate.\r\n\r\nWhile \r\n```\r\ndf.loc[0, 'col1'] = 0\r\n```\r\n\r\nraises \r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/developer/.config/JetBrains/PyCharm2020.2/scratches/scratch_4.py\", line 44, in <module>\r\n    df.loc[0, 'col1'] = 0\r\n  File \"/home/developer/PycharmProjects/pandas/pandas/core/indexing.py\", line 684, in __setitem__\r\n    iloc._setitem_with_indexer(indexer, value, self.name)\r\n  File \"/home/developer/PycharmProjects/pandas/pandas/core/indexing.py\", line 1613, in _setitem_with_indexer\r\n    labels = index.insert(len(index), key)\r\n  File \"/home/developer/PycharmProjects/pandas/pandas/core/indexes/datetimelike.py\", line 935, in insert\r\n    return DatetimeIndexOpsMixin.insert(self, loc, item)\r\n  File \"/home/developer/PycharmProjects/pandas/pandas/core/indexes/datetimelike.py\", line 613, in insert\r\n    result = super().insert(loc, item)\r\n  File \"/home/developer/PycharmProjects/pandas/pandas/core/indexes/extension.py\", line 340, in insert\r\n    code = arr._validate_scalar(item)\r\n  File \"/home/developer/PycharmProjects/pandas/pandas/core/arrays/datetimelike.py\", line 567, in _validate_scalar\r\n    raise TypeError(msg)\r\nTypeError: value should be a 'Timestamp' or 'NaT'. Got 'int' instead.\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\nwhich does seem appropriate too?", "Any update on `df.loc[0, 'col1'] = 0` getting the error `TypeError: value should be a 'Timestamp' or 'NaT'. Got 'int' instead.` ? I use Python 3.7.2.", "yep this looks closable with a test in master @phofl as the above is correct (raising)", "If this raises, is there a suggestion how to achieve what we want - i.e., assign a value to a particular cell?", "u can use labels with loc or iloc with positional indexers\n\nyou cannot mix these", "@jreback  there are already tests for slices in main:\r\nhttps://github.com/pandas-dev/pandas/blob/main/pandas/tests/indexing/test_loc.py#L2707\r\nThat should close issue 1 of 2.\r\n\r\nThe other case no longer throws an error in main. See script and results below:\r\n\r\n    import numpy as np\r\n    import pandas as pd\r\n    print(pd.__version__)\r\n    \r\n    def get_df():\r\n        arr = np.random.rand(2, 2)\r\n        colnames = ['col1', 'col2']\r\n        index = pd.date_range('1-1-2018', periods=2)\r\n        df = pd.DataFrame(data=arr, index=index, columns=colnames)\r\n        return df\r\n    \r\n    print('ex2')\r\n\r\n    df = get_df()\r\n    print(df)\r\n    df.loc[0, 'col1'] = 1\r\n    print(df)\r\n\r\nAnd results:\r\n\r\n    $ python /mnt/c/tmp/test_py.py\r\n    0.9.0+25706.g9289c46e16.dirty\r\n    ex2\r\n                    col1      col2\r\n    2018-01-01  0.816587  0.962762\r\n    2018-01-02  0.259267  0.076658\r\n                             col1      col2\r\n    2018-01-01 00:00:00  0.816587  0.962762\r\n    2018-01-02 00:00:00  0.259267  0.076658\r\n    0                    1.000000       NaN\r\n\r\n\r\nComparing stack trace above to stack trace when TypeError is raised in main, I see that we now go through base.py which catches the TypeError and performs a cast:\r\n\r\nhttps://github.com/pandas-dev/pandas/blob/main/pandas/core/indexes/base.py#L6873\r\n\r\nSo *questions to @jreback* are:\r\n* Do we intend for df[0, 'col1'] = 0 to throw here? If so I'm happy to try to fix that, but lmk if this is a minor case of some larger project in works that will just clobber a fix to this bug.\r\n* Based on my understanding above, type confusion in loc is far broader just datetimes, and the \"cast to common\" on TypeError in Index.insert strategy should be more nuanced (e.g. not casting to Object). Is there an opinion on correct behavior here? \r\n", "take", "take", "Hello, is the issue still open? I am a beginner and I would like to help. Thanks!", "1.`df.loc[0, 'col1'] = 0`\n\n- Fails because .loc[] is label-based.\n- DataFrame has a DatetimeIndex\nWhen you write .loc[0, 'col1'], Pandas looks for index label 0, not the first row.\n0 is not a datetime, so Pandas inserts a new row with index 0 or it causes a TypeError.\n\n2.` df.loc[0:1, 'col1'] = 0`\n\n- Fails because .loc[0:1] is trying to slice by position, which is not allowed with .loc.\n- .loc expects label slices, not integer positions.\nResults in:TypeError: Slicing a positional slice with .loc is not\n\n**Solutions:**\n1.Use .loc (Label-Based Indexing)\n.loc : label-based indexing, accesses rows and columns using the actual labels (not numeric positions).\n\n`df.loc['2018-01-01', 'col1'] = 0`\n\n2. Use .iloc (Position-Based Indexing)\niloc : integer-location based indexing,accesses elements of a DataFrame by row and column positions (integers), not by their labels.\n\n`df.iloc[0, 0] = 0`\n(first row,first col)", "Hi there, is this still an issue? Not seeing many responses to previous comments. Willing to help if possible.", "take" ],
      "repository" : {
        "description" : "Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more",
        "homepage" : "https://pandas.pydata.org",
        "name" : "pandas",
        "fullName" : "pandas-dev/pandas",
        "htmlUrl" : "https://github.com/pandas-dev/pandas",
        "gitUrl" : "git://github.com/pandas-dev/pandas.git",
        "sshUrl" : "git@github.com:pandas-dev/pandas.git",
        "cloneUrl" : "https://github.com/pandas-dev/pandas.git",
        "owner" : {
          "login" : "pandas-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18671,
        "stargazersCount" : 45948,
        "watchersCount" : 45948,
        "size" : 370136,
        "openIssuesCount" : 3746,
        "subscribersCount" : 1111,
        "pushedAt" : "2025-07-11T22:50:19Z",
        "languages" : {
          "Smarty" : 8852,
          "Dockerfile" : 6015,
          "Shell" : 21583,
          "CSS" : 7370,
          "C" : 354816,
          "Meson" : 12525,
          "HTML" : 457849,
          "XSLT" : 1196,
          "Cython" : 1390704,
          "Python" : 20993687
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to update the value of a single row of a column in a dataframe with DatetimeIndex using .loc or .at, but it fails due to the DatetimeIndex and the type of indexing used.",
      "validationOrRequirement" : "The issue is related to DatetimeIndex and the use of .loc or .at for updating values in a dataframe.",
      "attemptedFixes" : "FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead.",
      "otherNotes" : "Trying to update the value of a single row of a column in a dataframe with DatetimeIndex using .loc or .at leads to an error. For instance df.loc[0, 'col1'] = 0 fails, while df.loc[0:1, 'col1'] = 0 works.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285190
  }, {
    "issueDTO" : {
      "id" : 669239940,
      "title" : "BUG: read_sql no longer works simply with SqlAlchemy selectables and a quick fix",
      "url" : "https://github.com/pandas-dev/pandas/issues/35484",
      "repositoryName" : "pandas-dev/pandas",
      "description" : "- [x] I have checked that this issue has not already been reported.\r\n\r\n- [x] I have confirmed this bug exists on the latest version of pandas.\r\n\r\n- [x] (optional) I have confirmed this bug exists on the master branch of pandas.\r\n\r\n---\r\n\r\n#### Code Sample, a copy-pastable example\r\n\r\nHey--I noticed while running [siuba's](https://github.com/machow/siuba) SQL unit tests that queries using the modulo operator are failing.\r\n\r\nThe issue is due to a recent change for issue #34211 in pandas setting the [no_parameters](https://github.com/pandas-dev/pandas/blame/5507452c4a675ad5453bc5f02cd68b65fe3977df/pandas/io/sql.py#L1161) argument before executing via a sqlalchemy engine. This was done to allow queries like `SELECT 1 % 2`, but causes SqlAlchemy expressions handling `%` to not always work with `read_sql`.\r\n\r\n**Solution**. Rather than executing in a special way (`no_parameters`), I think you want to wrap a string query in SqlAlchemy.sql.text ([see here](https://docs.sqlalchemy.org/en/13/core/tutorial.html#using-textual-sql)). This will allow both queries with `%` and the full range of SqlAlchemy expressions. WDYT?\r\n\r\n```python\r\nfrom sqlalchemy import sql, create_engine\r\nimport pandas as pd\r\n\r\nengine = create_engine('postgresql://postgres:@localhost:5433/postgres', echo=False)\r\n#engine = create_engine('postgresql://USERNAME:PASSWORD@localhost:PORT/DBNAME', echo=False)\r\n\r\n# doesn't work, original issue in pandas: 'dict' object does not support indexing\r\nengine.execute(\"SELECT 1 % 2\")\r\n\r\n# works, ideal solution\r\nengine.execute(sql.text(\"SELECT 1 % 2\" ))\r\n\r\n# queries below broken by no_parameters change ----\r\npd.read_sql(sql.text(\"SELECT 1 % 2\"), engine)\r\n\r\npd.read_sql(sql.select([sql.literal(1) % sql.literal(2)]), engine)\r\n```\r\n\r\nHere's a gist of the error for the last two queries...\r\n\r\n```\r\nProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: integer %% integer\r\nLINE 1: SELECT 1 %% 2\r\n                 ^\r\nHINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\r\n\r\n[SQL: SELECT 1 %% 2]\r\n(Background on this error at: http://sqlalche.me/e/13/f405)\r\n```\r\n\r\nFull traceback in the details\r\n\r\n<details>\r\n```\r\n---------------------------------------------------------------------------\r\nUndefinedFunction                         Traceback (most recent call last)\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/base.py in _execute_context(self, dialect, constructor, statement, parameters, *args)\r\n   1267                     self.dialect.do_execute_no_params(\r\n-> 1268                         cursor, statement, context\r\n   1269                     )\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/default.py in do_execute_no_params(self, cursor, statement, context)\r\n    595     def do_execute_no_params(self, cursor, statement, context=None):\r\n--> 596         cursor.execute(statement)\r\n    597 \r\n\r\nUndefinedFunction: operator does not exist: integer %% integer\r\nLINE 1: SELECT 1 %% 2\r\n                 ^\r\nHINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\r\n\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nProgrammingError                          Traceback (most recent call last)\r\n<ipython-input-6-5831ea4e198c> in <module>\r\n----> 1 pd.read_sql(sql.text(\"SELECT 1 % 2\"), engine)\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/pandas/io/sql.py in read_sql(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\r\n    513             coerce_float=coerce_float,\r\n    514             parse_dates=parse_dates,\r\n--> 515             chunksize=chunksize,\r\n    516         )\r\n    517 \r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/pandas/io/sql.py in read_query(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\r\n   1293         args = _convert_params(sql, params)\r\n   1294 \r\n-> 1295         result = self.execute(*args)\r\n   1296         columns = result.keys()\r\n   1297 \r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/pandas/io/sql.py in execute(self, *args, **kwargs)\r\n   1160         \"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\r\n   1161         return self.connectable.execution_options(no_parameters=True).execute(\r\n-> 1162             *args, **kwargs\r\n   1163         )\r\n   1164 \r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/base.py in execute(self, statement, *multiparams, **params)\r\n   2236 \r\n   2237         connection = self._contextual_connect(close_with_result=True)\r\n-> 2238         return connection.execute(statement, *multiparams, **params)\r\n   2239 \r\n   2240     def scalar(self, statement, *multiparams, **params):\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/base.py in execute(self, object_, *multiparams, **params)\r\n   1012             )\r\n   1013         else:\r\n-> 1014             return meth(self, multiparams, params)\r\n   1015 \r\n   1016     def _execute_function(self, func, multiparams, params):\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/sql/elements.py in _execute_on_connection(self, connection, multiparams, params)\r\n    296     def _execute_on_connection(self, connection, multiparams, params):\r\n    297         if self.supports_execution:\r\n--> 298             return connection._execute_clauseelement(self, multiparams, params)\r\n    299         else:\r\n    300             raise exc.ObjectNotExecutableError(self)\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/base.py in _execute_clauseelement(self, elem, multiparams, params)\r\n   1131             distilled_params,\r\n   1132             compiled_sql,\r\n-> 1133             distilled_params,\r\n   1134         )\r\n   1135         if self._has_events or self.engine._has_events:\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/base.py in _execute_context(self, dialect, constructor, statement, parameters, *args)\r\n   1316         except BaseException as e:\r\n   1317             self._handle_dbapi_exception(\r\n-> 1318                 e, statement, parameters, cursor, context\r\n   1319             )\r\n   1320 \r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/base.py in _handle_dbapi_exception(self, e, statement, parameters, cursor, context)\r\n   1510             elif should_wrap:\r\n   1511                 util.raise_(\r\n-> 1512                     sqlalchemy_exception, with_traceback=exc_info[2], from_=e\r\n   1513                 )\r\n   1514             else:\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/util/compat.py in raise_(***failed resolving arguments***)\r\n    176 \r\n    177         try:\r\n--> 178             raise exception\r\n    179         finally:\r\n    180             # credit to\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/base.py in _execute_context(self, dialect, constructor, statement, parameters, *args)\r\n   1266                 if not evt_handled:\r\n   1267                     self.dialect.do_execute_no_params(\r\n-> 1268                         cursor, statement, context\r\n   1269                     )\r\n   1270             else:\r\n\r\n~/Dropbox/Repo/siuba/env/lib/python3.6/site-packages/sqlalchemy/engine/default.py in do_execute_no_params(self, cursor, statement, context)\r\n    594 \r\n    595     def do_execute_no_params(self, cursor, statement, context=None):\r\n--> 596         cursor.execute(statement)\r\n    597 \r\n    598     def is_disconnect(self, e, connection, cursor):\r\n\r\nProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: integer %% integer\r\nLINE 1: SELECT 1 %% 2\r\n                 ^\r\nHINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\r\n\r\n[SQL: SELECT 1 %% 2]\r\n(Background on this error at: http://sqlalche.me/e/13/f405)\r\n```\r\n\r\n</details>\r\n\r\n",
      "updatedAt" : 1752194274.000000000,
      "user" : "machow",
      "userHtmlUrl" : "https://github.com/machow",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2574498?v=4",
      "labels" : [ "Needs Tests", "good first issue", "IO SQL" ],
      "state" : "OPEN",
      "comments" : [ "@machow want to make a PR for this?", "@jbrockmendel sure! I have the changes running and passing tests in the pandas docker image. I'm noticing that the tests cover only either queries with parameters or using `%` as an operator.\r\n\r\nI'll try adding two new kinds of tests:\r\n\r\n* queries with `%%` (should pass after changes)\r\n* queries with a combination of parameters and `%` as operator. (should fail before and after changes?).\r\n\r\nWill add tests and open a PR tomorrow.", "might be closed by https://github.com/pandas-dev/pandas/pull/37534 (e.g. working on master).", "Hey--that PR (#37534) just changed the code in PR #34211 back, so reverted back to pandas v1.05 behavior that I listed in my PR (#36275).\r\n\r\nHere is the table I made in that PR for reference\r\n\r\n| query |   v1.05 | v.1.1 | my PR #36275 | issue |\r\n| --- | --- | --- | --- | --- |\r\n| no params, `%` | ??? | ??? | ??? | #34211 (merged) |\r\n| no params, `%%` | ??? | ??? | ??? | #35871 |\r\n| params, `%` | ??? | ??? | ??? |  https://github.com/psycopg/psycopg2/issues/827 |\r\n| params, `%%` | ??? | ??? | ??? | | \r\n| sqla declarative, `%` | ??? | ??? | ??? | #35484 |\r\n\r\nThat means this code worked in v1.1, but fails now (as it did in v1.05; it's the no params, `%` case):\r\n\r\n```python\r\nimport pandas as pd\r\nfrom sqlalchemy import create_engine\r\n\r\n# 1.3.5\r\npd.__version__\r\n\r\nengine = create_engine(\"postgresql://postgres:@localhost:5432/postgres\", echo=False)\r\n\r\n# TypeError: dict is not a sequence\r\npd.read_sql(\"SELECT 1 % 2\", engine)\r\n```\r\n\r\nI'm not sure whether y'all consider this a bug or not, but pandas' behavior as it exists now IMO aligns well with sqlalchemy's API, since technically you shouldn't pass a sql string to `engine.execute`, but wrap it in sqlalchemy.sql.text (which is how you can support people passing SQL as a string).", "@machow I would like to take this issue, I am a new contributor. Probably need some guidance.", "Hey! I haven't looked at this issue for a while, and am not sure if it's intended behavior in pandas or not. I wonder if another issue with the label [\"good first issue\"](https://github.com/pandas-dev/pandas/labels/good%20first%20issue) might be a bit easier to pick up?", "take", "hello, @machow , is this issue still being pursued?", "I just encountered this too. This bug prevents executing `SELECT ... WHERE col like '...%...'` statements.", "> I just encountered this too. This bug prevents executing `SELECT ... WHERE col like '...%...'` statements.\r\n\r\nThe fix for this is to use two %, example:\r\n\r\n`SELECT ... WHERE fullname like 'John%%'`\r\ninstead of `SELECT ... WHERE fullname like 'John%'`\r\n\r\nRead about it here:\r\nhttps://stackoverflow.com/questions/64252764/sql-case-when-x-like-t-in-python-script-resulting-in-typeerror-dict-is-not", "engine.execute(r\"SELECT 1 % 2\")\r\n\r\nhow about writing like this, converting it to raw string , if i understand the problem right", "I want to work on this issue has it already been resolved. ", "take" ],
      "repository" : {
        "description" : "Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more",
        "homepage" : "https://pandas.pydata.org",
        "name" : "pandas",
        "fullName" : "pandas-dev/pandas",
        "htmlUrl" : "https://github.com/pandas-dev/pandas",
        "gitUrl" : "git://github.com/pandas-dev/pandas.git",
        "sshUrl" : "git@github.com:pandas-dev/pandas.git",
        "cloneUrl" : "https://github.com/pandas-dev/pandas.git",
        "owner" : {
          "login" : "pandas-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18671,
        "stargazersCount" : 45948,
        "watchersCount" : 45948,
        "size" : 370136,
        "openIssuesCount" : 3746,
        "subscribersCount" : 1111,
        "pushedAt" : "2025-07-11T22:50:19Z",
        "languages" : {
          "Smarty" : 8852,
          "Dockerfile" : 6015,
          "Shell" : 21583,
          "CSS" : 7370,
          "C" : 354816,
          "Meson" : 12525,
          "HTML" : 457849,
          "XSLT" : 1196,
          "Cython" : 1390704,
          "Python" : 20993687
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "BUG: read_sql no longer works simply with SqlAlchemy selectables and a quick fix",
      "validationOrRequirement" : "The issue is specific to read_sql and sqlalchemy, and requires the use of SqlAlchemy.sql.text to wrap the query string.",
      "attemptedFixes" : "A PR has been opened to fix this issue, and the author is working on adding tests to cover the issue. The PR has been reverted due to another PR changing the code in pandas v1.05 behavior back to v1.1 behavior.",
      "otherNotes" : "The issue is due to a recent change in pandas setting the no_parameters argument before executing via a sqlalchemy engine, which causes SqlAlchemy expressions handling % to not always work with read_sql. The suggested solution is to wrap a string query in SqlAlchemy.sql.text, which will allow both queries with % and the full range of SqlAlchemy expressions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285197
  }, {
    "issueDTO" : {
      "id" : 2918592145,
      "title" : "Rework/simplify Martin demo site",
      "url" : "https://github.com/maplibre/martin/issues/1749",
      "repositoryName" : "maplibre/martin",
      "description" : "The site at https://martin.maplibre.org/ is really long and verbose. We should simplify it, possibly removing a lot of things, and focus on a short summary of what's available plus the demo.  Brevity ??? the sister of talent...",
      "updatedAt" : 1752193657.000000000,
      "user" : "nyurik",
      "userHtmlUrl" : "https://github.com/nyurik",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1641515?v=4",
      "labels" : [ "docs", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "It also heavily focusses on postgis support, while not even mentioning that we added support mbtiles/pmtiles/cog \uD83D\uDE05 " ],
      "repository" : {
        "description" : "Blazing fast and lightweight PostGIS, MBtiles and PMtiles tile server, tile generation, and mbtiles tooling.",
        "homepage" : "https://martin.maplibre.org",
        "name" : "martin",
        "fullName" : "maplibre/martin",
        "htmlUrl" : "https://github.com/maplibre/martin",
        "gitUrl" : "git://github.com/maplibre/martin.git",
        "sshUrl" : "git@github.com:maplibre/martin.git",
        "cloneUrl" : "https://github.com/maplibre/martin.git",
        "owner" : {
          "login" : "maplibre",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 266,
        "stargazersCount" : 2828,
        "watchersCount" : 2828,
        "size" : 20365,
        "openIssuesCount" : 99,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T02:52:40Z",
        "languages" : {
          "TypeScript" : 830,
          "Shell" : 29490,
          "CSS" : 198,
          "Rust" : 672567,
          "JavaScript" : 436,
          "HTML" : 18833,
          "Just" : 14278
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rework/simplify Martin demo site",
      "validationOrRequirement" : "simplify the site, possibly removing a lot of things, and focus on a short summary of what's available plus the demo",
      "attemptedFixes" : "",
      "otherNotes" : "The site at https://martin.maplibre.org/ is really long and verbose, and it heavily focusses on postgis support, while not even mentioning that we added support mbtiles/pmtiles/cog",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285200
  }, {
    "issueDTO" : {
      "id" : 2297519879,
      "title" : "Brakes scroll of parent, only ios",
      "url" : "https://github.com/KevinnZou/compose-webview-multiplatform/issues/155",
      "repositoryName" : "KevinnZou/compose-webview-multiplatform",
      "description" : "Hi. Any chance to fix this issue? Some webviews needed to be displayed in a regular scrollable column in my project. Or do I miss maybe a setting which can fix this issue?\r\nOn Android I can scroll down the column easily even if I drag the webview, but not on iOS. It scrolls only if I drag outside the webview. Which is not possible eg if the webview is higher than the screen height. Then every other content of the column after the webview will be unreachable:(. I also tried overflow hidden on the webpage, did not help. Also set webViewState.webSettings.iOSWebSettings.scrollEnabled = false for a try, but it just changed the scrollablity of the html content inside the webview. In normal case in swiftui and wkwebview works together smoothly.\r\n\r\nTo reproduce:\r\n<img width=\"638\" alt=\"Screenshot 2024-05-15 at 12 21 31\" src=\"https://github.com/KevinnZou/compose-webview-multiplatform/assets/40792011/2d95b84e-e181-4e16-b1d4-34406ff13e51\">\r\n",
      "updatedAt" : 1752193325.000000000,
      "user" : "AttilaBarany",
      "userHtmlUrl" : "https://github.com/AttilaBarany",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/40792011?v=4",
      "labels" : [ "wait external fix", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@AttilaBarany The issue is related to nested scrolling and is not a problem with this library. You can refer to this [reply](https://github.com/KevinnZou/compose-webview-multiplatform/issues/123#issuecomment-2014150718) and try to implement `nestedscroll` functionality. ", "@KevinnZou  Thanks for the fast reply. The problem is just the opposite. Yes, nestedscroll did have problems in compose with Androidview, where parent steels the scroll event, we can read a lot about it on stackoverflow too. But here, the child (webview) steels all the events from the parent on ios. I tried to add ondrag, customnestedscroll etc... to the webview directly, and does not trigger anything on ios. I could not get a single println of them. The event stucks somewhere inside the lib. So actually this looks a library problem on ios platform. This is a big limitation that on iOS you can not use it, just with full screen, where no other components needed to display.", "@AttilaBarany Thanks for your information! I do not have time to check it deeply currently. But I think `nestscroll` modifier should solve your issue. You just need to intercept the scroll of webview first and then check whether webview can scroll. If it cannot, then pass the scroll event to the parent. I would recommend you check this [lib](https://github.com/KevinnZou/compose-nestedscroll-webview).  Could you please provide the code for the custom nested scroll?", "@KevinnZou Thanks, but I was digging deeper, and found out, the problem happens with every UIKitView (I beleive you use that one too for ios wkwebview), even with just a single UIView(). So I filed a ticket at compose multiplatform. It is such a basic functionality, and I think the whole UIKitView thing worth nothing without having them in scrollable views. Btw Flutter was suffering from the same thing before, I dont know if still do.\r\nYou can follow the issue if interested, they are saying they know about it, and trying to resolve:\r\nhttps://github.com/JetBrains/compose-multiplatform/issues/4818\r\nI think you can close this ticket, or maybe need some adjustment later once they find a solution for the original problem.\r\nThanks!:)", "> @KevinnZou Thanks, but I was digging deeper, and found out, the problem happens with every UIKitView (I beleive you use that one too for ios wkwebview), even with just a single UIView(). So I filed a ticket at compose multiplatform. It is such a basic functionality, and I think the whole UIKitView thing worth nothing without having them in scrollable views. Btw Flutter was suffering from the same thing before, I dont know if still do. You can follow the issue if interested, they are saying they know about it, and trying to resolve: [JetBrains/compose-multiplatform#4818](https://github.com/JetBrains/compose-multiplatform/issues/4818) I think you can close this ticket, or maybe need some adjustment later once they find a solution for the original problem. Thanks!:)\r\n@AttilaBarany \r\n\r\nHello Senior Developer,\r\n\r\nI found this project because I need WebView and Adjust, and I read through various issues here. I noticed that you are using WebView and Adjust on iOS. I have been having configuration issues with this part myself. This is my project: https://github.com/cybernhl/webapp\r\n\r\nCould you please guide me on how to configure it?\r\n\r\nThank you.", "> > @KevinnZou Thanks, but I was digging deeper, and found out, the problem happens with every UIKitView (I beleive you use that one too for ios wkwebview), even with just a single UIView(). So I filed a ticket at compose multiplatform. It is such a basic functionality, and I think the whole UIKitView thing worth nothing without having them in scrollable views. Btw Flutter was suffering from the same thing before, I dont know if still do. You can follow the issue if interested, they are saying they know about it, and trying to resolve: [JetBrains/compose-multiplatform#4818](https://github.com/JetBrains/compose-multiplatform/issues/4818) I think you can close this ticket, or maybe need some adjustment later once they find a solution for the original problem. Thanks!:)\r\n> > @AttilaBarany\r\n> \r\n> Hello Senior Developer,\r\n> \r\n> I found this project because I need WebView and Adjust, and I read through various issues here. I noticed that you are using WebView and Adjust on iOS. I have been having configuration issues with this part myself. This is my project: https://github.com/cybernhl/webapp\r\n> \r\n> Could you please guide me on how to configure it?\r\n> \r\n> Thank you.\r\n\r\nThere is no multiplatform solution for this yet. It is waiting for compose multiplatform to handle UIKitviews properly in scrollables. This issue is flagged to be \"waiting external solution\". Only workaround is to build your screen or page entirely in SwiftUI/UIKit, and make an if in compose. If the platform is iOS then load the whole page in UIKitView, so you can have native iOS scrollview embedding WKWebview.", "Was this issue ever fixed? I'm running into this issue still on iOS, where the WebView captures the scroll gesture and doesn't pass it on (bubble up) to the parent views, so the scroll intended on the LazyColumn just gets stuck.\n\n```\n    webViewState.webSettings.apply {\n        supportZoom = false\n        iOSWebSettings.apply { \n            scrollEnabled = false\n        }\n    }\n```" ],
      "repository" : {
        "description" : "WebView for JetBrains Compose Multiplatform",
        "homepage" : "https://kevinnzou.github.io/compose-webview-multiplatform/",
        "name" : "compose-webview-multiplatform",
        "fullName" : "KevinnZou/compose-webview-multiplatform",
        "htmlUrl" : "https://github.com/KevinnZou/compose-webview-multiplatform",
        "gitUrl" : "git://github.com/KevinnZou/compose-webview-multiplatform.git",
        "sshUrl" : "git@github.com:KevinnZou/compose-webview-multiplatform.git",
        "cloneUrl" : "https://github.com/KevinnZou/compose-webview-multiplatform.git",
        "owner" : {
          "login" : "KevinnZou",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 93,
        "stargazersCount" : 738,
        "watchersCount" : 738,
        "size" : 66651,
        "openIssuesCount" : 99,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-01T09:29:15Z",
        "languages" : {
          "Shell" : 807,
          "Kotlin" : 221737
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the problem where the webview captures the scroll gesture and doesn't pass it on to the parent views, making the scroll intended on the LazyColumn get stuck.",
      "validationOrRequirement" : "The issue is specific to iOS and only occurs when the webview is inside a scrollable parent.",
      "attemptedFixes" : "The author tried overflow hidden on the webpage, set webViewState.webSettings.iOSWebSettings.scrollEnabled = false, but it just changed the scrollability of the html content inside the webview. He also tried to add ondrag, customnestedscroll etc... to the webview directly, but it did not trigger anything on ios.",
      "otherNotes" : "The issue is related to nested scrolling and is not a problem with this library. The problem is that the child (webview) steals all the events from the parent on ios. The workaround is to build the screen or page entirely in SwiftUI/UIKit, and make an if in compose. If the platform is iOS then load the whole page in UIKitView, so you can have native iOS scrollview embedding WKWebview. This issue is flagged to be 'waiting external solution'.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285208
  }, {
    "issueDTO" : {
      "id" : 3130097595,
      "title" : "Set Up Linters and Code Style Checkers",
      "url" : "https://github.com/beehive-lab/GPULlama3.java/issues/16",
      "repositoryName" : "beehive-lab/GPULlama3.java",
      "description" : "Introduce basic code quality tools for both Java and Python code in the repo. This helps ensure formatting and best practices are followed consistently across contributors.\n\n### ??? Tasks\n\n> You don???t need to do all of them in one go ??? even completing just **one** is helpful!\n\n#### 0?????? Java Linter & Formatter\n- [ ] Add **Checkstyle** using the default or Google style in `pom.xml` or `build.gradle`\n- [ ] Add config file (e.g., `checkstyle.xml`)\n- [ ] Add GitHub Action to run `mvn checkstyle:check` or `gradle check`\n\n#### 1?????? Java Auto-Formatter\n- [ ] Add **Spotless** (Google Java Format) via Gradle or Maven\n- [ ] Add commands like `./gradlew spotlessApply` or `mvn spotless:apply`\n\n#### 2?????? Python Formatter (for auxiliary Python scripts)\n- [ ] Add **Black** formatter (`black .`)\n- [ ] Add a GitHub Action to check formatting, e.g.:\n\n```yaml\nname: Python Format Check\n\non: [push, pull_request]\n\njobs:\n  black-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install Black\n        run: pip install black\n      - name: Check formatting with Black\n        run: black --check .\n3?????? .editorconfig",
      "updatedAt" : 1752193013.000000000,
      "user" : "mikepapadim",
      "userHtmlUrl" : "https://github.com/mikepapadim",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8652854?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @mikepapadim , would like to contribute on this issue. Thanks!", "Hi, was wondering if there was any update on this issue? Thanks." ],
      "repository" : {
        "description" : "GPU-accelerated Llama3.java inference in pure Java using TornadoVM. ",
        "homepage" : "https://github.com/beehive-lab/GPULlama3.java",
        "name" : "GPULlama3.java",
        "fullName" : "beehive-lab/GPULlama3.java",
        "htmlUrl" : "https://github.com/beehive-lab/GPULlama3.java",
        "gitUrl" : "git://github.com/beehive-lab/GPULlama3.java.git",
        "sshUrl" : "git@github.com:beehive-lab/GPULlama3.java.git",
        "cloneUrl" : "https://github.com/beehive-lab/GPULlama3.java.git",
        "owner" : {
          "login" : "beehive-lab",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15,
        "stargazersCount" : 139,
        "watchersCount" : 139,
        "size" : 36078,
        "openIssuesCount" : 16,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-07T10:40:35Z",
        "languages" : {
          "Java" : 253621,
          "Shell" : 1061,
          "Batchfile" : 983,
          "Makefile" : 786,
          "Python" : 16611
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Introduce basic code quality tools for both Java and Python code in the repository to ensure formatting and best practices are followed consistently across contributors.",
      "validationOrRequirement" : "The requirements are to add Checkstyle and config file in pom.xml or build.gradle, add Spotless via Gradle or Maven, add Black formatter for auxiliary Python scripts, and set up a GitHub Action to check formatting.",
      "attemptedFixes" : "The tasks mentioned include setting up Checkstyle, Spotless, and Black for Java and Python code, respectively, as well as configuring GitHub Actions to run these tools.",
      "otherNotes" : "The issue is about setting up linters and code style checkers for both Java and Python code in the repository. It aims to ensure consistent formatting and best practices across contributors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285213
  }, {
    "issueDTO" : {
      "id" : 3156203456,
      "title" : "[Investigate] Graceful shutdown testing",
      "url" : "https://github.com/google/dranet/issues/122",
      "repositoryName" : "google/dranet",
      "description" : "The driver, once exists, needs to remove the socket so the kubelet can cleanup the orphan resourceslices\n\nIdially we should add an e2e test with bats that just edits the DS to move to 0 replicas, and verify that no resources slices exist",
      "updatedAt" : 1752193010.000000000,
      "user" : "aojea",
      "userHtmlUrl" : "https://github.com/aojea",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6450081?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hey @aojea  i am new to open source can you assign me this issue i just started learning kubernetes i will try to resolve is that okay\nif issue is finalized\n", "This requires some previous knowledge of kubernetes, kind, linux ... so just try to evaluate if you are able to tackle this tasks and once you are confident I'll assign it to you", "> This requires some previous knowledge of kubernetes, kind, linux ... so just try to evaluate if you are able to tackle this tasks and once you are confident I'll assign it to you\n\nyeah sure i will try if i can come with some solution\n", "hey @aojea  please review this \n\n<img width=\"645\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/cdc074f0-d1fa-464f-9ef4-03338096584d\" />", "Great, please go ahead and send a PR, replace the sleep with an active loop, you can query it using --wait or other option\n\n", "as requested i have added --wait instead of sleep and sent a PR", "<img width=\"871\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/816ad05d-c17d-4a79-8ee7-cc7160312d26\" />\n@gauravkghildiyal can you please review these i have removed teardown and setup", "Hi @gmarav05, can you please reopen the same PR and we can start reviewing from there. Were you able to get the local testing working?", "While https://github.com/google/dranet/blob/main/tests/README.md should be a good enough resource to help you run the tests, we also have https://github.com/google/dranet/blob/main/DEVELOPER.md for a more general troubleshooting. ", "yeah sure I will reopen the PR and my local tests are failing. I think i have deleted that branch. can I start from scratch? @gauravkghildiyal ", "It'd be nice if you could push to the same branch to keep context of previous discussion (I think that should be possible). Though if that doesn't work, sure feel free to send in a new PR." ],
      "repository" : {
        "description" : "DraNet is a Kubernetes Network Driver that uses Dynamic Resource Allocation (DRA) to deliver high-performance networking for demanding applications in Kubernetes.",
        "homepage" : "http://dranet.dev/",
        "name" : "dranet",
        "fullName" : "google/dranet",
        "htmlUrl" : "https://github.com/google/dranet",
        "gitUrl" : "git://github.com/google/dranet.git",
        "sshUrl" : "git@github.com:google/dranet.git",
        "cloneUrl" : "https://github.com/google/dranet.git",
        "owner" : {
          "login" : "google",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 88,
        "watchersCount" : 88,
        "size" : 20077,
        "openIssuesCount" : 16,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-09T09:10:42Z",
        "languages" : {
          "Dockerfile" : 997,
          "Shell" : 16476,
          "C" : 408,
          "Makefile" : 2122,
          "Go" : 229948
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add an e2e test with bats that edits the DS to move to 0 replicas and verifies that no resources slices exist.",
      "validationOrRequirement" : "The test should be reviewed and possibly reopened for further testing. The test requires previous knowledge of Kubernetes, kind, and Linux.",
      "attemptedFixes" : "The attempted fix was to replace the sleep with an active loop using --wait option and send a PR. However, the local tests are failing and the branch was deleted, so it was suggested to start from scratch or push to the same branch to keep the context of previous discussion.",
      "otherNotes" : "The issue is related to adding an e2e test with bats that edits the DS to move to 0 replicas and verifies that no resources slices exist. The test requires previous knowledge of Kubernetes, kind, and Linux. The test is to be reviewed and possibly reopened for further testing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285220
  }, {
    "issueDTO" : {
      "id" : 2127602809,
      "title" : "Warning about missing resource types should be more explicit about impact (and where is the link to the help page?)",
      "url" : "https://github.com/Azure/bicep/issues/13287",
      "repositoryName" : "Azure/bicep",
      "description" : "Given this:\r\n\r\n> **To Reproduce** I need define Geneva configs as below, but get type unavailable. Looks like bicep has no support to Geneva configs\r\n\r\nand\r\n\r\n> If not, is there a known workaround to add these settings in a bicep template without the resource?\r\n_Originally posted by @shcherbin in https://github.com/Azure/bicep-types-az/issues/1843#issuecomment-1927517792_\r\n\r\nas well as a direct e-mail inquiry about work-arounds... \r\n\r\nI think the warning should probably be more clear about the actual effects.  Something like \"Resource type \"Microsoft.Web/serverfarms/firstPartyApps/settings@2019-08-01\" does not have types available. Either the type or version does not exist, or Bicep does not yet know about it. This does not prevent attempting deployment, but does mean Bicep may not be able to provide Intellisense or detect potential errors.\"\r\n\r\n<img width=\"861\" alt=\"image\" src=\"https://github.com/Azure/bicep/assets/6913354/c0d45302-e554-47c3-8887-4cd22258555c\">",
      "updatedAt" : 1752192845.000000000,
      "user" : "StephenWeatherford",
      "userHtmlUrl" : "https://github.com/StephenWeatherford",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6913354?v=4",
      "labels" : [ "Needs: Upvote", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "ALSO: I *cannot* find the official help page for BCP081 or any other Bicep warnings/errors.  Where did that go, and why is there no link in the warning message itself?" ],
      "repository" : {
        "description" : "Bicep is a declarative language for describing and deploying Azure resources",
        "homepage" : "",
        "name" : "bicep",
        "fullName" : "Azure/bicep",
        "htmlUrl" : "https://github.com/Azure/bicep",
        "gitUrl" : "git://github.com/Azure/bicep.git",
        "sshUrl" : "git@github.com:Azure/bicep.git",
        "cloneUrl" : "https://github.com/Azure/bicep.git",
        "owner" : {
          "login" : "Azure",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 783,
        "stargazersCount" : 3407,
        "watchersCount" : 3407,
        "size" : 184643,
        "openIssuesCount" : 1294,
        "subscribersCount" : 107,
        "pushedAt" : "2025-07-12T00:55:16Z",
        "languages" : {
          "C#" : 10641095,
          "TypeScript" : 652341,
          "PowerShell" : 17186,
          "Shell" : 6165,
          "CSS" : 1939,
          "Bicep" : 16429086,
          "Batchfile" : 3756,
          "JavaScript" : 9726,
          "Inno Setup" : 1745,
          "HTML" : 290309,
          "1C Enterprise" : 3072
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to improve the clarity and explicitness of the warning about missing resource types in Bicep, and to provide a link to the help page for BCP081 and other Bicep warnings/errors.",
      "validationOrRequirement" : "The issue requires a clear and explicit warning about the impact of missing resource types, and a link to the help page for BCP081 and other Bicep warnings/errors.",
      "attemptedFixes" : "The original poster suggests that the warning should be more explicit about the actual effects, and provides a possible rewording.",
      "otherNotes" : "The issue is related to the warning about missing resource types and the lack of clarity about its impact. There is also a concern about the missing link to the help page for BCP081 and other Bicep warnings/errors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285225
  }, {
    "issueDTO" : {
      "id" : 2458728903,
      "title" : "Support TS config files",
      "url" : "https://github.com/microsoft/vscode-eslint/issues/1917",
      "repositoryName" : "microsoft/vscode-eslint",
      "description" : "ESLint 9.9.0 was just released with support for TS config files:\r\nhttps://github.com/eslint/eslint/pull/18134",
      "updatedAt" : 1752192818.000000000,
      "user" : "polyzen",
      "userHtmlUrl" : "https://github.com/polyzen",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3533182?v=4",
      "labels" : [ "feature-request", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Not sure if it's as simple as adding eslint.config.ts, eslint.config.mts, and eslint.config.cts to https://github.com/microsoft/vscode-eslint/blob/release/3.0.10/server/src/eslint.ts#L800\r\n\r\nEdit: For the VS Code client these need to be updated (seems they're also missing .mjs and .cjs?):\r\nhttps://github.com/microsoft/vscode-eslint/blob/release/3.0.10/client/src/client.ts#L140\r\nhttps://github.com/microsoft/vscode-eslint/blob/release/3.0.10/client/src/client.ts#L424", "Need also to at least pass `--flag unstable_ts_config`, but not having success using a TS config with just ESLint myself yet.\r\nhttps://eslint.org/docs/latest/use/configure/configuration-files#typescript-configuration-files", "You can add the following settings:\r\n\r\n```json\r\n{\r\n  \"eslint.options\": {\r\n    \"flags\": [\"unstable_ts_config\"]\r\n  }\r\n}\r\n```\r\n\r\n> eslint.options: options to configure how ESLint is started using either the [ESLint class API](http://eslint.org/docs/developer-guide/nodejs-api#eslint-class) or the [CLIEngine API](http://eslint.org/docs/developer-guide/nodejs-api#cliengine).\r\n> \r\n> options.flags (string[])\r\n> Default is []. The feature flags to enable for this instance.\r\n\r\n- https://eslint.org/docs/latest/integrate/nodejs-api#parameters\r\n- https://github.com/Microsoft/vscode-eslint#settings-options", "I added mjs and cjs to the watcher pattern. With the ts I would like to wait to see where the feature in eslint is heading to.", "@dbaeumer what questions can I answer about this feature for you?\r\n\r\n(In general, feel free to reach out via GitHub discussion or Discord if you're ever blocked waiting for info about what ESLint is doing.)", "@nzakas my biggest question is currently why this is in ESLint since NodeJS itself added experimental support for this: https://nodejs.org/api/typescript.html#type-stripping\r\n\r\n", "@dbaeumer because ESLint needs to run on multiple versions of Node.js, some of which don't have experimental support, as well as Bun and Deno. Once TypeScript support is built into Node.js as stable, and we are able to move off of support for older versions, we can remove the `jiti` dependency.", "@gorstak17 please open a fresh issue for your problem, best with a GitHub repository I can clone with a minimal repro case that demos the problem you are seeing. This being said, please ensure that ESLint works correctly in the terminal before file the issue.", "Anyone facing issues with an npm workspaces setup, you will need to also enable `\"eslint.workingDirectories\": [{ \"mode\": \"auto\" }]`.", "> With the ts I would like to wait to see where the feature in eslint is heading to.\n\n@dbaeumer Just in case you missed it, now eslint.config.ts is available without an experimental flag", "Is this possible without `jiti` now? https://github.com/eslint/eslint/pull/19401", "I quickly looked into this and it should IMO work if you use a custom Node runtime via the setting `eslint.runtime`. VS Code still used Node 20.18.3 which has no support for type stripping. Can someone that is using ts config file check if this works as expected using the `eslint.runtime` setting.", "Is there support for Node 18 with `jiti`? I am having a similiar issue to https://github.com/eslint/eslint/issues/19413 (post  `v9.9.0`), only happens in Eslint VSCode extension and a `pnp` project.\n\n```json\n{\n  \"eslint.runtime\": \"node\",\n  \"eslint.useFlatConfig\": true,\n  \"eslint.workingDirectories\": [{ \"mode\": \"auto\" }],\n  \"eslint.options\": {\n    \"flags\": [\"unstable_config_lookup_from_file\"]\n  }\n}\n```\n\n```sh\n2025-04-21T17:13:54.533Z eslint:eslint Using config loader ConfigLoader\n2025-04-21T17:13:54.533Z eslint:config-loader Calculating config for file /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/src/routes/sverdle/+page.svelte\n2025-04-21T17:13:54.533Z eslint:config-loader Override config file path is eslint.config.ts\n2025-04-21T17:13:54.533Z eslint:config-loader Calculating config for directory /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/src/routes/sverdle/+page.svelte\n2025-04-21T17:13:54.533Z eslint:config-loader Using config file /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/eslint.config.ts and base path /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app\n2025-04-21T17:13:54.533Z eslint:config-loader Calculating config array from config file /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/eslint.config.ts and base path /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app\n2025-04-21T17:13:54.533Z eslint:config-loader Loading config file /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/eslint.config.ts\n2025-04-21T17:13:54.533Z eslint:config-loader Loading config from /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/eslint.config.ts\n2025-04-21T17:13:54.533Z eslint:config-loader Config file URL is file:///Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/eslint.config.ts\n[Error - 10:13:55 AM] An unexpected error occurred:\n[Error - 10:13:55 AM] TypeError: Cannot read properties of undefined (reading 'Visitor')\n    at /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/node_modules/.store/eslint-scope-npm-8.2.0-d74e314c9e/package/lib/pattern-visitor.js:54:52\n    at async import (/Users/mitran/.yarn/berry/cache/jiti-npm-2.4.2-d980cbb540-10c0.zip/node_modules/jiti/dist/jiti.cjs:1:199772)\n    at async /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/node_modules/.store/eslint-scope-npm-8.2.0-d74e314c9e/package/lib/referencer.js:29:23\n    at async import (/Users/mitran/.yarn/berry/cache/jiti-npm-2.4.2-d980cbb540-10c0.zip/node_modules/jiti/dist/jiti.cjs:1:199772)\n    at async /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/node_modules/.store/eslint-scope-npm-8.2.0-d74e314c9e/package/lib/index.js:52:19\n    at async import (/Users/mitran/.yarn/berry/cache/jiti-npm-2.4.2-d980cbb540-10c0.zip/node_modules/jiti/dist/jiti.cjs:1:199772)\n    at async /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/node_modules/.store/svelte-eslint-parser-virtual-4ac8103543/package/lib/parser/index.js:3:20\n    at async import (/Users/mitran/.yarn/berry/cache/jiti-npm-2.4.2-d980cbb540-10c0.zip/node_modules/jiti/dist/jiti.cjs:1:199772)\n    at async /Users/mitran/Projects/vite-storybook-boilerplate/apps/svelte-app/node_modules/.store/svelte-eslint-parser-virtual-4ac8103543/package/lib/main.js:5:15\n    at async import (/Users/mitran/.yarn/berry/cache/jiti-npm-2.4.2-d980cbb540-10c0.zip/node_modules/jiti/dist/jiti.cjs:1:199772)\n```", "@psychobolt Can you try `JITI_INTEROP_DEFAULT=true` environment variable when running command to see if it makes a difference?\n\nOtherwise please feel free to open a reproduction issue in [jiti](https://github.com/unjs/jiti) would be happy to investigate.", "@pi0 I don't see how that could help, `JITI_INTEROP_DEFAULT` is a default and is overriden by eslint under user options: https://github.com/unjs/jiti/blob/b396aec45847a32677417ea9dfc78098b6d45c23/src/options.ts#L43 . \n\nAnother case, is that running `eslint --flag unstable_config_lookup_from_file .` with CLI works fine when interop is disabled. Just not under the extension. My setup is using `yarn` and a sub-package configured with `pnpm`. So therefore, I can't really reproduce the issue in the project with CLI tools only e.g. `yarn eslint --flag unstable_config_lookup_from_file .`\n\nBefore `jiti` was introduced in `eslint`, I used a [swc register](https://github.com/psychobolt/vite-storybook-boilerplate/tree/main/bin#esm-register) for typescript configs without much issues, I just needed to workaround with passing a custom runtime script within the `settings.json` file. e.g.\n\n```js\nconst nodeOptions = execSync('yarn node -p process.env.NODE_OPTIONS')\n    .toString()\n    .slice(0, -1)\n    .replace('--experimental-loader', '--loader');\n\n  // IPC is blocked for `yarn node`, see https://github.com/yarnpkg/berry/issues/1696\n  const child = spawn('node', args, {\n    env: {\n      ...process.env,\n      NODE_OPTIONS: nodeOptions // <-- include runtime options here...\n    },\n    stdio: ['inherit', 'inherit', 'inherit', 'ipc']\n  }).on('message', (data) => {\n    if (process.send !== undefined) {\n      process.send(data);\n    }\n  });\n\n  process.on('message', (data) => {\n    child.send(data);\n  });\n```\n\nI tried to do the same after the `jiti` introduction and even patching `eslint` interop, however I was not able to get this working.\n", "Just a thought. Would it be viable to launch another process that runs eslint which communicates with the eslintServer through IPC? I would mainly like to run eslint through bun, but launching a LanguageClient using a bun runtime doesn't seem to work. So could client -> server -> eslint-api-server be viable? The `ESLintClass` in `server/src/eslint.ts` would have the same signature but e.g. the `lintText` method would get `ESLintDocumentReport`s not through invoking the eslint library but through an IPC call to a eslint-api-server etc.", "> I quickly looked into this and it should IMO work if you use a custom Node runtime via the setting `eslint.runtime`. VS Code still used Node 20.18.3 which has no support for type stripping. Can someone that is using ts config file check if this works as expected using the `eslint.runtime` setting.\n\n\nI was able to make it work with the following config : \n\n```json\n\"eslint.runtime\": \"node\",\n\"eslint.workingDirectories\": [{ \"mode\": \"auto\" }]\n```\n\nnode version : 22.13.1\neslint version : 9.28.0", "```\n    \"eslint.runtime\": \"bun\",\n```\n\nworked as well" ],
      "repository" : {
        "description" : "VSCode extension to integrate eslint into VSCode",
        "homepage" : null,
        "name" : "vscode-eslint",
        "fullName" : "microsoft/vscode-eslint",
        "htmlUrl" : "https://github.com/microsoft/vscode-eslint",
        "gitUrl" : "git://github.com/microsoft/vscode-eslint.git",
        "sshUrl" : "git@github.com:microsoft/vscode-eslint.git",
        "cloneUrl" : "https://github.com/microsoft/vscode-eslint.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 356,
        "stargazersCount" : 1840,
        "watchersCount" : 1840,
        "size" : 6764,
        "openIssuesCount" : 86,
        "subscribersCount" : 66,
        "pushedAt" : "2025-07-07T13:32:57Z",
        "languages" : {
          "TypeScript" : 230280,
          "Shell" : 114,
          "JavaScript" : 21522,
          "Vue" : 1174,
          "HTML" : 186,
          "Jupyter Notebook" : 115246
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to support TypeScript config files in the VS Code ESLint extension, specifically with the release of ESLint 9.9.0.",
      "validationOrRequirement" : "The author is asking for help in implementing the support for TypeScript config files in the VS Code ESLint extension. The discussion revolves around the use of jiti, a JavaScript runtime, and its compatibility with TypeScript config files. The author needs to ensure that ESLint works correctly in the terminal before filing an issue.",
      "attemptedFixes" : "The author has tried using a custom Node runtime via the setting `eslint.runtime` and was able to make it work with the following config: `\"eslint.runtime\": \"node\", \"eslint.workingDirectories\": [{ \"mode\": \"auto\" }]`. They also tried using `\"eslint.runtime\": \"bun\"` which worked as well. @dbaeumer suggested using a custom Node runtime via the setting `eslint.runtime` and @pi0 mentioned that `JITI_INTEROP_DEFAULT` is a default and is overridden by ESLint under user options.",
      "otherNotes" : "The issue is about supporting TypeScript config files in ESLint, specifically with the release of ESLint 9.9.0. The author is asking for help in implementing this feature in the VS Code ESLint extension. The discussion revolves around the use of jiti, a JavaScript runtime, and its compatibility with TypeScript config files. The author has tried using a custom Node runtime via the setting `eslint.runtime` and was able to make it work with the following config: `\"eslint.runtime\": \"node\", \"eslint.workingDirectories\": [{ \"mode\": \"auto\" }]`. They also tried using `\"eslint.runtime\": \"bun\"` which worked as well.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285238
  }, {
    "issueDTO" : {
      "id" : 463227886,
      "title" : "Drag'n'drop",
      "url" : "https://github.com/codex-team/editor.js/issues/838",
      "repositoryName" : "codex-team/editor.js",
      "description" : "Add ability to move blocks by drag-n-drop\r\n- [ ] should work with one block and with several selected blocks\r\n- [ ] Should use same scroll behaviour as used in RectangleSelection\r\n- [ ] Should work by pressing on Block Tunes toggle (and alt-text should be `Click to tune or drag to move`)\r\n\r\n<img width=\"237\" alt=\"image\" src=\"https://user-images.githubusercontent.com/3684889/152971766-115dd4f5-41b1-478b-8c6a-f8701d400303.png\">\r\n",
      "updatedAt" : 1752192469.000000000,
      "user" : "neSpecc",
      "userHtmlUrl" : "https://github.com/neSpecc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3684889?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\uD83D\uDC4D ", "@neSpecc Hi there. Having this would be great along with the ability to add layouts which would make it complete. May I know if there is any update regarding this? Thanks.", "Any updates on 2021 Q3?", "I want that too. In fact, the first time I saw that button, I thought it was for dragging the block but it wasn't, sadly :'(" ],
      "repository" : {
        "description" : "A block-style editor with clean JSON output",
        "homepage" : "https://editorjs.io",
        "name" : "editor.js",
        "fullName" : "codex-team/editor.js",
        "htmlUrl" : "https://github.com/codex-team/editor.js",
        "gitUrl" : "git://github.com/codex-team/editor.js.git",
        "sshUrl" : "git@github.com:codex-team/editor.js.git",
        "cloneUrl" : "https://github.com/codex-team/editor.js.git",
        "owner" : {
          "login" : "codex-team",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2178,
        "stargazersCount" : 30490,
        "watchersCount" : 30490,
        "size" : 20644,
        "openIssuesCount" : 679,
        "subscribersCount" : 252,
        "pushedAt" : "2025-04-30T16:52:33Z",
        "languages" : {
          "TypeScript" : 874284,
          "CSS" : 38035,
          "JavaScript" : 3657,
          "HTML" : 53972
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add ability to move blocks by drag-n-drop",
      "validationOrRequirement" : "should work with one block and with several selected blocks, same scroll behaviour as used in RectangleSelection, work by pressing on Block Tunes toggle (and alt-text should be `Click to tune or drag to move`)",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "Having this would be great along with the ability to add layouts which would make it complete. May I know if there is any update regarding this? Thanks. Any updates on 2021 Q3? I want that too. In fact, the first time I saw that button, I thought it was for dragging the block but it wasn't, sadly :('",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285243
  }, {
    "issueDTO" : {
      "id" : 3221037648,
      "title" : "Address commit comments (commit `e711bd7`)",
      "url" : "https://github.com/stdlib-js/stdlib/issues/7613",
      "repositoryName" : "stdlib-js/stdlib",
      "description" : "This commit has **1** comment(s) from core contributors that require attention.\n\n**Commit:** [e711bd7d9e72c365915dfbe92ac50394890a2da4](https://github.com/stdlib-js/stdlib/commit/e711bd7d9e72c365915dfbe92ac50394890a2da4)\n\n**Comments:**\n\n-   https://github.com/stdlib-js/stdlib/commit/e711bd7d9e72c365915dfbe92ac50394890a2da4#r161820245\n\n    > @stdlib-bot Should be `bench( pkg+'::native', opts, function benchmark( b ) {`\n\n    https://github.com/stdlib-js/stdlib/blob/e711bd7d9e72c365915dfbe92ac50394890a2da4/lib/node_modules/@stdlib/stats/base/dists/pareto-type1/mean/benchmark/benchmark.native.js#L-3-L3\n\nInterested in helping improve the project? If you are, the comment linked to above has **1** comment(s) from core contributors that could use your attention.\n\nWhat do you need to do?\n\n1.  Open the above linked comments mentioning @stdlib-bot.\n2.  Review the suggested changes or follow-up tasks (e.g., formatting improvements, small refactorings, or clean-up).\n3.  If you are a first-time contributor, follow the [contributing](https://github.com/stdlib-js/stdlib/blob/develop/CONTRIBUTING.md) and [development](https://github.com/stdlib-js/stdlib/blob/develop/docs/contributing/development.md) guides to setup your local environment for contributing to stdlib. If you are already a seasoned stdlib contributor, create a new branch on your local fork for making the changes.\n4.  Make all the desired changes and commit those changes to a local branch.\n5.  Push the changes to GitHub and open a new pull request against the `develop` branch of the main stdlib development [repository](https://github.com/stdlib-js/stdlib).\n\nOnce you've opened a pull request, a stdlib maintainer will review your work and suggest any follow-up changes.\n\nAnd that's it!\n\nThank you for your help in reducing the project backlog and in improving the quality of stdlib. \uD83D\uDE4C\n\n* * *\n\n## Notes\n\n-  When creating your pull request, please use the following format for the PR title:\n\n   ```\n   chore: address commit comments for commit `e711bd7` (issue #NNNN)\n   ```\n\n   where `NNNN` is the issue number assigned to this issue.\n\n-  For older commits, there is a chance that comments will have been already been addressed due to other refactorings. If you find that to be true, don't worry! Just move on to addressing the next comment, and, when opening your pull request and describing your proposed changes, be sure to link to the comment and mention that it has been addressed. This will help reviewers when reviewing your code!\n\n* * *\n\nThis issue was created automatically to address commit comments tagging @stdlib-bot.",
      "updatedAt" : 1752192451.000000000,
      "user" : "stdlib-bot",
      "userHtmlUrl" : "https://github.com/stdlib-bot",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82920195?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "# :wave: Important: PLEASE READ :wave:\n\nThis issue has been labeled as a **good first issue** and is available for anyone to work on.\n\nIf this is your first time contributing to an open source project, some aspects of the development process may seem unusual, arcane, or some combination of both.\n\n1.  **You cannot \"claim\" issues.** People new to open source often want to \"claim\" or be assigned an issue before beginning work. The typical rationale is that people want to avoid wasted work in the event that someone else ends up working the issue. However, this practice is not effective in open source, as it often leads to \"issue squatting\", in which an individual asks to be assigned, is granted their request, and then never ends up working on the issue. Accordingly, you are encouraged to communicate your intent to address this issue, ideally by providing a rough outline as to how you plan to address the issue or asking clarifying questions, but, at the end of the day, we will take running code and rough consensus in order to move forward quickly.\n2.  **We have a very high bar for contributions.** We have very high standards for contributions and expect all contributions???whether new features, tests, or documentation???to be rigorous, thorough, and complete. Once a pull request is merged into stdlib, that contribution immediately becomes the collective responsibility of all maintainers of stdlib. When we merge code into stdlib, we are saying that we, the maintainers, commit to reviewing subsequent changes and making bugfixes to the code. Hence, in order to ensure future maintainability, this naturally leads to a higher standard of contribution.\n\nBefore working on this issue and opening a pull request, please read the project's [contributing guidelines](https://github.com/stdlib-js/stdlib/blob/develop/CONTRIBUTING.md). These guidelines and the associated [development guide](https://github.com/stdlib-js/stdlib/blob/develop/docs/contributing/development.md) provide important information, including links to stdlib's [Code of Conduct](https://github.com/stdlib-js/stdlib/blob/develop/CODE_OF_CONDUCT.md), license policy, and steps for setting up your local development environment.\n\nTo reiterate, we **strongly** encourage you to refer to our contributing guides **before** beginning work on this issue. Failure to follow our guidelines significantly decreases the likelihood that you'll successfully contribute to stdlib and may result in automatic closure of a pull request without review.\n\nSetting up your local development environment is a critical first step, as doing so ensures that automated development processes for linting, license verification, and unit testing can run prior to authoring commits and pushing changes. If you would prefer to avoid manual setup, we provide pre-configured [development containers](https://github.com/stdlib-js/stdlib/tree/develop/.devcontainer) for use locally or in GitHub Codespaces.\n\nWe place a high value on consistency throughout the stdlib codebase. We encourage you to closely examine other packages in stdlib and attempt to emulate the practices and conventions found therein.\n\n-   If you are attempting to contribute a new package, sometimes the best approach is to simply copy the contents of an existing package and then modify the minimum amount necessary to implement the feature (e.g., changing descriptions, parameter names, and implementation).\n-   If you are contributing tests, find a package implementing a similar feature and emulate the tests of that package.\n-   If you are updating documentation, examine several similar packages and emulate the content, style, and prose of those packages.\n\nIn short, the more effort you put in to ensure that your contribution looks and feels like stdlib???including variables names, bracket spacing, line breaks, etc???the more likely that your contribution will be reviewed and ultimately accepted. We encourage you to closely study the codebase **before** beginning work on this issue.\n\n:sparkles: Thank you again for your interest in stdlib, and we look forward to reviewing your future contributions. :sparkles:\n" ],
      "repository" : {
        "description" : "??? Standard library for JavaScript and Node.js. ???",
        "homepage" : "https://stdlib.io",
        "name" : "stdlib",
        "fullName" : "stdlib-js/stdlib",
        "htmlUrl" : "https://github.com/stdlib-js/stdlib",
        "gitUrl" : "git://github.com/stdlib-js/stdlib.git",
        "sshUrl" : "git@github.com:stdlib-js/stdlib.git",
        "cloneUrl" : "https://github.com/stdlib-js/stdlib.git",
        "owner" : {
          "login" : "stdlib-js",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 843,
        "stargazersCount" : 5263,
        "watchersCount" : 5263,
        "size" : 2119351,
        "openIssuesCount" : 833,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-11T22:10:54Z",
        "languages" : {
          "C++" : 322679,
          "CSS" : 50680,
          "C" : 44265210,
          "WebAssembly" : 205765,
          "HTML" : 55717,
          "Fortran" : 365806,
          "TypeScript" : 31139318,
          "Julia" : 5682,
          "Shell" : 213507,
          "R" : 5700,
          "Awk" : 3608,
          "JavaScript" : 135406211,
          "Python" : 8521226
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Address commit comments (commit `e711bd7`) by reviewing and addressing the comment from core contributors, making the desired changes, and opening a pull request against the `develop` branch.",
      "validationOrRequirement" : "The issue requires the contributor to review the suggested changes or follow-up tasks, make the desired changes, commit those changes to a local branch, push the changes to GitHub, and open a new pull request against the `develop` branch.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is about addressing commit comments, specifically one comment from core contributors that requires attention. It is a good first issue and has been labeled as such. The issue has been created automatically to address commit comments tagging @stdlib-bot.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285248
  }, {
    "issueDTO" : {
      "id" : 2276778343,
      "title" : "RBAC: Implement instance-wide default role",
      "url" : "https://github.com/kafbat/kafka-ui/issues/344",
      "repositoryName" : "kafbat/kafka-ui",
      "description" : "### Issue submitter TODO list\r\n\r\n- [X] I've searched for an already existing issues [here](https://github.com/kafbat/kafka-ui/issues)\r\n- [X] I'm running a supported version of the application which is listed [here](https://github.com/kafbat/kafka-ui/blob/main/.github/SECURITY.md) and the feature is not present there\r\n\r\n### Is your proposal related to a problem?\r\n\r\nHi,\r\nWhen new kafka consumer gives me a request to approach kafka ui (for readonly),\r\ni have to rewrite rbac yaml file.\r\nI deployed two Kafka UI to solve this problem.\r\nFirst one has basic authentication is for admin users.\r\nThe other one is readonly for kafka consumers.\r\n\r\n### Describe the feature you're interested in\r\n\r\nI think it is useful if the way i can setup default role is exists.\r\n```yaml\r\nrbac:\r\n  roles:\r\n    - name: \"admins\"\r\n      clusters:\r\n        - development\r\n      subjects:\r\n         - provider: oauth_github\r\n           type: user\r\n           value: 'seono'\r\n      permissions:\r\n        ...\r\n    - name: \"readonly\"\r\n      clusters:\r\n        - development\r\n      subjects:\r\n        - provider: oauth_github\r\n          type: default\r\n      permissions:\r\n        ...\r\n```\r\n\r\n### Describe alternatives you've considered\r\n\r\nI know there is other type `organization` and `team`.\r\nIf someone wants readonly permission, I can invite them to the group.\r\nBut.. In my case, my company has too many organzations and teams so i can not use it properly.\r\n\r\n\r\n### Version you're running\r\n\r\nhttps://github.com/kafbat/kafka-ui/commit/9843ee0\r\n\r\n### Additional context\r\n\r\n_No response_",
      "updatedAt" : 1752192347.000000000,
      "user" : "seono",
      "userHtmlUrl" : "https://github.com/seono",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47937302?v=4",
      "labels" : [ "status/triage/completed", "scope/backend", "type/enhancement", "good first issue", "area/rbac" ],
      "state" : "OPEN",
      "comments" : [ "Hi seono! \uD83D\uDC4B\n\nWelcome, and thank you for opening your first issue in the repo!\n\nPlease wait for triaging by our maintainers.\n\nAs development is carried out in our spare time, you can support us by sponsoring our activities or even funding the development of specific issues.\n[Sponsorship link](https://github.com/kafbat)\n\nIf you plan to raise a PR for this issue, please take a look at our [contributing guide](https://ui.docs.kafbat.io/development/contributing).", "hi @Haarolean any update on this feature, it's very important for us since default role is needed for company wide, it would be really helpful if you can integrate this feature ASAP", "@sankhyan As development is done in the spare time of our team members, our bandwidth is limited. You (or your company) can sponsor the development of this feature: https://github.com/sponsors/kafbat/sponsorships?tier_id=384551", "Being able to use regex will also help in my particular case.", "@githubwalvarado that's a diff issue: #300", "TODO:\r\n- Implement a default role with this config syntax:\r\n```\r\nrbac:\r\n  default-role: \"memelords\"\r\n  roles: []\r\n```\r\n- The role should be assigned to anyone who can successfully login", "I'll prepare the PR.", "Any updates on this one? :) ", "@Haarolean  @jonykrause Hello.\nUnfortunately, I???m currently tied up with other commitments, so I???d really appreciate if someone else could take over preparing this PR.\nApologies for the delay!", "@Haarolean @wernerdv \nhi, I wanted to give it a try, so I created a draft PR https://github.com/kafbat/kafka-ui/pull/1056\n\n\n> TODO:\n> \n> * Implement a default role with this config syntax:\n> \n> ```\n> rbac:\n>   default-role: \"memelords\"\n>   roles: []\n> ```\n> \n> * The role should be assigned to anyone who can successfully login\n\n\nI implemented the changes based on the comment above and tested them locally.\nIf this aligns with what you had in mind, I???ll follow up with test cases and documentation.", "@seono, would you like to raise a PR to update the docs, please? \nhttps://github.com/kafbat/ui-docs", "@Haarolean, I???ll put up a PR for the default role." ],
      "repository" : {
        "description" : "Open-Source Web UI for managing Apache Kafka clusters",
        "homepage" : "https://kafbat.io",
        "name" : "kafka-ui",
        "fullName" : "kafbat/kafka-ui",
        "htmlUrl" : "https://github.com/kafbat/kafka-ui",
        "gitUrl" : "git://github.com/kafbat/kafka-ui.git",
        "sshUrl" : "git@github.com:kafbat/kafka-ui.git",
        "cloneUrl" : "https://github.com/kafbat/kafka-ui.git",
        "owner" : {
          "login" : "kafbat",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 151,
        "stargazersCount" : 1222,
        "watchersCount" : 1222,
        "size" : 36704,
        "openIssuesCount" : 229,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-10T17:43:33Z",
        "languages" : {
          "TypeScript" : 1240190,
          "Java" : 1607680,
          "Dockerfile" : 1018,
          "ANTLR" : 17012,
          "Gherkin" : 5886,
          "SCSS" : 27,
          "JavaScript" : 3698,
          "HTML" : 1779
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement instance-wide default role in RBAC configuration to simplify setup for readonly access",
      "validationOrRequirement" : "Implement instance-wide default role with specific config syntax; assign default role to anyone who can successfully login",
      "attemptedFixes" : "Implementing changes based on comments and testing them locally; preparing a PR for the default role",
      "otherNotes" : "TODO list includes implementing a default role with specific config syntax and assigning it to anyone who can successfully login; a draft PR is available at https://github.com/kafbat/kafka-ui/pull/1056",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285253
  }, {
    "issueDTO" : {
      "id" : 3165305425,
      "title" : "Upgrade package graphql_flutter from 5.2.0-beta.8 to 5.2.0",
      "url" : "https://github.com/PalisadoesFoundation/talawa/issues/2839",
      "repositoryName" : "PalisadoesFoundation/talawa",
      "description" : "## Rationale\n1. This was previously attempted by the automated dependabot job but the PR tests failed.\n1. This issue has been created to fix the issue as there may be multiple dependency requirements that need updating\n1. If this is a major revision upgrade, then many files may need to be updated to the new syntax, in their functions, methods and classes.\n1. Other dependencies may need to be upgraded too\n1. If this package is no longer being used, then remove from the repository's configuration\n\n##\n\n1. We upgrade dependencies to improve security and our code health \n1. This is a good first issue\n\n\n## Background Failing PRs\n\n- https://github.com/PalisadoesFoundation/talawa/pull/2833\n- https://github.com/PalisadoesFoundation/talawa/actions/runs/15102492880/job/42445599007?pr=2833",
      "updatedAt" : 1752192342.000000000,
      "user" : "palisadoes",
      "userHtmlUrl" : "https://github.com/palisadoes",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16875803?v=4",
      "labels" : [ "security", "feature request", "good first issue", "no-issue-activity", "dependencies" ],
      "state" : "OPEN",
      "comments" : [ "Hello @palisadoes  I would like to work on this issue. Could you please assign it to me\n\nThank you", "This issue did not get any activity in the past 10 days and will be closed in 180 days if no update occurs. Please check if the develop branch has fixed it and report again or close the issue.", "Want to work on the issue as well !!. Could you please assign the issue to me.", "This issue did not get any activity in the past 10 days and will be closed in 180 days if no update occurs. Please check if the develop branch has fixed it and report again or close the issue." ],
      "repository" : {
        "description" : "Community Organization Management Software. Click on the link below to see our documentation.",
        "homepage" : "https://docs.talawa.io/",
        "name" : "talawa",
        "fullName" : "PalisadoesFoundation/talawa",
        "htmlUrl" : "https://github.com/PalisadoesFoundation/talawa",
        "gitUrl" : "git://github.com/PalisadoesFoundation/talawa.git",
        "sshUrl" : "git@github.com:PalisadoesFoundation/talawa.git",
        "cloneUrl" : "https://github.com/PalisadoesFoundation/talawa.git",
        "owner" : {
          "login" : "PalisadoesFoundation",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 518,
        "stargazersCount" : 415,
        "watchersCount" : 415,
        "size" : 35728,
        "openIssuesCount" : 21,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-08T06:08:48Z",
        "languages" : {
          "Shell" : 1253,
          "Objective-C" : 38,
          "Swift" : 404,
          "Ruby" : 1353,
          "Dart" : 2530144,
          "Python" : 13515,
          "Kotlin" : 123
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Upgrade package graphql_flutter from 5.2.0-beta.8 to 5.2.0 to improve security and code health",
      "validationOrRequirement" : "Upgrade package graphql_flutter from 5.2.0-beta.8 to 5.2.0, consider updating other dependencies, and potentially update many files to the new syntax",
      "attemptedFixes" : "The automated dependabot job previously attempted to upgrade the package but the PR tests failed",
      "otherNotes" : "The automated dependabot job previously attempted to upgrade the package but the PR tests failed, and this issue is being created to fix the issue as there may be multiple dependency requirements that need updating.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285257
  }, {
    "issueDTO" : {
      "id" : 3096385556,
      "title" : "[BUG]: 'Edit' button on website does not redirect to main brain of project on Github",
      "url" : "https://github.com/the-turing-way/the-turing-way/issues/4246",
      "repositoryName" : "the-turing-way/the-turing-way",
      "description" : "### Description\n\nBug with the edit button on the website.\n\n### Expected behavior\n\nPressing the 'edit' button on the website doesn't take the user to the main brain.\n\n<img width=\"762\" alt=\"Screenshot of turing way website with edit button outlined in red\" src=\"https://github.com/user-attachments/assets/7f2a58cf-521f-4e19-b532-89d30ac13e59\" />\n\nAfter clicking on this button, the user is redirected to a new page:\n\n<img width=\"1784\" alt=\"Screenshot of Github page with branch and error message outlined in red\" src=\"https://github.com/user-attachments/assets/5a4ed557-0382-4dd1-814e-493db3262806\" />\n\nThe user is not able to edit the page without switching to the main branch.\n\n### Actual behaviour\n\nUser needs to be able to switch manually to the main page.\n\n### How to reproduce\n\nN/A\n\n### Your personal set up\n\nN/A\n\n### Dependencies\n\nN/A\n\n### Log messages\n\nN/A",
      "updatedAt" : 1752192185.000000000,
      "user" : "aleesteele",
      "userHtmlUrl" : "https://github.com/aleesteele",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18509789?v=4",
      "labels" : [ "bug", "infrastructure", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Uh oh! @aleesteele, the image you shared is missing helpful alt text. Check  your issue body.\n\nAlt text is an invisible description that helps screen readers describe images to blind or low-vision users. If you are using markdown to display images, add your alt text inside the brackets of the markdown image.\n\nLearn more about alt text at [Basic writing and formatting syntax: images on GitHub Docs](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#images).", "It looks like it is taking you to the commit where the file was last modified. I expect this is to do with the Myst Book theme.\n\n- [Docs for the button](https://mystmd.org/guide/website-navigation#use-the-edit-this-page-button), these say we can set the edit url using a frontmatter field\n- [Frontmatter fields, including `edit_url`](https://mystmd.org/guide/frontmatter#available-frontmatter-fields)\n\nIt may also be that the behaviour is different if the `github` value in the form `org/repo` instead of a URL.\nhttps://github.com/the-turing-way/the-turing-way/blob/80940356994e4efc73cd76cf429587d2ba3a5a8d/book/website/myst.yml#L12\n\nThe [MyST Markdown docs](https://mystmd.org/guide/) always seem to redirect to the main branch for example.", "Hi! I???m interested in this issue. Can I work on it?\n", "@SakshamSharma10989 Absolutely :tada:", "Hi, I got assigned to this but can???t work on it right now. Please feel free to reassign it. Sorry!" ],
      "repository" : {
        "description" : "Book repository for The Turing Way: a how to guide for reproducible, ethical and collaborative data science",
        "homepage" : "https://the-turing-way.org/",
        "name" : "the-turing-way",
        "fullName" : "the-turing-way/the-turing-way",
        "htmlUrl" : "https://github.com/the-turing-way/the-turing-way",
        "gitUrl" : "git://github.com/the-turing-way/the-turing-way.git",
        "sshUrl" : "git@github.com:the-turing-way/the-turing-way.git",
        "cloneUrl" : "https://github.com/the-turing-way/the-turing-way.git",
        "owner" : {
          "login" : "the-turing-way",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 693,
        "stargazersCount" : 2044,
        "watchersCount" : 2044,
        "size" : 742879,
        "openIssuesCount" : 603,
        "subscribersCount" : 59,
        "pushedAt" : "2025-07-11T09:07:33Z",
        "languages" : {
          "Shell" : 3807,
          "CSS" : 725,
          "TeX" : 123958,
          "Makefile" : 810,
          "JavaScript" : 697,
          "Python" : 14656
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The 'Edit' button on the website does not redirect to the main brain of the project on Github, and the user needs to switch manually to the main branch to edit the page.",
      "validationOrRequirement" : "The Myst Markdown docs specify that we can set the edit URL using a frontmatter field, and the 'edit_url' field is available in the frontmatter fields.",
      "attemptedFixes" : "It seems that the Myst Markdown docs always redirect to the main branch, and the issue may be related to the 'github' value in the form 'org/repo' instead of a URL.",
      "otherNotes" : "The issue is related to the Myst Book theme, and the expected behavior is that pressing the 'edit' button on the website should take the user to the main brain of the project on Github, but instead, it redirects to a new page with an error message. The user needs to switch manually to the main branch to edit the page.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285264
  }, {
    "issueDTO" : {
      "id" : 2266856185,
      "title" : "Remove commented content in git  commit message",
      "url" : "https://github.com/apache/fory/issues/1588",
      "repositoryName" : "apache/fory",
      "description" : "## Is your feature request related to a problem? Please describe.\r\nCurrently there are many comments contents in PR.\r\n```\r\n<!--\r\n**Thanks for contributing to Fury.**\r\n\r\n**If this is your first time opening a PR on fury, you can refer to [CONTRIBUTING.md](https://github.com/apache/incubator-fury/blob/main/CONTRIBUTING.md).**\r\n\r\nContribution Checklist\r\n\r\n    - The **Apache Fury (incubating)** community has restrictions on the naming of pr titles. You can also find instructions in [CONTRIBUTING.md](https://github.com/apache/incubator-fury/blob/main/CONTRIBUTING.md).\r\n\r\n    - Fury has a strong focus on performance. If the PR you submit will have an impact on performance, please benchmark it first and provide the benchmark result here.\r\n-->\r\n\r\n## What does this PR do?\r\n\r\n<!-- Describe the purpose of this PR. -->\r\n\r\n\r\n## Related issues\r\n\r\n<!--\r\nIs there any related issue? Please attach here.\r\n\r\n- #xxxx0\r\n- #xxxx1\r\n- #xxxx2\r\n-->\r\n\r\n\r\n## Does this PR introduce any user-facing change?\r\n\r\n<!--\r\nIf any user-facing interface changes, please [open an issue](https://github.com/apache/incubator-fury/issues/new/choose) describing the need to do so and update the document if necessary.\r\n-->\r\n\r\n- [ ] Does this PR introduce any public API change?\r\n- [ ] Does this PR introduce any binary protocol compatibility change?\r\n\r\n\r\n## Benchmark\r\n\r\n<!--\r\nWhen the PR has an impact on performance (if you don't know whether the PR will have an impact on performance, you can submit the PR first, and if it will have impact on performance, the code reviewer will explain it), be sure to attach a benchmark data here.\r\n-->\r\n\r\n```\r\n\r\nIf contributor doesn't remove it, it will be included in the commited message, which make the git history kinds of messy.\r\n\r\n## Describe the solution you'd like\r\nWe should remove such conents automatically before merge PR\r\n\r\n## Additional context\r\n#1477 ",
      "updatedAt" : 1752191283.000000000,
      "user" : "chaokunyang",
      "userHtmlUrl" : "https://github.com/chaokunyang",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12445254?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "That's strange. Do you copy the PR body into the merge description when confirming a merge? If so, I think we can modify the PR raw text body automatically after people create the PR. I found a GitHub Actions plugin: [Update PR Description](https://github.com/marketplace/actions/update-pr-description) that works as follows.\r\n![image](https://github.com/apache/fury/assets/61675635/23d50839-ac6b-40ce-b1c0-ca4372178725)\r\nand it works on my demo\r\n![image](https://github.com/apache/fury/assets/61675635/78ad863e-7263-435b-8991-b883530858cc)\r\nHowever, for this issue, it might be necessary to create a custom action plugin. I'd like to take this on, but I'm not very familiar with writing action plugins. Could you allow me a few days to study this and then we can continue the discussion?\r\n ", "Of course, feel free to study this at your own pace. This is not urgent", "I have created a github action: [Remove markdown comments in PR](https://github.com/marketplace/actions/remove-markdown-comments-in-pr), detail usage are provided in its README. But if `<!-- comment -->` in PR body `code blocks` , it will also be removed.\r\n![image](https://github.com/apache/fury/assets/61675635/7ec2cd8d-3bee-44ba-8ed9-b65a2f842d30)\r\n\r\n", "I have tested it in my own copied repository, and it is effective, you can see in https://github.com/urlyy/fury_action_test/pull/1. But I don't know if you are satisfied with this effect, and whether submitting a PR about modifying the project's CI/CD is dangerous. Looking forward to your reply.", "I will take a look later. It needs a token, we need to ensure it's safe. I'm not familiar with github action. \r\nBTW, this is a common issue, is there any github action which has implemented this feature?", "> I will take a look later. It needs a token, we need to ensure it's safe. I'm not familiar with github action. BTW, this is a common issue, is there any github action which has implemented this feature?\r\n\r\nSorry, I didn't spend much time searching to see if relavant github action exists. I'll go check it out now.\r\n\r\n And if you want to know the process of my action ,only need to look at the `index.js` and `action.yml`, the `dist` directory is generated by `index.js` and something else, I learned at https://docs.github.com/en/actions/creating-actions/creating-a-javascript-action#commit-tag-and-push-your-action-to-github. \r\n\r\nAnd for https://github.com/urlyy/fury_action_test/pull/1 , I just add a yaml file at https://github.com/urlyy/fury_action_test/blob/main/.github/workflows/remove-pr-comment.yaml", "The action exists now because you created it: https://github.com/marketplace/actions/remove-markdown-comments-in-pr\n\nAre you going to integrate it?", "> The action exists now because you created it: https://github.com/marketplace/actions/remove-markdown-comments-in-pr\n> \n> Are you going to integrate it?\n\nI won't.", "Have you used it anywhere; is it tested?", "> Have you used it anywhere; is it tested?\n\nBoth no" ],
      "repository" : {
        "description" : "A blazingly fast multi-language serialization framework powered by JIT and zero-copy.",
        "homepage" : "https://fory.apache.org/",
        "name" : "fory",
        "fullName" : "apache/fory",
        "htmlUrl" : "https://github.com/apache/fory",
        "gitUrl" : "git://github.com/apache/fory.git",
        "sshUrl" : "git@github.com:apache/fory.git",
        "cloneUrl" : "https://github.com/apache/fory.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 281,
        "stargazersCount" : 3343,
        "watchersCount" : 3343,
        "size" : 14892,
        "openIssuesCount" : 195,
        "subscribersCount" : 47,
        "pushedAt" : "2025-07-10T09:29:58Z",
        "languages" : {
          "Java" : 3777274,
          "C++" : 241364,
          "Rust" : 151251,
          "C" : 61699,
          "Scala" : 43160,
          "Go" : 199995,
          "Kotlin" : 52952,
          "TypeScript" : 277332,
          "Shell" : 27432,
          "Starlark" : 33896,
          "JavaScript" : 21133,
          "Cython" : 177613,
          "Dart" : 606095,
          "Python" : 354184
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove commented content in Git commit messages to keep the Git history clean",
      "validationOrRequirement" : "The PR should remove commented content in the commit message, and the author suggested a GitHub Actions plugin to achieve this.",
      "attemptedFixes" : "A GitHub Actions plugin was suggested, and the author created a custom action plugin. The plugin was tested and is available on the GitHub Marketplace.",
      "otherNotes" : "The issue is about removing commented content in Git commit messages, which makes the Git history messy. The suggested solution is to remove these contents automatically before merging the PR.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285268
  }, {
    "issueDTO" : {
      "id" : 3186555429,
      "title" : "Outline Manager fails to create GCP server",
      "url" : "https://github.com/Jigsaw-Code/outline-apps/issues/2534",
      "repositoryName" : "Jigsaw-Code/outline-apps",
      "description" : "### Application\n\nOutline Manager\n\n### Describe the bug\n\nWhen using GCP option in \"ADD SERVER\" tab the app hangs on create server step. \nThe problem is connected to missing `projects/ubuntu-os-cloud/global/images/family/ubuntu-2004-lts` image that should be used when creating a compute engine instance. \n\nIn GCP logs for compute engine the following error message can be found:\n```\nThe resource 'projects/ubuntu-os-cloud/global/images/family/ubuntu-2004-lts' was not found\n```\nFor reference see [Operating system details](https://cloud.google.com/compute/docs/images/os-details#ubuntu_lts) section of Compute Engine Documentation. It clearly states that EOS and image deprecation date for tis image is May 2025. \n\nI suspect the error can be easily fixed by updating [this line](https://github.com/Jigsaw-Code/outline-apps/blob/55d09c01704909e1142fd14e2a91d5525872efd0/server_manager/www/gcp_account.ts#L275), but I'm not sure what image is to be used (otherwise I could try to open a PR). \n\n### Steps to reproduce\n\n1. open Outline Manager\n2. connect to GCP account\n3. create a project using \"ADD SERVER\" tab\n4. create server using on of the locations (same behaviour is observed for multiple server locations)\n\n### What did you expect to happen?\n\nSuccessfully completed addition of new server as it was before.\n\n### What actually happened?\n\nI've tried to create a new GCP server using the respective option in \"ADD SERVER\" tab. \n\n### Outline Version\n\n1.17.2\n\n### What operation system are you using?\n\nmacOS\n\n### Operating System Version\n\nSonoma 14.6.1\n\n### Screenshots and Videos\n\n_No response_",
      "updatedAt" : 1752190926.000000000,
      "user" : "contrapost",
      "userHtmlUrl" : "https://github.com/contrapost",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10920409?v=4",
      "labels" : [ "manager", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ " i facing like this issue 'projects/ubuntu-os-cloud/global/images/family/ubuntu-2004-lts' was not found , how can i do for this ?", "'projects/ubuntu-os-cloud/global/images/family/ubuntu-2004-lts' was not found, I using window, I create server from outline manager , version is 1.17.2, but i can't create server.", "Same problems on Windows client for Outline Manager." ],
      "repository" : {
        "description" : "Outline Client and Manager, developed by Jigsaw. Outline Manager makes it easy to create your own VPN server. Outline Client lets you share access to your VPN with anyone in your network, giving them access to the free and open internet.",
        "homepage" : "https://getoutline.org/",
        "name" : "outline-apps",
        "fullName" : "Jigsaw-Code/outline-apps",
        "htmlUrl" : "https://github.com/Jigsaw-Code/outline-apps",
        "gitUrl" : "git://github.com/Jigsaw-Code/outline-apps.git",
        "sshUrl" : "git@github.com:Jigsaw-Code/outline-apps.git",
        "cloneUrl" : "https://github.com/Jigsaw-Code/outline-apps.git",
        "owner" : {
          "login" : "Jigsaw-Code",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1402,
        "stargazersCount" : 8803,
        "watchersCount" : 8803,
        "size" : 600609,
        "openIssuesCount" : 491,
        "subscribersCount" : 215,
        "pushedAt" : "2025-07-11T23:28:50Z",
        "languages" : {
          "C#" : 47419,
          "Java" : 59742,
          "C++" : 80752,
          "CSS" : 10458,
          "C" : 1563,
          "CMake" : 1960,
          "Go" : 227076,
          "HTML" : 4901,
          "NSIS" : 6749,
          "AIDL" : 3979,
          "TypeScript" : 998476,
          "Dockerfile" : 1297,
          "Shell" : 53409,
          "Batchfile" : 11358,
          "JavaScript" : 147188,
          "Objective-C" : 18048,
          "Swift" : 67429
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Outline Manager fails to create a GCP server due to a missing image, resulting in an error message 'The resource 'projects/ubuntu-os-cloud/global/images/family/ubuntu-2004-lts' was not found'.",
      "validationOrRequirement" : "The issue requires a specific image to be used when creating a compute engine instance in GCP.",
      "attemptedFixes" : "The author suspects that updating the line https://github.com/Jigsaw-Code/outline-apps/blob/55d09c01704909e1142fd14e2a91d5525872efd0/server_manager/www/gcp_account.ts#L275 could fix the issue, but is unsure what image to use.",
      "otherNotes" : "The issue is related to missing image 'projects/ubuntu-os-cloud/global/images/family/ubuntu-2004-lts' in GCP, which is deprecated and will be removed in May 2025.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285274
  }, {
    "issueDTO" : {
      "id" : 3217994894,
      "title" : "[Improvement] Correct URL encode path in alterModelVersion in GenericModelCatalog.java",
      "url" : "https://github.com/apache/gravitino/issues/7638",
      "repositoryName" : "apache/gravitino",
      "description" : "### What would you like to be improved?\n\nIn alterModelVersion in clients/client-java/src/main/java/org/apache/gravitino/client/GenericModelCatalog.java the path needs to be URL encoded\n```\n    ModelVersionResponse resp =\n        restClient.put(\n            formatModelVersionRequestPath(modelFullIdent) + \"/aliases/\" + alias,\n            req,\n            ModelVersionResponse.class,\n            Collections.emptyMap(),\n            ErrorHandlers.modelErrorHandler());\n```\n\n### How should we improve?\n\nalias needs to be URL encoded",
      "updatedAt" : 1752190305.000000000,
      "user" : "justinmclean",
      "userHtmlUrl" : "https://github.com/justinmclean",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/144504?v=4",
      "labels" : [ "improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi\uD83D\uDC4B, can i take this issue ? Thanks" ],
      "repository" : {
        "description" : "World's most powerful open data catalog for building a high-performance, geo-distributed and federated metadata lake.",
        "homepage" : "https://gravitino.apache.org",
        "name" : "gravitino",
        "fullName" : "apache/gravitino",
        "htmlUrl" : "https://github.com/apache/gravitino",
        "gitUrl" : "git://github.com/apache/gravitino.git",
        "sshUrl" : "git@github.com:apache/gravitino.git",
        "cloneUrl" : "https://github.com/apache/gravitino.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 530,
        "stargazersCount" : 1693,
        "watchersCount" : 1693,
        "size" : 61834,
        "openIssuesCount" : 721,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-11T12:29:22Z",
        "languages" : {
          "Smarty" : 5095,
          "TypeScript" : 1191,
          "Java" : 14734465,
          "Dockerfile" : 26062,
          "Shell" : 184089,
          "CSS" : 937,
          "Rust" : 206295,
          "Batchfile" : 1647,
          "Makefile" : 3325,
          "JavaScript" : 511804,
          "Python" : 1191811
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Correct URL encode path in alterModelVersion in GenericModelCatalog.java",
      "validationOrRequirement" : "The path needs to be URL encoded and alias needs to be URL encoded.",
      "attemptedFixes" : "No attempted fixes or blockers are mentioned in the description or comments.",
      "otherNotes" : "The issue description includes a code snippet and mentions that the path needs to be URL encoded.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285277
  }, {
    "issueDTO" : {
      "id" : 3137733974,
      "title" : "install_executorch.sh --clean should remove buck-out/",
      "url" : "https://github.com/pytorch/executorch/issues/11564",
      "repositoryName" : "pytorch/executorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nWe remove `cmake-out/` `pip-out/` when we run `install_executorch.sh --clean`, we should also remove `buck-out/` as some of the file changes will not update in `buck-out/` automatically if we pull the latest, and that causes issues.\n\nFor example, #10675 introduces a new file `platform/platforms.cpp` and since `buck-out/` caches the value of `buck uquery \"inputs(deps(//runtime/platform:platform))\"`, it doesn't generate `executorch_srcs.cmake` file correctly, with the new file `platform/platforms.cpp`. \n\nThis kind of issue is hard to debug, so we should remove `buck-out/` every time user run `install_executorch.sh --clean`.\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### RFC (Optional)\n\n_No response_",
      "updatedAt" : 1752189687.000000000,
      "user" : "larryliu0820",
      "userHtmlUrl" : "https://github.com/larryliu0820",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8188269?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Can this issue be closed since #11641 merged into main? @larryliu0820 " ],
      "repository" : {
        "description" : "On-device AI across mobile, embedded and edge for PyTorch",
        "homepage" : "https://pytorch.org/executorch/",
        "name" : "executorch",
        "fullName" : "pytorch/executorch",
        "htmlUrl" : "https://github.com/pytorch/executorch",
        "gitUrl" : "git://github.com/pytorch/executorch.git",
        "sshUrl" : "git@github.com:pytorch/executorch.git",
        "cloneUrl" : "https://github.com/pytorch/executorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 613,
        "stargazersCount" : 3029,
        "watchersCount" : 3029,
        "size" : 238670,
        "openIssuesCount" : 1225,
        "subscribersCount" : 70,
        "pushedAt" : "2025-07-12T00:52:56Z",
        "languages" : {
          "Java" : 91154,
          "C++" : 7468950,
          "Jinja" : 11160,
          "C" : 92510,
          "Objective-C++" : 585572,
          "CMake" : 253562,
          "Kotlin" : 47365,
          "Dockerfile" : 2690,
          "Shell" : 234857,
          "Starlark" : 485277,
          "Batchfile" : 339,
          "Objective-C" : 192295,
          "Swift" : 90538,
          "Python" : 9370932,
          "GLSL" : 313850
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to remove buck-out/ when running install_executorch.sh --clean to avoid issues caused by caching in buck-out/.",
      "validationOrRequirement" : "The issue requires the removal of buck-out/ when running install_executorch.sh --clean.",
      "attemptedFixes" : "No specific attempted fixes or blockers are mentioned in the issue.",
      "otherNotes" : "The issue is hard to debug, and it is recommended to remove buck-out/ every time the user runs install_executorch.sh --clean.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285280
  }, {
    "issueDTO" : {
      "id" : 3181945033,
      "title" : "Remove conda from image type",
      "url" : "https://github.com/meta-llama/llama-stack/issues/2539",
      "repositoryName" : "meta-llama/llama-stack",
      "description" : "### \uD83D\uDE80 Describe the new functionality needed\n\nWhen building a distribution, we currently support three options:\n* Conda environments\n* Virtual environments (venv)\n* Containers\n\nVirtual environments are very popular and quite similar to Conda. With the growing adoption of [uv](https://docs.astral.sh/uv/), which has boosted venv???s traction even further, I think it might be time to consider dropping Conda support.\n\nThat said, I???d argue that venv is mainly a developer convenience rather than something people would actually use in production. So perhaps we should also consider discussing its removal in the future.\n\n@ashwinb are you ready?\n\n### \uD83D\uDCA1 Why is this needed? What if we don't build it?\n\nWe need to simplify our building options.\n\n### Other thoughts\n\n_No response_",
      "updatedAt" : 1752189261.000000000,
      "user" : "leseb",
      "userHtmlUrl" : "https://github.com/leseb",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/912735?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @raghotham @ehhuang ", "I (finally) took a deeper look into `uv` and tried it. I'll migrate my workflow to use uv, so removing conda sounds good to me!" ],
      "repository" : {
        "description" : "Composable building blocks to build Llama Apps",
        "homepage" : "https://llama-stack.readthedocs.io",
        "name" : "llama-stack",
        "fullName" : "meta-llama/llama-stack",
        "htmlUrl" : "https://github.com/meta-llama/llama-stack",
        "gitUrl" : "git://github.com/meta-llama/llama-stack.git",
        "sshUrl" : "git@github.com:meta-llama/llama-stack.git",
        "cloneUrl" : "https://github.com/meta-llama/llama-stack.git",
        "owner" : {
          "login" : "meta-llama",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1095,
        "stargazersCount" : 7904,
        "watchersCount" : 7904,
        "size" : 24835,
        "openIssuesCount" : 228,
        "subscribersCount" : 126,
        "pushedAt" : "2025-07-11T20:38:28Z",
        "languages" : {
          "TypeScript" : 223246,
          "Dockerfile" : 870,
          "Shell" : 38615,
          "CSS" : 4168,
          "JavaScript" : 474,
          "Objective-C" : 394,
          "Swift" : 15927,
          "Python" : 3475649
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to simplify building options by removing conda support, potentially replacing it with virtual environments (venv) or other options.",
      "validationOrRequirement" : "The issue requires a simplification of building options and a consideration of the growing adoption of virtual environments (venv).",
      "attemptedFixes" : "The author, leseb, is considering removing conda support and possibly discussing the removal of virtual environments (venv) in the future.",
      "otherNotes" : "The issue is about simplifying building options, specifically removing conda support, as virtual environments (venv) are gaining popularity and may be a better option.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285285
  }, {
    "issueDTO" : {
      "id" : 1981346642,
      "title" : "Improve error messages during account setup",
      "url" : "https://github.com/thunderbird/thunderbird-android/issues/7332",
      "repositoryName" : "thunderbird/thunderbird-android",
      "description" : "Currently our error messages during account setup aren't as detailed as they could and should be. \r\n\r\nWhen we're able to connect to an IMAP server, but that server returns an error message, we currently don't show it to the user. But we should.\r\n\r\nFor network errors we should provide more details (e.g. no internet connectivity, server couldn't be reached, name couldn't be resolved).",
      "updatedAt" : 1752189204.000000000,
      "user" : "cketti",
      "userHtmlUrl" : "https://github.com/cketti",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/218061?v=4",
      "labels" : [ "type: enhancement", "good first issue", "priority: low" ],
      "state" : "OPEN",
      "comments" : [ "When you work on this issue, please think about the categories of errors and how to present this to the user. We don't just want to pipe through any error message to the user. Thank you for considering!", "A good first step for this issue would be to:\n* Determine what types of errors could occur during account setup and categorize them\n* Determine what errors we could show a more pretty message about, and which ones would need the raw server message\n\n@snk-git-hub not sure if you are still interested, but if so what are your thoughts on these questions?", "Hey, someone could give me a north where this should be implemented?", "I think the more product-focused questions above would be a good first step before implementation. If you could check in on Matrix afterwards I think that will give you a quicker engineering answer :)", "Hi @joohnq, \n\nThank you for your interest in this issue!\n\nTo complete this task, we need to finish some other tasks in the In-app error notification epic first. However, as @kewisch mentioned, a great first step would be to categorize the account setup errors, and we would greatly appreciate your assistance with this.\n\nHere are the steps I would take to start identifying and categorizing the account setup errors:\n\n#### 1. Identify the Current Errors We Display\nThe first step is to identify the current errors we display and understand what may be unclear to the user. It???s crucial to ensure that the error messages are clear from the perspective of a non-power user (a user without a technical background). \n\nA good starting point would be the module `:feature:account:setup`. Here are a few key files to begin reviewing:\n- `feature/account/setup/src/main/kotlin/app/k9mail/feature/account/setup/ui/autodiscovery/AutoDiscoveryStringMapper.kt`\n- `feature/account/setup/src/main/kotlin/app/k9mail/feature/account/setup/ui/autodiscovery/AccountAutoDiscoveryViewModel.kt`\n- `feature/account/setup/src/main/kotlin/app/k9mail/feature/account/setup/ui/autodiscovery/AccountAutoDiscoveryStateMapper.kt`\n- `feature/account/setup/src/main/kotlin/app/k9mail/feature/account/setup/ui/createaccount/CreateAccountViewModel.kt`\n- `feature/account/setup/src/main/kotlin/app/k9mail/feature/account/setup/domain/usecase/GetAutoDiscovery.kt`\n- `feature/account/setup/src/main/kotlin/app/k9mail/feature/account/setup/domain/usecase/CreateAccount.kt`\n- `feature/account/setup/src/main/kotlin/app/k9mail/feature/account/setup/domain/usecase/GetSpecialFolderOptions.kt`\n\n#### 2. Understand IMAP Server Errors\nDuring account setup, we send certain IMAP commands to the server to initiate authentication, check special folders, etc. The next step is to understand these commands and identify the potential error responses they may yield. Typically, if an IMAP command fails on the server, the response begins with \"BAD\".\n\nHere are some commands we execute during setup, but this is not an exhaustive list:\n- CAPABILITY\n- AUTHENTICATE\n- ID\n- NAMESPACE\n- LIST\n\nYou can find the definitions of these commands in [RFC 3501](https://datatracker.ietf.org/doc/html/rfc3501) and [RFC 9051](https://datatracker.ietf.org/doc/html/rfc9051) (@kewisch please correct me if I'm wrong or missed any RFC).\n\n#### 3. Map IMAP Command Errors\nOnce you have identified the possible error responses from the IMAP server for the commands used during account setup, the next step is to map these errors in the application. Check to see if they have been mapped yet and provide clear reasoning for each, ideally offering a solution that can be displayed to the user.\n\n#### 4. Display the Error Message\nLastly, we need to present the error to the user. This can be done using the new (under development) `NotificationSender`, creating an `InAppNotification` related to each error, which could also be reused later if the error occurs again after the account setup. Alternatively, we could handle it directly within the `:feature:account:setup` module by managing the state outcome of the use cases.\n\nI prefer using the `NotificationSender` and `InAppNotification` as this would test the new API and allow the app to handle similar errors in the future. However, this approach depends on issues #9245 and #9312, so I am also fine with the second method.\n\n> [!IMPORTANT]\n> It's important to note that steps 3 and 4 may require guidance from both UX and UI perspectives. I would love to hear @solangevalverde???s thoughts on this.\n\n---\n\nI also think it would be beneficial to split this task into smaller tasks, such as:\n- IMAP errors categorization and identification\n- A task to handle each IMAP error identified\n\nPlease let me know if you are interested in working on this, and I will create the smaller tasks and assign them to you.", "I'll check it out and get back to you.", "Well, I???ve studied the scenarios, but I feel I don???t yet have a broad enough understanding of the app to fully cover all the cases in this issue. Maybe, when the @rafaeltonholo splits the task into smaller ones, I can contribute.", "The good news is that I have an upcoming task that covers account setup adjustments \uD83C\uDF89. \"Bad\" news is that the design would be ready by the end of next week if not sooner. Once ready, I can upload designs here unless @laurelterlesky has conflicting information \uD83D\uDC40\nps.: @Jesse-Moz this is something to keep an eye while we tackle the FTUE discovery task." ],
      "repository" : {
        "description" : "Thunderbird for Android ??? Open Source Email App for Android (fka K-9 Mail)",
        "homepage" : "https://thunderbird.net/mobile",
        "name" : "thunderbird-android",
        "fullName" : "thunderbird/thunderbird-android",
        "htmlUrl" : "https://github.com/thunderbird/thunderbird-android",
        "gitUrl" : "git://github.com/thunderbird/thunderbird-android.git",
        "sshUrl" : "git@github.com:thunderbird/thunderbird-android.git",
        "cloneUrl" : "https://github.com/thunderbird/thunderbird-android.git",
        "owner" : {
          "login" : "thunderbird",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2600,
        "stargazersCount" : 12189,
        "watchersCount" : 12189,
        "size" : 153903,
        "openIssuesCount" : 837,
        "subscribersCount" : 363,
        "pushedAt" : "2025-07-11T20:58:43Z",
        "languages" : {
          "Java" : 2129634,
          "Shell" : 15322,
          "AIDL" : 1946,
          "Kotlin" : 6539022,
          "Python" : 31547
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve error messages during account setup by providing more detailed and user-friendly error messages when connecting to an IMAP server or experiencing network errors.",
      "validationOrRequirement" : "The issue requires categorization of errors during account setup, understanding IMAP server errors, mapping IMAP command errors, and displaying the error message in a clear and user-friendly way.",
      "attemptedFixes" : "No specific attempts or fixes mentioned in the issue description or comments.",
      "otherNotes" : "The issue is related to improving error messages during account setup, and it's suggested to split the task into smaller ones, such as IMAP errors categorization and identification, and handling each IMAP error identified. The author also mentioned that UX and UI perspectives are important for steps 3 and 4.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285290
  }, {
    "issueDTO" : {
      "id" : 1291268538,
      "title" : "BruteSharkCLI will fail on pcap files when running on Ubuntu 22.04 LTS",
      "url" : "https://github.com/odedshimon/BruteShark/issues/124",
      "repositoryName" : "odedshimon/BruteShark",
      "description" : "BruteSharkCLI will fail on processing pcap files when running on the 22.04 LTS release on Ubuntu (20.04 seems to work fine):\r\n\r\n`./BruteSharkCli -i Pcap_Examples/Ftp.pcap -m Credentials -o Example`\r\n`[+] Start analyzing 1 files`\r\n`[+] Start processing file : Ftp.pcap`\r\n`ERROR: Failed to process file : Ftp.pcap`\r\n`[+] Successfully exported extracted files to: Demo/Files`\r\n`[+] BruteShark finished processing`\r\n",
      "updatedAt" : 1752189139.000000000,
      "user" : "Limpem",
      "userHtmlUrl" : "https://github.com/Limpem",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/48247481?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@Limpem \r\nThank you for reporting this.\r\n1. Are you sure you have read privileges for this file?\r\n2. Can you run it at debug mot (e.g. using VS Code) and share the exception? ", "Thank you for looking into this. To answer your questions:\r\n1. Yes (I am using the Ftp.pcap found in the examples folder)\r\n2. When I use debug-mode (./BruteSharkCli --debug) on 20.04:\r\n`Brute-Shark > add-file Ftp.pcap`\r\n`Brute-Shark > start`\r\n`[+] Packets Analyzed: 38, TCP: 38 UDP: 0`\r\n`[+] TCP Sessions Analyzed: 3 UDP Streams Analyzed: 0`\r\n`[+] Passwords Found: 1`\r\n`[+] Hashes Found: 0`\r\n`[+] Network Connections Found: 6`\r\n`Brute-Shark > show-passwords`\r\n`NetworkPassword:`\r\n`??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????`\r\n`??? Username ??? Password ??? Protocol ??? Source        ??? Destination   ???`\r\n`??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????`\r\n`??? csanders ??? echo     ??? FTP      ??? 192.168.0.114 ??? 192.168.0.193 ???`\r\n`??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????`\r\n\r\nWhen I do the same thing on 22.04:\r\n`Brute-Shark > add-file Ftp.pcap`\r\n`Brute-Shark > start`\r\n`Brute-Shark > show-passwords`\r\n`NetworkPassword:`\r\n`???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????`\r\n`??? Username ??? Password ??? Protocol ??? Source ??? Destination ???`\r\n`???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????`\r\n`???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????`\r\n\r\nSo it doesn't seem to do anything after running the start command.\r\nlibpcap is installed on both, but is seems 22.04 is using a newer version.\r\n\r\nlibpcap on 20.04:\r\nlibpcap-dev/focal,now 1.9.1-3 amd64 [installed]\r\nlibpcap0.8-dev/focal,now 1.9.1-3 amd64 [installed]\r\nlibpcap0.8/focal,now 1.9.1-3 amd64 [installed]\r\n\r\nlibpcap on 22.04:\r\nlibpcap-dev/jammy,now 1.10.1-4build1 amd64 [installed]\r\nlibpcap0.8-dev/jammy,now 1.10.1-4build1 amd64 [installed]\r\nlibpcap0.8/jammy,now 1.10.1-4build1 amd64 [installed]\r\n\r\n\r\n", "Hello\r\nWe have the same issue in Kali / Debian. It appeared with the latest version of the libc in Debian. I ran the command with strace to debug the issue.\r\nHere is the relevant part I think:\r\n```\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 53\r\nnewfstatat(53, \"\", {st_mode=S_IFREG|0644, st_size=38698, ...}, AT_EMPTY_PATH) = 0\r\nmmap(NULL, 38698, PROT_READ, MAP_PRIVATE, 53, 0) = 0x7f51f6610000\r\nclose(53)                               = 0\r\nopenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/lib/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nmunmap(0x7f51f6610000, 38698)           = 0\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 53\r\nnewfstatat(53, \"\", {st_mode=S_IFREG|0644, st_size=38698, ...}, AT_EMPTY_PATH) = 0\r\nmmap(NULL, 38698, PROT_READ, MAP_PRIVATE, 53, 0) = 0x7f51f6610000\r\nclose(53)                               = 0\r\nopenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/lib/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nmunmap(0x7f51f6610000, 38698)           = 0\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 53\r\nnewfstatat(53, \"\", {st_mode=S_IFREG|0644, st_size=38698, ...}, AT_EMPTY_PATH) = 0\r\nmmap(NULL, 38698, PROT_READ, MAP_PRIVATE, 53, 0) = 0x7f51f6610000\r\nclose(53)                               = 0\r\nopenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/lib/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nmunmap(0x7f51f6610000, 38698)           = 0\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 53\r\nnewfstatat(53, \"\", {st_mode=S_IFREG|0644, st_size=38698, ...}, AT_EMPTY_PATH) = 0\r\nmmap(NULL, 38698, PROT_READ, MAP_PRIVATE, 53, 0) = 0x7f51f6610000\r\nclose(53)                               = 0\r\nopenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/lib/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nmunmap(0x7f51f6610000, 38698)           = 0\r\nfutex(0x7f51fb7971f0, FUTEX_WAKE_PRIVATE, 2147483647) = 0\r\nmprotect(0x7f518233e000, 4096, PROT_READ|PROT_WRITE) = 0\r\nmprotect(0x7f518234f000, 4096, PROT_READ|PROT_WRITE) = 0\r\nmprotect(0x7f51822a0000, 4096, PROT_READ|PROT_WRITE) = 0\r\nmprotect(0x7f51822a0000, 4096, PROT_READ|PROT_WRITE|PROT_EXEC) = 0\r\nmprotect(0x7f518233f000, 4096, PROT_READ|PROT_WRITE) = 0\r\nmprotect(0x7f51823d0000, 4096, PROT_READ|PROT_WRITE) = 0\r\nmprotect(0x7f51823d1000, 4096, PROT_READ|PROT_WRITE) = 0\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 53\r\nnewfstatat(53, \"\", {st_mode=S_IFREG|0644, st_size=38698, ...}, AT_EMPTY_PATH) = 0\r\nmmap(NULL, 38698, PROT_READ, MAP_PRIVATE, 53, 0) = 0x7f51f6610000\r\nclose(53)                               = 0\r\nopenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/lib/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/libdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nmunmap(0x7f51f6610000, 38698)           = 0\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 53\r\nnewfstatat(53, \"\", {st_mode=S_IFREG|0644, st_size=38698, ...}, AT_EMPTY_PATH) = 0\r\nmmap(NULL, 38698, PROT_READ, MAP_PRIVATE, 53, 0) = 0x7f51f6610000\r\nclose(53)                               = 0\r\nopenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/lib/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/liblibdl.so\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nmunmap(0x7f51f6610000, 38698)           = 0\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 53\r\nnewfstatat(53, \"\", {st_mode=S_IFREG|0644, st_size=38698, ...}, AT_EMPTY_PATH) = 0\r\nmmap(NULL, 38698, PROT_READ, MAP_PRIVATE, 53, 0) = 0x7f51f6610000\r\nclose(53)                               = 0\r\nopenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/lib/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/libdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nmunmap(0x7f51f6610000, 38698)           = 0\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/brutesharkcli/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 53\r\nnewfstatat(53, \"\", {st_mode=S_IFREG|0644, st_size=38698, ...}, AT_EMPTY_PATH) = 0\r\nmmap(NULL, 38698, PROT_READ, MAP_PRIVATE, 53, 0) = 0x7f51f6610000\r\nclose(53)                               = 0\r\nopenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/lib/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nopenat(AT_FDCWD, \"/usr/lib/liblibdl\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (Aucun fichier ou dossier de ce type)\r\nmunmap(0x7f51f6610000, 38698)           = 0\r\nmprotect(0x7f51822a1000, 4096, PROT_READ|PROT_WRITE) = 0\r\nmprotect(0x7f51822a1000, 4096, PROT_READ|PROT_WRITE|PROT_EXEC) = 0\r\nwrite(1, \"\\33[39;49m\", 8)               = 8\r\nwrite(1, \"\\33[91m\", 5)                  = 5\r\nwrite(41, \"ERROR: Failed to process file : \"..., 41ERROR: Failed to process file : Ftp.pcap\r\n) = 41\r\n```\r\n\r\nbrutesharkcli is looking for libdl.so but it does not exist anymore, the libdl has been merged in the libc:\r\nhttps://sourceware.org/glibc/wiki/Release/2.34#Libraries_merged_into_libc\r\n\r\nI fixed the issue in Kali with a symlink: /usr/lib/brutesharkcli/libdl.so -> /lib/x86_64-linux-gnu/libdl.so.2\r\n", "Thank you @sbrun, @Limpem \r\nThis is very helpful.\r\nThat might be a change needed in SharpPcap[](https://github.com/dotpcap/sharppcap) - a major framework BruteShark is using.\r\nI'm currently on a vacation until mid November, I will try to investigate it when I will be back.", "Any updates on this? Still seems to be an issue on the latest version", "As @odedshimon suggested, an update in SharpPcap might be necessary. Therefore, I updated the following solution files:\r\n* BruteShark/PcapProcessor/PcapProcessor.csproj\r\n* BruteShark/PcapProcessorTest/PcapProcessorTest.csproj\r\n\r\nWhat I updated was the package reference from SharpPcap 6.0.0 to SharpPcap 6.3.0:\r\n`<PackageReference Include=\"SharpPcap\" Version=\"6.3.0\" />` \r\n\r\nUnder Linux, I was able to build the BruteSharkCli. First, I removed the BruteSharkDesktop solution (it's a Windows app) and then I ran:\r\n` dotnet publish -c Release -r linux-x64 `\r\n\r\nThat resulted in a successful build on the latest Arch Linux. The BruteSharkCli is not quitting with an error anymore:\r\n```\r\n???  /tmp ~/Software/bruteshark/BruteSharkCli -m Credentials -i ./test-dump.pcapng\r\n[+] Start analyzing 1 files\r\n[+] Start processing file : test-dump.pcapng\r\n[+] Finished processing file : test-dump.pcapng\r\n[+] BruteShark finished processing\r\n```\r\n\r\nHow could we further test my \"fix\" to implement it later into BruteShark?\r\n", "@Affenselfie \r\nThank you for validating the hypothesis about the SharpPcap version! Nice work!\r\n\r\nI need to bump the version at the source code, compile a new version and publish it as a new release.\r\nHopefuly I will get to it soon.", "> [@Affenselfie](https://github.com/Affenselfie) Thank you for validating the hypothesis about the SharpPcap version! Nice work!\n> \n> I need to bump the version at the source code, compile a new version and publish it as a new release. Hopefuly I will get to it soon.\n\nbro died" ],
      "repository" : {
        "description" : "Network Analysis Tool",
        "homepage" : "",
        "name" : "BruteShark",
        "fullName" : "odedshimon/BruteShark",
        "htmlUrl" : "https://github.com/odedshimon/BruteShark",
        "gitUrl" : "git://github.com/odedshimon/BruteShark.git",
        "sshUrl" : "git@github.com:odedshimon/BruteShark.git",
        "cloneUrl" : "https://github.com/odedshimon/BruteShark.git",
        "owner" : {
          "login" : "odedshimon",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 356,
        "stargazersCount" : 3250,
        "watchersCount" : 3250,
        "size" : 82356,
        "openIssuesCount" : 38,
        "subscribersCount" : 93,
        "pushedAt" : "2023-04-10T15:30:02Z",
        "languages" : {
          "C#" : 384343
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "BruteSharkCLI fails on Ubuntu 22.04 LTS due to the newer version of libpcap",
      "validationOrRequirement" : "The issue is present on Ubuntu 22.04 LTS and Kali. The fix is to update SharpPcap to 6.3.0 and build the BruteSharkCli on Linux.",
      "attemptedFixes" : "Symlink fix in Kali, updating SharpPcap version to 6.3.0",
      "otherNotes" : "The issue is with BruteSharkCLI failing on Ubuntu 22.04 LTS due to the newer version of libpcap. It seems that the libdl.so library is no longer available and has been merged into libc. A symlink fix was done in Kali. The issue is also present in the latest version of BruteShark. An update in SharpPcap might be necessary. The issue was fixed by updating the SharpPcap version to 6.3.0 and building the BruteSharkCli on Linux.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285298
  }, {
    "issueDTO" : {
      "id" : 2338820188,
      "title" : "[Time Picker] Reconsider use of shadow",
      "url" : "https://github.com/Esri/calcite-design-system/issues/9533",
      "repositoryName" : "Esri/calcite-design-system",
      "description" : "### Check existing issues\n\n- [X] I have [checked for existing issues](https://github.com/Esri/calcite-design-system/issues) to avoid duplicates\n\n### Description\n\nTime Picker is styled with a shadow, but Date Picker and Color Picker are not. When Time Picker is used in Input Time Picker it is currently placed inside a Popover, effectively doubling its shadow. \n![CleanShot 2024-06-03 at 11 19 13@2x (1)](https://github.com/Esri/calcite-design-system/assets/108549080/c8ca945f-e3f8-4ab7-a622-0b084af26734)\n![CleanShot 2024-06-03 at 11 19 19@2x (1)](https://github.com/Esri/calcite-design-system/assets/108549080/16ac70ae-99b4-42bb-98b2-0badda2d314b)\n\n\n### Acceptance Criteria\n\nTo align with Color Picker and Date Picker:\n- [ ] Remove shadow\n- [ ] Add 1px border using `border.3`\n- [ ] Add component token for new border\n- [ ] Set `pointer-disabled` on Popover used in Input Time Picker\n- [ ] Use component token on Time Picker to remove the double border in Input Time Picker\n- [ ] Use component tokens to round the corners of Time Picker or set Popover to clip its content\n\n[Figma reference](https://www.figma.com/design/tPVipgkKSUMpMDeL1DViHz/Template-(Copy)?node-id=301-305&m=dev&focus-id=366-34616)\n\n<img width=\"910\" height=\"754\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/47838694-8367-431a-b290-e7d9f47f1daf\" />\n\n### Relevant Info\n\n_No response_\n\n### Which Component\n\nTime Picker\n\n### Example Use Case\n\n_No response_\n\n### Priority impact\n\nimpact - p3 - not time sensitive\n\n### Calcite package\n\n- [X] @esri/calcite-components\n- [ ] @esri/calcite-components-angular\n- [ ] @esri/calcite-components-react\n- [ ] @esri/calcite-design-tokens\n- [ ] @esri/eslint-plugin-calcite-components\n\n### Esri team\n\nCalcite (design)\n\n**monday.com sync:** #9365326852",
      "updatedAt" : 1752189040.000000000,
      "user" : "ashetland",
      "userHtmlUrl" : "https://github.com/ashetland",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/108549080?v=4",
      "labels" : [ "ready for dev", "estimate - design - sm", "impact - p3 - not time sensitive", "enhancement", "monday.com sync", "visual changes", "good first issue", "p - low", "estimate - 3", "Calcite (design)", "design", "2 - in development", "calcite-components" ],
      "state" : "OPEN",
      "comments" : [ "cc  @geospatialem, @brittneytewks", "Should be paired with #9758 ", "@ashetland @jcfranco since this is adding `Add 1px border using border.3`, this should require adding a new design token for customizing the border.  \n\nDo we have a way to label issues that require a new token? Otherwise, this may get missed and need to be added later.", "Can we just use the `design-tokens` label? Seems to align with the description, but I'm not 100% sure we've been using it that way.", "I think we should define a process here. Otherwise features will be implemented without design tokens.", "> I think we should define a process here. Otherwise features will be implemented without design tokens.\n\nAgreed.\n\nAlso, I just noticed that we missed a detail in the spec. We'll need to set `pointer-disabled` on the Popover used in Input Time Picker. That will match our other inputs' dropdowns and prevent a border under the pointer:\n\n<img width=\"380\" height=\"354\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ce30630d-5152-400d-b14e-367a1a3bd0fa\" />\n\nI can add that to the figma file for posterity as well.", "Actually, because we're using Popover here, we're now also getting a double border. Do we have preferences on how to deal with this?\n\n1. Refactor Input Date Picker to not use Popover (we could match Combobox or Input Date Picker)\n2. Remove the border we just added to Time Picker (we wanted to add the border to match our other pickers)\n3. Use tokens to hide in the border in Input Time Picker (the least desirable option?)", "Why not remove the pointer tail on the popover and use any css vars applicable?\n\n Its good to reuse components when possible.", "I'm fine with that. Do we want a separate issue for those changes or can we just include them here? I can add three tasks above to add the token, turn off the pointer, and remove the double border.", "I think this issue should be fine \uD83D\uDC4D ", "Updated the criteria above. @Amretasre002762670, I also added a note to properly round the corners. Not sure if we can just have Popover clip its content or if we need to use tokens to round the corners of Time Picker. Either way, the goal is consistent floating ui styling that aligns with #9758.", "Just audited the components and it seems like both `action-menu` and `input-time-picker` use `calcite-popover`.\n\nHowever, there aren't any vars to remove the border from the `calcite-popover`.\n\nIdeally, we should be able to theme `calcite-popover` to look just like a menu if necessary. So we may need more tokens here.\n\nWhether or not we should be using `calcite-popover` for a menu, i'm not sure. We don't use the popover for other menus like for combobox, or input-date-picker. However, it might save code and promote reusability if we did use popover for those eventually. So i'm not sure if we should proceed to fix popover or remove its usage. \n\n@jcfranco what do you think?", "Installed and assigned for verification.", "@ashetland This may be too small to notice, but should the `time-picker` controls have rounded outer corners when placed inside the `popover`?\n\n<img width=\"583\" height=\"553\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2602548c-36e7-45f4-a598-87b3289f569c\" />", "Oh nice catch! I wonder if we can set `overflow: hidden;` on this `div` in Time Picker? \n\n<img width=\"1138\" height=\"588\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d029d39d-8e2a-4bcc-8084-0b6442c5eb1d\" />\n\nThis wouldn't be visible in the default Time Picker, but would be visible here when we round the corners and slot into Popover.", "@Amretasre002762670 Could you please look into this? See the two comments above for context." ],
      "repository" : {
        "description" : "A monorepo containing the packages for Esri's Calcite Design System",
        "homepage" : "https://developers.arcgis.com/calcite-design-system/",
        "name" : "calcite-design-system",
        "fullName" : "Esri/calcite-design-system",
        "htmlUrl" : "https://github.com/Esri/calcite-design-system",
        "gitUrl" : "git://github.com/Esri/calcite-design-system.git",
        "sshUrl" : "git@github.com:Esri/calcite-design-system.git",
        "cloneUrl" : "https://github.com/Esri/calcite-design-system.git",
        "owner" : {
          "login" : "Esri",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 79,
        "stargazersCount" : 324,
        "watchersCount" : 324,
        "size" : 353570,
        "openIssuesCount" : 797,
        "subscribersCount" : 248,
        "pushedAt" : "2025-07-11T23:43:00Z",
        "languages" : {
          "TypeScript" : 5777880,
          "MDX" : 3481,
          "Shell" : 5608,
          "CSS" : 3562,
          "SCSS" : 499290,
          "JavaScript" : 45742,
          "HTML" : 5951657
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to align the Time Picker with the Date Picker and Color Picker by removing the shadow, adding a 1px border, and using component tokens to remove the double border in Input Time Picker.",
      "validationOrRequirement" : "The requirements for this issue include removing the shadow, adding a 1px border, setting pointer-disabled on Popover, and using component tokens to remove the double border in Input Time Picker. The design tokens should be used to customize the border and the Popover should be used consistently for other inputs' dropdowns.",
      "attemptedFixes" : "The attempts made to fix the issue include adding a new design token for customizing the border, setting pointer-disabled on Popover, and using component tokens to remove the double border in Input Time Picker. The blockers encountered include the need for a new design token and the complexity of using Popover for other inputs' dropdowns.",
      "otherNotes" : "The issue is about reconsidering the use of shadow in Time Picker, as it is not used in Date Picker and Color Picker. The acceptance criteria include removing the shadow, adding a 1px border, setting pointer-disabled on Popover, and using component tokens to remove the double border in Input Time Picker. The issue also discusses the need for a new design token for customizing the border and whether to use Popover for other inputs' dropdowns.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285307
  }, {
    "issueDTO" : {
      "id" : 3176889734,
      "title" : "[Margin app] Add assets statistic",
      "url" : "https://github.com/djeck1432/spotnet/issues/906",
      "repositoryName" : "djeck1432/spotnet",
      "description" : "## Guideline\n1. Carefully read the issue description before applying to ensure you have all the necessary information to start working on it.\n2. Write a brief description of how you will approach the task (without using ChatGPT).\n3. Add your Telegram handler in your application (e.g., in OnlyDust or similar)\n4. Write ETA in your application\n\n\n\n## What should I do if I have a problem\n1. Try to google it before asking. Googling is taking major part of dev work \n2. If you couldn't find answer your question with Google, text your question to [dev](https://t.me/spotnet_dev/4) group with your question.\n3. Do not send DM to maintainer, it would be better and faster to ask other contributors in chat \n\n\n## How to prepare PR\n1. Check if your code [smell](https://refactoring.guru/refactoring/smells) good\n2.  Add `close #<issue number>` to link your issue with your PR\n3.  Do not commit changes which is not related to your task \n4. Check after you created PR, if you committed everything.\n\n\n## Task Description\n1. Implement CRUD methods to retrieve the data shown in the following diagram:\n\n   ![Image](https://github.com/user-attachments/assets/cb26457a-78c3-4f47-bdc6-876f4b917848)\n\nIt will be calculated by summing the token amounts across all `user_pools` and multiplying them by their current prices, as defined in [this issue](https://github.com/djeck1432/spotnet/issues/909).\n\n2. Add a new endpoint `/admin/statistic/assets` in the [`admin.py`](https://github.com/djeck1432/spotnet/blob/main/margin/margin_app/app/api/admin.py) file to expose this data.\n3. Write tests for the new endpoint, covering both positive and negative scenarios.\n4. Verify that all CI workflows pass and the endpoint functions correctly.\n",
      "updatedAt" : 1752188929.000000000,
      "user" : "CBoYXD",
      "userHtmlUrl" : "https://github.com/CBoYXD",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135316445?v=4",
      "labels" : [ "Backend", "onlydust-wave", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This issue looks like a great fit for me, I???d love to pick it up and contribute.", "Hi, I???d like to take this on. I???ll implement the /admin/statistic/assets endpoint by summing user_pool token amounts and multiplying by current prices. I???ll write full tests and ensure CI passes.\nTelegram: @mkalbani\nETA: 24 hours", "Could I try solving this?" ],
      "repository" : {
        "description" : "Spot Leveraging in the Starknet Ecosystem",
        "homepage" : "https://spotnet.xyz/",
        "name" : "spotnet",
        "fullName" : "djeck1432/spotnet",
        "htmlUrl" : "https://github.com/djeck1432/spotnet",
        "gitUrl" : "git://github.com/djeck1432/spotnet.git",
        "sshUrl" : "git@github.com:djeck1432/spotnet.git",
        "cloneUrl" : "https://github.com/djeck1432/spotnet.git",
        "owner" : {
          "login" : "djeck1432",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 223,
        "stargazersCount" : 20,
        "watchersCount" : 20,
        "size" : 32762,
        "openIssuesCount" : 7,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-06T12:20:24Z",
        "languages" : {
          "TypeScript" : 3596969,
          "Dockerfile" : 2777,
          "CSS" : 80574,
          "Shell" : 1426,
          "Cairo" : 173004,
          "Makefile" : 652,
          "JavaScript" : 224387,
          "HTML" : 2265,
          "Jupyter Notebook" : 6810,
          "Mako" : 1145,
          "Python" : 734600
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add assets statistic functionality to the margin app, including CRUD methods, a new endpoint, and tests, to retrieve data shown in a provided diagram.",
      "validationOrRequirement" : "The issue requires a thorough understanding of the provided diagram, the ability to implement CRUD methods, and the creation of a new endpoint. The contributor must also write tests and verify CI workflows. Additionally, the contributor is expected to follow the provided guideline and provide a brief description of their approach.",
      "attemptedFixes" : "The contributor has already shown interest in taking on the issue and has provided a plan for implementing the /admin/statistic/assets endpoint, writing full tests, and ensuring CI passes.",
      "otherNotes" : "The issue requires adding assets statistic, including CRUD methods, a new endpoint, and tests. It also requires verifying CI workflows and ensuring the endpoint functions correctly. The contributor is expected to follow a specific guideline and provide a brief description of their approach. They should also add their Telegram handler and write an ETA.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285314
  }, {
    "issueDTO" : {
      "id" : 1572480304,
      "title" : "Add Unit tests for CLI commands",
      "url" : "https://github.com/lingui/js-lingui/issues/1407",
      "repositoryName" : "lingui/js-lingui",
      "description" : "Currently, all the CLI commands are not covered by Unit tests. It's difficult to test these commands since it mocks the filesystem and console logs, so this leads to unexpected results and it's very hard to catch bugs during tests.\r\n\r\nSo this issue requires some refactoring of CLI in order to make it testable.\r\n\r\nView the corresponding discussion in the [Discord channel](https://discord.com/channels/974702239358783608/974704133661655060/1072097536455753808). It includes some possible ways how to solve this.\r\n\r\nCurrent coverage of the CLI package - [Codecov](https://app.codecov.io/gh/lingui/js-lingui/tree/main/packages/cli/src).",
      "updatedAt" : 1752188253.000000000,
      "user" : "andrii-bodnar",
      "userHtmlUrl" : "https://github.com/andrii-bodnar",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29282228?v=4",
      "labels" : [ "\uD83D\uDCE6 cli", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@andrii-bodnar, have you made any progress here or is this issue lingering?", "@TheWitness, a lot has changed since this issue was created, but looking at the Codecov report for the CLI package, there's still some room for improvement.", "Thanks.  I attempted to migrate an app to 5.3.2 and was having issues.  Something is structurally different. " ],
      "repository" : {
        "description" : "\uD83C\uDF0D \uD83D\uDCD6 A readable, automated, and optimized (2 kb) internationalization for JavaScript",
        "homepage" : "https://lingui.dev",
        "name" : "js-lingui",
        "fullName" : "lingui/js-lingui",
        "htmlUrl" : "https://github.com/lingui/js-lingui",
        "gitUrl" : "git://github.com/lingui/js-lingui.git",
        "sshUrl" : "git@github.com:lingui/js-lingui.git",
        "cloneUrl" : "https://github.com/lingui/js-lingui.git",
        "owner" : {
          "login" : "lingui",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 414,
        "stargazersCount" : 5236,
        "watchersCount" : 5236,
        "size" : 27644,
        "openIssuesCount" : 51,
        "subscribersCount" : 32,
        "pushedAt" : "2025-07-11T13:06:46Z",
        "languages" : {
          "TypeScript" : 625650,
          "MDX" : 42340,
          "Shell" : 69,
          "SCSS" : 9840,
          "JavaScript" : 15017,
          "Vue" : 1142
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add unit tests for CLI commands to cover all commands and make it easier to test and catch bugs.",
      "validationOrRequirement" : "The issue requires refactoring of the CLI to make it testable.",
      "attemptedFixes" : "The author of the issue, andrii-bodnar, attempted to migrate an app to 5.3.2 and was having issues, but did not provide further details.",
      "otherNotes" : "The issue description includes a link to the corresponding Discord channel discussion with possible ways to solve the issue. The Codecov report for the CLI package is also provided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285318
  }, {
    "issueDTO" : {
      "id" : 3220920902,
      "title" : "feature: nut20 - Signature on Mint Quote",
      "url" : "https://github.com/nutty-raccoon/paynet/issues/141",
      "repositoryName" : "nutty-raccoon/paynet",
      "description" : "impl [nut 20](https://cashubtc.github.io/nuts/20/) following cashu specs, on both the node and the wallet",
      "updatedAt" : 1752188031.000000000,
      "user" : "tdelabro",
      "userHtmlUrl" : "https://github.com/tdelabro",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/34384633?v=4",
      "labels" : [ "help wanted", "enhancement", "infra", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : " A privacy-preserving payment network. Enabling seamless off-chain transactions with bearer tokens backed by on-chain assets.",
        "homepage" : "",
        "name" : "paynet",
        "fullName" : "nutty-raccoon/paynet",
        "htmlUrl" : "https://github.com/nutty-raccoon/paynet",
        "gitUrl" : "git://github.com/nutty-raccoon/paynet.git",
        "sshUrl" : "git@github.com:nutty-raccoon/paynet.git",
        "cloneUrl" : "https://github.com/nutty-raccoon/paynet.git",
        "owner" : {
          "login" : "nutty-raccoon",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 27,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 2501,
        "openIssuesCount" : 13,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-12T00:56:37Z",
        "languages" : {
          "TypeScript" : 5328,
          "Dockerfile" : 6150,
          "Shell" : 2819,
          "RenderScript" : 2,
          "Rust" : 573371,
          "Cairo" : 9207,
          "JavaScript" : 1287,
          "HTML" : 323,
          "Svelte" : 44003
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "feature: nut20 - Signature on Mint Quote",
      "validationOrRequirement" : "impl [nut 20](https://cashubtc.github.io/nuts/20/) following cashu specs, on both the node and the wallet",
      "attemptedFixes" : "",
      "otherNotes" : "impl [nut 20](https://cashubtc.github.io/nuts/20/) following cashu specs, on both the node and the wallet",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285322
  }, {
    "issueDTO" : {
      "id" : 3220902548,
      "title" : "Mixed String Type Foreign Keys",
      "url" : "https://github.com/dolthub/dolt/issues/9494",
      "repositoryName" : "dolthub/dolt",
      "description" : "`char` and `varchar`, and `binary` and `varbinary` can reference each other in foreign key constraints.\n\nSkipped tests: https://github.com/dolthub/go-mysql-server/pull/3087",
      "updatedAt" : 1752187421.000000000,
      "user" : "jycor",
      "userHtmlUrl" : "https://github.com/jycor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30810879?v=4",
      "labels" : [ "correctness", "good repro", "good first issue", "sql" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Dolt ??? Git for Data",
        "homepage" : "https://www.dolthub.com",
        "name" : "dolt",
        "fullName" : "dolthub/dolt",
        "htmlUrl" : "https://github.com/dolthub/dolt",
        "gitUrl" : "git://github.com/dolthub/dolt.git",
        "sshUrl" : "git@github.com:dolthub/dolt.git",
        "cloneUrl" : "https://github.com/dolthub/dolt.git",
        "owner" : {
          "login" : "dolthub",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 568,
        "stargazersCount" : 18870,
        "watchersCount" : 18870,
        "size" : 155830,
        "openIssuesCount" : 429,
        "subscribersCount" : 116,
        "pushedAt" : "2025-07-11T23:37:55Z",
        "languages" : {
          "C#" : 8841,
          "Java" : 12609,
          "C++" : 2745,
          "C" : 4925,
          "Rust" : 1991,
          "CMake" : 591,
          "Makefile" : 3258,
          "Go" : 15461516,
          "Perl" : 3555,
          "TypeScript" : 2938,
          "Dockerfile" : 578,
          "Shell" : 2668304,
          "R" : 4965,
          "Batchfile" : 521,
          "JavaScript" : 46932,
          "PHP" : 2434,
          "Tcl" : 1569,
          "Ruby" : 2603,
          "Elixir" : 2236,
          "Python" : 11991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Mixed String Type Foreign Keys can reference each other in foreign key constraints",
      "validationOrRequirement" : "char and varchar, and binary and varbinary can reference each other in foreign key constraints",
      "attemptedFixes" : "",
      "otherNotes" : "Skipped tests: https://github.com/dolthub/go-mysql-server/pull/3087",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285324
  }, {
    "issueDTO" : {
      "id" : 3052632205,
      "title" : "Allow custom helm repository for Argo CD",
      "url" : "https://github.com/dag-andersen/argocd-diff-preview/issues/167",
      "repositoryName" : "dag-andersen/argocd-diff-preview",
      "description" : "My company uses a pull-through caching proxy for helm charts and container images. When using argocd-diff-preview, we'd prefer for it to pull the Argo CD helm chart from our proxy rather than from the Internet. Currently, the URL is hard-coded:\nhttps://github.com/dag-andersen/argocd-diff-preview/blob/main/pkg/argocd/argocd.go#L126\nWould it be possible to make the helm chart URL configurable?",
      "updatedAt" : 1752186990.000000000,
      "user" : "nhavens",
      "userHtmlUrl" : "https://github.com/nhavens",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/754908?v=4",
      "labels" : [ "feature-request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @nhavens \nSure! Can you make a PR for it? Or do you want me to do it? :) ", "I'm happy to give it a shot, but it may take me a bit. I'm not a golang expert.", "@nhavens Are you on that already? We would need that feature as well.", "@christianhuth I've not found the time to work on this feature yet. If you have time, go for it." ],
      "repository" : {
        "description" : "Tool for rendering manifest changes on pull requests.",
        "homepage" : "https://dag-andersen.github.io/argocd-diff-preview/",
        "name" : "argocd-diff-preview",
        "fullName" : "dag-andersen/argocd-diff-preview",
        "htmlUrl" : "https://github.com/dag-andersen/argocd-diff-preview",
        "gitUrl" : "git://github.com/dag-andersen/argocd-diff-preview.git",
        "sshUrl" : "git@github.com:dag-andersen/argocd-diff-preview.git",
        "cloneUrl" : "https://github.com/dag-andersen/argocd-diff-preview.git",
        "owner" : {
          "login" : "dag-andersen",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 34,
        "stargazersCount" : 329,
        "watchersCount" : 329,
        "size" : 7462,
        "openIssuesCount" : 31,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-11T16:17:20Z",
        "languages" : {
          "Dockerfile" : 1710,
          "Makefile" : 8581,
          "Go" : 252369
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow custom helm repository for Argo CD, to enable pulling the Argo CD helm chart from a company-specific proxy rather than the Internet.",
      "validationOrRequirement" : "The requirement is to make the helm chart URL configurable, possibly by allowing a custom helm repository.",
      "attemptedFixes" : "No attempted fixes mentioned in the comments, but @christianhuth expressed willingness to work on the feature if someone else takes the lead.",
      "otherNotes" : "The issue is related to a pull-through caching proxy for helm charts and container images, and the need to make the helm chart URL configurable.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285328
  }, {
    "issueDTO" : {
      "id" : 3213739367,
      "title" : "Empty string in `SET` behavior differs from MySQL",
      "url" : "https://github.com/dolthub/dolt/issues/9468",
      "repositoryName" : "dolthub/dolt",
      "description" : "In certain scenarios we don't display the empty string as part of the set, and don't properly filter for empty string.\n\nskipped tests: https://github.com/dolthub/go-mysql-server/pull/3077",
      "updatedAt" : 1752186699.000000000,
      "user" : "jycor",
      "userHtmlUrl" : "https://github.com/jycor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30810879?v=4",
      "labels" : [ "correctness", "good repro", "good first issue", "sql" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Dolt ??? Git for Data",
        "homepage" : "https://www.dolthub.com",
        "name" : "dolt",
        "fullName" : "dolthub/dolt",
        "htmlUrl" : "https://github.com/dolthub/dolt",
        "gitUrl" : "git://github.com/dolthub/dolt.git",
        "sshUrl" : "git@github.com:dolthub/dolt.git",
        "cloneUrl" : "https://github.com/dolthub/dolt.git",
        "owner" : {
          "login" : "dolthub",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 568,
        "stargazersCount" : 18870,
        "watchersCount" : 18870,
        "size" : 155830,
        "openIssuesCount" : 429,
        "subscribersCount" : 116,
        "pushedAt" : "2025-07-11T23:37:55Z",
        "languages" : {
          "C#" : 8841,
          "Java" : 12609,
          "C++" : 2745,
          "C" : 4925,
          "Rust" : 1991,
          "CMake" : 591,
          "Makefile" : 3258,
          "Go" : 15461516,
          "Perl" : 3555,
          "TypeScript" : 2938,
          "Dockerfile" : 578,
          "Shell" : 2668304,
          "R" : 4965,
          "Batchfile" : 521,
          "JavaScript" : 46932,
          "PHP" : 2434,
          "Tcl" : 1569,
          "Ruby" : 2603,
          "Elixir" : 2236,
          "Python" : 11991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "In certain scenarios, empty string in `SET` behavior differs from MySQL",
      "validationOrRequirement" : "properly filter for empty string and display as part of the set",
      "attemptedFixes" : "",
      "otherNotes" : "https://github.com/dolthub/go-mysql-server/pull/3077 skipped tests",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285331
  }, {
    "issueDTO" : {
      "id" : 1501713152,
      "title" : "Rubidum Extras Entity Invisibility on Assembled Ships",
      "url" : "https://github.com/ValkyrienSkies/Valkyrien-Skies-2/issues/270",
      "repositoryName" : "ValkyrienSkies/Valkyrien-Skies-2",
      "description" : "Rubidium Extras causes entities such as the wheel and beds to be invisible. Disabling Max Entity distance fixes this issue. \r\n![javaw_lEsx8dmMj0](https://user-images.githubusercontent.com/15059363/208278898-12156b9b-a746-4903-a745-63e6448c7268.png)\r\n",
      "updatedAt" : 1752185840.000000000,
      "user" : "flour-cpu",
      "userHtmlUrl" : "https://github.com/flour-cpu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15059363?v=4",
      "labels" : [ "forge", "good first issue", "compat" ],
      "state" : "OPEN",
      "comments" : [ "Also ran into the same thing, and disabling it also fixed it, thanks :)", "Can be fixed by using [Embeddium++](https://www.curseforge.com/minecraft/mc-mods/embeddiumplus)'s fast beds option" ],
      "repository" : {
        "description" : "Valkyrien Skies 2",
        "homepage" : "https://valkyrienskies.org/",
        "name" : "Valkyrien-Skies-2",
        "fullName" : "ValkyrienSkies/Valkyrien-Skies-2",
        "htmlUrl" : "https://github.com/ValkyrienSkies/Valkyrien-Skies-2",
        "gitUrl" : "git://github.com/ValkyrienSkies/Valkyrien-Skies-2.git",
        "sshUrl" : "git@github.com:ValkyrienSkies/Valkyrien-Skies-2.git",
        "cloneUrl" : "https://github.com/ValkyrienSkies/Valkyrien-Skies-2.git",
        "owner" : {
          "login" : "ValkyrienSkies",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 136,
        "stargazersCount" : 301,
        "watchersCount" : 301,
        "size" : 5009,
        "openIssuesCount" : 346,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-10T04:15:14Z",
        "languages" : {
          "Java" : 962892,
          "Kotlin" : 425624
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rubidium Extras causes entities to be invisible on assembled ships",
      "validationOrRequirement" : "Entities such as the wheel and beds are invisible when Rubidium Extras is enabled",
      "attemptedFixes" : "Disabling Max Entity distance",
      "otherNotes" : "The issue description includes a screenshot, and the author mentions that disabling Max Entity distance fixes the issue. A user in the comments also confirms this fix. Additionally, a potential solution is mentioned in the comments, using Embeddium++'s fast beds option.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285335
  }, {
    "issueDTO" : {
      "id" : 3163754147,
      "title" : "CoP: Data Science: Create a Networking/ Speaker Invitation Guide",
      "url" : "https://github.com/hackforla/data-science/issues/223",
      "repositoryName" : "hackforla/data-science",
      "description" : "### Overview\nWe need someone from our Community of Practice  with networking experience to write a guide for inviting in guest speakers \n\n### Action Items\n\n- [ ] A Guide, with social networking advice and techniques\n- [ ] An email template, I will help with this\n- [ ] For peer review of it, and my review\n\n\n### Resources/Instructions\nWe need resources to be gathered and put in the guide.\n\n\n",
      "updatedAt" : 1752185527.000000000,
      "user" : "chinaexpert1",
      "userHtmlUrl" : "https://github.com/chinaexpert1",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4008095?v=4",
      "labels" : [ "Guide: Create Guide", "project: missing", "role: missing", "Guide: Draft Guide", "documentation", "size: missing", "CoP: Data Science", "good first issue", "complexity: missing", "milestone: missing" ],
      "state" : "OPEN",
      "comments" : [ "Speaker topics that were suggested by the team:\n\n- [ ] Emerging trends in DS. What's new? including AI, Human Computer Interaction, what skills to learn to be competitive?\n- [ ] Data collection and preprocessing best practices\n- [ ] Data engineering and how that can be crossed with web development\n- [ ] What inspired you to pursue DS?\n- [ ] What do you know about Model Context Protocol, a protocol for ingress of data to Retrieval Augmented Generation?\n- [ ] Tell us about your personal experience with data. What data have you worked with? What part of DS are you involved in?\n- [ ] What would you tell yourself 5 years ago that would have made things easier/better for your progress?", "Update:\n\nI read two social networking guides:\n[Harvard Business Review A Beginner's Guide to Networking](https://hbr.org/2023/03/a-beginners-guide-to-networking)\n[Hubspot: The Complete Guide to Business Networking](https://blog.hubspot.com/sales/what-is-business-networking)\n\nI am going to read a little more this week and start a wiki page when we get back from break.\n\nBlockers:\n\n- [ ] I need the HfLA historical roster from Bonnie for the DS CoP so I can invite speakers that used to work here.\n\nFuture Work: \n\n- [ ] Create the guide by rereading/using those two sources and following their links\n- [ ] Create a contact list to start networking from Bonnie's roster and this list of companies and people:\n- [ ] Edit and update my LinkedIn profile\n- [ ] Start networking\n\nAsk who we know at:\n\n[1. Google]\n[2. Microsoft]\n[3. Amazon]\n[4. IBM]\n[5. Fractal Analytics]\n[6. Mu Sigma]\n[7. Accenture]\n[8. Cloudera]\n[9. Nvidia]\n[10. Airbnb]\n\nThese are the top 10 DS companies in 2025 according to reputable site.\n\nAlso mine[ this list ](https://digitaldefynd.com/IQ/famous-chief-data-officers/)for Data Officers to speak here, these are the top CDOs today.\n\nETA:\n\nAFTER RETURNING FROM JULY BREAK...\n1-2 weeks for the guide\nweek 3: peer review done\n4 weeks or less to start contacting speakers\n\nPossible:\n\n- Look at previous issue authors in DS CoP for speakers\n- Remember to offer something in return when approaching speakers" ],
      "repository" : {
        "description" : "The Hack For LA Data Science team is a Community of Practice within the LA brigade seeking to make analytical and machine learning services available to local communities and organizations.",
        "homepage" : "",
        "name" : "data-science",
        "fullName" : "hackforla/data-science",
        "htmlUrl" : "https://github.com/hackforla/data-science",
        "gitUrl" : "git://github.com/hackforla/data-science.git",
        "sshUrl" : "git@github.com:hackforla/data-science.git",
        "cloneUrl" : "https://github.com/hackforla/data-science.git",
        "owner" : {
          "login" : "hackforla",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 30,
        "watchersCount" : 30,
        "size" : 165183,
        "openIssuesCount" : 68,
        "subscribersCount" : 79,
        "pushedAt" : "2025-01-17T05:19:31Z",
        "languages" : {
          "Dockerfile" : 1933,
          "Batchfile" : 5134,
          "Makefile" : 10333,
          "Jupyter Notebook" : 34627718,
          "Python" : 167059
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a guide for inviting guest speakers in the Data Science Community of Practice with networking experience",
      "validationOrRequirement" : "The guide should include social networking advice and techniques, an email template, and a peer review process. The author needs the HfLA historical roster from Bonnie for the DS CoP to invite speakers that used to work here.",
      "attemptedFixes" : "The author has read two social networking guides and plans to read more. The author also plans to start a wiki page and create a contact list.",
      "otherNotes" : "The issue is about creating a guide for inviting guest speakers in the Data Science Community of Practice. The guide should include social networking advice and techniques, an email template, and a peer review process. The author has already read two social networking guides and plans to create a wiki page. The future work includes creating the guide, creating a contact list, editing and updating the author's LinkedIn profile, and starting networking.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285341
  }, {
    "issueDTO" : {
      "id" : 3219300089,
      "title" : "Support showing hidden values in Auth Tab",
      "url" : "https://github.com/EXXETA/trufos/issues/449",
      "repositoryName" : "EXXETA/trufos",
      "description" : "**Is your feature request related to a problem? Please describe.**\nWhen filling out secret information in the auth tab, the text is hidden. This is intended and good, however, I want to be able to show the hidden value.\n\n<img width=\"2272\" height=\"1680\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/538b5ce4-1c47-4206-a68f-6efe410c333c\" />\n\n**Describe the solution you'd like**\nHaving a button inside the password input of the `ModularForm` which toggles the value being visible or not. Maybe as an eye icon.\n\n**Describe alternatives you've considered**\n\n\n**Additional context**\n\n",
      "updatedAt" : 1752185279.000000000,
      "user" : "SoulKa",
      "userHtmlUrl" : "https://github.com/SoulKa",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15342503?v=4",
      "labels" : [ "enhancement", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I checked out the code and the suggestion in the issue. Happy to take this on if you could assign it to me. :)" ],
      "repository" : {
        "description" : "A modern, open source REST API client",
        "homepage" : "https://exxeta.github.io/trufos/",
        "name" : "trufos",
        "fullName" : "EXXETA/trufos",
        "htmlUrl" : "https://github.com/EXXETA/trufos",
        "gitUrl" : "git://github.com/EXXETA/trufos.git",
        "sshUrl" : "git@github.com:EXXETA/trufos.git",
        "cloneUrl" : "https://github.com/EXXETA/trufos.git",
        "owner" : {
          "login" : "EXXETA",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 41,
        "watchersCount" : 41,
        "size" : 5379,
        "openIssuesCount" : 32,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-11T15:22:54Z",
        "languages" : {
          "TypeScript" : 428169,
          "CSS" : 4412,
          "JavaScript" : 5800,
          "HTML" : 220
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to add a button to the password input of the ModularForm that toggles the visibility of the hidden value, possibly with an eye icon.",
      "validationOrRequirement" : "No specific validation or requirements mentioned.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "Description includes a screenshot of the auth tab, and a description of the proposed solution and alternatives considered.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285344
  }, {
    "issueDTO" : {
      "id" : 3180146176,
      "title" : "Body is deleted when sending Request",
      "url" : "https://github.com/EXXETA/trufos/issues/418",
      "repositoryName" : "EXXETA/trufos",
      "description" : "**Describe the bug**\nThe request body is being deleted when sending a request while not being in the body tab.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Open a request\n2. Write something in the body\n3. Send request and see that body does **not** disappear\n4. Change to another tab (e.g. headers)\n5. Send request\n6. Change to body tab and see that body is gone\n\n**Expected behavior**\nIt should not matter which tab is open while sending a request. Body should not disappear.\n\n**Screenshots/Video**\n\n\n**Desktop (please complete the following information):**\n - OS: macOS\n - Version v0.1.0\n\n**Additional context**\nIt's possibly due to the request body `MonacoEditor` not being rendered. I think that the request body content is read before sending the request. If the editor is not mount however, there is no body content to send --> empty request body. Should be fixable if we do only save the request body when the body tab is actually currently open or when switching away from the body tab.\n",
      "updatedAt" : 1752185181.000000000,
      "user" : "SoulKa",
      "userHtmlUrl" : "https://github.com/SoulKa",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15342503?v=4",
      "labels" : [ "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hi! @SoulKa should I try this too?", "Sure :)", "I tested the application and encountered the same issue you described. I'm using Windows, so it seems the problem occurs across all operating systems. I'm actively working on finding a solution as quickly as possible. Apologies for the delayed response.", "No worries. For a first guess of the origin of this issue you can see the **Additional context** in the issue description:\n> It's possibly due to the request body `MonacoEditor` not being rendered. I think that the request body content is read before sending the request. If the editor is not mount however, there is no body content to send --> empty request body. Should be fixable if we do only save the request body when the body tab is actually currently open or when switching away from the body tab.", "Hi @SoulKa,\nThe body content wasn???t staying when switching tabs ??? looks like the MonacoEditor was getting reset. I???ve attached a video with the solution. Kindly check and confirm if this was the exact issue you had in mind.\n\nhttps://github.com/user-attachments/assets/f3e28854-3474-4bce-afe4-ad9ab1e394eb", "@vipinsao yes that was the issue :) feel free to open a PR", "@SoulKa OK I am doing that", "Hi @SoulKa, while running the CI, I noticed an error related to SSH access, and there is one more. Kindly help me about this." ],
      "repository" : {
        "description" : "A modern, open source REST API client",
        "homepage" : "https://exxeta.github.io/trufos/",
        "name" : "trufos",
        "fullName" : "EXXETA/trufos",
        "htmlUrl" : "https://github.com/EXXETA/trufos",
        "gitUrl" : "git://github.com/EXXETA/trufos.git",
        "sshUrl" : "git@github.com:EXXETA/trufos.git",
        "cloneUrl" : "https://github.com/EXXETA/trufos.git",
        "owner" : {
          "login" : "EXXETA",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 41,
        "watchersCount" : 41,
        "size" : 5379,
        "openIssuesCount" : 32,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-11T15:22:54Z",
        "languages" : {
          "TypeScript" : 428169,
          "CSS" : 4412,
          "JavaScript" : 5800,
          "HTML" : 220
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The request body is being deleted when sending a request while not being in the body tab.",
      "validationOrRequirement" : "It should not matter which tab is open while sending a request. Body should not disappear.",
      "attemptedFixes" : "The body content wasn???t staying when switching tabs ??? looks like the MonacoEditor was getting reset. I???ve attached a video with the solution.",
      "otherNotes" : "It's possibly due to the request body `MonacoEditor` not being rendered. I think that the request body content is read before sending the request. If the editor is not mount however, there is no body content to send --> empty request body. Should be fixable if we do only save the request body when the body tab is actually currently open or when switching away from the body tab.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285350
  }, {
    "issueDTO" : {
      "id" : 3220827485,
      "title" : "[ENH] move test skip config from `tests._config` to estimator tags",
      "url" : "https://github.com/sktime/sktime/issues/8515",
      "repositoryName" : "sktime/sktime",
      "description" : "Test skip configs should be moved from `tests._config` to estimator tags.\n\nThis is a good first issue with a recipe applicable to many cases:\n\n1. pick one estimator that has an entry in `tests._config`, in `EXCLUDE_ESTIMATORS`, `EXCLUDED_TESTS`, or `EXCLUDED_TESTS_BY_TEST`\n2. remove from `EXCLUDE_ESTIMATORS` and instead add the tag `\"tests:skip_all\": True` to the estimator (see other examples)\n3. remove from `EXCLUDED_TESTS`, and instead add the tag `\"tests:skip_by_name\"` to the estimator, with value the list of skipped tests.\n4. if the estimator appears in `EXCLUDED_TESTS_BY_TEST` as well, try to fix `get_test_params` or the docstring (do not transfer this otherwise).\n\nPlease only handle a single estimator at a time, since the tests will trigger in the pull request.",
      "updatedAt" : 1752184965.000000000,
      "user" : "fkiraly",
      "userHtmlUrl" : "https://github.com/fkiraly",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7985502?v=4",
      "labels" : [ "module:tests", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A unified framework for machine learning with time series",
        "homepage" : "https://www.sktime.net",
        "name" : "sktime",
        "fullName" : "sktime/sktime",
        "htmlUrl" : "https://github.com/sktime/sktime",
        "gitUrl" : "git://github.com/sktime/sktime.git",
        "sshUrl" : "git@github.com:sktime/sktime.git",
        "cloneUrl" : "https://github.com/sktime/sktime.git",
        "owner" : {
          "login" : "sktime",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1659,
        "stargazersCount" : 9149,
        "watchersCount" : 9149,
        "size" : 83131,
        "openIssuesCount" : 1527,
        "subscribersCount" : 112,
        "pushedAt" : "2025-07-11T08:53:14Z",
        "languages" : {
          "Dockerfile" : 1942,
          "CSS" : 8789,
          "Shell" : 1823,
          "Makefile" : 3358,
          "Jupyter Notebook" : 22524,
          "MATLAB" : 4442,
          "Python" : 11501863
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Move test skip config from `tests._config` to estimator tags.",
      "validationOrRequirement" : "Pick one estimator with an entry in `tests._config`, `EXCLUDE_ESTIMATORS`, `EXCLUDED_TESTS`, or `EXCLUDED_TESTS_BY_TEST`.",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "The issue is applicable to many cases, and it's recommended to handle a single estimator at a time in the pull request.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1752285353
  } ]
}