{
  "count" : 397,
  "summaries" : [ {
    "issueDTO" : {
      "id" : 3260940396,
      "title" : "UI improvements",
      "url" : "https://github.com/langgenius/dify/issues/22930",
      "repositoryName" : "langgenius/dify",
      "description" : "### Self Checks\n\n- [x] I have read the [Contributing Guide](https://github.com/langgenius/dify/blob/main/CONTRIBUTING.md) and [Language Policy](https://github.com/langgenius/dify/issues/1542).\n- [x] I have searched for existing issues [search for existing issues](https://github.com/langgenius/dify/issues), including closed ones.\n- [x] I confirm that I am using English to submit this report, otherwise it will be closed.\n- [x] Please do not modify this template :) and fill in all the required fields.\n\n### 1. Is this request related to a challenge you're experiencing? Tell me about your story.\n\nThere's an extra divider:\n\n<img width=\"548\" height=\"129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e97abf1c-874e-4c01-a517-59e7998773c1\" />\n\nsection title is probably wrong:\n\n<img width=\"679\" height=\"579\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b65a4ca1-25e6-4e71-ade2-bf33b032c990\" />\n\n### 2. Additional context or comments\n\n_No response_\n\n### 3. Can you help us with this feature?\n\n- [ ] I am interested in contributing to this feature.",
      "updatedAt" : 1753405076.000000000,
      "user" : "DavideDelbianco",
      "userHtmlUrl" : "https://github.com/DavideDelbianco",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/37332069?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Production-ready platform for agentic workflow development.",
        "homepage" : "https://dify.ai",
        "name" : "dify",
        "fullName" : "langgenius/dify",
        "htmlUrl" : "https://github.com/langgenius/dify",
        "gitUrl" : "git://github.com/langgenius/dify.git",
        "sshUrl" : "git@github.com:langgenius/dify.git",
        "cloneUrl" : "https://github.com/langgenius/dify.git",
        "owner" : {
          "login" : "langgenius",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16463,
        "stargazersCount" : 108287,
        "watchersCount" : 108287,
        "size" : 106201,
        "openIssuesCount" : 788,
        "subscribersCount" : 660,
        "pushedAt" : "2025-07-25T00:55:09Z",
        "languages" : {
          "TypeScript" : 11963370,
          "MDX" : 889613,
          "Dockerfile" : 4231,
          "CSS" : 176931,
          "Shell" : 19844,
          "SCSS" : 21945,
          "Makefile" : 1304,
          "JavaScript" : 1430866,
          "PHP" : 6106,
          "HTML" : 102368,
          "Mako" : 518,
          "Python" : 7312026
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to make UI improvements, specifically related to a challenge the contributor is experiencing.",
      "validationOrRequirement" : "The contributor has read the contributing guide and language policy, and has searched for existing issues.",
      "attemptedFixes" : "No attempts or blockers are mentioned in the issue description.",
      "otherNotes" : "The issue is related to a story, but no additional context or comments are provided. There are two images attached, possibly showing wrong section titles.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406126
  }, {
    "issueDTO" : {
      "id" : 2275601665,
      "title" : "Casks with homepage or source issues",
      "url" : "https://github.com/Homebrew/homebrew-cask/issues/172732",
      "repositoryName" : "Homebrew/homebrew-cask",
      "description" : "Testbot will automatically comment here once issues are found in Casks. \r\nThese should be easy issues for new contributors to work on.",
      "updatedAt" : 1753405009.000000000,
      "user" : "SMillerDev",
      "userHtmlUrl" : "https://github.com/SMillerDev",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1484494?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "quodlibet source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "shattered-pixel-dungeon source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "aleph-one source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "clickup source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "lbry source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "buckets source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "biscuit source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "marvel source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "mplab-xc16 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "playcover-community source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "freeshow source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "hdfview source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "samsung-portable-ssd-t7 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "iina-plus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "google-web-designer source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "sonarr@beta source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "namechanger source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "itraffic source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "power-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "logitune source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "moom source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "openra source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "vysor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "gephi source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "prezi-video source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "sparkleshare source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "syncalicious source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "moneymoney source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "celestia source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "supertuxkart source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "cityofzion-neon source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "drawbot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "mailspring source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "jumpshare source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "safari-technology-preview source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "metarename source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "posterazor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "piezo source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "pixelorama source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "universal-media-server source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "lunarbar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "minisim source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "tenable-nessus-agent source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "soundtoys source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830", "synology-photo-station-uploader source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957984780", "keet source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8962738793", "command-tab-plus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8962738793", "synology-photo-station-uploader source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957984780\r\n\r\nThe application has been removed, or at least I couldn't find it on the download site, the closest thing that I could find is [This](https://www.synology.com/en-us/support/download/VirtualDSM?version=7.2#utilities) or [This](https://www.synology.com/en-us/support/download/DDSM?version=6.2#system)", "@Eason-S-Lu Thanks for looking into it.\r\nIf it is indeed not available any more, a PR can be opened to `disable` the cask, here's an example: https://github.com/Homebrew/homebrew-cask/pull/172410", "> samsung-portable-ssd-t7 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8957841830\r\nhttps://github.com/Homebrew/homebrew-cask/actions/runs/8957841830, I think the entire action is misconfigured, newer version of the test does not use the -s option. See https://github.com/Homebrew/homebrew-cask/actions/runs/8978228967\r\n\r\nThis commit has fixed this issue a4718d9e965d260f5739d520aac381e04ed87b5d", "touch-bar-simulator should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/8994700870", "gretl source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9040045838", "Hello, the dvdstyler seems to have a problem with the download URL :\r\n```\r\nbrew install dvdstyler\r\n==> Downloading https://downloads.sourceforge.net/dvdstyler/DVDStyler-3.2.1-MacOSX.dmg\r\ncurl: (22) The requested URL returned error: 404     \r\nhttps://downloads.sourceforge.net/dvdstyler/DVDStyler-3.2.1-MacOSX.dmg\r\n```\r\nI don't know how or what to do, but it's probably in there :\r\nhttps://github.com/Homebrew/homebrew-cask/blob/29b229ac878e6fa2e53028f9682d9f6dcc330d4b/Casks/d/dvdstyler.rb", "smart-converter-pro source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9088591766", "snipy source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9105032431", "jetbrains-gateway source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9121531766", "font-inconsolata-g source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9136243239", "get-backup-pro source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9136243239", "cardpresso source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9136243239", "font-rounded-mplus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9144085505", "quiterss source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9217240516", "touchosc-editor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9262141233", "quiterss source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9278806536", "font-genshingothic source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9295536516", "font-hanamina source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9334661753", "font-ezra-sil source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9342875566", "cleanclip source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9342875566", "parallels-access source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9342875566", "ringcentral-meetings source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9359749280", "cloud189 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9359749280", "webplotdigitizer source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9376717587", "mblock source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9393671688", "wormhole source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9410231623", "monotype source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9425131537", "jalview source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9425131537", "vivaldi@snapshot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9441127505", "confluent-cli source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9475234215", "ringcentral-meetings source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9492208269", "vapor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9557430319", "fuzzyclock source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9574669045", "ideamaker source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9590202712", "operator source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9629772329", "polypad source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9654955412", "clipgrab source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9672085240", "sameboy source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9672085240", "kstars source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9689221986", "fabfilter-volcano source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9689221986", "font-infini source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9753518102", "denemo source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9801738028", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9849478500", "font-chiayi-city source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9866693223", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9849478500", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/9849478500", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10024595767", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10024595767", "ifunbox source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10086609691", "font-jaapokki source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10190357305", "keepassxc@snapshot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10190357305", "font-jaapokki source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10190357305", "revolver-office source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10241061127", "optimage source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10276570498", "yealink-meeting source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10344488864", "graalvm-jdk@21 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10379870800", "azure-data-studio source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10413152596", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10024595767", "artisan source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10445565425", "font-lexend-deca source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10500241285", "retroactive should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10500241285", "xiami source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10518318277", "mamp source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10518318277", "retroactive should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10500241285", "metashapepro source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10534603295", "ogdesign-eagle source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10534603295", "pretzel source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10551954731", "roam source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10588575678", "sonixd should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10625266120", "todour source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10649865808", "polypad source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10649865808", "pb source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10675079349", "thedesk should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10730863399", "font-scheherazade source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10730863399", "thedesk should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10730863399", "tysimulator should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10764933202", "font-chenyuluoyan source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10858376128", "font-sans-forgetica source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10858376128", "mit-app-inventor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10913921346", "airdisplay source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/10968546029", "font-meltho source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11043908568", "sensei source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11172439198", "subsync should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11189291785", "font-hyppolit source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11246587124", "polyphone source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11265814666", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11622658696", "shadow source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11675845634", "monarch source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11714920841", "mate-translate source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11761074175", "cisdem-duplicate-finder source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11789040471", "plugdata@nightly source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11789040471", "menubar-stats source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11808887648", "font-lxgw-fasmartgothic should be archived. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11944889708", "fl-studio source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/11992036093", "jgrasp source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12001560309", "mochi source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12077530793", "bepo source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12151295297", "ava source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12171512023", "ava source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12208733716", "azure-data-studio@insiders source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12364593946", "whoozle-android-file-transfer@nightly source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12440967310", "shadow-bot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12522593291", "preference-manager source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12531360234", "mate-translate source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/12980389880", "duplicate-annihilator-for-photos source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13043875432", "scilab source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13126455628", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13191340191", "mate-translate source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13254024883", "fmail source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13350473635", "cisdem-pdf-converter-ocr source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13610781662", "xiami source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13689180882", "istherenet source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13801718060", "fmail2 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13848005328", "font-sumana source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "font-koho source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "font-radio-canada source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "font-abhaya-libre source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "font-tiro-bangla source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13868135908", "vesta source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13878582532", "xiami source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/13982745758", "nomad source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14014246153", "f-bar source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14025298437", "multimc source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14298892812", "thelowtechguys-cling source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14346995509", "ved source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14370346244", "isubtitle source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14393651740", "classroom-mode-for-minecraft source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14506088189", "infra source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14607990720", "monofocus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14806136362", "notchnook source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14816434725", "longplay source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14896676415", "wins source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/14919493587", "softraid source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15010256877", "istat-server source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15080279426", "latest source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15151482044", "infra source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15222055356", "font-bukyvede-regular source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15244264768", "longplay source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15289408479", "lo-rain source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15289408479", "firebase-admin source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15369561683", "squash source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15369561683", "bricklink-partdesigner source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15456352827", "deeper source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15480828108", "deeper source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15480828108", "soundanchor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15502841713", "db-browser-for-sqlcipher@nightly source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15548485471", "isubtitle source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15624381675", "monofocus source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15669782524", "paletro source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15769266242", "font-stix source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15769266242", "ideamaker source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15813388160", "font-fzxiaobiaosong-b05 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15813388160", "font-fzshusong-z01 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15813388160", "font-fzkai-z03 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15899954150", "pastenow source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15916104168", "polyphone source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/15961806460", "font-fzhei-b01 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16013983634", "font-fzxiaobiaosong-b05 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16063882972", "diskcatalogmaker source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16083215336", "tal-drum source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16131764584", "font-fzfangsong-z02 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16209752535", "ideamaker source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16244006102", "fmail source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16244006102", "whatsapp@beta source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16244006102", "sharemouse source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16244006102", "font-fzkai-z03 source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16255881750", "filebot source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16255881750", "soundanchor source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16255881750", "libreoffice-still-language-pack source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16359978698", "libreoffice-still source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16359978698", "sharemouse source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16383493741", "airmedia source has problems. Check https://github.com/Homebrew/homebrew-cask/actions/runs/16459366635" ],
      "repository" : {
        "description" : "\uD83C\uDF7B A CLI workflow for the administration of macOS applications distributed as binaries",
        "homepage" : "https://brew.sh",
        "name" : "homebrew-cask",
        "fullName" : "Homebrew/homebrew-cask",
        "htmlUrl" : "https://github.com/Homebrew/homebrew-cask",
        "gitUrl" : "git://github.com/Homebrew/homebrew-cask.git",
        "sshUrl" : "git@github.com:Homebrew/homebrew-cask.git",
        "cloneUrl" : "https://github.com/Homebrew/homebrew-cask.git",
        "owner" : {
          "login" : "Homebrew",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11024,
        "stargazersCount" : 21463,
        "watchersCount" : 21463,
        "size" : 385356,
        "openIssuesCount" : 25,
        "subscribersCount" : 313,
        "pushedAt" : "2025-07-25T00:58:53Z",
        "languages" : {
          "Shell" : 32255,
          "Ruby" : 6429797,
          "Python" : 14037
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to identify and fix issues with casks, ensuring they can be successfully installed and used.",
      "validationOrRequirement" : "Casks with issues in their homepages or sources, which may require validation or specific requirements to be met.",
      "attemptedFixes" : "Several casks have been attempted to be fixed by testing and validating the downloads, but some may still have issues.",
      "otherNotes" : "Casks with homepage or source issues, attempted fixes, and blockers encountered. Some casks may be archived or have issues with downloads.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406131
  }, {
    "issueDTO" : {
      "id" : 3245304443,
      "title" : "Migrate store location endpoint",
      "url" : "https://github.com/josdem/vetlog-spring-boot/issues/662",
      "repositoryName" : "josdem/vetlog-spring-boot",
      "description" : "As **a user**, I want a store geolocation endpoint **so that** I can store all pets geolocation in a walk\n\n**Acceptance Criteria**\n- Migrate current end-point [Store location](https://github.com/josdem/vetlog-spring-boot/blob/d29bee31eef883bba9fedbccca70dbfe680ba5a7/src/main/java/com/josdem/vetlog/controller/LocationController.java#L49L69)\n- The new controller should be a `@RestController`\n- I have a new `@PostMapping` end-point named `storeLocation` \n- I have a `ConcurrentHashMap` to store pets in memory\n- I have tests written in Kotlin\n- All tests passing\n- This implementation should be in this repository: [vetlog-backend](https://github.com/josdem/vetlog-beackend)",
      "updatedAt" : 1753404993.000000000,
      "user" : "josdem",
      "userHtmlUrl" : "https://github.com/josdem",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1222062?v=4",
      "labels" : [ "development", "ready for development", "backlog", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @josdem \n\"I???m not sure I totally get it, but mind if I give it a shot? I???ll ask questions if I get lost!\"", "> Hi [@josdem](https://github.com/josdem) \"I???m not sure I totally get it, but mind if I give it a shot? I???ll ask questions if I get lost!\"\n\nHi @kaminuma your collaboration is always appreciated; however, this issue is not ready for picking up yet. What is missing?\n- Create a new repository named: vetlog-backend\n- Create the inital setup to this new repository\n- Create a new release and add all issues we want to deliver\n- Add more description to this issue in order to be ready.\n\nI will let you know once it is ready for development. Thanks!", "Hi @kaminuma , this issue is ready for development, let me know if any questions.", "Hi @josdem \nThank you. I'll double check the details and get to work.", "Hi @josdem \nIf I want to pass the test for this implementation, I will have to implement a fairly wide range of issues, and it may be concluded with other issues,\nso when would be a good time to submit a PR?", "> Hi [@josdem](https://github.com/josdem) If I want to pass the test for this implementation, I will have to implement a fairly wide range of issues, and it may be concluded with other issues, so when would be a good time to submit a PR?\n\nHi @kaminuma , I appreciate it; however, let's start with the scope defined in this issue only, and we can go from there. Thanks!", "@kaminuma please ping me when this feature will be ready to review. I want to take part in this.", "Hi @josdem \nFor example, in order to test, you need to set up Gradle files, files other than the controller, related services and property files, etc., so you probably need to set those up first.\n\nHi @bestemic \nThaks???" ],
      "repository" : {
        "description" : "Maintain your pet history organized",
        "homepage" : "https://vetlog.org",
        "name" : "vetlog-spring-boot",
        "fullName" : "josdem/vetlog-spring-boot",
        "htmlUrl" : "https://github.com/josdem/vetlog-spring-boot",
        "gitUrl" : "git://github.com/josdem/vetlog-spring-boot.git",
        "sshUrl" : "git@github.com:josdem/vetlog-spring-boot.git",
        "cloneUrl" : "https://github.com/josdem/vetlog-spring-boot.git",
        "owner" : {
          "login" : "josdem",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 63,
        "stargazersCount" : 40,
        "watchersCount" : 40,
        "size" : 33151,
        "openIssuesCount" : 12,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-25T00:07:20Z",
        "languages" : {
          "Java" : 197283,
          "Dockerfile" : 980,
          "CSS" : 18698,
          "JavaScript" : 109358,
          "HTML" : 105541,
          "Kotlin" : 163665
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Migrate the store location endpoint to a new controller and implement a ConcurrentHashMap to store pets in memory.",
      "validationOrRequirement" : "Create a new repository named vetlog-backend, create initial setup, create a new release, and add more description to the issue.",
      "attemptedFixes" : "The comments mention that the issue is not ready for development yet, and that the author will let the contributors know when it's ready.",
      "otherNotes" : "The issue requires the creation of a new repository named vetlog-backend, initial setup, and a new release with all desired issues. The issue is not ready for development yet.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406136
  }, {
    "issueDTO" : {
      "id" : 3259342322,
      "title" : "Find missing games from https://quakeengines.github.io",
      "url" : "https://github.com/opengaming/osgameclones/issues/3205",
      "repositoryName" : "opengaming/osgameclones",
      "description" : "Also\n- Set up a script to scrape the site / repo and update games\n- Link to the page from OSGC",
      "updatedAt" : 1753404710.000000000,
      "user" : "cxong",
      "userHtmlUrl" : "https://github.com/cxong",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1083215?v=4",
      "labels" : [ "game-addition", "good first issue", "game-correction" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I'm new to open source and would love to work on this issue. Could you please assign it to me? \uD83D\uDE0A\n", "There are many parts to this issue and they can be done individually by separate people, feel free to call out what you want to work on in this thread so others picking it up know you are already working on it" ],
      "repository" : {
        "description" : "Open Source Clones of Popular Games",
        "homepage" : "https://osgameclones.com/",
        "name" : "osgameclones",
        "fullName" : "opengaming/osgameclones",
        "htmlUrl" : "https://github.com/opengaming/osgameclones",
        "gitUrl" : "git://github.com/opengaming/osgameclones.git",
        "sshUrl" : "git@github.com:opengaming/osgameclones.git",
        "cloneUrl" : "https://github.com/opengaming/osgameclones.git",
        "owner" : {
          "login" : "opengaming",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 325,
        "stargazersCount" : 1803,
        "watchersCount" : 1803,
        "size" : 6417,
        "openIssuesCount" : 36,
        "subscribersCount" : 62,
        "pushedAt" : "2025-07-24T10:18:25Z",
        "languages" : {
          "Dockerfile" : 476,
          "Jinja" : 11074,
          "CSS" : 11008,
          "Makefile" : 462,
          "JavaScript" : 37822,
          "HTML" : 17059,
          "Python" : 38122
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to find missing games from https://quakeengines.github.io, set up a script to scrape the site/repo and update games, and link the page from OSGC.",
      "validationOrRequirement" : "No specific validations or requirements are mentioned in the issue description or comments.",
      "attemptedFixes" : "No attempted fixes are mentioned in the issue description or comments.",
      "otherNotes" : "The issue is related to game addition and correction, and is labeled as a good first issue, indicating it's suitable for new contributors. The author is cxong and the repository is opengaming/osgameclones.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406140
  }, {
    "issueDTO" : {
      "id" : 3249614160,
      "title" : "Remove use of `@Lazy`",
      "url" : "https://github.com/hiero-ledger/hiero-mirror-node/issues/11631",
      "repositoryName" : "hiero-ledger/hiero-mirror-node",
      "description" : "### Problem\n\nSpring's `@Lazy` annotation does not work with `bootBuildImage` or with GraalVM native image.\n\n### Solution\n\n* Remove use of `@Lazy` everywhere\n* Use `ObjectProvider` wrapper around `JdbcOperations`, repositories, etc used in lazy beans to provide programmatic creation and retrieval of troublesome dependencies\n* Add `protected final NamedParameterJdbcOperations getJdbcOperations()` to `AsyncJavaMigration` that hides use of `ObjectProvider`\n\n### Alternatives\n\n_No response_",
      "updatedAt" : 1753404296.000000000,
      "user" : "steven-sheehy",
      "userHtmlUrl" : "https://github.com/steven-sheehy",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/17552371?v=4",
      "labels" : [ "importer", "enhancement", "technical debt", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello @steven-sheehy , I would like to work on this issue, can you assign me?", "Thanks, assigned!" ],
      "repository" : {
        "description" : "Hiero Mirror Node archives data from consensus nodes and serves it via an API",
        "homepage" : "",
        "name" : "hiero-mirror-node",
        "fullName" : "hiero-ledger/hiero-mirror-node",
        "htmlUrl" : "https://github.com/hiero-ledger/hiero-mirror-node",
        "gitUrl" : "git://github.com/hiero-ledger/hiero-mirror-node.git",
        "sshUrl" : "git@github.com:hiero-ledger/hiero-mirror-node.git",
        "cloneUrl" : "https://github.com/hiero-ledger/hiero-mirror-node.git",
        "owner" : {
          "login" : "hiero-ledger",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 126,
        "stargazersCount" : 171,
        "watchersCount" : 171,
        "size" : 652165,
        "openIssuesCount" : 229,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-24T23:20:25Z",
        "languages" : {
          "Java" : 12106091,
          "Dockerfile" : 12554,
          "Shell" : 98576,
          "Solidity" : 619657,
          "Gherkin" : 71940,
          "PLpgSQL" : 87384,
          "JavaScript" : 1723934,
          "Go" : 502946,
          "Mustache" : 24547,
          "Kotlin" : 4328,
          "Python" : 1445
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove the use of `@Lazy` annotation in the project, which is not compatible with `bootBuildImage` or GraalVM native image.",
      "validationOrRequirement" : "Remove use of `@Lazy` annotation and provide an alternative solution.",
      "attemptedFixes" : "Remove use of `@Lazy` everywhere, use `ObjectProvider` wrapper around `JdbcOperations`, repositories, etc used in lazy beans to provide programmatic creation and retrieval of troublesome dependencies, and add `protected final NamedParameterJdbcOperations getJdbcOperations()` to `AsyncJavaMigration` that hides use of `ObjectProvider`.",
      "otherNotes" : "The issue is related to the use of Spring's `@Lazy` annotation not working with `bootBuildImage` or GraalVM native image.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406146
  }, {
    "issueDTO" : {
      "id" : 3250793653,
      "title" : "[Task] ???????????????1.0.0.2????????????memory??????",
      "url" : "https://github.com/alibaba/spring-ai-alibaba/issues/1746",
      "repositoryName" : "alibaba/spring-ai-alibaba",
      "description" : "### Description\n\n???????????????1.0.0.2????????????memory??????\n\nmemory?????????\nhttps://github.com/alibaba/spring-ai-alibaba/tree/main/community/memories\n?????????????????????example??????\n\npr?????????????????????????????????\nhttps://github.com/springaialibaba/spring-ai-alibaba-website\n\n???????????????\n<img width=\"948\" height=\"1010\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/594a5b40-9360-4f3c-b260-a167efd6b073\" />\n\n### Task List\n\n???????????????1.0.0.2????????????memory??????",
      "updatedAt" : 1753404029.000000000,
      "user" : "SCMRCORE",
      "userHtmlUrl" : "https://github.com/SCMRCORE",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/147306064?v=4",
      "labels" : [ "kind/task", "area/docs", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Agentic AI Framework for Java Developers",
        "homepage" : "https://java2ai.com",
        "name" : "spring-ai-alibaba",
        "fullName" : "alibaba/spring-ai-alibaba",
        "htmlUrl" : "https://github.com/alibaba/spring-ai-alibaba",
        "gitUrl" : "git://github.com/alibaba/spring-ai-alibaba.git",
        "sshUrl" : "git@github.com:alibaba/spring-ai-alibaba.git",
        "cloneUrl" : "https://github.com/alibaba/spring-ai-alibaba.git",
        "owner" : {
          "login" : "alibaba",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 998,
        "stargazersCount" : 5006,
        "watchersCount" : 5006,
        "size" : 147621,
        "openIssuesCount" : 286,
        "subscribersCount" : 66,
        "pushedAt" : "2025-07-24T23:14:32Z",
        "languages" : {
          "Java" : 6218355,
          "CSS" : 26756,
          "Makefile" : 7848,
          "TeX" : 4902,
          "Vue" : 496814,
          "Mustache" : 4656,
          "HTML" : 119089,
          "TypeScript" : 536249,
          "Dockerfile" : 2057,
          "Shell" : 42951,
          "Smalltalk" : 11271,
          "Batchfile" : 3003,
          "JavaScript" : 34104,
          "Less" : 6998,
          "Python" : 3892
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add memory content to official website 1.0.0.2 version",
      "validationOrRequirement" : "add memory content to official website 1.0.0.2 version, reference example repository for memory code",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "memory code can be referenced from example repository, PR should be submitted to official website repository",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406148
  }, {
    "issueDTO" : {
      "id" : 2232161625,
      "title" : "CLI doesn't handle spaces well",
      "url" : "https://github.com/lockbook/lockbook/issues/2606",
      "repositoryName" : "lockbook/lockbook",
      "description" : "Probably the way we're invoking vim is not right and ignoring quoted arguments or something\r\n\r\nrequested by @alexwasserman",
      "updatedAt" : 1753403774.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "cli", "request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "FYI - there's already #2210, but the app seems to handle spaces in file names ok, but the CLI doesn't", "yeah I believe #2210 is from a time when the apps were discouraging spaces in their UX, but as we can't see those fields (encrypted) and people actually do want spaces (@CoreyCole & You?) in their filenames we're starting to move away from that incorrect assumption", "`\\ ` doesn't work either" ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The CLI doesn't handle spaces well and needs to be fixed.",
      "validationOrRequirement" : "The way we're invoking vim is not right and ignoring quoted arguments or something.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "There's already #2210, but the app seems to handle spaces in file names ok, but the CLI doesn't. Also, \\ doesn't work either.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406151
  }, {
    "issueDTO" : {
      "id" : 2363391037,
      "title" : "desktop support for freebsd",
      "url" : "https://github.com/lockbook/lockbook/issues/2701",
      "repositoryName" : "lockbook/lockbook",
      "description" : "Build fails:\r\n```\r\nerror[E0425]: cannot find function `init` in crate `lb_pdf`\r\n  --> libs/content/workspace/src/tab/pdf_viewer.rs:58:30\r\n   |\r\n58 |         let pdfium = lb_pdf::init(&pdfium_binary_path);\r\n   |                              ^^^^ not found in `lb_pdf`\r\n   |\r\nnote: found an item that was configured out\r\n  --> /usr/ports/deskutils/lockbook/work/lb-pdf-220d771d43d682c646e5110506224ddc7a7b1448/src/lib.rs:4:8\r\n   |\r\n4  | pub fn init(_statically_linked: &str) -> Pdfium {\r\n   |        ^^^^\r\n   = note: the item is gated behind the `apple` feature\r\nnote: found an item that was configured out\r\n  --> /usr/ports/deskutils/lockbook/work/lb-pdf-220d771d43d682c646e5110506224ddc7a7b1448/src/lib.rs:26:8\r\n   |\r\n26 | pub fn init(binary_folder: &String) -> Pdfium {\r\n   |        ^^^^\r\nnote: found an item that was configured out\r\n  --> /usr/ports/deskutils/lockbook/work/lb-pdf-220d771d43d682c646e5110506224ddc7a7b1448/src/lib.rs:33:8\r\n   |\r\n33 | pub fn init(binary_folder: &String) -> Pdfium {\r\n   |        ^^^^\r\nnote: found an item that was configured out\r\n  --> /usr/ports/deskutils/lockbook/work/lb-pdf-220d771d43d682c646e5110506224ddc7a7b1448/src/lib.rs:40:8\r\n   |\r\n40 | pub fn init(binary_folder: &String) -> Pdfium {\r\n   |        ^^^^\r\n   = note: the item is gated behind the `linux` feature\r\nnote: found an item that was configured out\r\n  --> /usr/ports/deskutils/lockbook/work/lb-pdf-220d771d43d682c646e5110506224ddc7a7b1448/src/lib.rs:47:8\r\n   |\r\n47 | pub fn init(binary_folder: &String) -> Pdfium {\r\n   |        ^^^^\r\n   = note: the item is gated behind the `android` feature\r\nhelp: consider importing one of these items\r\n   |\r\n1  + use crate::theme::visuals::init;\r\n   |\r\n1  + use lb_rs::service::log_service::init;\r\n   |\r\nhelp: if you import `init`, refer to it directly\r\n   |\r\n58 -         let pdfium = lb_pdf::init(&pdfium_binary_path);\r\n58 +         let pdfium = init(&pdfium_binary_path);\r\n   |\r\n\r\n```\r\n\r\nVersion: 0.9.3\r\nrust: 1.79.0\r\nFreeBSD 14.1\r\n",
      "updatedAt" : 1753403718.000000000,
      "user" : "yurivict",
      "userHtmlUrl" : "https://github.com/yurivict",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/271906?v=4",
      "labels" : [ "request", "egui", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @yurivict I believe we're probably 1-3 steps away from supporting FreeBSD, I'll leave a bunch of my thoughts below. I'd be happy to support whoever is interested in driving FreeBSD development for our Desktop client. Worth mentioning that we've invested a reasonable [amount of effort](https://blog.lockbook.net/cp/137878891) in our [CLI](https://github.com/lockbook/lockbook/tree/master/clients/cli) which should run on anything Rust runs on without an issue. If that's not the case let me know and we should start there.\r\n\r\nAs the compiler error suggests presently we can't compile lb-pdf, the module that drives PDF previews for our desktop clients. I can see 3 courses of action here:\r\n1. add a conditional flag for pdf support, default to off for unsupported platforms\r\n2. build pdfium for freebsd and support freebsd within lb-pdf (https://github.com/lockbook/lb-pdf/issues/6)\r\n3. overhaul how we're doing pdf previews (#2417) to have a higher quality and platform agnostic pdf implementation (render to SVG). \r\n\r\nOnce we're over that hurdle if I am interpreting [WINIT's platform chart](https://github.com/rust-windowing/winit/blob/master/FEATURES.md) our [egui-client](https://github.com/lockbook/lockbook/tree/master/clients/egui) or our dedicated [linux-client](https://github.com/lockbook/lockbook/tree/master/clients/linux) should work. Though some [trivial changes](https://github.com/lockbook/lockbook/blob/master/clients/linux/Cargo.toml#L6) may be required.\r\n\r\nIf all is successful we can add the BSD targets to our releaser automating the process of continuously delivering updates to the BSD platforms we choose to support.\r\n\r\nLooking forward to working with whoever chooses to go down this road.", "lb-pdf - what is a problem with it? Why does it fail on FreeBSD?\r\n", "lb-pdf manages the static or dynamic linking of `pdfium` the pdf library that google makes. It uses https://github.com/bblanchon/pdfium-binaries and https://github.com/paulocoutinhox/pdfium-lib for it's pdfs. They aren't shipping FreeBSD binaries. If they were we could just drop them in and expand lb-pdf. However there's a number of reasons we don't really like our current approach.\r\n\r\n#2417 outlines what I think the ultimate solution looks like." ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add desktop support for FreeBSD, which is currently failing due to the lack of pdfium binaries for the platform.",
      "validationOrRequirement" : "The issue requires the creation of FreeBSD binaries for pdfium or a new solution that does not rely on these binaries.",
      "attemptedFixes" : "Three possible courses of action are suggested: adding a conditional flag for pdf support, building pdfium for FreeBSD, or overhauling the pdf preview implementation to be more platform-agnostic.",
      "otherNotes" : "The issue is related to the lack of FreeBSD binaries for pdfium, which is used by lb-pdf. The current approach is not preferred and a new solution is being worked on in #2417.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406156
  }, {
    "issueDTO" : {
      "id" : 2611888602,
      "title" : "Add more descriptive logging for component startup failure",
      "url" : "https://github.com/dapr/dapr/issues/8236",
      "repositoryName" : "dapr/dapr",
      "description" : "<!-- If you need to report a security issue please visit https://docs.dapr.io/operations/support/support-security-issues -->\r\n\r\n## In what area(s)?\r\n\r\n<!-- Remove the '> ' to select -->\r\n\r\n> /area runtime\r\n\r\n## Describe the feature\r\nCurrently, at least in the scenario I am currently experiencing, component startup failures (when the dapr sidecar fails) do not explicitly log what component has caused the logged failure. As an example (directly taken from our own logs)\r\n\r\n```\r\ntime=\"2024-10-24T14:16:38.96601361Z\" level=info msg=\"Loading components???\"\r\ntime=\"2024-10-24T14:16:38.966165869Z\" level=debug msg=\"Loading component: kubernetes (secretstores.kubernetes/v1)\" \r\ntime=\"2024-10-24T14:16:38.966859016Z\" level=info msg=\"Component loaded: kubernetes (secretstores.kubernetes/v1)\"\r\ntime=\"2024-10-24T14:16:38.968072409Z\" level=info msg=\"Dapr is shutting down\"\r\ntime=\"2024-10-24T14:16:38.968092427Z\" level=debug msg=\"Graceful shutdown timeout: 5s\"\r\ntime=\"2024-10-24T14:16:38.968190794Z\" level=info msg=\"Shutting down component kubernetes (secretstores.kubernetes/v1)\"\r\ntime=\"2024-10-24T14:16:38.968228115Z\" level=info msg=\"Dapr runtime stopped\" \r\ntime=\"2024-10-24T14:16:38.968274223Z\" level=debug msg=\"stopping workload cert expiry watcher\"\r\ntime=\"2024-10-24T14:16:38.96829895Z\" level=fatal msg=\"Fatal error from runtime: failed to load components: rpc error: code = Unknown desc = Secret XXX not found\" \r\n```\r\nNote that this is running ver=1.13.4, I have looked through some changelogs and don't see anything that implies this has been changed in later versions, but if it has then feel free to close this obviously.\r\n\r\nAs you can see the logs do not explicitly specify which component has failed: \"kubernetes\" is marked as having loaded, but there is no followup \"loading component\" for any other component before it fails, nor does any other log name any other component that might have failed.\r\n\r\nI propose that the component responsible for the failure is added to the final \"fatal\" log, example:\r\n\r\n```Fatal error from runtime: failed to load components: Failed to load component {COMPONENT}: errormessage```\r\n\r\nor just \r\n\r\n```Fatal error from runtime: Failed to load component {COMPONENT}: errormessage```\r\n\r\n## Release Note\r\nRELEASE NOTE: More descriptive logging for component startup failures\r\n",
      "updatedAt" : 1753403563.000000000,
      "user" : "lor1113",
      "userHtmlUrl" : "https://github.com/lor1113",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15572735?v=4",
      "labels" : [ "kind/enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This looks like a great first-time issue to learn from. Could I take it on?", "/assign", "I would like to work on this issue.", "/assign", "Hey @SpiffyEight77 , you workin' on this, let me know", "> Hey @SpiffyEight77 , you workin' on this, let me know\r\n\r\nHi @RohanMishra315, I'm still working on this issue.", "Hey [SpiffyEight77](https://github.com/SpiffyEight77) still working on this?", "> Hey [SpiffyEight77](https://github.com/SpiffyEight77) still working on this?\n\nHello @adam6878 , I'm not working on this anymore. Please feel free to take it.", "/assign" ],
      "repository" : {
        "description" : "Dapr is a portable runtime for building distributed applications across cloud and edge, combining event-driven architecture with workflow orchestration.",
        "homepage" : "https://dapr.io",
        "name" : "dapr",
        "fullName" : "dapr/dapr",
        "htmlUrl" : "https://github.com/dapr/dapr",
        "gitUrl" : "git://github.com/dapr/dapr.git",
        "sshUrl" : "git@github.com:dapr/dapr.git",
        "cloneUrl" : "https://github.com/dapr/dapr.git",
        "owner" : {
          "login" : "dapr",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1983,
        "stargazersCount" : 24989,
        "watchersCount" : 24989,
        "size" : 128137,
        "openIssuesCount" : 444,
        "subscribersCount" : 421,
        "pushedAt" : "2025-07-24T22:11:47Z",
        "languages" : {
          "C#" : 20676,
          "Smarty" : 1572,
          "Java" : 17757,
          "Makefile" : 76413,
          "Go" : 9168786,
          "Mustache" : 7525,
          "Dockerfile" : 10848,
          "Shell" : 77921,
          "Bicep" : 26628,
          "Batchfile" : 1187,
          "JavaScript" : 26814,
          "PHP" : 2600,
          "Python" : 13029
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add more descriptive logging for component startup failure, specifically logging the name of the component that caused the failure.",
      "validationOrRequirement" : "The issue requires more descriptive logging for component startup failures, with the component name and error message.",
      "attemptedFixes" : "The author proposes that the component responsible for the failure is added to the final 'fatal' log, with an example of the expected log message.",
      "otherNotes" : "The issue is related to runtime and secretstores.kubernetes/v1 component, and the author has checked the changelogs and doesn't see anything that implies this has been changed in later versions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406161
  }, {
    "issueDTO" : {
      "id" : 621037277,
      "title" : "[macOS] Battery API support",
      "url" : "https://github.com/unoplatform/uno/issues/3194",
      "repositoryName" : "unoplatform/uno",
      "description" : "<!-- Please only use this template for submitting enhancement requests -->\r\n\r\n## What would you like to be added:\r\n\r\nSupport for `PowerManager`:\r\n\r\nhttps://github.com/unoplatform/uno/blob/04bcc890aa02bb15a575682ae396b936d2c14e95/src/Uno.UWP/System/Power/PowerManager.cs#L8\r\n\r\n## For contributors\r\n\r\nYou can use `IOPMPowerSource` API to achieve this, check out [this Stack Overflow answer](https://stackoverflow.com/questions/31633503/fetch-the-battery-status-of-my-macbook-with-swift)",
      "updatedAt" : 1753403550.000000000,
      "user" : "jeromelaban",
      "userHtmlUrl" : "https://github.com/jeromelaban",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5839577?v=4",
      "labels" : [ "platform/macos \uD83C\uDF4F", "stale", "project/non-ui ??????", "difficulty/starter \uD83D\uDE80", "kind/enhancement", "hacktoberfest", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey there ??? just a heads-up that this issue has been quiet for over a year. If there???s no update or comment in the next 10 days, it???ll be closed automatically. Feel free to remove the stale label or drop a note to keep it open." ],
      "repository" : {
        "description" : "Open-source platform for building cross-platform native Mobile, Web, Desktop and Embedded apps quickly.  Create rich, C#/XAML, single-codebase apps from any IDE. Hot Reload included! 90m+ NuGet Downloads!!",
        "homepage" : "https://platform.uno",
        "name" : "uno",
        "fullName" : "unoplatform/uno",
        "htmlUrl" : "https://github.com/unoplatform/uno",
        "gitUrl" : "git://github.com/unoplatform/uno.git",
        "sshUrl" : "git@github.com:unoplatform/uno.git",
        "cloneUrl" : "https://github.com/unoplatform/uno.git",
        "owner" : {
          "login" : "unoplatform",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 799,
        "stargazersCount" : 9528,
        "watchersCount" : 9528,
        "size" : 285449,
        "openIssuesCount" : 1640,
        "subscribersCount" : 198,
        "pushedAt" : "2025-07-24T22:08:34Z",
        "languages" : {
          "C#" : 55319448,
          "PowerShell" : 43798,
          "Java" : 109472,
          "CSS" : 19753,
          "Makefile" : 1162,
          "HTML" : 536,
          "TypeScript" : 271934,
          "Dockerfile" : 3263,
          "Shell" : 52978,
          "Batchfile" : 1900,
          "JavaScript" : 70437,
          "Objective-C" : 138819,
          "Python" : 1825
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for `PowerManager` on macOS, specifically the `PowerManager.cs` file.",
      "validationOrRequirement" : "Use `IOPMPowerSource` API to achieve support for `PowerManager`.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description or comments.",
      "otherNotes" : "This issue has been quiet for over a year and will be closed automatically if no update or comment is made within the next 10 days.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406164
  }, {
    "issueDTO" : {
      "id" : 3259556877,
      "title" : "socks proxy support",
      "url" : "https://github.com/containers/ramalama/issues/1740",
      "repositoryName" : "containers/ramalama",
      "description" : "### Feature request description\n\nHi. I'm trying to run ramalama from China, where most of the free internet is only accessible over a proxy. Naive attempts to invoke a proxy with all_proxy fail:\n```\n$ export all_proxy=\"socks5h://localhost:1080\"\n```\n```\n$ ramalama rag ~/test.md localhost/test.md\nConverting test.md.pdf .   2025-07-24 11:18:52.081 | ERROR    | fastembed.common.model_management:download_model:430 - Could not download model from HuggingFace: (ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')), '(Request ID: b19d6dd2-5b1f-40d3-9670-d54511639529)') Falling back to other sources.\n2025-07-24 11:18:52.081 | ERROR    | fastembed.common.model_management:download_model:452 - Could not download model from either source, sleeping for 3.0 seconds, 2 retries left.\n...\n```\n\nIt would be great to have support for a socks proxy (actually socks5h, so that the DNS queries are also proxied).\n\n### Suggest potential solution\n\n_No response_\n\n### Have you considered any alternatives?\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753403537.000000000,
      "user" : "johonan",
      "userHtmlUrl" : "https://github.com/johonan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/143036861?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Interested in opening a PR to add support? \n", "I can take a look, but I don't really have an idea how it would be done best. Perhaps if all downloads were made with curl, proxies would just work, but is it sensible to change everything to curl?", "> I can take a look, but I don't really have an idea how it would be done best. Perhaps if all downloads were made with curl, proxies would just work, but is it sensible to change everything to curl?\n\nShort answer, sadly no it is not sensible to change everything to curl...", "Googling this says that Python should be supporting ALL_PROXY out of the box with the http calls.\n", "What version of RamaLama are  you using?", "> What version of RamaLama are you using?\n\n```\n$ ramalama version\nramalama version 0.11.1\n```" ],
      "repository" : {
        "description" : "RamaLama is an open-source developer tool that simplifies the local serving of AI models from any source and facilitates their use for inference in production, all through the familiar language of containers.",
        "homepage" : "https://ramalama.ai",
        "name" : "ramalama",
        "fullName" : "containers/ramalama",
        "htmlUrl" : "https://github.com/containers/ramalama",
        "gitUrl" : "git://github.com/containers/ramalama.git",
        "sshUrl" : "git@github.com:containers/ramalama.git",
        "cloneUrl" : "https://github.com/containers/ramalama.git",
        "owner" : {
          "login" : "containers",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 222,
        "stargazersCount" : 1929,
        "watchersCount" : 1929,
        "size" : 3759,
        "openIssuesCount" : 72,
        "subscribersCount" : 30,
        "pushedAt" : "2025-07-24T23:44:27Z",
        "languages" : {
          "MDX" : 129089,
          "TypeScript" : 10702,
          "Dockerfile" : 7680,
          "Shell" : 270255,
          "CSS" : 3603,
          "Makefile" : 7694,
          "Perl" : 38574,
          "Nix" : 1640,
          "Python" : 484499
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add socks proxy support to ramalama, specifically socks5h, so that DNS queries are also proxied, allowing users to run the application from China where free internet is only accessible over a proxy.",
      "validationOrRequirement" : "The user wants to run ramalama from China with socks5h proxy support, specifically to access free internet. The issue is labeled as an enhancement and a good first issue.",
      "attemptedFixes" : "The user suggests that if all downloads were made with curl, proxies would just work, but it's not considered sensible to change everything to curl. It's also mentioned that Python should support ALL_PROXY out of the box with HTTP calls, but this is not working.",
      "otherNotes" : "The issue is about adding socks proxy support to ramalama, specifically socks5h, so that DNS queries are also proxied. The user is trying to run ramalama from China where free internet is only accessible over a proxy. The user has tried setting the all_proxy environment variable but it's not working.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406171
  }, {
    "issueDTO" : {
      "id" : 2140643224,
      "title" : "zsh tab completion refinements",
      "url" : "https://github.com/lockbook/lockbook/issues/2455",
      "repositoryName" : "lockbook/lockbook",
      "description" : "zsh tab completions insert space after folder -- annoying",
      "updatedAt" : 1753403445.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "cli", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "dupe: https://github.com/lockbook/cli-rs/issues/21" ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to refine zsh tab completions to not insert a space after a folder.",
      "validationOrRequirement" : "The requirement is to refine zsh tab completions to not insert a space after a folder.",
      "attemptedFixes" : "The issue is marked as a duplicate of #21, but no specific fixes are mentioned.",
      "otherNotes" : "The issue is about zsh tab completions inserting a space after a folder, which is considered annoying.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406174
  }, {
    "issueDTO" : {
      "id" : 2140644158,
      "title" : "stream in can't handle new files",
      "url" : "https://github.com/lockbook/lockbook/issues/2457",
      "repositoryName" : "lockbook/lockbook",
      "description" : "cannot author new file via `stream in`",
      "updatedAt" : 1753403445.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "cli", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to resolve the issue with 'stream in' not handling new files",
      "validationOrRequirement" : "Cannot author new file via 'stream in' functionality",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the 'stream in' functionality in the Lockbook repository, specifically with authoring new files.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406177
  }, {
    "issueDTO" : {
      "id" : 2140644363,
      "title" : "unmount should retry",
      "url" : "https://github.com/lockbook/lockbook/issues/2458",
      "repositoryName" : "lockbook/lockbook",
      "description" : "check if unmount succeeded",
      "updatedAt" : 1753403445.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "cli", "lbfs", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "related [#2370](https://github.com/lockbook/lockbook/issues/2370)" ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "the issue is about retrying the unmount operation",
      "validationOrRequirement" : "check if unmount succeeded",
      "attemptedFixes" : "no attempts or blockers mentioned",
      "otherNotes" : "related to issue #2370",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406179
  }, {
    "issueDTO" : {
      "id" : 2128742904,
      "title" : "nfs-utils as cli dep",
      "url" : "https://github.com/lockbook/lockbook/issues/2428",
      "repositoryName" : "lockbook/lockbook",
      "description" : "will allow linux cli people to try it if installing from a package manager",
      "updatedAt" : 1753403444.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "infra", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow Linux CLI people to try installing from a package manager",
      "validationOrRequirement" : "nfs-utils as cli dep",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the lockbook/lockbook repository and is labeled as infra and good first issue, indicating it might be suitable for new contributors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406181
  }, {
    "issueDTO" : {
      "id" : 2140643048,
      "title" : "account status refinements ",
      "url" : "https://github.com/lockbook/lockbook/issues/2454",
      "repositoryName" : "lockbook/lockbook",
      "description" : "lockbook account status bad timestamp (renews on), bad usage info",
      "updatedAt" : 1753403444.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "cli", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refine account status in Lockbook by addressing bad timestamp and usage information.",
      "validationOrRequirement" : "Requires a good understanding of the Lockbook CLI and good first issue experience.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to account status refinements in Lockbook, specifically dealing with bad timestamp and usage information.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406184
  }, {
    "issueDTO" : {
      "id" : 3237169168,
      "title" : "Allow users to visit eachothers profile through projects and launches",
      "url" : "https://github.com/ossdotnow/ossdotnow/issues/91",
      "repositoryName" : "ossdotnow/ossdotnow",
      "description" : "When a user clicks on the profile picture or username on a launch or on a project it should take them to that persons profile.\n\n<img width=\"416\" height=\"460\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/96d8a368-a16a-4646-940e-138ab59cd553\" />",
      "updatedAt" : 1753403123.000000000,
      "user" : "ahmetskilinc",
      "userHtmlUrl" : "https://github.com/ahmetskilinc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/37756565?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\uD83D\uDE4B\uD83C\uDFFB?????????", "assigned you @Spandan-Mishra ", "Hi @Spandan-Mishra it has been 4 days what is the progress?", "@ahmetskilinc I'm trying to fix my system. I'll update you by tomorrow.", "@Spandan-Mishra anything?" ],
      "repository" : {
        "description" : "Platform to connect with open source maintainers and contributors",
        "homepage" : "https://oss.now",
        "name" : "ossdotnow",
        "fullName" : "ossdotnow/ossdotnow",
        "htmlUrl" : "https://github.com/ossdotnow/ossdotnow",
        "gitUrl" : "git://github.com/ossdotnow/ossdotnow.git",
        "sshUrl" : "git@github.com:ossdotnow/ossdotnow.git",
        "cloneUrl" : "https://github.com/ossdotnow/ossdotnow.git",
        "owner" : {
          "login" : "ossdotnow",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 52,
        "stargazersCount" : 243,
        "watchersCount" : 243,
        "size" : 1252,
        "openIssuesCount" : 20,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T18:29:57Z",
        "languages" : {
          "TypeScript" : 782621,
          "CSS" : 4490,
          "PLpgSQL" : 4190,
          "JavaScript" : 4944
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow users to visit each other's profiles through projects and launches",
      "validationOrRequirement" : "no specific validations or requirements mentioned",
      "attemptedFixes" : "ahmetskilinc mentioned they're trying to fix their system, but didn't specify what the issue is",
      "otherNotes" : "A comment was left by the author after 4 days, and another comment was left by ahmetskilinc saying they're trying to fix their system and will update by tomorrow.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406187
  }, {
    "issueDTO" : {
      "id" : 3255311146,
      "title" : "[MCP] Knack",
      "url" : "https://github.com/activepieces/activepieces/issues/8472",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview\n\nKnack is a flexible, no-code database and app builder that lets users create custom objects, forms, and workflows.  \nThis integration enables AI agents and workflows to automatically trigger on data changes and manage records and files.\n\n---\n\n## ?????? Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n**Contributors based in India: please check your eligibility for receiving payments through your Stripe account before submitting, as this may affect your ability to get paid.**\n\n---\n\n## \uD83D\uDEA8 Triggers\n\n| **Trigger**            | **Use Case** |\n|------------------------|--------------|\n| **New Form Submission** | Fires when a form is submitted in a live Knack app. |\n| **New Record**         | Fires when a new record is created via API or app. |\n| **Updated Record**     | Fires when an existing record is updated. |\n| **Deleted Record**     | Fires when a record is deleted in the live app. |\n\n\n---\n\n## \uD83D\uDEE0??? Write Actions\n\n| **Action Item**       | **Use Case** |\n|------------------------|--------------|\n| **Create Record**     | Insert a new record into a specified object/table. |\n| **Update Record**     | Update fields of an existing record. |\n| **Delete Record**     | Permanently delete a record from a table. |\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Action Item**       | **Use Case** |\n|------------------------|--------------|\n| **Find Record**       | Search for a single record using field filters (e.g., email, ID). |\n\n---\n\n## \uD83D\uDCDA API Reference\n\n- [Knack API Documentation](https://docs.knack.com/reference/getting-started)\n\n---\n\n## \uD83E\uDDEA Test Account Access\n\nYou can test Knack APIs by signing up for a free account at [Knack](https://www.knack.com/).\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
      "updatedAt" : 1753403034.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "$100", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-841/mcp-knack\">AP-841 [MCP] Knack</a></p>", "/bounty $100", "## \uD83D\uDC8E $100 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8472` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8472` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @sparkybug | Jul 23, 2025, 08:15:25 AM | WIP |  |\n| \uD83D\uDFE2 @Sanket6652 | Jul 23, 2025, 09:12:26 AM | WIP |  |\n| \uD83D\uDFE2 @owuzo | Jul 23, 2025, 12:01:44 PM | #8518 | [Reward](https://algora.io/claims/qwKPpRPzgT2aPNjJ) |\n| \uD83D\uDFE2 @aryel780 | Jul 24, 2025, 09:27:23 AM | #8502 | [Reward](https://algora.io/claims/ycjsVy5jbK3ZHVgC) |\n| \uD83D\uDFE2 @krushnarout | Jul 24, 2025, 09:23:50 AM | WIP |  |", "/attempt #8472", "/attempt #8472", "/attempt #8472", "/attempt #8472", "/attempt #8472" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2245,
        "stargazersCount" : 15953,
        "watchersCount" : 15953,
        "size" : 303244,
        "openIssuesCount" : 395,
        "subscribersCount" : 99,
        "pushedAt" : "2025-07-24T23:50:49Z",
        "languages" : {
          "TypeScript" : 14822092,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 72085,
          "Shell" : 3862,
          "JavaScript" : 14477,
          "HTML" : 212991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to integrate Knack, a flexible, no-code database and app builder, with Activepieces, an open-source AI automation platform, to enable AI agents and workflows to automatically trigger on data changes and manage records and files.",
      "validationOrRequirement" : "The feature must be submitted as a Piece following the Activepieces architecture. Submissions that do not follow this format will not be accepted.",
      "attemptedFixes" : "Several attempts have been made by @sparkybug, @Sanket6652, @owuzo, @aryel780, and @krushnarout. However, no solution has been implemented yet.",
      "otherNotes" : "This integration enables AI agents and workflows to automatically trigger on data changes and manage records and files. Contributors are required to submit the feature as a Piece following the Activepieces architecture. Submissions that do not follow this format will not be accepted.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406193
  }, {
    "issueDTO" : {
      "id" : 3237190588,
      "title" : "Contributions tab overflowing on mobile in Profile page",
      "url" : "https://github.com/ossdotnow/ossdotnow/issues/95",
      "repositoryName" : "ossdotnow/ossdotnow",
      "description" : "<img width=\"430\" height=\"932\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b33d5c36-8fdc-4f4d-b111-dbef41ee2e70\" />",
      "updatedAt" : 1753403008.000000000,
      "user" : "ahmetskilinc",
      "userHtmlUrl" : "https://github.com/ahmetskilinc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/37756565?v=4",
      "labels" : [ "bug", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "???\uD83C\uDFFB", "It seems to be fine. \nCan you mention any specific device you are using?\n\n<img width=\"1352\" height=\"1438\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/affb8e68-25c3-4479-99d3-6329723d04a8\" />", "There are indeed some issue with the counts.\nThese can be fixed for mobile screens.\n\n<img width=\"1352\" height=\"210\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/12cbcd07-4c0d-432a-ad5e-d2589cb6b6bc\" />", "I have created a PR for this [here](https://github.com/ossdotnow/ossdotnow/pull/107).\n", "> It seems to be fine. \n> Can you mention any specific device you are using?\n> \n> <img width=\"1352\" height=\"1438\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/affb8e68-25c3-4479-99d3-6329723d04a8\" />\n\nit isn't necessarily the device but the length of the branch names that are doing it", "Will see to it again.", "Hey, I was not able to reproduce the issue so feel free to unassign me from this one so someone can work on it.\nThanks. " ],
      "repository" : {
        "description" : "Platform to connect with open source maintainers and contributors",
        "homepage" : "https://oss.now",
        "name" : "ossdotnow",
        "fullName" : "ossdotnow/ossdotnow",
        "htmlUrl" : "https://github.com/ossdotnow/ossdotnow",
        "gitUrl" : "git://github.com/ossdotnow/ossdotnow.git",
        "sshUrl" : "git@github.com:ossdotnow/ossdotnow.git",
        "cloneUrl" : "https://github.com/ossdotnow/ossdotnow.git",
        "owner" : {
          "login" : "ossdotnow",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 52,
        "stargazersCount" : 243,
        "watchersCount" : 243,
        "size" : 1252,
        "openIssuesCount" : 20,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T18:29:57Z",
        "languages" : {
          "TypeScript" : 782621,
          "CSS" : 4490,
          "PLpgSQL" : 4190,
          "JavaScript" : 4944
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the Contributions tab overflowing on mobile devices in the Profile page due to the length of branch names.",
      "validationOrRequirement" : "The issue is related to the length of branch names, which is causing the Contributions tab to overflow on mobile devices in the Profile page.",
      "attemptedFixes" : "A PR has been created for this issue, but the author was unable to reproduce the issue and unassigned themselves from the issue.",
      "otherNotes" : "The issue is related to the length of branch names, not the device. A PR has been created for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406197
  }, {
    "issueDTO" : {
      "id" : 3237178817,
      "title" : "Allow users to edit projects that they are an owner of",
      "url" : "https://github.com/ossdotnow/ossdotnow/issues/93",
      "repositoryName" : "ossdotnow/ossdotnow",
      "description" : "Right now a user cannot edit a project once it is submitted. We should allow the owner of the project to be able to edit a project.",
      "updatedAt" : 1753402981.000000000,
      "user" : "ahmetskilinc",
      "userHtmlUrl" : "https://github.com/ahmetskilinc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/37756565?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "mine", "i guess hemanth-1321 stole this from me smh\nfair play", "@0ni-x4 take it" ],
      "repository" : {
        "description" : "Platform to connect with open source maintainers and contributors",
        "homepage" : "https://oss.now",
        "name" : "ossdotnow",
        "fullName" : "ossdotnow/ossdotnow",
        "htmlUrl" : "https://github.com/ossdotnow/ossdotnow",
        "gitUrl" : "git://github.com/ossdotnow/ossdotnow.git",
        "sshUrl" : "git@github.com:ossdotnow/ossdotnow.git",
        "cloneUrl" : "https://github.com/ossdotnow/ossdotnow.git",
        "owner" : {
          "login" : "ossdotnow",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 52,
        "stargazersCount" : 243,
        "watchersCount" : 243,
        "size" : 1252,
        "openIssuesCount" : 20,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T18:29:57Z",
        "languages" : {
          "TypeScript" : 782621,
          "CSS" : 4490,
          "PLpgSQL" : 4190,
          "JavaScript" : 4944
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow users to edit projects that they are an owner of, enabling project owners to make changes to their projects after submission.",
      "validationOrRequirement" : "None mentioned, but the issue is labeled as an enhancement and good first issue.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "Issue description includes a comment about a user feeling their idea was stolen and a mention of @0ni-x4 taking over the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406201
  }, {
    "issueDTO" : {
      "id" : 898817034,
      "title" : "Support secure DNS",
      "url" : "https://github.com/TrackerControl/tracker-control-android/issues/201",
      "repositoryName" : "TrackerControl/tracker-control-android",
      "description" : "At the moment, you can set custom DNS in the application, but it's IP-based. It would be great to be able to specify a DoH or DoT endpoint.",
      "updatedAt" : 1753402846.000000000,
      "user" : "laurentlbm",
      "userHtmlUrl" : "https://github.com/laurentlbm",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1180863?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "You already can set up Nebulo with TrackerControl, and thereby get secure DNS. :)", "Use the port forwarding functionality. The set-up is similar as for NetGuard.", "Thanks, that works great. I had never heard of Nebulo before.", "Try Invizible with Tracker control for DoH. It superb ", "After I learned that one has to turn off private (encrypted DoT/DoH) DNS to be able to use TrackerControl, I was slightly bummed. It feels like getting one privacy improvement by giving up another. I want to have both. That's how I found this topic.\r\n\r\nYes, using [Nebulo](https://git.frostnerd.com/PublicAndroidApps/smokescreen) seems to work: Now I can use encrypted DNS _and_ TrackerControl at the same time. For those coming here and wondering _how_ to do this: I followed [this article](https://git.frostnerd.com/PublicAndroidApps/smokescreen/-/blob/master/docs/NONVPNMODE.md). Use the guide for NetGuard; the setup is identical.\r\n\r\nI'm still of the opinion that this situation is not ideal. TrackerControl is a simple tool for non-techy people who want to improve their privacy. They're not going to follow GitHub issues and daisy-chain apps by port-forwarding TrackerControl back to their local device.\r\n\r\nIs there a way to integrate this \"Nebulo trick\" into TrackerControl or somehow enable a private encrypted DNS solution to make this easier for the non-techy user? At least IMO the user should be informed what the consequence of giving up private DNS is and maybe be pointed to this workaround.", "I agree it's not ideal. I've been considering implementing a simpler setup of the port forwarding, and would appreciate help with this.", "I have the same setup running with TrackerControl and port forwarding DNS traffic into Nebulo so I can use DoT. \r\nNow I had to disable monitoring for my browser app, as it is not working (also stated within TC that you have to disable it for browsers to work) and ran into the issue that DNS queries from said browser would not get routed into Nebulo. As I understand the port forwarding is only applied to monitored apps and traffic from non monitored apps is just passed through. Is that correct? Is there any way to apply port forwarding to all traffic that passes through TC?", "> Is that correct?\r\n\r\nThat is an interesting find!\r\n\r\nI did a quick test with my browser _not_ monitored through TrackerControl. You're right, the DNS specified in Nebulo won't be used in this case. That's another bummer.\r\n\r\nOn the other hand:\r\nI did a second quick test. This time I had TrackerControl monitor my browser. Now the secure DNS is used as expected. I do not experience any drawbacks. My browser app is still working fine. Therefore: Why not just leave it that way?\r\n\r\n", "Because for me it does not work like that. When I have monitoring activated for my browser and try to access reddit.com for example the site won't load. Looking into the traffic log I can see that e.reddit.com was blocked. Though it isn't mentioned in the monitoring page of the browser. ", "> I have the same setup running with TrackerControl and port forwarding DNS traffic into Nebulo so I can use DoT. Now I had to disable monitoring for my browser app, as it is not working (also stated within TC that you have to disable it for browsers to work) and ran into the issue that DNS queries from said browser would not get routed into Nebulo. As I understand the port forwarding is only applied to monitored apps and traffic from non monitored apps is just passed through. Is that correct? Is there any way to apply port forwarding to all traffic that passes through TC?\r\n\r\nYou can still use TC with the browser, just turn off any blocking and you'll get the same behavior, but with DNS requests routed through TC.\r\n\r\nI use dnscrypt+invizible pro, works like a charm.", "Please support secure DNS natively for easy setup.\nSecure DNS is a must for privacy when the user is travelling and uses public Wifi.", "I have to use a VPN but this disables TC and vice versa. " ],
      "repository" : {
        "description" : "TrackerControl Android: monitor and control trackers and ads.",
        "homepage" : "https://trackercontrol.org/",
        "name" : "tracker-control-android",
        "fullName" : "TrackerControl/tracker-control-android",
        "htmlUrl" : "https://github.com/TrackerControl/tracker-control-android",
        "gitUrl" : "git://github.com/TrackerControl/tracker-control-android.git",
        "sshUrl" : "git@github.com:TrackerControl/tracker-control-android.git",
        "cloneUrl" : "https://github.com/TrackerControl/tracker-control-android.git",
        "owner" : {
          "login" : "TrackerControl",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 91,
        "stargazersCount" : 2177,
        "watchersCount" : 2177,
        "size" : 26648,
        "openIssuesCount" : 122,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-11T10:56:54Z",
        "languages" : {
          "Java" : 662909,
          "C" : 208878,
          "CMake" : 707,
          "TeX" : 11275,
          "SCSS" : 380,
          "HTML" : 2126
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement native support for secure DNS (DoH or DoT) in TrackerControl, allowing users to easily set up and use secure DNS without requiring additional apps or workarounds.",
      "validationOrRequirement" : "Support for secure DNS (DoH or DoT) should be native and easy to set up, without requiring additional apps or workarounds.",
      "attemptedFixes" : "Port forwarding and disabling monitoring for some apps, but users still encounter issues with blocking and routing DNS queries.",
      "otherNotes" : "TrackerControl can be used with Nebulo for secure DNS, but requires port forwarding and disabling monitoring for some apps. Some users have reported issues with blocking and routing DNS queries.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406205
  }, {
    "issueDTO" : {
      "id" : 2838018084,
      "title" : "Using vllm runtime generates \"unrecognized arguments\" error",
      "url" : "https://github.com/containers/ramalama/issues/758",
      "repositoryName" : "containers/ramalama",
      "description" : "An attempt to use `vllm` runtime generates the following error:\n```\nerror: unrecognized arguments: llama-run -c 2048 --temp 0.8 -v --ngl 999 /mnt/models/model.file\n```\n\nFull log:\n```\n$ ramalama --debug --runtime vllm run llama3.2\nexec_cmd:  podman run --rm -i --label RAMALAMA --security-opt=label=disable --name ramalama_PNB6UFIqIM --pull=newer -t --device /dev/dri --device nvidia.com/gpu=all -e CUDA_VISIBLE_DEVICES=0 --mount=type=bind,src=/home/dw/.local/share/ramalama/models/ollama/llama3.2:latest,destination=/mnt/models/model.file,ro quay.io/modh/vllm:rhoai-2.17-cuda llama-run -c 2048 --temp 0.8 -v --ngl 999 /mnt/models/model.file\nusage: __main__.py [-h] [--host HOST] [--port PORT] [--uvicorn-log-level {debug,info,warning,error,critical,trace}] [--allow-credentials] [--allowed-origins ALLOWED_ORIGINS] [--allowed-methods ALLOWED_METHODS]\n                   [--allowed-headers ALLOWED_HEADERS] [--api-key API_KEY] [--lora-modules LORA_MODULES [LORA_MODULES ...]] [--prompt-adapters PROMPT_ADAPTERS [PROMPT_ADAPTERS ...]] [--chat-template CHAT_TEMPLATE]\n                   [--chat-template-content-format {auto,string,openai}] [--response-role RESPONSE_ROLE] [--ssl-keyfile SSL_KEYFILE] [--ssl-certfile SSL_CERTFILE] [--ssl-ca-certs SSL_CA_CERTS] [--ssl-cert-reqs SSL_CERT_REQS]\n                   [--root-path ROOT_PATH] [--middleware MIDDLEWARE] [--return-tokens-as-token-ids] [--disable-frontend-multiprocessing] [--enable-request-id-headers] [--enable-auto-tool-choice]\n                   [--tool-call-parser {granite-20b-fc,granite,hermes,internlm,jamba,llama3_json,mistral,pythonic} or name registered in --tool-parser-plugin] [--tool-parser-plugin TOOL_PARSER_PLUGIN] [--model MODEL]\n                   [--task {auto,generate,embedding,embed,classify,score,reward}] [--tokenizer TOKENIZER] [--skip-tokenizer-init] [--revision REVISION] [--code-revision CODE_REVISION] [--tokenizer-revision TOKENIZER_REVISION]\n                   [--tokenizer-mode {auto,slow,mistral}] [--trust-remote-code] [--allowed-local-media-path ALLOWED_LOCAL_MEDIA_PATH] [--download-dir DOWNLOAD_DIR]\n                   [--load-format {auto,pt,safetensors,npcache,dummy,tensorizer,sharded_state,gguf,bitsandbytes,mistral,runai_streamer}] [--config-format {auto,hf,mistral}] [--dtype {auto,half,float16,bfloat16,float,float32}]\n                   [--kv-cache-dtype {auto,fp8,fp8_e5m2,fp8_e4m3}] [--quantization-param-path QUANTIZATION_PARAM_PATH] [--max-model-len MAX_MODEL_LEN] [--guided-decoding-backend {outlines,lm-format-enforcer,xgrammar}]\n                   [--logits-processor-pattern LOGITS_PROCESSOR_PATTERN] [--distributed-executor-backend {ray,mp}] [--worker-use-ray] [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE] [--tensor-parallel-size TENSOR_PARALLEL_SIZE]\n                   [--max-parallel-loading-workers MAX_PARALLEL_LOADING_WORKERS] [--ray-workers-use-nsight] [--block-size {8,16,32,64,128}] [--enable-prefix-caching | --no-enable-prefix-caching] [--disable-sliding-window]\n                   [--use-v2-block-manager] [--num-lookahead-slots NUM_LOOKAHEAD_SLOTS] [--seed SEED] [--swap-space SWAP_SPACE] [--cpu-offload-gb CPU_OFFLOAD_GB] [--gpu-memory-utilization GPU_MEMORY_UTILIZATION]\n                   [--num-gpu-blocks-override NUM_GPU_BLOCKS_OVERRIDE] [--max-num-batched-tokens MAX_NUM_BATCHED_TOKENS] [--max-num-seqs MAX_NUM_SEQS] [--max-logprobs MAX_LOGPROBS] [--disable-log-stats]\n                   [--quantization {aqlm,awq,deepspeedfp,tpu_int8,fp8,fbgemm_fp8,modelopt,marlin,gguf,gptq_marlin_24,gptq_marlin,awq_marlin,gptq,compressed-tensors,bitsandbytes,qqq,hqq,experts_int8,neuron_quant,ipex,None}]\n                   [--rope-scaling ROPE_SCALING] [--rope-theta ROPE_THETA] [--hf-overrides HF_OVERRIDES] [--enforce-eager] [--max-seq-len-to-capture MAX_SEQ_LEN_TO_CAPTURE] [--disable-custom-all-reduce]\n                   [--tokenizer-pool-size TOKENIZER_POOL_SIZE] [--tokenizer-pool-type TOKENIZER_POOL_TYPE] [--tokenizer-pool-extra-config TOKENIZER_POOL_EXTRA_CONFIG] [--limit-mm-per-prompt LIMIT_MM_PER_PROMPT]\n                   [--mm-processor-kwargs MM_PROCESSOR_KWARGS] [--disable-mm-preprocessor-cache] [--enable-lora] [--enable-lora-bias] [--max-loras MAX_LORAS] [--max-lora-rank MAX_LORA_RANK]\n                   [--lora-extra-vocab-size LORA_EXTRA_VOCAB_SIZE] [--lora-dtype {auto,float16,bfloat16}] [--long-lora-scaling-factors LONG_LORA_SCALING_FACTORS] [--max-cpu-loras MAX_CPU_LORAS] [--fully-sharded-loras]\n                   [--enable-prompt-adapter] [--max-prompt-adapters MAX_PROMPT_ADAPTERS] [--max-prompt-adapter-token MAX_PROMPT_ADAPTER_TOKEN] [--device {auto,cuda,neuron,cpu,openvino,tpu,xpu,hpu}]\n                   [--num-scheduler-steps NUM_SCHEDULER_STEPS] [--multi-step-stream-outputs [MULTI_STEP_STREAM_OUTPUTS]] [--scheduler-delay-factor SCHEDULER_DELAY_FACTOR] [--enable-chunked-prefill [ENABLE_CHUNKED_PREFILL]]\n                   [--speculative-model SPECULATIVE_MODEL]\n                   [--speculative-model-quantization {aqlm,awq,deepspeedfp,tpu_int8,fp8,fbgemm_fp8,modelopt,marlin,gguf,gptq_marlin_24,gptq_marlin,awq_marlin,gptq,compressed-tensors,bitsandbytes,qqq,hqq,experts_int8,neuron_quant,ipex,None}]\n                   [--num-speculative-tokens NUM_SPECULATIVE_TOKENS] [--speculative-disable-mqa-scorer] [--speculative-draft-tensor-parallel-size SPECULATIVE_DRAFT_TENSOR_PARALLEL_SIZE]\n                   [--speculative-max-model-len SPECULATIVE_MAX_MODEL_LEN] [--speculative-disable-by-batch-size SPECULATIVE_DISABLE_BY_BATCH_SIZE] [--ngram-prompt-lookup-max NGRAM_PROMPT_LOOKUP_MAX]\n                   [--ngram-prompt-lookup-min NGRAM_PROMPT_LOOKUP_MIN] [--spec-decoding-acceptance-method {rejection_sampler,typical_acceptance_sampler}]\n                   [--typical-acceptance-sampler-posterior-threshold TYPICAL_ACCEPTANCE_SAMPLER_POSTERIOR_THRESHOLD] [--typical-acceptance-sampler-posterior-alpha TYPICAL_ACCEPTANCE_SAMPLER_POSTERIOR_ALPHA]\n                   [--disable-logprobs-during-spec-decoding [DISABLE_LOGPROBS_DURING_SPEC_DECODING]] [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG] [--ignore-patterns IGNORE_PATTERNS] [--preemption-mode PREEMPTION_MODE]\n                   [--served-model-name SERVED_MODEL_NAME [SERVED_MODEL_NAME ...]] [--qlora-adapter-name-or-path QLORA_ADAPTER_NAME_OR_PATH] [--otlp-traces-endpoint OTLP_TRACES_ENDPOINT]\n                   [--collect-detailed-traces COLLECT_DETAILED_TRACES] [--disable-async-output-proc] [--scheduling-policy {fcfs,priority}] [--override-neuron-config OVERRIDE_NEURON_CONFIG]\n                   [--override-pooler-config OVERRIDE_POOLER_CONFIG] [--compilation-config COMPILATION_CONFIG] [--kv-transfer-config KV_TRANSFER_CONFIG] [--worker-cls WORKER_CLS] [--generation-config GENERATION_CONFIG]\n                   [--disable-log-requests] [--max-log-len MAX_LOG_LEN] [--disable-fastapi-docs] [--enable-prompt-tokens-details] [--model-name MODEL_NAME] [--max-sequence-length MAX_SEQUENCE_LENGTH] [--max-new-tokens MAX_NEW_TOKENS]\n                   [--max-batch-size MAX_BATCH_SIZE] [--max-concurrent-requests MAX_CONCURRENT_REQUESTS] [--dtype-str DTYPE_STR] [--quantize {awq,gptq,squeezellm,None}] [--num-gpus NUM_GPUS] [--num-shard NUM_SHARD]\n                   [--output-special-tokens OUTPUT_SPECIAL_TOKENS] [--default-include-stop-seqs DEFAULT_INCLUDE_STOP_SEQS] [--grpc-port GRPC_PORT] [--tls-cert-path TLS_CERT_PATH] [--tls-key-path TLS_KEY_PATH]\n                   [--tls-client-ca-cert-path TLS_CLIENT_CA_CERT_PATH] [--adapter-cache ADAPTER_CACHE] [--prefix-store-path PREFIX_STORE_PATH] [--speculator-name SPECULATOR_NAME] [--speculator-n-candidates SPECULATOR_N_CANDIDATES]\n                   [--speculator-max-batch-size SPECULATOR_MAX_BATCH_SIZE] [--enable-vllm-log-requests ENABLE_VLLM_LOG_REQUESTS] [--disable-prompt-logprobs DISABLE_PROMPT_LOGPROBS]\n__main__.py: error: unrecognized arguments: llama-run -c 2048 --temp 0.8 -v --ngl 999 /mnt/models/model.file\n```\n```\n$ rpm -qv podman\npodman-5.3.1-1.fc41.x86_64\n```\n```\n$ rpm -qv python3-ramalama\npython3-ramalama-0.5.5-1.fc41.noarch\n```\n```\n$ rpm -qv golang-github-nvidia-container-toolkit\ngolang-github-nvidia-container-toolkit-1.16.2-1.fc41.x86_64\n```\n```\n$ nvidia-ctk cdi list\nINFO[0000] Found 3 CDI devices                          \nnvidia.com/gpu=0\nnvidia.com/gpu=GPU-9282fe1f-02bd-d793-11a8-5341a0858e3b\nnvidia.com/gpu=all\n```",
      "updatedAt" : 1753402719.000000000,
      "user" : "dwrobel",
      "userHtmlUrl" : "https://github.com/dwrobel",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/228873?v=4",
      "labels" : [ "stale-issue", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Yes vllm can only do serve at this point.", "Not even sure how well that works either.", "It works for me. I installed ramalama from the latest source code.\n\n$ rpm -q podman\npodman-5.3.1-1.fc41.x86_64\n\n$ ramalama version\nramalama version 0.7.5\n\n```\n$  ramalama --debug --runtime vllm run llama3.2\nexec_cmd:  podman run --rm --label ai.ramalama.model=llama3.2 --label ai.ramalama.engine=podman --label ai.ramalama.runtime=vllm --label ai.ramalama.command=run --device /dev/dri --network none --security-opt=label=disable --cap-drop=all --security-opt=no-new-privileges --pull newer --env \"LLAMA_PROMPT_PREFIX=\uD83E\uDDAD > \" -t -i --label ai.ramalama --name ramalama_nYEXaTkuU6 --env=HOME=/tmp --init --label ai.ramalama.model=llama3.2 --label ai.ramalama.engine=podman --label ai.ramalama.runtime=vllm --label ai.ramalama.command=run --mount=type=bind,src=/home/zguo/.local/share/ramalama/store/ollama/llama3.2/llama3.2/blobs/sha256-dde5aa3fc5ffc17176b5e8bdc82f587b24b2678c6c66101bf7da77af9f7ccdff,destination=/mnt/models/model.file,ro --mount=type=bind,src=/home/zguo/.local/share/ramalama/store/ollama/llama3.2/llama3.2/snapshots/sha256-dde5aa3fc5ffc17176b5e8bdc82f587b24b2678c6c66101bf7da77af9f7ccdff/chat_template,destination=/mnt/models/chat_template.file,ro quay.io/ramalama/ramalama:0.7 llama-run --jinja -c 2048 --temp 0.8 -v --threads 4 /mnt/models/model.file\nLoading modelllama_model_loader: loaded meta data with 30 key-value pairs and 255 tensors from /mnt/models/model.file (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.type str              = model\nllama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3B Instruct\nllama_model_loader: - kv   3:                           general.finetune str              = Instruct\nllama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\nllama_model_loader: - kv   5:                         general.size_label str              = 3B\nllama_model_loader: - kv   6:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\nllama_model_loader: - kv   7:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\nllama_model_loader: - kv   8:                          llama.block_count u32              = 28\nllama_model_loader: - kv   9:                       llama.context_length u32              = 131072\nllama_model_loader: - kv  10:                     llama.embedding_length u32              = 3072\nllama_model_loader: - kv  11:                  llama.feed_forward_length u32              = 8192\nllama_model_loader: - kv  12:                 llama.attention.head_count u32              = 24\nllama_model_loader: - kv  13:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv  14:                       llama.rope.freq_base f32              = 500000.000000\nllama_model_loader: - kv  15:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  16:                 llama.attention.key_length u32              = 128\nllama_model_loader: - kv  17:               llama.attention.value_length u32              = 128\nllama_model_loader: - kv  18:                          general.file_type u32              = 15\nllama_model_loader: - kv  19:                           llama.vocab_size u32              = 128256\nllama_model_loader: - kv  20:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv  21:                       tokenizer.ggml.model str              = gpt2\nllama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = llama-bpe\nllama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\nllama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\nllama_model_loader: - kv  25:                      tokenizer.ggml.merges arr[str,280147]  = [\"?? ??\", \"?? ??????\", \"???? ????\", \"...\nllama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 128000\nllama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 128009\nllama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\nllama_model_loader: - kv  29:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   58 tensors\nllama_model_loader: - type q4_K:  168 tensors\nllama_model_loader: - type q6_K:   29 tensors\nprint_info: file format = GGUF V3 (latest)\nprint_info: file type   = Q4_K - Medium\n\n```", "A friendly reminder that this issue had no activity for 30 days." ],
      "repository" : {
        "description" : "RamaLama is an open-source developer tool that simplifies the local serving of AI models from any source and facilitates their use for inference in production, all through the familiar language of containers.",
        "homepage" : "https://ramalama.ai",
        "name" : "ramalama",
        "fullName" : "containers/ramalama",
        "htmlUrl" : "https://github.com/containers/ramalama",
        "gitUrl" : "git://github.com/containers/ramalama.git",
        "sshUrl" : "git@github.com:containers/ramalama.git",
        "cloneUrl" : "https://github.com/containers/ramalama.git",
        "owner" : {
          "login" : "containers",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 222,
        "stargazersCount" : 1929,
        "watchersCount" : 1929,
        "size" : 3759,
        "openIssuesCount" : 72,
        "subscribersCount" : 30,
        "pushedAt" : "2025-07-24T23:44:27Z",
        "languages" : {
          "MDX" : 129089,
          "TypeScript" : 10702,
          "Dockerfile" : 7680,
          "Shell" : 270255,
          "CSS" : 3603,
          "Makefile" : 7694,
          "Perl" : 38574,
          "Nix" : 1640,
          "Python" : 484499
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to use vllm runtime and resolve the 'unrecognized arguments' error.",
      "validationOrRequirement" : "The issue requires using vllm runtime and getting an 'unrecognized arguments' error. The error is shown in the full log.",
      "attemptedFixes" : "The issue was reported, but no fix was attempted or provided.",
      "otherNotes" : "The issue is about using vllm runtime and getting an 'unrecognized arguments' error. The error is shown in the full log. The issue was reported 30 days ago and has no activity.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406210
  }, {
    "issueDTO" : {
      "id" : 2985625134,
      "title" : "rag: ramalama run --rag tries to connect to port 8080 even if a different port is chosen",
      "url" : "https://github.com/containers/ramalama/issues/1162",
      "repositoryName" : "containers/ramalama",
      "description" : "When port 8080 is already used by a different program, ramalama chooses a different port but the `rag_framework` script hard-codes the port number, leading to a \"connection refused\" error when interacting on the prompt:\n\n```console\n$ nc -l -p 8080 &\n$ ramalama --debug --image quay.io/ramalama/ramalama-rag run -y.io/localhost/myrag:0.1 deepseek\nWorking directory: None\nIgnore stderr: False\nIgnore all: False\nCommand finished with return code: 0\nChecking if 8080 is available\nChecking if 8084 is available\nexec_cmd:  podman run --rm -i --label ai.ramalama --name ramalama_lij2JQobRo --env=HOME=/tmp --init --security-opt=label=disable --cap-drop=all --security-opt=no-new-privileges --label ai.ramalama.model=ollama://deepseek-r1 --label ai.ramalama.engine=podman --label ai.ramalama.runtime=llama.cpp --label ai.ramalama.port=8084 --label ai.ramalama.command=run --env LLAMA_PROMPT_PREFIX=\uD83E\uDDAD >  --pull=newer -t -p 8084:8084 --device /dev/dri --device /dev/kfd -e HIP_VISIBLE_DEVICES=0 --network bridge --mount=type=image,source=localhost/myrag:0.1,destination=/rag,rw=true --mount=type=bind,src=/home/ueno/.local/share/ramalama/models/ollama/deepseek-r1:latest,destination=/mnt/models/model.file,ro quay.io/ramalama/ramalama-rag:0.7 bash -c nohup llama-server --port 8084 --model /mnt/models/model.file --alias deepseek-r1 --ctx-size 2048 --temp 0.8 --jinja -v -ngl 0 --threads 8 --host 0.0.0.0 &> /tmp/llama-server.log & rag_framework run /rag/vector.db\n[...]\n> What's the goal of RamaLama project?\n[...]\nopenai.APIConnectionError: Connection error.\n```\n\nI can think of two ways to fix it:\n- add an option to `rag_framework` to specify the connecting port and pass the actual port number\n- assume `--network private` and always use port 8080",
      "updatedAt" : 1753402712.000000000,
      "user" : "ueno",
      "userHtmlUrl" : "https://github.com/ueno",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47549?v=4",
      "labels" : [ "stale-issue", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "We should leak the PORT into the container so that scripts will no which to connect to.  Interested in opening a PR?", "A slightly better approach might be to communicate through a Unix domain socket, given the latest llama.cpp [got](https://github.com/ggml-org/llama.cpp/pull/12613) support for it in llama-server. Then rag_framework can be modified as below, so no external ports are needed:\n```diff\ndiff --git a/container-images/scripts/rag_framework b/container-images/scripts/rag_framework\nindex 7b9544d..8012739 100755\n--- a/container-images/scripts/rag_framework\n+++ b/container-images/scripts/rag_framework\n@@ -15,6 +15,7 @@ from fastapi import FastAPI, HTTPException\n from fastapi.responses import JSONResponse\n from pydantic import BaseModel\n from fastapi import FastAPI\n+import httpx\n import uvicorn\n \n # Global Vars\n@@ -45,7 +46,10 @@ class Rag(cmd.Cmd):\n         self.reranker = TextCrossEncoder(model_name=RANK_MODEL)\n \n         # Setup openai api\n-        self.llm = openai.OpenAI(api_key=\"your-api-key\", base_url=\"http://localhost:8080\")\n+        http_transport = httpx.HTTPTransport(uds=\"/run/llama-server.sock\")\n+        http_client = httpx.Client(transport=transport)\n+        self.llm = openai.OpenAI(api_key=\"your-api-key\", base_url=\"http://localhost:8080\",\n+                                 http_client=http_client)\n         self.chat_history = []  # Store chat history\n \n     def do_EOF(self, user_content):\n```", "I like this alot, although I think in the long run we might move to llama-stack for connecting these services together.\n", "@ueno do you know if we have the latest llama.cpp in our containers yet, or do we need to update the release?", "@rhatdan yes, the latest container [image](https://quay.io/repository/ramalama/ramalama/manifest/sha256:51892a55dbbf6b9c117e26ef8e234b5db331edcc99e10095f00084112f1bdf95) seems to include the feature.", "A friendly reminder that this issue had no activity for 30 days." ],
      "repository" : {
        "description" : "RamaLama is an open-source developer tool that simplifies the local serving of AI models from any source and facilitates their use for inference in production, all through the familiar language of containers.",
        "homepage" : "https://ramalama.ai",
        "name" : "ramalama",
        "fullName" : "containers/ramalama",
        "htmlUrl" : "https://github.com/containers/ramalama",
        "gitUrl" : "git://github.com/containers/ramalama.git",
        "sshUrl" : "git@github.com:containers/ramalama.git",
        "cloneUrl" : "https://github.com/containers/ramalama.git",
        "owner" : {
          "login" : "containers",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 222,
        "stargazersCount" : 1929,
        "watchersCount" : 1929,
        "size" : 3759,
        "openIssuesCount" : 72,
        "subscribersCount" : 30,
        "pushedAt" : "2025-07-24T23:44:27Z",
        "languages" : {
          "MDX" : 129089,
          "TypeScript" : 10702,
          "Dockerfile" : 7680,
          "Shell" : 270255,
          "CSS" : 3603,
          "Makefile" : 7694,
          "Perl" : 38574,
          "Nix" : 1640,
          "Python" : 484499
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the connection error when trying to connect to port 8080, even though a different port is chosen.",
      "validationOrRequirement" : "The issue seems to require a fix to rag_framework to allow it to connect to a different port than 8080.",
      "attemptedFixes" : "Two potential fixes are suggested: adding an option to rag_framework to specify the connecting port or assuming --network private and always using port 8080.",
      "otherNotes" : "RamaLama project goal is not explicitly mentioned in the issue, but it seems to be related to connecting services together. The issue description provides a code snippet and a console output showing a connection error when trying to connect to port 8080, even though a different port is chosen. Two potential fixes are suggested: adding an option to rag_framework to specify the connecting port or assuming --network private and always using port 8080. Comments suggest modifying rag_framework to use a Unix domain socket instead of external ports, which is a better approach.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406217
  }, {
    "issueDTO" : {
      "id" : 2000669746,
      "title" : "Adding cp.squeeze",
      "url" : "https://github.com/cvxpy/cvxpy/issues/2290",
      "repositoryName" : "cvxpy/cvxpy",
      "description" : "**Is your feature request related to a problem? Please describe.**\r\nMissing squeeze operation for full compatibility with NumPy. This currently has the same functionality as flatten since cvxpy expressions are limited to 2-dimensions. However with the addition of nd-expressions, the squeeze operation could be helpful to ensure shape consistency. \r\n\r\n**Describe the solution you'd like**\r\nImplement an equivalent operation to [np.squeeze](https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html) in cvxpy. \r\n\r\n",
      "updatedAt" : 1753402585.000000000,
      "user" : "Transurgeon",
      "userHtmlUrl" : "https://github.com/Transurgeon",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/89562186?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Is this still of interest? I'd like to give it a try." ],
      "repository" : {
        "description" : "A Python-embedded modeling language for convex optimization problems.",
        "homepage" : "https://www.cvxpy.org",
        "name" : "cvxpy",
        "fullName" : "cvxpy/cvxpy",
        "htmlUrl" : "https://github.com/cvxpy/cvxpy",
        "gitUrl" : "git://github.com/cvxpy/cvxpy.git",
        "sshUrl" : "git@github.com:cvxpy/cvxpy.git",
        "cloneUrl" : "https://github.com/cvxpy/cvxpy.git",
        "owner" : {
          "login" : "cvxpy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1112,
        "stargazersCount" : 5850,
        "watchersCount" : 5850,
        "size" : 215756,
        "openIssuesCount" : 267,
        "subscribersCount" : 128,
        "pushedAt" : "2025-07-22T15:59:57Z",
        "languages" : {
          "C++" : 7050392,
          "Shell" : 3300,
          "C" : 153750,
          "SWIG" : 2403,
          "CMake" : 694,
          "Makefile" : 6320,
          "Python" : 2681809,
          "Linear Programming" : 9052
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Adding cp.squeeze for full compatibility with NumPy.",
      "validationOrRequirement" : "Implement an equivalent operation to [np.squeeze](https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html) in cvxpy.",
      "attemptedFixes" : "Is this still of interest? I'd like to give it a try.",
      "otherNotes" : "Is your feature request related to a problem? Please describe. Missing squeeze operation for full compatibility with NumPy.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406220
  }, {
    "issueDTO" : {
      "id" : 2803024268,
      "title" : "improve definition of constructor args",
      "url" : "https://github.com/flashbots/contender/issues/105",
      "repositoryName" : "flashbots/contender",
      "description" : "**Is your feature request related to a problem? Please describe.**\n\nPassing constructor args when writing `[[create]]` directives is painstaking and error-prone. You have to zero-pad and append the args to the raw bytecode. This makes updating the bytecode later very tedious.\n\n**Describe the solution you'd like**\n\n- add a new `args = [...]` field to the `[[create]]` directive; same design as setup/spam directives.\n- zero-pad args automatically\n- append passed args to bytecode\n\n**Describe alternatives you've considered**\n\n- perpetual suffering\n",
      "updatedAt" : 1753402450.000000000,
      "user" : "zeroXbrock",
      "userHtmlUrl" : "https://github.com/zeroXbrock",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2791467?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@zeroXbrock can I work on this issue?\n", "hey @NehharShah, sorry I didn't see your comment. Yes, please do!" ],
      "repository" : {
        "description" : "run highly configurable benchmarks for EVM-based execution nodes over JSON-RPC",
        "homepage" : "",
        "name" : "contender",
        "fullName" : "flashbots/contender",
        "htmlUrl" : "https://github.com/flashbots/contender",
        "gitUrl" : "git://github.com/flashbots/contender.git",
        "sshUrl" : "git@github.com:flashbots/contender.git",
        "cloneUrl" : "https://github.com/flashbots/contender.git",
        "owner" : {
          "login" : "flashbots",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 27,
        "stargazersCount" : 82,
        "watchersCount" : 82,
        "size" : 2930,
        "openIssuesCount" : 28,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-24T22:00:25Z",
        "languages" : {
          "Dockerfile" : 1309,
          "Shell" : 506,
          "Rust" : 494181,
          "Handlebars" : 17302
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve the definition of constructor args by adding a new field to the [[create]] directive, automatically zero-padding and appending passed args to the bytecode.",
      "validationOrRequirement" : "Add a new 'args = [...]' field to the [[create]] directive, zero-pad args automatically, and append passed args to bytecode.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is related to the problem of passing constructor args when writing [[create]] directives, which is error-prone and tedious to update later.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406224
  }, {
    "issueDTO" : {
      "id" : 3070937135,
      "title" : "Include PTM datasets",
      "url" : "https://github.com/prescient-design/lobster/issues/81",
      "repositoryName" : "prescient-design/lobster",
      "description" : "- Add [PTM-mamba](https://www.nature.com/articles/s41592-025-02656-9) datasets ",
      "updatedAt" : 1753402327.000000000,
      "user" : "ncfrey",
      "userHtmlUrl" : "https://github.com/ncfrey",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19844216?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I have submitted a preliminary PR to add the dataset.  \n\nI'd be happy to work on PTM-specific tokenization integration with Lobster's tokenizer system, including more comprehensive test coverage if needed, and Integration with Lobster's training pipeline." ],
      "repository" : {
        "description" : "Lbster: Language models for Biological Sequence Transformation and Evolutionary Representation",
        "homepage" : "https://prescient-design.github.io/lobster-docs/",
        "name" : "lobster",
        "fullName" : "prescient-design/lobster",
        "htmlUrl" : "https://github.com/prescient-design/lobster",
        "gitUrl" : "git://github.com/prescient-design/lobster.git",
        "sshUrl" : "git@github.com:prescient-design/lobster.git",
        "cloneUrl" : "https://github.com/prescient-design/lobster.git",
        "owner" : {
          "login" : "prescient-design",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28,
        "stargazersCount" : 122,
        "watchersCount" : 122,
        "size" : 14507,
        "openIssuesCount" : 19,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-24T21:59:33Z",
        "languages" : {
          "Shell" : 6252,
          "CSS" : 1760,
          "JavaScript" : 99640,
          "HTML" : 13025,
          "Jupyter Notebook" : 19495,
          "Python" : 1948769
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Include PTM datasets",
      "validationOrRequirement" : "add PTM-mamba datasets",
      "attemptedFixes" : "preliminary PR submitted to add the dataset",
      "otherNotes" : "PTM-specific tokenization integration with Lobster's tokenizer system and comprehensive test coverage is also planned",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406226
  }, {
    "issueDTO" : {
      "id" : 2932667909,
      "title" : "Unit Tests: AIService.java",
      "url" : "https://github.com/BuildCLI/BuildCLI/issues/374",
      "repositoryName" : "BuildCLI/BuildCLI",
      "description" : "\n## Description:\nBuildCLI currently lacks comprehensive unit tests for its core components. To improve the reliability and maintainability of the project, we should implement a robust suite of unit tests covering the core logic, ensuring that individual components function correctly in isolation.\n\n## Why is this important?\n- Ensures correctness of core functionalities.\n- Prevents regressions when modifying the codebase.\n- Improves confidence when refactoring or adding new features.\n- Facilitates contributions by providing clear expectations for component behavior.\n\n## Suggested Approach:\n- Use JUnit 5 as the testing framework.\n- Utilize Mockito for mocking dependencies where necessary.\n- Cover core utility classes and service components with meaningful unit tests.\n- Follow Picocli???s best practices for testing CLI applications: Picocli Testing Guide.\n- Ensure tests follow best practices and remain maintainable.\n\n## Next Steps:\n- Identify key components lacking test coverage.\n- Define a structured test plan for each component.\n- Implement initial test cases and validate expected behavior.\n- Integrate unit tests with the CI/CD pipeline to ensure automated execution.\n\nContributions and feedback are welcome! \uD83D\uDE80\n\n**Attention, this issue was made with automation and AI, so be careful and check if is really needed**",
      "updatedAt" : 1753402285.000000000,
      "user" : "omatheusmesmo",
      "userHtmlUrl" : "https://github.com/omatheusmesmo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/99829531?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\uD83E\uDD16 To be assigned to this issue, comment with one of the following phrases:\n  - \"Assign me\"\n  - \"I would like to work on this\"\n  If the issue is already assigned, the assigned user will be asked if they are still working on it.", "Assign me", "\uD83E\uDD16 @tinexu, you have been assigned to this issue! ???", "\uD83E\uDD16 @tinexu, you have been assigned to this issue! ???" ],
      "repository" : {
        "description" : "BuildCLI is a command-line interface (CLI) tool for managing and automating common tasks in Java project development.",
        "homepage" : "https://buildcli.dev",
        "name" : "BuildCLI",
        "fullName" : "BuildCLI/BuildCLI",
        "htmlUrl" : "https://github.com/BuildCLI/BuildCLI",
        "gitUrl" : "git://github.com/BuildCLI/BuildCLI.git",
        "sshUrl" : "git@github.com:BuildCLI/BuildCLI.git",
        "cloneUrl" : "https://github.com/BuildCLI/BuildCLI.git",
        "owner" : {
          "login" : "BuildCLI",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 87,
        "stargazersCount" : 127,
        "watchersCount" : 127,
        "size" : 1291,
        "openIssuesCount" : 173,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-21T17:58:26Z",
        "languages" : {
          "Java" : 534847,
          "Shell" : 4105,
          "Batchfile" : 2891
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement comprehensive unit tests for BuildCLI's core components to improve reliability and maintainability, ensuring correctness of core functionalities, preventing regressions, improving confidence, and facilitating contributions",
      "validationOrRequirement" : "Use JUnit 5 as the testing framework, Utilize Mockito for mocking dependencies where necessary, Cover core utility classes and service components with meaningful unit tests, Follow Picocli's best practices for testing CLI applications: Picocli Testing Guide, Ensure tests follow best practices and remain maintainable",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue was made with automation and AI, so be careful and check if it's really needed",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406231
  }, {
    "issueDTO" : {
      "id" : 3261563553,
      "title" : "Fix JavaScript lint errors",
      "url" : "https://github.com/stdlib-js/stdlib/issues/7736",
      "repositoryName" : "stdlib-js/stdlib",
      "description" : "  ## JavaScript Linting Failures\n\n  Linting failures were detected in the automated JavaScript lint workflow run.\n\n  ### Workflow Details\n\n  - Run: https://github.com/stdlib-js/stdlib/actions/runs/16510434736\n  - Type: JavaScript Linting\n  - Date: 2025-07-25 00:08:44 UTC\n\n  ### Error Details\n  ```\n  make[1]: Entering directory '/home/runner/work/stdlib/stdlib'\n\nLinting file: lib/node_modules/@stdlib/math/strided/special/smskabs2/lib/native.js\n\nLinting file: lib/node_modules/@stdlib/stats/strided/nanmin-by/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/plot/base/ctor/lib/props/y-domain/get.js\n\nLinting file: lib/node_modules/@stdlib/math/iter/sequences/even-integers/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/random/iter/laplace/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/stats/strided/dnanstdevtk/lib/ndarray.js\n\nLinting file: lib/node_modules/@stdlib/ndarray/base/unary-reduce-strided1d/lib/10d_blocked_accessors.js\n\nLinting file: lib/node_modules/@stdlib/stats/base/snanvarianceyc/lib/snanvarianceyc.js\n\nLinting file: lib/node_modules/@stdlib/blas/ext/base/gcusumkbn2/lib/accessors.js\n\nLinting file: lib/node_modules/@stdlib/repl/lib/commands/delete_workspace.js\n\nLinting file: lib/node_modules/@stdlib/random/streams/poisson/lib/main.js\n\nLinting file: lib/node_modules/@stdlib/simulate/iter/dirac-comb/lib/validate.js\n\nLinting file: lib/node_modules/@stdlib/math/base/special/atanf/lib/main.js\n\nLinting file: lib/node_modules/@stdlib/stats/array/nanstdev/lib/main.js\n\nLinting file: lib/node_modules/@stdlib/math/base/assert/is-integerf/lib/native.js\n\nLinting file: lib/node_modules/@stdlib/random/streams/chisquare/lib/object_mode.js\n\nLinting file: lib/node_modules/@stdlib/stats/base/dists/kumaraswamy/ctor/lib/main.js\n\nLinting file: lib/node_modules/@stdlib/_tools/repl-txt/rules/has-alias-signature/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/_tools/eslint/rules/jsdoc-no-shortcut-reference-image/lib/main.js\n\nLinting file: lib/node_modules/@stdlib/_tools/eslint/rules/jsdoc-no-duplicate-headings-in-section/lib/index.js\n\nLinting file: lib/node_modules/@stdlib/strided/base/map-by/lib/map.js\nmake[1]: Leaving directory '/home/runner/work/stdlib/stdlib'\n  ```\n\n  ### Pull Request Instructions\n\n  -   Please use the following PR title format:\n  \"chore: fix JavaScript lint errors (issue #<ISSUE_NUMBER>)\".\n  -   Reference this issue in the \"Related Issues\" section of the PR body as \"resolves #<ISSUE_NUMBER>\".\n",
      "updatedAt" : 1753402137.000000000,
      "user" : "stdlib-bot",
      "userHtmlUrl" : "https://github.com/stdlib-bot",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82920195?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "# :wave: Important: PLEASE READ :wave:\n\nThis issue has been labeled as a **good first issue** and is available for anyone to work on.\n\nIf this is your first time contributing to an open source project, some aspects of the development process may seem unusual, arcane, or some combination of both.\n\n1.  **You cannot \"claim\" issues.** People new to open source often want to \"claim\" or be assigned an issue before beginning work. The typical rationale is that people want to avoid wasted work in the event that someone else ends up working the issue. However, this practice is not effective in open source, as it often leads to \"issue squatting\", in which an individual asks to be assigned, is granted their request, and then never ends up working on the issue. Accordingly, you are encouraged to communicate your intent to address this issue, ideally by providing a rough outline as to how you plan to address the issue or asking clarifying questions, but, at the end of the day, we will take running code and rough consensus in order to move forward quickly.\n2.  **We have a very high bar for contributions.** We have very high standards for contributions and expect all contributions???whether new features, tests, or documentation???to be rigorous, thorough, and complete. Once a pull request is merged into stdlib, that contribution immediately becomes the collective responsibility of all maintainers of stdlib. When we merge code into stdlib, we are saying that we, the maintainers, commit to reviewing subsequent changes and making bugfixes to the code. Hence, in order to ensure future maintainability, this naturally leads to a higher standard of contribution.\n\nBefore working on this issue and opening a pull request, please read the project's [contributing guidelines](https://github.com/stdlib-js/stdlib/blob/develop/CONTRIBUTING.md). These guidelines and the associated [development guide](https://github.com/stdlib-js/stdlib/blob/develop/docs/contributing/development.md) provide important information, including links to stdlib's [Code of Conduct](https://github.com/stdlib-js/stdlib/blob/develop/CODE_OF_CONDUCT.md), license policy, and steps for setting up your local development environment.\n\nTo reiterate, we **strongly** encourage you to refer to our contributing guides **before** beginning work on this issue. Failure to follow our guidelines significantly decreases the likelihood that you'll successfully contribute to stdlib and may result in automatic closure of a pull request without review.\n\nSetting up your local development environment is a critical first step, as doing so ensures that automated development processes for linting, license verification, and unit testing can run prior to authoring commits and pushing changes. If you would prefer to avoid manual setup, we provide pre-configured [development containers](https://github.com/stdlib-js/stdlib/tree/develop/.devcontainer) for use locally or in GitHub Codespaces.\n\nWe place a high value on consistency throughout the stdlib codebase. We encourage you to closely examine other packages in stdlib and attempt to emulate the practices and conventions found therein.\n\n-   If you are attempting to contribute a new package, sometimes the best approach is to simply copy the contents of an existing package and then modify the minimum amount necessary to implement the feature (e.g., changing descriptions, parameter names, and implementation).\n-   If you are contributing tests, find a package implementing a similar feature and emulate the tests of that package.\n-   If you are updating documentation, examine several similar packages and emulate the content, style, and prose of those packages.\n\nIn short, the more effort you put in to ensure that your contribution looks and feels like stdlib???including variables names, bracket spacing, line breaks, etc???the more likely that your contribution will be reviewed and ultimately accepted. We encourage you to closely study the codebase **before** beginning work on this issue.\n\n:sparkles: Thank you again for your interest in stdlib, and we look forward to reviewing your future contributions. :sparkles:\n" ],
      "repository" : {
        "description" : "??? Standard library for JavaScript and Node.js. ???",
        "homepage" : "https://stdlib.io",
        "name" : "stdlib",
        "fullName" : "stdlib-js/stdlib",
        "htmlUrl" : "https://github.com/stdlib-js/stdlib",
        "gitUrl" : "git://github.com/stdlib-js/stdlib.git",
        "sshUrl" : "git@github.com:stdlib-js/stdlib.git",
        "cloneUrl" : "https://github.com/stdlib-js/stdlib.git",
        "owner" : {
          "login" : "stdlib-js",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 854,
        "stargazersCount" : 5288,
        "watchersCount" : 5288,
        "size" : 2123788,
        "openIssuesCount" : 837,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-24T22:13:47Z",
        "languages" : {
          "C++" : 322679,
          "CSS" : 50680,
          "C" : 44459264,
          "WebAssembly" : 212150,
          "HTML" : 55717,
          "Fortran" : 365806,
          "TypeScript" : 31500177,
          "Julia" : 5682,
          "Shell" : 213507,
          "R" : 5700,
          "Awk" : 3608,
          "JavaScript" : 136703263,
          "Python" : 8613230
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Automated JavaScript lint workflow run detected linting failures in the stdlib repository",
      "validationOrRequirement" : "Fix JavaScript lint errors",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue has been labeled as a good first issue and is available for anyone to work on. It is important to read the project's contributing guidelines and development guide before beginning work on this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406234
  }, {
    "issueDTO" : {
      "id" : 2993291098,
      "title" : "Verify the Dangi calendar comparing with https://astro.kasi.re.kr/life/pageView/5",
      "url" : "https://github.com/unicode-org/icu4x/issues/6455",
      "repositoryName" : "unicode-org/icu4x",
      "description" : "It would be prudent to check that ICU4X's Dangi calendar agrees with https://astro.kasi.re.kr/life/pageView/5 ",
      "updatedAt" : 1753402067.000000000,
      "user" : "hsivonen",
      "userHtmlUrl" : "https://github.com/hsivonen",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/478856?v=4",
      "labels" : [ "C-calendar", "U-temporal", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I wrote a script using Deno and `icu` npm package to check discrepancies between ICU4X and official Korean lunisolar calendar.\n\n```sh\ndeno run --allow-net --allow-write fetch.ts korean_calendar.jsonl\ndeno run --allow-read check.ts korean_calendar.jsonl\n```\n\n<details>\n<summary>source code</summary>\n\n```typescript\n// fetch.ts\nimport { DOMParser } from \"jsr:@b-fuze/deno-dom@0.1.52\";\nimport { delay } from \"jsr:@std/async@1.0.13/delay\";\n\nasync function fetchPage(isoYear: number, isoMonth: number) {\n  const isoMonthString = isoMonth.toString().padStart(2, \"0\");\n  const response = await fetch(\"https://astro.kasi.re.kr/life/pageView/5\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/x-www-form-urlencoded\",\n    },\n    body: new URLSearchParams({\n      search_year: isoYear.toString(),\n      search_month: isoMonthString,\n      search_dp: \"1\",\n      search_check: \"G\",\n      select: \"1\",\n      yyyy: isoYear.toString(),\n      mm: isoMonthString,\n      date: `${isoYear}-${isoMonthString}`,\n    }),\n  });\n  return response.text();\n}\n\nfunction exactlyOne<T>(array: ArrayLike<T>): T {\n  if (array.length !== 1) {\n    throw new Error();\n  }\n  return array[0];\n}\n\nfunction extractDatesFromHtml(html: string) {\n  const doc = new DOMParser().parseFromString(html, \"text/html\");\n  const table = exactlyOne(doc.querySelectorAll(\"#container table\"));\n  const headers = [\n    ...exactlyOne(table.querySelectorAll(\"thead tr\")).querySelectorAll(\"th\"),\n  ].map((e) => e.textContent);\n  if (headers.length !== 5) {\n    throw new Error();\n  }\n  const gregorianIndex = headers.indexOf(\"???????????????\");\n  const lunarIndex = headers.indexOf(\"??????\");\n  if (gregorianIndex === -1 || lunarIndex === -1) {\n    throw new Error();\n  }\n  return [...table.querySelectorAll(\"tbody tr\")].map((e) => {\n    const cells = e.querySelectorAll(\"th, td\");\n    return {\n      iso: parseKoreanGregorianDate(cells[gregorianIndex].textContent),\n      lunar: parseKoreanLunarDate(cells[lunarIndex].textContent),\n    };\n  });\n}\n\nfunction parseKoreanGregorianDate(\n  date: string,\n): [year: number, month: number, day: number] {\n  const result = date.match(/(\\d+)??? (\\d\\d)??? (\\d\\d)???/);\n  if (!result) {\n    throw new Error();\n  }\n  return [parseInt(result[1]), parseInt(result[2]), parseInt(result[3])];\n}\n\nfunction parseKoreanLunarDate(\n  date: string,\n): [year: number, monthCode: string, day: number] {\n  const result = date.match(/(\\d+)??? (???)?(\\d\\d)??? (\\d\\d)???/);\n  if (!result) {\n    throw new Error();\n  }\n  return [\n    parseInt(result[1]),\n    result[2] !== undefined ? `M${result[3]}L` : `M${result[3]}`,\n    parseInt(result[4]),\n  ];\n}\n\nconst outputFile = Deno.args[0];\nif (outputFile === undefined) {\n  console.error(\"Specify output file\");\n  Deno.exit(1);\n}\n\nDeno.writeTextFile(outputFile, \"\");\n\n// from 1800 to 2050\nfor (let year = 1800; year <= 2050; year++) {\n  for (let month = 1; month <= 12; month++) {\n    console.error(`${year} ${month}`);\n    const filteredDates = extractDatesFromHtml(await fetchPage(year, month))\n      // only output a start or an end of a lunisolar month\n      .filter((date) => date.lunar[2] < 3 || date.lunar[2] > 27);\n    for (const date of filteredDates) {\n      Deno.writeTextFile(outputFile, `${JSON.stringify(date)}\\n`, {\n        append: true,\n      });\n    }\n    await delay(300);\n  }\n}\n```\n\n```typescript\n// check.ts\nimport * as icu from \"npm:icu@2.0.4\";\nimport * as v from \"npm:valibot@1.1.0\";\n\nconst inputFile = Deno.args[0];\nif (inputFile === undefined) {\n  console.error(\"Specify input file\");\n  Deno.exit(1);\n}\n\nconst schema = v.strictObject({\n  iso: v.tuple([v.number(), v.number(), v.number()]),\n  lunar: v.tuple([v.number(), v.string(), v.number()]),\n});\n\nconst koreanLunarCalendar = new icu.Calendar(icu.CalendarKind.Dangi);\n\nfor (const line of (await Deno.readTextFile(inputFile)).trim().split(\"\\n\")) {\n  const { iso, lunar } = v.parse(schema, JSON.parse(line));\n  const koreanDate = icu.Date.fromIsoInCalendar(\n    ...iso,\n    koreanLunarCalendar,\n  );\n  if (koreanDate.monthCode !== lunar[1] || koreanDate.dayOfMonth !== lunar[2]) {\n    console.log(iso, lunar, [\n      koreanDate.eraYearOrRelatedIso,\n      koreanDate.monthCode,\n      koreanDate.dayOfMonth,\n    ]);\n  }\n}\n```\n</details>\n\nThe script checks years between 1800 and 2050. According to the script, there are some differences before 1912: in 1803, 1804, 1809, 1815, 1818, 1821, 1827, 1828, 1831, 1832, 1846, 1847, 1849, 1851, 1852, 1857, 1862, 1870, 1882, 1890, 1896, 1897, 1903, 1904, 1905, 1908, 1911 (based on related ISO year, not Gregorian years). There is no differences after 1912, including future dates until 2050.\n\nraw data from the KASI site: https://gist.github.com/fabon-f/297420e4606fe8410b7f0348773e3918", "This is great, thank you!\n\nI wonder what happened in 1912. Prior to 1911, the Chinese calendar used by the Qing Dynasty had methods slightly different from the modern methods. I wonder if there's something similar going on with the Korean calendar." ],
      "repository" : {
        "description" : "Solving i18n for client-side and resource-constrained environments.",
        "homepage" : "https://icu4x.unicode.org",
        "name" : "icu4x",
        "fullName" : "unicode-org/icu4x",
        "htmlUrl" : "https://github.com/unicode-org/icu4x",
        "gitUrl" : "git://github.com/unicode-org/icu4x.git",
        "sshUrl" : "git@github.com:unicode-org/icu4x.git",
        "cloneUrl" : "https://github.com/unicode-org/icu4x.git",
        "owner" : {
          "login" : "unicode-org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 215,
        "stargazersCount" : 1570,
        "watchersCount" : 1570,
        "size" : 659128,
        "openIssuesCount" : 581,
        "subscribersCount" : 34,
        "pushedAt" : "2025-07-24T17:04:37Z",
        "languages" : {
          "Dockerfile" : 569,
          "Jinja" : 21090,
          "C++" : 1379,
          "Shell" : 297,
          "Rust" : 10612926,
          "Makefile" : 3779,
          "SCSS" : 562,
          "WebAssembly" : 369868,
          "JavaScript" : 151131,
          "HTML" : 3559,
          "Dart" : 17232
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Verify the Dangi calendar comparing with https://astro.kasi.re.kr/life/pageView/5",
      "validationOrRequirement" : "check that ICU4X's Dangi calendar agrees with https://astro.kasi.re.kr/life/pageView/5",
      "attemptedFixes" : "script checks years between 1800 and 2050 and identifies differences before 1912: in 1803, 1804, 1809, 1815, 1818, 1821, 1827, 1828, 1831, 1832, 1846, 1847, 1849, 1851, 1852, 1857, 1862, 1870, 1882, 1890, 1896, 1897, 1903, 1904, 1905, 1908, 1911 (based on related ISO year, not Gregorian years). There is no differences after 1912, including future dates until 2050.",
      "otherNotes" : "raw data from the KASI site: https://gist.github.com/fabon-f/297420e4606fe8410b7f0348773e3918, This is great, thank you!",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406242
  }, {
    "issueDTO" : {
      "id" : 3152889757,
      "title" : "Add workflow to test docker and docker examples",
      "url" : "https://github.com/intentee/paddler/issues/63",
      "repositoryName" : "intentee/paddler",
      "description" : "We already have a Dockerfile and a `docker-compose` example (started by #61 ). It would be nice to have a GitHub workflow that runs the example automatically after there are some changes introduced to either the Dockerfile or the `examples` directory to be sure they are always up to date and working.",
      "updatedAt" : 1753402021.000000000,
      "user" : "mcharytoniuk",
      "userHtmlUrl" : "https://github.com/mcharytoniuk",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1286785?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I want to work on this issue" ],
      "repository" : {
        "description" : "Stateful load balancer custom-tailored for llama.cpp \uD83C\uDFD3\uD83E\uDD99",
        "homepage" : "",
        "name" : "paddler",
        "fullName" : "intentee/paddler",
        "htmlUrl" : "https://github.com/intentee/paddler",
        "gitUrl" : "git://github.com/intentee/paddler.git",
        "sshUrl" : "git@github.com:intentee/paddler.git",
        "cloneUrl" : "https://github.com/intentee/paddler.git",
        "owner" : {
          "login" : "intentee",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 41,
        "stargazersCount" : 797,
        "watchersCount" : 797,
        "size" : 29069,
        "openIssuesCount" : 17,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-24T23:18:38Z",
        "languages" : {
          "TypeScript" : 32563,
          "HCL" : 7264,
          "Dockerfile" : 538,
          "CSS" : 8913,
          "Rust" : 189758,
          "Gherkin" : 7667,
          "Makefile" : 1197,
          "JavaScript" : 9028,
          "HTML" : 597
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a GitHub workflow to test docker and docker examples by running them automatically after changes are introduced to the Dockerfile or the 'examples' directory.",
      "validationOrRequirement" : "The workflow should run automatically after changes are introduced to the Dockerfile or the 'examples' directory.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "This issue is labeled as 'help wanted' and 'good first issue', indicating it's suitable for new contributors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406246
  }, {
    "issueDTO" : {
      "id" : 3152900041,
      "title" : "Add the possibility to use pre-downloaded models in `examples`",
      "url" : "https://github.com/intentee/paddler/issues/64",
      "repositoryName" : "intentee/paddler",
      "description" : "We have a working `docker-compose` setup thanks to #61 . Internally, it downloads a test model from Huggingface, which is nice, but it would also be good to have a way to use a pre-downloaded model (maybe by mounting it as a volume in `docker-compose`?) to avoid having to download it to run the examples.",
      "updatedAt" : 1753402021.000000000,
      "user" : "mcharytoniuk",
      "userHtmlUrl" : "https://github.com/mcharytoniuk",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1286785?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Currently, llama-server uses the `LLAMA_ARG_HF_REPO` environment variable to automatically download the model into `/root/.cache/llama.cpp`, which is persisted via the `hf-cache` volume.\n\nTo avoid downloading from Hugging Face, it can set `LLAMA_ARG_MODEL` to point to a local GGUF model file instead???this adds a bit of complexity but works well for pre-downloaded models.\n\nWould it make sense to add a `./models` directory and mount it as a volume in docker-compose so users can more easily manage and see their local model files?" ],
      "repository" : {
        "description" : "Stateful load balancer custom-tailored for llama.cpp \uD83C\uDFD3\uD83E\uDD99",
        "homepage" : "",
        "name" : "paddler",
        "fullName" : "intentee/paddler",
        "htmlUrl" : "https://github.com/intentee/paddler",
        "gitUrl" : "git://github.com/intentee/paddler.git",
        "sshUrl" : "git@github.com:intentee/paddler.git",
        "cloneUrl" : "https://github.com/intentee/paddler.git",
        "owner" : {
          "login" : "intentee",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 41,
        "stargazersCount" : 797,
        "watchersCount" : 797,
        "size" : 29069,
        "openIssuesCount" : 17,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-24T23:18:38Z",
        "languages" : {
          "TypeScript" : 32563,
          "HCL" : 7264,
          "Dockerfile" : 538,
          "CSS" : 8913,
          "Rust" : 189758,
          "Gherkin" : 7667,
          "Makefile" : 1197,
          "JavaScript" : 9028,
          "HTML" : 597
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add the possibility to use pre-downloaded models in examples",
      "validationOrRequirement" : "add a way to use a pre-downloaded model (maybe by mounting it as a volume in docker-compose?) to avoid having to download it to run the examples",
      "attemptedFixes" : "Would it make sense to add a ./models directory and mount it as a volume in docker-compose so users can more easily manage and see their local model files?",
      "otherNotes" : "Currently, llama-server uses the LLAMA_ARG_HF_REPO environment variable to automatically download the model into /root/.cache/llama.cpp, which is persisted via the hf-cache volume. To avoid downloading from Hugging Face, it can set LLAMA_ARG_MODEL to point to a local GGUF model file instead???this adds a bit of complexity but works well for pre-downloaded models.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406251
  }, {
    "issueDTO" : {
      "id" : 3261558687,
      "title" : "Fix EditorConfig lint errors",
      "url" : "https://github.com/stdlib-js/stdlib/issues/7735",
      "repositoryName" : "stdlib-js/stdlib",
      "description" : "## EditorConfig Linting Failures\n\nLinting failures were detected in the automated EditorConfig lint workflow run.\n\n### Workflow Details\n\n- Run: https://github.com/stdlib-js/stdlib/actions/runs/16510434736\n- Type: EditorConfig Linting\n- Date: 2025-07-25 00:04:27 UTC\n\n### Error Details\n\n```\nLinting files for basic formatting errors...\nDownloading v3.3.0\nlib/node_modules/@stdlib/complex/float32/real/manifest.json:\n\t2-35: Wrong indent style found (tabs instead of spaces)\n\t38-39: Wrong indent style found (tabs instead of spaces)\nlib/node_modules/@stdlib/strided/dtypes/manifest.json:\n\t2-37: Wrong indent style found (tabs instead of spaces)\n\n3 errors found\nmake: *** [/home/runner/work/stdlib/stdlib/tools/make/lib/lint/editorconfig.mk:90: lint-editorconfig-files] Error 1\n```\n\n### Pull Request Instructions\n\n-   Please use the following PR title format:\n\"chore: fix EditorConfig lint errors (issue #<ISSUE_NUMBER>)\".\n-   Reference this issue in the \"Related Issues\" section of the PR body as \"resolves #<ISSUE_NUMBER>\".\n",
      "updatedAt" : 1753401874.000000000,
      "user" : "stdlib-bot",
      "userHtmlUrl" : "https://github.com/stdlib-bot",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82920195?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "# :wave: Important: PLEASE READ :wave:\n\nThis issue has been labeled as a **good first issue** and is available for anyone to work on.\n\nIf this is your first time contributing to an open source project, some aspects of the development process may seem unusual, arcane, or some combination of both.\n\n1.  **You cannot \"claim\" issues.** People new to open source often want to \"claim\" or be assigned an issue before beginning work. The typical rationale is that people want to avoid wasted work in the event that someone else ends up working the issue. However, this practice is not effective in open source, as it often leads to \"issue squatting\", in which an individual asks to be assigned, is granted their request, and then never ends up working on the issue. Accordingly, you are encouraged to communicate your intent to address this issue, ideally by providing a rough outline as to how you plan to address the issue or asking clarifying questions, but, at the end of the day, we will take running code and rough consensus in order to move forward quickly.\n2.  **We have a very high bar for contributions.** We have very high standards for contributions and expect all contributions???whether new features, tests, or documentation???to be rigorous, thorough, and complete. Once a pull request is merged into stdlib, that contribution immediately becomes the collective responsibility of all maintainers of stdlib. When we merge code into stdlib, we are saying that we, the maintainers, commit to reviewing subsequent changes and making bugfixes to the code. Hence, in order to ensure future maintainability, this naturally leads to a higher standard of contribution.\n\nBefore working on this issue and opening a pull request, please read the project's [contributing guidelines](https://github.com/stdlib-js/stdlib/blob/develop/CONTRIBUTING.md). These guidelines and the associated [development guide](https://github.com/stdlib-js/stdlib/blob/develop/docs/contributing/development.md) provide important information, including links to stdlib's [Code of Conduct](https://github.com/stdlib-js/stdlib/blob/develop/CODE_OF_CONDUCT.md), license policy, and steps for setting up your local development environment.\n\nTo reiterate, we **strongly** encourage you to refer to our contributing guides **before** beginning work on this issue. Failure to follow our guidelines significantly decreases the likelihood that you'll successfully contribute to stdlib and may result in automatic closure of a pull request without review.\n\nSetting up your local development environment is a critical first step, as doing so ensures that automated development processes for linting, license verification, and unit testing can run prior to authoring commits and pushing changes. If you would prefer to avoid manual setup, we provide pre-configured [development containers](https://github.com/stdlib-js/stdlib/tree/develop/.devcontainer) for use locally or in GitHub Codespaces.\n\nWe place a high value on consistency throughout the stdlib codebase. We encourage you to closely examine other packages in stdlib and attempt to emulate the practices and conventions found therein.\n\n-   If you are attempting to contribute a new package, sometimes the best approach is to simply copy the contents of an existing package and then modify the minimum amount necessary to implement the feature (e.g., changing descriptions, parameter names, and implementation).\n-   If you are contributing tests, find a package implementing a similar feature and emulate the tests of that package.\n-   If you are updating documentation, examine several similar packages and emulate the content, style, and prose of those packages.\n\nIn short, the more effort you put in to ensure that your contribution looks and feels like stdlib???including variables names, bracket spacing, line breaks, etc???the more likely that your contribution will be reviewed and ultimately accepted. We encourage you to closely study the codebase **before** beginning work on this issue.\n\n:sparkles: Thank you again for your interest in stdlib, and we look forward to reviewing your future contributions. :sparkles:\n" ],
      "repository" : {
        "description" : "??? Standard library for JavaScript and Node.js. ???",
        "homepage" : "https://stdlib.io",
        "name" : "stdlib",
        "fullName" : "stdlib-js/stdlib",
        "htmlUrl" : "https://github.com/stdlib-js/stdlib",
        "gitUrl" : "git://github.com/stdlib-js/stdlib.git",
        "sshUrl" : "git@github.com:stdlib-js/stdlib.git",
        "cloneUrl" : "https://github.com/stdlib-js/stdlib.git",
        "owner" : {
          "login" : "stdlib-js",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 854,
        "stargazersCount" : 5288,
        "watchersCount" : 5288,
        "size" : 2123788,
        "openIssuesCount" : 837,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-24T22:13:47Z",
        "languages" : {
          "C++" : 322679,
          "CSS" : 50680,
          "C" : 44459264,
          "WebAssembly" : 212150,
          "HTML" : 55717,
          "Fortran" : 365806,
          "TypeScript" : 31500177,
          "Julia" : 5682,
          "Shell" : 213507,
          "R" : 5700,
          "Awk" : 3608,
          "JavaScript" : 136703263,
          "Python" : 8613230
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix EditorConfig lint errors in the stdlib project, specifically in the automated EditorConfig lint workflow run.",
      "validationOrRequirement" : "The issue requires the contributor to follow the project's contributing guidelines and development guide to ensure that their contribution meets the project's high standards.",
      "attemptedFixes" : "None mentioned in the issue description",
      "otherNotes" : "This issue is labeled as a good first issue, and contributors are encouraged to read the project's contributing guidelines and development guide before beginning work. The guidelines provide important information on code of conduct, license policy, and setting up the local development environment.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406256
  }, {
    "issueDTO" : {
      "id" : 3250875037,
      "title" : "update Read.md",
      "url" : "https://github.com/abhishektripathi66/DSA/issues/215",
      "repositoryName" : "abhishektripathi66/DSA",
      "description" : "**Describe the bug**\nThe package structure in the Readme.md is not updated. Please update it. \n\n\n**Expected behavior**\nThe read me file should be always updated.\nMake the read me file easy to understand, what the users can expect from the repo.\n\n",
      "updatedAt" : 1753401862.000000000,
      "user" : "abhishektripathi66",
      "userHtmlUrl" : "https://github.com/abhishektripathi66",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/42455093?v=4",
      "labels" : [ "first timer only", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @abhishektripathi66 ,\n\nI???d like to take it on and help update the `README.md` to reflect the current package structure and make it more user-friendly. My plan is to:\n- Update the package structure section with the latest directory layout (e.g., `codingquestions`, `datastructures`).\n\nI???m excited to contribute and will submit a PR once I have your input. Looking forward to your thoughts." ],
      "repository" : {
        "description" : "Learn the DSA and be Interview ready",
        "homepage" : "https://abhishektripathi66.github.io/DSA/",
        "name" : "DSA",
        "fullName" : "abhishektripathi66/DSA",
        "htmlUrl" : "https://github.com/abhishektripathi66/DSA",
        "gitUrl" : "git://github.com/abhishektripathi66/DSA.git",
        "sshUrl" : "git@github.com:abhishektripathi66/DSA.git",
        "cloneUrl" : "https://github.com/abhishektripathi66/DSA.git",
        "owner" : {
          "login" : "abhishektripathi66",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 54,
        "stargazersCount" : 47,
        "watchersCount" : 47,
        "size" : 1960,
        "openIssuesCount" : 2,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T13:59:41Z",
        "languages" : {
          "Java" : 597591
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the package structure in the Readme.md to reflect the current package structure and make it more user-friendly.",
      "validationOrRequirement" : "None mentioned",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The package structure in the Readme.md is not updated. The read me file should be always updated and make it more user-friendly.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406258
  }, {
    "issueDTO" : {
      "id" : 2119787660,
      "title" : "restore udeps checks",
      "url" : "https://github.com/lockbook/lockbook/issues/2379",
      "repositoryName" : "lockbook/lockbook",
      "description" : "on the latest nightly udeps fails because of:\r\n\r\n```\r\nerror[E0635]: unknown feature `stdsimd`\r\n  --> /Users/parth/.cargo/registry/src/index.crates.io-6f17d22bba15001f/ahash-0.8.3/src/lib.rs:99:42\r\n   |\r\n99 | #![cfg_attr(feature = \"stdsimd\", feature(stdsimd))]\r\n   |                                          ^^^^^^^\r\n\r\n    Checking flume v0.10.14\r\n    Checking nohash-hasher v0.2.0\r\nFor more information about this error, try `rustc --explain E0635`.\r\n    Checking typed-arena v2.0.2\r\nerror: could not compile `ahash` (lib) due to previous error\r\nwarning: build failed, waiting for other jobs to finish...\r\n```\r\nnote interleaved output. \r\n\r\nI disabled udeps to merge: #2280 \r\n\r\nThis is coming from `ahash` which seems to be using a feature that may have been removed. `ahash` exclusively comes from:\r\n\r\n```\r\negui_editor v0.8.4 (/Users/parth/Documents/lockbook/lockbook/libs/content/editor/egui_editor)\r\n????????? egui v0.22.0\r\n???   ????????? accesskit v0.11.0\r\n???   ????????? ahash v0.8.3\r\n???   ???   ????????? cfg-if v1.0.0\r\n???   ???   ????????? once_cell v1.18.0\r\n???   ???   [build-dependencies]\r\n???   ???   ????????? version_check v0.9.4\r\n???   ????????? epaint v0.22.0\r\n???   ???   ????????? ab_glyph v0.2.21\r\n???   ???   ???   ????????? ab_glyph_rasterizer v0.1.8\r\n???   ???   ???   ????????? owned_ttf_parser v0.19.0\r\n???   ???   ???       ????????? ttf-parser v0.19.1\r\n???   ???   ????????? ahash v0.8.3 (*)\r\n???   ???   ????????? bytemuck v1.13.1 (*)\r\n???   ???   ????????? ecolor v0.22.0\r\n???   ???   ???   ????????? bytemuck v1.13.1 (*)\r\n???   ???   ????????? emath v0.22.0\r\n???   ???   ???   ????????? bytemuck v1.13.1 (*)\r\n???   ???   ????????? log v0.4.19\r\n???   ???   ????????? nohash-hasher v0.2.0\r\n???   ???   ????????? parking_lot v0.12.1 (*)\r\n???   ????????? log v0.4.19\r\n???   ????????? nohash-hasher v0.2.0\r\n```\r\n\r\nThis is probably resolved on a newer version of egui. But some further investigation needs to be done.",
      "updatedAt" : 1753401709.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "egui", "infra", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "context: unused dependencies happen when change directions with some engineering and forget to remove an older dep that's no longer used. We want to eliminate these to speed up builds (probably) reduce binary size and overall reduce noise." ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Restore udeps checks on the latest nightly, failing due to unknown feature `stdsimd` in ahash",
      "validationOrRequirement" : "Check for removed features in dependencies, specifically ahash",
      "attemptedFixes" : "Disabled udeps to merge #2280",
      "otherNotes" : "Unused dependencies happen when change directions with some engineering and forget to remove an older dep that's no longer used. We want to eliminate these to speed up builds, reduce binary size and overall reduce noise.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406262
  }, {
    "issueDTO" : {
      "id" : 2903695842,
      "title" : "Migrate to new error API from RFC-0007",
      "url" : "https://github.com/slatedb/slatedb/issues/508",
      "repositoryName" : "slatedb/slatedb",
      "description" : "Now that we've agreed on our error API approach, the existing errors need to be migrated. See the RFC here:\n\nhttps://github.com/slatedb/slatedb/blob/main/rfcs/0007-api-errors.md\n\nAnd the PR/discussion here:\n\nhttps://github.com/slatedb/slatedb/pull/471",
      "updatedAt" : 1753401645.000000000,
      "user" : "criccomini",
      "userHtmlUrl" : "https://github.com/criccomini",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/167569?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'd like to work on this.", "Wonderful! Thanks. I've assigned the issue to you. LMK if you have any questions.", "@criccomini I've gone through the RFC and would like to start implementing it. \n\nIs there some error Enum already defined somewhere (I couldn't find it)? Or an Enum should be created and contain all the different errors across the codebase? ", "`errors.rs` contains `SlateDBError`. It uses the `thiserror` crate. You should be able to modify things there.", "@kiran-4444 Thanks for picking this up. In case it helps, what I roughly had in mind to implement this is 1) introduce the public Error type, 2) create some kind of mapping between the existing `SlateDbError` and the new `Error` type (should we rename `SlateDBError` to something else to emphasize internal use?), 3) update public APIs to return `Error` type, and 4) update documentation for each public API. ", "I???ve started to work on this. @criccomini can you assign it to me? I should have a PR ready before the end of the week." ],
      "repository" : {
        "description" : "A cloud native embedded storage engine built on object storage.",
        "homepage" : "https://slatedb.io",
        "name" : "slatedb",
        "fullName" : "slatedb/slatedb",
        "htmlUrl" : "https://github.com/slatedb/slatedb",
        "gitUrl" : "git://github.com/slatedb/slatedb.git",
        "sshUrl" : "git@github.com:slatedb/slatedb.git",
        "cloneUrl" : "https://github.com/slatedb/slatedb.git",
        "owner" : {
          "login" : "slatedb",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 122,
        "stargazersCount" : 2144,
        "watchersCount" : 2144,
        "size" : 2159,
        "openIssuesCount" : 102,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-24T22:25:11Z",
        "languages" : {
          "Shell" : 5910,
          "Rust" : 1409626,
          "Python" : 18153
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Migrate to a new error API from RFC-0007, by creating a public Error type, mapping between existing SlateDbError and the new Error type, renaming SlateDBError to emphasize internal use, updating public APIs, and updating documentation.",
      "validationOrRequirement" : "The issue requires creating a public Error type, mapping between existing SlateDbError and the new Error type, renaming SlateDBError to emphasize internal use, updating public APIs, and updating documentation.",
      "attemptedFixes" : "The author has started working on the issue, and another contributor has asked to assign it to them. A PR is expected to be ready before the end of the week.",
      "otherNotes" : "The issue is related to migrating to a new error API from RFC-0007, and the author would like to work on it. The discussion involves creating a public Error type, mapping between existing SlateDbError and the new Error type, renaming SlateDBError to emphasize internal use, updating public APIs, and updating documentation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406268
  }, {
    "issueDTO" : {
      "id" : 3260734349,
      "title" : "List available endpoints for kube-controller-manager's /statusz ",
      "url" : "https://github.com/kubernetes/kubernetes/issues/133182",
      "repositoryName" : "kubernetes/kubernetes",
      "description" : "Sub-issue of https://github.com/kubernetes/kubernetes/issues/132474\n\nAdd additional text of \"Paths:\" with available paths of kube-controller-manager:\n\n\"/livez\"\n\"/readyz\"\n\"/healthz\"\n\"/metrics\"\n\n/sig instrumentation",
      "updatedAt" : 1753401495.000000000,
      "user" : "richabanker",
      "userHtmlUrl" : "https://github.com/richabanker",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/26771552?v=4",
      "labels" : [ "sig/instrumentation", "help wanted", "triage/accepted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/triage accepted", "/help\n/good first issue", "@richabanker: \n\tThis request has been marked as needing help from a contributor.\n\n### Guidelines\nPlease ensure that the issue body includes answers to the following questions:\n- Why are we solving this issue?\n- To address this issue, are there any code changes? If there are code changes, what needs to be done in the code and what places can the assignee treat as reference points?\n- How can the assignee reach out to you for help?\n\n\nFor more details on the requirements of such an issue, please see [here](https://www.kubernetes.dev/docs/guide/help-wanted/) and ensure that they are met.\n\nIf this request no longer meets these requirements, the label can be removed\nby commenting with the `/remove-help` command.\n\n\n<details>\n\nIn response to [this](https://github.com/kubernetes/kubernetes/issues/133182):\n\n>/help\n>/good first issue\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes-sigs/prow](https://github.com/kubernetes-sigs/prow/issues/new?title=Prow%20issue:) repository.\n</details>", "cc @nmn3m\n\n", "/good-first-issue", "@richabanker: \n\tThis request has been marked as suitable for new contributors.\n\n### Guidelines\nPlease ensure that the issue body includes answers to the following questions:\n- Why are we solving this issue?\n- To address this issue, are there any code changes? If there are code changes, what needs to be done in the code and what places can the assignee treat as reference points?\n- How can the assignee reach out to you for help?\n\n\nFor more details on the requirements of such an issue, please see [here](https://www.kubernetes.dev/docs/guide/help-wanted/#good-first-issue) and ensure that they are met.\n\nIf this request no longer meets these requirements, the label can be removed\nby commenting with the `/remove-good-first-issue` command.\n\n\n<details>\n\nIn response to [this](https://github.com/kubernetes/kubernetes/issues/133182):\n\n>/good-first-issue\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes-sigs/prow](https://github.com/kubernetes-sigs/prow/issues/new?title=Prow%20issue:) repository.\n</details>", "/assign", "/assign" ],
      "repository" : {
        "description" : "Production-Grade Container Scheduling and Management",
        "homepage" : "https://kubernetes.io",
        "name" : "kubernetes",
        "fullName" : "kubernetes/kubernetes",
        "htmlUrl" : "https://github.com/kubernetes/kubernetes",
        "gitUrl" : "git://github.com/kubernetes/kubernetes.git",
        "sshUrl" : "git@github.com:kubernetes/kubernetes.git",
        "cloneUrl" : "https://github.com/kubernetes/kubernetes.git",
        "owner" : {
          "login" : "kubernetes",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 41013,
        "stargazersCount" : 116497,
        "watchersCount" : 116497,
        "size" : 1388910,
        "openIssuesCount" : 2502,
        "subscribersCount" : 3212,
        "pushedAt" : "2025-07-25T00:59:14Z",
        "languages" : {
          "PowerShell" : 147503,
          "Dockerfile" : 45190,
          "Shell" : 1972289,
          "C" : 4205,
          "sed" : 1262,
          "Batchfile" : 833,
          "Makefile" : 64132,
          "Go" : 80356579,
          "HTML" : 106,
          "Python" : 18353
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "List available endpoints for kube-controller-manager's /statusz and add additional text of 'Paths:' with available paths of kube-controller-manager: '/livez', '/readyz', '/healthz', '/metrics'.",
      "validationOrRequirement" : "The issue body should include answers to the following questions: Why are we solving this issue?, To address this issue, are there any code changes? If there are code changes, what needs to be done in the code and what places can the assignee treat as reference points?, How can the assignee reach out to you for help?",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "This request has been marked as needing help from a contributor and suitable for new contributors. The issue body should include answers to specific questions and meet certain requirements.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406274
  }, {
    "issueDTO" : {
      "id" : 963243272,
      "title" : "FR: Allow Beams to keep on target from a moving source.",
      "url" : "https://github.com/scp-fs2open/fs2open.github.com/issues/3591",
      "repositoryName" : "scp-fs2open/fs2open.github.com",
      "description" : "Right now, if a beam source moves, the beam will not stay on the original target, but also move in the same way.\r\nAdd a flag to beams that offsets their target by the negative movement of the beam source , as to keep the beams hitting the same spot even if the beam source moves.\r\nThis is presumably a prerequisite to make #3516 work when the beam source is moving as well.",
      "updatedAt" : 1753401433.000000000,
      "user" : "BMagnu",
      "userHtmlUrl" : "https://github.com/BMagnu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6238428?v=4",
      "labels" : [ "enhancement", "good first issue", "gameplay" ],
      "state" : "OPEN",
      "comments" : [ "Note: With modular curves, this FR now boils down to effectively #6760, but with Shooter Velocity." ],
      "repository" : {
        "description" : "Origin Repository for SCP FreeSpace 2 Open",
        "homepage" : "https://www.hard-light.net/",
        "name" : "fs2open.github.com",
        "fullName" : "scp-fs2open/fs2open.github.com",
        "htmlUrl" : "https://github.com/scp-fs2open/fs2open.github.com",
        "gitUrl" : "git://github.com/scp-fs2open/fs2open.github.com.git",
        "sshUrl" : "git@github.com:scp-fs2open/fs2open.github.com.git",
        "cloneUrl" : "https://github.com/scp-fs2open/fs2open.github.com.git",
        "owner" : {
          "login" : "scp-fs2open",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 174,
        "stargazersCount" : 432,
        "watchersCount" : 432,
        "size" : 231890,
        "openIssuesCount" : 425,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-24T23:01:05Z",
        "languages" : {
          "C++" : 28140315,
          "C" : 8268786,
          "GDB" : 555,
          "CMake" : 385321,
          "Objective-C++" : 102268,
          "Makefile" : 26757,
          "HTML" : 2156,
          "Kotlin" : 1513,
          "Shell" : 10949,
          "Batchfile" : 9395,
          "ANTLR" : 3727,
          "Lua" : 40209,
          "Objective-C" : 21625,
          "Mako" : 5674,
          "Rich Text Format" : 16171,
          "Python" : 58386,
          "GLSL" : 5405
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow Beams to keep on target from a moving source",
      "validationOrRequirement" : "add a flag to beams that offsets their target by the negative movement of the beam source",
      "attemptedFixes" : "none mentioned in the description",
      "otherNotes" : "Note: With modular curves, this FR now boils down to effectively #6760, but with Shooter Velocity.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406276
  }, {
    "issueDTO" : {
      "id" : 3126467059,
      "title" : "Microsoft.Extensions.ApiDescription.Server - Surface Invocation with new TerminalLogger",
      "url" : "https://github.com/dotnet/aspnetcore/issues/62273",
      "repositoryName" : "dotnet/aspnetcore",
      "description" : "### Is there an existing issue for this?\n\n- [x] I have searched the existing issues\n\n### Is your feature request related to a problem? Please describe the problem.\n\nrunning a `dotnet build` on an ASP.NET Core project, does not indicate when `Microsoft.Extensions.ApiDescription.Server` runs the `GetDocument` tool. This is due to dotnet's new Terminal Logger, introduced in .NET 8.\n\nBuilding with the new Terminal Logger disabled `dotnet build  --tl:off` does show the logs from the tool invocation, including `Generating document named 'v1'`.\n\nHowever, building with a Terminal Logger Verbosity flag set to detailed `dotnet build -tlp:v=d` does show the GetDocument logs.\n\nSomeone who is unaware these logs exist, will never be able to find them.\nThis can be an issue when debugging document generation.\n\n### Describe the solution you'd like\n\nSurface these logs when using the new Terminal Logger, which is the default logger. This could be dependent on:\n* https://github.com/dotnet/sdk/issues/43293\n* https://github.com/dotnet/msbuild/issues/6944\n* https://github.com/dotnet/msbuild/issues/10416\n\nor may be resolved via: https://github.com/dotnet/msbuild/pull/9810, by making the message higher priority, which may appear at lower log verbosity levels.\n\nalternatively, `-tlp:v=d` may be an acceptable solution, and we could instead inform users about it in the README of the the NuGet package.\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753401311.000000000,
      "user" : "MattParkerDev",
      "userHtmlUrl" : "https://github.com/MattParkerDev",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/61717342?v=4",
      "labels" : [ "help wanted", "feature-openapi", "good first issue", "area-commandlinetools" ],
      "state" : "OPEN",
      "comments" : [ "This is a sensible proposal. PR welcome assuming we can do thorough validation on this change.", "Looks like this issue has been identified as a candidate for community contribution. If you're considering sending a PR for this issue, look for the `Summary Comment` link in the issue description. That comment has been left by an engineer on our team to help you get started with handling this issue. You can learn more about our Help Wanted process [here](https://aka.ms/aspnet/processes/help-wanted)\n<!-- Policy app identification https://img.shields.io/static/v1?label=PullRequestIssueManagement. -->" ],
      "repository" : {
        "description" : "ASP.NET Core is a cross-platform .NET framework for building modern cloud-based web applications on Windows, Mac, or Linux.",
        "homepage" : "https://asp.net",
        "name" : "aspnetcore",
        "fullName" : "dotnet/aspnetcore",
        "htmlUrl" : "https://github.com/dotnet/aspnetcore",
        "gitUrl" : "git://github.com/dotnet/aspnetcore.git",
        "sshUrl" : "git@github.com:dotnet/aspnetcore.git",
        "cloneUrl" : "https://github.com/dotnet/aspnetcore.git",
        "owner" : {
          "login" : "dotnet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 10410,
        "stargazersCount" : 36899,
        "watchersCount" : 36899,
        "size" : 366275,
        "openIssuesCount" : 3789,
        "subscribersCount" : 1434,
        "pushedAt" : "2025-07-25T00:15:26Z",
        "languages" : {
          "C#" : 60644415,
          "PowerShell" : 317972,
          "Java" : 568974,
          "C++" : 1244944,
          "CSS" : 104309,
          "C" : 124045,
          "CMake" : 14853,
          "HTML" : 1673332,
          "TypeScript" : 1178863,
          "Dockerfile" : 423,
          "Shell" : 181419,
          "Batchfile" : 26222,
          "SCSS" : 12,
          "JavaScript" : 175738,
          "Lua" : 4904,
          "ASP.NET" : 109,
          "F#" : 6234,
          "Less" : 12,
          "Python" : 13176
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Surface invocation with new TerminalLogger in Microsoft.Extensions.ApiDescription.Server to indicate when Microsoft.Extensions.ApiDescription.Server runs the GetDocument tool during a dotnet build, making it easier to debug document generation.",
      "validationOrRequirement" : "The issue requires thorough validation on the change, and it's a candidate for community contribution.",
      "attemptedFixes" : "The issue is dependent on https://github.com/dotnet/sdk/issues/43293, https://github.com/dotnet/msbuild/issues/6944, https://github.com/dotnet/msbuild/issues/10416, and https://github.com/dotnet/msbuild/pull/9810, or may be resolved via the latter by making the message higher priority, which may appear at lower log verbosity levels.",
      "otherNotes" : "The issue is related to debugging document generation in ASP.NET Core projects, and it's about surfacing logs when using the new Terminal Logger, which is the default logger.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406282
  }, {
    "issueDTO" : {
      "id" : 2960639432,
      "title" : "Reports output modes to respect privacy settings",
      "url" : "https://github.com/fujiapple852/trippy/issues/1532",
      "repositoryName" : "fujiapple852/trippy",
      "description" : "Currently the Trippy report modes (i.e. `json`, `csv`, `markdown` & `pretty`) do not respect the users hop privacy settings (`--tui-privacy-max-ttl`). This setting is used in the Tui to mask sensitive information for hops of a given ttl.\n",
      "updatedAt" : 1753400969.000000000,
      "user" : "fujiapple852",
      "userHtmlUrl" : "https://github.com/fujiapple852",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/36075719?v=4",
      "labels" : [ "report", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This should be fairly simple to add. If anyone wishes to try I'm happy to coach someone through it.", "Hi, I'd like to work on this. It will be my first contribution to the project, and I'll be sure to ask any questions here if I get stuck.", "@ObsidianAli thanks for giving this a go! Feel free to tag me here on any questions or jump on the Zulip chat.", "Thanks for the welcome, @fujiapple852!\n\nAs I'm digging into the code, I just had a quick clarifying question. The description lists json, csv, markdown, and pretty. Should I also apply the privacy logic to the stream, dot, and flows modes to cover all the report types?\n\nHappy to do it for all of them, just wanted to double-check the scope first. Thanks again!" ],
      "repository" : {
        "description" : "A network diagnostic tool ",
        "homepage" : "https://trippy.rs",
        "name" : "trippy",
        "fullName" : "fujiapple852/trippy",
        "htmlUrl" : "https://github.com/fujiapple852/trippy",
        "gitUrl" : "git://github.com/fujiapple852/trippy.git",
        "sshUrl" : "git@github.com:fujiapple852/trippy.git",
        "cloneUrl" : "https://github.com/fujiapple852/trippy.git",
        "owner" : {
          "login" : "fujiapple852",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 149,
        "stargazersCount" : 5581,
        "watchersCount" : 5581,
        "size" : 25837,
        "openIssuesCount" : 67,
        "subscribersCount" : 24,
        "pushedAt" : "2025-07-21T02:42:44Z",
        "languages" : {
          "Dockerfile" : 2517,
          "Shell" : 1913,
          "Rust" : 1145477,
          "Makefile" : 318
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add report modes that respect user privacy settings, specifically for the Trippy report modes (`json`, `csv`, `markdown`, and `pretty`) and potentially other report types (stream, dot, and flows)",
      "validationOrRequirement" : "The issue requires the report modes to respect the users hop privacy settings (`--tui-privacy-max-ttl`)",
      "attemptedFixes" : "The author is open to coaching someone through the fix and has asked for clarification on the scope of the issue.",
      "otherNotes" : "This issue is marked as good first issue, enhancement, and help wanted, and is related to adding report modes that respect user privacy settings.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406287
  }, {
    "issueDTO" : {
      "id" : 3243839814,
      "title" : "Add dim order variant clone operator",
      "url" : "https://github.com/pytorch/executorch/issues/12645",
      "repositoryName" : "pytorch/executorch",
      "description" : "Currently clone operator is removed in the export pipeline without tracing its (possible) memory format / dim order changes within the copy and may lead to wrong memory format / dim order changes in the final exported model.\n\nOne of the essential features to solve the issue is creating dim order variant clone operator to ensure the correct dim order propagation in export graph. With the dim order variant clone op, we can make the `TestRemoveCloneOpsTransform` remove clone operator with dim order aware of.\n\ncc. @digantdesai \n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### RFC (Optional)\n\n_No response_\n\ncc @JacobSzwejbka @angelayi",
      "updatedAt" : 1753400897.000000000,
      "user" : "Gasoonjia",
      "userHtmlUrl" : "https://github.com/Gasoonjia",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22138577?v=4",
      "labels" : [ "actionable", "good first issue", "module: exir" ],
      "state" : "OPEN",
      "comments" : [ "so,\n(1) create `clone_dim_order` op\n(2) update the `MemoryFormatOps` pass to replace clone with this op\n(3) update `TestRemoveCloneOpsTransform` pass to be dim_order aware (not memory_format)", "I'd like to work on this! I have a few questions:\n\n1. After registering `clone_dim_order` in `dim_order_ops_registery.py`, will `MemoryFormatOpsPass` automatically replace `aten.clone` with `clone_dim_order`, or are additional changes required to ensure that the mapping occurs?\n\n2. Once `_clone_dim_order.out` is declared in `edge_dialect_aten_op.yaml`, where should the corresponding kernel implementation be placed?\n\n3. If `clone_dim_order` changes the dim order of its input, is it treated as a permanent op, or does its removal from the graph before final export need to be implemented in a pass?\n\n4. I wasn???t able to find `TestRemoveCloneOpsTransform` in the codebase. Is this referring to a test that should be added in `test_memory_format_ops_pass.py` to validate the removal of `clone_dim_order`?", "@keyprocedure Thanks for taking this!\n\n1. In the AOT side, yes, the replacement will be happen. We still need to impl runtime operators.\n2. for its aten version, please put it here https://github.com/pytorch/executorch/tree/main/kernels/aten/cpu; for its portable version, please here https://github.com/pytorch/executorch/tree/main/kernels/portable/cpu\n3. if it will change dim order, it should not be removed for dim order correctness.\n4. i think it should be `RemoveCloneOpsTransform` pass: https://github.com/pytorch/executorch/blob/c310efee9e011b74a210098a2a62441751e4c3e6/backends/transforms/remove_clone_ops.py#L28 @digantdesai  can you confirm it?" ],
      "repository" : {
        "description" : "On-device AI across mobile, embedded and edge for PyTorch",
        "homepage" : "https://pytorch.org/executorch/",
        "name" : "executorch",
        "fullName" : "pytorch/executorch",
        "htmlUrl" : "https://github.com/pytorch/executorch",
        "gitUrl" : "git://github.com/pytorch/executorch.git",
        "sshUrl" : "git@github.com:pytorch/executorch.git",
        "cloneUrl" : "https://github.com/pytorch/executorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 627,
        "stargazersCount" : 3054,
        "watchersCount" : 3054,
        "size" : 242669,
        "openIssuesCount" : 1273,
        "subscribersCount" : 69,
        "pushedAt" : "2025-07-25T00:57:59Z",
        "languages" : {
          "Java" : 91516,
          "C++" : 7679686,
          "Jinja" : 11160,
          "C" : 92780,
          "Objective-C++" : 585916,
          "CMake" : 258695,
          "Kotlin" : 47365,
          "Dockerfile" : 2846,
          "Shell" : 249480,
          "Starlark" : 490914,
          "Batchfile" : 339,
          "Objective-C" : 192676,
          "Swift" : 92248,
          "Python" : 9717219,
          "GLSL" : 337891
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a dim order variant clone operator to the export pipeline to ensure correct dim order propagation and prevent memory format changes in the final exported model.",
      "validationOrRequirement" : "The requirement is to create a dim order variant clone operator to ensure correct dim order propagation in the export graph.",
      "attemptedFixes" : "The author suggests creating a `clone_dim_order` op, updating `MemoryFormatOps` pass to replace clone with this op, and updating `TestRemoveCloneOpsTransform` pass to be dim_order aware.",
      "otherNotes" : "The issue description provides context for the problem and the requirement to create a dim order variant clone operator to ensure correct dim order propagation in the export graph. The comments section provides additional details and questions about the implementation, including the mapping of clone_dim_order to aten.clone, kernel implementation, and treatment of the operator's output.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406293
  }, {
    "issueDTO" : {
      "id" : 1940594531,
      "title" : "typo in `make-swift-test-lib` subcommand description",
      "url" : "https://github.com/lockbook/lockbook/issues/2182",
      "repositoryName" : "lockbook/lockbook",
      "description" : "<img width=\"708\" alt=\"image\" src=\"https://github.com/lockbook/lockbook/assets/20663038/3d448db3-437d-4568-8097-1bb5773d5989\">\r\n\r\n`make-swift-test-lib` does not use jni.",
      "updatedAt" : 1753400831.000000000,
      "user" : "smailbarkouch",
      "userHtmlUrl" : "https://github.com/smailbarkouch",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20663038?v=4",
      "labels" : [ "infra", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Correct the typo in the description of the `make-swift-test-lib` subcommand",
      "validationOrRequirement" : "None mentioned",
      "attemptedFixes" : "",
      "otherNotes" : "The description of the `make-swift-test-lib` subcommand contains a typo, and it's mentioned that it does not use jni.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406296
  }, {
    "issueDTO" : {
      "id" : 2568866657,
      "title" : "Add Group policy for playlist",
      "url" : "https://github.com/brave/brave-browser/issues/41428",
      "repositoryName" : "brave/brave-browser",
      "description" : "### Platforms\n\nLinux, macOS, Windows\n\n### Description\n\nIn https://github.com/brave/brave-core/pull/25710 we started to migrate towards group policies that match how Chromium does it. We currently have a few group policies for Brave specific features and this issue is to add a new policy that would disable playlist as well.",
      "updatedAt" : 1753400757.000000000,
      "user" : "kdenhartog",
      "userHtmlUrl" : "https://github.com/kdenhartog",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/23125059?v=4",
      "labels" : [ "feature-request", "enterprise", "feature/brave-origin", "help wanted", "good first issue", "features/playlist" ],
      "state" : "OPEN",
      "comments" : [ "Folks who were interested in this - you can check out the steps outlined here:\nhttps://github.com/brave/brave-core/tree/master/components/policy/resources/templates/policy_definitions\n\nThose go over the steps needed to create a new policy. You can also search our pull requests for `group policy` to find some of the prior implementations folks have done.", "Please assign this to me", "Hi! If this feature hasn't been completed, can I work on it? I don't need to be assigned to it.", "Certainly, I've not seen a PR for it yet so this is still free for anyone to work on." ],
      "repository" : {
        "description" : "Brave browser for Android, iOS, Linux, macOS, Windows.",
        "homepage" : "https://brave.com",
        "name" : "brave-browser",
        "fullName" : "brave/brave-browser",
        "htmlUrl" : "https://github.com/brave/brave-browser",
        "gitUrl" : "git://github.com/brave/brave-browser.git",
        "sshUrl" : "git@github.com:brave/brave-browser.git",
        "cloneUrl" : "https://github.com/brave/brave-browser.git",
        "owner" : {
          "login" : "brave",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2676,
        "stargazersCount" : 19802,
        "watchersCount" : 19802,
        "size" : 32242,
        "openIssuesCount" : 9220,
        "subscribersCount" : 393,
        "pushedAt" : "2025-07-25T00:03:04Z",
        "languages" : {
          "JavaScript" : 5040
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a group policy for playlist, as part of the migration towards group policies started in https://github.com/brave/brave-core/pull/25710",
      "validationOrRequirement" : "Create a new group policy that matches how Chromium does it, specifically to disable playlist.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue description provides a link to the steps needed to create a new policy and suggests searching pull requests for 'group policy' for prior implementations.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406299
  }, {
    "issueDTO" : {
      "id" : 3020653121,
      "title" : "ArgoCD Notifications Controller spawns hundreds of connections per instance without ever closing them",
      "url" : "https://github.com/argoproj/argo-cd/issues/22800",
      "repositoryName" : "argoproj/argo-cd",
      "description" : "# Summary\n\nArgoCD Notifications Controller should not spawn that many connections to api.github.com - there should be a more optimal solution. Otherwise it should at least close older connections after some time.\n\n# Motivation\n\nThe number of connections can pile up in excess of 50000 which takes it toll on the overall network performance.\n\n# Proposal\n\nConnections should be closed after x number of hours or whenever there is no longer need for them.\n\nTo reproduce, follow this procedure:\n```\noc debug node/worker-node-mss2d\nNAME=argocd-notifications-controller-54cd595994-l69k2\nNAMESPACE=argocd-namespace\npod_id=$(chroot /host crictl pods --namespace ${NAMESPACE} --name ${NAME} -q)\nns_path=\"/host/$(chroot /host bash -c \"crictl inspectp $pod_id | jq  '.info.runtimeSpec.linux.namespaces[]|select(.type==\\\"network\\\").path' -r\")\"\nnsenter \"--net=${ns_path}\"\nnetstat -anptu\n```\nThe output will be similar to this:\n```\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 10.131.14.13:55830      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:50148      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:39290      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:40204      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:39292      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:37258      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:56338      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:48840      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:38580      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:46462      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:39224      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:37324      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:33404      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:54680      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:43728      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:39366      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:58074      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:35686      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:47106      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:50594      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:57562      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:50164      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:40870      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:58798      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:36542      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:50062      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:43368      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:39854      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:51098      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:34568      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:60512      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:50846      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:50474      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:46732      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:44530      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:49940      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:38284      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:42992      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:47860      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:50108      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:32946      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:45586      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\ntcp        0      0 10.131.14.13:34006      10.125.19.58:443        ESTABLISHED 7099/argocd-notific\n....\n....\n```\nIn this case it was over 1200 open connections:\n```\nnetstat -anptu | wc -l\n1295\n```",
      "updatedAt" : 1753400713.000000000,
      "user" : "alxivanov",
      "userHtmlUrl" : "https://github.com/alxivanov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/89388397?v=4",
      "labels" : [ "component:notifications", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "What's the Argo CD version?", "There's probably [some love](https://github.com/argoproj/notifications-engine/blob/e3fe62649285afb289b2eb760e6bf8bd6819e639/pkg/services/github.go#L405-L414) that can be done for the Github service.", "Great catch @blakepettersson! Is there anything that can be done to promote this issue?", "@alxivanov I'd say the way to go would be to checkout the notifications-engine and tweak the underlying http client to your liking. Ideally there should be some way to be able to set the various settings (max no. of connections, keepalive etc etc). Once that's done submit a PR to notifications-engine. Once that's merged we'd need to create a PR with the upgraded notifications-engine that can make use of the various http client flags.", "Hi, I would like to take this up. I will put up some questions soon if any.", "@afzal442 Thanks, much appreciated!", "I have come to some understandings. I would like to get some suggestions if any. Blake, as you mentioned the snippet link, fwiu,  by default, each call to `http.Client{Transport: itr}` creates a new client with a new connection pool. We should be able to control connection behavior by customizing the `http.Transport`.\nhttps://github.com/argoproj/notifications-engine/blob/e3fe62649285afb289b2eb760e6bf8bd6819e639/pkg/util/http/transport.go#L16-L19", "@afzal442 that's right. For this specific issue we'd need a way to be able to set/override the parameters below from their defaults (which is unlimited). You can pass in those numbers as parameters to the `NewTransport` function and instantiate the http.Transport using said values.\n\n\n```golang\n\thttp.Transport{\n\t\tMaxIdleConns:           0,\n\t\tMaxIdleConnsPerHost:    0,\n\t\tMaxConnsPerHost:        0,\n\t\tIdleConnTimeout:        0,\n}\n```", "@afzal442 I see that you've already raised a PR for this issue. I just wanted to know if you're still working on it. If not, I'd like to work on it." ],
      "repository" : {
        "description" : "Declarative Continuous Deployment for Kubernetes",
        "homepage" : "https://argo-cd.readthedocs.io",
        "name" : "argo-cd",
        "fullName" : "argoproj/argo-cd",
        "htmlUrl" : "https://github.com/argoproj/argo-cd",
        "gitUrl" : "git://github.com/argoproj/argo-cd.git",
        "sshUrl" : "git@github.com:argoproj/argo-cd.git",
        "cloneUrl" : "https://github.com/argoproj/argo-cd.git",
        "owner" : {
          "login" : "argoproj",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 6209,
        "stargazersCount" : 20156,
        "watchersCount" : 20156,
        "size" : 138292,
        "openIssuesCount" : 3717,
        "subscribersCount" : 183,
        "pushedAt" : "2025-07-24T14:26:52Z",
        "languages" : {
          "CSS" : 2209,
          "Procfile" : 10164,
          "Makefile" : 25368,
          "Go" : 7193080,
          "Mustache" : 1066,
          "HTML" : 895,
          "TypeScript" : 1356519,
          "Dockerfile" : 15719,
          "Shell" : 61221,
          "Starlark" : 6864,
          "SCSS" : 98248,
          "JavaScript" : 6255,
          "Lua" : 261518
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "ArgoCD Notifications Controller should not spawn hundreds of connections to api.github.com without closing them, and instead, connections should be closed after a certain time or when no longer needed to prevent network performance issues.",
      "validationOrRequirement" : "The issue requires a way to set/override the default connection parameters, specifically MaxIdleConns, MaxIdleConnsPerHost, MaxConnsPerHost, and IdleConnTimeout, to prevent the accumulation of too many open connections.",
      "attemptedFixes" : "The discussion mentions customizing the http.Transport to control connection behavior, specifically setting parameters like MaxIdleConns, MaxIdleConnsPerHost, MaxConnsPerHost, and IdleConnTimeout.",
      "otherNotes" : "The issue is about ArgoCD Notifications Controller spawning hundreds of connections to api.github.com without ever closing them, leading to network performance issues. The proposal is to close older connections after a certain time or when no longer needed. The issue is labeled as an enhancement and good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406306
  }, {
    "issueDTO" : {
      "id" : 1988627601,
      "title" : "Copy to cliboard button doesn't indicate success of the copy ",
      "url" : "https://github.com/lockbook/lockbook/issues/2253",
      "repositoryName" : "lockbook/lockbook",
      "description" : "\r\n\r\n## Current behavior:\r\nWhen you click copy in settings > account nothing happens, the user is left to wonder if the copy worked or no  \r\n![image](https://github.com/lockbook/lockbook/assets/66345861/22815430-031e-44a2-a790-1b3f825d0b38)\r\n\r\n## ideal behavior \r\nWhen you click copy, a visual indicator will be displayed. For example you can change the text of the button from \"Copy to Clipboard\" to \"Copied\". \r\n![](https://www.daveabrock.com/content/images/2021/05/clipboard-success.gif)\r\n",
      "updatedAt" : 1753400615.000000000,
      "user" : "ad-tra",
      "userHtmlUrl" : "https://github.com/ad-tra",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/66345861?v=4",
      "labels" : [ "egui", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a visual indicator when the user successfully copies something to the clipboard.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the issue description.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description.",
      "otherNotes" : "The issue is related to the Copy to clipboard button in settings > account, and the expected behavior is that a visual indicator is displayed when the copy is successful.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406309
  }, {
    "issueDTO" : {
      "id" : 1061773542,
      "title" : "Propagate singularity bind points from initial docker command?",
      "url" : "https://github.com/neurodesk/neurodesktop/issues/67",
      "repositoryName" : "neurodesk/neurodesktop",
      "description" : "Trying to run a simg within neurodesktop but it seems the bind points from my initial Docker call (for an external drive) in Windows to neurodesktop don't propagate to singularity containers inside. \r\nWould be a nice feature to add to a startup script (i.e., bind all external drives in Docker call (if user wants)- propogate these bindpoints to transparent singularity or wherever the code is now?) ",
      "updatedAt" : 1753400536.000000000,
      "user" : "thomshaw92",
      "userHtmlUrl" : "https://github.com/thomshaw92",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/31721414?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This already works. We should quickly look at this together why it doesn't\nwork in your case :)\n\nOn Wed, Nov 24, 2021, 8:30 AM Thom Shaw ***@***.***> wrote:\n\n> Trying to run a simg within neurodesktop but it seems the bind points from\n> my initial Docker call (for an external drive) in Windows to neurodesktop\n> don't propagate to singularity containers inside.\n> Would be a nice feature to add to a startup script (i.e., bind all\n> external drives in Docker call (if user wants)- propogate these bindpoints\n> to transparent singularity or wherever the code is now?)\n>\n> ???\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/NeuroDesk/neurodesktop/issues/67>, or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AA6V2WZICXC2IZ3PLRDRXRTUNQIZFANCNFSM5IUTTUAQ>\n> .\n>\n", "running \r\n```\r\nPS C:\\Users\\thoma> docker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -v E:/STIMMRI_DATA/:/STIMMRI -p 8080:8080 -h neurodesktop-20211028 vnmd/neurodesktop:20211028  \r\n```\r\n\r\nThen inside neurodesktop in the fMRIPrep container:\r\n```\r\nSingularity> ls /STIMMRI\r\nls: cannot access '/STIMMRI': No such file or directory\r\n```", "Dear Tom,\r\n\r\ncan you try to mount the external drive to the mountpoint that we created for this use-case  :/data ?\r\n\r\nPS C:\\Users\\thoma> docker run --shm-size=1gb -it --privileged --name neurodesktop -v C:/neurodesktop-storage:/neurodesktop-storage -v E:/STIMMRI_DATA/:/data -p 8080:8080 -h neurodesktop-20211028 vnmd/neurodesktop:20211028  \r\n\r\nThe problem is that we need to create the mountpoints at buildtime, so we cannot easily add these at runtime.\r\n", "Ah yes that works... Does it cost us anything to automatically mount all drives and do this in an automatic way at startup? e.g., My external drives in E:/ and F:/ to /mnt/e and /mnt/f/ in neurodesktop?\r\n", "the problem is that the docker container doesn't know that E: and F: exists, so the startup script proposed in #64 needs to do this. It shouldn't be very difficult, but will need a bit of Powershell / bat magic by @thomshaw92 ", "Dear @thomshaw92 - did you get a chance to look at this already?" ],
      "repository" : {
        "description" : "The plug-and-play, browser-accessible, containerised data analysis environment.",
        "homepage" : "https://neurodesk.org",
        "name" : "neurodesktop",
        "fullName" : "neurodesk/neurodesktop",
        "htmlUrl" : "https://github.com/neurodesk/neurodesktop",
        "gitUrl" : "git://github.com/neurodesk/neurodesktop.git",
        "sshUrl" : "git@github.com:neurodesk/neurodesktop.git",
        "cloneUrl" : "https://github.com/neurodesk/neurodesktop.git",
        "owner" : {
          "login" : "neurodesk",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 48,
        "watchersCount" : 48,
        "size" : 10697,
        "openIssuesCount" : 14,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-24T17:26:18Z",
        "languages" : {
          "Dockerfile" : 15204,
          "Shell" : 33151,
          "Batchfile" : 475,
          "JavaScript" : 421,
          "Python" : 723
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Propagate singularity bind points from initial docker command to make it possible to automatically mount all drives and bind points to transparent singularity or wherever the code is now.",
      "validationOrRequirement" : "The user needs to manually mount the external drives, which is not a convenient solution. It would be a nice feature to add to a startup script to automatically mount all drives and bind points to transparent singularity or wherever the code is now.",
      "attemptedFixes" : "The user tried to mount the external drive to the mountpoint created for this use-case, but it didn't work. The problem is that the mountpoints need to be created at buildtime, so it's not possible to add them at runtime.",
      "otherNotes" : "The issue is about propagating bind points from initial Docker command to singularity containers. The problem is that the bind points are not propagated and the user needs to manually mount the external drives.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406315
  }, {
    "issueDTO" : {
      "id" : 2689711512,
      "title" : "Log URL redirecting to No XCom error",
      "url" : "https://github.com/apache/airflow/issues/44337",
      "repositoryName" : "apache/airflow",
      "description" : "### Apache Airflow version\r\n\r\nOther Airflow 2 version (please specify below)\r\n\r\n### If \"Other Airflow 2 version\" selected, which one?\r\n\r\n2.10.1\r\n\r\n### What happened?\r\n\r\nThe Log URL (`ti.log_url`) from the triggered retry email doesn't redirect to the Logs when clicked but instead shows 'No XCom' as the error in the Airflow UI. The Logs are shown when a time in future is selected as the `base_date` in the UI.\r\n\r\nBefore changing the base_date in the UI,\r\n\r\n![image](https://github.com/user-attachments/assets/6a4a2edd-a2c6-42ca-95d2-6315ba4acc48)\r\n\r\nAfter adding 1 second to the base_date in UI,\r\n\r\n![image](https://github.com/user-attachments/assets/7cc6af14-92f9-46e0-8ac8-7abc63abaf54)\r\n\r\n\r\n\r\n\r\n### What you think should happen instead?\r\n\r\nI think the issue might be due to milli seconds getting truncated which causes the difference between the execution datetime (untruncated) and the execution datetime rendered - `base_date` (truncated) in the `ti.log_url`\r\n\r\n### How to reproduce\r\n\r\nHere is the DAG to reproduce the issue,\r\n\r\n```\r\nfrom airflow.decorators import dag, task\r\nfrom datetime import datetime, timedelta\r\n\r\n@dag(\r\n    dag_id='default_email_on_retry_example',\r\n    schedule_interval='@once',\r\n    start_date=datetime(2023, 1, 1),\r\n    catchup=False,\r\n    default_args={\r\n        'email': ['your@email.com'],  \r\n        'email_on_retry': True,  \r\n        'email_on_failure': False,  \r\n    },\r\n)\r\ndef default_email_on_retry_dag():\r\n\r\n    @task\r\n    def success_task():\r\n        print(\"This task will always succeed!\")\r\n\r\n    @task(task_id='retry_task', retries=3, retry_delay=timedelta(seconds=15))\r\n    def retry_task():\r\n        print(\"This task will retry and fail.\")\r\n        raise Exception(\"Simulated task failure for retry.\")\r\n\r\n    success = success_task()\r\n    retry = retry_task()\r\n\r\n    success >> retry\r\n\r\ndefault_email_on_retry_dag()\r\n```\r\n\r\n![image](https://github.com/user-attachments/assets/b6394374-69cf-4d88-bc6d-6154e8ef9ecb)\r\n\r\nClick the Log `Link` from the email triggered by the DAG\r\n\r\n### Operating System\r\n\r\nLinux\r\n\r\n### Versions of Apache Airflow Providers\r\n\r\n_No response_\r\n\r\n### Deployment\r\n\r\nAmazon (AWS) MWAA\r\n\r\n### Deployment details\r\n\r\n_No response_\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit PR?\r\n\r\n- [ ] Yes I am willing to submit a PR!\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)\r\n",
      "updatedAt" : 1753400463.000000000,
      "user" : "sam-gen-cop",
      "userHtmlUrl" : "https://github.com/sam-gen-cop",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/182846498?v=4",
      "labels" : [ "kind:bug", "area:UI", "area:core", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for opening your first issue here! Be sure to follow the issue template! If you are willing to raise PR to address this issue please do so, no need to wait for approval.\n", "+1", "+1", "Hi @potiuk could you please assign the issue to me?", "+1 in 2025", "I tested it in 2.11.0 and it works as expected. It fails for 2.10.3, though - tested both locally today", "FYI I think this was fixed in [#50306](https://github.com/apache/airflow/pull/50306), and the fix is [available in 2.11](https://airflow.apache.org/docs/apache-airflow/2.11.0/release_notes.html#bug-fixes)." ],
      "repository" : {
        "description" : "Apache Airflow - A platform to programmatically author, schedule, and monitor workflows",
        "homepage" : "https://airflow.apache.org/",
        "name" : "airflow",
        "fullName" : "apache/airflow",
        "htmlUrl" : "https://github.com/apache/airflow",
        "gitUrl" : "git://github.com/apache/airflow.git",
        "sshUrl" : "git@github.com:apache/airflow.git",
        "cloneUrl" : "https://github.com/apache/airflow.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15362,
        "stargazersCount" : 41230,
        "watchersCount" : 41230,
        "size" : 419309,
        "openIssuesCount" : 1522,
        "subscribersCount" : 763,
        "pushedAt" : "2025-07-24T23:09:06Z",
        "languages" : {
          "Java" : 1443,
          "Jinja" : 76192,
          "CSS" : 15733,
          "Go" : 63158,
          "HTML" : 43330,
          "Jupyter Notebook" : 7288,
          "TypeScript" : 2168833,
          "HCL" : 3786,
          "Dockerfile" : 119789,
          "Shell" : 232889,
          "JavaScript" : 329955,
          "Mako" : 2684,
          "Python" : 42616717
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Log URL (ti.log_url) from the triggered retry email doesn't redirect to the Logs when clicked but instead shows 'No XCom' as the error in the Airflow UI.",
      "validationOrRequirement" : "Apache Airflow version 2.10.1, Linux operating system, Amazon (AWS) MWAA deployment, and the DAG to reproduce the issue is provided.",
      "attemptedFixes" : "The issue was tested in 2.11.0 and it works as expected. It fails for 2.10.3, though - tested both locally today. The fix is available in 2.11.",
      "otherNotes" : "The issue is related to Log URL redirecting to No XCom error, specifically when clicking on the Log URL from the triggered retry email in Airflow UI. The issue seems to be due to milli seconds getting truncated which causes the difference between the execution datetime (untruncated) and the execution datetime rendered - base_date (truncated) in the ti.log_url.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406322
  }, {
    "issueDTO" : {
      "id" : 1905762883,
      "title" : "editor export as rich text",
      "url" : "https://github.com/lockbook/lockbook/issues/2109",
      "repositoryName" : "lockbook/lockbook",
      "description" : "enables copy & paste to substack, google docs, confluence, etc",
      "updatedAt" : 1753400432.000000000,
      "user" : "tvanderstad",
      "userHtmlUrl" : "https://github.com/tvanderstad",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6198756?v=4",
      "labels" : [ "editor", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Enabling editor export as rich text",
      "validationOrRequirement" : "None mentioned",
      "attemptedFixes" : "No attempts or blockers mentioned",
      "otherNotes" : "The issue is about enabling copy & paste to substack, google docs, confluence, etc",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406324
  }, {
    "issueDTO" : {
      "id" : 1763876498,
      "title" : "latex support",
      "url" : "https://github.com/lockbook/lockbook/issues/1846",
      "repositoryName" : "lockbook/lockbook",
      "description" : "Render latex inline, similar to url images. Need to find a library to render as an image, then can re-use image render code to put it in the doc. Also need to find a way to get the markdown parser to tell me where the latex source text is and identify it as an element.",
      "updatedAt" : 1753400431.000000000,
      "user" : "tvanderstad",
      "userHtmlUrl" : "https://github.com/tvanderstad",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6198756?v=4",
      "labels" : [ "editor", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Render latex inline, similar to url images.",
      "validationOrRequirement" : "Need to find a library to render as an image, then can re-use image render code to put it in the doc. Also need to find a way to get the markdown parser to tell me where the latex source text is and identify it as an element.",
      "attemptedFixes" : "",
      "otherNotes" : "Need to find a library to render as an image, then can re-use image render code to put it in the doc. Also need to find a way to get the markdown parser to tell me where the latex source text is and identify it as an element.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406329
  }, {
    "issueDTO" : {
      "id" : 3261136847,
      "title" : "Toggle Button for curvy/square",
      "url" : "https://github.com/kubestellar/ui/issues/1633",
      "repositoryName" : "kubestellar/ui",
      "description" : "<img width=\"1437\" height=\"412\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/28fa41bd-8580-4beb-8b0e-cc2d0ee64b72\" />\n\nhere in this we can add a toggle button like dark/light mode similar for this curvy/square style. or it's css still be improved for better UX",
      "updatedAt" : 1753400385.000000000,
      "user" : "naman9271",
      "userHtmlUrl" : "https://github.com/naman9271",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/179296103?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@btwshivam !!", "<img width=\"207\" height=\"112\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/402d3780-ad0c-4244-a063-8aebcaedc949\" />\n\nalso in dark mode it is not clearly visible", "/assign", "@Nupurshivani #1397 this issue description might me be helpful to you" ],
      "repository" : {
        "description" : "KubeStellar's User Interface",
        "homepage" : "",
        "name" : "ui",
        "fullName" : "kubestellar/ui",
        "htmlUrl" : "https://github.com/kubestellar/ui",
        "gitUrl" : "git://github.com/kubestellar/ui.git",
        "sshUrl" : "git@github.com:kubestellar/ui.git",
        "cloneUrl" : "https://github.com/kubestellar/ui.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 148,
        "stargazersCount" : 56,
        "watchersCount" : 56,
        "size" : 8601,
        "openIssuesCount" : 108,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-24T21:23:12Z",
        "languages" : {
          "TypeScript" : 2560024,
          "Dockerfile" : 4363,
          "Shell" : 4960,
          "CSS" : 4768,
          "Makefile" : 7244,
          "JavaScript" : 5463,
          "Go" : 1176913,
          "HTML" : 345
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a toggle button for curvy/square style or improve the CSS for better UX.",
      "validationOrRequirement" : "The requirement is to add a toggle button for curvy/square style, similar to dark/light mode, or improve the CSS for better UX.",
      "attemptedFixes" : "No specific attempted fixes are mentioned in the issue description or comments.",
      "otherNotes" : "The issue description includes an image and a mention of improving the UX. In a comment, @btwshivam is tagged and an image is attached. Another comment mentions the issue description might be helpful and assigns @Nupurshivani to the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406333
  }, {
    "issueDTO" : {
      "id" : 2963906340,
      "title" : "[OpenAPI] Cannot skip SecurityScheme for controllers with [AllowAnonymous]",
      "url" : "https://github.com/dotnet/aspnetcore/issues/61264",
      "repositoryName" : "dotnet/aspnetcore",
      "description" : "### Is there an existing issue for this?\n\n- [x] I have searched the existing issues\n\n### Describe the bug\n\nhttps://learn.microsoft.com/en-us/aspnet/core/fundamentals/openapi/customize-openapi?view=aspnetcore-9.0\n\ndocumentation shows you can do something like this\n\n    internal sealed class BearerSecuritySchemeTransformer(IAuthenticationSchemeProvider authenticationSchemeProvider) : IOpenApiDocumentTransformer\n    {\n        public async Task TransformAsync(OpenApiDocument document, OpenApiDocumentTransformerContext context, CancellationToken cancellationToken)\n        {\n            var authenticationSchemes = await authenticationSchemeProvider.GetAllSchemesAsync();\n            if (authenticationSchemes.Any(authScheme => authScheme.Name == \"Bearer\"))\n            {\n                // Add the security scheme at the document level\n                var requirements = new Dictionary<string, OpenApiSecurityScheme>\n                {\n                    [\"Bearer\"] = new OpenApiSecurityScheme\n                    {\n                        Type = SecuritySchemeType.Http,\n                        Scheme = \"bearer\", // \"bearer\" refers to the header name here\n                        In = ParameterLocation.Header,\n                        BearerFormat = \"Json Web Token\"\n                    }\n                };\n                document.Components ??= new OpenApiComponents();\n                document.Components.SecuritySchemes = requirements;\n\n                // Apply it as a requirement for all operations\n                foreach (var operation in document.Paths.Values.SelectMany(path => path.Operations))\n                {\n                    operation.Value.Security.Add(new OpenApiSecurityRequirement\n                    {\n                        [new OpenApiSecurityScheme { Reference = new OpenApiReference { Id = \"Bearer\", Type = ReferenceType.SecurityScheme } }] = Array.Empty<string>()\n                    });\n                }\n            }\n        }\n    }\n\nWhich applies the security schema for all the endpoints, but it doesnt show a way to skip the endpoints or controllers that have the AllowAnonymousAttribute applied\n\nfor now the only workaround I have found is by using Tags, but it is a little hacky.\n\n    internal sealed class BearerSecuritySchemeTransformer(\n        IAuthenticationSchemeProvider authenticationSchemeProvider\n    ) : IOpenApiDocumentTransformer\n    {\n        private const string SecuritySchemeName = \"Bearer\";\n        private const string AnonymousTagName = \"Anonymous\";\n\n        public async Task TransformAsync(\n            OpenApiDocument document,\n            OpenApiDocumentTransformerContext context,\n            CancellationToken cancellationToken\n        )\n        {\n            var authenticationSchemes = await authenticationSchemeProvider.GetAllSchemesAsync();\n            bool hasBearerScheme = authenticationSchemes.Any(authScheme => authScheme.Name == SecuritySchemeName);\n\n            if (hasBearerScheme)\n            {\n                document.Components ??= new OpenApiComponents();\n                document.Components.SecuritySchemes ??= new Dictionary<string, OpenApiSecurityScheme>();\n\n                // Only add if it doesn't exist - avoid conflicts if multiple transformers run\n                if (!document.Components.SecuritySchemes.ContainsKey(SecuritySchemeName))\n                {\n                    document.Components.SecuritySchemes.Add(SecuritySchemeName, new OpenApiSecurityScheme\n                    {\n                        Type = SecuritySchemeType.Http,\n                        Scheme = \"bearer\",\n                        BearerFormat = \"JWT\",\n                        Name = \"Authorization\",\n                        In = ParameterLocation.Header,\n                    });\n                }\n            }\n\n            // Remove Anonymous tag from the tags collection if it exists\n            var anonymousTag = document.Tags.FirstOrDefault(t => t.Name == AnonymousTagName);\n            if (anonymousTag != null)\n            {\n                document.Tags.Remove(anonymousTag);\n            }\n\n            foreach (var path in document.Paths.Values)\n            {\n                foreach (var operation in path.Operations)\n                {\n                    // Check if operation has Anonymous tag\n                    var anonymousTagInOperation = operation.Value.Tags.FirstOrDefault(t => t.Name == AnonymousTagName);\n\n                    if (anonymousTagInOperation != null)\n                    {\n                        // Remove Anonymous tag from the operation\n                        operation.Value.Tags.Remove(anonymousTagInOperation);\n\n                        // Skip adding security requirement\n                        continue;\n                    }\n\n                    // Add security requirement for non-anonymous operations\n                    operation.Value.Security.Add(new OpenApiSecurityRequirement\n                    {\n                        [new OpenApiSecurityScheme\n                        {\n                            Reference = new OpenApiReference\n                            {\n                                Id = SecuritySchemeName,\n                                Type = ReferenceType.SecurityScheme\n                            }\n                        }] = Array.Empty<string>()\n                    });\n                }\n            }\n        }\n    }\n\n\n\n### Expected Behavior\n\nPlease show an example on how to skip security requirements for controllers / endpoints that have the AllowAnonymousAttribute applied\n\nThanks. \n\n### Steps To Reproduce\n\nThe steps to repro the issue are at https://learn.microsoft.com/en-us/aspnet/core/fundamentals/openapi/customize-openapi?view=aspnetcore-9.0#use-document-transformers\n\n### Exceptions (if any)\n\n_No response_\n\n### .NET Version\n\n9.0.104\n\n### Anything else?\n\n_No response_",
      "updatedAt" : 1753400294.000000000,
      "user" : "DavidNorena",
      "userHtmlUrl" : "https://github.com/DavidNorena",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/26279057?v=4",
      "labels" : [ "area-minimal", "help wanted", "Docs", "feature-openapi", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @DavidNorena,\n\nIf you like to skip certain endpoints, I'd recommend using an operation transformer instead of a document transformer. In the `OpenApiOperationTransformerContext` you have access to all attributes of the endpoint. You could check out [this code](https://github.com/xC0dex/APIWeaver/blob/main/src/APIWeaver.OpenApi/Extensions/OpenApiOperationTransformerContextExtensions.cs). It shows and extension method `HasAuthorizationAsync()` which is used [here](https://github.com/xC0dex/APIWeaver/blob/main/src/APIWeaver.OpenApi/Extensions/OpenApiOptionsExtensions.cs#L120). This method checks for existing attributes to determine if a security requirement should be added to an operation.", "@xC0dex  thanks a lot for your comment, do you think this should be documented somehow ?\n\nSeems not to be a bug in OpenAPI package but a lack of documentation\n\nI tested your implementation and works very well thanks a lot for your reply", "@DavidNorena PR on the docs repo is welcome if you'd like to share your solution with the community.", "Looks like this issue has been identified as a candidate for community contribution. If you're considering sending a PR for this issue, look for the `Summary Comment` link in the issue description. That comment has been left by an engineer on our team to help you get started with handling this issue. You can learn more about our Help Wanted process [here](https://aka.ms/aspnet/processes/help-wanted)\n<!-- Policy app identification https://img.shields.io/static/v1?label=PullRequestIssueManagement. -->" ],
      "repository" : {
        "description" : "ASP.NET Core is a cross-platform .NET framework for building modern cloud-based web applications on Windows, Mac, or Linux.",
        "homepage" : "https://asp.net",
        "name" : "aspnetcore",
        "fullName" : "dotnet/aspnetcore",
        "htmlUrl" : "https://github.com/dotnet/aspnetcore",
        "gitUrl" : "git://github.com/dotnet/aspnetcore.git",
        "sshUrl" : "git@github.com:dotnet/aspnetcore.git",
        "cloneUrl" : "https://github.com/dotnet/aspnetcore.git",
        "owner" : {
          "login" : "dotnet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 10410,
        "stargazersCount" : 36899,
        "watchersCount" : 36899,
        "size" : 366275,
        "openIssuesCount" : 3789,
        "subscribersCount" : 1434,
        "pushedAt" : "2025-07-25T00:15:26Z",
        "languages" : {
          "C#" : 60644415,
          "PowerShell" : 317972,
          "Java" : 568974,
          "C++" : 1244944,
          "CSS" : 104309,
          "C" : 124045,
          "CMake" : 14853,
          "HTML" : 1673332,
          "TypeScript" : 1178863,
          "Dockerfile" : 423,
          "Shell" : 181419,
          "Batchfile" : 26222,
          "SCSS" : 12,
          "JavaScript" : 175738,
          "Lua" : 4904,
          "ASP.NET" : 109,
          "F#" : 6234,
          "Less" : 12,
          "Python" : 13176
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Skip security requirements for controllers/endpoints that have the AllowAnonymousAttribute applied.",
      "validationOrRequirement" : "Controllers/endpoints should have the AllowAnonymousAttribute applied to skip security requirements.",
      "attemptedFixes" : "A workaround is to use Tags, and a comment suggests using an operation transformer instead of a document transformer to achieve this.",
      "otherNotes" : "The issue is about skipping security requirements for controllers/endpoints that have the AllowAnonymousAttribute applied, and the workaround is to use Tags, but it's a little hacky. A comment suggests using an operation transformer instead of a document transformer to achieve this.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406337
  }, {
    "issueDTO" : {
      "id" : 1910347607,
      "title" : "support lockbook links on windows",
      "url" : "https://github.com/lockbook/lockbook/issues/2119",
      "repositoryName" : "lockbook/lockbook",
      "description" : null,
      "updatedAt" : 1753400255.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "egui", "windows", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Read through the [lnk standard](https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-shllink/16cb4ca1-9339-4d0c-a68d-bf1d6cc0f943) and I don't think it directly supports what we want, but someone should confirm." ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "support lockbook links on Windows",
      "validationOrRequirement" : "confirmation of lnk standard support",
      "attemptedFixes" : "none",
      "otherNotes" : "Read through the lnk standard and I don't think it directly supports what we want, but someone should confirm.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406340
  }, {
    "issueDTO" : {
      "id" : 1910347773,
      "title" : "support handling lockbook links on linux",
      "url" : "https://github.com/lockbook/lockbook/issues/2120",
      "repositoryName" : "lockbook/lockbook",
      "description" : "Could be part of the `.desktop` file.",
      "updatedAt" : 1753400249.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "linux", "egui", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support handling lockbook links on Linux",
      "validationOrRequirement" : "Part of the .desktop file",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to handling lockbook links on Linux, which could be part of the .desktop file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406342
  }, {
    "issueDTO" : {
      "id" : 3043123452,
      "title" : "Remove redundant type aliases of _device for torch.Device",
      "url" : "https://github.com/pytorch/pytorch/issues/152952",
      "repositoryName" : "pytorch/pytorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nWe should remove redundant type aliases for `_device_t` and replace with `torch.types.Device` where appropriate to make the typing system a bit more consistent. \n\n#152935 is a good step in that direction\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753400205.000000000,
      "user" : "Skylion007",
      "userHtmlUrl" : "https://github.com/Skylion007",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2053727?v=4",
      "labels" : [ "triaged", "actionable", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @Skylion007, I???m working on this issue and will submit a PR once the changes are complete. I???ll keep you updated.", "@Skylion007,\n\nI have a quick question regarding the task of replacing _device_t with torch.types.Device. I understand that the goal is to remove the redundant type alias _device_t and use torch.types.Device consistently throughout the codebase.\n\nTo clarify:\n\nDo I need to replace every occurrence of _device_t with torch.types.Device across all files in the PyTorch repository, including headers and source files? Or are there specific files or areas where the replacement is necessary?\n\nThank you for your guidance!", "Hi @Skylion007 @drisspg, I have a question. While replacing _device_t, I noticed that it also appears in the file ./torch/_dynamo/device_interface.py . Should I replace those instances as well? The reason I am asking is,  _device_t was already replaced in that file in the issue number (#152935) by galexite, and it is still in the process of being merged. Since I am new to this, I would appreciate your guidance.\n\nThank you!", "Can I take up this issue? ", "@bigachin I am already working on it.", "Is this issue closed with  [f58143b](https://github.com/pytorch/pytorch/commit/f58143b945538397be8d7adf0b8be29cacdc8bdc) ?   @shink ", "Hi, can. work on this issue? First time contributing to pytorch", "@Skylion007 this won't be closed until, all `_device_t` are changed to `torch.types.Device`. right?", "I would like to work on this issue." ],
      "repository" : {
        "description" : "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
        "homepage" : "https://pytorch.org",
        "name" : "pytorch",
        "fullName" : "pytorch/pytorch",
        "htmlUrl" : "https://github.com/pytorch/pytorch",
        "gitUrl" : "git://github.com/pytorch/pytorch.git",
        "sshUrl" : "git@github.com:pytorch/pytorch.git",
        "cloneUrl" : "https://github.com/pytorch/pytorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 24761,
        "stargazersCount" : 91742,
        "watchersCount" : 91742,
        "size" : 1083834,
        "openIssuesCount" : 16648,
        "subscribersCount" : 1786,
        "pushedAt" : "2025-07-25T00:47:06Z",
        "languages" : {
          "C" : 1827350,
          "GDB" : 653,
          "CMake" : 817716,
          "Makefile" : 12990,
          "HTML" : 384,
          "Metal" : 314357,
          "Jupyter Notebook" : 186191,
          "Shell" : 444379,
          "JavaScript" : 92859,
          "Objective-C" : 58643,
          "Assembly" : 336439,
          "Python" : 73135317,
          "GLSL" : 204578,
          "Thrift" : 7059,
          "PowerShell" : 7509,
          "Smarty" : 376,
          "Java" : 87332,
          "C++" : 42371695,
          "Objective-C++" : 1377512,
          "HIP" : 287193,
          "Cuda" : 3678398,
          "Dockerfile" : 33907,
          "Starlark" : 329858,
          "Batchfile" : 78530,
          "Linker Script" : 473,
          "Vim Script" : 154
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove redundant type aliases for `_device_t` and replace them with `torch.types.Device` to make the typing system more consistent.",
      "validationOrRequirement" : "Replace every occurrence of `_device_t` with `torch.types.Device` across all files in the PyTorch repository, including headers and source files, unless specifically mentioned otherwise.",
      "attemptedFixes" : "The issue is not fully closed yet, as there are still instances of `_device_t` that need to be replaced. The commit [f58143b](https://github.com/pytorch/pytorch/commit/f58143b945538397be8d7adf0b8be29cacdc8bdc) is mentioned as a related issue.",
      "otherNotes" : "The issue is about removing redundant type aliases for `_device_t` and replacing them with `torch.types.Device` to make the typing system more consistent. There are questions and clarifications regarding the scope of replacement and specific files that need to be updated.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406348
  }, {
    "issueDTO" : {
      "id" : 1806397901,
      "title" : "export { md / svg } to { pdf, png, html, rtf }",
      "url" : "https://github.com/lockbook/lockbook/issues/1928",
      "repositoryName" : "lockbook/lockbook",
      "description" : "+ [ ] apple\n+ [ ] egui\n+ [ ] android",
      "updatedAt" : 1753400006.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "apple", "editor", "request", "canvas", "pdf", "android", "egui", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Requested by @MehrotraRahul\r\nRequested by @smailbarkouch \r\nRequested by @ad-tra \r\nRequested by @mahakanakala", "use case justification:\r\n+ pdf -- emails to normies\r\n+ png -- more universally accepted drawing format\r\n+ html -- blogs\r\n+ rtf -- paste into google docs / confluence [possible dupe](https://github.com/lockbook/lockbook/issues/2109)", "https://discord.com/channels/1014184997751619664/1026211549678936214/1297023224118378556" ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "export { md / svg } to { pdf, png, html, rtf }",
      "validationOrRequirement" : "none mentioned",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "use case justification: pdf -- emails to normies, png -- more universally accepted drawing format, html -- blogs, rtf -- paste into google docs / confluence, [possible dupe](https://github.com/lockbook/lockbook/issues/2109), https://discord.com/channels/1014184997751619664/1026211549678936214/1297023224118378556",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406352
  }, {
    "issueDTO" : {
      "id" : 2141469495,
      "title" : "integrate fs into linux",
      "url" : "https://github.com/lockbook/lockbook/issues/2506",
      "repositoryName" : "lockbook/lockbook",
      "description" : null,
      "updatedAt" : 1753399985.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "lbfs", "linux", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Integrate fs into Linux",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the issue.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue.",
      "otherNotes" : "No description provided, but the issue is labeled as a 'good first issue' and is related to Linux and fs integration.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406355
  }, {
    "issueDTO" : {
      "id" : 2127458828,
      "title" : "pdf from source",
      "url" : "https://github.com/lockbook/lockbook/issues/2417",
      "repositoryName" : "lockbook/lockbook",
      "description" : "Presently we use [static](https://github.com/paulocoutinhox/pdfium-lib) & [dynamic](https://github.com/bblanchon/pdfium-binaries) binaries. \r\n\r\nOur target state has us building these from source in a portable & static way.\r\n\r\nBonus points for supporting converting to vector formats (instead of rasterized formats).\r\n\r\nReasons for svg:\r\n+ primarily infinite zoom\r\n+ interesting opportunities with our canvas",
      "updatedAt" : 1753399982.000000000,
      "user" : "Parth",
      "userHtmlUrl" : "https://github.com/Parth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/821972?v=4",
      "labels" : [ "security", "pdf", "infra", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "We considered many approaches including pdf-rs but the only one which seems to have the _expected_ rendering of pdfs was \n- mupdf, a C library\n- poppler, what gnome uses\n- pdfium, what chrome uses\n\nI think something like this: https://fasterthanli.me/series/dont-shell-out (completely static binary, using the cc crate) with vendored C source code is probably our target state. ", "Looks like someone is giving this a go: https://github.com/messense/mupdf-rs/blob/main/mupdf-sys/build.rs", "@steverusso's prior attempt: https://github.com/lockbook/doc-conv/blob/steve-use-mupdf-to-convert-to-svg/pdfconv.c", "These are the thigns i need to make pdf to SVG \n\n_**Core Header:**_   fitz.h ??? the primary interface to MuPDF's functionality.\n\n**_Core Structures:_**\n\n- fz_context ??? manages the rendering context.\n- fz_document ??? represents the loaded PDF document.\n- fz_page ??? represents a single page of the document.\n- fz_device ??? the output device, in this case, an SVG device.\n- fz_output ??? manages the output stream for the SVG content.\n\n**_Functions:_**\n\n- fz_new_context() ??? initializes the MuPDF context.\n- fz_register_document_handlers() ??? registers document formats.\n- fz_open_document() ??? opens the PDF file.\n- fz_load_page() ??? loads a specific page.\n- fz_bound_page() ??? retrieves the page dimensions.\n- fz_new_output_with_path() ??? creates an output stream for the SVG file.\n- fz_new_svg_device() ??? creates an SVG output device.\n- fz_drop_*() ??? functions to release resources.\n\n\nMeaning that I can use mupdf/fitz.h for the first runs or iteration of the creation of the code, and after, I can attempt to shorten it down more to using only the required core structures and functions to make it as lightweight as possible.\n\nFirst try is this, but having some issue, will tell the fix on the issues when they are fixed \nhttps://github.com/Kjets22/pdf-from-source", "This is great! The only potential problem I see in the code is that you are opening a file, if you can tweak the implementation so that mupdf is operating in terms of binary data (and you're opening the file in C code and reading it yourself) it would probably be closer to how things will work in lockbook.\n\nI'm also curious how you build and run the code you linked to, do you just have the mu-pdf binaries installed on your machine? Not a problem during this prototyping phase, just curious. Installing the binaries directly will hide some potential struggles down the road, but it may not if mupdf is high quality.", "I am currently struggling to run the code, which is my biggest hurdle. I am really struggling to get Mudpf dependencies to work. Right now, I am asking chat and looking online for a solution, but have not found one.", "Did you see this prior attempt: https://github.com/lockbook/doc-conv/tree/steve-use-mupdf-to-convert-to-svg\n\nThere is a `build` file in there which may help point you in the right direction.\n\nI can't tell for sure but it suggests to me that mupdf was cloned and placed alongside this `build` script and compiled from source. @steverusso is that a safe assumption?", "https://mupdf.readthedocs.io/en/latest/quick-start-guide.html\n\nlooking at how approachable this is, feels like a safe bet. Down to hop on a call whenever you want if you encounter trouble getting that to work.", "> I can't tell for sure but it suggests to me that mupdf was cloned and placed alongside this `build` script and compiled from source. [@steverusso](https://github.com/steverusso) is that a safe assumption?\n\nPretty sure yes because of `-Lmupdf/build/release` in the build script." ],
      "repository" : {
        "description" : "Encrypted notebook",
        "homepage" : "https://lockbook.net",
        "name" : "lockbook",
        "fullName" : "lockbook/lockbook",
        "htmlUrl" : "https://github.com/lockbook/lockbook",
        "gitUrl" : "git://github.com/lockbook/lockbook.git",
        "sshUrl" : "git@github.com:lockbook/lockbook.git",
        "cloneUrl" : "https://github.com/lockbook/lockbook.git",
        "owner" : {
          "login" : "lockbook",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 192,
        "watchersCount" : 192,
        "size" : 119753,
        "openIssuesCount" : 325,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T19:52:13Z",
        "languages" : {
          "Java" : 9370,
          "CSS" : 6037,
          "C++" : 265,
          "Rust" : 2831998,
          "C" : 62,
          "CMake" : 1838,
          "Makefile" : 1745,
          "HTML" : 22203,
          "Kotlin" : 278482,
          "Shell" : 10862,
          "RenderScript" : 1,
          "JavaScript" : 3707,
          "Swift" : 404354,
          "Nix" : 2075
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to build pdf from source in a portable and static way, with the ability to convert the resulting pdf to a vector format like SVG.",
      "validationOrRequirement" : "The issue requires the ability to build pdf from source in a portable and static way, and to convert the resulting pdf to a vector format like SVG. The author has also mentioned the need to support infinite zoom and interesting opportunities with the canvas.",
      "attemptedFixes" : "The author has tried using mupdf, poppler, and pdfium libraries, and has attempted to build the code using the cc crate. There is also a prior attempt by @steverusso to use mupdf to convert to SVG, which is being referenced.",
      "otherNotes" : "The issue is about building pdf from source in a portable and static way, with the goal of converting to vector formats like SVG instead of rasterized formats. The author has tried using mupdf, poppler, and pdfium libraries, and is currently struggling to run the code due to issues with mupdf dependencies.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406362
  }, {
    "issueDTO" : {
      "id" : 3259946031,
      "title" : "Using keyword arguments to create Rects does not work.",
      "url" : "https://github.com/pygame-community/pygame-ce/issues/3539",
      "repositoryName" : "pygame-community/pygame-ce",
      "description" : "I was hesitant to come here, as this is my first time opening an issue on a GitHub project, but I think reporting this (even though you're already aware of it) could improve the experience for a PyGame noob when the bug is fixed (if it actually is one).\n\nI'm talking about using keyword arguments to create Rects using `pygame.Rect`.\n\n```\nbutton: pygame.Rect = pygame.Rect((100, 100, 200, 50))\n```\n^ The above code works perfectly\n\n```\nbutton: pygame.Rect = pygame.Rect(single_arg=(100, 100, 200, 50))\n```\n^ This doesn't work, when I try to draw the Rect using `pygame.draw.rect`, nothing is drawn on the screen. It's weird, I don't think it's supposed to work like that. The same behavior is observed when using `(left=*, top=*, width=* height=*)` or `(left_top=*, width_height=*)`.\n\nUpdate (as of this writing): The Rect is clearly created when I use print to check, but all of its information is reset. `print(button)` returns `Rect(0, 0, 0, 0)`.\n\nI have no idea if other pygame functions have the same behavior. I apologize if I'm accidentally duplicating an existing issue. I can provide more information about the executed code if needed. I hope this helps!\n\n`pygame.print_debug_info()` below:\n\n```\nPlatform:               Windows-10-10.0.19045-SP0\nSystem:                 Windows\nSystem Version:         10.0.19045\nProcessor:              Intel64 Family 6 Model 158 Stepping 10, GenuineIntel        SSE2: Yes       AVX2: Yes   NEON: No\nArchitecture:           Bits: 64bit     Linkage: WindowsPE\n\nPython:                 CPython 3.13.4 (tags/v3.13.4:8a526ec, Jun  3 2025, 17:46:04) [MSC v.1943 64 bit (AMD64)]\nGIL Enabled:            True\npygame version:         2.5.5\nSDL versions:           Linked: 2.32.6  Compiled: 2.32.6\nSDL Mixer versions:     Linked: 2.8.1   Compiled: 2.8.1\nSDL Font versions:      Linked: 2.24.0  Compiled: 2.24.0\nSDL Image versions:     Linked: 2.8.8   Compiled: 2.8.8\nFreetype versions:      Linked: 2.11.1  Compiled: 2.11.1\n\nDisplay Driver:         windows\nMixer Driver:           wasapi\n```",
      "updatedAt" : 1753399942.000000000,
      "user" : "Lirhio",
      "userHtmlUrl" : "https://github.com/Lirhio",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/162835877?v=4",
      "labels" : [ "rect", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "It's positional-only, that's why.\n\nThe stub for it could be improved to indicate this fact. Kwarg parsing is very slow, and rect creation needs to be as fast as possible.", "Thanks for the report!", "Aaah, so that's it. Thank you very much for the clarification! :D. In that case, I'll just close the issue. I think it's fine this way.", "Reopening because of the aforementioned stub issue", "Cool, sry about that." ],
      "repository" : {
        "description" : "\uD83D\uDC0D\uD83C\uDFAE pygame - Community Edition is a FOSS Python library for multimedia applications (like games). Built on top of the excellent SDL library.",
        "homepage" : "https://pyga.me",
        "name" : "pygame-ce",
        "fullName" : "pygame-community/pygame-ce",
        "htmlUrl" : "https://github.com/pygame-community/pygame-ce",
        "gitUrl" : "git://github.com/pygame-community/pygame-ce.git",
        "sshUrl" : "git@github.com:pygame-community/pygame-ce.git",
        "cloneUrl" : "https://github.com/pygame-community/pygame-ce.git",
        "owner" : {
          "login" : "pygame-community",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 194,
        "stargazersCount" : 1242,
        "watchersCount" : 1242,
        "size" : 45170,
        "openIssuesCount" : 414,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-24T08:55:27Z",
        "languages" : {
          "C++" : 61145,
          "Shell" : 31171,
          "C" : 3490010,
          "Meson" : 29899,
          "Makefile" : 5259,
          "Cython" : 116595,
          "Python" : 2802160
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to create Rects using keyword arguments in pygame without any issues or reset of information.",
      "validationOrRequirement" : "The issue is related to the creation of Rects using keyword arguments in pygame. The Rect should be created with the correct information.",
      "attemptedFixes" : "The issue is already known and the author is aware of it. The author has also mentioned that the issue is related to the slow parsing of keyword arguments.",
      "otherNotes" : "The issue is related to the creation of Rects using keyword arguments in pygame, where it does not work as expected. The Rect is created but its information is reset. The issue is also related to the slow parsing of keyword arguments.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406367
  }, {
    "issueDTO" : {
      "id" : 3047190321,
      "title" : "Identify and Fix Broken Links in README.md",
      "url" : "https://github.com/chaoss/augur/issues/3152",
      "repositoryName" : "chaoss/augur",
      "description" : "# Replication issue\nOn the README.md click on [8knot](https://github.com/oss-aspen/8kno)\n\n# Task\nUpdate the broken link [8knot](https://github.com/oss-aspen/8kno) with the correct [8knot](https://github.com/oss-aspen/8knot)\n\n# Improvement \nImplement a GitHub Action to automate the identification of broken links in the project's documentation.\n\n# Reason\nRegularly checking for broken links helps maintain the quality and reliability of documentation, ensuring users have access to accurate resources.\n\n# Benefit\nAutomating the detection of broken links ensures a better user experience, saves time for maintainers, and enhances project credibility and trust.",
      "updatedAt" : 1753399919.000000000,
      "user" : "CyrilBaah",
      "userHtmlUrl" : "https://github.com/CyrilBaah",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82481611?v=4",
      "labels" : [ "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @CyrilBaah,\nI???d like to work on this issue. I can start by identifying and fixing the broken 8knot link in the README.md, and then work on adding a GitHub Action to automate broken link checks in the documentation.\n\nPlease let me know if I can proceed. Thanks!", "I have added a job in workflow using lychee to solve the issue #3152, which will check if there is any broken link in README.md. Please review my PR. " ],
      "repository" : {
        "description" : "Python library and web service for Open Source Software Health and Sustainability metrics & data collection. You can find our documentation and new contributor information easily here: https://oss-augur.readthedocs.io/en/main/   ",
        "homepage" : "https://oss-augur.readthedocs.io/en/main/",
        "name" : "augur",
        "fullName" : "chaoss/augur",
        "htmlUrl" : "https://github.com/chaoss/augur",
        "gitUrl" : "git://github.com/chaoss/augur.git",
        "sshUrl" : "git@github.com:chaoss/augur.git",
        "cloneUrl" : "https://github.com/chaoss/augur.git",
        "owner" : {
          "login" : "chaoss",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 895,
        "stargazersCount" : 640,
        "watchersCount" : 640,
        "size" : 175705,
        "openIssuesCount" : 157,
        "subscribersCount" : 21,
        "pushedAt" : "2025-07-25T00:01:46Z",
        "languages" : {
          "Dockerfile" : 5884,
          "Jinja" : 135253,
          "Shell" : 42516,
          "CSS" : 13846,
          "PLpgSQL" : 1595488,
          "Makefile" : 5957,
          "JavaScript" : 655,
          "HTML" : 5230,
          "Mako" : 494,
          "Python" : 2335188
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to identify and fix broken links in README.md and implement a GitHub Action to automate the identification of broken links in the project's documentation.",
      "validationOrRequirement" : "The broken link [8knot](https://github.com/oss-aspen/8kno) needs to be updated with the correct [8knot](https://github.com/oss-aspen/8knot), and a GitHub Action needs to be implemented to automate the identification of broken links in the project's documentation.",
      "attemptedFixes" : "A job in workflow using lychee to solve the issue #3152 has been added to check if there is any broken link in README.md.",
      "otherNotes" : "The issue is about identifying and fixing broken links in README.md, and also implementing a GitHub Action to automate the identification of broken links in the project's documentation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406372
  }, {
    "issueDTO" : {
      "id" : 2526045874,
      "title" : "Support `jars.extra.classpath` in the Manifest editory to avoid confusion with `additional.bundles`",
      "url" : "https://github.com/eclipse-pde/eclipse.pde/issues/1407",
      "repositoryName" : "eclipse-pde/eclipse.pde",
      "description" : "Currently there is no UI support for `jars.extra.classpath` in the Manifest editor and du to its prominent placing people instead use often `additional.bundles` to add something that should be there for compile but not imported ([what serves a different purpose](https://help.eclipse.org/latest/index.jsp?topic=%2Forg.eclipse.pde.doc.user%2Fguide%2Ftools%2Feditors%2Fmanifest_editor%2Feditor.htm)) [leading to confusion](https://github.com/eclipse-pde/eclipse.pde/issues/1403).\r\n\r\nEven though `jars.extra.classpath` theoretically supports different styles, we should only support the form where one can specify a single bundle `platform:/plugin/<Bundle-SymbolicName>` as this is also supported by Tycho and easy to adapt by other tools.",
      "updatedAt" : 1753399840.000000000,
      "user" : "laeubi",
      "userHtmlUrl" : "https://github.com/laeubi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1331477?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This is a good idea.\r\n\r\nI'm not suggesting one needs to make things more complicated so this is just an FYI...\r\n\r\nThe scheme generally supports\r\n```\r\nplatform:/plugins/<bsn>_<version>/\r\n```\r\nas parsed by `org.eclipse.core.internal.boot.PlatformURLConnection.parse(String)`.", "> The scheme generally supports\r\n\r\nOfficially also relative path is supported as well as inner jars:\r\n\r\n> extra classpaths used to perform automated build. Classpath can either be relative paths, or platform urls referring to plug-ins and fragments of your development environment (e.g. ../someplugin/xyz.jar, platform:/plugins/org.apache.ant/ant.jar). Platform urls are recommended over relative paths;\r\n\r\nI just think that if one really requires a version or relative path one can do it manually, but e.g additional bundles do only support a BSN and people seem happy with that already (but using it for a different purpose).", "I 100% agree to keep this simple for the common case!", "I'm working on this.", "> I'm working on this.\r\n\r\nGreat. You are one of the students from CodeDays, aren't you?\r\n\r\nMuch success on this task and don't hesitate to ask for help if you need any.", "Thank you, yes I am from CodeDay. I wanted to reach out for clarification. In build configuration I am able to add jars by using Extra ClassPath Entries and using the add Jars feature, is there anything specific you wanted on top of having this available in the build section?\r\n", "> In build configuration I am able to add jars by using Extra ClassPath Entries and using the add Jars feature, is there anything specific you wanted on top of having this available in the build section?\r\n\r\nIndeed there is already some UI support in the `Build` section:\r\n![grafik](https://github.com/user-attachments/assets/6211ccc8-a9ee-4cc8-807e-514d5e0f6445)\r\n\r\nAnd it even seems to handle relative and 'absolute' URLs properly already.\r\n\r\nSo maybe we should just move it to the `Dependencies` section, maybe below the `Automated Management of Dependencies` to make it more visible?\r\n@laeubi or @merks any remarks from your side?", "Do what you think best. ", "> Indeed there is already some UI support in the Build section\r\n\r\nI never noticed that, its interesting how many features PDE has people often just don't recognize :-D\r\n\r\n> So maybe we should just move it to the Dependencies section, maybe below the Automated Management of Dependencies to make it more visible?\r\n\r\nI think the first thing should be to make it **expanded by default** currently it is simply to easy to overlook, beside from that I think it makes sense to have it in the \"build\" section because it is related to the `build.properties`.\r\n\r\nNext I think we should add a link in the description of the \"Automated Management of Dependencies\" with a link that jumps to that tab, that should be enough for people to discover it, if we then also add a N&N entry for that change it should be enough.\r\n\r\n> And it even seems to handle relative and 'absolute' URLs properly already.\r\n\r\nI think it currently does not work as expected (for me), e.g. it only allows to add *inner jars* from workspace projects, it should also allow to add bundles (either from workspace or target platform) so that needs to be improved to be useful.\r\n\r\nIf we then have a way to even mark some of them as test-only that would probably already help with  \r\n- https://github.com/eclipse-pde/eclipse.pde/pull/914\r\n\r\nbut that's a different topic of course.", "> > So maybe we should just move it to the Dependencies section, maybe below the Automated Management of Dependencies to make it more visible?\r\n> \r\n> I think the first thing should be to make it **expanded by default** currently it is simply to easy to overlook, beside from that I think it makes sense to have it in the \"build\" section because it is related to the `build.properties`.\r\n\r\nWith https://github.com/eclipse-pde/eclipse.pde/pull/1469, the section is now expanded by default, thanks to @anviik.", "Great so next step would be that it allows to select **any bundle** from the target platform, if that is in place we should  add this to the N&N to make people more aware about this \"new\" way of specify compile only dependencies.", "Hello, my name is Keith and I am from CodeDay. Me and my team will be working on this issue.", "> Hello, my name is Keith and I am from CodeDay. Me and my team will be working on this issue.\n\nWelcome, the following pages should help you to get started:\n- https://github.com/eclipse-ide/\n- https://github.com/eclipse-pde/eclipse.pde?tab=readme-ov-file#how-to-contribute\n\nand if you have further questions, don't hesitate to ask, we are here to help.", "Hello, before me and my team (@Phinhas214, @kwohyuno) get started on the solution, we would like to clarify our understanding of the issue and current plan for our implementation. \n\nOur current understanding of `additional.bundles` and `jars.extra.classpath`:\n\n- `additional.bundles` is used to add bundles as dependencies either through Require-Bundle or Import-Package that are needed for the plugin to run. They are added automatically to the `MANIFEST.MF` file. \n- `jars.extra.classpath` is used to add singular jar files that are compiled but not imported (not required at runtime). As of right now, `jars.extra.classpath` only supports adding jar files from workspace projects. We want it to be able to add bundles from the local workspace or target platform as well. \n\nIn addition to understanding the differences between the two features, we also familiarized ourself with the Eclipse ui framework by creating a simple perspective plugin.\n\n<img width=\"720\" height=\"405\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f4be2392-8c4b-4db7-bc44-abfbc3071394\" />\n\nWhat we plan to do:\n\n- Modify `jars.extra.classpath` so that users can add bundles from the target platform or local workspace \n- Add a description to the \"Automated Management of Dependencies\" view and a link to \"Extra Classpath Entries\" that says \n???You can go to the build page (link here) to add compile-only dependencies to the plugin.??? \n\nThese are the files that we think are relevant to this issue. \n\n- `BuildClassPathSection.java`: contains the logic for the Extra Classpath Entries feature which is what we will be changing to be able to add bundles from target platform or workspace\n- `DependencyManagement.java`: contains the logic for the Automated Management of Dependencies feature, which currently supports adding bundles, and what we will be using as inspiration to be added to Extra Classpath Entries. \n- `BuildPage.java`: UI page for Extra Classpath Entries. \n- `DependencyPage.java`: UI page for Automated Management of Dependencies.   \n\nWe want guidance on whether we should add another button (between the Add JARs??? and Remove button) which is intended to specifically add bundles, or just change the ???Add JARs?????? button so that users can add both singular jar files and bundles through the same button.\n\n- Option 1: separate button for bundles from singular jar files\n- Option 2: add a search bar to the ???Add JARs?????? view and have both jar files and bundles in the same view. \n\nWe wanted to propose these two options because having a separate button for jar files and a separate button for bundles allows for users to add exactly what they want and not have to search through one long list, but it may also make the ui a little bit cluttered so combining the two into one button with a search bar may also work. \n\nIs our understanding of the project correct and if so, is our plan for implementation fit for this issue?", "I think the best is to just start and see how things work out (e.g. one button versus two buttons), then present a screenshot (to see how text / link looks like).", "> As of right now, jars.extra.classpath only supports adding jar files from workspace projects. \n\nNot, both is possible.\n\n> We want it to be able to add bundles from the local workspace or target platform as well.\n\nThis is already possible, at least from local workspace. Not sure about target file.\n\n<img width=\"1530\" height=\"944\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5341cd94-0b7d-4d9f-bee1-a086404e5045\" />", "> Not, both is possible\n\nCan you then please share a screenshot that proofs that? For me it currently looks like this:\n\n<img width=\"981\" height=\"1413\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/485feeea-3ce9-4081-be5d-f143a225528f\" />\n\nso no way to add something else than a project jar.\n\n> This is already possible, at least from local workspace. Not sure about target file.\n\nWhat you show is text files using this feature to refrence a JAR so I'm not really sure what exactly \"already possible\" mean here in this context.", "By the way here is an example of how such entry looks **without a jar(!)** and yes it works in Tycho and the IDE and regardless of workspace or target content:\n\nhttps://github.com/eclipse-tycho/tycho/blob/main/demo/lombok/lombok-bundle/build.properties\n\nI hope this makes it more clear.", "Hello, me and my team (@Phinhas214, @kwohyuno) have made some progress with our implementation of the solution that we previously proposed for this issue. We wanted to ask for some feedback as well as some guidance on a few other things. This is how our current implementation of adding bundles in extra classpath entries currently looks. \n\n<img width=\"720\" height=\"432\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ee952188-ef4b-48f0-b597-3905b7e9651a\" />\n\n<img width=\"480\" height=\"434\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/769af090-5516-40f9-8395-cb7ea652c6ba\" />\n\nWe were wondering if this was what you guys wanted for the solution or if you would like us to make any necessary changes that fit your interests. \n\nOn another note, we tried to implement a link in automated management of dependencies that has a short description and link to the build configuration to avoid confusion with adding compile-only dependencies, but we ran into some issues when creating the link. \n\n- We tried to add the description in `pderesources.properties` by adding to `SecondaryBundlesSection_desc`. The description looked like this: `Augment the plug-in development classpath with the following dependencies without adding them to the MANIFEST.MF file. You can go to the <a href=\"build\">Build Configuration</a> to add compile-only dependencies to the plugin.` \n- We then tried to make some changes to `DependencyManagementSection.java` to support this change. We altered the `createClient()` function by changing the setText function call for the description text to render parseTags and expandURLs. We then added a `addHyperlinkListener` similar to the one created for the add dependencies hyperlink. \n- When making these changes, however, we ran into `\"org.eclipse.ui.IWorkbenchWindow.getActivePage()\" because the return value of \"org.eclipse.ui.IWorkbenchPartSite.getWorkbenchWindow()\" is null` errors. We are stuck on this part and would like some guidance on how to go about this.\n\nLastly, I wanted to ask if we would eventually add a N&N entry to this [page](https://eclipse.dev/eclipse/markdown/?f=news/4.37/pde.md) or is there a different way to add an entry?" ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "eclipse.pde",
        "fullName" : "eclipse-pde/eclipse.pde",
        "htmlUrl" : "https://github.com/eclipse-pde/eclipse.pde",
        "gitUrl" : "git://github.com/eclipse-pde/eclipse.pde.git",
        "sshUrl" : "git@github.com:eclipse-pde/eclipse.pde.git",
        "cloneUrl" : "https://github.com/eclipse-pde/eclipse.pde.git",
        "owner" : {
          "login" : "eclipse-pde",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 118,
        "stargazersCount" : 32,
        "watchersCount" : 32,
        "size" : 133312,
        "openIssuesCount" : 286,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T22:05:55Z",
        "languages" : {
          "Java" : 26040945,
          "CSS" : 18383,
          "Shell" : 4197,
          "JavaScript" : 7081,
          "HTML" : 1162730,
          "XSLT" : 20815
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add support for `jars.extra.classpath` in the Manifest editor to avoid confusion with `additional.bundles`.",
      "validationOrRequirement" : "The feature should only support the form where one can specify a single bundle `platform:/plugin/<Bundle-SymbolicName>` as this is also supported by Tycho and easy to adapt by other tools.",
      "attemptedFixes" : "The implementation plan includes modifying `BuildClassPathSection.java` to allow adding bundles from the target platform or local workspace, adding a description to the \"Automated Management of Dependencies\" view with a link to the build page, and possibly adding a separate button or search bar for adding bundles.",
      "otherNotes" : "The issue is about adding support for `jars.extra.classpath` in the Manifest editor to avoid confusion with `additional.bundles`. It currently does not support adding bundles from the target platform or local workspace. The plan is to modify `jars.extra.classpath` to allow adding bundles from the target platform or local workspace and add a description to the \"Automated Management of Dependencies\" view with a link to the build page.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406381
  }, {
    "issueDTO" : {
      "id" : 225188950,
      "title" : "Edition's bookcover alt-text should pull author from work",
      "url" : "https://github.com/internetarchive/openlibrary/issues/486",
      "repositoryName" : "internetarchive/openlibrary",
      "description" : "Correcting a work's author (e.g. https://openlibrary.org/works/OL3531880W/Living_with_Leviathan?b=4&a=3&_compare=Compare&m=diff ) also corrects the Alt-text for the work cover, (e.g. to alt=\"Cover of: Living with Leviathan by David Brian Smith\" ) but fails to correct the Alt-text for the editions below it, instead leaving it untouched (e.g. as alt=\"Cover of: Living with Leviathan by David Buchanan Smith\" ). Might this be why the edition is still found on searches for the old author spelling?\r\n\r\nview-source:https://openlibrary.org/books/OL17631357M/Living_with_Leviathan shows the error at lines 349, 357, 371\r\n\r\n**Proposed fix:** Ensure the edition alt-text author name uses the same source data as the rest of the edition interface, which takes the author attached to the work(if it exists)",
      "updatedAt" : 1753399570.000000000,
      "user" : "LeadSongDog",
      "userHtmlUrl" : "https://github.com/LeadSongDog",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11435431?v=4",
      "labels" : [ "Good First Issue", "Affects: UI", "Lead: @cdrini", "Type: Bug", "Affects: Data", "Priority: 3", "Affects: Server" ],
      "state" : "OPEN",
      "comments" : [ "Further, the edition edit-->add cover-->manage leads to a 500: https://openlibrary.org/books/OL17631357M/Living_with_Leviathan/edit#imagesManage", "Still there:\r\n![leviathan](https://user-images.githubusercontent.com/11435431/37295593-f07a4b5a-25ee-11e8-9128-c3001035fbcd.png)\r\nThe old author, OL592017A, also shows in the edition's json display:\r\nhttps://openlibrary.org/books/OL17631357M.json \r\nstill includes \"authors\": [{\"key\": \"/authors/OL592017A\"}] though it should have changed to \"/authors/OL1862019A\" with that edit last April 28.", "@mekarpeles @hornc \r\nAt: \r\nhttps://openlibrary.org/works/OL9340281W/Advanced_Organic_Chemistry?b=2&a=1&_compare=Compare&m=diff \r\nI changed the Work record to link to the correct Author record. This should have fixed all the Edition records and Covers under that Work, but clearly it did not:\r\n![authorbug](https://user-images.githubusercontent.com/11435431/38099669-397cce10-3349-11e8-880a-50cdfe0f26dd.png)\r\n", "This sounds like the same thing which has been reported multiple times before.\r\n\r\nWhat is new about this case?", "Just trying to give an example that is clear enough to get some attention. After almost a year, I don't Think that this has even been diagnosed yet, so I wanted to provide a very clear example. ", "This appears to be unresolved. @hornc I'm guessing this is your purview. Are you willing to be assignee? Note, being the assignee doesn't necessarily mean you are responsible for doing the work, just responsible for gathering/providing information to address the issue. From the Wiki.\r\n\r\n>The assigned owner is not necessarily the person who will fix the issue (it is not necessarily even established, at that point, if or when the issue will be fixed at all), but rather they are the person who will do as much or as little as needed to handle the issue (asking questions, soliciting input, establishing and updating the priority, checking if it is a duplicate, etc).\r\n>\r\n>Once an issue is labeled State: Work In Progress, the owner is the individual doing the work, or leading/coordinating the group that is doing the work.\r\n\r\nI've added labels per context: let me know your thoughts", "Some of the other issues which cover this are #628 and #891", "Something weird is going on here; the edition still has the wrong author (`...017A` instead of `...019A`) in the JSON. I don't think this is a solr issue. The work and edition author fields are out of sync (for some reason).\r\n\r\nhttps://openlibrary.org/books/OL17631357M.json", "I'm labeling this as an Infogami issue, but I'm guessing it may have something to do with Memcache as well. @tfmorris @cdrini @hornc What are your thoughts?", "My guess would be this is not a memcache issue (the .json endpoints don't use memcache). Not sure what the root cause is that could have caused the work/edition to fall out of sync :/\r\n\r\nOk, comparing with https://openlibrary.org/books/OL25934687M.json , it looks like `authors` should _not_ be on the edition record at all. My guess would be it appeared as a result of some fluke error. (This also used to be an orphan, so I'd guess there might've been some issue with un-orphaning it). I can fix this specific edition manually, and create an issue to investigate further.", "Fixed this specific edition https://openlibrary.org/books/OL17631357M/Living_with_Leviathan", "New issue: https://github.com/internetarchive/openlibrary/issues/2625", "@cdrini I don't think this should be closed - as I see it, the fix for this issue is for edition covers to pull the author name from the work like every other piece of UI code, for display consistency.\r\n\r\n\r\n#2625 is more than this.", ":+1: Fair enough; would you mind re-opening and updating the description?", "Assigning jdlrobson (not tagging per request) per slack discussion since it seems like something he word do.", "I'm not understanding the issue here or the high priority.\r\nWhen I visit the URL https://openlibrary.org/books/OL17631357M/Living_with_Leviathan the image of the cover has the alt text \"Cover of: Living with Leviathan | David B Smith\".\r\n\r\nWhat else is needed?\r\n", "@jdlrobson, that's because  @cdrini fixed that specific edition last month, but my example of OL10328206M still has the same problem. \r\n{\"publishers\": [\"John Wiley & Sons Inc\"], \"languages\": [{\"key\": \"/languages/eng\"}], \"classifications\": {}, \"key\": \"/books/OL10328206M\", \"title\": \"Advanced organic chemistry\", \"identifiers\": {\"goodreads\": [\"1580424\"]}, \"isbn_13\": [\"9780471514664\"], \"created\": {\"type\": \"/type/datetime\", \"value\": \"2008-04-30T09:38:13.731961\"}, \"physical_format\": \"Hardcover\", \"isbn_10\": [\"0471514667\"], \"latest_revision\": 5, \"last_modified\": {\"type\": \"/type/datetime\", \"value\": \"2018-03-29T15:08:46.741342\"}, \"authors\": [{\"key\": \"/authors/OL3385469A\"}], \"works\": [{\"key\": \"/works/OL9340281W\"}], \"type\": {\"key\": \"/type/edition\"}, \"subjects\": [\"Chemistry\"], \"revision\": 5}\r\n\r\nPlease note that it still shows the old author key OL3385469A, not the work author OL401050A which renders as: \r\n\r\n![staleauthor](https://user-images.githubusercontent.com/11435431/70634694-b1fdcf00-1c00-11ea-98c0-765517e8bc75.jpg)\r\n\r\nThe UI gives no way to correct the author entry in the edition record, just in the work record.", "So this seems like a backend problem not UI problem.\r\n\r\nThe template https://github.com/internetarchive/openlibrary/blob/a485ea50abfb66697a303356f4810a364bb4b8c0/openlibrary/templates/covers/book_cover.html\r\n\r\nis pretty dumb.. all it does is outputs the value of book.get_authors\r\n\r\nSo the issue lies somewhere outside the UI (wherever that get_authors function is defined). Fix that and you'll fix the UI.\r\n", "@jdlrobson It seems there are multiple places where get_authors is defined, perhaps that is a problem in itself?:\r\n\r\nhttps://github.com/internetarchive/openlibrary/blob/0aadc9d596671e48248cc6bcc2ba82020c0f0f4a/openlibrary/core/lists/engine.py#L38\r\n\r\nhttps://github.com/internetarchive/openlibrary/blob/19f2062f519ff3189d36ce23d252f1f5a2d36c92/openlibrary/plugins/books/dynlinks.py#L164\r\n\r\nhttps://github.com/internetarchive/openlibrary/blob/19f2062f519ff3189d36ce23d252f1f5a2d36c92/openlibrary/plugins/books/dynlinks.py#L337\r\n\r\nhttps://github.com/internetarchive/openlibrary/blob/51d7b5bf04959d23c4c216519fa9a13b34285866/openlibrary/plugins/upstream/models.py#L59\r\n\r\nhttps://github.com/internetarchive/openlibrary/blob/51d7b5bf04959d23c4c216519fa9a13b34285866/openlibrary/plugins/upstream/models.py#L596\r\n\r\nhttps://github.com/internetarchive/openlibrary/blob/c05b856c688658fd4ffa50e3aa1040936c51c2c0/openlibrary/plugins/openlibrary/home.py#L235\r\n" ],
      "repository" : {
        "description" : "One webpage for every book ever published!",
        "homepage" : "https://openlibrary.org",
        "name" : "openlibrary",
        "fullName" : "internetarchive/openlibrary",
        "htmlUrl" : "https://github.com/internetarchive/openlibrary",
        "gitUrl" : "git://github.com/internetarchive/openlibrary.git",
        "sshUrl" : "git@github.com:internetarchive/openlibrary.git",
        "cloneUrl" : "https://github.com/internetarchive/openlibrary.git",
        "owner" : {
          "login" : "internetarchive",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1583,
        "stargazersCount" : 5773,
        "watchersCount" : 5773,
        "size" : 99535,
        "openIssuesCount" : 877,
        "subscribersCount" : 174,
        "pushedAt" : "2025-07-24T23:21:11Z",
        "languages" : {
          "MDX" : 900,
          "Dockerfile" : 5593,
          "Shell" : 99314,
          "CSS" : 2800,
          "PLpgSQL" : 16061,
          "Makefile" : 2625,
          "JavaScript" : 635427,
          "Vue" : 208922,
          "HTML" : 701123,
          "Less" : 298302,
          "Python" : 2564724
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to ensure that the edition's bookcover alt-text correctly pulls the author from the work, and not leave it untouched as it is currently.",
      "validationOrRequirement" : "The edition alt-text author name should use the same source data as the rest of the edition interface, which takes the author attached to the work (if it exists).",
      "attemptedFixes" : "The issue has been partially fixed by @cdrini for a specific edition, but the problem still persists for other editions. The fix for this issue is to ensure the edition alt-text author name uses the same source data as the rest of the edition interface, which takes the author attached to the work (if it exists).",
      "otherNotes" : "The issue is about edition's bookcover alt-text not pulling author from work, leading to incorrect alt-text for editions. The problem is not with the UI, but with the backend, specifically with the get_authors function. There are multiple places where this function is defined, which might be the problem. The issue is also related to Memcache and Infogami.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406388
  }, {
    "issueDTO" : {
      "id" : 3253918319,
      "title" : "fix multi-mint token concatenation",
      "url" : "https://github.com/nutty-raccoon/paynet/issues/156",
      "repositoryName" : "nutty-raccoon/paynet",
      "description" : "https://github.com/cashubtc/nuts/issues/275 is about to set the specification for multi-mint token concatenation.\nThe need from a specification was raised by us after we did an implementation the `CBOR array approach` mentioned in the issue in PR #142 \n\nThis issue aims to change our implementation to follow Cashu sepcs and the `Colon-separated approach`\n\n",
      "updatedAt" : 1753399133.000000000,
      "user" : "tdelabro",
      "userHtmlUrl" : "https://github.com/tdelabro",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/34384633?v=4",
      "labels" : [ "onlydust-wave", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I???d like to work on this issue.\n\nYou initially implemented multi-mint token support using the CBOR array method in PR #142, which helped highlight the need for a clear spec. Now that the colon-separated format is being proposed as the standard, I???d like to update our implementation to match the official Cashu specification.\n\nI???m already familiar with how multi-mint tokens work in practice and the context behind this change, so I believe I???m a good fit to handle this update smoothly.\n\nLet me know if you'd like me to focus on. i am available to take on it", "I'll love to work on this issue. ETA - 48hrs", "Hi, my name is Godswill Idolor also know as Gwill. I am a blockchain engineer with 2 years of experience in backend and frontend. I am a contributor of projects like vitecare, harmony, mediano, Flare and Kindfi focusing on Smart Contracts using Rust, Python, Frontend and Backend. \nI also have experience with Cairo. StarkNet bootcamp graduate 12. I am passionate about smartcontract, which is why I enjoy designing the logic, and I have a natural ability to think critically and effectively. Along with my team, I won first place in OD hack13 as one of the top contributors. My experience in both frontend and backend enables me to carry out a wide variety of tasks to achieve set goals. I would really love to participate in the project with this issue.. please assign me\n\nRecommended by [OnlyDust](https://onlydust.com/) for high-quality and dependable contributions.", "Hi, my name is Ebuka Moses. I???m a blockchain developer with a strong focus on Smart contract, frontend engineering and smart contract integration. Over the years, I've contributed to several open-source projects in the Web3 space and bring a deep understanding of how decentralized applications should look and feel.\n\nI'm a StarkNet Cairo Bootcamp Cohort graduate, and while I have experience with smart contracts (Rust, Cairo, Solidity), I enjoy bringing dApps to life through intuitive, user-focused interfaces.\n\nAs a cohort captain at Web3Bridge, I mentor developers and lead sessions that bridge smart contracts with practical frontend development. I???d love the chance to contribute to this project and collaborate with others building in the ecosystem.\nPlease feel free to assign me to this issue." ],
      "repository" : {
        "description" : " A privacy-preserving payment network. Enabling seamless off-chain transactions with bearer tokens backed by on-chain assets.",
        "homepage" : "",
        "name" : "paynet",
        "fullName" : "nutty-raccoon/paynet",
        "htmlUrl" : "https://github.com/nutty-raccoon/paynet",
        "gitUrl" : "git://github.com/nutty-raccoon/paynet.git",
        "sshUrl" : "git@github.com:nutty-raccoon/paynet.git",
        "cloneUrl" : "https://github.com/nutty-raccoon/paynet.git",
        "owner" : {
          "login" : "nutty-raccoon",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28,
        "stargazersCount" : 31,
        "watchersCount" : 31,
        "size" : 2618,
        "openIssuesCount" : 20,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-24T13:34:01Z",
        "languages" : {
          "TypeScript" : 5641,
          "Dockerfile" : 6399,
          "Shell" : 4142,
          "RenderScript" : 2,
          "Rust" : 698138,
          "Cairo" : 9207,
          "JavaScript" : 1287,
          "HTML" : 323,
          "Svelte" : 47330
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix multi-mint token concatenation to follow the official Cashu specification and use the colon-separated approach.",
      "validationOrRequirement" : "The issue requires following the official Cashu specification for multi-mint token concatenation, and using the colon-separated approach.",
      "attemptedFixes" : "CBOR array approach was initially implemented in PR #142, but now needs to be updated to match the official Cashu specification.",
      "otherNotes" : "The issue aims to change the implementation of multi-mint token support from the CBOR array approach to the colon-separated approach, following the official Cashu specification.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406392
  }, {
    "issueDTO" : {
      "id" : 2628720108,
      "title" : "Services injected with attribute derived from FromKeyedServicesAttribute appear as request body in swagger",
      "url" : "https://github.com/dotnet/aspnetcore/issues/58739",
      "repositoryName" : "dotnet/aspnetcore",
      "description" : "### Is there an existing issue for this?\n\n- [x] I have searched the existing issues\n\n### Describe the bug\n\nThis is much like [#50704](https://github.com/dotnet/aspnetcore/issues/50704#issue-1896783129) except for attributes derived from `FromKeyedServicesAttribute`. The [fix](https://github.com/dotnet/aspnetcore/pull/50717/commits/47ddb2754a1e63dd15f33ec3092a9976abcbd62d) for the previous issue only checked if the type was exactly `FromKeyedServicesAttribute`. \n\n### Expected Behavior\n\nI'm hoping this could be changed to use something like `IsAssignableTo/From` so that it covers derived attributes too.\n\n### Steps To Reproduce\n\n_No response_\n\n### Exceptions (if any)\n\n_No response_\n\n### .NET Version\n\n_No response_\n\n### Anything else?\n\nIs there a workaround? e.g. some other \"Ignore this\" attribute I could apply to hide it?",
      "updatedAt" : 1753398783.000000000,
      "user" : "stevendarby",
      "userHtmlUrl" : "https://github.com/stevendarby",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/41150696?v=4",
      "labels" : [ "area-minimal", "help wanted", "feature-openapi", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "P.S. I'd be happy to raise a PR if that would help its chances of getting into a 9.0.x release.", "Workaround for swashbuckle, which works with the limited cases I have, but might not be generally applicable for everyone:\n\n```C#\npublic class KeyedServicesFilter : IOperationFilter\n{\n    public void Apply(OpenApiOperation operation, OperationFilterContext context)\n    {\n        if (context.ApiDescription.HttpMethod != HttpMethods.Get)\n        {\n            return;\n        }\n\n        var parameter = context.MethodInfo\n            .GetParameters()\n            .FirstOrDefault(p => p.CustomAttributes.Any(c => c.AttributeType.IsAssignableTo(typeof(FromKeyedServicesAttribute))));\n\n        if (parameter is not null)\n        {\n            operation.RequestBody = null;\n\n            if (context.SchemaRepository.TryLookupByType(parameter.ParameterType, out var schema))\n            {\n                context.SchemaRepository.Schemas.Remove(schema.Reference.Id);\n            }\n        }\n    }\n}\n```", "PRs are still welcome for this. I dunno how common a pattern derived from the BCL's `FromKeyedServicesAttribute` is but the fix seems fairly small. Marking as help wanted.", "Looks like this issue has been identified as a candidate for community contribution. If you're considering sending a PR for this issue, look for the `Summary Comment` link in the issue description. That comment has been left by an engineer on our team to help you get started with handling this issue. You can learn more about our Help Wanted process [here](https://aka.ms/aspnet/processes/help-wanted)\n<!-- Policy app identification https://img.shields.io/static/v1?label=PullRequestIssueManagement. -->" ],
      "repository" : {
        "description" : "ASP.NET Core is a cross-platform .NET framework for building modern cloud-based web applications on Windows, Mac, or Linux.",
        "homepage" : "https://asp.net",
        "name" : "aspnetcore",
        "fullName" : "dotnet/aspnetcore",
        "htmlUrl" : "https://github.com/dotnet/aspnetcore",
        "gitUrl" : "git://github.com/dotnet/aspnetcore.git",
        "sshUrl" : "git@github.com:dotnet/aspnetcore.git",
        "cloneUrl" : "https://github.com/dotnet/aspnetcore.git",
        "owner" : {
          "login" : "dotnet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 10410,
        "stargazersCount" : 36899,
        "watchersCount" : 36899,
        "size" : 366275,
        "openIssuesCount" : 3789,
        "subscribersCount" : 1434,
        "pushedAt" : "2025-07-25T00:15:26Z",
        "languages" : {
          "C#" : 60644415,
          "PowerShell" : 317972,
          "Java" : 568974,
          "C++" : 1244944,
          "CSS" : 104309,
          "C" : 124045,
          "CMake" : 14853,
          "HTML" : 1673332,
          "TypeScript" : 1178863,
          "Dockerfile" : 423,
          "Shell" : 181419,
          "Batchfile" : 26222,
          "SCSS" : 12,
          "JavaScript" : 175738,
          "Lua" : 4904,
          "ASP.NET" : 109,
          "F#" : 6234,
          "Less" : 12,
          "Python" : 13176
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to change the OpenAPI validation to correctly handle attributes derived from FromKeyedServicesAttribute.",
      "validationOrRequirement" : "The issue requires a change to the OpenAPI validation to check for derived attributes using IsAssignableTo/From.",
      "attemptedFixes" : "The workaround is a custom IOperationFilter that sets the request body to null if the attribute is present. There's also a mention of a fix in a PR, but it's not clear if that's the intended solution.",
      "otherNotes" : "This issue is similar to #50704, but it's about attributes derived from FromKeyedServicesAttribute. The fix for the previous issue only checked for the exact type, so this issue is asking for a change to use IsAssignableTo/From to cover derived attributes too. There's a workaround provided, and the issue is marked as help wanted.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406398
  }, {
    "issueDTO" : {
      "id" : 3200605482,
      "title" : "[ACTION] Tableau - Download PDF",
      "url" : "https://github.com/PipedreamHQ/pipedream/issues/17453",
      "repositoryName" : "PipedreamHQ/pipedream",
      "description" : "**Is there a specific app this action is for?**\nDownloading pdfs of Tableau views\n**Please provide a link to the relevant API docs for the specific service / operation.**\nhttps://help.tableau.com/current/api/rest_api/en-us/REST/rest_api_ref_workbooks_and_views.htm#download_workbook_pdf\n",
      "updatedAt" : 1753398130.000000000,
      "user" : "lauragpn",
      "userHtmlUrl" : "https://github.com/lauragpn",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131719629?v=4",
      "labels" : [ "triaged", "help wanted", "action", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Connect APIs, remarkably fast.  Free for developers.",
        "homepage" : "https://pipedream.com",
        "name" : "pipedream",
        "fullName" : "PipedreamHQ/pipedream",
        "htmlUrl" : "https://github.com/PipedreamHQ/pipedream",
        "gitUrl" : "git://github.com/PipedreamHQ/pipedream.git",
        "sshUrl" : "git@github.com:PipedreamHQ/pipedream.git",
        "cloneUrl" : "https://github.com/PipedreamHQ/pipedream.git",
        "owner" : {
          "login" : "PipedreamHQ",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5419,
        "stargazersCount" : 10247,
        "watchersCount" : 10247,
        "size" : 608233,
        "openIssuesCount" : 4153,
        "subscribersCount" : 276,
        "pushedAt" : "2025-07-25T00:33:00Z",
        "languages" : {
          "TypeScript" : 1313176,
          "MDX" : 1185411,
          "Dockerfile" : 295,
          "CSS" : 4596,
          "Shell" : 2688,
          "Makefile" : 270,
          "JavaScript" : 25500208,
          "HTML" : 568,
          "Jupyter Notebook" : 22765
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Downloading pdfs of Tableau views",
      "validationOrRequirement" : "Please provide a link to the relevant API docs for the specific service / operation.",
      "attemptedFixes" : "",
      "otherNotes" : "Is there a specific app this action is for? Please provide a link to the relevant API docs for the specific service / operation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406401
  }, {
    "issueDTO" : {
      "id" : 3248387181,
      "title" : "Analytics button in dashboard",
      "url" : "https://github.com/starkyorg/starky/issues/231",
      "repositoryName" : "starkyorg/starky",
      "description" : "## Description \uD83D\uDCF9\n\nAdd a button on the dashboard page to access the analytics page.\nThe button should reuse the logic of the `/starky-analytics` command:\n\n* It checks that the dashboard token is valid.\n* It generates an analytics token.\n* It stores this token in the database.\n* It opens the analytics page using this generated token.\n\n## Proposed Actions \uD83D\uDEE0???\n\nHere???s a checklist of actions to follow for resolving this issue:\n\n1. **Fork and Create Branch**:\n   Fork the repository and create a new branch using the issue number:\n\n```bash\n   git checkout -b fix-[issue-number]\n```\n\n2. **Implement Changes**:\n\n* [ ] Add a new button to the dashboard page UI to trigger analytics access.\n* [ ] On click, reuse the `/starky-analytics` backend logic to:\n\n  * [ ] Validate the current dashboard token.\n  * [ ] Generate a new analytics token.\n  * [ ] Store the token in the database.\n* [ ] Redirect the user to the analytics page using the generated token.\n\n3. **Run Tests and Commit Changes**:\n   Make sure your changes don't break existing functionality and commit with a clear message:\n\n```bash\n   git commit -m \"Fix: Add analytics access button to dashboard with token generation\"\n```\n\n## Required \uD83D\uDCCB\n\nTo keep our workflow smooth, please make sure you follow these guidelines:\n\n* **Assignment**: Don't create a pull request if you weren???t assigned to this issue.\n* **Timeframe**: Complete the task within **3 business days**.\n* **Closing the Issue**: In your PR description, close the issue by writing Close #\\[issue\\_id].\n* **Review Process**:\n\n  * Once you've submitted your PR, change the label to **\"ready for review\"**.\n  * If changes are requested, address them and then update the label back to **\"ready for review\"** once done.\n* **Testing**: Test your PR locally before pushing, and verify that tests and build are working after pushing.\n\nThank you for your contribution \uD83D\uDE4F\n\n?????? WARNING: Failure to follow the requirements above may result in being added to the OnlyDust blacklist, affecting your ability to receive future rewards.\n",
      "updatedAt" : 1753398127.000000000,
      "user" : "Marchand-Nicolas",
      "userHtmlUrl" : "https://github.com/Marchand-Nicolas",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/60229704?v=4",
      "labels" : [ "open for contribution", "onlydust-wave", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<img src=\"https://github.com/user-attachments/assets/2cf4109d-0f1c-4df8-8815-6eadca2d7ed0\" alt=\"Logo\" style=\"vertical-align: middle; margin-left: 10px; width: 20px; height: auto;\"><br>\n# [FE]: Add button to access the Analytics view from the Dashboard\n\nHi @Marchand-Nicolas and everyone!, I'm a Dojo Coding member??????\n\nI???d be happy to participate in this issue. With over 5 years of experience in frontend development, I???ve worked on similar projects and can ensure a clean, user-friendly, and well-structured implementation.\n\n## Steps to Resolve:\n\n<details>\n  <summary><strong>1) Locate the Dashboard View</strong></summary>\n  <br>\n  <ul>\n    <li>Find the main dashboard component in the codebase (likely in /app or /components).</li>\n    <li>Identify the best place in the UI to include the new button, considering design and usability.</li>\n  </ul>\n</details>\n\n<details>\n  <summary><strong>2) Add the Button to Navigate to Analytics</strong></summary>\n  <br>\n  <ul>\n    <li>Create a button labeled \"Analytics\".</li>\n    <li>Ensure it uses proper styling consistent with the rest of the app (e.g., using TailwindCSS or ShadCN components).</li>\n    <li>Link the button to redirect the user to `/app/analytics` or the correct route defined for analytics.</li>\n  </ul>\n</details>\n\n<details>\n  <summary><strong>3) Ensure Proper Navigation and UX</strong></summary>\n  <br>\n  <ul>\n    <li>Use Next.js `<Link>` component or programmatic routing with `useRouter` to handle the navigation properly.</li>\n    <li>Optionally include an icon (e.g., chart icon) to reinforce visual meaning.</li>\n  </ul>\n</details>\n\n<details>\n  <summary><strong>4) Test Responsiveness and Layout</strong></summary>\n  <br>\n  <ul>\n    <li>Ensure that the button appears correctly on all screen sizes.</li>\n    <li>Validate spacing and positioning with the rest of the dashboard components.</li>\n  </ul>\n</details>\n\n<details>\n  <summary><strong>5) Commit and Create a PR</strong></summary>\n  <br>\n  <ul>\n    <li>Push changes to a feature branch.</li>\n    <li>Open a pull request with a clear description, screenshots, and checklist.</li>\n  </ul>\n</details>\n\n---\n\n**Estimated Time:** Less than 1 day\n\n## Why I???m interested:\n\nI have a strong background in frontend development with React and Next.js, and I specialize in UI/UX consistency, component architecture, and accessibility. I???ve worked with dashboards before, and I know how crucial it is to ensure intuitive navigation and a clean UI/UX.\n\n## References:\n![Image](https://github.com/user-attachments/assets/50fcce52-e850-4bd2-8e58-b28cb1b9f17a)\n\nI am a rising contributor; other projects have already given me the opportunity to participate, and the final results have left the maintainers satisfied. So, I have work references, and they will continue to grow as long as you allow me to participate and contribute to making your dream a reality, which is an honor for me.\n\n[BabyBeastsv2](https://github.com/ByteBuildersLabs/BabyBeastsv2/pull/71)  \n[Lyricsflip](https://github.com/songifi/lyricsflip/pull/93)  \n[Revolutionary Farmers](https://github.com/Crypto-Jaguars/Revo-Marketplace/pull/43)  \n[SafeTrust](https://github.com/safetrustcr/dApp-SafeTrust/pull/30)  \n[Starklotto](https://starklotto.vercel.app/)  \n[StarShop](https://github.com/StarShopCr/StarShop-Frontend/pull/36)  \n[Timelycapsule](https://github.com/enbliq/timelycapsule-web/pull/52)  \n[VolunChain](https://github.com/VolunChain/VolunChain-Frontend/pull/23)\n\n## Social Link:\nTelegram: [drakkomaximo](https://t.me/drakkomaximo)\n\nLet me know if I can start working on this!\n", "Hi! I'd like to work on this issue, I have experience working with everything on the codebase and I expect to finish in less than a day!\n\nThanks!" ],
      "repository" : {
        "description" : "A Discord bot to verify onchain identity on Discord",
        "homepage" : "",
        "name" : "starky",
        "fullName" : "starkyorg/starky",
        "htmlUrl" : "https://github.com/starkyorg/starky",
        "gitUrl" : "git://github.com/starkyorg/starky.git",
        "sshUrl" : "git@github.com:starkyorg/starky.git",
        "cloneUrl" : "https://github.com/starkyorg/starky.git",
        "owner" : {
          "login" : "starkyorg",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 88,
        "stargazersCount" : 34,
        "watchersCount" : 34,
        "size" : 4078,
        "openIssuesCount" : 18,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-02T10:39:23Z",
        "languages" : {
          "TypeScript" : 252403,
          "Dockerfile" : 1705,
          "Shell" : 206,
          "SCSS" : 11549,
          "JavaScript" : 629
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a button on the dashboard page to access the analytics page, reusing the logic of the `/starky-analytics` command.",
      "validationOrRequirement" : "The issue has required guidelines, including assignment, timeframe, closing the issue, review process, and testing. The issue also has a checklist of actions to follow, including implementing changes, running tests, and committing changes. The issue requires the contributor to ensure that the changes don't break existing functionality and commit with a clear message.",
      "attemptedFixes" : "The issue has a proposed action plan with steps to resolve, including locating the dashboard view, adding the button to navigate to analytics, ensuring proper navigation and UX, testing responsiveness and layout, and committing and creating a PR. The issue also has a reference to a rising contributor with experience in frontend development and UI/UX consistency, component architecture, and accessibility.",
      "otherNotes" : "The issue is to add a button on the dashboard page to access the analytics page, reusing the logic of the `/starky-analytics` command. The button should validate the current dashboard token, generate a new analytics token, store the token in the database, and redirect the user to the analytics page using the generated token. The issue has a checklist of actions to follow, including implementing changes, running tests, and committing changes. The required guidelines include assignment, timeframe, closing the issue, review process, and testing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406410
  }, {
    "issueDTO" : {
      "id" : 3094445798,
      "title" : "Ecosystem integrations",
      "url" : "https://github.com/google/dranet/issues/93",
      "repositoryName" : "google/dranet",
      "description" : "Some projects it will be nice to get integrations\n\n- [x] MPI operator https://github.com/kubeflow/mpi-operator\n   - https://github.com/google/dranet/blob/main/site/content/docs/user/mpi-operator.md\n- [ ] Slurm on Kube https://github.com/slinkyproject\n   - Expose affinity mask Numa\n   - Expose fabric topology https://slurm.schedmd.com/topology.html?\n- [x] Kube Ray https://github.com/ray-project/kuberay\n  - reference https://github.com/ray-project/ray/issues/30094\n  - \"Ray Job Yaml Deployment Example\" with only a few GPUs and NICs and running in parallel\n  - https://github.com/google/dranet/pull/162\n- [ ] Jobset https://github.com/kubernetes-sigs/jobset\n- [ ] Kueue https://github.com/kubernetes-sigs/kueue\n- [x] GKE https://cloud.google.com/ai-hypercomputer/docs/create/gke-ai-hypercompute-custom\n- [ ] Flux operator https://github.com/flux-framework/flux-operator @vsoch\n- [ ] XPK https://github.com/AI-Hypercomputer/xpk/issues/482\n- [x] NVidia GPU driver https://github.com/NVIDIA/k8s-dra-driver-gpu\n   - https://github.com/google/dranet/pull/127\n- [ ] VLLM https://github.com/vllm-project/vllm\n- [ ] pytorch example https://docs.pytorch.org/docs/stable/distributed.html\n- [ ] GKE TPUs Trillium",
      "updatedAt" : 1753398095.000000000,
      "user" : "aojea",
      "userHtmlUrl" : "https://github.com/aojea",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6450081?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "tagging @siyuanfoundation for kuberay and @akulkapoor-google for mpi-operator ", "I'd like to propose [Kueue](https://github.com/kubernetes-sigs/kueue) as another potential integration. Especially since there's a high chance that today it won't play nice with Kueue's Topology Aware Scheduling.", "We can definitely add support for the Flux Operator! How are the devices (?) exposed to the applications in a pod?", "/cc @kevin85421 for kuberay", "https://github.com/ray-project/ray/pull/52938 Ray recently merged the first POC PR to natively support collective communication backends. We start from NCCL and GLOO and then we will also support other backends like RDMA and UCX later.", "I am currently working on KubeRay release. I will explore it after I finish the release process https://github.com/ray-project/kuberay/issues/3739.", "@aojea Before we ask for community input, is there consideration about moving this to a vendor neutral location?\n\nI think this would be a good candidate for kubernetes-sigs/dranet?\n\nIts not officially supported by google so not sure if it should live in the google org.", "> [@aojea](https://github.com/aojea) Before we ask for community input, is there consideration about moving this to a vendor neutral location?\n> \n> I think this would be a good candidate for kubernetes-sigs/dranet?\n> \n> Its not officially supported by google so not sure if it should live in the google org.\n\nIt's being under consideration, we are gathering positive feedback like this and I'm working on it", "I haven't looked over the code but there isn't anything here particular to google right?\n\nI could use this with on-prem?", "> I haven't looked over the code but there isn't anything here particular to google right?\n> \n> I could use this with on-prem?\n\nyes, the code is structured since the beginning to not be vendor specific", "And do you know what problems we would need to solve if we wanted to use CRIO?" ],
      "repository" : {
        "description" : "DraNet is a Kubernetes Network Driver that uses Dynamic Resource Allocation (DRA) to deliver high-performance networking for demanding applications in Kubernetes.",
        "homepage" : "http://dranet.dev/",
        "name" : "dranet",
        "fullName" : "google/dranet",
        "htmlUrl" : "https://github.com/google/dranet",
        "gitUrl" : "git://github.com/google/dranet.git",
        "sshUrl" : "git@github.com:google/dranet.git",
        "cloneUrl" : "https://github.com/google/dranet.git",
        "owner" : {
          "login" : "google",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 93,
        "watchersCount" : 93,
        "size" : 20219,
        "openIssuesCount" : 13,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-21T16:24:59Z",
        "languages" : {
          "Dockerfile" : 997,
          "Shell" : 19297,
          "C" : 408,
          "Makefile" : 2122,
          "Go" : 230160,
          "HTML" : 127
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "getting integrations with various projects, including MPI operator, Kube Ray, GKE, Jobset, Kueue, Flux operator, XPK, NVidia GPU driver, VLLM, pytorch example, and GKE TPUs Trillium",
      "validationOrRequirement" : "integrations with various projects, exposing affinity mask Numa, exposing fabric topology, reference to Ray Job Yaml Deployment Example, reference to https://github.com/google/dranet/pull/162",
      "attemptedFixes" : "tagging @siyuanfoundation and @akulkapoor-google for kuberay and mpi-operator, proposing Kueue as another potential integration, adding support for the Flux Operator, exploring KubeRay release",
      "otherNotes" : "consideration about moving this to a vendor neutral location, gathering positive feedback, code is structured to not be vendor specific, possibility of using with on-prem, potential issues with CRIO",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406416
  }, {
    "issueDTO" : {
      "id" : 3261354557,
      "title" : "[clang-format] typo in docs",
      "url" : "https://github.com/llvm/llvm-project/issues/150533",
      "repositoryName" : "llvm/llvm-project",
      "description" : "https://github.com/llvm/llvm-project/blob/5f1c89af241fc4846d612a237edfb5948071e879/clang/docs/ClangFormatStyleOptions.rst?plain=1#L1915\nhttps://github.com/llvm/llvm-project/blob/5f1c89af241fc4846d612a237edfb5948071e879/clang/include/clang/Format/Format.h#L834\ndoes not implies -> does not imply",
      "updatedAt" : 1753397750.000000000,
      "user" : "nullzeta",
      "userHtmlUrl" : "https://github.com/nullzeta",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/153915345?v=4",
      "labels" : [ "documentation", "clang-format", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\n@llvm/issue-subscribers-clang-format\n\nAuthor: None (nullzeta)\n\n<details>\nhttps://github.com/llvm/llvm-project/blob/5f1c89af241fc4846d612a237edfb5948071e879/clang/docs/ClangFormatStyleOptions.rst?plain=1#L1915\nhttps://github.com/llvm/llvm-project/blob/5f1c89af241fc4846d612a237edfb5948071e879/clang/include/clang/Format/Format.h#L834\ndoes not implies -&gt; does not imply\n</details>\n", "\nHi!\n\nThis issue may be a good introductory issue for people new to working on LLVM. If you would like to work on this issue, your first steps are:\n\n1. Check that no other contributor is working on this issue. If someone is assigned to the issue or claimed to be working on it, ping the person. After one week without a response, the assignee may be changed.\n1. Leave a comment indicating that you are working on the issue, or just create a [pull request](https://github.com/llvm/llvm-project/pulls) after following the steps below. [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n1. Fix the issue locally.\n1. [Run the test suite](https://llvm.org/docs/TestingGuide.html#unit-and-regression-tests) locally. Remember that the subdirectories under `test/` create fine-grained testing targets, so you can e.g. use `make check-clang-ast` to only run Clang's AST tests.\n1. Create a Git commit.\n1. Run [`git clang-format HEAD~1`](https://clang.llvm.org/docs/ClangFormat.html#git-integration) to format your changes.\n1. Open a [pull request](https://github.com/llvm/llvm-project/pulls) to the [upstream repository](https://github.com/llvm/llvm-project) on GitHub. Detailed instructions can be found [in GitHub's documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request). [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n\nIf you have any further questions about this issue, don't hesitate to ask via a comment in the thread below.\n\n", "\n@llvm/issue-subscribers-good-first-issue\n\nAuthor: None (nullzeta)\n\n<details>\nhttps://github.com/llvm/llvm-project/blob/5f1c89af241fc4846d612a237edfb5948071e879/clang/docs/ClangFormatStyleOptions.rst?plain=1#L1915\nhttps://github.com/llvm/llvm-project/blob/5f1c89af241fc4846d612a237edfb5948071e879/clang/include/clang/Format/Format.h#L834\ndoes not implies -&gt; does not imply\n</details>\n", "I was about to open a PR instead of an issue (which with this kind of contribution seems more appropriate), but the [email requirement](https://llvm.org/docs/DeveloperPolicy.html#github-email-address) is somewhat confusing. It also suggests using email forwarding services \"if you wish to keep your identity private\". But my account was previously \"shadow banned\" because of me using SimpleLogin as my email address :/" ],
      "repository" : {
        "description" : "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.",
        "homepage" : "http://llvm.org",
        "name" : "llvm-project",
        "fullName" : "llvm/llvm-project",
        "htmlUrl" : "https://github.com/llvm/llvm-project",
        "gitUrl" : "git://github.com/llvm/llvm-project.git",
        "sshUrl" : "git@github.com:llvm/llvm-project.git",
        "cloneUrl" : "https://github.com/llvm/llvm-project.git",
        "owner" : {
          "login" : "llvm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14563,
        "stargazersCount" : 33645,
        "watchersCount" : 33645,
        "size" : 2568475,
        "openIssuesCount" : 31089,
        "subscribersCount" : 580,
        "pushedAt" : "2025-07-25T00:59:09Z",
        "languages" : {
          "GDB" : 8473,
          "CMake" : 4108206,
          "Mustache" : 17219,
          "HTML" : 1956247,
          "Pawn" : 20078,
          "MATLAB" : 4946,
          "Fortran" : 11668142,
          "LLVM" : 634320209,
          "OCaml" : 335815,
          "Assembly" : 154980494,
          "Python" : 12978634,
          "Rust" : 4903,
          "Objective-C++" : 1178815,
          "SWIG" : 288374,
          "Tree-sitter Query" : 6195,
          "Perl" : 183797,
          "MLIR" : 21384848,
          "Cuda" : 1243277,
          "Scilab" : 160404,
          "Starlark" : 1194175,
          "Batchfile" : 52122,
          "AMPL" : 1662,
          "Swift" : 271,
          "DTrace" : 334,
          "C" : 202468383,
          "RPC" : 28,
          "Makefile" : 114950,
          "Cool" : 5401,
          "Jupyter Notebook" : 72939,
          "M" : 9785,
          "TypeScript" : 69121,
          "Shell" : 264842,
          "Awk" : 127345,
          "JavaScript" : 161607,
          "Mathematica" : 1118,
          "Objective-C" : 4302574,
          "Lua" : 12033,
          "PHP" : 64,
          "Limbo" : 303,
          "POV-Ray SDL" : 861,
          "Emacs Lisp" : 69003,
          "C++" : 490174634,
          "CSS" : 63859,
          "FIRRTL" : 4349198,
          "TeX" : 2141,
          "AppleScript" : 1429,
          "NASL" : 35217,
          "HIP" : 857866,
          "Julia" : 49676,
          "Dockerfile" : 23110,
          "Linker Script" : 903,
          "Roff" : 61624,
          "HLSL" : 1512603,
          "Mercury" : 14,
          "Vim Script" : 29186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Correct a typo in the ClangFormatStyleOptions.rst documentation",
      "validationOrRequirement" : "Fix the typo in the documentation and create a pull request with the changes",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is about a typo in the ClangFormatStyleOptions.rst documentation, and it is considered a good first issue for contributors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406419
  }, {
    "issueDTO" : {
      "id" : 3212782838,
      "title" : "ENH: Add Polars engine to read_csv",
      "url" : "https://github.com/pandas-dev/pandas/issues/61813",
      "repositoryName" : "pandas-dev/pandas",
      "description" : "Since we won't get it for free via #61642, is would be good to add a Polars engine manually, so pandas users can benefit from state-of-the-art speed while readings CSVs.\n\n@pandas-dev/pandas-core any objection? ",
      "updatedAt" : 1753397263.000000000,
      "user" : "datapythonista",
      "userHtmlUrl" : "https://github.com/datapythonista",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10058240?v=4",
      "labels" : [ "IO CSV", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "1. How does it compare performance wise to the PyArrow csv parser?\n2. Compared to the PyArrow csv reader, I'm less eager to add a Polars engine since it already has a `to_pandas` method and pandas `read_csv` doesn't have a use for the intermediate Polars data structures unlike PyArrow (i.e. `ArrowExtensionArray` using `pyarrow.ChunkedArray`s when `dtype_backend=\"pyarrow\"`) ", "1. Last time I checked it took one third of the time compared to pandas with PyArrow\n2. Not sure I understand what's the problem. Polars will return a Polars dataframe that will be converted to a pandas dataframe backed by ArrowExtensionArray and PyArrow, no? Do you mind expanding on what's the issue?", "No objection in principle.\n\nI am curious if we can learn from what they've done to improve our engine.\n\nWould the implementation be roughly `return pl.read_csv(...).to_pandas()` or would the kwargs/outputs need some massaging like with the pyarrow engine?\n\nWill the tests Just Work with this engine or will they need a bunch of `if engine == \"polars\": ...` tweaks?", "I didn't check the mapping of all parameters in detail, but I'd use the lazy version with at least a `.select()` and a `.filter()` to support column pruning and predicate pushdown. So, not a single liner, but my expectation is that it's a simple wrapper.\n\nI'm hoping tests will pass. I guess not all kwargs may be supported as with pyarrow, so maybe something custom is needed.", "> I am curious if we can learn from what they've done to improve our engine.\n\nI checked some time ago and wrote about some of my findings in this blog post. It also contains benchmarks of different CSV readers: https://datapythonista.me/blog/how-fast-can-we-process-a-csv-file\n\nI can tell you that Ritchie spent a huge amount of time optimizing the Polars reader. But if you have time and interest, improving our C engine sounds great.", "> Do you mind expanding on what's the issue?\n\nMore just that, as @jbrockmendel mentioned, would `pd.read_csv(..., engine=\"polars\")` just be syntatic sugar for `pl.read_csv(...).to_pandas()` correct?\n\nWhile at least with `pd.read_csv(..., engine=\"pyarrow\", dtype_backend=\"pyarrow\")`, it's not just syntatic sugar as we're still holding/using PyArrow objects after the reading of the CSV. i.e. there is more \"use\" for PyArrow here.\n\nEDIT: I see that you mentioned in https://github.com/pandas-dev/pandas/issues/61813#issuecomment-3049520253 it might not just a be a 1 liner but fitting the right lazy APIs to our `read_csv` signature, so I would be a bit more positive including this now as there's more \"art\" than just being a `pl.read_csv(...).to_pandas()` passthrough", "I read the blog post and got curious about when engine=\"python\" is necessary.  Patching read_csv to change `engine in {\"python\", \"python-fwf\"}` to \"c\" breaks <s>26</s> <b>I applied the patch incorrectly. Will update with correct number</b>  tests.  <s>10 of those are about on_bad_line being callable.  The rest need a closer look but tentatively look like they are about string inference.  It may be feasible to just get rid of the python engine.</s> 112 tests.  on_bad_lines being callable, regex separators, skipfooter support are the main ones.\n\nNext up, patching to always use the pyarrow engine and see if it breaks the world.  3137 failures.  Looks like mostly about unsupported keywords like low_memory, thousands.", "Nice blog post. Those are some impressive benchmarks on the polars side.\n\nDo you think it matters at all that polars uses string views for storage whereas we are going to default to large strings? I think that gets doubly confusing when you try to mix the pyarrow backend with the polars engine, as I'm unsure what data type a user would expect in that case (probably string_view?)", "Polars read_csv is very fast. Won't it be easier for the user to do a `pl.read_csv` or `pl.scan_csv` followed by `to_pandas`? There is also the maintenance aspect of it. Or maybe mention in the user guide that there are faster CSV readers that the user may access instead. Just an opinion ", "> Won't it be easier for the user to do a `pl.read_csv` or `pl.scan_csv` followed by `to_pandas`?\n\nEasier for us, but not easier for users in my opinion. I don't disagree with you, but in many parts of the pandas API we provide syntactic sugar to make user code look very simple and compact. For example allowing urls or compressed files when reading files. My preferred option would be the PR referenced in the description, but since there is no consensus for that, I think providing polars in the same way as we provide pyarrow is fair. Otherwise we are encouraging users to use a much slower reader.", "Most people won't be reading large amounts of data that would require using Polars' engine, and the current approach will be sufficient.\nIf you want to use Polars, just read it with pl.read_csv and then use to_pandas.\nI also tried reading 2,000 CSV files (total of 100 million records) and creating a pandas DataFrame, and pyarrow was faster than Polars.\n" ],
      "repository" : {
        "description" : "Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more",
        "homepage" : "https://pandas.pydata.org",
        "name" : "pandas",
        "fullName" : "pandas-dev/pandas",
        "htmlUrl" : "https://github.com/pandas-dev/pandas",
        "gitUrl" : "git://github.com/pandas-dev/pandas.git",
        "sshUrl" : "git@github.com:pandas-dev/pandas.git",
        "cloneUrl" : "https://github.com/pandas-dev/pandas.git",
        "owner" : {
          "login" : "pandas-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18716,
        "stargazersCount" : 46087,
        "watchersCount" : 46087,
        "size" : 370472,
        "openIssuesCount" : 3744,
        "subscribersCount" : 1112,
        "pushedAt" : "2025-07-24T20:02:20Z",
        "languages" : {
          "Smarty" : 8852,
          "Dockerfile" : 6015,
          "Shell" : 21760,
          "CSS" : 7370,
          "C" : 354816,
          "Meson" : 12525,
          "HTML" : 457849,
          "XSLT" : 1196,
          "Cython" : 1391478,
          "Python" : 20997424
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to add Polars engine to read_csv, allowing pandas users to benefit from state-of-the-art speed while reading CSVs.",
      "validationOrRequirement" : "The issue requires adding a Polars engine manually, providing syntactic sugar to make user code look simple and compact, and ensuring compatibility with existing tests and APIs.",
      "attemptedFixes" : "Patching read_csv to change `engine in {",
      "otherNotes" : "The discussion revolves around adding Polars engine to read_csv, comparing performance to PyArrow, and the possibility of using Polars' `to_pandas` method. There are also mentions of tests and potential issues with large strings and data types.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406424
  }, {
    "issueDTO" : {
      "id" : 3216445130,
      "title" : "Applicant Pages (Northstar) No Longer Support Custom Favicon",
      "url" : "https://github.com/civiform/civiform/issues/10975",
      "repositoryName" : "civiform/civiform",
      "description" : "The ability to setting the favicon did not get added in northstar\n\nRelated to: #9046",
      "updatedAt" : 1753397140.000000000,
      "user" : "gwendolyngoetz",
      "userHtmlUrl" : "https://github.com/gwendolyngoetz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/195162?v=4",
      "labels" : [ "bug", "needs-triage", "good first issue", "[Epic] North Star Applicant UI" ],
      "state" : "OPEN",
      "comments" : [ "The favicon isn't loading for me in legacy either.  Could this be unrelated to NS?", "I just fixed a bug around that. The `civiform.us/favicon.png` no longer exists and that was the default.", "Related to: #10974" ],
      "repository" : {
        "description" : "CiviForm simplifies the application process for government benefits programs by re-using applicant data for multiple benefits applications. It's being developed by Google.org and Exygy, in collaboration with the City of Seattle and community contributors.",
        "homepage" : "https://civiform.us",
        "name" : "civiform",
        "fullName" : "civiform/civiform",
        "htmlUrl" : "https://github.com/civiform/civiform",
        "gitUrl" : "git://github.com/civiform/civiform.git",
        "sshUrl" : "git@github.com:civiform/civiform.git",
        "cloneUrl" : "https://github.com/civiform/civiform.git",
        "owner" : {
          "login" : "civiform",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 74,
        "stargazersCount" : 108,
        "watchersCount" : 108,
        "size" : 812702,
        "openIssuesCount" : 923,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-24T23:53:00Z",
        "languages" : {
          "Java" : 7564267,
          "CSS" : 5635,
          "Jinja" : 1938,
          "Scala" : 23205,
          "PLpgSQL" : 9424,
          "HTML" : 175110,
          "TypeScript" : 2068988,
          "Dockerfile" : 11726,
          "Shell" : 90575,
          "SCSS" : 25962,
          "JavaScript" : 16945,
          "Ruby" : 90677,
          "Python" : 171904
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The ability to set favicon is no longer supported in Northstar",
      "validationOrRequirement" : "Add the ability to set favicon in Northstar",
      "attemptedFixes" : "The ability to setting the favicon did not get added in northstar",
      "otherNotes" : "The favicon isn't loading for me in legacy either.  Could this be unrelated to NS? I just fixed a bug around that. The `civiform.us/favicon.png` no longer exists and that was the default.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406427
  }, {
    "issueDTO" : {
      "id" : 3018604080,
      "title" : "[Android] Add method metadata report API in Module.java",
      "url" : "https://github.com/pytorch/executorch/issues/10453",
      "repositoryName" : "pytorch/executorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nPurpose: For feature parity as python runtime, and maybe users will need the metadata to check for inputs, or do test automation.\n\nAdd more APIs to \n\nhttps://github.com/pytorch/executorch/blob/main/extension/android/executorch_android/src/main/java/org/pytorch/executorch/MethodMetadata.java#L12\n\nIn https://github.com/pytorch/executorch/blob/143224370c106e8fa5421d4b49d5b28a1a725aff/extension/android/executorch_android/src/main/java/org/pytorch/executorch/Module.java#L43, add a new API like `listMethods()`\n\nWe will need a new Method.java as well, to save some metadata.\n\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### RFC (Optional)\n\n_No response_\n\ncc @cbilgin",
      "updatedAt" : 1753396916.000000000,
      "user" : "kirklandsign",
      "userHtmlUrl" : "https://github.com/kirklandsign",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/107070759?v=4",
      "labels" : [ "triaged", "Android_GA", "module: android", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "On-device AI across mobile, embedded and edge for PyTorch",
        "homepage" : "https://pytorch.org/executorch/",
        "name" : "executorch",
        "fullName" : "pytorch/executorch",
        "htmlUrl" : "https://github.com/pytorch/executorch",
        "gitUrl" : "git://github.com/pytorch/executorch.git",
        "sshUrl" : "git@github.com:pytorch/executorch.git",
        "cloneUrl" : "https://github.com/pytorch/executorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 627,
        "stargazersCount" : 3054,
        "watchersCount" : 3054,
        "size" : 242669,
        "openIssuesCount" : 1273,
        "subscribersCount" : 69,
        "pushedAt" : "2025-07-25T00:57:59Z",
        "languages" : {
          "Java" : 91516,
          "C++" : 7679686,
          "Jinja" : 11160,
          "C" : 92780,
          "Objective-C++" : 585916,
          "CMake" : 258695,
          "Kotlin" : 47365,
          "Dockerfile" : 2846,
          "Shell" : 249480,
          "Starlark" : 490914,
          "Batchfile" : 339,
          "Objective-C" : 192676,
          "Swift" : 92248,
          "Python" : 9717219,
          "GLSL" : 337891
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add method metadata report API in Module.java for feature parity as python runtime and for users to check for inputs or do test automation.",
      "validationOrRequirement" : "Add more APIs to https://github.com/pytorch/executorch/blob/main/extension/android/executorch_android/src/main/java/org/pytorch/executorch/MethodMetadata.java#L12, and add a new API like `listMethods()` in https://github.com/pytorch/executorch/blob/143224370c106e8fa5421d4b49d5b28a1a725aff/extension/android/executorch_android/src/main/java/org/pytorch/executorch/Module.java#L43, and create a new Method.java to save some metadata.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description.",
      "otherNotes" : "The feature is for feature parity as python runtime, and maybe users will need the metadata to check for inputs, or do test automation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406434
  }, {
    "issueDTO" : {
      "id" : 3261056991,
      "title" : "Gemini CLI crashes on terminal resize or drag (Windows)",
      "url" : "https://github.com/google-gemini/gemini-cli/issues/4809",
      "repositoryName" : "google-gemini/gemini-cli",
      "description" : "<img width=\"634\" height=\"1021\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/84517a89-05bb-407f-9f37-bb3145782738\" />\n\n### What happened?\n\nAfter launching the gemini CLI using the gemini command on a Windows machine, the interface starts up normally. However, when I resize or drag the terminal window, the CLI enters a loop, repeatedly printing the startup screen. The UI becomes unusable and doesn't respond to inputs properly after this.\n\n### What did you expect to happen?\n\nThe Gemini CLI should retain its state and layout when the terminal is resized or moved, without entering an infinite redraw loop or crashing.\n\n### Client information\n\n<details>\n\n```console\n$ gemini /about\n# | CLI Version                    0.1.13                                                    \n | Git Commit                     412b78c5 (local modifications)                           \n??? Model                          gemini-2.5-pro                                            \n??? Sandbox                        no sandbox                                                \n??? OS                             win32                                                     \n??? Auth Method                    OAuth   \n```\nPlatform\nWindows 11 Home 64-bit\n[Using Windows Terminal]\n\n</details>\n\n\n### Login information\n\nGoogle Account\n\n### Anything else we need to know?\n\n_No response_",
      "updatedAt" : 1753396677.000000000,
      "user" : "Sparshr04",
      "userHtmlUrl" : "https://github.com/Sparshr04",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/154352929?v=4",
      "labels" : [ "kind/bug", "kind/documentation", "priority/p2", "area/contribution", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'd love to test the waters here and see if I can figure out what's going wrong. looks like it might be something with how resize events are handled, I???ll try reproducing it on my end and poke around the code a bit.\nIf no one???s on it yet, I???d be down to take a stab at a fix.", "That's great news! Thanks so much for offering to look into this. Let me know if you need any more information from my end, I'm happy to help in any way I can\n\n> I'd love to test the waters here and see if I can figure out what's going wrong. looks like it might be something with how resize events are handled, I???ll try reproducing it on my end and poke around the code a bit. If no one???s on it yet, I???d be down to take a stab at a fix.\n\n" ],
      "repository" : {
        "description" : "An open-source AI agent that brings the power of Gemini directly into your terminal.",
        "homepage" : "",
        "name" : "gemini-cli",
        "fullName" : "google-gemini/gemini-cli",
        "htmlUrl" : "https://github.com/google-gemini/gemini-cli",
        "gitUrl" : "git://github.com/google-gemini/gemini-cli.git",
        "sshUrl" : "git@github.com:google-gemini/gemini-cli.git",
        "cloneUrl" : "https://github.com/google-gemini/gemini-cli.git",
        "owner" : {
          "login" : "google-gemini",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5999,
        "stargazersCount" : 63648,
        "watchersCount" : 63648,
        "size" : 18267,
        "openIssuesCount" : 1398,
        "subscribersCount" : 311,
        "pushedAt" : "2025-07-25T00:19:30Z",
        "languages" : {
          "TypeScript" : 2800004,
          "Dockerfile" : 1354,
          "Shell" : 1112,
          "Makefile" : 1336,
          "JavaScript" : 87062
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the Gemini CLI crashing on terminal resize or drag on Windows.",
      "validationOrRequirement" : "The Gemini CLI should retain its state and layout when the terminal is resized or moved, without entering an infinite redraw loop or crashing.",
      "attemptedFixes" : "The issue has been discussed in the comments, and someone has offered to take a stab at a fix if no one else is working on it.",
      "otherNotes" : "The issue is reproducible on Windows 11 Home 64-bit using Windows Terminal, and the client information includes CLI Version 0.1.13, Git Commit 412b78c5, Model gemini-2.5-pro, Sandbox no sandbox, OS win32, and Auth Method OAuth.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406439
  }, {
    "issueDTO" : {
      "id" : 2640582608,
      "title" : "[Feature] Disable reporting per policy",
      "url" : "https://github.com/kyverno/kyverno/issues/11555",
      "repositoryName" : "kyverno/kyverno",
      "description" : "### Problem Statement\n\nThe huge number of resources in the cluster generates a huge number of reports, which is redundant and loads ETCD. However, disabling reporting completely is also not an option because some policies (with audit mode) require viewing the results.\n\n### Solution Description\n\nIt would be great to be able to disable reporting for selected policies if it is not necessary.\n\n### Alternatives\n\n_No response_\n\n### Additional Context\n\n_No response_\n\n### Slack discussion\n\nhttps://kubernetes.slack.com/archives/CLGR9BJU9/p1730887018753109\n\n### Research\n\n- [X] I have read and followed the documentation AND the [troubleshooting guide](https://kyverno.io/docs/troubleshooting/).\n- [X] I have searched other issues in this repository and mine is not recorded.",
      "updatedAt" : 1753396621.000000000,
      "user" : "nikprid",
      "userHtmlUrl" : "https://github.com/nikprid",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/26462673?v=4",
      "labels" : [ "reports", "end user", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/assign", "i think, It would also be great if it was possible to choose what will happen to policyReport resources after reporting is disabled for a policy: deleting reports for this policy or saving it.", "@realshuting can i contribute to this issue as i am total beginner and wants to start my opensource journey ", "/assign", "I am working on this now. If in one week no pull request comes from my side, then others can solve this issue\n" ],
      "repository" : {
        "description" : "Cloud Native Policy Management",
        "homepage" : "https://kyverno.io",
        "name" : "kyverno",
        "fullName" : "kyverno/kyverno",
        "htmlUrl" : "https://github.com/kyverno/kyverno",
        "gitUrl" : "git://github.com/kyverno/kyverno.git",
        "sshUrl" : "git@github.com:kyverno/kyverno.git",
        "cloneUrl" : "https://github.com/kyverno/kyverno.git",
        "owner" : {
          "login" : "kyverno",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1062,
        "stargazersCount" : 6541,
        "watchersCount" : 6541,
        "size" : 155513,
        "openIssuesCount" : 367,
        "subscribersCount" : 50,
        "pushedAt" : "2025-07-24T17:09:49Z",
        "languages" : {
          "Dockerfile" : 1720,
          "Shell" : 27881,
          "Makefile" : 51451,
          "Go" : 8444921,
          "Mustache" : 27483
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Disable reporting per policy for selected policies if it is not necessary",
      "validationOrRequirement" : "read and followed the documentation, searched other issues in this repository, and followed the troubleshooting guide",
      "attemptedFixes" : "I am working on this now",
      "otherNotes" : "Policies with audit mode require viewing results, disabling reporting completely is not an option, and some users are interested in deleting policyReport resources after reporting is disabled",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406442
  }, {
    "issueDTO" : {
      "id" : 354052775,
      "title" : "Duplicate colors in palette causes issues",
      "url" : "https://github.com/WordPress/gutenberg/issues/9357",
      "repositoryName" : "WordPress/gutenberg",
      "description" : "In the customizer we have created a palette control system, so users have a place to manage their palette globally for our themes.  After working on integration with Gutenburg, I've ran into an issue where users are selecting the same color for more than one of the colors in their palette.  In the color settings two colors are selected:\r\n\r\n![image](https://user-images.githubusercontent.com/11907254/44623442-402f3400-a89c-11e8-93ca-07bb4f56b0ea.png)\r\n\r\nWhen entering into the editor, the following error:\r\n\r\nWarning: Encountered two children with the same key, `rgb(29, 16, 22)`. Keys should be unique so that components maintain their identity across updates. Non-unique keys may cause children to be duplicated and/or omitted ??? the behavior is unsupported and could change in a future version.\r\n\r\nSince our themes let users change the palette in the customizer, and the color classes are already applied to several elements, it's easy for a user to select the same color twice.\r\n\r\nThis can be reproduced more easily by adding the same color key via the add_theme_support method:\r\n\r\n```\r\nadd_theme_support( 'editor-color-palette', array(\r\n    array(\r\n        'name' => __( 'Dark Background', 'themeLangDomain' ),\r\n        'slug' => 'dark-background',\r\n        'color' => 'rgb(0, 0, 0)',\r\n    ),\r\n    array(\r\n        'name' => __( 'Dark Text', 'themeLangDomain' ),\r\n        'slug' => 'dark-text',\r\n        'color' => 'rgb(0, 0, 0)',\r\n    ),\r\n) );\r\n```\r\nI think that the same color should be allowed to exist in the palette for the use case of allowing a user to easily change their entire palette for a theme via the global controls (ie the customizer), and that the color selected in the editor should be based on the slug key opposed to using the color key as the slug is meant to be unique, whereas a color doesn't necessarily need to be.\r\n\r\nOn an instance by instance basis editing content, it might not make much sense to allow multiple colors, so one way to solve this issue would be to remove duplicate colors and prevent the errors from occurring.  On the other hand as an example of where this is desirable: We have a theme author create a theme with our system and they assign a slot in the palette for the header background color, which is white, and they also assign another slot to the site content's background color, which is also white.  An end user who has the theme and wishes to customize it might want to change the color of their header to something more contrasting with the site content's background, and they can easily do this.  The same palette also impacts all of their site content, so it provides a way for a theme author supplying starter content in their themes a way to declare a relationship of how each slot in a palette effects elements on the site instead of tying the color directly to all elements just because it's the same, and ultimately gives the end users less flexibility.\r\n\r\nThe same issue would be evident when tackling #6941 as it would be easy for a user to select the same color twice as opposed to using a color they have already added in their palette.  \r\n\r\nTested on Gutenberg v3.6.2 & WordPress v4.9.8",
      "updatedAt" : 1753396255.000000000,
      "user" : "timelsass",
      "userHtmlUrl" : "https://github.com/timelsass",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11907254?v=4",
      "labels" : [ "Good First Issue", "Customization", "[Feature] Extensibility", "[Type] Enhancement", "Global Styles", "[Feature] Colors" ],
      "state" : "OPEN",
      "comments" : [ "I feel I mistakenly labeled this as a help request while it may make more sense as a feature request or enhancement and am correcting that now.", "I have the same problem with the theme I am developing. I also included a dark mode so now the problem is, that if there is the same color two times, always the first one is selected, although that one is thought for a totally different purpose, that way it can happen that the webpage looks not good anymore in one of the modes.", "+1 here. Same issue with the same reasoning behind having duplicate colors.", "@timelsass Did you find a workaround? I'm curious about slightly altering the syntax `rgb(0, 0, 0)` vs `rgb(0,0,0)` vs `rgb(0,0, 0)` each time it's duplicated. Feels super hacky but the still curious ;P", "+1 this is a very big problem for the theme I???m creating also. I very much want users to be able to reuse the same colors with different names (slugs). I want them to be able to select header, title, footer, primary, etc. colors that the theme uses. Users will definitely want the ability to specify the same color # for more than one of those. \r\n\r\nGutenberg already places the slug into the source HTML instead of the color, but it just chooses the first slug with the selected color. We would just need it to return the slug of the color that the user selected Is a color picker Instead.", "I am still facing the same issue in 2023, I still don't understand why WordPress uses color as the unique factor. Where the color can be same from time to time. Using slug would be have been the best approach. This is a really big problem.\r\n\r\nMy current hacky workaround is to change the last digit or alphabet of the hex eg: \r\nChange this from  #251046 -> #251045 , So one slug will have : #251046  and the other one will have #251045 , So that WordPress thinks that  its a different color, Hence as per WordPress a different slug. And as per user experience are concerned the difference in the color is not noticeable at all . Hope this helps others as a hacky workaround for the time being, Till WordPress fixes this issue. \r\n\r\n**Before :** \r\n\r\n![Animation22](https://user-images.githubusercontent.com/28552974/236424975-3028a0a1-3173-41b2-9655-0a06cec3eecc.gif)\r\n\r\n\r\n**After :** \r\n\r\n![Animation22](https://user-images.githubusercontent.com/28552974/236424677-7d0a710e-c25a-4495-adde-dcb737c2146b.gif)\r\n\r\n", "This has caused some issues for us that were very difficult to track down and identify and really should be improved or fixed. \r\n\r\nWe are upgrading from WP 5.4 to WP 5.7. Sometime between 5.4 and 5.7 two new default colors were added by WP / Gutenberg (White and Black with `#ffffff` and `#000000`)\r\n\r\nOur plugin was adding new color themes to the default list of colors and we have a color system that treats the colors as a \"theme\" and then applies that theme styling to the block if that `has-color-<theme>` class is applied. There are several colors palettes such as `Primary`, `Secondary` so classes are added as `has-color-primary` but we also had a `light` and `dark` option which the hex codes for the colors were set as `#ffffff` and `#000000`. \r\n\r\nIn 5.7 we were finding that when the user applied `Light` color the class `has-color-white` would be applied instead of `has-color-light` and so the styling for the \"Light\" theme was lost and not applied. \r\n\r\nIf instead of relying on the color value to apply the corresponding class name for the color it relied on the slug of the registered color it seems like this issue might go away. \r\n\r\nOur current work around is as others have said to go through and change our `Light` and `Dark` registered colors to be a slightly different hex code. However that is going to require updating not just our plugin but a good number of themes that can use a filter to modify the registered colors. \r\n\r\nIf this can't be fixed, at a minimum some documentation should be noted so that people avoid registering colors that have the same color value as any other colors that are registered. It'd be nice to see a warning in the console or editor if 2 colors with the same color value are registered and are going to result in this issue happening and the wrong class name getting applied. ", "I'm also having this problem (on wp: 6.4-beta1-56741; & gut: 16.7.0).\r\nAnd It's really frustrating. \r\nIt slows down the process of creating a theme, since it forces you to change the colors manually.\r\n\r\n![image](https://github.com/WordPress/gutenberg/assets/679512/0dad326e-61e6-41a7-819a-e412a18a96bb)\r\n\r\nI will use slighly different colors as nathan did [here](https://github.com/WordPress/gutenberg/issues/9357#issuecomment-1535941510) as workaround.\r\n\r\nI hope this gets fixed soon\uD83D\uDE4F", "How is this still not fixed? It destroys the very purpose of tokenizing themes.", "## Reproduction Report\n### Description\n??? This report validates that the issue can be reproduced.\n\n### Environment\n- WordPress: 6.9-alpha-60093-src\n- PHP: 8.2.29\n- Server: Apache/2.4.62 (Debian)\n- Database: mysqli (Server: 11.8.2-MariaDB-ubu2404 / Client: mysqlnd 8.2.29)\n- Browser: Chrome 138.0.0.0\n- OS: Windows 10/11\n- Theme: Twenty Twenty-Five 1.3\n- MU Plugins: None activated\n- Plugins:\n  * Gutenberg 21.3.0-rc.1\n  * Test Reports 1.2.0\n\n### Testing Instructions\n1. Add some extra colours to the `theme.json` **settings > color > palette** like this:\n```json\n{\n\t\"slug\": \"color-one\",\n\t\"name\": \"Color One\",\n\t\"color\": \"#ff0000\"\n},\n{\n\t\"slug\": \"color-two\",\n\t\"name\": \"Color Two\",\n\t\"color\": \"#ff0000\"\n},\n```\n2. Add to blocks in the editor, for example two paragraphs\n3. Select any of these two colours for background, for example\n4. \uD83D\uDC1E Both colours are selected at the same time\n\n### Actual Results\n1.  ??? Error condition occurs (reproduced).\n\n### Additional Notes\n- As many have pointed out, this is still live nowadays. It appears that the palette is prioritizing by the colour and not by the slug, which technically should be the unique ID for anything on WordPress. \n- For this reason, I think that this report is ready for patch and I believe it should not be very complex, so I think it is a good `Good First Bug`. If anyone is willing to take it, please ping me and I will be doing the follow-up testing.\n\n### Supplemental Artifacts\n\nScreencast showcase: https://f003.backblazeb2.com/file/wordpress-videos/wp-videos/2025/07/gb9357.mp4" ],
      "repository" : {
        "description" : "The Block Editor project for WordPress and beyond. Plugin is available from the official repository.",
        "homepage" : "https://wordpress.org/gutenberg/",
        "name" : "gutenberg",
        "fullName" : "WordPress/gutenberg",
        "htmlUrl" : "https://github.com/WordPress/gutenberg",
        "gitUrl" : "git://github.com/WordPress/gutenberg.git",
        "sshUrl" : "git@github.com:WordPress/gutenberg.git",
        "cloneUrl" : "https://github.com/WordPress/gutenberg.git",
        "owner" : {
          "login" : "WordPress",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4475,
        "stargazersCount" : 11303,
        "watchersCount" : 11303,
        "size" : 888958,
        "openIssuesCount" : 7577,
        "subscribersCount" : 344,
        "pushedAt" : "2025-07-25T00:54:39Z",
        "languages" : {
          "MDX" : 32524,
          "Java" : 211238,
          "CSS" : 20859,
          "Mustache" : 30576,
          "HTML" : 791962,
          "Kotlin" : 42181,
          "TypeScript" : 4490680,
          "Shell" : 24077,
          "Starlark" : 152,
          "PEG.js" : 8241,
          "SCSS" : 785897,
          "JavaScript" : 13250996,
          "PHP" : 2004595,
          "Objective-C" : 7609,
          "Swift" : 126502,
          "Ruby" : 6854
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the error 'Warning: Encountered two children with the same key, rgb(29, 16, 22). Keys should be unique so that components maintain their identity across updates.' and to allow users to easily change their entire palette for a theme via the global controls.",
      "validationOrRequirement" : "The validation or requirement is that the color key should be unique, and the color selected in the editor should be based on the slug instead of the color key. The issue is that the color key is not unique, and the color selected in the editor is based on the color key instead of the slug.",
      "attemptedFixes" : "Some users have used a hacky workaround by changing the last digit or alphabet of the hex code to make it unique. Others have suggested using a slug instead of the color key to identify the color. The author of the issue has also suggested that the palette should prioritize the slug instead of the color.",
      "otherNotes" : "The issue is with the duplicate colors in the palette, which causes the error 'Warning: Encountered two children with the same key, rgb(29, 16, 22). Keys should be unique so that components maintain their identity across updates.' The problem is that the color key is not unique, and the color selected in the editor is based on the color key instead of the slug. This can be reproduced by adding the same color key via the add_theme_support method. The issue is that the same color can exist in the palette for the use case of allowing a user to easily change their entire palette for a theme via the global controls. The workaround is to remove duplicate colors and prevent the errors from occurring.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406453
  }, {
    "issueDTO" : {
      "id" : 3097820780,
      "title" : "Prompt Improvements",
      "url" : "https://github.com/srbhr/Resume-Matcher/issues/374",
      "repositoryName" : "srbhr/Resume-Matcher",
      "description" : "### **Is your feature request related to a problem? Please describe.**\n\nHey team,\n\nWe've hit a bit of a snag with our AI's performance, specifically concerning its tendency to **hallucinate** when using the [`apps/backend/app/prompt/resume_improvement.py`](https://github.com/srbhr/Resume-Matcher/blob/main/apps/backend/app/prompt/resume_improvement.py) prompt. While our current prompts are generally functional, this hallucination leads to the AI generating inaccurate or fabricated suggestions for resume improvements. This directly impacts the quality of the advice we offer users and, frankly, chips away at their trust in our application.\n\nBeyond that, I'm anticipating some memory usage inefficiencies as our application grows and our prompts become more complex. We need to be proactive about **optimizing our memory** to keep things running smoothly.\n\n---\n\n### **Describe the solution you'd like**\n\nMy vision is to make our AI prompts more robust and our application more memory-efficient. Here???s what I propose:\n\n* **Tackling Hallucination in [`resume_improvement.py`](https://github.com/srbhr/Resume-Matcher/blob/main/apps/backend/app/prompt/resume_improvement.py):**\n    * We need to dive deep into this specific prompt. Let's try refining the instructions to be super clear, adding stronger constraints, and possibly providing more targeted examples within the prompt itself. The goal is to guide the AI away from generating any made-up content.\n    * We should also consider techniques like Chain-of-Thought prompting or giving the AI better contextual grounding to ensure its suggestions are always accurate and relevant.\n\n* **General Prompt Optimization:**\n    * Let's also take a look at all other prompts located in [`apps/backend/app/prompt/`](https://github.com/srbhr/Resume-Matcher/tree/main/apps/backend/app/prompt). We should aim to make them as clear and concise as possible, reducing any ambiguity that might lead to less-than-ideal AI responses.\n\n* **Strategic Garbage Collection:**\n    * We need to identify areas where we might be holding onto memory unnecessarily. Think about parts of the code where large, temporary data structures are created during prompt processing or AI interactions but aren't needed afterward. We should implement garbage collection in these specific spots to free up that memory and boost performance.\n\n---\n\n### **Describe alternatives you've considered**\n\nI've thought about a couple of other approaches, but I believe addressing the prompts directly is our best bet:\n\n* **Post-processing AI output:** We could try to build a system that filters out or corrects hallucinated content *after* the AI generates it. While this might catch some issues, it's a reactive fix and could introduce extra latency and complexity. I'd rather prevent the problem at its source.\n* **Exploring different AI models:** While a different LLM might have fewer hallucination tendencies, I think we can get significant improvements by optimizing how we interact with our current model through prompt engineering. This is a more immediate and controlled path forward without requiring major infrastructure changes.\n\n---\n\n### **Additional context**\n\nThe resume improvement feature is a cornerstone of our application, providing direct value to our users. Making it more reliable will significantly enhance user satisfaction and our product's overall quality. Plus, optimizing memory with garbage collection isn't just about immediate performance; it's about ensuring our application remains stable and scalable as we grow.\n\nLet's deliver a more robust experience for our users!",
      "updatedAt" : 1753396241.000000000,
      "user" : "rrvrs",
      "userHtmlUrl" : "https://github.com/rrvrs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47035684?v=4",
      "labels" : [ "veridis_quo", "ai", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@rrvrs can you add the links to the files in this issue? Namely to the `resume_improvement.py` file?", "Thanks for pointing that out @srbhr. I have added the links and updated the above issue.", "Hi, I want to start working on this issue. How can I start? I have worked on similar projects in the past.\n@rrvrs ", "I have a few suggestions ->\n1.) in [apps/backend/app/agent/providers/openai.py](https://github.com/srbhr/Resume-Matcher/blob/main/apps/backend/app/agent/providers/openai.py), we can use structured output and output it as JSON and convert it to markdown. \nhttps://platform.openai.com/docs/guides/structured-outputs?api-mode=responses&example=chain-of-thought\nThis is specifically important in the JSON Extraction Prompt, we dont need to handle as the OpenAI API will do the job for us.\n\n2.) To tackle the hallucination issue in apps/backend/app/prompt/resume_improvement.py, the core problem stems from the prompt's allowance for \"adding\" content, which can encourage the LLM to fabricate details not present in the original resume.  I recommend revising the prompt to strictly limit changes to rephrasing, reorganizing, and emphasizing existing content only. This prevents invention of new facts while still allowing keyword integration where it naturally fits.\n\nFor example,\n```\nPROMPT = \"\"\"\nYou are an expert resume editor and talent acquisition specialist. Your task is to revise the following resume so that it aligns as closely as possible with the provided job description and extracted job keywords, in order to maximize the cosine similarity between the resume and the job keywords.\n\nInstructions:\n- Carefully review the job description and the list of extracted job keywords.\n- Update the candidate's resume by:\n  - Emphasizing and naturally incorporating relevant skills, experiences, and keywords from the job description and keyword list, but only where they align with existing content in the original resume.\n  - Where appropriate, naturally weave the extracted job keywords into the resume content if they can be supported by the original details???do not force them if they do not fit.\n  - Rewriting or removing resume content as needed to better match the job requirements, but do not add any new experiences, skills, achievements, or details that are not present in the original resume.\n  - Base all revisions strictly on the original resume; do not invent or fabricate any information.\n  - Maintaining a natural, professional tone and avoiding keyword stuffing.\n  - Where possible, use quantifiable achievements and action verbs from the original content.\n  - The current cosine similarity score is {current_cosine_similarity:.4f}. Revise the resume to further increase this score without violating the above rules.\n- ONLY output the improved updated resume. Do not include any explanations, commentary, or formatting outside of the resume itself.\n\nJob Description:\n```md\n{raw_job_description}\n\nExtracted Job Keywords:\n```md\n{extracted_job_keywords}\n```\n\nOriginal Resume:\n```md\n{raw_resume}\n```\n\nExtracted Resume Keywords:\n```md\n{extracted_resume_keywords}\n```\n\nNOTE: ONLY OUTPUT THE IMPROVED UPDATED RESUME IN MARKDOWN FORMAT.\n\"\"\"\n```\n\nOther Improvements that can be possible ->\na) Add Few-Shot Examples: Include 1-2 concise examples within the prompt to demonstrate ideal revisions. This helps the LLM pattern-match more effectively.But this will increase the prompt length and memory footprint.\nb) Enhance Constraints with Chain-of-Thought (CoT) Guidance : Encourage internal reasoning without outputting it. Update instructions:\n    \"First, internally identify exact matches between original resume elements and job keywords. Then, revise only those sections. Do not output this reasoning.\" This promotes step-by-step thinking, reducing errors in alignment.\nc) Using a RAG workflow on the resume combined with  CoT guidance. \n", "> * Tackling Hallucination in `resume_improvement.py`\n\n@rrvrs There is a fine line between hallucinating and aligning the resume with the job description. How can we increase the score, but at the same time stay true to the candidate's experience? I struggle with this when editing manually???some people are just naturally better at it than others.\n\n\n" ],
      "repository" : {
        "description" : "Improve your resumes with Resume Matcher. Get insights, keyword suggestions and tune your resumes to job descriptions. ",
        "homepage" : "https://resumematcher.fyi/",
        "name" : "Resume-Matcher",
        "fullName" : "srbhr/Resume-Matcher",
        "htmlUrl" : "https://github.com/srbhr/Resume-Matcher",
        "gitUrl" : "git://github.com/srbhr/Resume-Matcher.git",
        "sshUrl" : "git@github.com:srbhr/Resume-Matcher.git",
        "cloneUrl" : "https://github.com/srbhr/Resume-Matcher.git",
        "owner" : {
          "login" : "srbhr",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4027,
        "stargazersCount" : 18643,
        "watchersCount" : 18643,
        "size" : 113247,
        "openIssuesCount" : 92,
        "subscribersCount" : 78,
        "pushedAt" : "2025-07-23T10:25:47Z",
        "languages" : {
          "TypeScript" : 92852,
          "PowerShell" : 11492,
          "Shell" : 5349,
          "CSS" : 4652,
          "Makefile" : 1281,
          "JavaScript" : 1264,
          "Python" : 90317
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to improve the AI prompts to reduce hallucination and optimize memory usage, specifically in the `resume_improvement.py` prompt, to provide a more robust experience for users and ensure the application remains stable and scalable as it grows.",
      "validationOrRequirement" : "The author has proposed some requirements for the solution, including refining the `resume_improvement.py` prompt, optimizing other prompts, and implementing strategic garbage collection. The author has also mentioned that the solution should prevent the AI from generating made-up content and ensure that the suggestions are always accurate and relevant.",
      "attemptedFixes" : "The author has suggested a few approaches to tackle the hallucination issue, including refining the prompt, using structured output, and revising the prompt to strictly limit changes to rephrasing, reorganizing, and emphasizing existing content only. The author has also provided some suggestions for further improvements, such as adding few-shot examples, enhancing constraints with chain-of-thought guidance, and using a RAG workflow on the resume combined with CoT guidance.",
      "otherNotes" : "The issue is about improving AI prompts to reduce hallucination and optimizing memory usage. The proposed solution includes refining the `resume_improvement.py` prompt, optimizing other prompts, and implementing strategic garbage collection. The author has considered alternative approaches and provided additional context about the importance of the resume improvement feature.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406462
  }, {
    "issueDTO" : {
      "id" : 3099241575,
      "title" : "DecompositionContext is never None",
      "url" : "https://github.com/quantumlib/Cirq/issues/7384",
      "repositoryName" : "quantumlib/Cirq",
      "description" : "In `decompose_protocol.py`, `\"_decompose_with_context_\"` is never called without a valid `DecompositionContext`. However, many of the type annotations, both in `decompose_protocol.py` and in `_decompose_with_context_` implementations across the project, specify `context: DecompositionContext | None = None`. The `None` option should be removed from all of these except at the very top level `decompose_protocol` entrypoints (`decompose`, `decompose_once`, and `decompose_once_with_qubits`), since AFAICT they'll never be hit.",
      "updatedAt" : 1753396239.000000000,
      "user" : "daxfohl",
      "userHtmlUrl" : "https://github.com/daxfohl",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/905073?v=4",
      "labels" : [ "no QC knowledge needed", "triage/accepted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey, I would like to take up this issue\n", "@siddhantlal Thank you for your interest. Just to clarify, you are interested in doing this independently of the unitaryHACK? (This is not an issue for the hackathon.)", "@mhucka Hey there, actually I was doing this independently of the Hackathon ", "Quick note on this: a few of the classes that implement `_decompose_with_context_` also define a `def _decompose_(...): self._decompose_with_context_(context=None)`, which does pass `None` in for `context`. So it would seem that maybe the `context` parameter of `_decompose_with_context_` does need to support `None` in these cases.\n\n**However**, those `_decompose_` definitions are unnecessary and should be removed. The `decompose` protocol itself only calls `_decompose_` after it has already tried calling `_decompose_with_context_`, so there's no reason to have a `_decompose_` implementation that just re-calls `_decompose_with_context_`; it's just a redundant call, and could even result in a bug because it causes the provided context to be ignored.\n\nOnce those are removed, then the `None` option can be removed from the corresponding `_decompose_with_context_` implementations.", "One exception to the above comment: removing `GateOperation._decompose_` is problematic because `SingleQubitPauliStringGateOperation` inherits both `GateOperation` and `PauliString`. Currently the `GateOperation._decompose_` hides `PauliString._decompose_`, but if we delete the former, then the latter will get called instead for `SingleQubitPauliStringGateOperation`, which will lead to problems. A couple options:\n\n1. Have `GateOperation._decompose_` return `NotImplemented` explicitly instead of removing it.\n2. Rename `PauliString._decompose_` to `PauliString._decompose_with_context_` so that `GateOperation` still hides it.\n3. Have `PauliString._decompose_` explicitly return `NotImplemented` if it's a `GateOperation`.\n4. Update the decompose protocol itself to call one or the other, but not both. \n\nAny one or all of them would work." ],
      "repository" : {
        "description" : "An open-source Python framework for creating, editing, and invoking Noisy Intermediate-Scale Quantum (NISQ) circuits.",
        "homepage" : "https://quantumai.google/cirq",
        "name" : "Cirq",
        "fullName" : "quantumlib/Cirq",
        "htmlUrl" : "https://github.com/quantumlib/Cirq",
        "gitUrl" : "git://github.com/quantumlib/Cirq.git",
        "sshUrl" : "git@github.com:quantumlib/Cirq.git",
        "cloneUrl" : "https://github.com/quantumlib/Cirq.git",
        "owner" : {
          "login" : "quantumlib",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1128,
        "stargazersCount" : 4663,
        "watchersCount" : 4663,
        "size" : 41184,
        "openIssuesCount" : 169,
        "subscribersCount" : 187,
        "pushedAt" : "2025-07-24T20:17:39Z",
        "languages" : {
          "TypeScript" : 90782,
          "Shell" : 66105,
          "Scilab" : 1447,
          "JavaScript" : 660,
          "Jupyter Notebook" : 672285,
          "Python" : 9877208
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "DecomposeContext is never None, remove None option from type annotations, handle GateOperation._decompose_ method separately",
      "validationOrRequirement" : "remove None option from all type annotations except at the very top level decompose_protocol entrypoints",
      "attemptedFixes" : "removing unnecessary _decompose_ methods, handling GateOperation._decompose_ method separately due to inheritance issues",
      "otherNotes" : "A few classes that implement _decompose_with_context_ also define a def _decompose_(...) method, which does pass None in for context. This _decompose_ method is unnecessary and should be removed. Additionally, GateOperation._decompose_ method should be handled separately due to inheritance issues with SingleQubitPauliStringGateOperation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406467
  }, {
    "issueDTO" : {
      "id" : 3256380971,
      "title" : "Increase margin at the main menu bottom",
      "url" : "https://github.com/josdem/vetlog-spring-boot/issues/665",
      "repositoryName" : "josdem/vetlog-spring-boot",
      "description" : "**Steps to reproduce**\n- Run the application\n- Go to the home page\n- Make a mouse over at the main menu\n\n**Expected result**\n- Vetlog logo and the orange shade are in the same size\n\n**Actual result**\n- Main menu has a white space at the bottom\n\n**Screenshot**\n<img width=\"1149\" height=\"732\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ca34edf9-a37d-4c86-b776-868961a68fd1\" />",
      "updatedAt" : 1753395917.000000000,
      "user" : "josdem",
      "userHtmlUrl" : "https://github.com/josdem",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1222062?v=4",
      "labels" : [ "development", "backlog", "bug", "help wanted", "enhancement", "front-end", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@josdem what browser are you using? I tested on Opera and Chrome and on both I don't see mentioned issue. On your screenshot I see that under photo there is white margin. But normally it is not present.\n\n<img width=\"758\" height=\"99\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7c1361a5-b342-46e6-9ae8-5c7872dda4aa\" />", "> [@josdem](https://github.com/josdem) what browser are you using? I tested on Opera and Chrome and on both I don't see mentioned issue. On your screenshot I see that under photo there is white margin. But normally it is not present.\n> \n> <img alt=\"Image\" width=\"758\" height=\"99\" src=\"https://private-user-images.githubusercontent.com/33027221/470459149-7c1361a5-b342-46e6-9ae8-5c7872dda4aa.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTMzOTAzNTIsIm5iZiI6MTc1MzM5MDA1MiwicGF0aCI6Ii8zMzAyNzIyMS80NzA0NTkxNDktN2MxMzYxYTUtYjM0Mi00NmU2LTlhZTgtNWM3ODcyZGRhNGFhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA3MjQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNzI0VDIwNDczMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA4ZTJjNzRlNTkyNGQxZWVmNmNjNmQyMWFhZmVlNGEwMDEzOGRhODViODA0NDZiNWE5NTVjOTEyODYyMDY4MWImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.GL3HQVrxfekeUH1sFSRl5wIxiuvT3KslBhaNRt9SYb8\">\n\nHi @bestemic are you running locally? please update your code base with main branch and you will see it, please let me now if is not the case.", "@josdem I have latest version of the code. Also I have checked on official website and it is also looking in the same way. Please see below:\n\n<img width=\"753\" height=\"164\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b5c8688e-d491-48c1-a879-d6541c0e8c18\" />" ],
      "repository" : {
        "description" : "Maintain your pet history organized",
        "homepage" : "https://vetlog.org",
        "name" : "vetlog-spring-boot",
        "fullName" : "josdem/vetlog-spring-boot",
        "htmlUrl" : "https://github.com/josdem/vetlog-spring-boot",
        "gitUrl" : "git://github.com/josdem/vetlog-spring-boot.git",
        "sshUrl" : "git@github.com:josdem/vetlog-spring-boot.git",
        "cloneUrl" : "https://github.com/josdem/vetlog-spring-boot.git",
        "owner" : {
          "login" : "josdem",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 63,
        "stargazersCount" : 40,
        "watchersCount" : 40,
        "size" : 33151,
        "openIssuesCount" : 12,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-25T00:07:20Z",
        "languages" : {
          "Java" : 197283,
          "Dockerfile" : 980,
          "CSS" : 18698,
          "JavaScript" : 109358,
          "HTML" : 105541,
          "Kotlin" : 163665
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Increase the margin at the main menu bottom to match the size of the Vetlog logo and the orange shade.",
      "validationOrRequirement" : "The issue is related to the main menu having a white space at the bottom, which is not expected. The expected result is that the Vetlog logo and the orange shade are the same size.",
      "attemptedFixes" : "The author asked @bestemic to run the application locally and update the code base with the main branch, but it's not clear if this was done. The author also checked if the issue was present on the official website.",
      "otherNotes" : "The issue is related to the main menu having a white space at the bottom, which is not expected. The expected result is that the Vetlog logo and the orange shade are the same size. The author tested on Opera and Chrome and did not see the issue. The author also checked on the official website and it looks the same way.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406474
  }, {
    "issueDTO" : {
      "id" : 3246359512,
      "title" : "API: Update `init` function of slack integration",
      "url" : "https://github.com/keyshade-xyz/keyshade/issues/1082",
      "repositoryName" : "keyshade-xyz/keyshade",
      "description" : "## Description\n\nWe should update this function to send a message to the slack channel stating that it has been configured properly in keyshade,\n\nhttps://github.com/keyshade-xyz/keyshade/blob/9fba34814557a0fef4622c6ca3c820d3cd9d038f/apps/api/src/integration/plugins/slack.integration.ts#L33-L36",
      "updatedAt" : 1753395825.000000000,
      "user" : "rajdip-b",
      "userHtmlUrl" : "https://github.com/rajdip-b",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/83924254?v=4",
      "labels" : [ "difficulty: 2", "type: enhancement", "scope: api", "good first issue", "priority: medium" ],
      "state" : "OPEN",
      "comments" : [ "/attempt", "Assigned the issue to @m1r9n1!", "@m1r9n1, please open a draft PR linking this issue!" ],
      "repository" : {
        "description" : "Realtime secret and configuration management tool, with the best in class security and seamless integration support",
        "homepage" : "https://keyshade.xyz",
        "name" : "keyshade",
        "fullName" : "keyshade-xyz/keyshade",
        "htmlUrl" : "https://github.com/keyshade-xyz/keyshade",
        "gitUrl" : "git://github.com/keyshade-xyz/keyshade.git",
        "sshUrl" : "git@github.com:keyshade-xyz/keyshade.git",
        "cloneUrl" : "https://github.com/keyshade-xyz/keyshade.git",
        "owner" : {
          "login" : "keyshade-xyz",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 218,
        "stargazersCount" : 415,
        "watchersCount" : 415,
        "size" : 24032,
        "openIssuesCount" : 68,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-24T16:03:04Z",
        "languages" : {
          "TypeScript" : 2273788,
          "MDX" : 64059,
          "Dockerfile" : 5043,
          "CSS" : 1444,
          "PLpgSQL" : 15228,
          "JavaScript" : 9318
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the `init` function of slack integration to send a message to the slack channel stating that it has been configured properly in keyshade",
      "validationOrRequirement" : "difficulty: 2, type: enhancement, scope: api, good first issue, priority: medium",
      "attemptedFixes" : "Assigned the issue to @m1r9n1!, @m1r9n1, please open a draft PR linking this issue!",
      "otherNotes" : "https://github.com/keyshade-xyz/keyshade/blob/9fba34814557a0fef4622c6ca3c820d3cd9d038f/apps/api/src/integration/plugins/slack.integration.ts#L33-L36",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406479
  }, {
    "issueDTO" : {
      "id" : 2176793537,
      "title" : "org.eclipse.lsp4jakarta.commons.JavaCursorContextKind.forValue() throws an IllegalArgumentException when passed the value from its own NONE constant.",
      "url" : "https://github.com/eclipse-lsp4jakarta/lsp4jakarta/issues/520",
      "repositoryName" : "eclipse-lsp4jakarta/lsp4jakarta",
      "description" : "This was discovered while testing completion support in Liberty Tools for IntelliJ. See discussion here: https://github.com/OpenLiberty/liberty-tools-intellij/issues/681. The problem is that the `forValue()` method assumes that all of the values are 1 more than their regular enum ordinal value which is true for all of the constants except for `NONE` whose value is 2000.",
      "updatedAt" : 1753395503.000000000,
      "user" : "mrglavas",
      "userHtmlUrl" : "https://github.com/mrglavas",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/890521?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Since `JavaCursorContextKind` is a copy of an enum class that is also in LSP4MP, LSP4MP also has this issue.", "@archana-1924 do you want to make the same change in LSP4MP? If you prefer I could do it." ],
      "repository" : {
        "description" : "Language Server for Jakarta EE",
        "homepage" : "",
        "name" : "lsp4jakarta",
        "fullName" : "eclipse-lsp4jakarta/lsp4jakarta",
        "htmlUrl" : "https://github.com/eclipse-lsp4jakarta/lsp4jakarta",
        "gitUrl" : "git://github.com/eclipse-lsp4jakarta/lsp4jakarta.git",
        "sshUrl" : "git@github.com:eclipse-lsp4jakarta/lsp4jakarta.git",
        "cloneUrl" : "https://github.com/eclipse-lsp4jakarta/lsp4jakarta.git",
        "owner" : {
          "login" : "eclipse-lsp4jakarta",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 56,
        "stargazersCount" : 35,
        "watchersCount" : 35,
        "size" : 8855,
        "openIssuesCount" : 108,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-18T21:40:46Z",
        "languages" : {
          "Java" : 1305881,
          "Shell" : 256
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The JavaCursorContextKind.forValue() method throws an IllegalArgumentException when passed the value from its own NONE constant.",
      "validationOrRequirement" : "The forValue() method should handle the value from its own NONE constant correctly.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue was discovered while testing completion support in Liberty Tools for IntelliJ, and the problem is that the forValue() method assumes that all of the values are 1 more than their regular enum ordinal value which is true for all of the constants except for NONE whose value is 2000.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406482
  }, {
    "issueDTO" : {
      "id" : 2008332524,
      "title" : "Avoid variables named _",
      "url" : "https://github.com/philips-software/roslyn-analyzers/issues/719",
      "repositoryName" : "philips-software/roslyn-analyzers",
      "description" : "The following card is not a discard, but a variable named underscore:\r\n\r\n`byte[] _ = ExtractData(reader);\r\n`",
      "updatedAt" : 1753395440.000000000,
      "user" : "bcollamore",
      "userHtmlUrl" : "https://github.com/bcollamore",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/57269455?v=4",
      "labels" : [ "new analyzer", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Roslyn Diagnostic Analyzers are customized compiler errors providing real-time feedback to C# developers. Each Analyzer optionally includes an automatic Code Fixer.",
        "homepage" : null,
        "name" : "roslyn-analyzers",
        "fullName" : "philips-software/roslyn-analyzers",
        "htmlUrl" : "https://github.com/philips-software/roslyn-analyzers",
        "gitUrl" : "git://github.com/philips-software/roslyn-analyzers.git",
        "sshUrl" : "git@github.com:philips-software/roslyn-analyzers.git",
        "cloneUrl" : "https://github.com/philips-software/roslyn-analyzers.git",
        "owner" : {
          "login" : "philips-software",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 13,
        "stargazersCount" : 54,
        "watchersCount" : 54,
        "size" : 3245,
        "openIssuesCount" : 48,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T22:56:45Z",
        "languages" : {
          "C#" : 1112229,
          "PowerShell" : 12745
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Avoid variables named _ in a specific code snippet",
      "validationOrRequirement" : "Variables should not be named _",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about avoiding variables named _ in a specific code snippet, and it is labeled as a good first issue and new analyzer.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406485
  }, {
    "issueDTO" : {
      "id" : 3018305497,
      "title" : "[Android] Add a Runtime.java",
      "url" : "https://github.com/pytorch/executorch/issues/10439",
      "repositoryName" : "pytorch/executorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nRight now we have two places loading library https://github.com/search?q=repo%3Apytorch%2Fexecutorch%20loadlib&type=code\n\nInstead, can we just have one place, in a new file say Runtime.java?\n\n```\nclass Runtime {\nstatic {\n  // Loads libexecutorch.so from jniLibs\n  NativeLoader.loadLibrary(\"executorch\");\n}\n\nstatic boolean isInitialized() {\n  // maybe check something else?\n}\n}\n```\n\nThen in NativePeer.java and LlmModule.java\n\n```\nstatic {\n  if (!Runtime.isInitialized()) {\n    throw ...\n  }\n}\n\n```\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\n### RFC (Optional)\n\n_No response_\n\ncc @cbilgin",
      "updatedAt" : 1753395409.000000000,
      "user" : "kirklandsign",
      "userHtmlUrl" : "https://github.com/kirklandsign",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/107070759?v=4",
      "labels" : [ "triaged", "Android_GA", "module: android", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hello there can work for this issue?", "Hi @LefterisXefteris feel free to grab it.", "Hi @LefterisXefteris, I'm working on [adding Java API for runtime info](https://github.com/pytorch/executorch/issues/10438). I've implemented Runtime.java (along with a unit test) for the feature. Feel free to use the code from [my branch](https://github.com/pytorch/executorch/compare/main...keyprocedure:executorch:add-android-runtime-api) if it helps to close out this issue.\n\n\n", "@keyprocedure ohh sorry for the delay, i will do that now, thanks", "Hello @keyprocedure @LefterisXefteris  please feel free to open up a PR. Thank you!", "For delegate list, use https://github.com/pytorch/executorch/blob/9f6c0f2d85fed86f9daac76e8ccb13af2b838c3d/runtime/backend/interface.h#L146-L151\n\n\nSo in Java, expect something like \n```\npublic class Runtime {\npublic String[] getRegisteredBackends() {} -> JNI #include <executorch/runtime/backend/interface.h> and for (int size_t i = 0; i < executorch::ET_RUNTIME_NAMESPACE::get_num_registered_backends()) { result.add(get_backend_name(i)) }\n}\n```\nFor kernels (ops) it's\nhttps://github.com/pytorch/executorch/blob/9f6c0f2d85fed86f9daac76e8ccb13af2b838c3d/runtime/kernel/operator_registry.h#L237-L240\nand you can visit kernel.name_\n" ],
      "repository" : {
        "description" : "On-device AI across mobile, embedded and edge for PyTorch",
        "homepage" : "https://pytorch.org/executorch/",
        "name" : "executorch",
        "fullName" : "pytorch/executorch",
        "htmlUrl" : "https://github.com/pytorch/executorch",
        "gitUrl" : "git://github.com/pytorch/executorch.git",
        "sshUrl" : "git@github.com:pytorch/executorch.git",
        "cloneUrl" : "https://github.com/pytorch/executorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 627,
        "stargazersCount" : 3054,
        "watchersCount" : 3054,
        "size" : 242669,
        "openIssuesCount" : 1273,
        "subscribersCount" : 69,
        "pushedAt" : "2025-07-25T00:57:59Z",
        "languages" : {
          "Java" : 91516,
          "C++" : 7679686,
          "Jinja" : 11160,
          "C" : 92780,
          "Objective-C++" : 585916,
          "CMake" : 258695,
          "Kotlin" : 47365,
          "Dockerfile" : 2846,
          "Shell" : 249480,
          "Starlark" : 490914,
          "Batchfile" : 339,
          "Objective-C" : 192676,
          "Swift" : 92248,
          "Python" : 9717219,
          "GLSL" : 337891
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Consolidate two places loading a library into a new file named Runtime.java, and add a check to ensure the library is initialized before using it.",
      "validationOrRequirement" : "The code should be reviewed and tested to ensure it meets the requirements. The Runtime.java file should be used in NativePeer.java and LlmModule.java. The getRegisteredBackends() method should return an array of registered backends.",
      "attemptedFixes" : "A Runtime.java file has been implemented, along with a unit test. The code is available on a branch.",
      "otherNotes" : "The feature aims to consolidate two places loading a library into a new file named Runtime.java. It also involves checking if the library is initialized before using it. The issue has been partially addressed, with a Runtime.java file implemented and a unit test added.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406490
  }, {
    "issueDTO" : {
      "id" : 3261404603,
      "title" : "Add trending score to the Book Page (if > threshold)",
      "url" : "https://github.com/internetarchive/openlibrary/issues/11072",
      "repositoryName" : "internetarchive/openlibrary",
      "description" : "### Feature Request\n\n### Problem / Opportunity\n<!-- Describe: What is the problem this proposal addresses & for which audience(s)? -->\n\nWe recently added trending scores to our solr search engine. This means, when we arrive on the book page, we should have trending score available to us.\n\n<!-- Justify: Why should we work on this and what is the measurable impact? -->\n\n<!-- Define Success: How will we know when the problem is solved? -->\n\n### Proposal\n<!-- Brief overview of your proposed solution -->\n\nIf the trending score for the book on the book page is > some threshold e.g. 5, then render the trending badge macro.\n\nhttps://github.com/internetarchive/openlibrary/blob/master/openlibrary/macros/TrendingBadge.html\n\nPlease propose a design if you'd like to work on this issue :) \n\n<!-- Relevant designs, screenshots, or reference implementations that may help reviewers evaluate your proposal -->\n\n\n### Breakdown\n\n### Related files\n<!-- Add links to files relevant to the implementation of this proposal; useful for good first issues -->\nRefer to [this map of common Endpoints](https://github.com/internetarchive/openlibrary/wiki/Endpoints):\n*\n\n### Requirements Checklist\nChecklist of requirements that need to be satisfied in order for this issue to be closed:\n* [ ]\n\n### Stakeholders\n<!-- @ tag stakeholders of this feature, clarify their stake, and specify what checkoff is required from them -->\n*\n\n<hr>\n\n### Instructions for Contributors\n<!-- Please leave the following reminder section as is to help new contributors and add instructions where necessary -->\n* **Before** [creating a new branch](https://github.com/internetarchive/openlibrary/wiki/Git-Cheat-Sheet#making-changes-and-creating-a-pull-request) or pushing up changes to a PR, please first [run these commands](https://github.com/internetarchive/openlibrary/wiki/Git-Cheat-Sheet#working-on-your-branch) to ensure your repository is up to date, as the pre-commit bot may add commits to your PRs upstream.\n",
      "updatedAt" : 1753395355.000000000,
      "user" : "mekarpeles",
      "userHtmlUrl" : "https://github.com/mekarpeles",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/978325?v=4",
      "labels" : [ "Good First Issue", "Lead: @cdrini", "Priority: 3", "Theme: Book Page", "Type: Feature Request" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "One webpage for every book ever published!",
        "homepage" : "https://openlibrary.org",
        "name" : "openlibrary",
        "fullName" : "internetarchive/openlibrary",
        "htmlUrl" : "https://github.com/internetarchive/openlibrary",
        "gitUrl" : "git://github.com/internetarchive/openlibrary.git",
        "sshUrl" : "git@github.com:internetarchive/openlibrary.git",
        "cloneUrl" : "https://github.com/internetarchive/openlibrary.git",
        "owner" : {
          "login" : "internetarchive",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1583,
        "stargazersCount" : 5773,
        "watchersCount" : 5773,
        "size" : 99535,
        "openIssuesCount" : 877,
        "subscribersCount" : 174,
        "pushedAt" : "2025-07-24T23:21:11Z",
        "languages" : {
          "MDX" : 900,
          "Dockerfile" : 5593,
          "Shell" : 99314,
          "CSS" : 2800,
          "PLpgSQL" : 16061,
          "Makefile" : 2625,
          "JavaScript" : 635427,
          "Vue" : 208922,
          "HTML" : 701123,
          "Less" : 298302,
          "Python" : 2564724
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add trending score to the Book Page (if > threshold) and render the trending badge macro if the score is above the threshold.",
      "validationOrRequirement" : "The trending score for the book on the book page should be > some threshold e.g. 5, then render the trending badge macro.",
      "attemptedFixes" : "None mentioned in the issue description.",
      "otherNotes" : "The issue is related to adding trending score to the Book Page, which is already available in the Solr search engine.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406494
  }, {
    "issueDTO" : {
      "id" : 762554480,
      "title" : "Remove jquery constructs used in angularJS code",
      "url" : "https://github.com/oppia/oppia/issues/11371",
      "repositoryName" : "oppia/oppia",
      "description" : "- [x] .addClass(), .removeClass(): #11329\n- [x] .css(): #11330 @himkar-cmd  \n  - PR: https://github.com/oppia/oppia/pull/22477\n- [ ] Animations including .animate(), .blur(), .fadeIn(), .fadeOut() @himkar-cmd \n  - PR: https://github.com/oppia/oppia/pull/22510\n  - New PR: https://github.com/oppia/oppia/pull/22847\n- [x] Element manipulation like .attr, .data, .text, .append, .html  @KartikSuryavanshi \n  - PR: https://github.com/oppia/oppia/pull/22494\n- [x] Attaching events to elements like .on, .bind, .resize\n  - PR: https://github.com/oppia/oppia/pull/22477 @himkar-cmd \n- [ ] Where the element is not manipulated itself, but some of its information is used in the file, for example: .filter, .text, .html, .position and check this [docs](https://docs.google.com/document/d/1tGL15dpTGLXWsZdmu2qOVKNLIyL09W7HyEUznwc8hx0/edit?usp=sharing) for more. @himkar-cmd \n\n\n\n\nNote: See https://youmightnotneedjquery.com/ for possible replacements. We do not need to support IE.\n\nNote: After this issue is completed we might want to tackle https://github.com/oppia/oppia/issues/12146.",
      "updatedAt" : 1753395218.000000000,
      "user" : "nithusha21",
      "userHtmlUrl" : "https://github.com/nithusha21",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11898234?v=4",
      "labels" : [ "enhancement", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hi @oppia/core-maintainers, this issue is not assigned to any project. Can you please update the same? Thanks!", "Hey @nithusha21 @brianrodri is this issue open to all?\r\nI am a newbie to Oppia and would love to contribute!\r\n", "Hi, I can work on this issue :)", "@Red-0111 Per the guidance at https://github.com/oppia/oppia/wiki/Contributing-code-to-Oppia#choosing-a-good-first-issue, please provide an explanation of what your PR will do (with names of files you're changing, what you plan to change in each file, etc.). If it looks good, we can assign you to this issue.\r\n\r\nFor this issue in particular, please do the following:\r\n\r\n1. Provide a full list of usages of jQuery in the codebase.\r\n2. Explain what you plan to do with each of those -- see https://youmightnotneedjquery.com/ for ideas. Show code snippets for at least some of them.\r\n3. For at least a couple of the changes, show screencasts demonstrating that the site works correctly after the changes.\r\n\r\nPlease also follow the other instructions on that wiki page if you have not yet done so. Thanks!", "@HardikGoyal2003  In this issue , I think only 1st pointer is left . Is anything else also there ?  3rd pointer pr is merged so I think that is also completed . \nSo in this Issue we left with 1st pointer only am I right ? \nAlso in 1st Pointer  Issue [thread](https://github.com/oppia/oppia/issues/11329)  its current status is extensions/interactions/MusicNotesInput/directives/oppia-interactive-music-notes-input.directive.ts so I have to work on this am I right ? ", "> [@HardikGoyal2003](https://github.com/HardikGoyal2003) In this issue , I think only 1st pointer is left . Is anything else also there ? 3rd pointer pr is merged so I think that is also completed . So in this Issue we left with 1st pointer only am I right ? Also in 1st Pointer Issue [thread](https://github.com/oppia/oppia/issues/11329) its current status is extensions/interactions/MusicNotesInput/directives/oppia-interactive-music-notes-input.directive.ts so I have to work on this am I right ?\n\nI see there is some part is left too , as this one [closed](https://github.com/oppia/oppia/pull/22854/files ) I am clear now thanks! ", "@HardikGoyal2003 I think the [documentation](https://docs.google.com/document/u/0/d/1tGL15dpTGLXWsZdmu2qOVKNLIyL09W7HyEUznwc8hx0/mobilebasic)  is not up to date am i right ? some of them are already fixed . might need an update Thanks!" ],
      "repository" : {
        "description" : "A free, online learning platform to make quality education accessible for all.",
        "homepage" : "https://www.oppia.org",
        "name" : "oppia",
        "fullName" : "oppia/oppia",
        "htmlUrl" : "https://github.com/oppia/oppia",
        "gitUrl" : "git://github.com/oppia/oppia.git",
        "sshUrl" : "git@github.com:oppia/oppia.git",
        "cloneUrl" : "https://github.com/oppia/oppia.git",
        "owner" : {
          "login" : "oppia",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : false,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4628,
        "stargazersCount" : 6107,
        "watchersCount" : 6107,
        "size" : 329533,
        "openIssuesCount" : 1605,
        "subscribersCount" : 240,
        "pushedAt" : "2025-07-24T22:09:02Z",
        "languages" : {
          "TypeScript" : 18857278,
          "CSS" : 613399,
          "Shell" : 20235,
          "PEG.js" : 71377,
          "Makefile" : 13374,
          "JavaScript" : 1193315,
          "HTML" : 2488320,
          "Python" : 20284607
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove jQuery constructs used in AngularJS code, with a focus on specific usages and replacements, and provide documentation updates.",
      "validationOrRequirement" : "The issue requires providing a full list of usages of jQuery in the codebase, explaining what to do with each, and demonstrating correct site functionality after changes. The author also asked for code snippets and screencasts.",
      "attemptedFixes" : "PRs 22477, 22494, 22510, and 22847 were created to address the issue. However, PR 22854 was closed, and the documentation may need an update.",
      "otherNotes" : "The issue is about removing jQuery constructs used in AngularJS code, with references to specific PRs and documentation. There are multiple attempts and blockers mentioned, including a merged PR. The author has asked for clarification on what's left to do.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406499
  }, {
    "issueDTO" : {
      "id" : 2478714556,
      "title" : "Add file markings to code blocks in the docs",
      "url" : "https://github.com/zmkfirmware/zmk/issues/2435",
      "repositoryName" : "zmkfirmware/zmk",
      "description" : "We have a lot of code blocks in the docs. It would be useful if someone could go through and mark the blocks with `title=` where it could be helpful for readers to understand where the code blocks belong. Could be a useful task for someone who wants to become more familiar with the way things work.",
      "updatedAt" : 1753394717.000000000,
      "user" : "nmunnich",
      "userHtmlUrl" : "https://github.com/nmunnich",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/98408764?v=4",
      "labels" : [ "documentation", "good first issue", "Stale" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "ZMK Firmware Repository",
        "homepage" : "https://zmk.dev/",
        "name" : "zmk",
        "fullName" : "zmkfirmware/zmk",
        "htmlUrl" : "https://github.com/zmkfirmware/zmk",
        "gitUrl" : "git://github.com/zmkfirmware/zmk.git",
        "sshUrl" : "git@github.com:zmkfirmware/zmk.git",
        "cloneUrl" : "https://github.com/zmkfirmware/zmk.git",
        "owner" : {
          "login" : "zmkfirmware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3382,
        "stargazersCount" : 3407,
        "watchersCount" : 3407,
        "size" : 27227,
        "openIssuesCount" : 495,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-23T05:24:13Z",
        "languages" : {
          "Dockerfile" : 91,
          "Shell" : 7865,
          "C" : 1326486,
          "CMake" : 37748,
          "Linker Script" : 1955,
          "JavaScript" : 67,
          "Python" : 3015
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add file markings to code blocks in the docs",
      "validationOrRequirement" : "Marking code blocks with `title=` where it could be helpful for readers to understand where the code blocks belong.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to documentation, specifically adding file markings to code blocks in the docs. It's labeled as good first issue, making it suitable for new contributors. The author is nmunnich from the zmkfirmware/zmk repository.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406503
  }, {
    "issueDTO" : {
      "id" : 3261377660,
      "title" : "Display notification if a request to a coordinato fails or times out",
      "url" : "https://github.com/RoboSats/robosats/issues/2106",
      "repositoryName" : "RoboSats/robosats",
      "description" : "**Is your feature request related to a problem?**\n\nHttp and WS calls fail silently. \n\n**Describe the solution you'd like**\n\nA notification should be displayed to the user to warn about the unavailability of a coordinator. This also includes WS connections.\n\nIt's also possible that Tor sometimes never closes the route and the request is never resolved. The client should control better timeouts.",
      "updatedAt" : 1753394579.000000000,
      "user" : "KoalaSat",
      "userHtmlUrl" : "https://github.com/KoalaSat",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/111684255?v=4",
      "labels" : [ "enhancement \uD83C\uDD99", "good first issue", "???Eligible for Sats ???", "javascript" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A simple and private bitcoin exchange",
        "homepage" : "https://learn.robosats.org",
        "name" : "robosats",
        "fullName" : "RoboSats/robosats",
        "htmlUrl" : "https://github.com/RoboSats/robosats",
        "gitUrl" : "git://github.com/RoboSats/robosats.git",
        "sshUrl" : "git@github.com:RoboSats/robosats.git",
        "cloneUrl" : "https://github.com/RoboSats/robosats.git",
        "owner" : {
          "login" : "RoboSats",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 173,
        "stargazersCount" : 877,
        "watchersCount" : 877,
        "size" : 184978,
        "openIssuesCount" : 42,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-24T16:21:27Z",
        "languages" : {
          "TypeScript" : 1044495,
          "Dockerfile" : 6379,
          "Shell" : 82565,
          "CSS" : 36709,
          "JavaScript" : 7692,
          "HTML" : 688,
          "Python" : 2148123,
          "Kotlin" : 49673,
          "EJS" : 4634
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "display a notification to the user when a request to a coordinator fails or times out",
      "validationOrRequirement" : "javascript",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "Http and WS calls fail silently, WS connections may not be resolved due to Tor sometimes never closing the route",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406505
  }, {
    "issueDTO" : {
      "id" : 2177231479,
      "title" : "[Feature Request]  Option to disable sleep while bluetooth connection is active",
      "url" : "https://github.com/zmkfirmware/zmk/issues/2198",
      "repositoryName" : "zmkfirmware/zmk",
      "description" : "The ZMK checks the USB connection before starting the sleep timer. I would like to be able to check the BLE connections.\r\n\r\nNow the keyboard falls asleep when I watch a video and I have to wake it up every time to pause the video.\r\n\r\nI increased the time before falling asleep to an hour. Now, after turning off the PC, the keyboard still tries to connect to it for a long time.\r\n\r\nI would like the keyboard to fall asleep 5 minutes after losing connection to the PC.",
      "updatedAt" : 1753394416.000000000,
      "user" : "aroum",
      "userHtmlUrl" : "https://github.com/aroum",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22220502?v=4",
      "labels" : [ "bluetooth", "enhancement", "good first issue", "Stale" ],
      "state" : "OPEN",
      "comments" : [ "I think this is a really nice idea as a tweak or optional change to the current sleep code. Some folks may still prefer the current behavior, so probably work putting behavior a new Kconfig flag." ],
      "repository" : {
        "description" : "ZMK Firmware Repository",
        "homepage" : "https://zmk.dev/",
        "name" : "zmk",
        "fullName" : "zmkfirmware/zmk",
        "htmlUrl" : "https://github.com/zmkfirmware/zmk",
        "gitUrl" : "git://github.com/zmkfirmware/zmk.git",
        "sshUrl" : "git@github.com:zmkfirmware/zmk.git",
        "cloneUrl" : "https://github.com/zmkfirmware/zmk.git",
        "owner" : {
          "login" : "zmkfirmware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3382,
        "stargazersCount" : 3407,
        "watchersCount" : 3407,
        "size" : 27227,
        "openIssuesCount" : 495,
        "subscribersCount" : 44,
        "pushedAt" : "2025-07-23T05:24:13Z",
        "languages" : {
          "Dockerfile" : 91,
          "Shell" : 7865,
          "C" : 1326486,
          "CMake" : 37748,
          "Linker Script" : 1955,
          "JavaScript" : 67,
          "Python" : 3015
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement an option to disable sleep while a Bluetooth connection is active.",
      "validationOrRequirement" : "The keyboard should fall asleep 5 minutes after losing connection to the PC.",
      "attemptedFixes" : "The author increased the time before falling asleep to an hour.",
      "otherNotes" : "The keyboard falls asleep when losing connection to the PC, and the author wants to disable sleep while a Bluetooth connection is active.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406508
  }, {
    "issueDTO" : {
      "id" : 3261372701,
      "title" : "Refactor tracking of packet # to analysis harness",
      "url" : "https://github.com/EFForg/rayhunter/issues/475",
      "repositoryName" : "EFForg/rayhunter",
      "description" : "In many of our heuristics, we've found it very useful to track the packet number since the start of the analysis. In most cases, this just ends up being reported in informational or warning logs to assist in manual analysis, but it has also been used in the analysis itself.\n\nInstead of effectively forcing each heuristic to do its own packet number tracking, let's track it in the harness and pass the number to `analyze_information_element` alongside the `InformationElement`.",
      "updatedAt" : 1753394206.000000000,
      "user" : "wgreenberg",
      "userHtmlUrl" : "https://github.com/wgreenberg",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/626277?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Rust tool to detect cell site simulators on an orbic mobile hotspot ",
        "homepage" : "https://efforg.github.io/rayhunter/",
        "name" : "rayhunter",
        "fullName" : "EFForg/rayhunter",
        "htmlUrl" : "https://github.com/EFForg/rayhunter",
        "gitUrl" : "git://github.com/EFForg/rayhunter.git",
        "sshUrl" : "git@github.com:EFForg/rayhunter.git",
        "cloneUrl" : "https://github.com/EFForg/rayhunter.git",
        "owner" : {
          "login" : "EFForg",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 176,
        "stargazersCount" : 2237,
        "watchersCount" : 2237,
        "size" : 4099,
        "openIssuesCount" : 46,
        "subscribersCount" : 53,
        "pushedAt" : "2025-07-24T23:45:02Z",
        "languages" : {
          "TypeScript" : 22015,
          "PowerShell" : 4170,
          "Dockerfile" : 78,
          "Shell" : 1458,
          "CSS" : 95,
          "Rust" : 2369573,
          "JavaScript" : 2033,
          "HTML" : 425,
          "Svelte" : 39197,
          "Python" : 7001
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor tracking of packet number to analysis harness, passing the number to `analyze_information_element` alongside the `InformationElement`",
      "validationOrRequirement" : "enhancement, good first issue",
      "attemptedFixes" : "",
      "otherNotes" : "In many heuristics, packet number tracking is useful for manual analysis, but it's currently handled by each heuristic individually. This issue aims to refactor tracking to the analysis harness.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406511
  }, {
    "issueDTO" : {
      "id" : 3255229402,
      "title" : "WSL Should Considered As Operating System",
      "url" : "https://github.com/muety/wakapi/issues/817",
      "repositoryName" : "muety/wakapi",
      "description" : "First of all thanks for this project I love it!\n\nI am using WSL2 for my main development. Wakatime considers it as another operating system but in Wakapi UI it is considered as Linux. I think this mentality should change.\n\nI came to this conclusion from your this comment. https://github.com/muety/wakapi/issues/718#issuecomment-2557603423\n\nAlso in last softwere industry surveys also listing WSL as another operation system. So I know technically it is not but here is the situation \uD83D\uDE04 \n\n\n### Wakatime - Same Data\n\n<img width=\"599\" height=\"215\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e7d78ded-dc6d-4cb2-9b28-456fe90bc0ef\" />\n\n### Wakapi - Same Data\n\n<img width=\"858\" height=\"325\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/461fc569-aac6-4cfb-884e-c95617b40372\" />\n\n",
      "updatedAt" : 1753394164.000000000,
      "user" : "muhammedogz",
      "userHtmlUrl" : "https://github.com/muhammedogz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/54470681?v=4",
      "labels" : [ "effort:1", "good first issue", "prio c" ],
      "state" : "OPEN",
      "comments" : [ "> Also in last softwere industry surveys also listing WSL as another operation system\n\nCould you share them? I'd be interested.\n\nWSL2 is essentially a virtualization technology, compare it with Docker. You're running _Linux_ inside _Windows_, so the only reasonable options to display here, in my opinion, is either of those (instead of \"WSL\" / \"Docker\", ...).\n\nBut since you're not the first person bringing this up and since it's a small and not very much impactful change, I'll add it as change request nevertheless.", "Sure, here is some surveys\n\n[Stackoverflow 2024](https://survey.stackoverflow.co/2024/technology#1-operating-system)\n[Stackoverflow 2023](https://survey.stackoverflow.co/2023/#section-most-popular-technologies-operating-system)\n\nI also regenerated my summaries today (before your message) and older Linux data became WSL. but new datas are considered as Linux again.\nI tried regenerate again but there is no change.\n\n<img width=\"739\" height=\"326\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/431e6851-3bbc-4e27-9390-97f8ed144b9b\" />\n\nAlso a lot of \"unknown\" labeled data instead of \"coding\" but clearly they are came from VsCode extension and has coding related info such as branch or etc whilte category field is empty. But it is not related with WSL.", "Hm maybe WSL showed in above picture because I clicked import data in integration tab for wakatime. I will check again after my 24 hour waiting time complete" ],
      "repository" : {
        "description" : "\uD83D\uDCCA A minimalist, self-hosted WakaTime-compatible backend for coding statistics",
        "homepage" : "https://wakapi.dev",
        "name" : "wakapi",
        "fullName" : "muety/wakapi",
        "htmlUrl" : "https://github.com/muety/wakapi",
        "gitUrl" : "git://github.com/muety/wakapi.git",
        "sshUrl" : "git@github.com:muety/wakapi.git",
        "cloneUrl" : "https://github.com/muety/wakapi.git",
        "owner" : {
          "login" : "muety",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 219,
        "stargazersCount" : 3524,
        "watchersCount" : 3524,
        "size" : 8464,
        "openIssuesCount" : 36,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-18T12:44:06Z",
        "languages" : {
          "Dockerfile" : 1972,
          "Shell" : 14144,
          "CSS" : 4253,
          "JavaScript" : 49986,
          "Go" : 894781,
          "HTML" : 163085,
          "Python" : 19313
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Wakatime should consider WSL as an operating system, as it is considered as another operating system by Wakatime itself and also listed as another operating system in software industry surveys.",
      "validationOrRequirement" : "WSL should be considered as an operating system, based on Wakatime's comment and software industry surveys.",
      "attemptedFixes" : "I also regenerated my summaries today (before your message) and older Linux data became WSL. but new datas are considered as Linux again. I tried regenerate again but there is no change.",
      "otherNotes" : "WSL2 is essentially a virtualization technology, compare it with Docker. You're running _Linux_ inside _Windows_, so the only reasonable options to display here, in my opinion, is either of those (instead of \"WSL\" / \"Docker\", ...).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406517
  }, {
    "issueDTO" : {
      "id" : 3261366515,
      "title" : "bug: Remove unnecessary double definition of `ITSName` variables in WDS CP",
      "url" : "https://github.com/kubestellar/kubestellar/issues/3124",
      "repositoryName" : "kubestellar/kubestellar",
      "description" : "### Describe the bug\n\nThe line https://github.com/kubestellar/kubestellar/blob/6baafdad09f9dc8685eda1564f2e3ff8a956246a/core-chart/templates/controlplanes/wds.yaml#L14 is unnecessary and should be removed\n\nThe variable is not different than the globalVar definition\n\n### Output from KubeStellar-Snapshot.sh\n\n_No response_\n\n### Steps To Reproduce\n\nsee above\n\n### Expected Behavior\n\nThere is not need to define twice the same variable with the same value.\nIt could lead to issues down the road.\n\n### Want to contribute?\n\n- [ ] I would like to work on this issue.\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1753394017.000000000,
      "user" : "francostellari",
      "userHtmlUrl" : "https://github.com/francostellari",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/50019234?v=4",
      "labels" : [ "kind/bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "KubeStellar - a flexible solution for multi-cluster configuration management for edge, multi-cloud, and hybrid cloud",
        "homepage" : "https://kubestellar.io",
        "name" : "kubestellar",
        "fullName" : "kubestellar/kubestellar",
        "htmlUrl" : "https://github.com/kubestellar/kubestellar",
        "gitUrl" : "git://github.com/kubestellar/kubestellar.git",
        "sshUrl" : "git@github.com:kubestellar/kubestellar.git",
        "cloneUrl" : "https://github.com/kubestellar/kubestellar.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 163,
        "stargazersCount" : 438,
        "watchersCount" : 438,
        "size" : 209303,
        "openIssuesCount" : 211,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-24T19:02:58Z",
        "languages" : {
          "Smarty" : 2184,
          "Dockerfile" : 1303,
          "Shell" : 192050,
          "Makefile" : 14208,
          "Go" : 642298,
          "Python" : 30022
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The line in wds.yaml file is unnecessary and should be removed as the variable is not different than the globalVar definition",
      "validationOrRequirement" : "Remove unnecessary double definition of `ITSName` variables in WDS CP, variable should not be defined twice with the same value",
      "attemptedFixes" : "No fixes attempted or blockers encountered",
      "otherNotes" : "No response from KubeStellar-Snapshot.sh, no additional context provided",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406520
  }, {
    "issueDTO" : {
      "id" : 3141896382,
      "title" : "Seach by Sylow properties",
      "url" : "https://github.com/LMFDB/lmfdb/issues/6399",
      "repositoryName" : "LMFDB/lmfdb",
      "description" : "There are a couple improvements possible for searching by Sylow subgorup\n\n1. On the subgroup search pages, it would be helpful to be able to require the result be a Sylow subgroup, and to show the prime in a column if it is.\n2. On group search pages, there are a couple properties that might be relevant to search by: whether the Sylow subgroup at a particular prime is normal, and whether the complement is normal.",
      "updatedAt" : 1753393902.000000000,
      "user" : "roed314",
      "userHtmlUrl" : "https://github.com/roed314",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22795?v=4",
      "labels" : [ "finite groups", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Part 1 is finished by #6484.", "Hello, I???m a high school student with a strong interest in math (I don't even know how I stumbled upon this project), and I???d love to work on part 2. Right now I'm currently getting SageMath set up (3+ hours into trying to build it) and am digging into the codebase. Sylow subgroups are like the only concept I know in this entire thing, so this seems like a great place to start contributing.\n\nJust wanted to let you know I???m planning to take this on and am happy to coordinate if there are any existing plans!" ],
      "repository" : {
        "description" : "L-Functions and Modular Forms Database",
        "homepage" : null,
        "name" : "lmfdb",
        "fullName" : "LMFDB/lmfdb",
        "htmlUrl" : "https://github.com/LMFDB/lmfdb",
        "gitUrl" : "git://github.com/LMFDB/lmfdb.git",
        "sshUrl" : "git@github.com:LMFDB/lmfdb.git",
        "cloneUrl" : "https://github.com/LMFDB/lmfdb.git",
        "owner" : {
          "login" : "LMFDB",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 222,
        "stargazersCount" : 275,
        "watchersCount" : 275,
        "size" : 52460,
        "openIssuesCount" : 278,
        "subscribersCount" : 34,
        "pushedAt" : "2025-07-22T20:53:55Z",
        "languages" : {
          "Dockerfile" : 115,
          "CSS" : 52416,
          "Shell" : 3925,
          "TeX" : 1973,
          "JavaScript" : 166702,
          "Mathematica" : 778,
          "HTML" : 723092,
          "Sage" : 18062,
          "Gnuplot" : 11047,
          "M" : 12198,
          "Python" : 3889954
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve searching by Sylow subgroups, adding features to subgroup search pages and group search pages.",
      "validationOrRequirement" : "require result be a Sylow subgroup, show prime in column if it is, search by Sylow subgroup being normal and complement being normal.",
      "attemptedFixes" : "Part 1 is finished, setting up SageMath and digging into codebase.",
      "otherNotes" : "Part 1 is finished by #6484., high school student contributor planning to take on part 2, coordination offered.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406524
  }, {
    "issueDTO" : {
      "id" : 3261331352,
      "title" : "Replace deprecated method at unit tests",
      "url" : "https://github.com/LibreSign/libresign/issues/5242",
      "repositoryName" : "LibreSign/libresign",
      "description" : "### Describe the solution you'd like\n\nWe need to replace deprecated methods of PHPUnit by newest syntax.\n\nLook the follow image that will expose the issue:\n\n<img width=\"797\" height=\"309\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f5c1d169-a627-4bbf-a026-98592672e20f\" />\n\nSearch by `->will($this->returnValue(`\n\nAnd replace by:\n\n`->willReturn(`\n\nI found 37 replacements.\n\nReplace all, send a new PR with the replace and interact with a maintainer until your PR be approved and merged.\n\n### \uD83D\uDCA1 Additional notes\n\nThis issue is open for contributors. If you'd like to help, feel free to leave a comment or start a draft PR!\n",
      "updatedAt" : 1753393575.000000000,
      "user" : "vitormattos",
      "userHtmlUrl" : "https://github.com/vitormattos",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1079143?v=4",
      "labels" : [ "php", "backend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "?????? Nextcloud app to sign PDF documents",
        "homepage" : "https://libresign.coop",
        "name" : "libresign",
        "fullName" : "LibreSign/libresign",
        "htmlUrl" : "https://github.com/LibreSign/libresign",
        "gitUrl" : "git://github.com/LibreSign/libresign.git",
        "sshUrl" : "git@github.com:LibreSign/libresign.git",
        "cloneUrl" : "https://github.com/LibreSign/libresign.git",
        "owner" : {
          "login" : "LibreSign",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 85,
        "stargazersCount" : 604,
        "watchersCount" : 604,
        "size" : 81417,
        "openIssuesCount" : 78,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T22:16:16Z",
        "languages" : {
          "TypeScript" : 329407,
          "Shell" : 1136,
          "Gherkin" : 115841,
          "Makefile" : 4519,
          "SCSS" : 1973,
          "Twig" : 783,
          "JavaScript" : 1245882,
          "Vue" : 337431,
          "PHP" : 1010899
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace deprecated method at unit tests by newest syntax",
      "validationOrRequirement" : "Replace all deprecated methods of PHPUnit by newest syntax, search by `->will($this->returnValue(` and replace with `->willReturn(`",
      "attemptedFixes" : "37 replacements were found and need to be replaced with the new syntax",
      "otherNotes" : "The issue is open for contributors and requires a draft PR to be created and interacted with a maintainer until approved and merged.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406527
  }, {
    "issueDTO" : {
      "id" : 1832711514,
      "title" : "`@next/next/no-html-link-for-pages` rule does not work with `pageExtensions`",
      "url" : "https://github.com/vercel/next.js/issues/53473",
      "repositoryName" : "vercel/next.js",
      "description" : "### Verify canary release\n\n- [X] I verified that the issue exists in the latest Next.js canary release\n\n### Provide environment information\n\n```bash\nOperating System:\r\n      Platform: darwin\r\n      Arch: arm64\r\n      Version: Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\r\n    Binaries:\r\n      Node: 18.14.2\r\n      npm: 9.8.1\r\n      Yarn: 1.22.19\r\n      pnpm: 8.3.1\r\n    Relevant Packages:\r\n      next: 13.4.13-canary.9\r\n      eslint-config-next: 13.4.12\r\n      react: 18.2.0\r\n      react-dom: 18.2.0\r\n      typescript: 5.1.3\r\n    Next.js Config:\r\n      output: N/A\n```\n\n\n### Which area(s) of Next.js are affected? (leave empty if unsure)\n\nESLint (eslint-config-next)\n\n### Link to the code that reproduces this issue or a replay of the bug\n\nhttps://github.com/nnmax/next-eslint-config-reproduction-app\n\n### To Reproduce\n\n1. `git clone https://github.com/nnmax/next-eslint-config-reproduction-app.git`\r\n2. `cd next-eslint-config-reproduction-app`\r\n3. `npm install`\r\n4. `npm run lint`\r\n5. Observe the ESLint output from the terminal.\n\n### Describe the Bug\n\nThe `@next/next/no-html-link-for-pages` rule doesn't work after configuring custom `pageExtensions`.\n\n### Expected Behavior\n\nIt should recognize `pageExtensions`.\r\n\r\n<img width=\"1322\" alt=\"image\" src=\"https://github.com/vercel/next.js/assets/48519459/d890191a-0d82-40e7-b475-9def57403e8b\">\r\n\n\n### Which browser are you using? (if relevant)\n\n_No response_\n\n### How are you deploying your application? (if relevant)\n\n_No response_",
      "updatedAt" : 1753393464.000000000,
      "user" : "nnmax",
      "userHtmlUrl" : "https://github.com/nnmax",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/48519459?v=4",
      "labels" : [ "Linting", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Currently, the ESLint rule is indeed unaware of this configuration.\r\n\r\nSee https://github.com/vercel/next.js/blob/e757cac3f4c9152209537f8274e29e41a470920b/packages/eslint-plugin-next/src/rules/no-html-link-for-pages.ts#L95", "Can I make a PR to accomplish this? I would be happy to help.\r\n\r\nI readed the source code and found only one difficulty, how to get the user configured `pageExtensions` parameter. I have two ideas for this:\r\n\r\n- Get the `pageExtensions` parameter from the user's `next.config.js` or `next.config.mjs` configuration file.\r\n  * Use the [`loadConfig`](https://github.com/vercel/next.js/blob/b31b0ee0cceeb68c01363cb1adb95ea8041c9974/packages/next/src/server/config.ts#L764) function to get the configuration. But unfortunately, this function is an async function, and the ESLint create function [does not support async calls](https://github.com/eslint/eslint/issues/15394). So this solution does not work.\r\n  * Read the configuration file via `require()`. If the user is only using the CommonJS and exporting a configuration object, this is easy enough to get the `pageExtensions` parameter. But if the user is using an `ES Module` or exporting a sync or async function, I can't get the `pageExtensions` parameter. Because the `require()` function doesn't support dynamic import of an `ES Module`. So this solution also fails.\r\n- Provide an ESLint option named `pageExtensions`.\r\n  * This is the only option that works so far.\r\n\r\nThis is my current idea, feel free to discuss it.", "Hello, I am new to open source and want to work on this issue. Do I need to get this assigned first or should I just fork and start working directly?", "@abhishek1810 \r\n\r\nIt looks like this is already being worked on for a duplicate ticket. Here's the PR: https://github.com/vercel/next.js/pull/51783\r\n\r\nMaybe reviewing and commenting on that PR first would be helpful. ", "Is this still open? I would be happy to fix this issue if someone can guide me where in the project this error is being produced.", "Hello @nnmax  @balazsorban44  can i do on this issues becaus I thing I found the solution of this issues so can you please doing work on this issue\n\n_Edit by maintainer bot: Comment was **automatically** minimized because it was considered unhelpful. (If you think this was by mistake, let us know). Please only comment if it adds context to the issue. If you want to express that you have the same problem, use the upvote \uD83D\uDC4D on the issue description or subscribe to the issue for updates. Thanks!_", "Is this issue is still exists cause I want to work on it", "@balazsorban44 closed in https://github.com/vercel/next.js/pull/68770 , correct?", "Hi, I???d like to work on this issue. Please assign it to me.\n\n_Edit by maintainer bot: Comment was **automatically** minimized because it was considered unhelpful. (If you think this was by mistake, let us know). Please only comment if it adds context to the issue. If you want to express that you have the same problem, use the upvote \uD83D\uDC4D on the issue description or subscribe to the issue for updates. Thanks!_", "Hi! I???d like to contribute to this issue and help standardize the terminology across the documentation. I???ve reviewed the context and plan to update all instances of ???file-system??? to ???filesystem??? for consistency. Please let me know if there are any exceptions I should be aware of before I get started.", "Hi @balazsorban44, how are you?\nIt seems that the implementation mentioned by @jessfeliciano and @jackunion started at https://github.com/vercel/next.js/pull/51783 and https://github.com/vercel/next.js/pull/68770 does not have pageExtensions yet.\n\nI propose a solution at https://github.com/vercel/next.js/pull/80035. Can you review it when you have some time?", "Hey! I???d love to work on this issue. I???ve been working with custom pageExtensions in Next.js projects, so this bug directly affects some of my setups. I'm interested in digging into the eslint-config-next package to understand how the @next/next/no-html-link-for-pages rule is resolving page files.\n\nI think it's a great opportunity to contribute a fix that improves compatibility for more flexible project structures. I???ll start by reviewing how pageExtensions are parsed and check if they're being passed correctly to the ESLint rule logic. Let me know if there's any guidance before I dive in!", "Hi! I???d love to take on this issue.\n\nPlan:\nI???ll start by reproducing the bug with a custom pageExtensions config. Then I???ll inspect the logic inside the @next/next/no-html-link-for-pages rule to confirm if it???s hardcoded for .js/.jsx/.ts/.tsx. I???ll update it to respect pageExtensions from next.config.js, and add tests to cover this case.\n\nWhy me:\nI???ve worked with ESLint plugin development and Next.js config handling. I'm confident in making this rule more flexible while maintaining stability.", "Hey folks! Just a heads-up ??? I already came up with a proposed solution you can try out in [my MR #80035](https://github.com/vercel/next.js/pull/80035). Feel free to take a look, test it out, and let me know if you spot anything that could be improved. Happy to collaborate and iterate on it!", "Hi \uD83D\uDC4B I'd like to work on this issue as my first open-source contribution. Is it okay if I take it?\n", "Hi all, I'd like to help move this forward.\n\nI'm currently testing @viniciuspizettadesouza's solution in #80035 and can confirm it resolves the basic case for JavaScript configs (`next.config.js`). I'd be happy to help by:\n- Expanding test coverage for different `pageExtensions` configurations\n- Verifying edge cases (like mixed extensions or empty arrays)\n- Addressing any feedback from maintainers on the PR\n\nSince this is tagged `good first issue`, I'd appreciate guidance on:\n1. Preferred approach for testing TS configs (`next.config.ts`)\n2. Whether to focus on PR #80035 or tackle remaining gaps separately\n\nLooking forward to contributing!" ],
      "repository" : {
        "description" : "The React Framework",
        "homepage" : "https://nextjs.org",
        "name" : "next.js",
        "fullName" : "vercel/next.js",
        "htmlUrl" : "https://github.com/vercel/next.js",
        "gitUrl" : "git://github.com/vercel/next.js.git",
        "sshUrl" : "git@github.com:vercel/next.js.git",
        "cloneUrl" : "https://github.com/vercel/next.js.git",
        "owner" : {
          "login" : "vercel",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28923,
        "stargazersCount" : 133394,
        "watchersCount" : 133394,
        "size" : 2300326,
        "openIssuesCount" : 3277,
        "subscribersCount" : 1482,
        "pushedAt" : "2025-07-25T00:16:04Z",
        "languages" : {
          "MDX" : 306925,
          "CSS" : 504846,
          "Rust" : 7498015,
          "Pug" : 49,
          "WebAssembly" : 497,
          "Sass" : 302,
          "HTML" : 5074,
          "TypeScript" : 14219553,
          "Dockerfile" : 4523,
          "Shell" : 12598,
          "Batchfile" : 579,
          "SCSS" : 8077,
          "JavaScript" : 32492038
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about the `@next/next/no-html-link-for-pages` rule not working with `pageExtensions` configuration in Next.js.",
      "validationOrRequirement" : "The `@next/next/no-html-link-for-pages` rule should recognize `pageExtensions` configuration.",
      "attemptedFixes" : "The author has tried to reproduce the bug and has proposed a solution in a PR. Other contributors have also attempted to help by testing the solution and providing feedback.",
      "otherNotes" : "The issue is about the `@next/next/no-html-link-for-pages` rule not working with `pageExtensions` configuration in Next.js. The author has tried to reproduce the bug and has proposed a solution in a PR.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406532
  }, {
    "issueDTO" : {
      "id" : 187699454,
      "title" : "DOC:  min_itemsize for HDFStore append for encoded strings",
      "url" : "https://github.com/pandas-dev/pandas/issues/14601",
      "repositoryName" : "pandas-dev/pandas",
      "description" : "I'm confused about how to preset min_itemsizes for appending to an HDFStore. Say DataFrame a and b in the MWE below is user-provided, so it can contain any character and the encoding is unknown. Appending a works, but appending b fails even though:\r\n\r\n```python\r\nIn [4]: len('???')\r\nOut[4]: 1\r\n```\r\nSo far I simply used str.len().max() on the string columns to the the numbers for min_itemsize, but this does not work in the example here. This MWE is of course simplified, but I guess I'm wondering:\r\n\r\n- how does pytables come up with the string length?\r\n- how should I determine the string length? Considering the encoding is unknown, but pytables assumes some encoding / pytables converts the strings to some other object?\r\n\r\nIn this toy example I could encode the string as utf-8 to get the correct length, but this isn't a general approach:\r\n\r\n```python\r\nIn [5]: len('???'.encode('utf-8'))\r\nOut[5]: 3\r\n```\r\n\r\n#### MWE:\r\n```python\r\nimport pandas as pd\r\n                                                      \r\na = pd.DataFrame([['a', 'b']], columns = ['A', 'B'])\r\nb = pd.DataFrame([['???', 'b']], columns = ['A', 'B'])\r\n\r\nstore = pd.HDFStore('/tmp/tmpstore')\r\n\r\nstore.append('df', a, min_itemsizes={'A': 1, 'B': 1})\r\nstore.append('df', b, min_itemsizes={'A': 1, 'B': 1}) # fails\r\n\r\n```\r\n\r\n#### Expected Output\r\nValueError: Trying to store a string with len [3] in [values_block_0] column but\r\nthis column has a limit of [1]!\r\nConsider using min_itemsize to preset the sizes on these columns\r\nClosing remaining open files:/tmp/tmpstore...done\r\n\r\n#### Output of ``pd.show_versions()``\r\n\r\n<details>INSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.5.2.final.0\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.4.28-2-MANJARO\r\nmachine: x86_64\r\nprocessor: \r\nbyteorder: little\r\nLC_ALL: en_US.UTF-8\r\nLANG: en_DE.UTF-8\r\nLOCALE: en_US.UTF-8\r\n\r\npandas: 0.19.0\r\nnose: 1.3.7\r\npip: 8.1.2\r\nsetuptools: 27.2.0\r\nCython: 0.23.5\r\nnumpy: 1.11.2\r\nscipy: 0.18.1\r\nstatsmodels: None\r\nxarray: None\r\nIPython: 5.1.0\r\nsphinx: 1.4.8\r\npatsy: None\r\ndateutil: 2.5.3\r\npytz: 2016.7\r\nblosc: None\r\nbottleneck: None\r\ntables: 3.3.0\r\nnumexpr: 2.6.1\r\nmatplotlib: 1.5.3\r\nopenpyxl: None\r\nxlrd: None\r\nxlwt: None\r\nxlsxwriter: None\r\nlxml: None\r\nbs4: None\r\nhtml5lib: None\r\nhttplib2: None\r\napiclient: None\r\nsqlalchemy: 1.1.3\r\npymysql: None\r\npsycopg2: 2.6.2 (dt dec pq3 ext lo64)\r\njinja2: 2.8\r\nboto: None\r\npandas_datareader: None\r\n</details>\r\n",
      "updatedAt" : 1753393401.000000000,
      "user" : "johanneshk",
      "userHtmlUrl" : "https://github.com/johanneshk",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9724338?v=4",
      "labels" : [ "Docs", "good first issue", "IO HDF5" ],
      "state" : "OPEN",
      "comments" : [ "`min_itemsize` is the kw (not `min_itemsizes`).\n\nbut the size is actually the length of the stored bytes (and not characters), so you \nneed to encode anyhow. your best bet is to simply make a larger than needed size.\n\n```\nIn [52]: store = pd.HDFStore('tmp.h5', mode='w')\n\nIn [53]: store.append('df', a, min_itemsize={'A': 10, 'B': 10}, encoding='utf-8')\n\nIn [54]: store.append('df', b)\n```\n", "docs are [here](http://pandas.pydata.org/pandas-docs/stable/io.html#string-columns)\n\nI suppose a note on using encodings correctly might be nice if you want to do a PR.\n", "going to reopen this as a doc issue as explaining how the len counting works when data is encoded\n", "So the assumption here is: The user knows if her string contains encoded characters? In that case calling `len(string)` wouldn't suffice, instead one would need to do `len(string.encode('encoding'))` as demonstrated above (or the equivalent on a DataFrame column). In addition the encoding kw needs to be specified when appending.\nI'd like to submit a PR to clarify this. Will try to do this in the next few days.\n", "I'm trying to store dataframes in a store.\r\nIn the first dataframe, I have a 'chrNumber' column of 1 in that column.\r\nIn the further dataframes, I have a 'chrNumber' column of 10,11,12,... and so on  in that column.\r\nAlthough I have set min_itemsize={'chrNumber':2} in  the store.append() command \r\nBut, I still get the  ValueError:\r\n\r\n------------------------------------------------------------------\r\nValueError: Trying to store a string with len [2] in [chrNumber] column but\r\nthis column has a limit of [1]!\r\nConsider using min_itemsize to preset the sizes on these columns\r\nClosing remaining open files:df_all.h5...done\r\n------------------------------------------------------------------\r\n\r\nAnd this is the python code for appending dataframes into a store with min_itemsize.\r\n\r\nstore.append('df', augmented_chrBased_snp_df, data_columns=['Cancer Type', 'Sample', 'paperDOI', 'genomeAssembly', 'type', 'chrNumber', 'start', 'end', 'originalNucleotide', 'mutatedNucleotide', 'dataSource','strand', 'PyramidineStrand', 'Mutation Type', 'Mutation Subtype'], min_itemsize={'Cancer Type':15, 'Sample':8, 'chrNumber':2})\r\n            \r\n   ", "@burcakotlu, it might be due to the HDFStore already existing, therefore the min size for that column is set. I fixed this error in my case by deleting the existing HDFStore and recreating it, ensuring the the min_itemsize parameter was set from the beginning. Hope this helps!", "Does this issue still need to be resolved? I am looking for a first-time open-source contribution. ", "@riteshpen Yes please! The documentation for HDFStore is really bad IMHO\n\nConsider the following\n* https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.put.html\n* https://pandas.pydata.org/docs/reference/api/pandas.HDFStore.append.html\n\nIt is not explained what min_itemsize actually does. It is stated that it is a dictionary, but clearly in other places min_itemsize is used as an integer. What are the actual allowed types of min_itemsize, and what is the expected behaviour?", "take", "https://github.com/pandas-dev/pandas/pull/61936" ],
      "repository" : {
        "description" : "Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more",
        "homepage" : "https://pandas.pydata.org",
        "name" : "pandas",
        "fullName" : "pandas-dev/pandas",
        "htmlUrl" : "https://github.com/pandas-dev/pandas",
        "gitUrl" : "git://github.com/pandas-dev/pandas.git",
        "sshUrl" : "git@github.com:pandas-dev/pandas.git",
        "cloneUrl" : "https://github.com/pandas-dev/pandas.git",
        "owner" : {
          "login" : "pandas-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18716,
        "stargazersCount" : 46087,
        "watchersCount" : 46087,
        "size" : 370472,
        "openIssuesCount" : 3744,
        "subscribersCount" : 1112,
        "pushedAt" : "2025-07-24T20:02:20Z",
        "languages" : {
          "Smarty" : 8852,
          "Dockerfile" : 6015,
          "Shell" : 21760,
          "CSS" : 7370,
          "C" : 354816,
          "Meson" : 12525,
          "HTML" : 457849,
          "XSLT" : 1196,
          "Cython" : 1391478,
          "Python" : 20997424
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to understand how to set the correct min_itemsize for HDFStore when appending dataframes with encoded strings, and to provide a clear documentation for this feature.",
      "validationOrRequirement" : "The validation or requirement is that the min_itemsize needs to be set correctly to store dataframes with encoded strings in HDFStore.",
      "attemptedFixes" : "The user tried setting the min_itemsize based on the length of the string columns, but this did not work. The solution is to specify the encoding when appending and set the min_itemsize to a larger value than the maximum length of the strings.",
      "otherNotes" : "The issue is about setting the correct min_itemsize for HDFStore when appending dataframes with encoded strings. The problem is that the length of the stored bytes is different from the length of the characters, and the encoding needs to be specified when appending.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406539
  }, {
    "issueDTO" : {
      "id" : 3261292022,
      "title" : "Misleading error message \"URL must not be a blank string\" when URL is a non-string value which does not stringify to a fully valid URL with a hostname",
      "url" : "https://github.com/oven-sh/bun/issues/21361",
      "repositoryName" : "oven-sh/bun",
      "description" : "### What version of Bun is running?\n\n1.2.18+0d4089ea7\n\n### What platform is your computer?\n\nDarwin 24.3.0 arm64 arm\n\n### What steps can reproduce the bug?\n\nAny of the following (and more):\n\n```js\nawait fetch(undefined)\nawait fetch(123)\nawait fetch({toString() {return `/some_path`}})\n```\n\n### What is the expected behavior?\n\nSomething more precise, like:\n> `fetch() URL must have a hostname`\n\n### What do you see instead?\n\n> `fetch() URL must not be a blank string`\n\n### Additional information\n\nLink to offending line in Bun sources: https://github.com/oven-sh/bun/blob/bd232189b4c39ac3c8ccef9cf0932407d65c527a/src/bun.js/webcore/fetch.zig#L1448",
      "updatedAt" : 1753393168.000000000,
      "user" : "mitranim",
      "userHtmlUrl" : "https://github.com/mitranim",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4263831?v=4",
      "labels" : [ "confirmed bug", "bug", "web:fetch", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/oven/issue/ENG-19787/misleading-error-message-url-must-not-be-a-blank-string-when-url-is-a\">ENG-19787 Misleading error message \"URL must not be a blank string\" when URL is a non-string value which does not stringify to a fully valid URL with a hostname</a></p>" ],
      "repository" : {
        "description" : "Incredibly fast JavaScript runtime, bundler, test runner, and package manager ??? all in one",
        "homepage" : "https://bun.com",
        "name" : "bun",
        "fullName" : "oven-sh/bun",
        "htmlUrl" : "https://github.com/oven-sh/bun",
        "gitUrl" : "git://github.com/oven-sh/bun.git",
        "sshUrl" : "git@github.com:oven-sh/bun.git",
        "cloneUrl" : "https://github.com/oven-sh/bun.git",
        "owner" : {
          "login" : "oven-sh",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3214,
        "stargazersCount" : 79303,
        "watchersCount" : 79303,
        "size" : 329274,
        "openIssuesCount" : 5051,
        "subscribersCount" : 573,
        "pushedAt" : "2025-07-25T00:51:23Z",
        "languages" : {
          "PowerShell" : 27794,
          "MDX" : 864,
          "C++" : 8403381,
          "CSS" : 39855,
          "C" : 1447046,
          "Rust" : 31216,
          "CMake" : 140883,
          "Makefile" : 84640,
          "Perl" : 30364,
          "HTML" : 29325,
          "Svelte" : 7198,
          "TypeScript" : 3244064,
          "Dockerfile" : 18487,
          "Shell" : 115150,
          "Linker Script" : 6073,
          "AMPL" : 112,
          "JavaScript" : 608336,
          "Zig" : 23166226,
          "Objective-C" : 40909,
          "Ruby" : 14292,
          "Python" : 102154
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about a misleading error message 'URL must not be a blank string' when the URL is a non-string value that does not stringify to a fully valid URL with a hostname",
      "validationOrRequirement" : "The URL must have a hostname",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is reproducible with any of the following: `await fetch(undefined)`, `await fetch(123)`, `await fetch({toString() {return `/some_path`}})`. The expected behavior is a more precise error message like `fetch() URL must have a hostname`. The issue is linked to a specific line in the Bun sources.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406543
  }, {
    "issueDTO" : {
      "id" : 3260307540,
      "title" : "Doc update: Default value of disableTransitions in the code is true, however docs say it is false which is incorrect",
      "url" : "https://github.com/svecosystem/mode-watcher/issues/148",
      "repositoryName" : "svecosystem/mode-watcher",
      "description" : "https://github.com/svecosystem/mode-watcher/blob/f409100185f45912f111a98e3f1b7907fb911f5a/docs/src/content/components/mode-watcher.md?plain=1#L128",
      "updatedAt" : 1753393025.000000000,
      "user" : "Vrajs16",
      "userHtmlUrl" : "https://github.com/Vrajs16",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/89588024?v=4",
      "labels" : [ "docs", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Simple light/dark mode management for Svelte apps. \uD83C\uDF11 ?????? ??????",
        "homepage" : "https://mode-watcher.sveco.dev",
        "name" : "mode-watcher",
        "fullName" : "svecosystem/mode-watcher",
        "htmlUrl" : "https://github.com/svecosystem/mode-watcher",
        "gitUrl" : "git://github.com/svecosystem/mode-watcher.git",
        "sshUrl" : "git@github.com:svecosystem/mode-watcher.git",
        "cloneUrl" : "https://github.com/svecosystem/mode-watcher.git",
        "owner" : {
          "login" : "svecosystem",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 21,
        "stargazersCount" : 493,
        "watchersCount" : 493,
        "size" : 2305,
        "openIssuesCount" : 6,
        "subscribersCount" : 7,
        "pushedAt" : "2025-06-28T00:39:03Z",
        "languages" : {
          "TypeScript" : 35836,
          "CSS" : 1497,
          "JavaScript" : 3407,
          "HTML" : 320,
          "Svelte" : 8208
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the documentation to reflect the correct default value of disableTransitions in the code, which is true.",
      "validationOrRequirement" : "The default value of disableTransitions in the code should match the value stated in the documentation.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue description links to a specific line in a documentation file, and there are no comments on the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406546
  }, {
    "issueDTO" : {
      "id" : 1390159872,
      "title" : "Let's document: qm",
      "url" : "https://github.com/tldr-pages/tldr/issues/8537",
      "repositoryName" : "tldr-pages/tldr",
      "description" : "### Command description\n\nLets document [qm](https://pve.proxmox.com/pve-docs/qm.1.html).\n\n```\nUSAGE: qm <COMMAND> [ARGS] [OPTIONS]\n\n       qm cloudinit dump <vmid> <type>\n\n       qm guest cmd <vmid> <command>\n       qm guest exec-status <vmid> <pid>\n       qm guest passwd <vmid> <username> [OPTIONS]\n       qm guest exec <vmid> [<extra-args>] [OPTIONS]\n\n       qm clone <vmid> <newid> [OPTIONS]\n       qm config <vmid> [OPTIONS]\n       qm create <vmid> [OPTIONS]\n       qm delsnapshot <vmid> <snapname> [OPTIONS]\n       qm destroy <vmid> [OPTIONS] \n       qm list  [OPTIONS]\n       qm listsnapshot <vmid>\n       qm migrate <vmid> <target> [OPTIONS]\n       qm move_disk <vmid> <disk> <storage> [OPTIONS]\n       qm pending <vmid>\n       qm reboot <vmid> [OPTIONS]\n       qm reset <vmid> [OPTIONS]\n       qm resize <vmid> <disk> <size> [OPTIONS]\n       qm resume <vmid> [OPTIONS] ??? #9374\n       qm rollback <vmid> <snapname>\n       qm sendkey <vmid> <key> [OPTIONS]\n       qm set <vmid> [OPTIONS]\n       qm shutdown <vmid> [OPTIONS]\n       qm snapshot <vmid> <snapname> [OPTIONS]\n       qm start <vmid> [OPTIONS]\n       qm stop <vmid> [OPTIONS]\n       qm suspend <vmid> [OPTIONS]\n       qm template <vmid> [OPTIONS]\n       qm unlink <vmid> --idlist <string> [OPTIONS]\n\n       qm cleanup <vmid> <clean-shutdown> <guest-requested>\n       qm importdisk <vmid> <source> <storage> [OPTIONS]\n       qm importovf <vmid> <manifest> <storage> [OPTIONS]\n       qm monitor <vmid>\n       qm mtunnel \n       qm nbdstop <vmid>\n       qm rescan  [OPTIONS]\n       qm showcmd <vmid> [OPTIONS]\n       qm status <vmid> [OPTIONS]\n       qm terminal <vmid> [OPTIONS]\n       qm unlock <vmid>\n       qm vncproxy <vmid>\n       qm wait <vmid> [OPTIONS]\n\n       qm help [<extra-args>] [OPTIONS]\n```\n\nTodo:\n\n\n- [x] qm ??? #7157\n  - [x] cleanup ??? #9111\n  - [x] clone ??? #9038\n  - [x] cloudinit ??? #10891\n    - [x] dump ??? #8973\n  - [x] config ??? #9216\n  - [x] create ??? #8705\n  - [x] delsnapshot ??? #8852\n  - [x] destroy ??? #9054\n  - [ ] disk ??? \n    - [x] import ??? #10499\n    - [x] move ??? #10530\n    - [x] resize ??? #10496\n  - [ ] guest ??? \n    - [x] cmd ??? #9001\n    - [x] exec-status ??? #9102\n    - [x] exec ??? #9133\n    - [x] passwd ??? #9102\n  - [x] help ??? #9165\n  - [ ] import ??? \n  - [x] importdisk ??? #9028, #10499\n  - [ ] importovf ??? \n  - [x] list ??? #9139\n  - [x] listsnapshot ??? #8853\n  - [x] migrate ??? #9367\n  - [x] monitor ??? #8854\n  - [x] move_disk ??? #10530\n  - [x] mtunnel ??? #9152\n  - [x] nbdstop ??? #8679\n  - [x] pending ??? #9149\n  - [x] reboot ??? #8784\n  - [ ] remote-migrate ??? \n  - [x] rescan ??? #9215\n  - [x] reset ??? #8837\n  - [x] resize ??? #10496\n  - [x] resume ??? #9374\n  - [x] rollback ??? #9110\n  - [x] sendkey ??? #9246\n  - [ ] set ??? \n  - [x] showcmd ??? #9243\n  - [x] shutdown ??? #8764\n  - [x] snapshot ??? #8949\n  - [x] start ??? #8704\n  - [x] status ??? #9180\n  - [x] stop ??? #8538\n  - [x] suspend ??? #10469\n  - [x] template ??? #10481\n  - [ ] terminal ??? \n  - [ ] unlink ??? \n  - [x] unlock ??? #9051\n  - [x] vncproxy ??? #9150\n  - [x] wait ??? #8844\n- [x] qmrestore ??? #8790\n\n\n### OS\n\n- [X] Linux",
      "updatedAt" : 1753392941.000000000,
      "user" : "einverne",
      "userHtmlUrl" : "https://github.com/einverne",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1962738?v=4",
      "labels" : [ "new command", "let's document", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Can I work on this issue?", "> Can I work on this issue?\r\n\r\nOf course.", "Sir, Should I build another page than [qm page](https://pve.proxmox.com/pve-docs/qm.1.html) ? Asking this because all the given commands are already on the above page.", "> Sir, Should I build another page than [qm page](https://pve.proxmox.com/pve-docs/qm.1.html) ? Asking this because all the given commands are already on the above page.\r\n\r\nYou can build subcommand pages like [qm-stop](https://github.com/tldr-pages/tldr/pull/8538).  You can check how we document [git-extra](https://github.com/tldr-pages/tldr/issues/5137) pages.", "Ref: #9149 ", "@kbdharun @einverne @navarroaxel, please do review and merge PR #9149 #9165 #9152 #9150 \r\nThanks! ", "Hi @kbdharun @navarroaxel,\r\nThank you for the suggestions on PR #9149 #9165 #9152 #9150. \r\n\r\nI have updated them, please do merge them. \r\nThanks a lot!", "@einverne @kbdharun please review and merge PR #10469.\r\nThanks", "I cleaned up the OP. Here's an up-to-date list of commands\n```\nUSAGE: qm <COMMAND> [ARGS] [OPTIONS]\n\n       qm cloudinit dump <vmid> <type>\n       qm cloudinit pending <vmid>\n       qm cloudinit update <vmid>\n\n       qm disk move <vmid> <disk> [<storage>] [OPTIONS]\n       qm disk resize <vmid> <disk> <size> [OPTIONS]\n       qm disk unlink <vmid> --idlist <string> [OPTIONS]\n       qm disk import <vmid> <source> <storage> [OPTIONS]\n       qm disk rescan  [OPTIONS]\n\n       qm guest cmd <vmid> <command>\n       qm guest exec-status <vmid> <pid>\n       qm guest passwd <vmid> <username> [OPTIONS]\n       qm guest exec <vmid> [<extra-args>] [OPTIONS]\n\n       qm clone <vmid> <newid> [OPTIONS]\n       qm config <vmid> [OPTIONS]\n       qm create <vmid> [OPTIONS]\n       qm delsnapshot <vmid> <snapname> [OPTIONS]\n       qm destroy <vmid> [OPTIONS]\n       qm list  [OPTIONS]\n       qm listsnapshot <vmid>\n       qm migrate <vmid> <target> [OPTIONS]\n       qm pending <vmid>\n       qm reboot <vmid> [OPTIONS]\n       qm reset <vmid> [OPTIONS]\n       qm resume <vmid> [OPTIONS]\n       qm rollback <vmid> <snapname> [OPTIONS]\n       qm sendkey <vmid> <key> [OPTIONS]\n       qm set <vmid> [OPTIONS]\n       qm shutdown <vmid> [OPTIONS]\n       qm snapshot <vmid> <snapname> [OPTIONS]\n       qm start <vmid> [OPTIONS]\n       qm stop <vmid> [OPTIONS]\n       qm suspend <vmid> [OPTIONS]\n       qm template <vmid> [OPTIONS]\n\n       qm cleanup <vmid> <clean-shutdown> <guest-requested>\n       qm import <vmid> <source> --storage <string> [OPTIONS]\n       qm importovf <vmid> <manifest> <storage> [OPTIONS]\n       qm monitor <vmid>\n       qm mtunnel \n       qm nbdstop <vmid>\n       qm remote-migrate <vmid> [<target-vmid>] <target-endpoint> --target-bridge <string> --target-storage <string> [OPTIONS]\n       qm showcmd <vmid> [OPTIONS]\n       qm status <vmid> [OPTIONS]\n       qm terminal <vmid> [OPTIONS]\n       qm unlock <vmid>\n       qm vncproxy <vmid>\n       qm wait <vmid> [OPTIONS]\n\n       qm help [<extra-args>] [OPTIONS]\n```" ],
      "repository" : {
        "description" : "\uD83D\uDCDA Collaborative cheatsheets for console commands",
        "homepage" : "https://tldr.sh",
        "name" : "tldr",
        "fullName" : "tldr-pages/tldr",
        "htmlUrl" : "https://github.com/tldr-pages/tldr",
        "gitUrl" : "git://github.com/tldr-pages/tldr.git",
        "sshUrl" : "git@github.com:tldr-pages/tldr.git",
        "cloneUrl" : "https://github.com/tldr-pages/tldr.git",
        "owner" : {
          "login" : "tldr-pages",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4570,
        "stargazersCount" : 56519,
        "watchersCount" : 56519,
        "size" : 38054,
        "openIssuesCount" : 232,
        "subscribersCount" : 387,
        "pushedAt" : "2025-07-24T18:22:25Z",
        "languages" : {
          "Shell" : 18090,
          "CSS" : 1056,
          "JavaScript" : 1896,
          "Markdown" : 12665860,
          "Python" : 57544
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document the qm command and its subcommands.",
      "validationOrRequirement" : "The issue requires documentation of the qm command. The author is asking if they should build another page than the existing qm page.",
      "attemptedFixes" : "PRs #9149, #9165, #9152, #9150 were reviewed and merged. PR #10469 was reviewed and merged.",
      "otherNotes" : "qm is a command-line tool for Proxmox VE. The issue is about documenting the qm command. The author is asking if they should build another page than the existing qm page. Suggestions were made to build subcommand pages like qm-stop. The issue is labeled as new command, let's document, help wanted, and good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406551
  }, {
    "issueDTO" : {
      "id" : 3246202265,
      "title" : "[GUI][Wanted feature] Add new shortcuts to new Keyboard Key (e.g. `-`, `+`)",
      "url" : "https://github.com/kaikramer/keystore-explorer/issues/578",
      "repositoryName" : "kaikramer/keystore-explorer",
      "description" : "Hello KSE Team, @kaikramer, @jonwltn,\n\n**Is your feature request related to a problem? Please describe.**\nI'm always frustrated when 'View details on `Private` or `Public Key`' because there is not shortcut for that.\n\n**Describe the solution you'd like**\nTo continue:\n- #538\n\n\nHere is a proposal for a wanted feature:\n\nAs: \n| Keyboard Key | Action <br> _(or shortcut)_ |\n|--------|--------|\n| `Enter Key`| View details on `Certificate`,<br> or View details on `Secret Key`|\n\nCould you map: \uD83C\uDD95 \n| Keyboard Key | Action <br> _(or shortcut)_ |\n|--------|--------|\n| `Minus Key` `-`| View details on `Private Key`|\n| `Plus Key` `+`| View details on `Public Key`|\n\n_Open to debate,_\nRegards,\nTh.\n",
      "updatedAt" : 1753392723.000000000,
      "user" : "The-Lum",
      "userHtmlUrl" : "https://github.com/The-Lum",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/86879521?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I like it. Extending the shortcuts is always good and I think the choice of \"-\" and \"+\" is also good here." ],
      "repository" : {
        "description" : "KeyStore Explorer is a free GUI replacement for the Java command-line utilities keytool and jarsigner.",
        "homepage" : "https://keystore-explorer.org/",
        "name" : "keystore-explorer",
        "fullName" : "kaikramer/keystore-explorer",
        "htmlUrl" : "https://github.com/kaikramer/keystore-explorer",
        "gitUrl" : "git://github.com/kaikramer/keystore-explorer.git",
        "sshUrl" : "git@github.com:kaikramer/keystore-explorer.git",
        "cloneUrl" : "https://github.com/kaikramer/keystore-explorer.git",
        "owner" : {
          "login" : "kaikramer",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 294,
        "stargazersCount" : 1872,
        "watchersCount" : 1872,
        "size" : 41756,
        "openIssuesCount" : 47,
        "subscribersCount" : 63,
        "pushedAt" : "2025-07-23T21:05:25Z",
        "languages" : {
          "Java" : 4103866,
          "Shell" : 2561,
          "Nim" : 12676,
          "Inno Setup" : 1559
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add new shortcuts to 'Minus Key' and 'Plus Key' for 'View details on Private Key' and 'View details on Public Key' respectively.",
      "validationOrRequirement" : "The issue is labeled as 'good first issue', indicating it is suitable for new contributors.",
      "attemptedFixes" : "The author proposes a solution by mapping the 'Minus Key' and 'Plus Key' to 'View details on Private Key' and 'View details on Public Key' respectively.",
      "otherNotes" : "The author is frustrated with the lack of shortcuts for 'View details on Private or Public Key' and proposes adding new shortcuts for 'Minus Key' and 'Plus Key'.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406556
  }, {
    "issueDTO" : {
      "id" : 3261322226,
      "title" : "[libs] Ensure Logs Print At Least Error",
      "url" : "https://github.com/nanvix/nanvix/issues/704",
      "repositoryName" : "nanvix/nanvix",
      "description" : "## Description\n\nRight now, most of our subsystems will print no logging messages at all, unless we set a value to `RUST_LOG`. This includes, for example, error messages.\n\nWe should instead enforce a reasonable default. For example, if `RUST_LOG` is not set, print at least `error` messages.\n\nThis can be achieved with something like follows during logging initialization:\n\n```\nLogger::try_with_env_or_str(\"error\")\n```\n",
      "updatedAt" : 1753392614.000000000,
      "user" : "csegarragonz",
      "userHtmlUrl" : "https://github.com/csegarragonz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19322012?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Microkernel-Based Research Operating System Written in Rust",
        "homepage" : "https://github.com/nanvix",
        "name" : "nanvix",
        "fullName" : "nanvix/nanvix",
        "htmlUrl" : "https://github.com/nanvix/nanvix",
        "gitUrl" : "git://github.com/nanvix/nanvix.git",
        "sshUrl" : "git@github.com:nanvix/nanvix.git",
        "cloneUrl" : "https://github.com/nanvix/nanvix.git",
        "owner" : {
          "login" : "nanvix",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 90,
        "stargazersCount" : 168,
        "watchersCount" : 168,
        "size" : 8928,
        "openIssuesCount" : 150,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-25T00:28:37Z",
        "languages" : {
          "Dockerfile" : 1549,
          "Shell" : 62211,
          "C++" : 1676,
          "Rust" : 3289878,
          "C" : 184489,
          "GDB" : 399,
          "Linker Script" : 1812,
          "Makefile" : 59611,
          "JavaScript" : 2706,
          "Assembly" : 25967,
          "Python" : 11533
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Ensure logs print at least error messages, with a reasonable default if RUST_LOG is not set.",
      "validationOrRequirement" : "RUST_LOG should not be set, or set to a value that prints at least error messages.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description.",
      "otherNotes" : "The issue is about ensuring logs print at least error messages, with a reasonable default if RUST_LOG is not set.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406559
  }, {
    "issueDTO" : {
      "id" : 2862971690,
      "title" : "Simplify \"Bring You Own Backend\" deployments",
      "url" : "https://github.com/open-telemetry/opentelemetry-demo/issues/2052",
      "repositoryName" : "open-telemetry/opentelemetry-demo",
      "description" : "# Feature Request\n\nIt is already possible to use any `otlphttp` exporter following the [documentation](https://opentelemetry.io/docs/demo/kubernetes-deployment/#bring-your-own-backend) for Bring Your Own Backend for Kubernetes.\n\nWhile this approach works, it would be great to simplify the process of deploying the OpenTelemetry demo with a custom backend using an OTLP HTTP exporter. Additionally, deploying with Docker Compose currently requires either adding a new custom collector configuration or modifying the existing one.\n\n**Describe the solution you'd like:**\n\nBeing able to use any `otlphttp` exporter, with minimal configuration required.\n\nFor Kubernetes deployments, it would be great to add a new configuration option in the Helm charts that allows users to easily configure the OTLP HTTP endpoint. For example:\n\n``helm install otel-demo charts/opentelemetry-demo --set otlp-backend=true --set opentelemetry-collector.config.exporters.otlpbackend.endpoint=\"my-endpoint\"``\n\nFor Docker Compose deployments, it would be helpful to allow overriding OTLP endpoints and headers through environment variables. Additionally, it would be useful to enable users to select which exporters to use. One potential solution could be utilizing [Docker Compose Profiles](https://docs.docker.com/compose/how-tos/profiles/), enabling users to specify the desired profile with a command like:\n\n``PROFILE=byob make start``",
      "updatedAt" : 1753392507.000000000,
      "user" : "girodav",
      "userHtmlUrl" : "https://github.com/girodav",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1390902?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I support this idea, looks like it will be optional and won't affect the current deployment mechanism. The main benefit is that it will ease the `Bring your won backend` strategy, and testing different vendors/backends would be a matter of defining a different `otlp` endpoint.\n\nAnother option would be to use [docker compose overrides](https://docs.docker.com/compose/how-tos/multiple-compose-files/merge/), but Profiles seems more suitable for this use case (we can add as many otel-collector profiles as needed)\n\n@open-telemetry/demo-approvers wdyt?", "Ohhhhh, TIL! \uD83E\uDD13 \n\nProfiles look great!\nWe could drop the `minimal` docker compose override and just configure the profiles.\n\nI liked that!", "I'm struggling a little bit to understand how this would simplify things. An OTLP exporter is typically more than just an endpoint. OTLP headers are often required (especially for any SaaS vendor). Right now, we have 3 different pipelines configured for each telemetry type (traces, logs, metrics). Should this work for all 3? What if it should just be limited to 1 or 2 pipelines, how would those be specified as well?\n\nThere is certainly a level of complexity involved in needing to specify all the existing exporters because it's an array list, and YAML merges on arrays are destructive. At that same time, I'm also uncertain that this can be configured with a couple of command-line options and make things simpler.", "Just to raise a discussion here.\n\nI've tried setting up the docker compose profiles and they looked great at first sight!\nWe would drop 4 files in favour of 1.\n\nBut when I took a closer look to the `minimal` deployment it actually has one less env var: `KAFKA_ADDR` is not expected on the `checkout` service.\nI've googled a bit but it doesn't seem to be possible to have different env vars for different profiles.\n\nWe would need to have an `.override` file, which would still be better, but not sure if that's what we expected.\n\nAny opinions?", "> But when I took a closer look to the minimal deployment it actually has one less env var: KAFKA_ADDR is not expected on the checkout service.\n\nCould it be an option having multiple `.env` files? One for each profile and use [compose_env_files](https://docs.docker.com/compose/how-tos/environment-variables/envvars/#compose_env_files) in the Makefile.", "> > But when I took a closer look to the minimal deployment it actually has one less env var: KAFKA_ADDR is not expected on the checkout service.\n> \n> Could it be an option having multiple `.env` files? One for each profile and use [compose_env_files](https://docs.docker.com/compose/how-tos/environment-variables/envvars/#compose_env_files) in the Makefile.\n\nI had to change a bit the approach, but you actually triggered the idea \uD83E\uDD73 \n\nI have this one as draft if you would like to take a look: https://github.com/open-telemetry/opentelemetry-demo/pull/2396" ],
      "repository" : {
        "description" : "This repository contains the OpenTelemetry Astronomy Shop, a microservice-based distributed system intended to illustrate the implementation of OpenTelemetry in a near real-world environment.",
        "homepage" : "https://opentelemetry.io/docs/demo/",
        "name" : "opentelemetry-demo",
        "fullName" : "open-telemetry/opentelemetry-demo",
        "htmlUrl" : "https://github.com/open-telemetry/opentelemetry-demo",
        "gitUrl" : "git://github.com/open-telemetry/opentelemetry-demo.git",
        "sshUrl" : "git@github.com:open-telemetry/opentelemetry-demo.git",
        "cloneUrl" : "https://github.com/open-telemetry/opentelemetry-demo.git",
        "owner" : {
          "login" : "open-telemetry",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4102,
        "stargazersCount" : 2453,
        "watchersCount" : 2453,
        "size" : 47189,
        "openIssuesCount" : 68,
        "subscribersCount" : 48,
        "pushedAt" : "2025-07-24T12:58:38Z",
        "languages" : {
          "C#" : 27276,
          "Java" : 20387,
          "C++" : 14998,
          "CSS" : 951,
          "Rust" : 10489,
          "C" : 181,
          "CMake" : 3258,
          "Objective-C++" : 2723,
          "Makefile" : 9147,
          "Go" : 46577,
          "HTML" : 1885,
          "Kotlin" : 7382,
          "TypeScript" : 288690,
          "Dockerfile" : 22051,
          "Shell" : 6770,
          "JavaScript" : 12756,
          "PHP" : 7863,
          "Objective-C" : 405,
          "Ruby" : 4158,
          "Python" : 60269
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Simplify the process of deploying the OpenTelemetry demo with a custom backend using an OTLP HTTP exporter, allowing users to easily configure the OTLP HTTP endpoint for Kubernetes deployments and override OTLP endpoints and headers through environment variables for Docker Compose deployments.",
      "validationOrRequirement" : "The issue requires the ability to use any otlphttp exporter with minimal configuration required. For Kubernetes deployments, a new configuration option in the Helm charts is needed to easily configure the OTLP HTTP endpoint. For Docker Compose deployments, it would be helpful to allow overriding OTLP endpoints and headers through environment variables.",
      "attemptedFixes" : "There are different approaches discussed in the comments, such as using Docker Compose Profiles, [docker compose overrides](https://docs.docker.com/compose/how-tos/multiple-compose-files/merge/), or having multiple .env files. One potential solution could be utilizing Docker Compose Profiles, enabling users to specify the desired profile with a command like: `PROFILE=byob make start`.",
      "otherNotes" : "The issue is about simplifying the process of deploying OpenTelemetry demo with a custom backend using an OTLP HTTP exporter. It's already possible to use any otlphttp exporter following the documentation for Bring Your Own Backend for Kubernetes. The solution would allow users to easily configure the OTLP HTTP endpoint for Kubernetes deployments and override OTLP endpoints and headers through environment variables for Docker Compose deployments.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406569
  }, {
    "issueDTO" : {
      "id" : 3261020635,
      "title" : "[Bug]: Fix hover Animation effect on my name in footer",
      "url" : "https://github.com/itsAnimation/AnimateItNow/issues/347",
      "repositoryName" : "itsAnimation/AnimateItNow",
      "description" : "### What happened?\n\n<img width=\"1670\" height=\"456\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e96b6afb-59ab-4135-a97e-f2bc03b75c60\" />\n\nIt shows contributor when hovering on my name, change it to project admin , and on clicking it redirect to this link : https://www.linkedin.com/in/anujshrivastava1/\n\n### Screenshots\n\n_No response_\n\n### Steps to Reproduce\n\nfix bug\n\n### Environment\n\n_No response_\n\n### Severity\n\nNone",
      "updatedAt" : 1753392404.000000000,
      "user" : "AnujShrivastava01",
      "userHtmlUrl" : "https://github.com/AnujShrivastava01",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/150820396?v=4",
      "labels" : [ "bug", "level1", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'd like to work on this issue under GSSoC'25 . Please assign it to me .\n", "@AnujShrivastava01 I would love to do this task pls assign it to me", "@AnujShrivastava01 Hi! I???m a GSSoC???25 contributor and would love to work on this issue. Kindly assign it to me.\n", "I would like to work on this issue and change the design to match the theme of the website ", "@Avneetbhatia12 Assigning to you !" ],
      "repository" : {
        "description" : null,
        "homepage" : "https://animate-it-now.netlify.app/",
        "name" : "AnimateItNow",
        "fullName" : "itsAnimation/AnimateItNow",
        "htmlUrl" : "https://github.com/itsAnimation/AnimateItNow",
        "gitUrl" : "git://github.com/itsAnimation/AnimateItNow.git",
        "sshUrl" : "git@github.com:itsAnimation/AnimateItNow.git",
        "cloneUrl" : "https://github.com/itsAnimation/AnimateItNow.git",
        "owner" : {
          "login" : "itsAnimation",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 149,
        "stargazersCount" : 43,
        "watchersCount" : 43,
        "size" : 6051,
        "openIssuesCount" : 132,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T22:17:11Z",
        "languages" : {
          "CSS" : 30008,
          "JavaScript" : 5805,
          "HTML" : 181155
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix a bug in the hover animation effect on the contributor's name in the footer, changing it to project admin, and redirecting to a specific LinkedIn link upon click.",
      "validationOrRequirement" : "The issue requires changing the design to match the theme of the website, as mentioned in one of the comments.",
      "attemptedFixes" : "No specific fixes mentioned in the issue description or comments.",
      "otherNotes" : "The issue involves fixing a bug with hover animation effect on the contributor's name in the footer, changing it to project admin, and redirecting to a specific LinkedIn link upon click.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406573
  }, {
    "issueDTO" : {
      "id" : 3261310468,
      "title" : "`-Wno-whole-archive` does not work",
      "url" : "https://github.com/qualcomm/eld/issues/273",
      "repositoryName" : "qualcomm/eld",
      "description" : "All warning categories have a `-Wno-<category>` counterpart except `whole-archive` warning category. We should add support for `-Wno-whole-archive`.",
      "updatedAt" : 1753392355.000000000,
      "user" : "parth-07",
      "userHtmlUrl" : "https://github.com/parth-07",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/40723498?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Embedded Linker",
        "homepage" : "https://qualcomm.github.io/eld/",
        "name" : "eld",
        "fullName" : "qualcomm/eld",
        "htmlUrl" : "https://github.com/qualcomm/eld",
        "gitUrl" : "git://github.com/qualcomm/eld.git",
        "sshUrl" : "git@github.com:qualcomm/eld.git",
        "cloneUrl" : "https://github.com/qualcomm/eld.git",
        "owner" : {
          "login" : "qualcomm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28,
        "stargazersCount" : 193,
        "watchersCount" : 193,
        "size" : 5977,
        "openIssuesCount" : 63,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T23:16:38Z",
        "languages" : {
          "C++" : 3939450,
          "C" : 284731,
          "CMake" : 91812,
          "SWIG" : 484,
          "NASL" : 10036,
          "Common Lisp" : 1581,
          "Perl" : 3783,
          "Scilab" : 1248,
          "LLVM" : 769,
          "Linker Script" : 3709,
          "Roff" : 845,
          "Assembly" : 282484,
          "Lex" : 629,
          "Raku" : 261196,
          "Python" : 99885,
          "Terra" : 511
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for `-Wno-whole-archive` warning category, which is currently missing.",
      "validationOrRequirement" : "Add support for `-Wno-whole-archive` warning category, similar to other categories.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about adding support for `-Wno-whole-archive` warning category, which is missing a counterpart similar to other categories.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406576
  }, {
    "issueDTO" : {
      "id" : 2015897663,
      "title" : "Missions: Warn about auto-arm when pressing play",
      "url" : "https://github.com/bluerobotics/cockpit/issues/608",
      "repositoryName" : "bluerobotics/cockpit",
      "description" : "There should be a pop-up dialog warning the user, with \r\n- a message along the lines of \"Starting mission - ensure the vehicle is safe to launch.\"\r\n- a button for \"safe to launch\" / \"confirm\" / \"continue\"\r\n    - a corresponding checkbox for \"don't show again\" (for people who don't want that warning pop-up)\r\n- a \"cancel\" button\r\n\r\nThis could potentially be integrated as part of #22\r\n\r\nProblem raised by BillyBudd in [this forum comment](https://discuss.bluerobotics.com/t/blueos-1-1-0-release/14931/11).",
      "updatedAt" : 1753392354.000000000,
      "user" : "ES-Alexander",
      "userHtmlUrl" : "https://github.com/ES-Alexander",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25898329?v=4",
      "labels" : [ "safety", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An intuitive and customizable cross-platform ground control station for remote vehicles of all types.",
        "homepage" : "https://blueos.cloud/cockpit/docs",
        "name" : "cockpit",
        "fullName" : "bluerobotics/cockpit",
        "htmlUrl" : "https://github.com/bluerobotics/cockpit",
        "gitUrl" : "git://github.com/bluerobotics/cockpit.git",
        "sshUrl" : "git@github.com:bluerobotics/cockpit.git",
        "cloneUrl" : "https://github.com/bluerobotics/cockpit.git",
        "owner" : {
          "login" : "bluerobotics",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 32,
        "stargazersCount" : 116,
        "watchersCount" : 116,
        "size" : 575271,
        "openIssuesCount" : 490,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-25T00:18:19Z",
        "languages" : {
          "TypeScript" : 730256,
          "Dockerfile" : 4204,
          "CSS" : 1539,
          "SCSS" : 64,
          "Vue" : 1006790,
          "JavaScript" : 17266,
          "HTML" : 8918
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Warn the user about auto-arm when pressing play with a pop-up dialog, including a message, button for 'safe to launch', checkbox for 'don't show again', and 'cancel' button, to ensure the vehicle is safe to launch.",
      "validationOrRequirement" : "None mentioned in the issue description or comments.",
      "attemptedFixes" : "No attempts or blockers mentioned in the issue description or comments.",
      "otherNotes" : "This issue is related to #22 and was raised by BillyBudd in a forum comment.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406579
  }, {
    "issueDTO" : {
      "id" : 3261308995,
      "title" : "WebSocket Keep-Alive strategy and ping interval",
      "url" : "https://github.com/alexandrehtrb/Pororoca/issues/158",
      "repositoryName" : "alexandrehtrb/Pororoca",
      "description" : "Based on [docs](https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/websockets#keep-alive-strategies).\n\nWebSocket screen could have a new option tab to select:\n\n- Strategy: \n  - Unsolicited PONG\n  - PING/PONG\n- KeepAliveInterval \n- KeepAliveTimeout\n\nWe can do this after upgrading to .NET 10.",
      "updatedAt" : 1753392264.000000000,
      "user" : "alexandrehtrb",
      "userHtmlUrl" : "https://github.com/alexandrehtrb",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/27026741?v=4",
      "labels" : [ "hacktoberfest", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An API testing tool with support for HTTP/2 and HTTP/3. Alternative to Postman.",
        "homepage" : "https://pororoca.io",
        "name" : "Pororoca",
        "fullName" : "alexandrehtrb/Pororoca",
        "htmlUrl" : "https://github.com/alexandrehtrb/Pororoca",
        "gitUrl" : "git://github.com/alexandrehtrb/Pororoca.git",
        "sshUrl" : "git@github.com:alexandrehtrb/Pororoca.git",
        "cloneUrl" : "https://github.com/alexandrehtrb/Pororoca.git",
        "owner" : {
          "login" : "alexandrehtrb",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 50,
        "stargazersCount" : 597,
        "watchersCount" : 597,
        "size" : 11667,
        "openIssuesCount" : 20,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-23T17:49:18Z",
        "languages" : {
          "C#" : 1460152,
          "PowerShell" : 22705,
          "Shell" : 2131,
          "HTML" : 5914,
          "NSIS" : 320086
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a new option tab in WebSocket screen to select keep-alive strategy and configure keep-alive interval and timeout",
      "validationOrRequirement" : "Select strategy (Unsolicited PONG or PING/PONG), set KeepAliveInterval, and set KeepAliveTimeout",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Based on Microsoft documentation for WebSocket keep-alive strategies",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406582
  }, {
    "issueDTO" : {
      "id" : 3261198302,
      "title" : "Allow scalar int8 tensors to be unranked in the TOSA dialect",
      "url" : "https://github.com/llvm/llvm-project/issues/150519",
      "repositoryName" : "llvm/llvm-project",
      "description" : "Scalar operands in the TOSA dialect are currently required to be ranked. This leads to issues/reports similar to the following: https://discourse.llvm.org/t/tosa-pad-operand-must-be-tosa-conformant-scalar-tensor-of-number-values/87432\n\nScalar tensors are defined with the tablegen definition Tosa_ScalarInt8Tensor. This issue would require updating this definition to allow a scalar tensor to either be ranked or unranked. A similar pull request for reference can be found here: https://github.com/llvm/llvm-project/pull/143770 or here: https://github.com/llvm/llvm-project/pull/150399. Tests should also be added to support the change.",
      "updatedAt" : 1753391964.000000000,
      "user" : "lhutton1",
      "userHtmlUrl" : "https://github.com/lhutton1",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/35535092?v=4",
      "labels" : [ "mlir:tosa", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\nHi!\n\nThis issue may be a good introductory issue for people new to working on LLVM. If you would like to work on this issue, your first steps are:\n\n1. Check that no other contributor is working on this issue. If someone is assigned to the issue or claimed to be working on it, ping the person. After one week without a response, the assignee may be changed.\n1. Leave a comment indicating that you are working on the issue, or just create a [pull request](https://github.com/llvm/llvm-project/pulls) after following the steps below. [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n1. Fix the issue locally.\n1. [Run the test suite](https://llvm.org/docs/TestingGuide.html#unit-and-regression-tests) locally. Remember that the subdirectories under `test/` create fine-grained testing targets, so you can e.g. use `make check-clang-ast` to only run Clang's AST tests.\n1. Create a Git commit.\n1. Run [`git clang-format HEAD~1`](https://clang.llvm.org/docs/ClangFormat.html#git-integration) to format your changes.\n1. Open a [pull request](https://github.com/llvm/llvm-project/pulls) to the [upstream repository](https://github.com/llvm/llvm-project) on GitHub. Detailed instructions can be found [in GitHub's documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request). [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n\nIf you have any further questions about this issue, don't hesitate to ask via a comment in the thread below.\n\n", "\n@llvm/issue-subscribers-good-first-issue\n\nAuthor: Luke Hutton (lhutton1)\n\n<details>\nScalar operands in the TOSA dialect are currently required to be ranked. This leads to issues/reports similar to the following: https://discourse.llvm.org/t/tosa-pad-operand-must-be-tosa-conformant-scalar-tensor-of-number-values/87432\n\nScalar tensors are defined with the tablegen definition Tosa_ScalarInt8Tensor. This issue would require updating this definition to allow a scalar tensor to either be ranked or unranked. A similar pull request for reference can be found here: https://github.com/llvm/llvm-project/pull/143770 or here: https://github.com/llvm/llvm-project/pull/150399. Tests should also be added to support the change.\n</details>\n", " @lhutton1 I would like to work on this. This will be my first time working with MLIR, so I???d appreciate any feedback or guidance you can offer! Thanks!", "Thanks @yichi170, happy to help! I'll assign this issue to you" ],
      "repository" : {
        "description" : "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.",
        "homepage" : "http://llvm.org",
        "name" : "llvm-project",
        "fullName" : "llvm/llvm-project",
        "htmlUrl" : "https://github.com/llvm/llvm-project",
        "gitUrl" : "git://github.com/llvm/llvm-project.git",
        "sshUrl" : "git@github.com:llvm/llvm-project.git",
        "cloneUrl" : "https://github.com/llvm/llvm-project.git",
        "owner" : {
          "login" : "llvm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14563,
        "stargazersCount" : 33645,
        "watchersCount" : 33645,
        "size" : 2568475,
        "openIssuesCount" : 31089,
        "subscribersCount" : 580,
        "pushedAt" : "2025-07-25T00:59:09Z",
        "languages" : {
          "GDB" : 8473,
          "CMake" : 4108206,
          "Mustache" : 17219,
          "HTML" : 1956247,
          "Pawn" : 20078,
          "MATLAB" : 4946,
          "Fortran" : 11668142,
          "LLVM" : 634320209,
          "OCaml" : 335815,
          "Assembly" : 154980494,
          "Python" : 12978634,
          "Rust" : 4903,
          "Objective-C++" : 1178815,
          "SWIG" : 288374,
          "Tree-sitter Query" : 6195,
          "Perl" : 183797,
          "MLIR" : 21384848,
          "Cuda" : 1243277,
          "Scilab" : 160404,
          "Starlark" : 1194175,
          "Batchfile" : 52122,
          "AMPL" : 1662,
          "Swift" : 271,
          "DTrace" : 334,
          "C" : 202468383,
          "RPC" : 28,
          "Makefile" : 114950,
          "Cool" : 5401,
          "Jupyter Notebook" : 72939,
          "M" : 9785,
          "TypeScript" : 69121,
          "Shell" : 264842,
          "Awk" : 127345,
          "JavaScript" : 161607,
          "Mathematica" : 1118,
          "Objective-C" : 4302574,
          "Lua" : 12033,
          "PHP" : 64,
          "Limbo" : 303,
          "POV-Ray SDL" : 861,
          "Emacs Lisp" : 69003,
          "C++" : 490174634,
          "CSS" : 63859,
          "FIRRTL" : 4349198,
          "TeX" : 2141,
          "AppleScript" : 1429,
          "NASL" : 35217,
          "HIP" : 857866,
          "Julia" : 49676,
          "Dockerfile" : 23110,
          "Linker Script" : 903,
          "Roff" : 61624,
          "HLSL" : 1512603,
          "Mercury" : 14,
          "Vim Script" : 29186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow scalar int8 tensors to be unranked in the TOSA dialect, which would resolve issues/reports similar to the following: https://discourse.llvm.org/t/tosa-pad-operand-must-be-tosa-conformant-scalar-tensor-of-number-values/87432",
      "validationOrRequirement" : "Scalar operands in the TOSA dialect are currently required to be ranked.",
      "attemptedFixes" : "A similar pull request for reference can be found here: https://github.com/llvm/llvm-project/pull/143770 or here: https://github.com/llvm/llvm-project/pull/150399.",
      "otherNotes" : "Scalar tensors are defined with the tablegen definition Tosa_ScalarInt8Tensor. This issue would require updating this definition to allow a scalar tensor to either be ranked or unranked. Tests should also be added to support the change.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406588
  }, {
    "issueDTO" : {
      "id" : 3261236881,
      "title" : "Increase the structure limit for nations",
      "url" : "https://github.com/openfrontio/OpenFrontIO/issues/1561",
      "repositoryName" : "openfrontio/OpenFrontIO",
      "description" : "Increase the structure cap for nations, especially for ports and cities, in the late game.\n\nSome ideas to prevent things from getting out of hand are to tie the cap to the number of game ticks, or requiring the nation to save more gold in the bank for each additional structure.",
      "updatedAt" : 1753391912.000000000,
      "user" : "scottanderson",
      "userHtmlUrl" : "https://github.com/scottanderson",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/662325?v=4",
      "labels" : [ "Feature - AI", "Balance Tweak", "Feature - Frontend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This is just a suggestion, but I think it would make sense if the size of a territory affected the maximum number of units you can place there.\nIt seems like it would be difficult if the bot could put a large number of units on a very small territory." ],
      "repository" : {
        "description" : "Online browser-based RTS game",
        "homepage" : "https://openfront.io/",
        "name" : "OpenFrontIO",
        "fullName" : "openfrontio/OpenFrontIO",
        "htmlUrl" : "https://github.com/openfrontio/OpenFrontIO",
        "gitUrl" : "git://github.com/openfrontio/OpenFrontIO.git",
        "sshUrl" : "git@github.com:openfrontio/OpenFrontIO.git",
        "cloneUrl" : "https://github.com/openfrontio/OpenFrontIO.git",
        "owner" : {
          "login" : "openfrontio",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 359,
        "stargazersCount" : 762,
        "watchersCount" : 762,
        "size" : 233642,
        "openIssuesCount" : 263,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-24T23:38:55Z",
        "languages" : {
          "TypeScript" : 1306962,
          "Dockerfile" : 2055,
          "CSS" : 29813,
          "Shell" : 22020,
          "JavaScript" : 9195,
          "HTML" : 46775
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Increase the structure limit for nations, especially for ports and cities, in the late game",
      "validationOrRequirement" : "tie the cap to the number of game ticks, or requiring the nation to save more gold in the bank for each additional structure",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "idea to prevent things from getting out of hand are to tie the cap to the number of game ticks, or requiring the nation to save more gold in the bank for each additional structure",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406591
  }, {
    "issueDTO" : {
      "id" : 2736632625,
      "title" : "Request for clearer error message parsing pyproject.toml",
      "url" : "https://github.com/python-poetry/poetry/issues/9900",
      "repositoryName" : "python-poetry/poetry",
      "description" : "### Issue Kind\n\nChange in current behaviour\n\n### Description\n\nWhen the tool.poetry.source section in pyproject.toml is provided as a `[single table]` rather than `[[array of tables]]` the error poetry provides isn't very helpful:\r\n```\r\nThe Poetry configuration is invalid:\r\n  - data.source must be array\r\n```\r\n\r\nA more descriptive error and/or a reference to what section or line in the toml would be a little more friendly.  Tried this with -vvv and the stack trace also doesn't give a clue to what part of the toml is actually the problem.\r\n\r\nA more broad way to phrase it, if you like,  might be \"toml structure errors should report a line or section if possible\" \n\n### Impact\n\nSome more info in the error would make troubleshooting faster; as it is one either 'just knows' the expected structure or goes section by section, which might be slower or faster depending on the size of pyproject.toml.\n\n### Workarounds\n\nNone that I'm aware of",
      "updatedAt" : 1753391728.000000000,
      "user" : "Evan0000000000",
      "userHtmlUrl" : "https://github.com/Evan0000000000",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/160069225?v=4",
      "labels" : [ "kind/feature", "good first issue", "area/error-handling" ],
      "state" : "OPEN",
      "comments" : [ "Landed on this issue after running into this myself.\n\n@Evan0000000000 , any chance you can post an example / description of solution as you've proposed. Other people may end up here too looking to understand what the error means. \n\nI am one of those people, new to using poetry and I do not \"just know\" the solution. Additionally, OpenAI seems to strangely bounce you back-and-forth between two equally obscure error messages if you cut-and-paste the error & ask for assistance. ", "> Landed on this issue after running into this myself.\n> \n> [@Evan0000000000](https://github.com/Evan0000000000) , any chance you can post an example / description of solution as you've proposed. Other people may end up here too looking to understand what the error means.\n> \n> I am one of those people, new to using poetry and I do not \"just know\" the solution. Additionally, OpenAI seems to strangely bounce you back-and-forth between two equally obscure error messages if you cut-and-paste the error & ask for assistance.\n\nHey Jeremy, sure, as an example, in pyproject.toml the `tool.poetry.source` section must be an array, like `[[tool.poetry.source]]` even if you only specify one source. This makes total sense as arrays with 1 entry are completely valid.  \n\nThe confusion is that poetry will give you the error in my original message, which tells you something should be an array but not _which_ something, so the solution currently is just to review your pyproject.toml file very carefully with respect to what each tool you have using it expects.", "We already replace `data.` with `tool.poetry.` in https://github.com/python-poetry/poetry-core/blob/002aa3e16f98d21645bb9a45f698b55adc40f317/src/poetry/core/factory.py#L606-L609.\n\nWe probably have to do the same in https://github.com/python-poetry/poetry/blob/aeaa3d09ce7381bf34ac7e0ac27b929841256c90/src/poetry/factory.py#L335.", "hi may i pick this up as a first issue if no one is working on it? would like to take a shot at it", "> hi may i pick this up as a first issue if no one is working on it? would like to take a shot at it\n\nOf course. As far as I know, nobody submitted a PR yet." ],
      "repository" : {
        "description" : "Python packaging and dependency management made easy",
        "homepage" : "https://python-poetry.org",
        "name" : "poetry",
        "fullName" : "python-poetry/poetry",
        "htmlUrl" : "https://github.com/python-poetry/poetry",
        "gitUrl" : "git://github.com/python-poetry/poetry.git",
        "sshUrl" : "git@github.com:python-poetry/poetry.git",
        "cloneUrl" : "https://github.com/python-poetry/poetry.git",
        "owner" : {
          "login" : "python-poetry",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2356,
        "stargazersCount" : 33477,
        "watchersCount" : 33477,
        "size" : 23306,
        "openIssuesCount" : 578,
        "subscribersCount" : 190,
        "pushedAt" : "2025-07-21T20:28:44Z",
        "languages" : {
          "HTML" : 260611,
          "Python" : 2045674
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Request for clearer error message parsing pyproject.toml when the tool.poetry.source section is provided as a [single table] rather than [[array of tables]].",
      "validationOrRequirement" : "The `tool.poetry.source` section in pyproject.toml must be an array, like [[tool.poetry.source]], even if you only specify one source.",
      "attemptedFixes" : "The solution currently is just to review the pyproject.toml file very carefully with respect to what each tool you have using it expects.",
      "otherNotes" : "The issue is about improving error message parsing in pyproject.toml, specifically when the tool.poetry.source section is provided as a [single table] rather than [[array of tables]].",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406596
  }, {
    "issueDTO" : {
      "id" : 3248156191,
      "title" : "Git default branch is not specified in the github actions",
      "url" : "https://github.com/rails/rails/issues/55379",
      "repositoryName" : "rails/rails",
      "description" : "### Steps to reproduce\n\n```ruby\ncat ~/.gitconfig\n[init]\n    defaultBranch = master\n...\n\nrails new demo-app\n...\n\ncat demo-app/.github/workflows/ci.yml\nname: CI\n\non:\n  pull_request:\n  push:\n    branches: [ main ]\n...\n```\n### Expected behavior\n\nHaving the default branch specified on the gitconfig (git config init.defaultBranch)\n\n### Actual behavior\n\nA static value defined [here](https://github.com/rails/rails/blob/main/railties/lib/rails/generators/rails/app/templates/github/ci.yml.tt#L6)\n\n### System configuration\n\n**Rails version**: Rails 8.0.2\n\n**Ruby version**: ruby 3.4.3 (2025-04-14 revision d0b7e5b6a0) +PRISM [x86_64-linux]\n",
      "updatedAt" : 1753391421.000000000,
      "user" : "xfoucron",
      "userHtmlUrl" : "https://github.com/xfoucron",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/73240020?v=4",
      "labels" : [ "railties", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "If someone picks this up please address the other one too:\n\nhttps://github.com/rails/rails/blob/08b54b95a177511756fdb407f381bc5ec4bbdcdb/railties/lib/rails/generators/rails/plugin/templates/github/ci.yml.tt#L6" ],
      "repository" : {
        "description" : "Ruby on Rails",
        "homepage" : "https://rubyonrails.org",
        "name" : "rails",
        "fullName" : "rails/rails",
        "htmlUrl" : "https://github.com/rails/rails",
        "gitUrl" : "git://github.com/rails/rails.git",
        "sshUrl" : "git@github.com:rails/rails.git",
        "cloneUrl" : "https://github.com/rails/rails.git",
        "owner" : {
          "login" : "rails",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 21895,
        "stargazersCount" : 57184,
        "watchersCount" : 57184,
        "size" : 266813,
        "openIssuesCount" : 1320,
        "subscribersCount" : 2311,
        "pushedAt" : "2025-07-24T07:38:36Z",
        "languages" : {
          "Dockerfile" : 2006,
          "CSS" : 27100,
          "Shell" : 626,
          "SCSS" : 50596,
          "JavaScript" : 230742,
          "HTML" : 198278,
          "Ruby" : 17470393
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to specify the default branch in the GitHub Actions workflow, which is currently not specified.",
      "validationOrRequirement" : "The default branch should be specified on the gitconfig (git config init.defaultBranch).",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The issue is related to GitHub Actions, Rails version 8.0.2, and Ruby version 3.4.3.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406600
  }, {
    "issueDTO" : {
      "id" : 2973908140,
      "title" : "Refactoring for Unit Test Access Controls",
      "url" : "https://github.com/TEAMMATES/teammates/issues/13304",
      "repositoryName" : "TEAMMATES/teammates",
      "description" : "Part of #12048\n\n## Issue\nAfter most of the Unit Test migration in #12048, there are a lot of inconsistencies in access control test methods. This is because we did not migrate the many convenient, abstracted, and commonly used access control test methods from `ui/webapi/BaseActionTest.java` to `sqlui/webapi/BaseActionTest.java`.\n\nAfter merging #13254, all of the access control test methods in `BaseActionTest.java` have been migrated. Hence, this issue aims to refactor the unit test access controls to use these convenient test methods.\n\n## Progress\nThe progress for this refactoring can be found [here](https://docs.google.com/spreadsheets/d/1IcB-viJMrIOknYoBYasBuRBK9qnwY0-doEK4_Eb24IA/edit?gid=0#gid=0). I (the author) will update it when completed PRs are merged proactively.\n\n## Steps to Contribute\n\n1. Choose test(s) to work on in the above Google Sheets link\n2. Check that no on else have claimed the test cases to work on within the last 2 weeks, or that it has been completed by follow up PRs (but not updated in the sheets)\n3. Comment on this issue to indicate that you'd like to contribute on the chosen test(s). Update your comment if you need more than 2 weeks so that other contributors don't overlap with your work.\n4. Create a PR to refactor the unit test(s).\n5. Submit the PR, with a link to this issue by starting the description with \"Part of #13304\". \n6. Tag me or any other active reviewers and wait for us to review (so that we can get a notification)\n\n## Tips\n\n- Understand the access control test methods in `sqlui/webapi/BaseActionTest.java`, follow the refactoring in #13254\n- Most of the access control testing logic in the migrated unit tests under `sqlui/webapi` follows the old unit tests under `ui/webapi`, so you may wish to reference the old unit test for help",
      "updatedAt" : 1753391318.000000000,
      "user" : "InfinityTwo",
      "userHtmlUrl" : "https://github.com/InfinityTwo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/20984062?v=4",
      "labels" : [ "a-AccessControl", "good first issue", "c.Task" ],
      "state" : "OPEN",
      "comments" : [ "**Good First Issue - Notes for Contributors**\n  This issue is for **first-time contributors only**. If you are new to TEAMMATES, feel free to submit a PR for this issue.\n\n*Please note that we allow only one `good first issue` per contributor.* If you have already made a prior contribution to TEAMMATES, you may wish to take a look at issues with the `help wanted` tag instead.\n\n**We do not assign issues to contributors**. If you would like to pick up this issue, do post a comment below to express your interest and check if there is anyone else who is already working on the issue. We will do our best to reply and give you the go-ahead, but if we don't, feel free to submit a PR as long as there is no one else working on it.\n\n**To get started**, do read through our [contributing guidelines](https://teammates.github.io/teammates/contributing-doc.html) carefully, and [set up a development environment on your local machine](https://teammates.github.io/teammates/setting-up.html) before making a PR.\n\nIf you need any clarifications on our [developer guide](https://teammates.github.io/teammates/index.html), or are facing issues that are not found in our [troubleshooting guide](https://teammates.github.io/teammates/troubleshooting-guide.html), please [post a message in our discussion forum](https://github.com/TEAMMATES/teammates/discussions).", "Hello, I'm new to teammates and would like to take this as my first issue.", "> Hello, I'm new to teammates and would like to take this as my first issue.\n\nHi @alextlucas, thanks for wanting to contribute. I would like to suggest that you can consider waiting for my PR to be merged before tackling as there might still be changes after reviews on my PR. Also, do comment which tests you would like to contribute to so that it does not conflict with other developers who wish to contribute as well \uD83D\uDE04 ", "@InfinityTwo Sounds good, I will subscribe to the PR and wait for the merge. I can work on rows 38-48 to start, and do more if needed.", "Hello.\nHow are you?\nI'm new to Teammates and I'm very excited to contribute to the project!\nSince Lucas has already requested lines 38-48, can I start from there? Taking 49 to 59?", "Hey @InfinityTwo, would love to contribute to this issue! Was wondering whether I could work on lines 60 to 70? ", "Hey interested contributors, thanks for your interest and want to help! Feel free to work on whichever rows you want, no permission is required from me. All I ask for is to state which rows you intend to touch on and avoid clashing with others, by giving a 1-2 week grace period. If there are no subsequent PRs linked to this issue within that time, you may tag the previous user who claimed it know you are taking over if you would like to tackle it.", "Hi, since the other rows have already been taken, I'd be keen to do lines 71-78. Thank you!", "Hi @InfinityTwo, I'm working on lines 49-59.", "Hey @InfinityTwo, having some difficulty running the test files to check whether they're passing on IntelliJ. Would be great if u could pls help out. ", "> Hey @InfinityTwo, having some difficulty running the test files to check whether they're passing on IntelliJ. Would be great if u could pls help out. \n\nHi @arnav-goel05 what issue are you facing?", "Hey @InfinityTwo, thanks for getting back to me. I'm not sure how to run the test files in sqlui>webapi. The run button is greyed out for me. Not sure where I'm going wrong. ", "> Hey @InfinityTwo, thanks for getting back to me. I'm not sure how to run the test files in sqlui>webapi. The run button is greyed out for me. Not sure where I'm going wrong. \n\n@arnav-goel05 could you list out the steps you took to run the test files? \n\nMy initial guess would be that you might not have installed the project correctly or you might be running an incorrect file by getting confused with the different directories.", "The file I'm trying to run is: teammates\\src\\test\\java\\teammates\\sqlui\\webapi\\RegenerateInstructorKeyActionTest.java\nIs this the correct directory? Also, are these files part of the component or E2E tests? \n\nI followed the setup for the project using https://teammates.github.io/teammates/development.html. Is there a particular step I messed up? ", "> The file I'm trying to run is: teammates\\src\\test\\java\\teammates\\sqlui\\webapi\\RegenerateInstructorKeyActionTest.java\n> Is this the correct directory? Also, are these files part of the component or E2E tests? \n> \n> I followed the setup for the project using https://teammates.github.io/teammates/development.html. Is there a particular step I messed up? \n\n@arnav-goel05 these are part of component tests. As for setting up, I don't think so but you can try to reinstall if you would like to.\n\nFor me, I just click the play button beside the class/methods to run the tests, select the test that runs component and it should run.\n\nIt could also be that you did not set up Intellij configurations properly. Try to change it or clear the cache and restart Intellij.\n\nIf you are still unable to debug it, could you send some screenshots and videos of your steps and configurations?", "@InfinityTwo Thank u for pointing me towards Intellij configurations. The error seems to be that there isn't any run configurations set up. Could you please help me check with what I'm supposed to put under the Main class for the application config. I'm not able to find a suitable option.\n\n![Image](https://github.com/user-attachments/assets/4b7ba862-9b4e-4b59-84a8-1436f5fa2da5)", "> [@InfinityTwo](https://github.com/InfinityTwo) Thank u for pointing me towards Intellij configurations. The error seems to be that there isn't any run configurations set up. Could you please help me check with what I'm supposed to put under the Main class for the application config. I'm not able to find a suitable option.\n\n@arnav-goel05 I've pulled a fresh copy of TEAMMATES and opened the folder in Intellij but the run button automatically appears and it is not disabled. I did not install any dependencies or run any commands, and my configurations is empty. From that I am guessing your Intellij is missing something, perhaps Gradle or some other plugins that inhibits the use of testing. You can try adding the missing plugins, reinstall Intellij, or use another editor.", "@InfinityTwo Thank u for running on ur end! Reinstalled Intellij and it started working. Wanted to check one last thing, upon running the test files, I got the following error: \n\nNo matching tests found in any candidate test task.\n    Requested tests:\n        Test pattern teammates.sqlui.webapi.RegenerateInstructorKeyActionTest.testExecute_successfulRegenerationWithEmailFailed_success in task :architectureTest\n\nAre you getting the same error on your end?\n", "@arnav-goel05 You are running architectureTest which is not the correct test to run. Use componentTest instead (from my memory, use unitTest if it doesn't work). Hope it goes smoothly from here out, happy coding \uD83D\uDE03 ", "@arnav-goel05 works for me running unitTests within the test folder in the gradle panel in intellij", "@InfinityTwo @zedonggg Thank you so much for helping me out! Its finally running on my end. ", "@InfinityTwo I've submitted a PR for the test cases (#13353). However, some of the E2E tests are failing ((E2E Sql Tests / E2E-sql-testing (firefox, stable) (pull_request)). Is it necessary for all the test cases for E2E to pass in order to merge the code?\n\nCould you also please review my PR? Thank you!", "@arnav-goel05 yes all checks must pass minimally on GitHub Actions. I'll find a time to review after you manage to fix all the issues. Also, if you have any questions regarding your contribution, let's move the conversation over to your PR to avoid overcrowding this issue.", "Hi, I would like to work on lines 38-42 on refactoring those tests", "@alextlucas hi, do you mind if I pick up on lines 38-48? ", "Hi all interested contributors (including those before), please note that the rows in the sheets have been modified to include missed files. As such, all rows claimed previously will not correspond to the test you've claimed. Going forward, it would be great if you (including future contributors) state and edit the first and last file names in the rows you want or have claimed. Thanks!", "Thank you for the update, I'd love to work on line 50-59 then.", "Hi! I would like to contribute from First file name to Last File Name.\nFirst file name :- GetFeedbackQuestionsActionTest.java\nLast File Name. :- GetInstructorsActionTest.java\nPlease Point me if anyone is working on that.\n" ],
      "repository" : {
        "description" : "This is the project website for the TEAMMATES feedback management tool for education",
        "homepage" : "https://teammatesv4.appspot.com/",
        "name" : "teammates",
        "fullName" : "TEAMMATES/teammates",
        "htmlUrl" : "https://github.com/TEAMMATES/teammates",
        "gitUrl" : "git://github.com/TEAMMATES/teammates.git",
        "sshUrl" : "git@github.com:TEAMMATES/teammates.git",
        "cloneUrl" : "https://github.com/TEAMMATES/teammates.git",
        "owner" : {
          "login" : "TEAMMATES",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3429,
        "stargazersCount" : 1727,
        "watchersCount" : 1727,
        "size" : 278101,
        "openIssuesCount" : 105,
        "subscribersCount" : 91,
        "pushedAt" : "2025-07-23T18:53:12Z",
        "languages" : {
          "TypeScript" : 2893972,
          "Java" : 8834136,
          "Dockerfile" : 594,
          "Shell" : 2197,
          "CSS" : 156,
          "SCSS" : 44489,
          "JavaScript" : 2798,
          "HTML" : 773783
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor the unit test access controls to use convenient test methods in `sqlui/webapi/BaseActionTest.java`. The author has already migrated most of the Unit Test migration in #12048, and now this issue aims to refactor the unit test access controls to use these convenient test methods.",
      "validationOrRequirement" : "The author has mentioned that all of the access control test methods in `BaseActionTest.java` have been migrated after merging #13254. The contributor should check that no one else has claimed the test cases to work on within the last 2 weeks, or that it has been completed by follow-up PRs.",
      "attemptedFixes" : "The author has attempted to refactor the unit test access controls to use convenient test methods. @arnav-goel05 has also tried to run the test files but encountered some issues with Intellij configurations. @InfinityTwo has helped @arnav-goel05 to resolve the issues and now the tests are running.",
      "otherNotes" : "This issue is for first-time contributors only. If you are new to TEAMMATES, feel free to submit a PR for this issue. We do not assign issues to contributors. If you would like to pick up this issue, do post a comment below to express your interest and check if there is anyone else who is already working on the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406609
  }, {
    "issueDTO" : {
      "id" : 3254822539,
      "title" : "Add tests for <Card> component",
      "url" : "https://github.com/OWASP/Nest/issues/1803",
      "repositoryName" : "OWASP/Nest",
      "description" : " Write unit tests for the `<Card>` React component to ensure expected behavior, edge case handling, and rendering logic.\n\n## Essential Test Coverage Checklist\n\n- [ ] **Renders successfully with minimal required props**  \n- [ ] **Conditional rendering logic**  \n- [ ] **Prop-based behavior** ??? different props affect output  \n- [ ] **Event handling** ??? simulate user actions and verify callbacks  \n- [ ] **State changes / internal logic**  \n- [ ] **Default values and fallbacks**  \n- [ ] **Text and content rendering**  \n- [ ] **Handles edge cases and invalid inputs**  \n- [ ] **Accessibility roles and labels**  \n- [ ] **DOM structure / classNames / styles**\n\n\n## Test Reference  \nYou can refer to the `AutoScrollToTop.test.tsx` file for an example of structure and best practices.  \nTo explore more examples, see the full component tests folder.\n",
      "updatedAt" : 1753391270.000000000,
      "user" : "kasya",
      "userHtmlUrl" : "https://github.com/kasya",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5873153?v=4",
      "labels" : [ "frontend-tests", "gssoc25", "enhancement", "good first issue", "level 3" ],
      "state" : "OPEN",
      "comments" : [ "I would like to work on it. Please assign it to me!", "> I would like to work on it. Please assign it to me!\n\nThis is `level 3` issue, I suggest starting from something like level 1 or level 2", "Hi @arkid15r  @kasya ! I'd like to work on this issue.\n\nI recently completed comprehensive unit tests for the ActionButton component (Level 1 - successfully merged) and ContributorAvatar component (issue #1806, Level 2 - under review). I'm familiar with the project's testing patterns, React Testing Library setup, and the existing codebase structure.\n\n**My approach for the Card component:**\n- Follow the same comprehensive testing methodology I used for ContributorAvatar\n- Cover all items from the Essential Test Coverage Checklist  \n- Use React Testing Library with proper mocking strategies\n- Focus on user-facing behavior and accessibility\n- Include edge cases and error handling\n- Ensure tests match the component's TypeScript interface\n\n**Experience with this project:**\n- ??? Successfully implemented tests following project conventions\n- ??? Familiar with the build system (`make check-test`, CSpell, etc.)\n- ??? Understanding of the component architecture and dependencies\n- ??? Previous work demonstrates thorough checklist coverage\n\nI can start working on this immediately and expect to deliver the same quality and comprehensiveness as my previous contributions.\n\nThanks for considering!" ],
      "repository" : {
        "description" : "Your gateway to OWASP. Discover, engage, and help shape the future!",
        "homepage" : "https://nest.owasp.org",
        "name" : "Nest",
        "fullName" : "OWASP/Nest",
        "htmlUrl" : "https://github.com/OWASP/Nest",
        "gitUrl" : "git://github.com/OWASP/Nest.git",
        "sshUrl" : "git@github.com:OWASP/Nest.git",
        "cloneUrl" : "https://github.com/OWASP/Nest.git",
        "owner" : {
          "login" : "OWASP",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 127,
        "stargazersCount" : 107,
        "watchersCount" : 107,
        "size" : 277308,
        "openIssuesCount" : 112,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T19:15:06Z",
        "languages" : {
          "TypeScript" : 604537,
          "Dockerfile" : 4478,
          "Jinja" : 19164,
          "CSS" : 6717,
          "Shell" : 161,
          "Makefile" : 12753,
          "JavaScript" : 6838,
          "HTML" : 222,
          "Python" : 1284784
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add comprehensive unit tests for the <Card> React component to ensure expected behavior, edge case handling, and rendering logic.",
      "validationOrRequirement" : "The Essential Test Coverage Checklist provides specific requirements to be covered, including renders successfully with minimal required props, conditional rendering logic, prop-based behavior, event handling, state changes, default values, text and content rendering, handles edge cases, accessibility roles and labels, and DOM structure/classNames/styles.",
      "attemptedFixes" : "The author has recently completed comprehensive unit tests for the ActionButton component and ContributorAvatar component, and is ready to start working on this issue immediately.",
      "otherNotes" : "The issue is about adding comprehensive unit tests for the <Card> React component, covering expected behavior, edge cases, rendering logic, and accessibility. The author suggests following the same methodology used for ContributorAvatar and covering all items from the Essential Test Coverage Checklist. The author has experience with the project and is familiar with testing patterns, React Testing Library setup, and the existing codebase structure.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406616
  }, {
    "issueDTO" : {
      "id" : 3257454011,
      "title" : "Move CollectionUtil to commons/utils & add test",
      "url" : "https://github.com/operaton/operaton/issues/1007",
      "repositoryName" : "operaton/operaton",
      "description" : "**What needs to be done?**\n\nClass `org.operaton.bpm.engine.impl.util.CollectionUtil` is part of the engine module, but is generic and not engine specific.\n\nThis class should be moved to `commons/utils/src/main/java/org/operaton/commons/utils`.\n\nAlong with this a unit test `CollectionUtilTest` should be added that demonstrates the usage of its methods. Note that the new test needs the License Header from the [contribution guide](https://github.com/operaton/operaton/blob/main/CONTRIBUTING.md).\n\nOptional: Ideally add Javadocs to the methods.\n\n**Contribution**\n\nIf you want to work on this task, just state it in a comment. You don't have to wait until the task is assigned to you.\nFirst come, first serve! Avoid starting work on this task when someone else has already claimed it. \n\nAre you a first-time contributor? We are happy to see you here! \nJust state in a comment of your PR \"I confirm that my contribution and following ones comply with the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0) \nand the [Code of Conduct](https://github.com/operaton/operaton/blob/main/CODE_OF_CONDUCT.md)\"\n\nContributors will be added to the release notes of the next release.\n",
      "updatedAt" : 1753391240.000000000,
      "user" : "kthoms",
      "userHtmlUrl" : "https://github.com/kthoms",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/265597?v=4",
      "labels" : [ "migration", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@kthoms I would like to take this task, please", "Thank you @ahmedfarhat , go ahead." ],
      "repository" : {
        "description" : "BPMN-Process automation for everyone ",
        "homepage" : "https://operaton.org",
        "name" : "operaton",
        "fullName" : "operaton/operaton",
        "htmlUrl" : "https://github.com/operaton/operaton",
        "gitUrl" : "git://github.com/operaton/operaton.git",
        "sshUrl" : "git@github.com:operaton/operaton.git",
        "cloneUrl" : "https://github.com/operaton/operaton.git",
        "owner" : {
          "login" : "operaton",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 45,
        "stargazersCount" : 183,
        "watchersCount" : 183,
        "size" : 167392,
        "openIssuesCount" : 76,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T23:59:52Z",
        "languages" : {
          "Java" : 45664616,
          "CSS" : 5680,
          "HTML" : 971074,
          "XSLT" : 680,
          "Groovy" : 26430,
          "FreeMarker" : 1474580,
          "Shell" : 29067,
          "Batchfile" : 10299,
          "JavaScript" : 3000836,
          "Less" : 159111,
          "SQLPL" : 44210,
          "Ruby" : 20579,
          "Python" : 20655
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Move CollectionUtil class from engine module to commons/utils and add a unit test demonstrating its methods",
      "validationOrRequirement" : "Move class to commons/utils, add unit test, add Javadocs (optional)",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Contribution guide link: https://github.com/operaton/operaton/blob/main/CONTRIBUTING.md, Code of Conduct link: https://github.com/operaton/operaton/blob/main/CODE_OF_CONDUCT.md",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406620
  }, {
    "issueDTO" : {
      "id" : 1981736166,
      "title" : "Default timeout for queries",
      "url" : "https://github.com/grafana/timestream-datasource/issues/257",
      "repositoryName" : "grafana/timestream-datasource",
      "description" : "### Discussed in https://github.com/grafana/timestream-datasource/discussions/232\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **guelfey** April 24, 2023</sup>\r\nHi, we're successfully using this data source to visualize some internal metrics to our developers. We want them to be able to freely explore the data and create their own dashboards as they find useful. At the same time, it's possible that someone accidentally runs a query where some filter is missing that then causes a large amount of data to be scanned, and specifically for Timestream this then directly translates to a large cost. One idea to limit this would be to have a default timeout in the DataSource for all queries to Timestream, similar to how it's already possible to configure this for the CloudWatch or Prometheus data sources. This way, it's possible to prevent queries from running too long in a central place. Does that sound reasonable? I'd be happy to provide a PR in this case.</div>",
      "updatedAt" : 1753391141.000000000,
      "user" : "sarahzinger",
      "userHtmlUrl" : "https://github.com/sarahzinger",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6620164?v=4",
      "labels" : [ "prio/low", "type/feature-request", "good first issue", "datasource/Timestream" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Amazon Timestream in Grafana",
        "homepage" : "https://grafana.com/grafana/plugins/grafana-timestream-datasource",
        "name" : "timestream-datasource",
        "fullName" : "grafana/timestream-datasource",
        "htmlUrl" : "https://github.com/grafana/timestream-datasource",
        "gitUrl" : "git://github.com/grafana/timestream-datasource.git",
        "sshUrl" : "git@github.com:grafana/timestream-datasource.git",
        "cloneUrl" : "https://github.com/grafana/timestream-datasource.git",
        "owner" : {
          "login" : "grafana",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 29,
        "watchersCount" : 29,
        "size" : 130267,
        "openIssuesCount" : 9,
        "subscribersCount" : 142,
        "pushedAt" : "2025-07-24T12:04:58Z",
        "languages" : {
          "TypeScript" : 78389,
          "Dockerfile" : 2467,
          "Shell" : 388,
          "JavaScript" : 5124,
          "Go" : 54239
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a default timeout for queries in the Timestream data source to prevent accidental long-running queries and limit costs",
      "validationOrRequirement" : "None mentioned",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Discussed in https://github.com/grafana/timestream-datasource/discussions/232, originally posted by guelfey on April 24, 2023",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406622
  }, {
    "issueDTO" : {
      "id" : 3257680522,
      "title" : "Enable foreach_map to assert if kernel is not fully fused",
      "url" : "https://github.com/pytorch/pytorch/issues/158968",
      "repositoryName" : "pytorch/pytorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nThese enhancements are to have a better UX when using foreach_map, suggested in a few places, but most recently, https://github.com/pytorch/pytorch/issues/158371#issuecomment-3088757068\n\nThese enhancements should allow easier compiler-first custom optimizer implementations. \n### Alternatives\n\n_No response_\n\n### Additional context\n\n_No response_\n\ncc @chauhang @penguinwu @voznesenskym @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @ipiszy @chenyang78 @kadeng @muchulee8 @amjames @aakhundov @coconutruben @Lucaskabela",
      "updatedAt" : 1753391090.000000000,
      "user" : "mlazos",
      "userHtmlUrl" : "https://github.com/mlazos",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4105940?v=4",
      "labels" : [ "triaged", "module: inductor", "feature", "oncall: pt2", "good first issue", "module: dynamo", "internal ramp-up task" ],
      "state" : "OPEN",
      "comments" : [ "I'd like to volunteer for this issue please. thank you! @mlazos ", "> I'd like to volunteer for this issue please. thank you! [@mlazos](https://github.com/mlazos)\n\nLooking forward to the PR, sounds good!" ],
      "repository" : {
        "description" : "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
        "homepage" : "https://pytorch.org",
        "name" : "pytorch",
        "fullName" : "pytorch/pytorch",
        "htmlUrl" : "https://github.com/pytorch/pytorch",
        "gitUrl" : "git://github.com/pytorch/pytorch.git",
        "sshUrl" : "git@github.com:pytorch/pytorch.git",
        "cloneUrl" : "https://github.com/pytorch/pytorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 24761,
        "stargazersCount" : 91742,
        "watchersCount" : 91742,
        "size" : 1083834,
        "openIssuesCount" : 16648,
        "subscribersCount" : 1786,
        "pushedAt" : "2025-07-25T00:47:06Z",
        "languages" : {
          "C" : 1827350,
          "GDB" : 653,
          "CMake" : 817716,
          "Makefile" : 12990,
          "HTML" : 384,
          "Metal" : 314357,
          "Jupyter Notebook" : 186191,
          "Shell" : 444379,
          "JavaScript" : 92859,
          "Objective-C" : 58643,
          "Assembly" : 336439,
          "Python" : 73135317,
          "GLSL" : 204578,
          "Thrift" : 7059,
          "PowerShell" : 7509,
          "Smarty" : 376,
          "Java" : 87332,
          "C++" : 42371695,
          "Objective-C++" : 1377512,
          "HIP" : 287193,
          "Cuda" : 3678398,
          "Dockerfile" : 33907,
          "Starlark" : 329858,
          "Batchfile" : 78530,
          "Linker Script" : 473,
          "Vim Script" : 154
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Enable foreach_map to assert if kernel is not fully fused, aiming to have a better UX when using foreach_map and allow easier compiler-first custom optimizer implementations",
      "validationOrRequirement" : "No specific requirements mentioned in the issue description or comments",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments",
      "otherNotes" : "cc @chauhang @penguinwu @voznesenskym @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @ipiszy @chenyang78 @kadeng @muchulee8 @amjames @aakhundov @coconutruben @Lucaskabela",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406628
  }, {
    "issueDTO" : {
      "id" : 3259502370,
      "title" : "[MCP] Hunter",
      "url" : "https://github.com/activepieces/activepieces/issues/8506",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview\n\nHunter helps you find, verify, and manage professional email addresses at scale.  \nThis integration enables AI agents and workflows to automate email discovery, validation, lead tracking, and campaign outreach.\n\n---\n\n## ?????? Important Note for Contributors\n\nThis feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions not following this format will not be accepted. Please review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before development.\n\n**Contributors based in India: please check your eligibility for receiving payments through your Stripe account before submitting, as this may affect your ability to get paid.**\n\n---\n\n## \uD83D\uDEA8 Triggers\n\n| **Trigger**                | **Use Case** |\n|---------------------------|--------------|\n| **New Lead**              | Fires when a new lead is created. |\n\n\n---\n\n## \uD83D\uDEE0??? Write Actions\n\n| **Action Item**              | **Use Case** |\n|------------------------------|--------------|\n| **Add Recipients**           | Add one or multiple recipients to a campaign.|\n| **Count Emails**             | Returns the number of email addresses found for a domain or company. Useful before running full searches.|\n| **Create a Lead**            | Create and store a lead record.  |\n| **Delete a Lead**            | Delete a specific lead record by ID.  |\n| **Find an Email**            | Retrieve/propose the most likely email for a person at a domain.  |\n| **Get a Lead**               | Retrieve details of a specific lead.|\n| **Update a Lead**            | Modify existing lead data.} |\n| **Verify an Email**          | Check email deliverability and validation status. |\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Action Item**              | **Use Case** |\n|------------------------------|--------------|\n| **Search Leads**             | List and filter leads in the account.|\n\n---\n\n## \uD83D\uDCDA API Reference\n\n- [Official Hunter API documentation](https://hunter.io/api-documentation/v2#enrichment)\n\n---\n\n## \uD83E\uDDEA Test Account Access\n\nSign up at [Hunter](https://hunter.io/) to get your API key (Required for integration).\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
      "updatedAt" : 1753390947.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "$100", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-852/mcp-hunter\">AP-852 [MCP] Hunter</a></p>", "/bounty $100", "## \uD83D\uDC8E $100 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8506` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8506` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @Pranjal6955 | Jul 24, 2025, 11:43:39 AM | WIP |  |\n| \uD83D\uDFE2 @varshith257 | Jul 24, 2025, 12:18:28 PM | #8514 | [Reward](https://algora.io/claims/Gme7NNyt2v3Yw8Nu) |\n| \uD83D\uDFE2 @aryel780 | Jul 24, 2025, 12:59:25 PM | #8508 | [Reward](https://algora.io/claims/c533egJEHF8zxGw6) |\n| \uD83D\uDFE2 @sparkybug | Jul 24, 2025, 01:39:05 PM | #8516 | [Reward](https://algora.io/claims/us2Q9bhemRukQQaw) |", "/attempt #8506", "/attempt #8506", "/attempt #8506" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2245,
        "stargazersCount" : 15953,
        "watchersCount" : 15953,
        "size" : 303244,
        "openIssuesCount" : 395,
        "subscribersCount" : 99,
        "pushedAt" : "2025-07-24T23:50:49Z",
        "languages" : {
          "TypeScript" : 14822092,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 72085,
          "Shell" : 3862,
          "JavaScript" : 14477,
          "HTML" : 212991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to integrate Hunter with Activepieces, enabling AI agents and workflows to automate email discovery, validation, lead tracking, and campaign outreach.",
      "validationOrRequirement" : "The feature must be submitted as a Piece following the Activepieces architecture, and the contributor must provide a short demo video of their changes in their pull request.",
      "attemptedFixes" : "Several attempts have been made by @Pranjal6955, @varshith257, @aryel780, and @sparkybug, with @varshith257, @aryel780, and @sparkybug having received rewards for their work.",
      "otherNotes" : "This issue is related to the integration of Hunter with Activepieces, enabling AI agents and workflows to automate email discovery, validation, lead tracking, and campaign outreach. The issue requires the submission of a Piece following the Activepieces architecture, and contributors based in India need to check their eligibility for receiving payments through their Stripe account.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406634
  }, {
    "issueDTO" : {
      "id" : 3167302559,
      "title" : "Provide Windows-Specific Setup Instructions",
      "url" : "https://github.com/WellApp-ai/Well/issues/20",
      "repositoryName" : "WellApp-ai/Well",
      "description" : "Expand `ai-invoice-extractor/README.md` or `CONTRIBUTING.md` to include Windows-specific setup instructions, troubleshooting, and shell environment recommendations.\n",
      "updatedAt" : 1753390819.000000000,
      "user" : "maxchampoux",
      "userHtmlUrl" : "https://github.com/maxchampoux",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11485623?v=4",
      "labels" : [ "onlydust-wave", "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I have a good technical writing skill and good READ,me documentation to address this issue", "Amazing! \uD83D\uDE4F" ],
      "repository" : {
        "description" : "At Well, we believe that founders should spend their time building, not buried in admin.  We???re building the AI-powered infrastructure that automates receipts and supplier invoices retrieval, processing and orchestration to your preferred FinOps Tool ??? designed for solopreneurs, indie hackers, and lean startup teams.  ",
        "homepage" : "https://wellapp.ai/",
        "name" : "Well",
        "fullName" : "WellApp-ai/Well",
        "htmlUrl" : "https://github.com/WellApp-ai/Well",
        "gitUrl" : "git://github.com/WellApp-ai/Well.git",
        "sshUrl" : "git@github.com:WellApp-ai/Well.git",
        "cloneUrl" : "https://github.com/WellApp-ai/Well.git",
        "owner" : {
          "login" : "WellApp-ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 21,
        "stargazersCount" : 201,
        "watchersCount" : 201,
        "size" : 4342,
        "openIssuesCount" : 17,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-24T09:16:08Z",
        "languages" : {
          "TypeScript" : 30400,
          "Shell" : 335,
          "Batchfile" : 332,
          "JavaScript" : 5205,
          "Python" : 25317
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Provide Windows-Specific Setup Instructions for the WellApp-ai/Well repository",
      "validationOrRequirement" : "Good technical writing skill and good READ,me documentation are required to address this issue.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about expanding the README.md or CONTRIBUTING.md file to include Windows-specific setup instructions, troubleshooting, and shell environment recommendations.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406637
  }, {
    "issueDTO" : {
      "id" : 3167301913,
      "title" : "Consider Adding .env.example File",
      "url" : "https://github.com/WellApp-ai/Well/issues/18",
      "repositoryName" : "WellApp-ai/Well",
      "description" : "To help users configure environment variables, provide a template `.env.example` file listing all required or optional variables in `ai-invoice-extractor/`.\n",
      "updatedAt" : 1753390818.000000000,
      "user" : "maxchampoux",
      "userHtmlUrl" : "https://github.com/maxchampoux",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11485623?v=4",
      "labels" : [ "onlydust-wave", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey man!\nOf course we are looking for support and contributors. Let me\nKnow how I can support you or if you want a chat to see how to work together", "Hi, I'm Superior!\nI'm an experienced frontend developer with a strong background in React/Next.js and TypeScript, plus deep Web3 experience in Solidity, Cairo and Rust through my work with Web3Bridge. Having contributed to projects like CoinSafe and Scaffold-ETH, I'm confident I can jump right in and tackle this issue. My approach is straightforward: I'll start by diving into the codebase to understand the core problem, then implement a clean and thoroughly tested solution. I'll communicate proactively if any questions come up and will submit a well-documented PR for your review. \nLooking forward to contributing!" ],
      "repository" : {
        "description" : "At Well, we believe that founders should spend their time building, not buried in admin.  We???re building the AI-powered infrastructure that automates receipts and supplier invoices retrieval, processing and orchestration to your preferred FinOps Tool ??? designed for solopreneurs, indie hackers, and lean startup teams.  ",
        "homepage" : "https://wellapp.ai/",
        "name" : "Well",
        "fullName" : "WellApp-ai/Well",
        "htmlUrl" : "https://github.com/WellApp-ai/Well",
        "gitUrl" : "git://github.com/WellApp-ai/Well.git",
        "sshUrl" : "git@github.com:WellApp-ai/Well.git",
        "cloneUrl" : "https://github.com/WellApp-ai/Well.git",
        "owner" : {
          "login" : "WellApp-ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 21,
        "stargazersCount" : 201,
        "watchersCount" : 201,
        "size" : 4342,
        "openIssuesCount" : 17,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-24T09:16:08Z",
        "languages" : {
          "TypeScript" : 30400,
          "Shell" : 335,
          "Batchfile" : 332,
          "JavaScript" : 5205,
          "Python" : 25317
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Consider adding a .env.example file to help users configure environment variables",
      "validationOrRequirement" : "The requirement is to provide a template .env.example file listing all required or optional variables in ai-invoice-extractor/",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments.",
      "otherNotes" : "The issue is about adding a template .env.example file to help users configure environment variables in the ai-invoice-extractor/ directory. The contributor is experienced in React/Next.js, TypeScript, and Web3 technologies and is willing to jump in and tackle the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406641
  }, {
    "issueDTO" : {
      "id" : 3256928358,
      "title" : "[MCP] Teamleader",
      "url" : "https://github.com/activepieces/activepieces/issues/8489",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview\n\nTeamleader is an all-in-one CRM, project management, quote/invoice, and time-tracking platform designed for SMEs.  \nThis integration allows AI agents and workflows to manage contacts, companies, deals, invoices, tasks, time entries, and more.\n\n---\n\n## ?????? Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n**Contributors based in India: please check your eligibility for receiving payments through your Stripe account before submitting, as this may affect your ability to get paid.**\n\n\n---\n\n## \uD83D\uDEA8 Triggers\n\n| **Trigger**               | **Use Case**                                                                 |\n|---------------------------|------------------------------------------------------------------------------|\n| **New Contact**           | Fires when a new contact is created.                                         |\n| **New Company**           | Fires when a new company is added.                                           |\n| **New Deal**              | Fires when a new deal is created.                                            |\n| **Deal Accepted**         | Fires when a deal is accepted/won.                                           |\n| **New Invoice (Paid)** | Fires when an invoice is booked, sent, or paid.                     |\n\n---\n\n## \uD83D\uDEE0??? Write Actions\n\n| **Action Item**                     | **Use Case** |\n|-------------------------------------|--------------|\n| **Create Contact**                 | Create a new contact record. |\n| **Update Contact**                 | Modify existing contact data. |\n| **Create Company**                 | Add a new company record. |\n| **Update Company**                 | Modify company information. |\n| **Link Contact to Company**        | Associate a contact with a company. |\n| **Unlink Contact from Company**    | Remove the association between contact and company. |\n| **Create Deal**                    | Create a new deal/opportunity. |\n| **Update Deal**                    | Modify deal properties. |\n\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Action Item**        | **Use Case** |\n|-------------------------|--------------|\n| **Search Companies**    | List or filter companies. |\n| **Search Contacts**     | List or filter contacts. |\n| **Search Deals**        | List or filter deals. |\n| **Search Invoices**     | List/filter invoices. |\n\n---\n\n## \uD83D\uDCDA API Reference\n\n- [Teamleader API Documentation](https://developer.focus.teamleader.eu/docs/api/invoices-list)\n\n---\n\n## \uD83E\uDDEA Test Account Access\n\nYou can test Teamleader by signing up at [Teamleader Focus](https://signup.teamleader.eu/) and creating API credentials using OAuth2. \n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
      "updatedAt" : 1753390803.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "$100", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-848/mcp-teamleader\">AP-848 [MCP] Teamleader</a></p>", "/bounty $100", "## \uD83D\uDC8E $100 bounty [??? Penclone109](https://algora.io/Penclone109)\n## \uD83D\uDC8E $100 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8489` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8489` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @Pranjal6955 | Jul 23, 2025, 04:08:24 PM | #8492 | [Reward](https://algora.io/claims/ho9mzA63ERwg31dw) |\n| \uD83D\uDFE2 @Sanket6652 | Jul 23, 2025, 04:56:58 PM | #8491 | [Reward](https://algora.io/claims/2yR8Mb5iD3nbKbzR) |\n| \uD83D\uDFE2 @fortunamide | Jul 24, 2025, 09:00:02 PM | WIP |  |", "/attempt #8489", "/attempt #8489" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2245,
        "stargazersCount" : 15953,
        "watchersCount" : 15953,
        "size" : 303244,
        "openIssuesCount" : 395,
        "subscribersCount" : 99,
        "pushedAt" : "2025-07-24T23:50:49Z",
        "languages" : {
          "TypeScript" : 14822092,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 72085,
          "Shell" : 3862,
          "JavaScript" : 14477,
          "HTML" : 212991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement the Teamleader integration, allowing AI agents and workflows to manage contacts, companies, deals, invoices, tasks, and time entries.",
      "validationOrRequirement" : "The feature must be submitted as a Piece following the Activepieces architecture, and the contributor must review the Piece Development Guidelines before starting development.",
      "attemptedFixes" : "Pranjal6955 and Sanket6652 have already attempted to solve this issue, but the outcome is not specified.",
      "otherNotes" : "Contributors must submit the feature as a Piece following the Activepieces architecture, and review the Piece Development Guidelines before starting development. Contributors based in India must check their eligibility for receiving payments through Stripe.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406646
  }, {
    "issueDTO" : {
      "id" : 2887599653,
      "title" : "Refont of confirmation page when you enable subscription - Final Review",
      "url" : "https://github.com/lfglabs-dev/app.starknet.id/issues/1115",
      "repositoryName" : "lfglabs-dev/app.starknet.id",
      "description" : "## Description \uD83D\uDCF9\n\n- [x] https://github.com/lfglabs-dev/app.starknet.id/issues/1110\n- [x] https://github.com/lfglabs-dev/app.starknet.id/issues/1111\n- [x] https://github.com/lfglabs-dev/app.starknet.id/issues/1112\n- [x] https://github.com/lfglabs-dev/app.starknet.id/issues/1113\n- [x] https://github.com/lfglabs-dev/app.starknet.id/issues/1114\n\n**Today, we have a popup that appears to confirm the activation of the subscription. We can replace this popup with a full page that we already use as confirmation.**\n\n**Your task will be to check that all the issues have been correctly developed, that the components are properly arranged, and that everything matches exactly as in the Figma design:**\n\nhttps://www.figma.com/design/S1UKYgWewNqNHZFAaBUilG/%F0%9F%8F%9D%EF%B8%8F-Starknet-ID?node-id=7022-31922&t=XCt8XQUo4vZRtmIv-1\n\n### Purpose of the Issue\nThe goal of this issue is to finalize the redesign of the confirmation page that appears after activating a subscription on the Starknet ID platform. The current popup will be replaced with a full confirmation page, ensuring all components are properly developed and aligned with the Figma design.\n\n- **Alignment with Figma Design**:\n  - Check that all components are correctly arranged and match exactly as shown in the Figma file linked in the issue description.\n\n### Actions to Take\n1. **Review Sub-Issues**:\n   - Verify that each sub-issue (#1110???#1114) has been implemented according to specifications.\n   \n2. **Testing**:\n   - Test all functionalities locally, including navigation, button redirects, and visual alignment.\n   \n3. **Final Adjustments**:\n   - Ensure consistency across all elements (images, text, buttons) and fix any discrepancies between the implementation and the Figma design.\n\n4. **Commit and Submit**:\n   - Create a final commit summarizing changes (e.g., `git commit -m \"Final review: confirmation page redesign\"`).\n   - Submit a pull request for review and approval.\n\n### Constraints\n- All components must strictly follow the Figma design.\n- Testing should cover both functionality and visual accuracy.\n- This issue serves as a final review, so attention to detail is critical.\n\n\n## Proposed Actions \uD83D\uDEE0???\n\nHere???s a checklist of actions to follow for resolving this issue:\n\n1. **Fork and Create Branch**:  \n   Fork the repository and create a new branch using the issue number:\n   ```bash\n   git checkout -b fix-[issue-number]\n   ```\n\n2. **Implement Changes**:  \n\t[Insert Code snippet if needed with a mardown todo list]\n\n3. **Run Tests and Commit Changes**:  \n   Make sure your changes don't break existing functionality and commit with a clear message:\n   ```bash\n   git commit -m \"Fix: [Short description of the fix]\"\n   ```\n\n## Required \uD83D\uDCCB\n\nTo keep our workflow smooth, please make sure you follow these guidelines:\n\n- **Assignment**: Don't create a pull request if you weren???t assigned to this issue.\n- **Timeframe**: Complete the task within **3 business days**.\n- **Closing the Issue**: In your PR description, close the issue by writing `Close #[issue_id]`.\n- **Review Process**:\n  - Once you've submitted your PR, change the label to **\"ready for review\"**.\n  - If changes are requested, address them and then update the label back to **\"ready for review\"** once done.\n- **Testing**: Test your PR locally before pushing, and verify that tests and build are working after pushing.\n\nThank you for your contribution \uD83D\uDE4F\n\n?????? WARNING: Failure to follow the requirements above may result in being added to the OnlyDust blacklist, affecting your ability to receive future rewards.\n",
      "updatedAt" : 1753390731.000000000,
      "user" : "Kevils",
      "userHtmlUrl" : "https://github.com/Kevils",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/144677881?v=4",
      "labels" : [ "Open for contribution", "onlydust-wave", "Good first issue" ],
      "state" : "OPEN",
      "comments" : [ "May I take this issue and try to solve?I already have experience with this project.", "Hello, I am a software engineer with great expertise in react , next js, tailwindcss and backend technologies like express js etc.Please can i be assigned this task?", "My Background\nI have three years of experience developing web applications, specializing in Angular, React, TypeScript, and UX/UI design. I am passionate about building high-quality, user-friendly interfaces that align with modern design principles.\n\nApproach to the Issue\nI will carefully review and address every issue in this review. Currently, a popup appears to confirm the activation of the subscription. I propose replacing it with a full-page confirmation that is already in use, ensuring a more consistent user experience.", "Hello @Kevils, \nI can get this done.\n", "I can handle this ", "Would love to do this!", "`Enable Subscription` on `subscription` page is not working anymore. Currently fixing, so I can PR.", "As a recent OD fellow, I would love to contribute to this feature.", "Hi Starknet ID Team,\n\nI'd like to apply for the final review task of the subscription confirmation page redesign. With strong attention to detail and experience in Figma-to-code validation, component inspection, and UX testing, I???m confident I can ensure pixel-perfect alignment with the Figma design and verify all sub-issues (#1110???#1114) as required.\n\nIf assigned, I will:\n\nReview and validate each sub-issue implementation against the Figma spec\n\nTest component behavior, layout, navigation, and button redirects locally\n\nIdentify and fix any discrepancies in spacing, alignment, or content\n\nSubmit a final commit and PR titled clearly (e.g., Final review: confirmation page redesign)\n\nFollow all workflow requirements, including label updates, timeframe, and PR guidelines\n\nLooking forward to ensuring the page meets production quality.", "Ser @Marchand-Nicolas, I have a PR up for this. \nKindly review it and reassign, please. " ],
      "repository" : {
        "description" : "Identity Service for Starknet",
        "homepage" : "https://app.starknet.id/",
        "name" : "app.starknet.id",
        "fullName" : "lfglabs-dev/app.starknet.id",
        "htmlUrl" : "https://github.com/lfglabs-dev/app.starknet.id",
        "gitUrl" : "git://github.com/lfglabs-dev/app.starknet.id.git",
        "sshUrl" : "git@github.com:lfglabs-dev/app.starknet.id.git",
        "cloneUrl" : "https://github.com/lfglabs-dev/app.starknet.id.git",
        "owner" : {
          "login" : "lfglabs-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 141,
        "stargazersCount" : 59,
        "watchersCount" : 59,
        "size" : 31797,
        "openIssuesCount" : 32,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-09T12:52:13Z",
        "languages" : {
          "TypeScript" : 680963,
          "CSS" : 102465,
          "JavaScript" : 80859,
          "HTML" : 1939,
          "PureBasic" : 5425
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The goal of this issue is to finalize the redesign of the confirmation page that appears after activating a subscription on the Starknet ID platform, replacing the current popup with a full confirmation page.",
      "validationOrRequirement" : "All components must strictly follow the Figma design, testing should cover both functionality and visual accuracy, and attention to detail is critical.",
      "attemptedFixes" : "Some users have attempted to fix this issue by implementing changes in the code and testing them locally, but the issue remains open for final review.",
      "otherNotes" : "The issue is about replacing a popup with a full-page confirmation for subscription activation, ensuring all components are properly arranged and match the Figma design.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406650
  }, {
    "issueDTO" : {
      "id" : 3254832356,
      "title" : "Add tests for <ContributorAvatar> component",
      "url" : "https://github.com/OWASP/Nest/issues/1806",
      "repositoryName" : "OWASP/Nest",
      "description" : "Write unit tests for the `<ContributorAvatar>` React component to ensure expected behavior, edge case handling, and rendering logic.\n\n## Essential Test Coverage Checklist\n\n- [ ] **Renders successfully with minimal required props**  \n- [ ] **Conditional rendering logic**  \n- [ ] **Prop-based behavior** ??? different props affect output  \n- [ ] **Event handling** ??? simulate user actions and verify callbacks  \n- [ ] **State changes / internal logic**  \n- [ ] **Default values and fallbacks**  \n- [ ] **Text and content rendering**  \n- [ ] **Handles edge cases and invalid inputs**  \n- [ ] **Accessibility roles and labels**  \n- [ ] **DOM structure / classNames / styles**\n\n\n## Test Reference  \nYou can refer to the `AutoScrollToTop.test.tsx` file for an example of structure and best practices.  \nTo explore more examples, see the full component tests folder.\n",
      "updatedAt" : 1753390680.000000000,
      "user" : "kasya",
      "userHtmlUrl" : "https://github.com/kasya",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5873153?v=4",
      "labels" : [ "frontend-tests", "gssoc25", "enhancement", "good first issue", "level 2" ],
      "state" : "OPEN",
      "comments" : [ "Hi @kasya  @arkid15r ! \n\nI'd like to work on writing comprehensive unit tests for the `<ContributorAvatar>` component.\n\nMy Approach:\n\nI'll start by analyzing the ContributorAvatar component to understand its props, conditional rendering logic, and behavior patterns. Then I'll systematically work through the provided checklist, creating tests for basic rendering, prop variations, event handling, edge cases, and accessibility compliance. I'll follow the established testing patterns from `AutoScrollToTop.test.tsx` and other component tests in the project to ensure consistency with your testing standards.\n\n**Background:** I recently completed comprehensive unit tests for the ActionButton component (PR pending review) where I successfully covered all checklist items including conditional rendering, prop-based behavior, event handling, edge cases, and accessibility testing. I'm familiar with the project's testing setup, mocking strategies, and code quality requirements.\n\nI'm confident I can deliver thorough, well-structured tests that provide meaningful coverage and follow the project's established patterns. Would you be willing to assign this issue to me?\n\nThanks!", "Hi @kasya ,\n\nI've completed the ContributorAvatar unit tests with full checklist coverage:\n\n??? All 10 Essential Test Coverage items implemented\n??? 15 comprehensive test cases covering rendering, behavior, accessibility, and edge cases\n??? Proper mocking of external dependencies\n??? Tests pass locally and follow existing project patterns\n\nThe test suite covers component rendering, conditional logic, tooltip generation, accessibility features, and various edge cases. Ready for review.\n\nThanks,\nRizwaan | GSSoC Contributor" ],
      "repository" : {
        "description" : "Your gateway to OWASP. Discover, engage, and help shape the future!",
        "homepage" : "https://nest.owasp.org",
        "name" : "Nest",
        "fullName" : "OWASP/Nest",
        "htmlUrl" : "https://github.com/OWASP/Nest",
        "gitUrl" : "git://github.com/OWASP/Nest.git",
        "sshUrl" : "git@github.com:OWASP/Nest.git",
        "cloneUrl" : "https://github.com/OWASP/Nest.git",
        "owner" : {
          "login" : "OWASP",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 127,
        "stargazersCount" : 107,
        "watchersCount" : 107,
        "size" : 277308,
        "openIssuesCount" : 112,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T19:15:06Z",
        "languages" : {
          "TypeScript" : 604537,
          "Dockerfile" : 4478,
          "Jinja" : 19164,
          "CSS" : 6717,
          "Shell" : 161,
          "Makefile" : 12753,
          "JavaScript" : 6838,
          "HTML" : 222,
          "Python" : 1284784
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add tests for the <ContributorAvatar> component to ensure expected behavior, edge case handling, and rendering logic.",
      "validationOrRequirement" : "Write unit tests for the <ContributorAvatar> React component to ensure expected behavior, edge case handling, and rendering logic, following the established testing patterns from `AutoScrollToTop.test.tsx` and other component tests in the project.",
      "attemptedFixes" : "The contributor has already completed the unit tests for the <ContributorAvatar> component, covering all 10 essential test coverage items, with 15 comprehensive test cases, proper mocking of external dependencies, and the tests pass locally and follow existing project patterns.",
      "otherNotes" : "The author has recently completed comprehensive unit tests for the ActionButton component and is familiar with the project's testing setup, mocking strategies, and code quality requirements.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406656
  }, {
    "issueDTO" : {
      "id" : 2801381355,
      "title" : "FeatureHasher and HashingVectorizer does not expose requires_fit=False tag",
      "url" : "https://github.com/scikit-learn/scikit-learn/issues/30689",
      "repositoryName" : "scikit-learn/scikit-learn",
      "description" : "While `FeatureHasher` and `HashingVectorizer` are stateless estimator (at least in their docstrings), they do not expose the `requires_fit` tag to `False` as other stateless estimator.\n\n@adrinjalali Do you recall when changing the tags if there was a particular reason for those estimator to not behave the same way than others?",
      "updatedAt" : 1753390421.000000000,
      "user" : "glemaitre",
      "userHtmlUrl" : "https://github.com/glemaitre",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7454015?v=4",
      "labels" : [ "help wanted", "Enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "My PR didn't change a tag in that regard: \n\nhttps://github.com/scikit-learn/scikit-learn/pull/29677/files#diff-2ce614636a32fc7ddace8d5f36e320e0b348012dff967ad17c7fed8ea40b5723R196\n\nNote that `requires_fit` is tricky if the estimator does input / feature name / feature count validation.", "/take", "@glemaitre what condition would be require to set `requires_fit` tag to be False or is that the default behaviour?", "_Hi! I'm interested in working on this issue as my first contribution._\n\nI **understand that `FeatureHasher` and `HashingVectorizer` are stateless estimators and should have the `requires_fit = False` tag set, just like other stateless estimators.**\n\nI'd love to help fix this. Could you please **assign** this issue to me?\n\nThanks! \n", "/take", "We don't assign issues to anybody, and we also don't have a `/take` bot anymore. If you think you can handle the issue, please write how you think you can solve it, and then open a pull request.", "@adrinjalali Thank you for the clarification. I was reading through the online web documentation so I thought it was still in place. I mainly am new to open-source and want to find a way to contribute. \n\nDo you think it would be worth while if I opened an issue to update the online documentation to reflect that a bot is no longer used (Unless it states this that I didnt see)? ", "Hi, I'd like to work on this issue.\n\nMy plan is to:\n- Override the _get_tags() method in both FeatureHasher and HashingVectorizer to explicitly return \"requires_fit\": False.\n- This will ensure the tag correctly reflects their stateless behavior, as neither class requires fitting before transforming.\n- I'll also add unit tests to verify that this tag is correctly set.\n\nI'll submit a PR shortly. Let me know if you have any suggestions or concerns. Thanks!" ],
      "repository" : {
        "description" : "scikit-learn: machine learning in Python",
        "homepage" : "https://scikit-learn.org",
        "name" : "scikit-learn",
        "fullName" : "scikit-learn/scikit-learn",
        "htmlUrl" : "https://github.com/scikit-learn/scikit-learn",
        "gitUrl" : "git://github.com/scikit-learn/scikit-learn.git",
        "sshUrl" : "git@github.com:scikit-learn/scikit-learn.git",
        "cloneUrl" : "https://github.com/scikit-learn/scikit-learn.git",
        "owner" : {
          "login" : "scikit-learn",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 26079,
        "stargazersCount" : 62762,
        "watchersCount" : 62762,
        "size" : 173737,
        "openIssuesCount" : 2185,
        "subscribersCount" : 2137,
        "pushedAt" : "2025-07-24T10:36:54Z",
        "languages" : {
          "C++" : 147428,
          "Shell" : 46980,
          "CSS" : 13133,
          "C" : 41895,
          "Meson" : 32297,
          "Makefile" : 1034,
          "JavaScript" : 1730,
          "Cython" : 728806,
          "Python" : 12556187
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "FeatureHasher and HashingVectorizer should expose the 'requires_fit' tag as False to reflect their stateless behavior.",
      "validationOrRequirement" : "The requirements are to make FeatureHasher and HashingVectorizer consistent with other stateless estimators by exposing the 'requires_fit' tag as False.",
      "attemptedFixes" : "A PR will be submitted to override the _get_tags() method in both FeatureHasher and HashingVectorizer to explicitly return 'requires_fit': False, and add unit tests to verify the tag is correctly set.",
      "otherNotes" : "The issue is about FeatureHasher and HashingVectorizer not exposing the requires_fit=False tag, which is a deviation from other stateless estimators. The goal is to make them consistent.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406661
  }, {
    "issueDTO" : {
      "id" : 3100327223,
      "title" : "[documentation] README \"how to install\" instructions seem incomplete",
      "url" : "https://github.com/INGInious/INGInious/issues/1050",
      "repositoryName" : "INGInious/INGInious",
      "description" : "**Describe the bug**\n\nThe \"How to install?\" instructions in the README imply that invoking `docker compose up` and copying in a course under the `tasks` directory is enough to get a minimal working system. But I don't think that's correct ??? a user needs to pull at least one suitable \"environment\" image.\n\n**To Reproduce**\n\nSteps to reproduce the behavior:\n\n1. Clone the repo, and read the README, which advises running\n\n \n \n https://github.com/INGInious/INGInious/blob/ad7ab7214eff7094c39d6c445b24786f090221df/README.rst?plain=1#L37\n\n\n\n3. Create or clone a course - e.g. clone <https://github.com/INGInious/demo-tasks.git> and then `cp -a demo-tasks/tutorial tasks/`.\n4. Select any task (e.g. '1. Getting started' from the tutorial)\n5. Click \"Edit task\" on the left sidebar, then the \"Environment tab\"\n6. Try to select a \"Grading environment\"\n\n**Expected behavior**\n\nFollowing the README should result in an instance with at least one grading environment.\n\n**Actual behavior**\n\nNo grading environments are available. So any attempt to submit an answer to any task will result in a 'Environment not available' error.\n\n**Desktop (please complete the following information):**\n\nN/A\n\n**Additional context**\n\nI assume the README should advise users to, at a minimum, run\n\n```\ndocker pull ghcr.io/inginious/env-default\n```\n\nAnd maybe other environments (e.g. env-python3?) - not yet having got through it, I'm not sure what the tutorial requires.\n\n\n",
      "updatedAt" : 1753390333.000000000,
      "user" : "phlummox",
      "userHtmlUrl" : "https://github.com/phlummox",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18113700?v=4",
      "labels" : [ "Good First Issue", "Documentation" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for the report. I would rather extend the `docker-compose.yml` file to build locally the [default grading environment](https://github.com/INGInious/INGInious/tree/main/base-containers/default) so that the project deployment from sources is self-contained." ],
      "repository" : {
        "description" : "INGInious is a secure and automated exercises assessment platform using your own tests, also providing a pluggable interface with your existing LMS.",
        "homepage" : "http://www.inginious.org",
        "name" : "INGInious",
        "fullName" : "INGInious/INGInious",
        "htmlUrl" : "https://github.com/INGInious/INGInious",
        "gitUrl" : "git://github.com/INGInious/INGInious.git",
        "sshUrl" : "git@github.com:INGInious/INGInious.git",
        "cloneUrl" : "https://github.com/INGInious/INGInious.git",
        "owner" : {
          "login" : "INGInious",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 143,
        "stargazersCount" : 223,
        "watchersCount" : 223,
        "size" : 45271,
        "openIssuesCount" : 156,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-24T21:18:28Z",
        "languages" : {
          "Dockerfile" : 4928,
          "CSS" : 50599,
          "Shell" : 82,
          "JavaScript" : 104266,
          "HTML" : 402038,
          "Less" : 13199,
          "Python" : 1044324
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The 'How to install?' instructions in the README seem incomplete and do not provide a correct way to get a minimal working system.",
      "validationOrRequirement" : "Following the README should result in an instance with at least one grading environment.",
      "attemptedFixes" : "The README should advise users to, at a minimum, run `docker pull ghcr.io/inginious/env-default` and maybe other environments (e.g. env-python3?) - not yet having got through it, I'm not sure what the tutorial requires.",
      "otherNotes" : "The README implies that invoking `docker compose up` and copying in a course under the `tasks` directory is enough to get a minimal working system, but this is not correct and users need to pull at least one suitable 'environment' image.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406666
  }, {
    "issueDTO" : {
      "id" : 3261216582,
      "title" : "\uD83D\uDCA1make the sidebar scroll separateley so you can watch the vid while scrolling on the side",
      "url" : "https://github.com/code-charity/youtube/issues/3057",
      "repositoryName" : "code-charity/youtube",
      "description" : "<!--\n(Click PREVIEW to undestand this template) \n               OPTIONALLY fill the table if each point fits in the same line: \n-->\n\n??? _PROBLEM_: \n<!-- (Does your IDEA / feature request relate to a Problem? Which problem is? \n           Ex. I'm always frustrated when [...] )-->\n\n??? _SOLUTION_:    \n<!-- (Describe what you'd like \n          (A clear and concise description of what you want to happen). \n           Please consider screenshots or sketches if it makes sense)-->\n\n ??? _ALTERNATIVES_: \n<!-- (Describe what you've considered: \n      Alternative solutions or features, you'd consider as equal or inferior). -->\n\n ??? _RELEVANCE / SCOPE_: \n<!-- (Would this be good by for everybody by default? (hypothetically). \n          Estimate how many percent of our users (or all youtube users) should/would use your idea? ) -->\n\n??? _\"SIDE EFFECTS\"_:   \n<!-- (Is there any conflict with any other feature? \n           Who might NOT want this?(How many percent of users could be bothered by it even filling space in our menu?)--> \n\n??? _CONTEXT_:       <!-- any other context. -->\n// \n Thank  you!\n\nSHORT Table | (Summary)     \n------------ | -------------   \n*Problem*     |              cant see vid while scrolling the side bar                     \n*Solution*     |              make the sidebar scroll separateley                                              <!-- TYPE HERE, 1 line each) -->         \n*Alternatives*|        make the video auto pip when scrolling \n*Scope*         |           everyone\n*Side effects*|        maybe they don't want to I guess idk\n*Context*      |        this issue has been annoying me and if anyone can fix it it's probably u guys\n",
      "updatedAt" : 1753390317.000000000,
      "user" : "Ariyan0813",
      "userHtmlUrl" : "https://github.com/Ariyan0813",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/82626362?v=4",
      "labels" : [ "Feature request", "help wanted", "good first issue", "up-for-grabs" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Open YouTube & Video browser-extension [top~1] Enrich your experience&choice!\uD83E\uDDF0200+options; clever features\uD83D\uDCCCset&forget\uD83D\uDCCCLongest-standing. Join\uD83E\uDDE9us?\uD83D\uDC68???\uD83D\uDC69???\uD83D\uDC67???\uD83D\uDC67  ??? {playback|content discovery|player|extra buttons|distractions|related videos|shorts|ads|quality|codec|full tab|full screen}",
        "homepage" : "http://improvedtube.com",
        "name" : "youtube",
        "fullName" : "code-charity/youtube",
        "htmlUrl" : "https://github.com/code-charity/youtube",
        "gitUrl" : "git://github.com/code-charity/youtube.git",
        "sshUrl" : "git@github.com:code-charity/youtube.git",
        "cloneUrl" : "https://github.com/code-charity/youtube.git",
        "owner" : {
          "login" : "code-charity",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 657,
        "stargazersCount" : 3848,
        "watchersCount" : 3848,
        "size" : 11907,
        "openIssuesCount" : 928,
        "subscribersCount" : 274,
        "pushedAt" : "2025-07-19T15:33:09Z",
        "languages" : {
          "CSS" : 282473,
          "JavaScript" : 536753,
          "HTML" : 4280,
          "Python" : 11326
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "make the sidebar scroll separately so you can watch the vid while scrolling on the side",
      "validationOrRequirement" : "make the video auto pip when scrolling as an alternative",
      "attemptedFixes" : "no attempts mentioned",
      "otherNotes" : "this issue has been annoying me and if anyone can fix it it's probably u guys",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406669
  }, {
    "issueDTO" : {
      "id" : 2768804597,
      "title" : "[Bug]: After adding nested groups from the inside out, the inner groups cannot be operated",
      "url" : "https://github.com/Comfy-Org/ComfyUI_frontend/issues/2154",
      "repositoryName" : "Comfy-Org/ComfyUI_frontend",
      "description" : "### Frontend Version\n\n1.7.1\n\n### Expected Behavior\n\nAfter adding another group outside the group, can directly operate on the internal group.\n??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n\n### Actual Behavior\n\nAfter adding another group outside the group, cannot directly operate on the internal group, it works after do something for the outermost group.\n????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n![PixPin_2025-01-04_19-25-38](https://github.com/user-attachments/assets/d04612e7-8db7-45be-97c0-5b837b2dcb3f)\n\n\n### Steps to Reproduce\n\n1. Add a group A for some nodes\n2. Add a group B containing group A\n3. Try move group A, rename title of group A\n\n### Debug Logs\n\n```powershell\nN/A\n```\n\n\n### Browser Logs\n\nN/A\n\n### Setting JSON\n\nN/A\n\n### What browsers do you use to access the UI ?\n\nMicrosoft Edge\n\n### Other\n\n_No response_\n\n???Issue is synchronized with this [Notion page](https://www.notion.so/Issue-2154-Bug-After-adding-nested-groups-from-the-inside-out-the-inner-groups-cannot-be-oper-1716d73d36508146b69dd273c6921a42) by [Unito](https://www.unito.io)\n",
      "updatedAt" : 1753390225.000000000,
      "user" : "lldacing",
      "userHtmlUrl" : "https://github.com/lldacing",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/43737696?v=4",
      "labels" : [ "Bounty", "good first issue", "verified bug" ],
      "state" : "OPEN",
      "comments" : [ "Technical detail:\r\n- Known issue due to stacking\r\n- Intention was to resolve when impl. litegraph group overhaul (new design resolves organically)\r\n- Workaround is possible: recalc group stacking on add", "Hi @webfiltered ??? could you please give a hint/starting point for this?\n> Workaround is possible: recalc group stacking on add", "Litegraph - LGraphGroup.  Detect stacking when adding a group by checking overlaps of `boundingRect`.  Create a list, reorder the groups so the parent group is lowest on the stack.", "Great, thanks a lot!", "https://github.com/user-attachments/assets/a4692e6b-c3ed-4c11-99eb-839a023fe19e I think simply calling group.recomputeInsideNodes() whenever a new group is added could resolve this issue.\n\n", "This Issues has been set to be bounty, here is the link on how to sign up for this bounty: https://comfyorg.notion.site/ComfyUI-Bounty-Tasks-1fb6d73d36508064af76d05b3f35665f or [click here to sign up](mailto:bounty@comfy.org?subject=I%20can%20help%20%5B%5BBug%5D%3A%20After%20adding%20nested%20groups%20from%20the%20inside%20out%2C%20the%20inner%20groups%20cannot%20be%20operated%5D&body=I%20can%20help%20with%20%5BBug%5D%3A%20After%20adding%20nested%20groups%20from%20the%20inside%20out%2C%20the%20inner%20groups%20cannot%20be%20operated%0A%20issue_url%3A%20https%3A%2F%2Fgithub.com%2FComfy-Org%2FComfyUI_frontend%2Fissues%2F2154%0A%0AMy%20approach%20is%20...%0A%0AMy%20timeline%20is%20...)" ],
      "repository" : {
        "description" : "Official front-end implementation of ComfyUI",
        "homepage" : "https://www.comfy.org/",
        "name" : "ComfyUI_frontend",
        "fullName" : "Comfy-Org/ComfyUI_frontend",
        "htmlUrl" : "https://github.com/Comfy-Org/ComfyUI_frontend",
        "gitUrl" : "git://github.com/Comfy-Org/ComfyUI_frontend.git",
        "sshUrl" : "git@github.com:Comfy-Org/ComfyUI_frontend.git",
        "cloneUrl" : "https://github.com/Comfy-Org/ComfyUI_frontend.git",
        "owner" : {
          "login" : "Comfy-Org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 329,
        "stargazersCount" : 1219,
        "watchersCount" : 1219,
        "size" : 180007,
        "openIssuesCount" : 420,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-25T00:54:35Z",
        "languages" : {
          "TypeScript" : 3319527,
          "CSS" : 22418,
          "Vue" : 688905,
          "JavaScript" : 33170,
          "HTML" : 836,
          "Python" : 456
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "After adding nested groups from the inside out, the inner groups cannot be operated on directly, need to do something for the outermost group to restore normal behavior",
      "validationOrRequirement" : "Known issue due to stacking, need to resolve when impl. litegraph group overhaul (new design resolves organically)",
      "attemptedFixes" : "recalc group stacking on add, Litegraph - LGraphGroup. Detect stacking when adding a group by checking overlaps of `boundingRect`. Create a list, reorder the groups so the parent group is lowest on the stack., group.recomputeInsideNodes() whenever a new group is added",
      "otherNotes" : "Known issue due to stacking, workaround is possible by recalculating group stacking on add, or by calling group.recomputeInsideNodes() whenever a new group is added",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406674
  }, {
    "issueDTO" : {
      "id" : 2537440383,
      "title" : "drop loopback out-of-process",
      "url" : "https://github.com/bootc-dev/bootc/issues/799",
      "repositoryName" : "bootc-dev/bootc",
      "description" : "This one may be a good first issue: today when doing `install --via-loopback`, if we get killed by e.g. `Ctrl-C` (i.e. `SIGINT`) we will leak the loopback device allocation.\r\n\r\nI've been thinking here what would be nice in general is to create a little \"out of process drop\" helper that could handle these external resources; it would:\r\n\r\n- mask most signals that would otherwise be fatal\r\n- own the resource and if the parent process died (via `PR_SET_PDEATHSIG`) we'd take care of dropping them\r\n\r\nThis type of flow would also be nice for temporary directories, which are also easy to leak in this way.\r\n\r\n---\r\n\r\nHmm, we may also be able to stop forking `/bin/losetup` and instead use the ioctl APIs and only hold a file descriptor, but that's a bigger change.",
      "updatedAt" : 1753390017.000000000,
      "user" : "cgwalters",
      "userHtmlUrl" : "https://github.com/cgwalters",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/244096?v=4",
      "labels" : [ "bug", "good first issue", "area/install" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I'm interested in tackling this. I'm not sure if my understanding is correct, but it seems like we need to:\n\n1. Fork a child process\n2. Mask signals in the child process\n3. Have the child process create the loopback device and have the parent process wait until it is opened\n4. Set up a signal handler to drop the loopback device if the parent process is killed.\n\nAm I missing anything here?", "\uD83D\uDC4B Thanks for your interest in this! One thing I'd note here is that this problem domain generalizes into a \"remote process object holder + drop handler\" that is independent of bootc really. Another good example of something to also do this way would be `tempfile::tempdir()`.\n\nI did some searching on crates.io but didn't find something exactly like this, though there are various related crates like https://lib.rs/crates/defer-drop and https://lib.rs/crates/backdrop\nBasically we need a process and not a thread so we handle signals (and crashing).\n\nI think instead of a plain fork let's do an actual fork+exec which is a lot safer and easier to manage. The downside is that data passing is a bit more complex.\n", "Thanks so much for the clarification! So just to make sure, this would have to be a separate binary? And if we're fork+execing could this just be done with std::process::Command::spawn then?", "We don't need a separate binary, but can re-exec our own binary with a new entrypoint. See the handling of `bootc internals` - I did something similar in [this commit](https://github.com/containers/bootc/pull/915/commits/c5852ad405a953ce54d5b777b9e1160df21919a2) especially [this section](https://github.com/containers/bootc/pull/915/commits/c5852ad405a953ce54d5b777b9e1160df21919a2#diff-1bb9c5f23547105e52b5e81bb676cd9c8b75c4d85fc5baa77eec39cd2869d4a2R148).", "Ah ok, very interesting, thanks!", "Re-opening because of https://github.com/bootc-dev/bootc/issues/1439.\nNew PR: https://github.com/bootc-dev/bootc/pull/1449" ],
      "repository" : {
        "description" : "Boot and upgrade via container images",
        "homepage" : "https://bootc-dev.github.io/bootc/",
        "name" : "bootc",
        "fullName" : "bootc-dev/bootc",
        "htmlUrl" : "https://github.com/bootc-dev/bootc",
        "gitUrl" : "git://github.com/bootc-dev/bootc.git",
        "sshUrl" : "git@github.com:bootc-dev/bootc.git",
        "cloneUrl" : "https://github.com/bootc-dev/bootc.git",
        "owner" : {
          "login" : "bootc-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 126,
        "stargazersCount" : 1365,
        "watchersCount" : 1365,
        "size" : 6012,
        "openIssuesCount" : 193,
        "subscribersCount" : 26,
        "pushedAt" : "2025-07-24T21:04:33Z",
        "languages" : {
          "Dockerfile" : 4421,
          "Shell" : 26682,
          "Rust" : 1180309,
          "Makefile" : 4856,
          "Nu" : 549,
          "Lua" : 3843,
          "Nushell" : 17450,
          "Just" : 731
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to drop the loopback device out-of-process when installing via loopback and getting killed by Ctrl-C (SIGINT).",
      "validationOrRequirement" : "The issue requires creating a 'out of process drop' helper that can handle external resources, own the resource and take care of dropping it if the parent process dies.",
      "attemptedFixes" : "Forking a child process, masking signals, creating the loopback device, setting up a signal handler to drop the loopback device if the parent process is killed. Also, using fork+exec instead of plain fork, re-execing the binary with a new entrypoint.",
      "otherNotes" : "The issue is related to leak of loopback device allocation when installing via loopback and getting killed by Ctrl-C (SIGINT).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406680
  }, {
    "issueDTO" : {
      "id" : 3260798811,
      "title" : "UI Bug: Strange margin in last home button",
      "url" : "https://github.com/josdem/vetlog-spring-boot/issues/673",
      "repositoryName" : "josdem/vetlog-spring-boot",
      "description" : "## UI Bug: Strange margin in last home button\n\n### Summary\nThe text inside action buttons such as **LOGS**, **EDIT**, and **DELETE** is not properly vertically aligned. It appears slightly shifted upward.\n\n---\n\n### Steps to Reproduce\n1. Open home page\n2. Observe the lat button labeled **DO IT NOW**.\n\n---\n\n### Expected Result\nThe text inside button should be **vertically centered**.\nButton and description start aligned together.\n\n---\n\n### Actual Result\n- The text appears **shifted upward**.\n- Button on the right shifted below description.\n\n---\n\n### Screenshots\n<img width=\"1177\" height=\"371\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4ac9c54d-9c93-4ce5-af63-8ab35e1ee3e1\" />\n\n<img width=\"1227\" height=\"155\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0d437797-c8bf-42f8-96fd-2fafea977267\" />\n\n<img width=\"1190\" height=\"141\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ec737285-467b-475b-8c04-610ae38e374d\" />",
      "updatedAt" : 1753390005.000000000,
      "user" : "bestemic",
      "userHtmlUrl" : "https://github.com/bestemic",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/33027221?v=4",
      "labels" : [ "backlog", "bug", "front-end", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I???d like to work on this issue. Could you please assign it to me?\n", "> Hi! I???d like to work on this issue. Could you please assign it to me?\n\nHi @fatemeh-mkh ; absolutely, your collaboration is appreciated, let us know if any questions." ],
      "repository" : {
        "description" : "Maintain your pet history organized",
        "homepage" : "https://vetlog.org",
        "name" : "vetlog-spring-boot",
        "fullName" : "josdem/vetlog-spring-boot",
        "htmlUrl" : "https://github.com/josdem/vetlog-spring-boot",
        "gitUrl" : "git://github.com/josdem/vetlog-spring-boot.git",
        "sshUrl" : "git@github.com:josdem/vetlog-spring-boot.git",
        "cloneUrl" : "https://github.com/josdem/vetlog-spring-boot.git",
        "owner" : {
          "login" : "josdem",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 63,
        "stargazersCount" : 40,
        "watchersCount" : 40,
        "size" : 33151,
        "openIssuesCount" : 12,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-25T00:07:20Z",
        "languages" : {
          "Java" : 197283,
          "Dockerfile" : 980,
          "CSS" : 18698,
          "JavaScript" : 109358,
          "HTML" : 105541,
          "Kotlin" : 163665
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The text inside action buttons such as **LOGS**, **EDIT**, and **DELETE** is not properly vertically aligned. It appears slightly shifted upward.",
      "validationOrRequirement" : "The text inside button should be vertically centered. Button and description should start aligned together.",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "UI Bug: Strange margin in last home button",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406683
  }, {
    "issueDTO" : {
      "id" : 1863792844,
      "title" : "Update README to include instructions for provisioning a SiteWise data source",
      "url" : "https://github.com/grafana/iot-sitewise-datasource/issues/215",
      "repositoryName" : "grafana/iot-sitewise-datasource",
      "description" : "See the [Athena data source README](https://github.com/grafana/athena-datasource/blob/91394b62e7653e8d9a8db6e99f015a68f6bb830b/README.md?plain=1#L186-L267) for an example of what to include",
      "updatedAt" : 1753389920.000000000,
      "user" : "kevinwcyu",
      "userHtmlUrl" : "https://github.com/kevinwcyu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19530599?v=4",
      "labels" : [ "stale", "prio/low", "datasource/Sitewise", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This issue has been automatically marked as stale because it has not had activity in the last year. It will be closed in 30 days if no further activity occurs. Please feel free to leave a comment if you believe the issue is still relevant. Thank you for your contributions!" ],
      "repository" : {
        "description" : "IoT Sitewise",
        "homepage" : "",
        "name" : "iot-sitewise-datasource",
        "fullName" : "grafana/iot-sitewise-datasource",
        "htmlUrl" : "https://github.com/grafana/iot-sitewise-datasource",
        "gitUrl" : "git://github.com/grafana/iot-sitewise-datasource.git",
        "sshUrl" : "git@github.com:grafana/iot-sitewise-datasource.git",
        "cloneUrl" : "https://github.com/grafana/iot-sitewise-datasource.git",
        "owner" : {
          "login" : "grafana",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14,
        "stargazersCount" : 20,
        "watchersCount" : 20,
        "size" : 158027,
        "openIssuesCount" : 16,
        "subscribersCount" : 150,
        "pushedAt" : "2025-07-24T01:32:19Z",
        "languages" : {
          "TypeScript" : 298651,
          "Dockerfile" : 2467,
          "Shell" : 388,
          "JavaScript" : 5636,
          "Go" : 375106
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update README to include instructions for provisioning a SiteWise data source",
      "validationOrRequirement" : "See the Athena data source README for an example of what to include",
      "attemptedFixes" : "",
      "otherNotes" : "The issue has been automatically marked as stale because it has not had activity in the last year and will be closed in 30 days if no further activity occurs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406685
  }, {
    "issueDTO" : {
      "id" : 3258213317,
      "title" : "Gemini tries to read gemini.md \"file\" but its really a directory",
      "url" : "https://github.com/google-gemini/gemini-cli/issues/4760",
      "repositoryName" : "google-gemini/gemini-cli",
      "description" : "### What happened?\n\nWhen I start Gemini CLI I get this warning (not pasting the full path but you get the idea)\n\n[WARN] [MemoryDiscovery] Warning: Could not read GEMINI.md file at /Users/ ... / gemini.md. Error: EISDIR: illegal operation on a directory, read\n\n### What did you expect to happen?\n\nI don't get to see this as I dont have a file at that path called gemini.md, I have a directory there called gemini.md\n\n### Client information\n\n<details>\n\n```console\n$ gemini /about\nCLI Version             0.1.13                                       ???\n??? Git Commit              412b78c5 (local modifications)               ???\n??? Model                   gemini-2.5-pro                               ???\n??? Sandbox                 no sandbox                                   ???\n??? OS                      darwin                                       ???\n??? Auth Method             OAuth\n```\n\n</details>\n\n\n### Login information\n\n_No response_\n\n### Anything else we need to know?\n\n_No response_",
      "updatedAt" : 1753389883.000000000,
      "user" : "LyalinDotCom",
      "userHtmlUrl" : "https://github.com/LyalinDotCom",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2363526?v=4",
      "labels" : [ "kind/bug", "area/core", "priority/p3", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "An open-source AI agent that brings the power of Gemini directly into your terminal.",
        "homepage" : "",
        "name" : "gemini-cli",
        "fullName" : "google-gemini/gemini-cli",
        "htmlUrl" : "https://github.com/google-gemini/gemini-cli",
        "gitUrl" : "git://github.com/google-gemini/gemini-cli.git",
        "sshUrl" : "git@github.com:google-gemini/gemini-cli.git",
        "cloneUrl" : "https://github.com/google-gemini/gemini-cli.git",
        "owner" : {
          "login" : "google-gemini",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5999,
        "stargazersCount" : 63648,
        "watchersCount" : 63648,
        "size" : 18267,
        "openIssuesCount" : 1398,
        "subscribersCount" : 311,
        "pushedAt" : "2025-07-25T00:19:30Z",
        "languages" : {
          "TypeScript" : 2800004,
          "Dockerfile" : 1354,
          "Shell" : 1112,
          "Makefile" : 1336,
          "JavaScript" : 87062
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the warning displayed when trying to read a directory instead of a file in the Gemini CLI.",
      "validationOrRequirement" : "The issue requires validation that the path provided is a file and not a directory.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to Gemini CLI and a warning is displayed when trying to read a directory instead of a file. The client information and login information are provided. The issue is labeled as a bug, core area, and priority is set to p3.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406689
  }, {
    "issueDTO" : {
      "id" : 3261129225,
      "title" : "Too many Toast messages",
      "url" : "https://github.com/kubestellar/ui/issues/1632",
      "repositoryName" : "kubestellar/ui",
      "description" : "<img width=\"1917\" height=\"879\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/af1ee4d2-163c-4e93-9a0e-2ac725d4ce8c\" />\n\nI think 1 message is also enough to get info this much toast message is decreasing UX",
      "updatedAt" : 1753389872.000000000,
      "user" : "naman9271",
      "userHtmlUrl" : "https://github.com/naman9271",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/179296103?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@btwshivam what is your take on this ?" ],
      "repository" : {
        "description" : "KubeStellar's User Interface",
        "homepage" : "",
        "name" : "ui",
        "fullName" : "kubestellar/ui",
        "htmlUrl" : "https://github.com/kubestellar/ui",
        "gitUrl" : "git://github.com/kubestellar/ui.git",
        "sshUrl" : "git@github.com:kubestellar/ui.git",
        "cloneUrl" : "https://github.com/kubestellar/ui.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 148,
        "stargazersCount" : 56,
        "watchersCount" : 56,
        "size" : 8601,
        "openIssuesCount" : 108,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-24T21:23:12Z",
        "languages" : {
          "TypeScript" : 2560024,
          "Dockerfile" : 4363,
          "Shell" : 4960,
          "CSS" : 4768,
          "Makefile" : 7244,
          "JavaScript" : 5463,
          "Go" : 1176913,
          "HTML" : 345
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to reduce the number of Toast messages to improve UX.",
      "validationOrRequirement" : "No specific validations or requirements mentioned.",
      "attemptedFixes" : "No specific fixes or blockers mentioned.",
      "otherNotes" : "The issue is about too many Toast messages, which is decreasing UX, and the author thinks one message is enough.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406692
  }, {
    "issueDTO" : {
      "id" : 3253806570,
      "title" : "Expect.toBeInRange",
      "url" : "https://github.com/robstoll/atrium/issues/2051",
      "repositoryName" : "robstoll/atrium",
      "description" : "*Platform* (all, jvm, js): all\n*Extension* (none, kotlin 1.3): none\n\n## Code related feature\n```kotlin\nexpect(x).toBeInRange(1..10)\nexpect(x).toBeInRange(1 until 10)\n\n//instead of\n\nexpect(x) {\n  toBeGreaterThanOrEqualTo(1)\n  toBeLessThanOrEqualTo(10)\n}\nexpect(x) {\n  toBeGreaterThanOrEqualTo(1)\n  toBeLessThan(10)\n}\n```\n\nFollowing the things you need to do:\n\n*logic*\n- [ ] create RangeAssertions with a function `toBeInRange` (see e.g. FloatingPointAssertions as a guideline)\n- [ ] implement toBeInRange in DefaultRangeAssertions.kt - make sure both bounds are evaluated (no fail fast behaviour)\n\n*api-fluent*\n- [ ] create rangeExpectations.kt with 3 times fun `Expect<T>.toBeInRange(t: T): Expect<T>` for T= CharRange, IntRange, LongRange\n- [ ] create a Test named AbstractRangeExpectationsSpec in atrium-specs -> commonMain  (see for instance AbstractComparableExpectationsTest) and extend it in atrium-api-fluent -> commonTest (name it RangeExpectationsSpec)\n- [ ] create RangeExpectationSamples.kt with 3 functions in commonTest -> samples (see other samples as guideline -- try to provide the reason why an expectation fails)\n- [ ] add `@sample` with link to your sample method to the 3 functions in rangeExpectations.kt\n- [ ] add `@since 1.3.0` (adapt to current [milestone](https://github.com/robstoll/atrium/milestones)) to KDOC of the three functions in RangeExpectations.kt\n\n\n*api-infix*\n- [ ] create rangeExpectations.kt with 3 times fun `Expect<T>.toBeInRange(t: T): Expect<T>` for T= CharRange, IntRange, LongRange\n- [ ] create RangeExpectationsTest in atrium-api-infix which extends AbstractRangeExpectationsSpec\n- [ ] add samples to RangeExpectationSamples.kt (3 fun again)\n- [ ] add `@sample` with link to your sample method to the 3 functions in rangeExpectations.kt\n- [ ] add `@since 1.3.0` (adapt to current [milestone](https://github.com/robstoll/atrium/milestones)) to KDOC of the two functions in RangeExpectations.kt\n\n## Your first contribution?\n- Write a comment `I'll work on this` if you would like to take this issue over. \n  This way we get the chance to revise the description in case things have changed in the meantime, we might give you additional hints and we can assign the task to you, so that others do not start as well.\n- See [Your first code contribution](https://github.com/robstoll/atrium/blob/main/.github/CONTRIBUTING.md#your-first-code-contribution) for guidelines.  \n- Do not hesitate to ask questions here or to contact us via [Atrium's slack channel](https://kotlinlang.slack.com/team/U3DE1TXKP) if you need help\n  ([Invite yourself](https://slack.kotlinlang.org/) in case you do not have an account yet).\n",
      "updatedAt" : 1753389737.000000000,
      "user" : "robstoll",
      "userHtmlUrl" : "https://github.com/robstoll",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5557885?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @robstoll , I'll work on this\nI???ve made a few OSS contributions before, but I still consider myself a beginner ??? I???d really appreciate your support if anything needs fixing!" ],
      "repository" : {
        "description" : "A multiplatform expectation library for Kotlin",
        "homepage" : "https://docs.atriumlib.org",
        "name" : "atrium",
        "fullName" : "robstoll/atrium",
        "htmlUrl" : "https://github.com/robstoll/atrium",
        "gitUrl" : "git://github.com/robstoll/atrium.git",
        "sshUrl" : "git@github.com:robstoll/atrium.git",
        "cloneUrl" : "https://github.com/robstoll/atrium.git",
        "owner" : {
          "login" : "robstoll",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 224,
        "stargazersCount" : 616,
        "watchersCount" : 616,
        "size" : 72676,
        "openIssuesCount" : 57,
        "subscribersCount" : 25,
        "pushedAt" : "2025-07-24T20:47:23Z",
        "languages" : {
          "Java" : 6386,
          "Shell" : 407,
          "Kotlin" : 3814831
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new feature in Atrium called 'RangeAssertions' with a function called 'toBeInRange' that can be used to assert if a value is within a range.",
      "validationOrRequirement" : "The function 'toBeInRange' should be implemented in DefaultRangeAssertions.kt and should make sure both bounds are evaluated. The API-fluent and API-infix versions of the feature should also be created.",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "This issue is about creating a new feature in Atrium, a Kotlin testing library. The feature is called 'RangeAssertions' and it should have a function called 'toBeInRange'. The function should be implemented in DefaultRangeAssertions.kt and should make sure both bounds are evaluated. The issue also involves creating API-fluent and API-infix versions of the feature. The issue is labeled as 'help wanted' and 'good first issue', indicating that it's suitable for beginners.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406698
  }, {
    "issueDTO" : {
      "id" : 2932692433,
      "title" : "Steane Example in PyZX",
      "url" : "https://github.com/tqec/tqec/issues/528",
      "repositoryName" : "tqec/tqec",
      "description" : "We need a PyZX graphS object that represents the Steane example from [these slides](https://docs.google.com/presentation/d/184GHX9jffq9dcwWzbku0K90V9xdA8_25lD8pfeEcgRg/edit#slide=id.g334ab20f3f2_0_265) (e.g. slide 59). Please let me know if we already have one. \n\nIn [an initial attempt](https://github.com/tqec/tqec/blob/steane-code-demo/examples/pyzx-steane/pyzx-steane.ipynb), I was able to read a qasm file, but input edges must be closed. In the `steane_code.qasm` file, I wrote out the entire Steane example circuit, but PyZX was unable to parse my `reset` instructions. \n\nEDIT: To avoid confusion, I renamed this issue and deleted broader questions about `PyZX` interoperability. Broader discussions about interoperability can happen at #449.",
      "updatedAt" : 1753389489.000000000,
      "user" : "KabirDubey",
      "userHtmlUrl" : "https://github.com/KabirDubey",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/44329881?v=4",
      "labels" : [ "backend", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "> I wrote out the entire Steane example circuit, but PyZX was unable to parse my reset instructions.\n\nThe workaround to this is to write the whole circuit in pyzx format. I have got an output after applying all the rules but I need to further simplify it to get it to exactly look like Austin's slide 59. \n\n```py\nimport pyzx as zx\nfrom pyzx.circuit import Circuit, CNOT, HAD\n\nc = zx.Circuit(10)\n\n\n# qubits 0, 1, 2 are ancillas\n\nc.add_gate(\"HAD\", 0)\nc.add_gate(\"CNOT\", 0, 3)\nc.add_gate(\"CNOT\", 0, 4)\nc.add_gate(\"CNOT\", 0, 5)\nc.add_gate(\"CNOT\", 0, 6)\nc.add_gate(\"HAD\", 0)\nc.add_gate(\"PostSelect\", 0)\n\n\nc.add_gate(\"HAD\", 1)\nc.add_gate(\"CNOT\", 1, 3)\nc.add_gate(\"CNOT\", 1, 4)\nc.add_gate(\"CNOT\", 1, 7)\nc.add_gate(\"CNOT\", 1, 8)\nc.add_gate(\"HAD\", 1)\nc.add_gate(\"PostSelect\", 1)\n\nc.add_gate(\"HAD\", 2)\nc.add_gate(\"CNOT\", 2, 3)\nc.add_gate(\"CNOT\", 2, 5)\nc.add_gate(\"CNOT\", 2, 7)\nc.add_gate(\"CNOT\", 2, 9)\nc.add_gate(\"HAD\", 2)\nc.add_gate(\"PostSelect\", 2)\n\n\n\ng = c.to_graph()\ng.apply_state('0'*10)\nzx.draw(g)\n```", "@KabirDubey Did you get a chance to work on this yet? I am trying to find a way to be consistent with how rules are applied in pyzx compared to Austin's slides. \n\nThe issue is that if I use the rules in pyzx rules as they are, the edge colors are changed whereas we want the node color to change. ", "> [@KabirDubey](https://github.com/KabirDubey) Did you get a chance to work on this yet?\n\nNot yet, I was planning on working on this later today or tomorrow. I'm broadly available today onwards if you or anyone else would like to discuss offline.\n\n> The issue is that if I use the rules in pyzx rules as they are, the edge colors are changed whereas we want the node color to change.\n\nI see. I saw a similar phenomenon when I was playing around with PyZX [on my branch](https://github.com/tqec/tqec/blob/steane-code-demo/examples/pyzx-steane/pyzx-steane.ipynb). Part of my vision for this issue is to document how the existing functionality of PyZX can be used for tqec.\n", "> I'm broadly available today onwards if you or anyone else would like to discuss offline.\n\nProbably not today or tomorrow. ", "Hi @KabirDubey and @purva-thakre, you might need to interpret the boundary node's Pauli web in PyZX differently. Aleks, Austin and I are in email conversations regarding that. \n\nA separate issue: I have also emailed Adrien about a bug in TQEC, if we start purely from a ZX diagram, the correlation surface finder seems to be buggy, or at least the plotting of Pauli webs (or maybe I am doing something wrong).\n\n<img width=\"428\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/17fb877f-9cb2-42f9-a5ce-9a43235449dc\" />", "> you might need to interpret the boundary node's Pauli web in PyZX differently\n\n@kh428 Thanks! I am working to understand this. Just to be clear, a Pauli web in PyZX is the same as a correlation surface in tqec, right?", "Right :-)\r\n\r\nOn Mon, Mar 24, 2025 at 2:38???PM Purva Thakre ***@***.***>\r\nwrote:\r\n\r\n> you might need to interpret the boundary node's Pauli web in PyZX\r\n> differently\r\n>\r\n> @kh428 <https://github.com/kh428> Thanks! I am working to understand\r\n> this. Just to be clear a Pauli web in PyZX is the same as a correlation\r\n> surface in tqec, right?\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2749460037>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAKAXTC35LJM7UOMVAT2V5D2WB3OHAVCNFSM6AAAAABZLQLLYCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDONBZGQ3DAMBTG4>\r\n> .\r\n> You are receiving this because you are subscribed to this thread.Message\r\n> ID: ***@***.***>\r\n> [image: purva-thakre]*purva-thakre* left a comment (tqec/tqec#528)\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2749460037>\r\n>\r\n> you might need to interpret the boundary node's Pauli web in PyZX\r\n> differently\r\n>\r\n> @kh428 <https://github.com/kh428> Thanks! I am working to understand\r\n> this. Just to be clear a Pauli web in PyZX is the same as a correlation\r\n> surface in tqec, right?\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2749460037>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAKAXTC35LJM7UOMVAT2V5D2WB3OHAVCNFSM6AAAAABZLQLLYCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDONBZGQ3DAMBTG4>\r\n> .\r\n> You are receiving this because you are subscribed to this thread.Message\r\n> ID: ***@***.***>\r\n>\r\n", "> I am trying to find a way to be consistent with how rules are applied in pyzx compared to Austin's slides.\n\nTo answer my own question on this, the current set of Hadamard rules in pyzx does not allow this. \n\nhttps://github.com/zxcalc/pyzx/blob/64ff4594a5104851ab7ccdb492e72548c4f10b27/pyzx/hrules.py#L4\n\n> you might need to interpret the boundary node's Pauli web in PyZX differently\n\n@kh428 Do you mind clarifying this further? Based on the pyzx documentation about Pauli web, if a certain number of conditions are not satisfied by a node (spider) or edge, then this node or edge is called the boundary. How would I interpret this differently?\n\nhttps://github.com/zxcalc/pyzx/blob/64ff4594a5104851ab7ccdb492e72548c4f10b27/pyzx/pauliweb.py#L54", "There is only one Hadamard rule. Choose any node in the ZX graph, you can\r\nflip its color and flip the presence of Hadamards on its edges.\r\n\r\nOn Wed, Mar 26, 2025, 4:32???PM Purva Thakre ***@***.***> wrote:\r\n\r\n> I am trying to find a way to be consistent with how rules are applied in\r\n> pyzx compared to Austin's slides.\r\n>\r\n> To answer my own question on this, the current set of Hadamard rules in\r\n> pyzx does not allow this.\r\n>\r\n>\r\n> https://github.com/zxcalc/pyzx/blob/64ff4594a5104851ab7ccdb492e72548c4f10b27/pyzx/hrules.py#L4\r\n>\r\n> you might need to interpret the boundary node's Pauli web in PyZX\r\n> differently\r\n>\r\n> @kh428 <https://github.com/kh428> Do you mind clarifying this further?\r\n> Based on the pyzx documentation about Pauli web, if a certain number of\r\n> conditions are not satisfied by a node (spider) or edge, then this node or\r\n> edge is called the boundary. How would I interpret this differently?\r\n>\r\n>\r\n> https://github.com/zxcalc/pyzx/blob/64ff4594a5104851ab7ccdb492e72548c4f10b27/pyzx/pauliweb.py#L54\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2755997529>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAKAXTHMWHJJ2FL7LAVOXFD2WM2IFAVCNFSM6AAAAABZLQLLYCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDONJVHE4TONJSHE>\r\n> .\r\n> You are receiving this because you commented.Message ID:\r\n> ***@***.***>\r\n> [image: purva-thakre]*purva-thakre* left a comment (tqec/tqec#528)\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2755997529>\r\n>\r\n> I am trying to find a way to be consistent with how rules are applied in\r\n> pyzx compared to Austin's slides.\r\n>\r\n> To answer my own question on this, the current set of Hadamard rules in\r\n> pyzx does not allow this.\r\n>\r\n>\r\n> https://github.com/zxcalc/pyzx/blob/64ff4594a5104851ab7ccdb492e72548c4f10b27/pyzx/hrules.py#L4\r\n>\r\n> you might need to interpret the boundary node's Pauli web in PyZX\r\n> differently\r\n>\r\n> @kh428 <https://github.com/kh428> Do you mind clarifying this further?\r\n> Based on the pyzx documentation about Pauli web, if a certain number of\r\n> conditions are not satisfied by a node (spider) or edge, then this node or\r\n> edge is called the boundary. How would I interpret this differently?\r\n>\r\n>\r\n> https://github.com/zxcalc/pyzx/blob/64ff4594a5104851ab7ccdb492e72548c4f10b27/pyzx/pauliweb.py#L54\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2755997529>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAKAXTHMWHJJ2FL7LAVOXFD2WM2IFAVCNFSM6AAAAABZLQLLYCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDONJVHE4TONJSHE>\r\n> .\r\n> You are receiving this because you commented.Message ID:\r\n> ***@***.***>\r\n>\r\n", "> > I am trying to find a way to be consistent with how rules are applied in pyzx compared to Austin's slides.\n\nRe: \"consistent with how rules are applied in PyZX compared to Austin's slides\", what do you mean, sorry I don't understand? My understanding is that they are consistent? You have the option of choosing between a Hadamard edge (cyan coloured) or an actual Hadamard vertex in PyZX.\n\nRe: Using PyZX to finding the Pauli webs. Let's look at the Steane code encoding logical circuit below. PyZX cannot output Pauli webs because the graph does not have gflow (generalised flow).\n<img width=\"943\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7d3b6b7a-bd70-49ac-b100-0695518b2396\" />\n\nHowever if you leave the output ports open (see below),\n<img width=\"881\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/30c054a4-b013-419b-bae7-62e0cb15e990\" />\nThen you can compute Pauli webs in PyZX. If you look at the Pauli-Z webs computed by PyZX then, you will notice something strange (see below).\n<img width=\"864\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6f77f7f7-1aa1-4164-8f8e-5bb66d3faba4\" />\nThe vertex labelled 0 has a 1 same colour Pauli web terminating on it. \n\nReferring to https://arxiv.org/abs/2410.17240, Pauli webs can be thought of as firing of spiders, i.e. choose a node and by adding pi spiders in the vicinity that respects the local symmetry of the particular node.\n<img width=\"754\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/06e656d2-9dad-4419-88d0-35c64ba9b393\" />\n<img width=\"773\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3d21fc2e-5d52-44a2-bdb6-6626108072d8\" />\n\nTo quote Aleks Kissinger: \"Boundary spiders, where the coloured edges do *not* correspond to an (anti-)stabiliser for that spider. These correspond to locations where a local, quantum correction might be needed (as opposed to just classical post-processing).\"\n\nThis is what I interpreted that the Pauli webs has a modified interpretation when there are boundary spiders. Let me know if I have made any mistakes/misinterpreted anything.\n", "> Re: \"consistent with how rules are applied in PyZX compared to Austin's slides\", what do you mean, sorry I don't understand? My understanding is that they are consistent? You have the option of choosing between a Hadamard edge (cyan coloured) or an actual Hadamard vertex in PyZX.\n\nhttps://docs.google.com/presentation/d/184GHX9jffq9dcwWzbku0K90V9xdA8_25lD8pfeEcgRg/edit#slide=id.g334ab20f3f2_0_190\n\nSee slides 51 and 52. \n\n![Image](https://github.com/user-attachments/assets/e49b20e4-b7ec-4c4f-813f-353dfc0ca8d1)\n\n![Image](https://github.com/user-attachments/assets/33ffd557-c7a5-45a8-9b99-989801b5d2bb)\n\n@kh428 It's the rule where the color of a vertex is changed: (quoting Austin) `if every edge of a node is a Hadamard edge, you can remove the Hadamards and change the color of the node`. \n\nI can't seem to find anything similar to this in `pyzx/hrules.py`. I have either an H edge or an H vertex in my graph, and that's it. \n\n![Image](https://github.com/user-attachments/assets/c62fb6cd-d69b-47d1-a185-1a70811e2daf)\n\n![Image](https://github.com/user-attachments/assets/0a67bfd3-73f9-4cfd-bb6e-07ac809a2785)\n\nI may not be interpreting some function docstrings correctly. Do you mind pointing me to a function like this in `pyzx`? My understanding so far is that I need to define a custom rule in my jupyter notebook to go from Slides 51 to 52.\n\nThank you for your helpful comment! ", "@purva-thakre sorry, I understand you now. I am not sure how, have you looked at `pyzx/hsimplify.py`, maybe there is something in there?", ">  I am not sure how, have you looked at pyzx/hsimplify.py, maybe there is something in there?\n\nThanks @kh428. Austin reached out to Aleks, and apparently I was looking in the wrong module. `hrules.py` is for the ZH-Calculus. ", "It looks like `pyzx` might need some additional work for us to go from [Slides 51 - 59](https://docs.google.com/presentation/d/184GHX9jffq9dcwWzbku0K90V9xdA8_25lD8pfeEcgRg/edit#slide=id.g334ab20f3f2_0_190).\n\nThe [`PostSelect`](https://github.com/zxcalc/pyzx/blob/9568bf38962efc9c87ab5159b9dca16fa473c9b0/pyzx/circuit/gates.py#L1160) gate is represented by the Z vertex, whereas it should be the X vertex. If I use the pyzx rules on this, the output looks something like this:\n\n![Image](https://github.com/user-attachments/assets/fcad75e6-b0d8-4ed2-b770-d334f3f87817)\n\nThere are issues with the Measurement gate not being supported in QASM circuit to pyzx circuit functionality. As noticed by Kabir. \n\nI also tried starting with a graph instead of converting a circuit to a graph, as it allows more control over measurement ~ X node. This output is a mess. 0, 1, and 2 are ancillas. \n\n![Image](https://github.com/user-attachments/assets/960ae504-8113-4a00-a50e-e29d688f33f4)\n\nApplying some of the pyzx rules, this is the closest I have gotten to the desired output. \n\n![Image](https://github.com/user-attachments/assets/10b53bba-efa2-499c-8356-e440538e61a2)\n\nEdit: There was an error in the previous graph where a Z node was in place of an X node. The updated graphs are provided below.\n\n![Image](https://github.com/user-attachments/assets/a7d3c967-af37-44ab-958d-6d1682b680fe)\n\n![Image](https://github.com/user-attachments/assets/a633d9c6-4f29-4856-9eee-b28daa913697)\n\nAfter removing the identity nodes, I get the desired output:\n\n![Image](https://github.com/user-attachments/assets/ced14e10-477e-4592-9620-3866a47feb0d)", "Thanks @purva-thakre, in the final graph, can you check if you could compute the pauli webs?\n", "@kh428 Computing the pauli webs for the final graph leads to `ValueError: Graph must have gFlow`\n\nI will clean up my code and provide a link to it by next week. ", "> [@kh428](https://github.com/kh428) Computing the pauli webs for the final graph leads to `ValueError: Graph must have gFlow`\n\nIt seems like one would need to go through PyZX `gflow` subroutine to compute Pauli webs. \n\nHowever in the equivalent Pipe/Block diagram in TQEC, the correlation surface finder is able to find correlation surfaces, I suppose. Why this difference?\n\n", "> It seems like one would need to go through PyZX gflow subroutine to compute Pauli webs.\n\n> However in the equivalent Pipe/Block diagram in TQEC, the correlation surface finder is able to find correlation surfaces, I suppose. Why this difference?\n\nTBH, I don't know the answer to this. Maybe, @afowler @nelimee @inmzhang do?", "> It seems like one would need to go through PyZX `gflow` subroutine to compute Pauli webs.\n> \n> However in the equivalent Pipe/Block diagram in TQEC, the correlation surface finder is able to find correlation surfaces, I suppose. Why this difference?\n\nThe last ZX diagram provided by Purva lacks a gflow (likely because it has a different number of inputs and outputs). The Pauli web computation in pyzx directly depends on the gflow property, which is why it fails in this case.\n\nIn TQEC, the Pauli web computation doesn't rely on gflow. Instead, it uses local rules for the Pauli web around a spider. For example, a red Pauli spider must have an even number of red-highlighted legs or have no/all legs highlighted in blue. After applying these local rules, a flood-fill algorithm is used to identify the global Pauli webs.", "\n> In TQEC, the Pauli web computation doesn't rely on gflow. Instead, it uses local rules for the Pauli web around a spider. For example, a red Pauli spider must have an even number of red-highlighted legs or have no/all legs highlighted in blue. After applying these local rules, a flood-fill algorithm is used to identify the global Pauli webs.\n\nI understand the concept of Pauli webs and it seems like generating it locally and propagating it to the whole ZX graph/structure would be a better approach? How can we rely on PyZX if it cannot even generate the Pauli web for a simple Steane code encoding circuit?", "> How can we rely on PyZX if it cannot even generate the Pauli web for a simple Steane code encoding circuit?\n\nThis is why we do not use the `compute_pauli_web` function from PyZX in the current codebase. We prefer to use it in the future???likely after PyZX upgrades the algorithm to support more general ZX diagrams???because it also outputs the T orders, which cannot be computed (or at least, I don???t know how to) using a simple graph traversal algorithm.", "> likely after PyZX upgrades the algorithm to support more general ZX diagrams\n\nAre there any indications that this will happen?", "To be clear, I'll think our community is going to have to play a\r\nsignificant role in the future development of PyZX.\r\n\r\nOn Fri, Apr 11, 2025, 3:36???AM kh428 ***@***.***> wrote:\r\n\r\n> likely after PyZX upgrades the algorithm to support more general ZX\r\n> diagrams\r\n>\r\n> Is there any indications that this will indeed happen?\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2796530199>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAKAXTCZPDJ5AMDHBEGYRXT2Y6LKDAVCNFSM6AAAAABZLQLLYCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDOOJWGUZTAMJZHE>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n> *kh428* left a comment (tqec/tqec#528)\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2796530199>\r\n>\r\n> likely after PyZX upgrades the algorithm to support more general ZX\r\n> diagrams\r\n>\r\n> Is there any indications that this will indeed happen?\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tqec/tqec/issues/528#issuecomment-2796530199>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAKAXTCZPDJ5AMDHBEGYRXT2Y6LKDAVCNFSM6AAAAABZLQLLYCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDOOJWGUZTAMJZHE>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n", "To quote this paper [here](https://arxiv.org/abs/2207.09368) by Mhalla, Perdrix and Sanselme.\n\n\"GFlow fails to be necessary for determinism when a measurement-based quantum computation involves Pauli measurements\"\n\nand \n\n\"In terms of determinism, Pauli measurements satisfy some particular properties that are not captured by GFlow. For instance, an MBQC involving an X measurement can be deterministic, even though the corresponding open graph has no GFlow...\"\n\nI guess you can sometime still draw Pauli webs/Stabiliser flow/etc in light of the ZX-diagram having no GFlow. The Shadow Pauli Flow introduced in this paper \"provides necessary and sufficient for robust determinism\"." ],
      "repository" : {
        "description" : "Design automation software tools for Topological Quantum Error Correction",
        "homepage" : "https://tqec.github.io/tqec/",
        "name" : "tqec",
        "fullName" : "tqec/tqec",
        "htmlUrl" : "https://github.com/tqec/tqec",
        "gitUrl" : "git://github.com/tqec/tqec.git",
        "sshUrl" : "git@github.com:tqec/tqec.git",
        "cloneUrl" : "https://github.com/tqec/tqec.git",
        "owner" : {
          "login" : "tqec",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 69,
        "stargazersCount" : 260,
        "watchersCount" : 260,
        "size" : 58799,
        "openIssuesCount" : 53,
        "subscribersCount" : 14,
        "pushedAt" : "2025-07-22T09:21:37Z",
        "languages" : {
          "Shell" : 2321,
          "Python" : 1418400
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The author is trying to generate the Pauli web for the Steane code encoding circuit using PyZX, but is having trouble due to the lack of gflow in the ZX diagram. The author is also trying to find a way to be consistent with how rules are applied in PyZX compared to Austin's slides.",
      "validationOrRequirement" : "The author needs to be able to generate the Pauli web for the Steane code encoding circuit using PyZX. The author also needs to be able to apply the rules consistently in PyZX compared to Austin's slides.",
      "attemptedFixes" : "The author tried to find a way to be consistent with how rules are applied in PyZX compared to Austin's slides. The author also tried to use the pyzx rules on the Steane code encoding circuit, but the output was not as desired. The author also tried to start with a graph instead of converting a circuit to a graph, but the output was still not as desired.",
      "otherNotes" : "The Steane code example in PyZX was not able to generate the desired Pauli web due to the lack of gflow in the ZX diagram. The Pauli web computation in PyZX directly depends on the gflow property, which is why it fails in this case. In TQEC, the Pauli web computation doesn't rely on gflow. Instead, it uses local rules for the Pauli web around a spider. For example, a red Pauli spider must have an even number of red-highlighted legs or have no/all legs highlighted in blue. After applying these local rules, a flood-fill algorithm is used to identify the global Pauli webs. The current codebase does not use the `compute_pauli_web` function from PyZX due to this limitation. There are indications that PyZX will upgrade its algorithm to support more general ZX diagrams in the future, but it is unclear when this will happen.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406712
  }, {
    "issueDTO" : {
      "id" : 3261167291,
      "title" : "[scripts/container-update] Replace hardcoded container URL to ghrc.io",
      "url" : "https://github.com/INGInious/INGInious/issues/1062",
      "repositoryName" : "INGInious/INGInious",
      "description" : "The [container_update.py](https://github.com/INGInious/INGInious/blob/main/inginious/scripts/container_update.py) script used to update every INGInious environment installed along an INGInious instance use [here and there hard-coded references to the DockerHub with the outdated container nomenclature](https://github.com/INGInious/INGInious/blob/main/inginious/scripts/container_update.py#L54), e.g., `ingi/inginious-c-base`.\n\nSince then, we moved to the Github registry and simplified the container nomencalture, i.e., `ghcr.io/inginious/env-base`. The [container_update.py](https://github.com/INGInious/INGInious/blob/main/inginious/scripts/container_update.py) script must be updated to reflect that change, as well as the related documentation. See also #1056.\n\nThis is a low priority issue since the recommended installation method leverages `docker compose`. The version of required environment images can be explicitly specified in the `compose` file.",
      "updatedAt" : 1753389449.000000000,
      "user" : "nrybowski",
      "userHtmlUrl" : "https://github.com/nrybowski",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/26024920?v=4",
      "labels" : [ "Good First Issue", "Scripts", "Documentation", "Priority: Low" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "INGInious is a secure and automated exercises assessment platform using your own tests, also providing a pluggable interface with your existing LMS.",
        "homepage" : "http://www.inginious.org",
        "name" : "INGInious",
        "fullName" : "INGInious/INGInious",
        "htmlUrl" : "https://github.com/INGInious/INGInious",
        "gitUrl" : "git://github.com/INGInious/INGInious.git",
        "sshUrl" : "git@github.com:INGInious/INGInious.git",
        "cloneUrl" : "https://github.com/INGInious/INGInious.git",
        "owner" : {
          "login" : "INGInious",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 143,
        "stargazersCount" : 223,
        "watchersCount" : 223,
        "size" : 45271,
        "openIssuesCount" : 156,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-24T21:18:28Z",
        "languages" : {
          "Dockerfile" : 4928,
          "CSS" : 50599,
          "Shell" : 82,
          "JavaScript" : 104266,
          "HTML" : 402038,
          "Less" : 13199,
          "Python" : 1044324
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace hardcoded container URL to ghcr.io in the container_update.py script",
      "validationOrRequirement" : "Update the script to reflect the change to the Github registry and simplified container nomenclature, and update related documentation.",
      "attemptedFixes" : "",
      "otherNotes" : "The script used to update INGInious environments uses outdated container nomenclature and hard-coded references to DockerHub, which needs to be updated to reflect the change to the Github registry and simplified container nomenclature.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406715
  }, {
    "issueDTO" : {
      "id" : 2584317056,
      "title" : "[Automatic Import] Tell users about the log formats we support",
      "url" : "https://github.com/elastic/kibana/issues/196039",
      "repositoryName" : "elastic/kibana",
      "description" : "### Context\n\nPreviously we had a message as a second line in the file upload box about only supporting the JSON/NDJSON format:\n\n![Image](https://github.com/user-attachments/assets/03a01bdc-10eb-4f24-afd4-8230ee9fb431)\n\n\nOwing to the maturity of log formats available now, with support for structured and unstructured logs previously implemented, we removed this verbiage in https://github.com/elastic/kibana/pull/194386 (the CSV format support PR) targeting 8.16.\n\n### Action Item\n\nProvide a new message to tell the user about the formats we support on the upload screen as well as in the error that is shown for unsupported formats (`'Unsupported log format in the samples.'`). \n\nIt could be a link to the docs as well.\n\n### Notes\n\nThe format support depends on the version ??? CSV support and wording removal were not backported to 8.15.x.\n\n### Design\n\n**??? please add here ???**\n\nSuggestions:\n\n> Please refer to the documentation [link] for supported formats\n\nor \n\n> Supported file types include JSON/NDJSON, CSV, ...\n",
      "updatedAt" : 1753389426.000000000,
      "user" : "ilyannn",
      "userHtmlUrl" : "https://github.com/ilyannn",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4211644?v=4",
      "labels" : [ "Feature:AutomaticImport", "Team:Security-Scalability", "enhancement", "good first issue", "needs design" ],
      "state" : "OPEN",
      "comments" : [ "Pinging @elastic/security-scalability (Team:Security-Scalability)", "@ebeahan will follow up with design & PM on how to approach.", "@jamiehynds any thoughts on how to approach informing users in-product about the supported log formats in Automatic Import?", "@ebeahan given the all the formats we now support, it may be easier to create a doc with the supported formats and link to it from here with a label 'To view the log formats supported by Automatic Import, please see here' (will need some refinement obviously). \n\nWhat do you think @einatjacoby?", "Suggestion:\n\n> Refer to [the documentation](https://www.elastic.co/guide/en/security/current/automatic-import.html) for supported log formats", "Another possibility:\n\n> Upload logs in structured or unstructured formats (including JSON, NDJSON, and Syslog).", "@benironside could you take a look at this issue please? When we launched Auto Import we only supported log samples in JSON/NDJSON and this was reflect in the UI. Now that we support other formats, we need to adjust the language on the UI. \n\nI lean towards Ilya's suggestion (Refer to [the documentation](https://www.elastic.co/guide/en/security/current/automatic-import.html) for supported log formats) to avoid listing all the supported formats on the UI. ", "> I lean towards Ilya's suggestion (Refer to [the documentation](https://www.elastic.co/guide/en/security/current/automatic-import.html) for supported log formats) to avoid listing all the supported formats on the UI.\n\nNo objection on the wording, but what are best practices for linking to the docs from Kibana? If you link to `/current/`, the link will eventually take you docs for a newer version (e.g. I'm running 8.18 but `current` points to `9.1`).", "@benironside is going to provide us with a 'stable' link to a doc that outlines our supported formats (with examples) that we can link to from Kibana. He's on PTO on Feb 20th but will provide as soon as he returns. ", "As communicated by @benironside:\n\n- the link for 9.0 should be https://www.elastic.co/docs/guides/solutions/security/get-started/automatic-import.html\n- for 8.18 docs, https://www.elastic.co/guide/en/security/current/automatic-import.html. \n- we recommend using the internal link service https://docs.elastic.dev/docs/kibana-doc-links.", "Update: the correct link for 9.0 is https://www.elastic.co/docs/solutions/security/get-started/automatic-import" ],
      "repository" : {
        "description" : "Your window into the Elastic Stack",
        "homepage" : "https://www.elastic.co/products/kibana",
        "name" : "kibana",
        "fullName" : "elastic/kibana",
        "htmlUrl" : "https://github.com/elastic/kibana",
        "gitUrl" : "git://github.com/elastic/kibana.git",
        "sshUrl" : "git@github.com:elastic/kibana.git",
        "cloneUrl" : "https://github.com/elastic/kibana.git",
        "owner" : {
          "login" : "elastic",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 8400,
        "stargazersCount" : 20598,
        "watchersCount" : 20598,
        "size" : 10739071,
        "openIssuesCount" : 13431,
        "subscribersCount" : 843,
        "pushedAt" : "2025-07-24T22:52:36Z",
        "languages" : {
          "MDX" : 2704842,
          "CSS" : 205939,
          "Standard ML" : 3033,
          "Handlebars" : 36754,
          "Makefile" : 5205,
          "HTML" : 19095,
          "Perl" : 12381,
          "Nunjucks" : 118640,
          "EJS" : 12706,
          "TypeScript" : 257819293,
          "Dockerfile" : 15257,
          "Shell" : 435147,
          "Starlark" : 40163,
          "PEG.js" : 20672,
          "Batchfile" : 5169,
          "ANTLR" : 41681,
          "SCSS" : 120798,
          "JavaScript" : 8668399,
          "Python" : 7624
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Tell users about the log formats we support",
      "validationOrRequirement" : "Provide a new message to tell the user about the formats we support on the upload screen as well as in the error that is shown for unsupported formats (`'Unsupported log format in the samples.'`).",
      "attemptedFixes" : "Pinging @elastic/security-scalability (Team:Security-Scalability), @ebeahan will follow up with design & PM on how to approach., @jamiehynds any thoughts on how to approach informing users in-product about the supported log formats in Automatic Import?, @ebeahan given the all the formats we now support, it may be easier to create a doc with the supported formats and link to it from here with a label 'To view the log formats supported by Automatic Import, please see here' (will need some refinement obviously).",
      "otherNotes" : "The format support depends on the version ??? CSV support and wording removal were not backported to 8.15.x.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406722
  }, {
    "issueDTO" : {
      "id" : 3242511681,
      "title" : "Add an option to disable auto-start on login",
      "url" : "https://github.com/Jigsaw-Code/outline-apps/issues/2559",
      "repositoryName" : "Jigsaw-Code/outline-apps",
      "description" : "### Is there an existing issue that is already proposing this?\n\n- [x] I have searched the existing issues\n\n### Application\n\nOutline Client\n\n### What are you trying to do? What is your use case?\n\nHello Outline Team,\n\nI would like to request an option in the settings of the Outline Manager for Windows to enable or disable the \"run on startup\" feature.\n\nCurrently, the app starts automatically every time Windows boots up. This is causing a recurring network problem for me, forcing me to perform a full \"Network Reset\" in Windows settings after every reboot to get my internet connection working again. This is very disruptive.\n\nA simple toggle switch in the app's settings to control the auto-start behavior would solve this issue and allow users to manage the app without resorting to drastic measures like resetting network adapters.\n\nThank you for your consideration!\n\n### Is your feature request related to a problem? Please describe it.\n\nYes, the problem is that when Outline Client starts automatically with Windows, it causes a network connectivity issue. The only way to fix this is to perform a full \"Network Reset\" through Windows settings after every reboot, which is very inconvenient.\n\n### Describe the solution you'd like.\n\nA simple toggle switch (On/Off) inside the Outline Client's settings menu to enable or disable the \"run on startup\" behavior. This would allow users to easily control the app's behavior.\n\n### Describe alternatives you've considered\n\nThe only current alternative is to manually disable the application from the Windows Task Manager's startup tab, which is not user-friendly for everyone and needs to be done outside of the app.",
      "updatedAt" : 1753389123.000000000,
      "user" : "mahdihoseini123",
      "userHtmlUrl" : "https://github.com/mahdihoseini123",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/73771914?v=4",
      "labels" : [ "os/windows", "feature request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'm less familiar with windows - @jyyi1 is this not configurable at the OS level?", "Hi @mahdihoseini123 , thanks for reaching out!\n\nIf you don't want Outline to start automatically with Windows, you can **disconnect from the VPN before you shut down or restart your computer**. Outline won't auto-start if you're disconnected.\n\nhttps://github.com/Jigsaw-Code/outline-apps/blob/102b817debf4a83b8162dbf9057c9b2e9142a5f0/client/electron/index.ts#L426\n\nIf Outline _still_ launches automatically even after you've disconnected from the VPN, please let us know. That would be a bug we need to investigate.", "I know this but I often forgot to do it. Now that I turned off fast boot and disabled startup apps, it doesn't cause any problems, but for a beginner it would be great if this option existed." ],
      "repository" : {
        "description" : "Outline Client and Manager, developed by Jigsaw. Outline Manager makes it easy to create your own VPN server. Outline Client lets you share access to your VPN with anyone in your network, giving them access to the free and open internet.",
        "homepage" : "https://getoutline.org/",
        "name" : "outline-apps",
        "fullName" : "Jigsaw-Code/outline-apps",
        "htmlUrl" : "https://github.com/Jigsaw-Code/outline-apps",
        "gitUrl" : "git://github.com/Jigsaw-Code/outline-apps.git",
        "sshUrl" : "git@github.com:Jigsaw-Code/outline-apps.git",
        "cloneUrl" : "https://github.com/Jigsaw-Code/outline-apps.git",
        "owner" : {
          "login" : "Jigsaw-Code",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1406,
        "stargazersCount" : 8823,
        "watchersCount" : 8823,
        "size" : 600789,
        "openIssuesCount" : 493,
        "subscribersCount" : 214,
        "pushedAt" : "2025-07-25T00:57:08Z",
        "languages" : {
          "C#" : 47419,
          "Java" : 59742,
          "C++" : 80752,
          "CSS" : 10496,
          "C" : 1563,
          "CMake" : 1960,
          "Go" : 227076,
          "HTML" : 4901,
          "NSIS" : 6749,
          "AIDL" : 3979,
          "TypeScript" : 998476,
          "Dockerfile" : 1297,
          "Shell" : 53409,
          "Batchfile" : 11358,
          "JavaScript" : 147188,
          "Objective-C" : 18048,
          "Swift" : 70894
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add an option to disable auto-start on login, which would allow users to manage the app without resorting to drastic measures like resetting network adapters.",
      "validationOrRequirement" : "The feature request is to add a toggle switch in the app's settings to control the auto-start behavior, which is currently not configurable at the OS level.",
      "attemptedFixes" : "The current workaround is to manually disable the application from the Windows Task Manager's startup tab, which is not user-friendly for everyone and needs to be done outside of the app.",
      "otherNotes" : "The issue is related to the auto-start behavior of the Outline Client on Windows, causing a network connectivity problem that can be fixed by performing a full 'Network Reset' through Windows settings after every reboot.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406727
  }, {
    "issueDTO" : {
      "id" : 2375018035,
      "title" : "Feature Request: Granual permission job system",
      "url" : "https://github.com/felixmosh/bull-board/issues/780",
      "repositoryName" : "felixmosh/bull-board",
      "description" : "**Problem**\r\nThere is [`readOnlyMode`](https://github.com/felixmosh/bull-board?tab=readme-ov-file#queue-options) but that is for the whole adapter. But it applies to the particular job on creation rather than runtime. Especially as the bull-board has grown in functionality over time with recent \"add job\" functionality\r\n\r\n**Suggestion**\r\nA finer control over which users can view/edit/... particular jobs. \r\n\r\nIt would be nice if there would be a function run per req that can determine \" CRUD-like functionality per adapter be able to:\r\n- view job\r\n- create new jobs\r\n- delete job\r\n- retry job\r\n- pause/play queues\r\n- clear queue\r\n\r\n**Reasoning**\r\nWe want to give access to bull-board (as an internal tool) depending on the roles of the user:\r\n- admin developer (full access)\r\n- developer (view permission and possible retry-job)\r\n- PM (view jobs, to help aid in troubleshooting operation issues)",
      "updatedAt" : 1753388838.000000000,
      "user" : "renarsvilnis",
      "userHtmlUrl" : "https://github.com/renarsvilnis",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3515099?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Yeah, that can be really cool,\r\nI you have some time, a PR will really help me to push this feature.", "Hi @renarsvilnis,\r\n\r\nI noticed this issue and would like to work on it. Is anyone currently assigned to this or actively working on it? If not, I would be happy to take it on :).\r\n\r\nThanks!", "No one is assigned to it, it can really help use.\r\nPay attention for current behavior, try to support it by default (if possible)", "Hi @felixmosh , \r\n\r\nI would love to work on implementing the granular permission job system as described. Could you please assign this issue to me so I can get started?", "I've added queue visibilty guard feature... that can show/hide queues to users" ],
      "repository" : {
        "description" : "\uD83C\uDFAF Queue background jobs inspector ",
        "homepage" : "",
        "name" : "bull-board",
        "fullName" : "felixmosh/bull-board",
        "htmlUrl" : "https://github.com/felixmosh/bull-board",
        "gitUrl" : "git://github.com/felixmosh/bull-board.git",
        "sshUrl" : "git@github.com:felixmosh/bull-board.git",
        "cloneUrl" : "https://github.com/felixmosh/bull-board.git",
        "owner" : {
          "login" : "felixmosh",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 424,
        "stargazersCount" : 2843,
        "watchersCount" : 2843,
        "size" : 17451,
        "openIssuesCount" : 26,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-24T20:27:50Z",
        "languages" : {
          "TypeScript" : 222077,
          "Dockerfile" : 145,
          "CSS" : 39289,
          "JavaScript" : 770,
          "EJS" : 705
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a granular permission job system to give access to bull-board (as an internal tool) depending on the roles of the user: admin developer (full access), developer (view permission and possible retry-job), PM (view jobs, to help aid in troubleshooting operation issues)",
      "validationOrRequirement" : "CRUD-like functionality per adapter: view job, create new jobs, delete job, retry job, pause/play queues, clear queue",
      "attemptedFixes" : "queue visibilty guard feature has been added, which can show/hide queues to users",
      "otherNotes" : "The current behavior should be supported by default, if possible, and pay attention to it. The feature would be nice to have, especially for troubleshooting operation issues.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406732
  }, {
    "issueDTO" : {
      "id" : 3261151937,
      "title" : "Add screenshots to readme",
      "url" : "https://github.com/yiisoft/error-handler/issues/148",
      "repositoryName" : "yiisoft/error-handler",
      "description" : "Need nice screenshots added to README.",
      "updatedAt" : 1753388831.000000000,
      "user" : "samdark",
      "userHtmlUrl" : "https://github.com/samdark",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47294?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Framework independent advanced error handler",
        "homepage" : "https://www.yiiframework.com/",
        "name" : "error-handler",
        "fullName" : "yiisoft/error-handler",
        "htmlUrl" : "https://github.com/yiisoft/error-handler",
        "gitUrl" : "git://github.com/yiisoft/error-handler.git",
        "sshUrl" : "git@github.com:yiisoft/error-handler.git",
        "cloneUrl" : "https://github.com/yiisoft/error-handler.git",
        "owner" : {
          "login" : "yiisoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15,
        "stargazersCount" : 20,
        "watchersCount" : 20,
        "size" : 382,
        "openIssuesCount" : 15,
        "subscribersCount" : 15,
        "pushedAt" : "2025-04-18T08:13:30Z",
        "languages" : {
          "CSS" : 20009,
          "PHP" : 160067
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add nice screenshots to the README file.",
      "validationOrRequirement" : "No specific validations or requirements mentioned.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned.",
      "otherNotes" : "The issue is about adding nice screenshots to the README file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406734
  }, {
    "issueDTO" : {
      "id" : 1650667115,
      "title" : "Add Conan package manager to Usage section of README.md",
      "url" : "https://github.com/uni-algo/uni-algo/issues/25",
      "repositoryName" : "uni-algo/uni-algo",
      "description" : "I've updated the conan package to 0.7.1. See: https://conan.io/center/uni-algo\r\n\r\nAdditionally, the Conan recipe behaves now like the CMake file. It builds by default a shared or static library but can be configured to emit a header only library. \r\n\r\nWith full support available now, you could add conan to the Usage section of the Readme.",
      "updatedAt" : 1753388677.000000000,
      "user" : "bigerl",
      "userHtmlUrl" : "https://github.com/bigerl",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/933146?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "BTW, [here](https://repology.org/project/uni-algo/versions) you can track the packaging status of the library in various repositories.", "> With full support available now, you could add conan to the Usage section of the Readme.\r\n\r\nI'm not familiar with Conan at all so it would be nice if someone could do it. PR is welcome.\r\n\r\n", "I've put it onto my todo list. If in the mean time someone else picks this up that's also fine with me. ;)", "I made this:  [https://github.com/HarryPehkonen/uni-algo-conan-example](https://github.com/HarryPehkonen/uni-algo-conan-example).  It may be useful for this use-case.\n\nIt demonstrates how to install uni-algo with Conan and then compile your project with CMake or even just g++.\n\nGitHub Actions compile and test in Linux, macOS, and Windows, but that's through CMake.  There are instructions for building with g++ manually.\n\nI'm not sure if I did everything correctly, but the documentation seems to confirm my findings:\n\n  -  The header-only form is missing a lot of functionality that the other forms provide\n  -  The shared library form can't be built in Windows\n\nIf I'm wrong about any of the above, please let me know." ],
      "repository" : {
        "description" : "Unicode Algorithms Implementation for C/C++",
        "homepage" : "",
        "name" : "uni-algo",
        "fullName" : "uni-algo/uni-algo",
        "htmlUrl" : "https://github.com/uni-algo/uni-algo",
        "gitUrl" : "git://github.com/uni-algo/uni-algo.git",
        "sshUrl" : "git@github.com:uni-algo/uni-algo.git",
        "cloneUrl" : "https://github.com/uni-algo/uni-algo.git",
        "owner" : {
          "login" : "uni-algo",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 26,
        "stargazersCount" : 299,
        "watchersCount" : 299,
        "size" : 2429,
        "openIssuesCount" : 7,
        "subscribersCount" : 15,
        "pushedAt" : "2024-01-05T14:06:22Z",
        "languages" : {
          "C++" : 2656788,
          "C" : 36682,
          "CMake" : 14372
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add Conan package manager to Usage section of README.md",
      "validationOrRequirement" : "add Conan package manager to Usage section of README.md, with full support available now",
      "attemptedFixes" : "Conan package manager updated to 0.7.1, Conan recipe behaves like CMake file, GitHub Actions test in Linux, macOS, and Windows, manual build instructions for g++",
      "otherNotes" : "Conan package manager updated to 0.7.1, Conan recipe behaves like CMake file, supports shared or static library and header-only library, GitHub Actions test in Linux, macOS, and Windows, manual build instructions for g++",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406739
  }, {
    "issueDTO" : {
      "id" : 3261144166,
      "title" : "[ACCESSIBILITY] Add Comprehensive Accessibility Features",
      "url" : "https://github.com/pieces-app/cli-agent/issues/381",
      "repositoryName" : "pieces-app/cli-agent",
      "description" : "## ??? Accessibility: Making Pieces CLI Usable for Everyone\n\n### Summary\nThe Pieces CLI currently lacks essential accessibility features, making it difficult or impossible for users with disabilities to use effectively. This includes users who rely on screen readers, have visual impairments, motor disabilities, or cognitive differences. Implementing comprehensive accessibility features is not just about compliance???it's about ensuring all developers can benefit from Pieces.\n\n### Current Accessibility Gaps\n\n#### 1. \uD83D\uDC41??? Visual Accessibility Issues\n\n**Problems:**\n- Heavy reliance on color for information (red=error, green=success)\n- No high contrast mode\n- Small text with no size options\n- ASCII art that screen readers can't parse\n- No alternative text for visual elements\n\n**Impact:**\n- Color-blind users can't distinguish between success/error\n- Low vision users struggle with small text\n- Screen reader users hear gibberish for ASCII art\n\n#### 2. \uD83D\uDD0A Screen Reader Compatibility\n\n**Problems:**\n- Output not optimized for screen readers\n- Progress indicators use visual-only feedback\n- Table formatting breaks screen reader flow\n- No semantic markup for different content types\n- Interactive menus not properly announced\n\n#### 3. ?????? Keyboard Navigation\n\n**Problems:**\n- Some features require mouse interaction\n- No documented keyboard shortcuts\n- Tab navigation not properly implemented\n- No skip navigation options\n- Focus indicators missing or unclear\n\n#### 4. \uD83E\uDDE0 Cognitive Accessibility\n\n**Problems:**\n- Complex command syntax without simpler alternatives\n- Technical jargon without plain language options\n- No command memory aids\n- Overwhelming output without summary options\n- No customizable complexity levels\n\n### Proposed Comprehensive Solution\n\n#### Phase 1: Visual Accessibility\n\n```python\n# src/pieces/accessibility/visual.py\nfrom enum import Enum\nfrom typing import Optional, Tuple\nimport os\n\nclass ColorScheme(Enum):\n    \"\"\"Accessible color schemes\"\"\"\n    DEFAULT = \"default\"\n    HIGH_CONTRAST = \"high_contrast\"\n    MONOCHROME = \"monochrome\"\n    DEUTERANOPIA = \"deuteranopia\"  # Red-green colorblind\n    PROTANOPIA = \"protanopia\"      # Red-green colorblind\n    TRITANOPIA = \"tritanopia\"      # Blue-yellow colorblind\n\nclass VisualAccessibility:\n    \"\"\"Visual accessibility features\"\"\"\n    \n    def __init__(self):\n        self.color_scheme = self._detect_preferred_scheme()\n        self.text_size = self._get_text_size()\n        self.use_unicode = self._check_unicode_support()\n    \n    def _detect_preferred_scheme(self) -> ColorScheme:\n        \"\"\"Detect user's preferred color scheme\"\"\"\n        # Check environment variables\n        if os.environ.get('PIECES_COLOR_SCHEME'):\n            return ColorScheme(os.environ['PIECES_COLOR_SCHEME'])\n        \n        # Check system preferences\n        if os.environ.get('NO_COLOR'):\n            return ColorScheme.MONOCHROME\n        \n        # Check for high contrast mode (Windows)\n        if sys.platform == 'win32':\n            import winreg\n            try:\n                key = winreg.OpenKey(\n                    winreg.HKEY_CURRENT_USER,\n                    r'Control Panel\\Accessibility\\HighContrast'\n                )\n                flags = winreg.QueryValueEx(key, 'Flags')[0]\n                if flags & 1:  # HCF_HIGHCONTRASTON\n                    return ColorScheme.HIGH_CONTRAST\n            except:\n                pass\n        \n        return ColorScheme.DEFAULT\n    \n    def get_color(self, \n                  semantic_color: str,\n                  text: str = \"\") -> str:\n        \"\"\"Get accessible color for semantic meaning\"\"\"\n        \n        color_map = {\n            ColorScheme.DEFAULT: {\n                'success': 'green',\n                'error': 'red',\n                'warning': 'yellow',\n                'info': 'blue',\n                'muted': 'dim'\n            },\n            ColorScheme.HIGH_CONTRAST: {\n                'success': 'bright_white on_black',\n                'error': 'bright_yellow on_black',\n                'warning': 'bright_cyan on_black',\n                'info': 'bright_white on_black',\n                'muted': 'white on_black'\n            },\n            ColorScheme.MONOCHROME: {\n                # Use text decorations instead of colors\n                'success': 'bold',\n                'error': 'reverse',\n                'warning': 'underline',\n                'info': 'normal',\n                'muted': 'dim'\n            },\n            ColorScheme.DEUTERANOPIA: {\n                # Avoid red-green combinations\n                'success': 'blue',\n                'error': 'bright_yellow',\n                'warning': 'bright_cyan',\n                'info': 'bright_blue',\n                'muted': 'dim'\n            }\n        }\n        \n        scheme_colors = color_map.get(self.color_scheme, color_map[ColorScheme.DEFAULT])\n        color = scheme_colors.get(semantic_color, 'normal')\n        \n        # Add text indicators for critical information\n        if self.color_scheme == ColorScheme.MONOCHROME:\n            if semantic_color == 'success':\n                text = f\"??? {text}\"\n            elif semantic_color == 'error':\n                text = f\"??? {text}\"\n            elif semantic_color == 'warning':\n                text = f\"??? {text}\"\n        \n        return f\"[{color}]{text}[/{color}]\"\n    \n    def format_for_accessibility(self, \n                               content: str,\n                               content_type: str = \"text\") -> str:\n        \"\"\"Format content for accessibility\"\"\"\n        \n        if content_type == \"ascii_art\":\n            # Replace ASCII art with text description\n            return self._ascii_to_text(content)\n        \n        elif content_type == \"table\":\n            # Format table for screen readers\n            return self._format_table_accessible(content)\n        \n        elif content_type == \"code\":\n            # Add syntax markers for screen readers\n            return self._format_code_accessible(content)\n        \n        return content\n    \n    def _ascii_to_text(self, ascii_art: str) -> str:\n        \"\"\"Convert ASCII art to screen reader friendly text\"\"\"\n        # Map common ASCII art patterns to descriptions\n        patterns = {\n            r'#{10,}': '[Section Separator]',\n            r'-{10,}': '[Horizontal Line]',\n            r'={10,}': '[Double Line]',\n            r'\\*{10,}': '[Decorative Border]'\n        }\n        \n        import re\n        result = ascii_art\n        \n        for pattern, description in patterns.items():\n            result = re.sub(pattern, description, result)\n        \n        return result\n```\n\n#### Phase 2: Screen Reader Support\n\n```python\n# src/pieces/accessibility/screen_reader.py\nfrom typing import Optional, List, Dict\nimport platform\n\nclass ScreenReaderSupport:\n    \"\"\"Screen reader compatibility features\"\"\"\n    \n    def __init__(self):\n        self.screen_reader_active = self._detect_screen_reader()\n        self.verbosity_level = self._get_verbosity_level()\n    \n    def _detect_screen_reader(self) -> bool:\n        \"\"\"Detect if screen reader is active\"\"\"\n        # Windows: Check for common screen readers\n        if platform.system() == 'Windows':\n            import ctypes\n            try:\n                # Check if screen reader flag is set\n                SPI_GETSCREENREADER = 0x0046\n                is_active = ctypes.c_bool()\n                ctypes.windll.user32.SystemParametersInfoW(\n                    SPI_GETSCREENREADER, 0, \n                    ctypes.byref(is_active), 0\n                )\n                return is_active.value\n            except:\n                pass\n        \n        # macOS: Check for VoiceOver\n        elif platform.system() == 'Darwin':\n            try:\n                import subprocess\n                result = subprocess.run(\n                    ['defaults', 'read', 'com.apple.universalaccess', 'voiceOverOnOffKey'],\n                    capture_output=True\n                )\n                return result.returncode == 0\n            except:\n                pass\n        \n        # Linux: Check for Orca\n        elif platform.system() == 'Linux':\n            return 'ORCA' in os.environ\n        \n        # Check environment variable\n        return os.environ.get('SCREEN_READER') == '1'\n    \n    def announce(self, \n                message: str,\n                priority: str = \"normal\",\n                interrupt: bool = False):\n        \"\"\"Announce message to screen reader\"\"\"\n        \n        if not self.screen_reader_active:\n            return\n        \n        # Format message for screen readers\n        formatted = self._format_for_speech(message)\n        \n        # Platform-specific announcement\n        if platform.system() == 'Windows':\n            self._announce_windows(formatted, priority, interrupt)\n        elif platform.system() == 'Darwin':\n            self._announce_macos(formatted, priority, interrupt)\n        else:\n            self._announce_linux(formatted, priority, interrupt)\n    \n    def _format_for_speech(self, text: str) -> str:\n        \"\"\"Format text for speech synthesis\"\"\"\n        # Expand abbreviations\n        abbreviations = {\n            'CLI': 'command line interface',\n            'API': 'A P I',\n            'URL': 'U R L',\n            'OS': 'operating system',\n            'ID': 'identifier'\n        }\n        \n        result = text\n        for abbr, expansion in abbreviations.items():\n            result = result.replace(abbr, expansion)\n        \n        # Add pauses for readability\n        result = result.replace('.', '. ')\n        result = result.replace(',', ', ')\n        \n        return result\n    \n    def format_output(self, \n                     output: str,\n                     output_type: str = \"general\") -> str:\n        \"\"\"Format output for screen reader compatibility\"\"\"\n        \n        if not self.screen_reader_active:\n            return output\n        \n        if output_type == \"list\":\n            return self._format_list_for_sr(output)\n        elif output_type == \"table\":\n            return self._format_table_for_sr(output)\n        elif output_type == \"menu\":\n            return self._format_menu_for_sr(output)\n        elif output_type == \"progress\":\n            return self._format_progress_for_sr(output)\n        \n        return output\n    \n    def _format_list_for_sr(self, items: List[str]) -> str:\n        \"\"\"Format list for screen readers\"\"\"\n        result = [f\"List with {len(items)} items:\"]\n        \n        for i, item in enumerate(items, 1):\n            result.append(f\"Item {i} of {len(items)}: {item}\")\n        \n        return \"\\n\".join(result)\n    \n    def _format_table_for_sr(self, table_data: List[Dict]) -> str:\n        \"\"\"Format table data for screen readers\"\"\"\n        if not table_data:\n            return \"Empty table\"\n        \n        result = [f\"Table with {len(table_data)} rows\"]\n        headers = list(table_data[0].keys())\n        result.append(f\"Columns: {', '.join(headers)}\")\n        \n        for i, row in enumerate(table_data, 1):\n            result.append(f\"\\nRow {i}:\")\n            for header in headers:\n                result.append(f\"  {header}: {row.get(header, 'None')}\")\n        \n        return \"\\n\".join(result)\n```\n\n#### Phase 3: Keyboard Navigation\n\n```python\n# src/pieces/accessibility/keyboard.py\nfrom typing import Dict, Callable, Optional, List\nimport sys\n\nclass KeyboardNavigation:\n    \"\"\"Enhanced keyboard navigation support\"\"\"\n    \n    def __init__(self):\n        self.shortcuts: Dict[str, Callable] = {}\n        self.navigation_mode = False\n        self.focus_stack: List[str] = []\n    \n    def register_shortcut(self, \n                         key_combo: str,\n                         action: Callable,\n                         description: str):\n        \"\"\"Register a keyboard shortcut\"\"\"\n        self.shortcuts[key_combo] = {\n            'action': action,\n            'description': description\n        }\n    \n    def setup_default_shortcuts(self):\n        \"\"\"Setup default keyboard shortcuts\"\"\"\n        defaults = {\n            'ctrl+h': {\n                'action': self.show_help,\n                'description': 'Show help'\n            },\n            'ctrl+c': {\n                'action': self.cancel_operation,\n                'description': 'Cancel current operation'\n            },\n            'ctrl+l': {\n                'action': self.clear_screen,\n                'description': 'Clear screen'\n            },\n            'tab': {\n                'action': self.next_element,\n                'description': 'Next element'\n            },\n            'shift+tab': {\n                'action': self.previous_element,\n                'description': 'Previous element'\n            },\n            'enter': {\n                'action': self.activate_element,\n                'description': 'Activate current element'\n            },\n            'escape': {\n                'action': self.exit_navigation,\n                'description': 'Exit navigation mode'\n            }\n        }\n        \n        self.shortcuts.update(defaults)\n    \n    def create_accessible_menu(self, \n                             title: str,\n                             options: List[Dict[str, Any]]) -> Optional[int]:\n        \"\"\"Create keyboard-navigable menu\"\"\"\n        from rich.console import Console\n        from rich.table import Table\n        \n        console = Console()\n        current_index = 0\n        \n        while True:\n            # Clear and redraw\n            console.clear()\n            \n            # Show title\n            console.print(f\"\\n[bold]{title}[/bold]\")\n            console.print(\"Use arrow keys to navigate, Enter to select, Esc to cancel\\n\")\n            \n            # Create table with focus indicator\n            table = Table(show_header=False, box=None)\n            table.add_column(\"\", width=3)\n            table.add_column(\"Option\")\n            table.add_column(\"Description\", style=\"dim\")\n            \n            for i, option in enumerate(options):\n                indicator = \"???\" if i == current_index else \" \"\n                style = \"bold cyan\" if i == current_index else \"normal\"\n                \n                table.add_row(\n                    indicator,\n                    f\"[{style}]{option['name']}[/{style}]\",\n                    option.get('description', '')\n                )\n            \n            console.print(table)\n            \n            # Show current item details for screen readers\n            if screen_reader.active:\n                current = options[current_index]\n                screen_reader.announce(\n                    f\"Selected: {current['name']}. {current.get('description', '')}\",\n                    priority=\"high\"\n                )\n            \n            # Get input\n            key = self.get_key()\n            \n            if key == 'up':\n                current_index = (current_index - 1) % len(options)\n            elif key == 'down':\n                current_index = (current_index + 1) % len(options)\n            elif key == 'enter':\n                return current_index\n            elif key == 'escape':\n                return None\n            \n            # Handle letter shortcuts\n            elif len(key) == 1 and key.isalpha():\n                # Jump to first item starting with letter\n                for i, option in enumerate(options):\n                    if option['name'].lower().startswith(key.lower()):\n                        current_index = i\n                        break\n```\n\n#### Phase 4: Cognitive Accessibility\n\n```python\n# src/pieces/accessibility/cognitive.py\nfrom typing import List, Dict, Optional\nimport difflib\n\nclass CognitiveAccessibility:\n    \"\"\"Features for cognitive accessibility\"\"\"\n    \n    def __init__(self):\n        self.complexity_level = self._get_complexity_level()\n        self.command_history = []\n        self.common_mistakes = {}\n    \n    def _get_complexity_level(self) -> str:\n        \"\"\"Get user's preferred complexity level\"\"\"\n        return os.environ.get('PIECES_COMPLEXITY', 'normal')\n    \n    def simplify_command(self, command: str) -> str:\n        \"\"\"Provide simplified command alternatives\"\"\"\n        simplifications = {\n            'pieces list assets --filter language:python --sort created:desc': \n                'pieces list python',\n            'pieces create asset --name \"My Code\" --language python':\n                'pieces save --python \"My Code\"',\n            'pieces conversation create --name \"New Chat\"':\n                'pieces chat new \"New Chat\"'\n        }\n        \n        return simplifications.get(command, command)\n    \n    def explain_command(self, command: str) -> str:\n        \"\"\"Explain what a command does in plain language\"\"\"\n        parts = command.split()\n        \n        explanations = {\n            'list': 'Shows all your saved items',\n            'create': 'Makes a new item',\n            'delete': 'Removes an item',\n            'search': 'Finds items matching your text',\n            'ask': 'Ask AI assistant a question',\n            'open': 'Opens an item for viewing',\n            'share': 'Shares an item with others'\n        }\n        \n        if len(parts) > 1 and parts[1] in explanations:\n            base_explain = explanations[parts[1]]\n            \n            # Add context\n            if 'assets' in command:\n                return f\"{base_explain} (code snippets)\"\n            elif 'conversation' in command:\n                return f\"{base_explain} (chat histories)\"\n            \n            return base_explain\n        \n        return \"I can help explain this command. Try 'pieces help explain <command>'\"\n    \n    def suggest_next_command(self, \n                           previous_command: str,\n                           context: Dict[str, Any]) -> List[str]:\n        \"\"\"Suggest logical next commands\"\"\"\n        \n        suggestions = []\n        \n        if 'list' in previous_command:\n            suggestions.extend([\n                \"pieces open <id>  # Open one of the items\",\n                \"pieces search <text>  # Search within items\",\n                \"pieces create  # Create a new item\"\n            ])\n        \n        elif 'create' in previous_command:\n            asset_id = context.get('created_id')\n            if asset_id:\n                suggestions.extend([\n                    f\"pieces open {asset_id}  # View what you created\",\n                    f\"pieces share {asset_id}  # Share with others\",\n                    \"pieces list  # See all items\"\n                ])\n        \n        elif 'search' in previous_command:\n            suggestions.extend([\n                \"pieces open <id>  # Open a search result\",\n                \"pieces search <different-term>  # Try different search\",\n                \"pieces list  # Show all items\"\n            ])\n        \n        return suggestions\n    \n    def create_command_wizard(self):\n        \"\"\"Interactive wizard for complex commands\"\"\"\n        from rich.prompt import Prompt, Confirm, IntPrompt\n        \n        console.print(\"\\n[bold]Command Helper Wizard[/bold]\")\n        console.print(\"I'll help you build the right command.\\n\")\n        \n        # What do you want to do?\n        action = Prompt.ask(\n            \"What would you like to do?\",\n            choices=[\"find\", \"save\", \"view\", \"share\", \"ask\"],\n            default=\"find\"\n        )\n        \n        if action == \"find\":\n            search_term = Prompt.ask(\"What are you looking for?\")\n            \n            # Build command\n            command = f\"pieces search {search_term}\"\n            \n            # Offer refinements\n            if Confirm.ask(\"Only search in a specific language?\"):\n                language = Prompt.ask(\"Which language?\", \n                                    choices=[\"python\", \"javascript\", \"java\", \"other\"])\n                command += f\" --language {language}\"\n        \n        elif action == \"save\":\n            # Guide through save process\n            name = Prompt.ask(\"What should we call this snippet?\")\n            \n            # Detect or ask for language\n            language = Prompt.ask(\n                \"What programming language?\",\n                choices=[\"python\", \"javascript\", \"java\", \"other\"],\n                default=\"python\"\n            )\n            \n            command = f\"pieces create --name '{name}' --language {language}\"\n        \n        # Show and explain command\n        console.print(f\"\\n[green]Generated command:[/green] {command}\")\n        console.print(f\"[dim]This will: {self.explain_command(command)}[/dim]\")\n        \n        if Confirm.ask(\"\\nRun this command?\", default=True):\n            return command\n        \n        return None\n```\n\n#### Phase 5: Accessibility Settings & Configuration\n\n```python\n# src/pieces/accessibility/config.py\nfrom dataclasses import dataclass\nfrom typing import Optional\nimport json\n\n@dataclass\nclass AccessibilityConfig:\n    \"\"\"Accessibility configuration\"\"\"\n    \n    # Visual\n    color_scheme: ColorScheme = ColorScheme.DEFAULT\n    text_size: str = \"normal\"  # small, normal, large\n    use_unicode: bool = True\n    reduce_motion: bool = False\n    \n    # Audio  \n    screen_reader_mode: bool = False\n    audio_cues: bool = False\n    speech_rate: float = 1.0\n    \n    # Interaction\n    keyboard_navigation: bool = True\n    sticky_keys: bool = False\n    slow_keys: bool = False\n    bounce_keys: bool = False\n    \n    # Cognitive\n    complexity_level: str = \"normal\"  # simple, normal, advanced\n    show_hints: bool = True\n    auto_complete: bool = True\n    command_memory: bool = True\n    \n    # Output\n    plain_language: bool = False\n    verbose_mode: bool = False\n    quiet_mode: bool = False\n    \n    @classmethod\n    def load(cls) -> 'AccessibilityConfig':\n        \"\"\"Load accessibility configuration\"\"\"\n        config_path = Path.home() / '.config' / 'pieces' / 'accessibility.json'\n        \n        if config_path.exists():\n            try:\n                with open(config_path) as f:\n                    data = json.load(f)\n                return cls(**data)\n            except:\n                pass\n        \n        # Load from environment\n        return cls.from_environment()\n    \n    @classmethod \n    def from_environment(cls) -> 'AccessibilityConfig':\n        \"\"\"Load settings from environment variables\"\"\"\n        config = cls()\n        \n        # Visual\n        if os.environ.get('NO_COLOR'):\n            config.color_scheme = ColorScheme.MONOCHROME\n        \n        # Screen reader\n        if os.environ.get('SCREEN_READER'):\n            config.screen_reader_mode = True\n            config.verbose_mode = True\n        \n        # Cognitive\n        if os.environ.get('PIECES_SIMPLE_MODE'):\n            config.complexity_level = 'simple'\n            config.plain_language = True\n        \n        return config\n    \n    def save(self):\n        \"\"\"Save accessibility configuration\"\"\"\n        config_path = Path.home() / '.config' / 'pieces' / 'accessibility.json'\n        config_path.parent.mkdir(parents=True, exist_ok=True)\n        \n        with open(config_path, 'w') as f:\n            json.dump(self.__dict__, f, indent=2)\n\nclass AccessibilityManager:\n    \"\"\"Central accessibility manager\"\"\"\n    \n    def __init__(self):\n        self.config = AccessibilityConfig.load()\n        self.visual = VisualAccessibility()\n        self.screen_reader = ScreenReaderSupport()\n        self.keyboard = KeyboardNavigation()\n        self.cognitive = CognitiveAccessibility()\n    \n    def setup(self):\n        \"\"\"Setup accessibility features\"\"\"\n        # Configure based on settings\n        if self.config.screen_reader_mode:\n            self.enable_screen_reader_mode()\n        \n        if self.config.keyboard_navigation:\n            self.keyboard.setup_default_shortcuts()\n        \n        if self.config.reduce_motion:\n            self.disable_animations()\n    \n    def format_output(self, \n                     content: str,\n                     content_type: str = \"text\") -> str:\n        \"\"\"Format output according to accessibility needs\"\"\"\n        \n        # Apply visual formatting\n        content = self.visual.format_for_accessibility(content, content_type)\n        \n        # Apply screen reader formatting\n        if self.config.screen_reader_mode:\n            content = self.screen_reader.format_output(content, content_type)\n        \n        # Apply cognitive simplifications\n        if self.config.plain_language:\n            content = self.cognitive.simplify_text(content)\n        \n        return content\n\n# Global accessibility manager\naccessibility = AccessibilityManager()\n```\n\n### Testing Accessibility\n\n```python\n# tests/test_accessibility.py\nimport pytest\nfrom unittest.mock import patch\n\nclass TestAccessibility:\n    def test_color_blind_mode(self):\n        \"\"\"Test color blind friendly colors\"\"\"\n        visual = VisualAccessibility()\n        visual.color_scheme = ColorScheme.DEUTERANOPIA\n        \n        # Should avoid red-green\n        success_color = visual.get_color('success', 'OK')\n        assert 'red' not in success_color.lower()\n        assert 'green' not in success_color.lower()\n    \n    def test_screen_reader_formatting(self):\n        \"\"\"Test screen reader output\"\"\"\n        sr = ScreenReaderSupport()\n        sr.screen_reader_active = True\n        \n        # Test table formatting\n        table_data = [\n            {'name': 'Asset 1', 'type': 'Python'},\n            {'name': 'Asset 2', 'type': 'JavaScript'}\n        ]\n        \n        output = sr.format_output(table_data, 'table')\n        assert 'Row 1:' in output\n        assert 'name: Asset 1' in output\n    \n    def test_keyboard_navigation(self):\n        \"\"\"Test keyboard navigation\"\"\"\n        kb = KeyboardNavigation()\n        kb.setup_default_shortcuts()\n        \n        # Test shortcut registration\n        assert 'ctrl+h' in kb.shortcuts\n        assert kb.shortcuts['ctrl+h']['description'] == 'Show help'\n```\n\n### Implementation Timeline\n\n#### Week 1: Foundation\n- [ ] Implement color scheme system\n- [ ] Add NO_COLOR support\n- [ ] Create accessibility configuration\n- [ ] Add text-only mode\n\n#### Week 2: Screen Reader\n- [ ] Implement screen reader detection\n- [ ] Format output for screen readers\n- [ ] Add semantic markup\n- [ ] Test with major screen readers\n\n#### Week 3: Keyboard & Cognitive\n- [ ] Implement keyboard navigation\n- [ ] Add command shortcuts\n- [ ] Create command wizard\n- [ ] Add plain language mode\n\n#### Week 4: Testing & Documentation\n- [ ] Test with real users\n- [ ] Create accessibility guide\n- [ ] Add automated testing\n- [ ] Update all commands\n\n### Success Metrics\n- WCAG 2.1 AA compliance\n- Screen reader compatibility > 95%\n- Keyboard-only navigation for all features\n- User satisfaction from accessibility users > 4/5\n\n### References\n- [WCAG 2.1 Guidelines](https://www.w3.org/WAI/WCAG21/quickref/)\n- [Command Line Accessibility](https://www.tpgi.com/basic-screen-reader-commands-for-accessibility-testing/)\n- [Python Accessibility Guide](https://docs.python.org/3/library/accessibility.html)",
      "updatedAt" : 1753388656.000000000,
      "user" : "tsavo-at-pieces",
      "userHtmlUrl" : "https://github.com/tsavo-at-pieces",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/102485237?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Pieces CLI for interacting with Pieces OS",
        "homepage" : "https://docs.pieces.app/products/cli",
        "name" : "cli-agent",
        "fullName" : "pieces-app/cli-agent",
        "htmlUrl" : "https://github.com/pieces-app/cli-agent",
        "gitUrl" : "git://github.com/pieces-app/cli-agent.git",
        "sshUrl" : "git@github.com:pieces-app/cli-agent.git",
        "cloneUrl" : "https://github.com/pieces-app/cli-agent.git",
        "owner" : {
          "login" : "pieces-app",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 84,
        "watchersCount" : 84,
        "size" : 24515,
        "openIssuesCount" : 56,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-24T20:10:45Z",
        "languages" : {
          "PowerShell" : 2058,
          "Shell" : 2452,
          "Ruby" : 193,
          "Python" : 7393011
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add comprehensive accessibility features to the Pieces CLI to make it usable for users with disabilities.",
      "validationOrRequirement" : "WCAG 2.1 AA compliance, screen reader compatibility, keyboard-only navigation, and user satisfaction",
      "attemptedFixes" : "The issue proposes a four-phase solution: visual accessibility, screen reader support, keyboard navigation, and cognitive accessibility. The implementation timeline is divided into four weeks, with specific tasks for each week.",
      "otherNotes" : "The issue aims to add comprehensive accessibility features to the Pieces CLI, making it usable for users with disabilities. The main goal is to ensure that all developers can benefit from Pieces. The issue proposes a four-phase solution: visual accessibility, screen reader support, keyboard navigation, and cognitive accessibility. The implementation timeline is divided into four weeks, with specific tasks for each week. The success metrics include WCAG 2.1 AA compliance, screen reader compatibility, keyboard-only navigation, and user satisfaction. The references provided include the WCAG 2.1 guidelines, command line accessibility, and Python accessibility guide.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406747
  }, {
    "issueDTO" : {
      "id" : 3259982902,
      "title" : "[Community] Member Profile: Naman Verma",
      "url" : "https://github.com/layer5io/layer5/issues/6656",
      "repositoryName" : "layer5io/layer5",
      "description" : "### Current Behavior\n\nThe following individual has been a consistent contributor and community member. Their demonstrated willingness to help others and desire to help improve projects here align with the community's culture.\n\n### Desired Situation\nLet's recognize this individual as a contributor and community member by creating a profile on https://layer5.io/community/members.\n\n- GitHub:           @Namanv0509 \n- Twitter:          <!-- username only -->\n- LinkedIn:         <!-- <profilename> only https://www.linkedin.com/in/<profilename> -->\n- Layer5 Cloud:     <!-- <user ID> only UUID https://cloud.layer5.io/user/<uuid> -->\n- Profile Picture:   <!-- hyperlink to their picture -->\n\nA detailed explanation on how to set up a community member profile can be found in the [CONTRIBUTING.md](https://github.com/layer5io/layer5/blob/master/CONTRIBUTING.md)\n\n---\n\n### Contributor Resources\n\nThe layer5.io website uses Gatsby, React, and GitHub Pages. Site content is found under the [`master` branch](https://github.com/layer5io/layer5/tree/master).\n- See [contributing instructions](https://github.com/layer5io/layer5/blob/master/CONTRIBUTING.md)\n- See Layer5 site designs in this [Figma project](https://www.figma.com/file/5ZwEkSJwUPitURD59YHMEN/Layer5-Designs). Join the [Layer5 Community](https://slack.layer5.io) for access.\n",
      "updatedAt" : 1753388621.000000000,
      "user" : "vr-varad",
      "userHtmlUrl" : "https://github.com/vr-varad",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/114755221?v=4",
      "labels" : [ "framework/gatsby", "area/community", "help wanted", "language/markdown", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@Namanv0509, can you please provide your social media handles here?", "- Twitter:  https://x.com/explorers_111\n- Linkedin: https://www.linkedin.com/in/naman-verma-6948a72a5\n- Layer5 Cloud: https://cloud.layer5.io/user/f6bedf26-411c-474b-89cb-3d7cf9f97ef2\n- Profile Picture: { will be be uploaded soon}", "Is anyone working on this issue ? ", "> Is anyone working on this issue ?\n\nNope, would you like to handle it?", "@LibenHailu, can I work on it if it's not yet assigned? ", "@LibenHailu  I'm working on this  kindly assign to me ..", "@Rajesh-Nagarajan-11, @LibenHailu, I've submitted the PR. It's my bad, I had forked earlier and edited the file, and waited for @Namanv0509 to submit the profile picture. @LibenHailu, kindly review the PR when convenient. ", "@Dinokojt7  No issues You can proceed ", "![Image](https://github.com/user-attachments/assets/778f7028-8b41-44ed-b4ac-688c5ab4f1f1)\n\n\n\n@Dinokojt7  ^^" ],
      "repository" : {
        "description" : "Layer5, expect more from your infrastructure",
        "homepage" : "https://layer5.io",
        "name" : "layer5",
        "fullName" : "layer5io/layer5",
        "htmlUrl" : "https://github.com/layer5io/layer5",
        "gitUrl" : "git://github.com/layer5io/layer5.git",
        "sshUrl" : "git@github.com:layer5io/layer5.git",
        "cloneUrl" : "https://github.com/layer5io/layer5.git",
        "owner" : {
          "login" : "layer5io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1365,
        "stargazersCount" : 937,
        "watchersCount" : 937,
        "size" : 11706603,
        "openIssuesCount" : 139,
        "subscribersCount" : 24,
        "pushedAt" : "2025-07-25T00:29:58Z",
        "languages" : {
          "MDX" : 3549387,
          "Dockerfile" : 679,
          "CSS" : 19435,
          "Shell" : 167,
          "Makefile" : 1647,
          "JavaScript" : 13729809,
          "HTML" : 345971
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Recognize Naman Verma as a contributor and community member by creating a profile on https://layer5.io/community/members",
      "validationOrRequirement" : "Provide social media handles, profile picture, and Layer5 Cloud user ID",
      "attemptedFixes" : "PR submitted by @Rajesh-Nagarajan-11, PR review requested by @LibenHailu, @Dinokojt7 confirmed no issues with the PR",
      "otherNotes" : "A detailed explanation on how to set up a community member profile can be found in the CONTRIBUTING.md",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406751
  }, {
    "issueDTO" : {
      "id" : 3146361467,
      "title" : "adding github-actions to automate the PR process.",
      "url" : "https://github.com/Bhavya1352/eventmappr/issues/17",
      "repositoryName" : "Bhavya1352/eventmappr",
      "description" : "I want to add github actions to this project, and you'll get two main advantage from this:\n\n - you can have a preview of the website for the PR created tht can help you understand how the PR is impacting the project.\n - the github actions will automatically push the PR to deploy it in vercel.",
      "updatedAt" : 1753388432.000000000,
      "user" : "trahulprabhu38",
      "userHtmlUrl" : "https://github.com/trahulprabhu38",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/167653990?v=4",
      "labels" : [ "SSOC S4", "Intermediate", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@trahulprabhu38 You have been assigned , you can start working on this", "Can i work on this?", "@GauravKarakoti You have experience with this right? I mean you know it well?", "> @GauravKarakoti You have experience with this right? I mean you know it well?\n\nYes" ],
      "repository" : {
        "description" : null,
        "homepage" : "https://eventmappr.vercel.app",
        "name" : "eventmappr",
        "fullName" : "Bhavya1352/eventmappr",
        "htmlUrl" : "https://github.com/Bhavya1352/eventmappr",
        "gitUrl" : "git://github.com/Bhavya1352/eventmappr.git",
        "sshUrl" : "git@github.com:Bhavya1352/eventmappr.git",
        "cloneUrl" : "https://github.com/Bhavya1352/eventmappr.git",
        "owner" : {
          "login" : "Bhavya1352",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 69,
        "stargazersCount" : 34,
        "watchersCount" : 34,
        "size" : 25214,
        "openIssuesCount" : 35,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T15:40:40Z",
        "languages" : {
          "CSS" : 156316,
          "JavaScript" : 457887,
          "HTML" : 96609
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Automate the PR process using GitHub Actions",
      "validationOrRequirement" : "no specific requirements mentioned",
      "attemptedFixes" : "",
      "otherNotes" : "PR will be automatically deployed to Vercel and provide a website preview for review",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406753
  }, {
    "issueDTO" : {
      "id" : 3261133595,
      "title" : "[UX] Major User Experience Improvements Needed",
      "url" : "https://github.com/pieces-app/cli-agent/issues/379",
      "repositoryName" : "pieces-app/cli-agent",
      "description" : "## \uD83C\uDFA8 UX Enhancement: Comprehensive User Experience Improvements\n\n### Summary\nThe Pieces CLI has several user experience issues that impact discoverability, usability, and overall satisfaction. These range from confusing command names and poor error messages to missing progress indicators and inconsistent output formatting.\n\n### Key UX Issues Identified\n\n#### 1. \uD83D\uDD0D Command Discoverability Problems\n\n**Current Issues:**\n- Some commands have non-intuitive names (e.g., `execute` vs `run`)\n- No built-in command search functionality\n- Limited command suggestions beyond typo correction\n- Confusing distinction between `pieces run` (interactive) and `pieces execute` (run code)\n\n**Example of Confusion:**\n```bash\n# What's the difference?\npieces run          # Starts interactive session\npieces execute      # Runs a code snippet\npieces open         # Opens... what exactly?\n\n# User expects:\npieces repl         # Clear: starts REPL\npieces run-snippet  # Clear: executes code\npieces open-asset   # Clear: opens an asset\n```\n\n#### 2. ??? Poor Error Messages\n\n**Current State:**\n```bash\n# Unhelpful error\n$ pieces invalid-command\nError: UNKNOWN EXCEPTION\n\n# No actionable information\n$ pieces list assets --invalid-flag\nError: Invalid argument\n\n# Technical jargon exposed\n$ pieces ask \"question\"\nError: WebSocket connection failed: [Errno 61] Connection refused\n```\n\n**Missing:**\n- What went wrong\n- Why it went wrong  \n- How to fix it\n- Where to get help\n\n#### 3. ??? Missing Progress Indicators\n\n**Problems:**\n- No feedback during long operations\n- Users don't know if CLI is working or frozen\n- No ETA for completion\n- Silent failures look like hangs\n\n```bash\n# Current experience\n$ pieces search \"complex query\"\n# ... nothing for 30 seconds ...\n# Is it working? Frozen? Network issue?\n```\n\n#### 4. \uD83D\uDCCA Inconsistent Output Formatting\n\n**Issues:**\n- ASCII art separators (`###########`) look outdated\n- Inconsistent spacing between sections\n- No structured output options (JSON, YAML)\n- Poor handling of wide content\n\n```bash\n# Current output\n##########################\nAsset Name: My Code\n##########################\nLanguage: Python\n##########################\n\n# Desired output\n?????? Asset: My Code ??????????????????????????????????????????\n??? Language: Python             ???\n??? Created:  2024-01-15         ???\n??? Tags:     algorithm, sorting ???\n????????????????????????????????????????????????????????????????????????????????????????????????\n```\n\n### Proposed Solutions\n\n#### Solution 1: Enhanced Command Structure\n\n```python\n# src/pieces/commands/improved_commands.py\n\nclass CommandAliases:\n    \"\"\"User-friendly command aliases\"\"\"\n    \n    ALIASES = {\n        # Clear, intuitive names\n        'repl': 'run',\n        'interactive': 'run',\n        'shell': 'run',\n        \n        'run-snippet': 'execute',\n        'exec': 'execute',\n        'run-code': 'execute',\n        \n        'open-asset': 'open',\n        'view': 'open',\n        'show': 'open',\n        \n        # Common typos\n        'lisr': 'list',\n        'seach': 'search',\n        'cerate': 'create',\n    }\n\nclass ImprovedCommands:\n    \"\"\"Commands with better UX\"\"\"\n    \n    @command(\n        name=\"search\",\n        aliases=[\"find\", \"query\", \"lookup\"],\n        description=\"Search for assets, conversations, or anything in Pieces\"\n    )\n    def search_command(self, query: str, type: str = \"all\"):\n        \"\"\"Unified search across all content\"\"\"\n        # Show immediate feedback\n        with Progress() as progress:\n            task = progress.add_task(f\"Searching for '{query}'...\", total=100)\n            \n            # Search different types\n            results = {\n                'assets': self.search_assets(query, progress, task),\n                'conversations': self.search_conversations(query, progress, task),\n                'collections': self.search_collections(query, progress, task),\n            }\n            \n        # Display results in organized way\n        self.display_search_results(results, query)\n```\n\n#### Solution 2: Intelligent Error Handling\n\n```python\n# src/pieces/errors/user_friendly.py\n\nclass UserFriendlyError:\n    \"\"\"Transform technical errors into helpful messages\"\"\"\n    \n    ERROR_MAPPINGS = {\n        ConnectionError: {\n            'message': \"Cannot connect to Pieces OS\",\n            'reasons': [\n                \"Pieces OS may not be running\",\n                \"Network connection issues\",\n                \"Firewall blocking connection\"\n            ],\n            'solutions': [\n                \"Ensure Pieces OS is running: pieces status\",\n                \"Check your network connection\",\n                \"Try restarting Pieces OS: pieces restart\"\n            ],\n            'help_link': \"https://docs.pieces.app/troubleshooting/connection\"\n        },\n        \n        AuthenticationError: {\n            'message': \"Authentication failed\",\n            'reasons': [\n                \"Invalid or expired credentials\",\n                \"Not logged in\"\n            ],\n            'solutions': [\n                \"Log in again: pieces login\",\n                \"Check your account status at pieces.app\"\n            ],\n            'help_link': \"https://docs.pieces.app/auth\"\n        }\n    }\n    \n    @classmethod\n    def format_error(cls, error: Exception) -> str:\n        \"\"\"Format error for user consumption\"\"\"\n        error_type = type(error)\n        \n        if error_type in cls.ERROR_MAPPINGS:\n            mapping = cls.ERROR_MAPPINGS[error_type]\n            \n            # Build user-friendly message\n            output = []\n            output.append(f\"??? {mapping['message']}\")\n            output.append(\"\")\n            \n            if mapping.get('reasons'):\n                output.append(\"Possible reasons:\")\n                for reason in mapping['reasons']:\n                    output.append(f\"  ??? {reason}\")\n                output.append(\"\")\n            \n            if mapping.get('solutions'):\n                output.append(\"Try these solutions:\")\n                for i, solution in enumerate(mapping['solutions'], 1):\n                    output.append(f\"  {i}. {solution}\")\n                output.append(\"\")\n            \n            if mapping.get('help_link'):\n                output.append(f\"\uD83D\uDCD6 More help: {mapping['help_link']}\")\n            \n            return \"\\n\".join(output)\n        \n        # Fallback for unknown errors\n        return cls.format_unknown_error(error)\n```\n\n#### Solution 3: Rich Progress Indicators\n\n```python\n# src/pieces/ui/progress.py\n\nfrom rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn\nfrom rich.console import Console\nfrom typing import Optional, Callable\n\nclass RichProgress:\n    \"\"\"Enhanced progress indicators for better UX\"\"\"\n    \n    def __init__(self):\n        self.console = Console()\n    \n    def with_spinner(self, message: str, task: Callable):\n        \"\"\"Show spinner for indeterminate progress\"\"\"\n        with self.console.status(message, spinner=\"dots\"):\n            return task()\n    \n    def with_progress_bar(self, \n                         items: list, \n                         task: Callable,\n                         description: str = \"Processing\"):\n        \"\"\"Show progress bar for determinate progress\"\"\"\n        \n        with Progress(\n            SpinnerColumn(),\n            TextColumn(\"[progress.description]{task.description}\"),\n            BarColumn(),\n            TextColumn(\"[progress.percentage]{task.percentage:>3.0f}%\"),\n            console=self.console\n        ) as progress:\n            \n            task_id = progress.add_task(description, total=len(items))\n            results = []\n            \n            for item in items:\n                result = task(item)\n                results.append(result)\n                progress.advance(task_id)\n            \n            return results\n    \n    def live_output(self, generator, title: str = \"Output\"):\n        \"\"\"Display live streaming output\"\"\"\n        from rich.live import Live\n        from rich.panel import Panel\n        \n        output_lines = []\n        \n        with Live(\n            Panel(\"\", title=title, border_style=\"green\"),\n            refresh_per_second=4,\n            console=self.console\n        ) as live:\n            for chunk in generator:\n                output_lines.append(chunk)\n                content = \"\".join(output_lines)\n                live.update(Panel(content, title=title, border_style=\"green\"))\n        \n        return \"\".join(output_lines)\n```\n\n#### Solution 4: Modern Output Formatting\n\n```python\n# src/pieces/ui/formatters.py\n\nfrom rich.table import Table\nfrom rich.panel import Panel\nfrom rich.tree import Tree\nfrom rich.syntax import Syntax\nfrom typing import Dict, List, Any\n\nclass ModernFormatters:\n    \"\"\"Modern, beautiful output formatting\"\"\"\n    \n    @staticmethod\n    def format_asset(asset: Dict[str, Any]) -> Panel:\n        \"\"\"Format asset with modern box drawing\"\"\"\n        from rich.console import Group\n        from rich.align import Align\n        \n        # Create formatted content\n        content = Group(\n            f\"[bold]Language:[/bold] {asset.get('language', 'Unknown')}\",\n            f\"[bold]Created:[/bold] {asset.get('created', 'Unknown')}\",\n            f\"[bold]Tags:[/bold] {', '.join(asset.get('tags', []))}\",\n            \"\",\n            Syntax(\n                asset.get('content', ''), \n                asset.get('language', 'text'),\n                theme=\"monokai\",\n                line_numbers=True\n            )\n        )\n        \n        return Panel(\n            content,\n            title=f\"\uD83D\uDCC4 {asset.get('name', 'Untitled')}\",\n            border_style=\"blue\",\n            padding=(1, 2)\n        )\n    \n    @staticmethod\n    def format_table(data: List[Dict], title: str = None) -> Table:\n        \"\"\"Create beautiful tables\"\"\"\n        table = Table(title=title, show_lines=True)\n        \n        # Auto-detect columns\n        if data:\n            for key in data[0].keys():\n                table.add_column(key.title(), style=\"cyan\")\n            \n            for row in data:\n                table.add_row(*[str(v) for v in row.values()])\n        \n        return table\n    \n    @staticmethod\n    def format_tree(data: Dict, title: str = \"Structure\") -> Tree:\n        \"\"\"Format hierarchical data as tree\"\"\"\n        tree = Tree(f\"[bold]{title}[/bold]\")\n        \n        def add_nodes(node: Tree, data: Dict):\n            for key, value in data.items():\n                if isinstance(value, dict):\n                    branch = node.add(f\"\uD83D\uDCC1 {key}\")\n                    add_nodes(branch, value)\n                else:\n                    node.add(f\"\uD83D\uDCC4 {key}: {value}\")\n        \n        add_nodes(tree, data)\n        return tree\n```\n\n#### Solution 5: Command Search & Discovery\n\n```python\n# src/pieces/commands/search.py\n\nfrom difflib import get_close_matches\nfrom typing import List, Optional\n\nclass CommandSearch:\n    \"\"\"Enhanced command discovery\"\"\"\n    \n    def __init__(self, commands: Dict[str, Command]):\n        self.commands = commands\n        self.build_search_index()\n    \n    def build_search_index(self):\n        \"\"\"Build search index for commands\"\"\"\n        self.index = {}\n        \n        for name, cmd in self.commands.items():\n            # Index by name\n            self.index[name] = cmd\n            \n            # Index by aliases\n            for alias in cmd.aliases:\n                self.index[alias] = cmd\n            \n            # Index by keywords in description\n            words = cmd.description.lower().split()\n            for word in words:\n                if word not in self.index:\n                    self.index[word] = []\n                self.index[word].append(cmd)\n    \n    def search(self, query: str) -> List[Command]:\n        \"\"\"Search commands by query\"\"\"\n        query = query.lower()\n        results = set()\n        \n        # Exact match\n        if query in self.index:\n            results.add(self.index[query])\n        \n        # Fuzzy match\n        matches = get_close_matches(query, self.index.keys(), n=5, cutoff=0.6)\n        for match in matches:\n            if isinstance(self.index[match], list):\n                results.update(self.index[match])\n            else:\n                results.add(self.index[match])\n        \n        return list(results)\n    \n    def suggest_command(self, invalid_cmd: str) -> Optional[str]:\n        \"\"\"Suggest correct command for typos\"\"\"\n        suggestions = self.search(invalid_cmd)\n        \n        if suggestions:\n            # Format suggestion\n            suggestion = suggestions[0]\n            return (\n                f\"Command '{invalid_cmd}' not found. \"\n                f\"Did you mean '{suggestion.name}'?\\n\\n\"\n                f\"Run 'pieces {suggestion.name} --help' for usage.\"\n            )\n        \n        return None\n```\n\n#### Solution 6: Interactive Help System\n\n```python\n# src/pieces/help/interactive.py\n\nclass InteractiveHelp:\n    \"\"\"Interactive help system for better discoverability\"\"\"\n    \n    def show_interactive_help(self):\n        \"\"\"Show interactive command browser\"\"\"\n        from rich.prompt import Prompt\n        from rich.console import Console\n        \n        console = Console()\n        \n        while True:\n            console.print(\"\\n[bold]Pieces CLI Help[/bold]\")\n            console.print(\"1. Browse commands by category\")\n            console.print(\"2. Search for a command\")\n            console.print(\"3. View common workflows\")\n            console.print(\"4. Troubleshooting guide\")\n            console.print(\"5. Exit help\")\n            \n            choice = Prompt.ask(\n                \"\\nWhat would you like help with?\",\n                choices=[\"1\", \"2\", \"3\", \"4\", \"5\"],\n                default=\"1\"\n            )\n            \n            if choice == \"1\":\n                self.browse_by_category()\n            elif choice == \"2\":\n                self.search_commands()\n            elif choice == \"3\":\n                self.show_workflows()\n            elif choice == \"4\":\n                self.show_troubleshooting()\n            else:\n                break\n    \n    def browse_by_category(self):\n        \"\"\"Browse commands organized by category\"\"\"\n        categories = {\n            \"Asset Management\": [\"create\", \"list\", \"search\", \"delete\", \"open\"],\n            \"AI & Copilot\": [\"ask\", \"explain\", \"generate\", \"complete\"],\n            \"Configuration\": [\"config\", \"login\", \"logout\", \"status\"],\n            \"Collaboration\": [\"share\", \"conversation\", \"commit\"],\n        }\n        \n        # Show category menu\n        # ... implementation ...\n```\n\n### Implementation Timeline\n\n#### Week 1: Foundation\n- [ ] Implement command aliases system\n- [ ] Create user-friendly error formatter\n- [ ] Add basic progress indicators\n\n#### Week 2: Rich UI\n- [ ] Integrate Rich library for formatting\n- [ ] Implement modern output formatters\n- [ ] Add progress bars and spinners\n\n#### Week 3: Discovery\n- [ ] Build command search system\n- [ ] Implement interactive help\n- [ ] Add command suggestions\n\n#### Week 4: Polish\n- [ ] Add output format options (--format json/yaml/table)\n- [ ] Implement color themes\n- [ ] Add accessibility features\n\n### Success Metrics\n- Command discovery time: < 10 seconds\n- Error resolution rate: > 80% self-service\n- User satisfaction: > 4.5/5 stars\n- Support ticket reduction: 50%\n\n### Before/After Examples\n\n**Before:**\n```bash\n$ pieces lst asstes\nError: Unknown command\n\n$ pieces list assets\n######################\nAsset 1\n######################\n```\n\n**After:**\n```bash\n$ pieces lst asstes\nCommand 'lst asstes' not found. Did you mean 'list assets'?\n\nRun 'pieces list assets --help' for usage.\n\n$ pieces list assets\n?????? Your Assets (showing 1-10 of 45) ??????????????????????????????????????????????????????????????????\n??? \uD83D\uDCC4 Quick Sort Algorithm            Python    2 days ago ???\n??? \uD83D\uDCC4 API Response Handler           TypeScript 3 days ago ???\n??? \uD83D\uDCC4 Database Connection Pool       Java      1 week ago ???\n??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????\n\nPress 'n' for next page, 'p' for previous, 'q' to quit\n```\n\n### References\n- [CLI Guidelines](https://clig.dev/)\n- [Rich Python Library](https://rich.readthedocs.io/)\n- [Command Line Interface Guidelines](https://www.nngroup.com/articles/command-line-interfaces/)",
      "updatedAt" : 1753388400.000000000,
      "user" : "tsavo-at-pieces",
      "userHtmlUrl" : "https://github.com/tsavo-at-pieces",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/102485237?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Pieces CLI for interacting with Pieces OS",
        "homepage" : "https://docs.pieces.app/products/cli",
        "name" : "cli-agent",
        "fullName" : "pieces-app/cli-agent",
        "htmlUrl" : "https://github.com/pieces-app/cli-agent",
        "gitUrl" : "git://github.com/pieces-app/cli-agent.git",
        "sshUrl" : "git@github.com:pieces-app/cli-agent.git",
        "cloneUrl" : "https://github.com/pieces-app/cli-agent.git",
        "owner" : {
          "login" : "pieces-app",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 84,
        "watchersCount" : 84,
        "size" : 24515,
        "openIssuesCount" : 56,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-24T20:10:45Z",
        "languages" : {
          "PowerShell" : 2058,
          "Shell" : 2452,
          "Ruby" : 193,
          "Python" : 7393011
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Pieces CLI has several user experience issues that impact discoverability, usability, and overall satisfaction, and needs major UX improvements to address these issues.",
      "validationOrRequirement" : "Success Metrics: Command discovery time, Error resolution rate, User satisfaction, and Support ticket reduction.",
      "attemptedFixes" : "Proposed Solutions: Enhanced Command Structure, Intelligent Error Handling, Rich Progress Indicators, Modern Output Formatting, Command Search & Discovery, Interactive Help System, and Implementation Timeline.",
      "otherNotes" : "UX Enhancement: Comprehensive User Experience Improvements for Pieces CLI, including command discoverability, error handling, progress indicators, output formatting, command search, and interactive help system.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406758
  }, {
    "issueDTO" : {
      "id" : 2382273053,
      "title" : "Path subsitution",
      "url" : "https://github.com/joshmedeski/sesh/issues/129",
      "repositoryName" : "joshmedeski/sesh",
      "description" : "### What would you like sesh to do?\r\n\r\nAs a user, I want to define global substitution rules, so I can create custom session name rules to improve my session names and create a more streamlined workflow.\r\n\r\n# Example\r\n\r\n- `~/c/dotfiles/.config/neovim` could be changed to `\uD83D\uDCBB neovim` (replacing `~/c/dotfiles/.config`)\r\n\r\n```toml\r\n[namer]\r\n[[find_and_replace]]\r\nfind = \"~/c/dotfiles/.config/\"\r\nreplace = \"\uD83D\uDCBB \"\r\n```",
      "updatedAt" : 1753388328.000000000,
      "user" : "joshmedeski",
      "userHtmlUrl" : "https://github.com/joshmedeski",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2036594?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @joshmedeski \n\nFirst off; thanks for providing sesh! It's been a great time saver within my workflow for some time now.\n\nI'm planning on submitting a PR for this exact feature, but I'd want to discuss the naming of the root setting; would you prefer \"namer\" over of \"substitutions\"? Imo. substituions (or \"path_substitutions\") is more concise regarding what it does. \n\nLet me know what you thought about the feature or if you have any other recommendations/ideas \uD83D\uDE01 \n" ],
      "repository" : {
        "description" : "Smart session manager for the terminal",
        "homepage" : "",
        "name" : "sesh",
        "fullName" : "joshmedeski/sesh",
        "htmlUrl" : "https://github.com/joshmedeski/sesh",
        "gitUrl" : "git://github.com/joshmedeski/sesh.git",
        "sshUrl" : "git@github.com:joshmedeski/sesh.git",
        "cloneUrl" : "https://github.com/joshmedeski/sesh.git",
        "owner" : {
          "login" : "joshmedeski",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 64,
        "stargazersCount" : 1161,
        "watchersCount" : 1161,
        "size" : 4075,
        "openIssuesCount" : 55,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-10T21:33:11Z",
        "languages" : {
          "Makefile" : 257,
          "Go" : 112888
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "allow users to define global substitution rules to create custom session name rules and improve session names",
      "validationOrRequirement" : "define global substitution rules, create custom session name rules, and improve session names",
      "attemptedFixes" : "naming of the root setting is being discussed, with suggestions for 'substitutions' or 'path_substitutions' instead of 'namer'",
      "otherNotes" : "sesh has been a great time saver within the author's workflow, and a PR is planned for this feature",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406762
  }, {
    "issueDTO" : {
      "id" : 2373052941,
      "title" : "Allow copying the table definition from the dropdown menu",
      "url" : "https://github.com/supabase/supabase/issues/27538",
      "repositoryName" : "supabase/supabase",
      "description" : "We can now get the table definition from here\r\n![screenshot-2024-06-25-at-13 24 51](https://github.com/supabase/supabase/assets/105593/3424110a-4994-4312-b4d4-1970fa811f2f)\r\n\r\n\r\nWould be great if we could copy it from here (\"Copy table definition\")\r\n\r\n![screenshot-2024-06-25-at-13 25 30](https://github.com/supabase/supabase/assets/105593/1e58262d-8a54-4408-b410-91e2ff60fb1b)\r\n",
      "updatedAt" : 1753388105.000000000,
      "user" : "saltcod",
      "userHtmlUrl" : "https://github.com/saltcod",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/105593?v=4",
      "labels" : [ "pr-opened", "external-issue", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Looks like something I can work on. Let me get familiar with the code and I'll come back to you before the weekend.", "Checkout: https://github.com/supabase/supabase/pull/27621\r\n\r\nNow in the 'Table Editor', when opening the menu of one of the tables, you'll get the option to 'Copy Definition' (see screenshot).\r\n\r\n<img width=\"287\" alt=\"copy-defintion\" src=\"https://github.com/supabase/supabase/assets/2932357/93f21c8c-c5d0-4a32-b4a4-9f5573e52bba\">\r\n\r\n</br>\r\n</br>\r\nI've used the same 'copy' icon as which is being used for 'Duplicate Table'. Because of this, I've put the 'Copy Definition' at the bottom of the list. Let me know if I need to use a different icon for this.\r\n\r\nI've also created a 'useTableDefinition' hook, the logic of this hook was found in the 'TableDefinition.tsx' component. Because I had to reuse this logic, I thought it would be a better idea to write one new hook and let the existing component and my new feature make use of it, instead of reusing/copying the same code. Please let me know is this is okay or if I need to do it differently.", "hello i am new to opensource if this issue is still present can you assign me this please? @saltcod  \r\n", "@saltcod, could you please review my changes of PR : \r\n- #30380", "is this issue still open?", "The code for copying definition is already defined in the table component, all we need to do is make it into a component and use it in the table as well as in the dropdown menu as an option", "Does the  the issue have been fixed?", "@saltcod  Hi, I've implemented the feature to allow copying the table definition from the dropdown menu (#27538).  \nCould you please review it when you have time? Let me know if any changes are needed.  \nThanks!\n", "hello if this issue is still present ,could u please assign it to me?", "Hi there! \nIf this issue is still open, would it be okay for me to take it up? I'd love to contribute and help resolve it.\nAlso, if there are any other related areas I can assist with, feel free to let me know  happy to contribute more wherever needed!", "hey there @saltcod is this issue still open , if yes can you assign it to me\n", "I see 2 PRs against this? Are they abandoned? Can I work on this?\nhttps://github.com/supabase/supabase/pull/34406\nhttps://github.com/supabase/supabase/pull/30380", "> I see 2 PRs against this? Are they abandoned? Can I work on this? [#34406](https://github.com/supabase/supabase/pull/34406) [#30380](https://github.com/supabase/supabase/pull/30380)\n\nThis issue is already fixed. The dropdown contains 'Copy table schema' which copies the table definition.\n\n<img width=\"448\" height=\"330\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/82321652-7fba-41c5-8898-bb9644b4d8d7\" />\n\n@saltcod We can close this Issue to prevent further discussion on this.\n" ],
      "repository" : {
        "description" : "The Postgres development platform. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.",
        "homepage" : "https://supabase.com",
        "name" : "supabase",
        "fullName" : "supabase/supabase",
        "htmlUrl" : "https://github.com/supabase/supabase",
        "gitUrl" : "git://github.com/supabase/supabase.git",
        "sshUrl" : "git@github.com:supabase/supabase.git",
        "cloneUrl" : "https://github.com/supabase/supabase.git",
        "owner" : {
          "login" : "supabase",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 9296,
        "stargazersCount" : 86100,
        "watchersCount" : 86100,
        "size" : 1741893,
        "openIssuesCount" : 738,
        "subscribersCount" : 587,
        "pushedAt" : "2025-07-25T00:49:41Z",
        "languages" : {
          "TypeScript" : 17050066,
          "MDX" : 8190394,
          "Dockerfile" : 4746,
          "CSS" : 140987,
          "Shell" : 5865,
          "SCSS" : 111346,
          "PLpgSQL" : 45021,
          "Makefile" : 8320,
          "JavaScript" : 962421,
          "HTML" : 453,
          "Mermaid" : 1578,
          "Elixir" : 1068
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow copying the table definition from the dropdown menu",
      "validationOrRequirement" : "The code for copying definition is already defined in the table component, all we need to do is make it into a component and use it in the table as well as in the dropdown menu as an option",
      "attemptedFixes" : "PR #27538 was implemented to allow copying the table definition from the dropdown menu",
      "otherNotes" : "The code for copying definition is already defined in the table component, all we need to do is make it into a component and use it in the table as well as in the dropdown menu as an option, The issue is already fixed, a PR was implemented to allow copying the table definition from the dropdown menu.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406767
  }, {
    "issueDTO" : {
      "id" : 3114547554,
      "title" : "I WISH CHECKMATE HAD...",
      "url" : "https://github.com/bluewave-labs/Checkmate/issues/2389",
      "repositoryName" : "bluewave-labs/Checkmate",
      "description" : "\nThis is a ticket to track a wishlist of items you wish Checkmate had.\n\n### COMMENT BELOW \uD83D\uDC47\n\nRespond with ?????? to any request you would also like to see.\n\nP.S.: Come say hi \uD83D\uDC4B on the [Discord](https://discord.com/invite/NAb6H3UTjK)",
      "updatedAt" : 1753388069.000000000,
      "user" : "gorkem-bwl",
      "userHtmlUrl" : "https://github.com/gorkem-bwl",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/167266851?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "###  Wishlist \n\n1. **Notifications:** Notifications are one of the most important part of any monitoring stack.  It doesn't matter how well the actual monitoring works if you can't be properly notified.  So I would love to see the following in a proper notification module:\n - Central notification channel management.  I shouldn't need to go to every single monitor to change a notification channel.  I shouldn't have to make the same update multiple times (i.e. changing a discord webhook to a new discord webhook for example)\n- Pluggable notification channels.  By this I mean, the Bluewave team may have Slack, Discord, Telegram, and email included out of the box, some may want an obscure notification channel that they use (NTFY for example).  Make it simple to add a new notification channel module without having to modify core code.  This allows the system to be adaptable and expandable without having to have the Bluewave team be the choking point.  The team can chose to bring in any quality and useful channels the community builds in to the core product if they so desire to.\n- Ability to add multiple notification channels of the same type.  I should be able to have multiple discord channels, maybe one for prod, one for non-prod.\n- Ability to send to multiple notifications for the same monitor.  Example, disk runs low on serverA I want to notify the support discord channel so that maybe one of the engineers that has a minute can grab it.  At the same time, or maybe with a configurable delay, I want to notify the on-call pager via another means (PagerDuty, OpGenie, Grafana On-Call, etc) so they are paged and can act on it.\n- Notification escalations.  Notification has been sent, it hasn't been acknowledged and is still alerting XX time later (configurable, minutes, hours, etc) it escalates to a different notification channel.\n- Custom service monitoring.  Ability to monitor a service on a server is paramount to a monitoring solution.  Sometimes a service doesn't expose a port or endpoint or that endpoint is restricted.  So being able to monitor for a process on a server where capture is already running, would be useful. \n\n\n2. **Other**\n- Tags on monitors that allow me to search and filter based on them.  This would include in the notifications.  For example, I would like to be able to notify a customer when their service is having an issue.  So if I could setup the monitor that's monitoring their service with a tag, then on the monitor add a filter for tag = XXX, send to this channel, but also send to this other channel (for a production support team for example). Example of this concept is Grafana Alerting: https://grafana.com/docs/grafana/latest/alerting/configure-notifications/\n- Searchable monitors.  Currently with ~150 monitors in Checkmate, I have to browse through all the pages to find the monitor I want to look at.  \n- Page size preference remembered sessions (at the user level would be ideal, along with having a global configurable default value).  Related to the above, if I change it to 25 per page and then refresh, it defaults back to 5.  Super annoying.\n- Custom script execution.  Similar to custom service monitoring, being able to create scripts or plugins that run and do something more complex than up/down and reports back a healthy or not makes a monitoring system extremely expandable and adaptable.  A good example is in Icinga/Nagios/Checkmk eco-system.  The parsing is simplified in that the return code of the plugin has to be 0, 1, 2, 3 for Ok, Warning, Critical, Unknown.  Then no need to have to parse all sort of different outputs.  https://www.monitoring-plugins.org/doc/guidelines.html#AEN74 \n- Websocket and gRPC monitoring.  Many of the endpoints I need to monitor are one of the two.  Being able to query them and check for successful replies is crucial to a complete monitoring solution.\n- Event handlers.  Being able to trigger event handlers based on certain criteria.  For example, if a service dies, restart it, however if that service dies more than once in a given time period, send a notification. \n- Ability to export metrics in prometheus style metrics.  Monitoring and observability are two different things, so even though I have monitoring in place I'm still going to have an observability platform.  Since the main metrics are being gathered by capture/checkmate, it would be nice if at a minimum those could be exposed as prometheus metrics, even better if there was a way to provide a prometheus compatible url and have it do the remote write.  \n\nAll these are features in other monitoring systems.  In all the cases where the ability to use a custom plugin, module, etc is proposed I would find it perfectly acceptable to require the plugin be written in a certain language and have other requirements (for example the return code of the custom script/plugin) to make it more easily to be \"plugged-in\" to checkmate/capture and to keep the system running efficiently.", "I think that we need the ability to group uptime and infrastructure monitors together, ie) all of the VMs in one section, all of the websites in a different section, external sites in a third section etc. ", "Ability to have agents in remote sites that push so no port forwarding needed in remote sites as the agents will send a heartbeat so as long as the server is reachable from the agent it will work (a plus if the agent can be used as a probe to reach other devices in that network)", "> I think that we need the ability to group uptime and infrastructure monitors together, ie) all of the VMs in one section, all of the websites in a different section, external sites in a third section etc.\n\nI think tagging monitors won't work in this case - you want them virtually grouped on the dashboard, right? For me to understand your use-case better, is there an example of a user interface from another application? ", "It would be fantastic to have the ability to show infrastructure information on the public status pages. (as an aside, the use of the word \"server\" in the app can be confusing - my assumption of \"server\" was that it was one of my servers (hardware) and not one of my services that I monitor for uptime and such, so adding \"servers\" to the status page was confusing to me as the servers (infrastructure in the app) I had added were not available to be added)\n\nI'd love to be able to show my users some basics about the hardware behind the scenes. Storage capacity/usage over time, CPU/RAM usage. Likely not nearly as much data as on a proper private dashboard, but I don't see why not allow the user to pick and choose which components they have being monitored infrastructure-wise and display them publicly. \n\nMy personal example would be two on-prem servers and one VPS and giving some high level data to those looking at the status page. Bonus points if the monitored services can be displayed in such a way that they tie back to the relevant server hardware being shown.", "> > I think that we need the ability to group uptime and infrastructure monitors together, ie) all of the VMs in one section, all of the websites in a different section, external sites in a third section etc.\n> \n> I think tagging monitors won't work in this case - you want them virtually grouped on the dashboard, right? For me to understand your use-case better, is there an example of a user interface from another application?\n\nUptime Kuma. \n\n![Image](https://github.com/user-attachments/assets/621a2f30-3c0a-467b-9cc9-3e215ddace6d)", "> > > I think that we need the ability to group uptime and infrastructure monitors together, ie) all of the VMs in one section, all of the websites in a different section, external sites in a third section etc.\n> > \n> > \n> > I think tagging monitors won't work in this case - you want them virtually grouped on the dashboard, right? For me to understand your use-case better, is there an example of a user interface from another application?\n> \n> Uptime Kuma.\n> \n> ![Image](https://github.com/user-attachments/assets/621a2f30-3c0a-467b-9cc9-3e215ddace6d)\n\nGot it. We can tag monitors and also have another option on the dashboard to additionally group them on the dashboard \uD83D\uDC4D It'll be a bit tricky using tags and groupings at the same time but we can figure it out :) ", "> > > > I think that we need the ability to group uptime and infrastructure monitors together, ie) all of the VMs in one section, all of the websites in a different section, external sites in a third section etc.\n> > > \n> > > \n> > > I think tagging monitors won't work in this case - you want them virtually grouped on the dashboard, right? For me to understand your use-case better, is there an example of a user interface from another application?\n> > \n> > \n> > Uptime Kuma.\n> > ![Image](https://github.com/user-attachments/assets/621a2f30-3c0a-467b-9cc9-3e215ddace6d)\n> \n> Got it. We can tag monitors and also have another option on the dashboard to additionally group them on the dashboard \uD83D\uDC4D It'll be a bit tricky using tags and groupings at the same time but we can figure it out :)\n\nIn the Uptime Kuma example, tags and groupings are separate.  In the above the group was set up as \"Docker Containers\", and each container was tagged separately with \"Docker\".  You can have one, both, or none. (groupings and tags)", "> In the Uptime Kuma example, tags and groupings are separate. In the above the group was set up as \"Docker Containers\", and each container was tagged separately with \"Docker\". You can have one, both, or none. (groupings and tags)\n\nYes. Having just the tags and no groups will be limiting in that case. Thanks for the heads up!", "I wish there was an option to use postgres or another kind of database, dealing with mongo deployments is shit, and its not even open source licenced \uD83D\uDE11", "> I wish there was an option to use postgres or another kind of database, dealing with mongo deployments is shit, and its not even open source licenced \uD83D\uDE11\n\nThanks for this. It'll be quite cumbersome to strip away Mongo and bring in another DB. What issue(s) did you have installing Mongo? Maybe we can address them in our docs?", "It would be awesome to have a Wake-On-LAN and a ping tool. Then, even better if a CRON-based scheduler for them. That's preventing us from adopting Checkmate.", "> It would be awesome to have a Wake-On-LAN and a ping tool. Then, even better if a CRON-based scheduler for them. That's preventing us from adopting Checkmate.\n\nThanks @SaadBazaz - do you mind giving me more information about how it works, and what your use cases are? As a plus, you can mention similar apps you use for this purpose as well. It will give us a lot of information when we start with this feature. The more detail the more it's helpful :) \n\nMany thanks!\n\n", "> > It would be awesome to have a Wake-On-LAN and a ping tool. Then, even better if a CRON-based scheduler for them. That's preventing us from adopting Checkmate.\n> \n> Thanks [@SaadBazaz](https://github.com/SaadBazaz) - do you mind giving me more information about how it works, and what your use cases are? As a plus, you can mention similar apps you use for this purpose as well. It will give us a lot of information when we start with this feature. The more detail the more it's helpful :)\n> \n> Many thanks!\n\n@gorkem-bwl \n\nThank you for such a prompt response! Bravo.\n\nBasically when we are managing servers, we often want to have scheduled sleep time and scheduled wake-times. (this is often done in small setups, for power saving). We also want to be able to manually wake / sleep devices.\n\nSo if we can have a simple CLI cron runner in Checkmate (i.e., the backend server runs the cron job on its host computer), we can have:\n- Wake on LAN tool\n- Ping tool\n- Literally any custom CLI call which the admin wants to set (maybe they want to `sudo systemctl suspend` at 5PM everyday, and then Wake on LAN at 9AM everyday)\n\nThese can be presented as buttons in the Three Dot Menu, along with a few modals here-and-there for inputs (e.g. Cron scheduler, custom command call, etc)\n\n**Our current solution:**\nWe run a custom container in docker which makes wake-on-lan calls for us. Previously, we tried to setup a wake on lan Web Client (https://github.com/sameerdhoot/wolweb) but it didn't work so well for us.", "Hello, I would also like to add something, altough I am unsure if this is outside of scope...\n\nIt would be really awesome to expand the docker monitoring feature to include docker container updates:\nLet's say my `awesome-container` is on an old `latest` tag, we already have tools like `Watchtower` for automatically updating containers, but you may not want to auto-update your containers, maybe you only want to get notified when a new update is available and then do the updating yourself.\nSo I propose it would be nice to have docker image update notifications in Checkmate.\n\nIs this inside of scope? Does this make sense?\nWould be really awesome to see this implemented!", "There is an issue about an announcement panel, I don't know if this would be a complement to that one, or a completely new request... but here it goes:\n\nWithin the status page it would be nice if at the end of the page there was a history of incidents, unlike the administrative history this would be visible to the public where administrators could add tags to incidents such as: investigating, working on a fix, resolved and also be able to attach messages explaining how it is being resolved.\n\n![Image](https://github.com/user-attachments/assets/dee1844a-0651-457f-b142-fad7289ae958)\n\n![Image](https://github.com/user-attachments/assets/9800b2e2-bb5e-4d81-9aef-9b499872d1e5)", "1. Allow Maintenance inputs to be tied to a notification and have an option for them to be displayed on the public status page. If multiple maintenances are input, it should stack them on top of the page. This provides downtime windows to be shown to those checking the status page and through the notifications.\n2. Hide the \"Administrator? Login Here\" on the bottom left of the status page. Please make it a toggle option for it to show.\n3. Introduce options to allow infrastructure to be added to the status page with basic up/down metrics. You'll earn cool points if you can also show usage stats, but make this toggleable.\n4. Allow a customizable scaling option for the public status page, as bars are a bit big. Custom CSS options would be amazing.", "@InfraCharm Created an issue for (2). \n\nFor (4), is it ok to define a size and based on this size, stretch the bars? Example:\n\n<img width=\"624\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c9754007-b8e7-41fb-9731-3b38f282642e\" />", "> [@InfraCharm](https://github.com/InfraCharm) Created an issue for (2).\n> \n> For (4), is it ok to define a size and based on this size, stretch the bars? Example:\n> \n> <img alt=\"Image\" width=\"624\" src=\"https://private-user-images.githubusercontent.com/167266851/457507372-c9754007-b8e7-41fb-9731-3b38f282642e.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTA0NTgxMTYsIm5iZiI6MTc1MDQ1NzgxNiwicGF0aCI6Ii8xNjcyNjY4NTEvNDU3NTA3MzcyLWM5NzU0MDA3LWI4ZTctNDFmYi05NzMxLTNiMzhmMjgyNjQyZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjIwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYyMFQyMjE2NTZaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMmUwYjZjMzI5NmFiZDE2OWViZGY4NWUzMDRlNTgyODM0NWY4YjhjZDE2NWFjNmQzOTRmOWE5NTM1Mzg0N2MzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.kywbYMGBd4t22j6IuyNjldgy4V7EuxAWrOVV9N0nNY4\">\n\nI can't give you an exact measurement as different clients of mine would have different size status pages.\n\nI think having a custom CSS box like other major status pages would be great and allow for the maximum amount of customizations on the status page itself.", "> Hello, I would also like to add something, altough I am unsure if this is outside of scope...\n> \n> It would be really awesome to expand the docker monitoring feature to include docker container updates:\n> Let's say my `awesome-container` is on an old `latest` tag, we already have tools like `Watchtower` for automatically updating containers, but you may not want to auto-update your containers, maybe you only want to get notified when a new update is available and then do the updating yourself.\n> So I propose it would be nice to have docker image update notifications in Checkmate.\n> \n> Is this inside of scope? Does this make sense?\n> Would be really awesome to see this implemented!\n\nCurious why not just run watchtower in monitor mode. Already does exactly what you're asking about. ", "@calebcall Yes you would be right, if Watchtower wasn???t abandoned, I can???t get simple notifications to work\nand as a bonus Checkmate would have an interface for said feature.", "Wishlist\nNotifications: Notifications are one of the most important part of any monitoring stack. It doesn't matter how well the actual monitoring works if you can't be properly notified. So I would love to see the following in a proper notification module:\nCentral notification channel management. I shouldn't need to go to every single monitor to change a notification channel. I shouldn't have to make the same update multiple times (i.e. changing a discord webhook to a new discord webhook for example)\nPluggable notification channels. By this I mean, the Bluewave team may have Slack, Discord, Telegram, and email included out of the box, some may want an obscure notification channel that they use (NTFY for example). Make it simple to add a new notification channel module without having to modify core code. This allows the system to be adaptable and expandable without having to have the Bluewave team be the choking point. The team can chose to bring in any quality and useful channels the community builds in to the core product if they so desire to.\nAbility to add multiple notification channels of the same type. I should be able to have multiple discord channels, maybe one for prod, one for non-prod.\nAbility to send to multiple notifications for the same monitor. Example, disk runs low on serverA I want to notify the support discord channel so that maybe one of the engineers that has a minute can grab it. At the same time, or maybe with a configurable delay, I want to notify the on-call pager via another means (PagerDuty, OpGenie, Grafana On-Call, etc) so they are paged and can act on it.\nNotification escalations. Notification has been sent, it hasn't been acknowledged and is still alerting XX time later (configurable, minutes, hours, etc) it escalates to a different notification channel.\nCustom service monitoring. Ability to monitor a service on a server is paramount to a monitoring solution. Sometimes a service doesn't expose a port or endpoint or that endpoint is restricted. So being able to monitor for a process on a server where capture is already running, would be useful.\nOther\nTags on monitors that allow me to search and filter based on them. This would include in the notifications. For example, I would like to be able to notify a customer when their service is having an issue. So if I could setup the monitor that's monitoring their service with a tag, then on the monitor add a filter for tag = XXX, send to this channel, but also send to this other channel (for a production support team for example). Example of this concept is Grafana Alerting: https://grafana.com/docs/grafana/latest/alerting/configure-notifications/\nSearchable monitors. Currently with ~150 monitors in Checkmate, I have to browse through all the pages to find the monitor I want to look at.\nPage size preference remembered sessions (at the user level would be ideal, along with having a global configurable default value). Related to the above, if I change it to 25 per page and then refresh, it defaults back to 5. Super annoying.\nCustom script execution. Similar to custom service monitoring, being able to create scripts or plugins that run and do something more complex than up/down and reports back a healthy or not makes a monitoring system extremely expandable and adaptable. A good example is in Icinga/Nagios/Checkmk eco-system. The parsing is simplified in that the return code of the plugin has to be 0, 1, 2, 3 for Ok, Warning, Critical, Unknown. Then no need to have to parse all sort of different outputs. https://www.monitoring-plugins.org/doc/guidelines.html#AEN74\nWebsocket and gRPC monitoring. Many of the endpoints I need to monitor are one of the two. Being able to query them and check for successful replies is crucial to a complete monitoring solution.\nEvent handlers. Being able to trigger event handlers based on certain criteria. For example, if a service dies, restart it, however if that service dies more than once in a given time period, send a notification.\nAbility to export metrics in prometheus style metrics. Monitoring and observability are two different things, so even though I have monitoring in place I'm still going to have an observability platform. Since the main metrics are being gathered by capture/checkmate, it would be nice if at a minimum those could be exposed as prometheus metrics, even better if there was a way to provide a prometheus compatible url and have it do the remote write.\nAll these are features in other monitoring systems. In all the cases where the ability to use a custom plugin, module, etc is proposed I would find it perfectly acceptable to require the plugin be written in a certain language and have other requirements (for example the return code of the custom script/plugin) to make it more easily to be \"plugged-in\" to checkmate/capture and to keep the system running efficiently", "How about supporting dedicated, persistent API tokens whith more or less granular permissions? Current workflow would be to login via the API, retrieve the token and use that for further API requests. This is rather bad for scripting/interfacing the API with an automation.\n\nThere's the checkmate CLI but this also seems to require username + password the aquire a token in the first place.\n\nMy usecase for this is basically having a script/daemon that's reads information from a Netbox and adds/updates/deletes monitors in Checkmate accordingly.", "> How about supporting dedicated, persistent API tokens whith more or less granular permissions? Current workflow would be to login via the API, retrieve the token and use that for further API requests. This is rather bad for scripting/interfacing the API with an automation.\n> \n> There's the checkmate CLI but this also seems to require username + password the aquire a token in the first place.\n> \n> My usecase for this is basically having a script/daemon that's reads information from a Netbox and adds/updates/deletes monitors in Checkmate accordingly.\n\nHi @jonasjelonek ,\n\nThis is a feature that I'd like to we as well. I'll discuss this with the team but I think it's something we can add to our list. \n\nThanks for the suggestion! ", "Thanks for taking this input. Would be great if this lands in Checkmate, but no hurry :)", "It would be great if we could monitor docker containers by name and not just ID - given that the ID changes when containers are taken down for any reason.\n\nThis is achievable with Uptime Kuma", "It would be great if we could make our app even more accessible for everyone!\nWe???ve already got some accessibility basics covered and we partially meet the WCAG Level A and some Level AA guidelines. but we know there???s still room to grow. Our goal is to fully support both Level A and Level AA standards.\nWe???re aiming for things like smoother keyboard navigation, clearer focus outlines, a handy ???skip to content??? link, better form labels, alt text for all images and icons, more semantic HTML, ARIA support for custom components, announcing dynamic updates, strong color contrast, accessible tables and lists, and clearer error messages. Some of this is already in place, but we want to make it even better!", "From deploying it on Kubernetes (and more kubernetes-related enhancements), here's my wishlist:\n\n- Support creating a \"registration token\" that could be used to let Capture auto-register to it.\n- Upgrade the current helm chart to something more full-fledged using sub-charts: I've used a combination of bjw-s-labs/app-template, bitnami/redis, bitnami/mongodb to have a more versatile deployment.\n- Upgrade the current helm chart to define a Capture daemonset to monitor the Kubernetes nodes\n- Allow passing variables to assemble the mongodb connection string (DB_HOST, DB_PORT, DB_USER, DB_PASS, etc.) instead of forcing `DB_CONNECTION_STRING`\n- Support for scanning and discovering ingresses inside the Kubernetes cluster to monitor them automatically.\n\nNot really Kubernetes-related but also interesting:\n- Add compatibility with other agents, such as node-exporter or telegraf.\n- Allow setting dependencies or links between services and infrastructure machines", "Thank you @InputObject2 - can you briefly describe this one and possibly give a use-case? \n\n> * Allow setting dependencies or links between services and infrastructure machines\n\n" ],
      "repository" : {
        "description" : "Checkmate is an open-source, self-hosted tool designed to track and monitor server hardware, uptime, response times, and incidents in real-time with beautiful visualizations. Don't be shy, join here: https://discord.com/invite/NAb6H3UTjK :)",
        "homepage" : "https://checkmate.so/",
        "name" : "Checkmate",
        "fullName" : "bluewave-labs/Checkmate",
        "htmlUrl" : "https://github.com/bluewave-labs/Checkmate",
        "gitUrl" : "git://github.com/bluewave-labs/Checkmate.git",
        "sshUrl" : "git@github.com:bluewave-labs/Checkmate.git",
        "cloneUrl" : "https://github.com/bluewave-labs/Checkmate.git",
        "owner" : {
          "login" : "bluewave-labs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 471,
        "stargazersCount" : 7403,
        "watchersCount" : 7403,
        "size" : 23537,
        "openIssuesCount" : 65,
        "subscribersCount" : 30,
        "pushedAt" : "2025-07-24T20:57:28Z",
        "languages" : {
          "Dockerfile" : 3853,
          "CSS" : 12186,
          "Shell" : 5544,
          "JavaScript" : 1488102,
          "HTML" : 362
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to provide a list of features that the user would like to see implemented in Checkmate, including improvements to notifications, custom service monitoring, and more.",
      "validationOrRequirement" : "Some of the features mentioned have specific requirements, such as the need for a custom plugin to be written in a certain language or the need for a specific return code from the plugin. Other features have no specific requirements mentioned.",
      "attemptedFixes" : "There are no specific attempted fixes mentioned in this issue, as it is a wishlist of features.",
      "otherNotes" : "This is a wishlist of features for Checkmate, including notifications, custom service monitoring, searchable monitors, custom script execution, and more. It also includes requests for improved accessibility and Kubernetes-related enhancements.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406774
  }, {
    "issueDTO" : {
      "id" : 3248137152,
      "title" : "Revisit whether \"provider_id\" should be mandatory during resource registration for vector DB",
      "url" : "https://github.com/meta-llama/llama-stack/issues/2834",
      "repositoryName" : "meta-llama/llama-stack",
      "description" : "### \uD83D\uDE80 Describe the new functionality needed\n\nVector_DB picks the first one in the list, are we sure about that?\n\n```python\n        if provider_id is None:\n            if len(self.impls_by_provider_id) > 0:\n                provider_id = list(self.impls_by_provider_id.keys())[0]\n                if len(self.impls_by_provider_id) > 1:\n                    logger.warning(\n                        f\"No provider specified and multiple providers available. Arbitrarily selected the first provider {provider_id}.\"\n                    )\n            else:\n                raise ValueError(\"No provider available. Please configure a vector_io provider.\")\n```\n\nShould we only pick a vector db if there is a single provider only? Like Model and Shields do?\n\n@franciscojavierarceo @jwm4 thoughts? \n\n### \uD83D\uDCA1 Why is this needed? What if we don't build it?\n\nArbitrary decisions are not good?\n\n### Other thoughts\n\n_No response_",
      "updatedAt" : 1753388057.000000000,
      "user" : "leseb",
      "userHtmlUrl" : "https://github.com/leseb",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/912735?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "can i take this plz ? ", "> can i take this plz ?\n\nYou already have 4 issues in progress so let's wait for completion!", "Yes, I wholeheartedly agree with the nudge. We should not arbitrarily pick the first -- we should never do any such thing. ", "Yeah +1" ],
      "repository" : {
        "description" : "Composable building blocks to build Llama Apps",
        "homepage" : "https://llama-stack.readthedocs.io",
        "name" : "llama-stack",
        "fullName" : "meta-llama/llama-stack",
        "htmlUrl" : "https://github.com/meta-llama/llama-stack",
        "gitUrl" : "git://github.com/meta-llama/llama-stack.git",
        "sshUrl" : "git@github.com:meta-llama/llama-stack.git",
        "cloneUrl" : "https://github.com/meta-llama/llama-stack.git",
        "owner" : {
          "login" : "meta-llama",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1112,
        "stargazersCount" : 7924,
        "watchersCount" : 7924,
        "size" : 25683,
        "openIssuesCount" : 213,
        "subscribersCount" : 125,
        "pushedAt" : "2025-07-24T23:21:17Z",
        "languages" : {
          "TypeScript" : 233696,
          "Dockerfile" : 870,
          "Shell" : 40375,
          "CSS" : 4168,
          "JavaScript" : 474,
          "Objective-C" : 394,
          "Swift" : 15927,
          "Python" : 3509207
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to determine whether 'provider_id' should be mandatory during resource registration for vector DB, and if so, what the correct behavior should be when there are multiple providers available.",
      "validationOrRequirement" : "The requirement is to revisit whether 'provider_id' should be mandatory during resource registration for vector DB.",
      "attemptedFixes" : "There's a suggestion to change the behavior to only pick a vector db if there is a single provider only, but it's not clear if this is the desired solution.",
      "otherNotes" : "The code currently picks the first provider in the list, but it's not clear if this is the desired behavior. There's a suggestion to only pick a vector db if there is a single provider only, like Model and Shields do.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406779
  }, {
    "issueDTO" : {
      "id" : 2840351320,
      "title" : "Support Generative Reward Model (GenRM)",
      "url" : "https://github.com/volcengine/verl/issues/229",
      "repositoryName" : "volcengine/verl",
      "description" : "According to the [documentation](https://verl.readthedocs.io/en/latest/examples/ppo_code_architecture.html), veRL only supports `AutoModelForSequenceClassification`. What would be the best way to implement generative reward model (GenRM) for veRL? I tried looking at [FSDP Workers](https://github.com/volcengine/verl/blob/main/verl/trainer/ppo/workers/fsdp_workers.py) and [Megatron-LM Workers](https://github.com/volcengine/verl/blob/main/verl/trainer/ppo/workers/megatron_workers.py) but they no longer exist.",
      "updatedAt" : 1753387912.000000000,
      "user" : "maksimstw",
      "userHtmlUrl" : "https://github.com/maksimstw",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/39599206?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Could you give an example of Generative RM and how it should be used?", "Instead of using a linear predictor, GenRM leverages CoT and next-token prediction to provide reward. GenRM is proven to be more accurate.\nhttps://arxiv.org/abs/2410.12832", "> Instead of using a linear predictor, GenRM leverages CoT and next-token prediction to provide reward. GenRM is proven to be more accurate. https://arxiv.org/abs/2410.12832\n\nAre there any pretrained GenRM that we can play around with?", "+1???looking forward to such a feature.", "> > Instead of using a linear predictor, GenRM leverages CoT and next-token prediction to provide reward. GenRM is proven to be more accurate. https://arxiv.org/abs/2410.12832\n> \n> Are there any pretrained GenRM that we can play around with?\n\nI???m not aware of any existing pretrained GenRM. However, a basic GenRM could be created by simply prompting an LLM to act as a judge. For example, a prompt like this could be used:\n```\nPlease act as a judge and provide a score from 1 to 5, with 5 being the highest quality. Think step by step before deciding on a score, and output the final score in \\box{}.\n```\nI???m happy to help implement this feature, but I could use some guidance on the best place to integrate this reward worker.", "> > > Instead of using a linear predictor, GenRM leverages CoT and next-token prediction to provide reward. GenRM is proven to be more accurate. https://arxiv.org/abs/2410.12832\n> > \n> > \n> > Are there any pretrained GenRM that we can play around with?\n> \n> I???m not aware of any existing pretrained GenRM. However, a basic GenRM could be created by simply prompting an LLM to act as a judge. For example, a prompt like this could be used:\n> \n> ```\n> Please act as a judge and provide a score from 1 to 5, with 5 being the highest quality. Think step by step before deciding on a score, and output the final score in \\box{}.\n> ```\n> \n> I???m happy to help implement this feature, but I could use some guidance on the best place to integrate this reward worker.\n\nHi, would you please introduce some best practices of using this kind of gen rewards? That will be of great thank to you.", "Looking forward to this feature too", "+1", "Looking forward, thumbs up", "+1. Need it. Does anyone have any knowledge of this?", "+1. Need it", "+1. Need it", "+1. Need it", "+1. Need it", "here's a naive implement of LLM as a Judge which runs as a new role in RL training. we use qwen model as a verifier, it could be replaced with any pretrained GRM as you like https://github.com/volcengine/verl/pull/1953", "https://github.com/volcengine/verl/tree/main/recipe/genrm_remote " ],
      "repository" : {
        "description" : "verl: Volcano Engine Reinforcement Learning for LLMs",
        "homepage" : "https://verl.readthedocs.io/en/latest/index.html",
        "name" : "verl",
        "fullName" : "volcengine/verl",
        "htmlUrl" : "https://github.com/volcengine/verl",
        "gitUrl" : "git://github.com/volcengine/verl.git",
        "sshUrl" : "git@github.com:volcengine/verl.git",
        "cloneUrl" : "https://github.com/volcengine/verl.git",
        "owner" : {
          "login" : "volcengine",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1900,
        "stargazersCount" : 11405,
        "watchersCount" : 11405,
        "size" : 8902,
        "openIssuesCount" : 914,
        "subscribersCount" : 69,
        "pushedAt" : "2025-07-24T21:53:24Z",
        "languages" : {
          "Shell" : 215619,
          "Roff" : 19922,
          "Python" : 3563625
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support Generative Reward Model (GenRM) for veRL, exploring the best way to implement it.",
      "validationOrRequirement" : "Implement generative reward model (GenRM) for veRL, leveraging CoT and next-token prediction to provide reward.",
      "attemptedFixes" : "A basic GenRM could be created by simply prompting an LLM to act as a judge.",
      "otherNotes" : "GenRM leverages CoT and next-token prediction to provide reward, proven to be more accurate. There are no pretrained GenRM available, but a basic GenRM could be created by prompting an LLM to act as a judge. There is a naive implementation of LLM as a Judge which runs as a new role in RL training.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406784
  }, {
    "issueDTO" : {
      "id" : 3261111663,
      "title" : "[HIGH] Dangerous Bare Exception Handlers Hide Critical Errors",
      "url" : "https://github.com/pieces-app/cli-agent/issues/375",
      "repositoryName" : "pieces-app/cli-agent",
      "description" : "## ?????? Code Quality: Bare Exception Handlers Swallow All Exceptions\n\n### Summary\nMultiple locations in the codebase use bare `except:` clauses that catch ALL exceptions, including system exits, keyboard interrupts, and critical errors. This anti-pattern makes debugging extremely difficult, hides programming errors, and can prevent proper program termination.\n\n### Critical Instances\n\n#### 1. Silent Failure in Client Connection\n[`src/pieces/client.py:236-237`](https://github.com/pieces-app/cli-agent/blob/main/src/pieces/client.py#L236-L237):\n```python\nexcept:\n    return False  # Hides ALL errors including KeyboardInterrupt\\!\n```\n\n#### 2. Silent Pass in Message Handler  \n[`src/pieces/message.py:69-70`](https://github.com/pieces-app/cli-agent/blob/main/src/pieces/message.py#L69-L70):\n```python\nexcept:\n    pass  # Silently ignores EVERYTHING\n```\n\n#### 3. Retry Logic with Bare Except\n[`src/pieces/client.py:250`](https://github.com/pieces-app/cli-agent/blob/main/src/pieces/client.py#L250):\n```python\nexcept:\n    if maximum_retries == 1:\n        return False\n```\n\n### Why This Is Dangerous\n\n1. **Catches System Exits**: `SystemExit` and `KeyboardInterrupt` are caught, preventing clean shutdown\n2. **Hides Programming Errors**: `NameError`, `AttributeError`, etc. are silently ignored\n3. **Masks Security Issues**: Security exceptions could go unnoticed\n4. **Impossible to Debug**: No error information is logged or reported\n5. **Breaks Exception Hierarchy**: Violates Python's exception handling best practices\n\n### Real-World Impact\n\n```python\n# Example 1: User can't exit program\ntry:\n    long_running_operation()\nexcept:  # Catches KeyboardInterrupt\n    pass  # Ctrl+C doesn't work\\!\n\n# Example 2: Typo goes unnoticed  \ntry:\n    usr.login()  # Should be 'user', not 'usr'\nexcept:\n    return False  # NameError hidden, seems like login failed\n\n# Example 3: Security issue hidden\ntry:\n    validate_certificate()  # Raises SecurityException\nexcept:\n    pass  # Security violation ignored\\!\n```\n\n### Proposed Solution\n\n#### Step 1: Identify What Should Be Caught\n```python\n# src/pieces/utils/exceptions.py\n\"\"\"Define application-specific exceptions\"\"\"\n\nclass PiecesException(Exception):\n    \"\"\"Base exception for all Pieces errors\"\"\"\n    pass\n\nclass NetworkException(PiecesException):\n    \"\"\"Network-related errors\"\"\"\n    pass\n\nclass AuthenticationException(PiecesException):\n    \"\"\"Authentication failures\"\"\"\n    pass\n\nclass ConfigurationException(PiecesException):\n    \"\"\"Configuration errors\"\"\"\n    pass\n\n# Define what exceptions are \"expected\" and can be handled\nEXPECTED_EXCEPTIONS = (\n    # Network errors\n    ConnectionError,\n    TimeoutError,\n    urllib.error.URLError,\n    requests.exceptions.RequestException,\n    \n    # API errors\n    PiecesException,\n    \n    # File errors\n    FileNotFoundError,\n    PermissionError,\n    \n    # Value errors\n    ValueError,\n    KeyError,\n    IndexError,\n)\n\n# Never catch these\nNEVER_CATCH = (\n    SystemExit,\n    KeyboardInterrupt,\n    GeneratorExit,\n)\n```\n\n#### Step 2: Replace Bare Excepts\n\n**Before:**\n```python\nexcept:\n    return False\n```\n\n**After:**\n```python\nexcept EXPECTED_EXCEPTIONS as e:\n    logger.debug(f\"Expected error in operation: {type(e).__name__}: {e}\")\n    return False\nexcept Exception as e:\n    # Unexpected error - log it\\!\n    logger.error(f\"Unexpected error: {type(e).__name__}: {e}\", exc_info=True)\n    raise  # Re-raise unexpected errors\n```\n\n#### Step 3: Specific Implementations\n\n**Fix for client.py:236-237:**\n```python\ndef check_connection(self) -> bool:\n    \"\"\"Check if connection is available\"\"\"\n    try:\n        response = self.api_client.well_known_health()\n        return response.status == 'ok'\n    except (ConnectionError, TimeoutError, urllib.error.URLError) as e:\n        logger.debug(f\"Connection check failed: {e}\")\n        return False\n    except Exception as e:\n        logger.error(f\"Unexpected error during connection check: {e}\", exc_info=True)\n        # Don't hide unexpected errors in production\n        if not settings.DEBUG:\n            return False\n        raise\n```\n\n**Fix for message.py:69-70:**\n```python\ndef parse_message(self, data: str) -> Optional[Message]:\n    \"\"\"Parse message data\"\"\"\n    try:\n        return Message.from_json(data)\n    except json.JSONDecodeError as e:\n        logger.debug(f\"Invalid JSON in message: {e}\")\n        return None\n    except ValidationError as e:\n        logger.debug(f\"Message validation failed: {e}\")\n        return None\n    except Exception as e:\n        logger.error(f\"Unexpected error parsing message: {e}\", exc_info=True)\n        raise  # Don't hide unexpected errors\n```\n\n#### Step 4: Audit Script\n```python\n#\\!/usr/bin/env python3\n\"\"\"Find and report bare except clauses\"\"\"\n\nimport ast\nimport sys\nfrom pathlib import Path\nfrom typing import List, Tuple\n\nclass BareExceptFinder(ast.NodeVisitor):\n    def __init__(self):\n        self.bare_excepts: List[Tuple[int, int]] = []\n    \n    def visit_ExceptHandler(self, node):\n        if node.type is None:  # Bare except\n            self.bare_excepts.append((node.lineno, node.col_offset))\n        self.generic_visit(node)\n\ndef find_bare_excepts(filepath: Path) -> List[Tuple[int, int]]:\n    \"\"\"Find all bare except clauses in a file\"\"\"\n    try:\n        tree = ast.parse(filepath.read_text(), filename=str(filepath))\n        finder = BareExceptFinder()\n        finder.visit(tree)\n        return finder.bare_excepts\n    except Exception as e:\n        print(f\"Error parsing {filepath}: {e}\")\n        return []\n\ndef audit_codebase(root: Path):\n    \"\"\"Audit entire codebase for bare excepts\"\"\"\n    issues = []\n    for py_file in root.rglob(\"*.py\"):\n        if \"_vendor\" in py_file.parts:\n            continue\n        \n        bare_excepts = find_bare_excepts(py_file)\n        if bare_excepts:\n            for line, col in bare_excepts:\n                issues.append(f\"{py_file}:{line}:{col}\")\n    \n    return issues\n\nif __name__ == \"__main__\":\n    issues = audit_codebase(Path(\"src\"))\n    if issues:\n        print(\"Bare except clauses found:\")\n        for issue in issues:\n            print(f\"  {issue}\")\n        sys.exit(1)\n    else:\n        print(\"No bare except clauses found\\!\")\n```\n\n### Implementation Plan\n\n1. **Immediate** (1-2 days)\n   - Fix critical bare excepts that catch KeyboardInterrupt\n   - Add logging to existing handlers\n\n2. **Short-term** (1 week)\n   - Define exception hierarchy\n   - Replace all bare excepts with specific handlers\n   - Add exception audit to CI/CD\n\n3. **Long-term** (2 weeks)\n   - Implement comprehensive error handling strategy\n   - Add error recovery mechanisms\n   - Create error handling guidelines\n\n### Testing Requirements\n```python\n# tests/test_exception_handling.py\nimport pytest\nfrom unittest.mock import patch, Mock\n\nclass TestExceptionHandling:\n    def test_keyboard_interrupt_not_caught(self):\n        \"\"\"Ensure KeyboardInterrupt is not swallowed\"\"\"\n        with pytest.raises(KeyboardInterrupt):\n            with patch('some_module.operation', side_effect=KeyboardInterrupt):\n                # This should propagate\n                result = check_connection()\n    \n    def test_system_exit_not_caught(self):\n        \"\"\"Ensure SystemExit is not swallowed\"\"\"\n        with pytest.raises(SystemExit):\n            with patch('some_module.operation', side_effect=SystemExit(1)):\n                result = perform_operation()\n    \n    def test_expected_exceptions_handled(self):\n        \"\"\"Ensure expected exceptions are handled gracefully\"\"\"\n        with patch('urllib.request.urlopen', side_effect=ConnectionError):\n            result = check_connection()\n            assert result is False  # Handled gracefully\n    \n    def test_unexpected_exceptions_logged(self):\n        \"\"\"Ensure unexpected exceptions are logged\"\"\"\n        with patch('some_module.operation', side_effect=RuntimeError(\"Unexpected\\!\")):\n            with patch('logger.error') as mock_log:\n                with pytest.raises(RuntimeError):\n                    perform_operation()\n                mock_log.assert_called_with(\n                    \"Unexpected error: RuntimeError: Unexpected\\!\",\n                    exc_info=True\n                )\n```\n\n### Linting Rules\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/PyCQA/flake8\n    hooks:\n      - id: flake8\n        args: ['--select=E722']  # Bare except\n\n# pyproject.toml\n[tool.ruff]\nselect = [\"E722\"]  # Flag bare excepts\n\n[tool.pylint]\nenable = [\"bare-except\"]\n```\n\n### Best Practices Going Forward\n\n1. **Never use bare except**\n   ```python\n   # BAD\n   except:\n       pass\n   \n   # GOOD\n   except SpecificException:\n       handle_error()\n   ```\n\n2. **Always log unexpected exceptions**\n   ```python\n   except Exception as e:\n       logger.error(f\"Unexpected: {e}\", exc_info=True)\n       raise\n   ```\n\n3. **Let system exceptions propagate**\n   ```python\n   except Exception as e:\n       if isinstance(e, (SystemExit, KeyboardInterrupt)):\n           raise\n       handle_error(e)\n   ```\n\n4. **Use exception groups (Python 3.11+)**\n   ```python\n   except* NetworkException as eg:\n       for e in eg.exceptions:\n           handle_network_error(e)\n   ```\n\n### References\n- [Python Exception Hierarchy](https://docs.python.org/3/library/exceptions.html#exception-hierarchy)\n- [PEP 3134 - Exception Chaining](https://www.python.org/dev/peps/pep-3134/)\n- [Bare Except Antipattern](https://realpython.com/the-most-diabolical-python-antipattern/)\n\n### Checklist\n- [ ] Audit all bare except clauses\n- [ ] Replace with specific exception handlers\n- [ ] Add logging for unexpected errors\n- [ ] Never catch SystemExit/KeyboardInterrupt\n- [ ] Add linting rules to prevent future issues\n- [ ] Document exception handling guidelines\n- [ ] Add exception hierarchy\n- [ ] Update code review checklist",
      "updatedAt" : 1753387872.000000000,
      "user" : "tsavo-at-pieces",
      "userHtmlUrl" : "https://github.com/tsavo-at-pieces",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/102485237?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Pieces CLI for interacting with Pieces OS",
        "homepage" : "https://docs.pieces.app/products/cli",
        "name" : "cli-agent",
        "fullName" : "pieces-app/cli-agent",
        "htmlUrl" : "https://github.com/pieces-app/cli-agent",
        "gitUrl" : "git://github.com/pieces-app/cli-agent.git",
        "sshUrl" : "git@github.com:pieces-app/cli-agent.git",
        "cloneUrl" : "https://github.com/pieces-app/cli-agent.git",
        "owner" : {
          "login" : "pieces-app",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 84,
        "watchersCount" : 84,
        "size" : 24515,
        "openIssuesCount" : 56,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-24T20:10:45Z",
        "languages" : {
          "PowerShell" : 2058,
          "Shell" : 2452,
          "Ruby" : 193,
          "Python" : 7393011
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Multiple locations in the codebase use bare `except:` clauses that catch ALL exceptions, including system exits, keyboard interrupts, and critical errors. This anti-pattern makes debugging extremely difficult, hides programming errors, and can prevent proper program termination.",
      "validationOrRequirement" : "Never use bare except, Always log unexpected exceptions, Let system exceptions propagate, Use exception groups (Python 3.11+)",
      "attemptedFixes" : "Multiple locations in the codebase use bare `except:` clauses that catch ALL exceptions, including system exits, keyboard interrupts, and critical errors.",
      "otherNotes" : "Code Quality: Bare Exception Handlers Swallow All Exceptions",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406789
  }, {
    "issueDTO" : {
      "id" : 3128263912,
      "title" : "<shift>-<enter> should do an enter but keep user control",
      "url" : "https://github.com/google-gemini/gemini-cli/issues/849",
      "repositoryName" : "google-gemini/gemini-cli",
      "description" : "**Describe the bug**\nSometimes I want to tell gemini cli: \n\"\"\"\nLook at this output, this is clearly wrong:\n\n  - gic_migration_2024_06_25: ??? Assertion passed: Command succeeded.\n  - sakura_repo_exists: ??? Path exists: /Users/ricc/git/sakura\n\"\"\"\n\nWhere the first part (lines 1/2) im typing and the second part (3/4) is the output of some commands i cut pasted.\n\nHowever, as soon as I press the first eNTER i lose control and gemini cli gets it. We need to have some mechanism to introduce an <ENTER> without ceding focus to the LLM and still be in tyiuping mode.\n\nI suppose SHIFT ENTER is the most natural, but happy to consider others too (or maybe one exists and Im not aware of it)",
      "updatedAt" : 1753387803.000000000,
      "user" : "palladius",
      "userHtmlUrl" : "https://github.com/palladius",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/132802?v=4",
      "labels" : [ "kind/bug", "kind/issue-triage", "area/ux", "kind/enhancement", "priority/p1", "good first issue", "kind/parent-issue" ],
      "state" : "OPEN",
      "comments" : [ "I'd support this, and it would be a good first issue for someone interested in contributing.\n\nIf no one takes it though then I will.", "Heads up, we do support shift-enter on mac if you follow the same steps that Claude asks you to follow to configure your terminal to support it. https://b.corp.google.com/issues/424007249 has more details.", "Related: #1699", ",take", "@dewitt @palladius @jacob314 \n\n### Investigation Summary\nHere is a step-by-step summary of my debugging process:\n\n1.  Forked and cloned the repository, then searched the codebase for `readline` usage to find the core input handling logic.\n2.  Identified `useKeypress.ts` (for raw keypress events) and `InputPrompt.tsx` (for input logic) as the key files.\n3.  To see what the application receives, I temporarily modified the code to log every keypress event to a `debug.log` file.\n4.  **Key Finding:** My initial debugging proved that on a default macOS Terminal, `Shift+Enter` sends the exact same sequence (`\\r`) as a regular `Enter` press, making the two indistinguishable.\n\n### Attempted Fix & The Final Discovery\n\nBased on the initial finding, I attempted a code-only fix by teaching the application to listen for a different key combination, `Shift+Down`, which often sends a unique sequence on other terminals.\n\n1. The Code I Tested\nI modified `useKeypress.ts` to listen for the `Shift+Down` sequence (`\\x1b[1;2B`) and `InputPrompt.tsx` to handle a `key.shift` flag.\n\n```typescript\n// In useKeypress.ts, I added a check:\nif (key.sequence === '\\x1b[1;2B') {\n  key.name = 'return';\n  key.shift = true;\n}\n```\n```typescript\n// In InputPrompt.tsx, I added the key.shift check:\nif (key.ctrl || key.meta || key.shift || charBefore === '\\\\' || key.paste) {\n  // ... newline logic\n}\n```\n\n2. The Result: It Also Failed\nThis proof-of-concept did not work. To understand why, I used the `cat` command to see what my terminal was actually sending when I pressed `Shift+Down`.\nFinal Proof: The terminal sent `^[[B`, which is the standard escape code for a plain Cursor Down key.\n\n### Conclusion\n\nThis investigation leads to a definitive conclusion: the default macOS Terminal is more limited than anticipated. It appears to strip the `Shift` modifier information from both the `Enter` key and the arrow keys, making a code-only fix for a `Shift+Key` newline combination unfeasible on this specific platform, although i think this might work on other platforms which by default register shift + down as '\\x1b[1;2B' but i cant really test it.\n\nThis might explain why `Ctrl+J` is a common suggested alternative, as it sends a universal newline character (`\\n`) that doesn't rely on modifier key parsing.\n\nAs this is my first contribution, my analysis could be wrong, and I apologize for the detailed-but-failed attempt. Given these findings, what is the desired path forward? Any information from the internal `b.corp.google.com` link about how other terminals are supported would still be very helpful.\n\nThank you for your time and guidance.", "Just to add, I personally use the Warp Terminal on Mac. By default, Warp allows you to add a new-line using either of the following:\n\n* ??? + ??? Enter\n* ??? + ??? Enter\n\nBut once you are running Gemini, it doesn't work with either approach. ", "Thamks for the info on warp. We would really appreciate a pull request to make both of them work  when Gemini Cli is running in warp.", "hey @maisyk as per my knowledge warp isnt a terminal on its own, it uses a custom Rust-based UI framework and handles input at the application layer, not via the OS TTY driver\n\nWarp collects keystrokes in its own internal editor, only sending the buffer to the shell on Enter or whatever you configure\n\nso when we use gemini on warp, it is no different than using a gemini on a normal terminal, i hope this helps us understand this issue better", "hey @jacob314 i have been trying to create pull requests, but i have been getting this cla error, i tried going through the the entire process mentioned in the initial readme file. i mightve made some error surely but im not able to fix it or anything i dont even know what really is happening\n", "Can you show a screenshot or paste of the error you get?", "@ShubhamSachdeva311205 happy to help but like @palladius I can't see the screenshot showing the error you are getting.", "<img width=\"1141\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/1db61084-6db6-4bda-a141-794d460a0e4a\" />\n<img width=\"1495\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e1c7c3c9-0786-42de-888e-e33b9435e06c\" />\n<img width=\"1012\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/618401dc-f368-434e-88be-fa1df80bfb3e\" />\n<img width=\"415\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f471b65a-4352-4e9f-8fad-bdf826183188\" />\n\n@jacob314 @palladius ", "Looks like one of your commits has your correct email and one has the wrong e-mail. Easiest way to fix this is to use git rebase -i to squash down to 1 commit and then force an upload again. You may want to track down which of your tools was using the wrong email... or no e-mail hence the macbook.local thing.", "This needs to be in the docs (new `/help` has keyboard shortcuts in the end) for new line or line break. Leaving a comment here for anyone looking to create a new line:\n\n1. `\\ + Enter`\n2. `Option + Enter` (only Mac OS)\n3. `Ctrl + J`", "Upgraded to a new version of gemini-cli and shift+enter stopped working (going to next line)\nThat still works in claude code though (I'm working out of Windsurf editor atm)", "hey @leonk-sportsbet wdym \"stopped working\" was it working on the older versions ?", "@jacob314 \uD83D\uDC4B \n\n> Heads up, we do support shift-enter on mac if you follow the same steps that Claude asks you to follow to configure your terminal to support it. https://b.corp.google.com/issues/424007249 has more details.\n\nI can't access this link, but do you know if there's a way to configure this for Windows PowerShell? Ctrl+Enter seems to work, but Shift+Enter is more natural (and also what Gemini tells me I should use), but it just sends the text immediately. I couldn't find anything in Claude's docs (or general PowerShell help) about handling Shift+Enter.", "Oh and it occurs to me that it might be more complicated for me.. I'm using PowerShell, but I'm using Gemini CLI in Sandbox mode (Docker), so Gemini CLI is running on a Linux container, but is running within PowerShell (/Windows Terminal).", "We need a fix for this", "We have updated the help text to support the different platforms. `https://github.com/google-gemini/gemini-cli/blob/7ffe8038efaa5bf263a2a933819bcd4badd37dc2/packages/cli/src/ui/components/Help.tsx#L112` ", "@scottdensmore this request was to support Shift+Enter, but that change just documents using Ctrl+Enter.\n\nIs it possible (even if it requires changes in the terminal) to support Shift+Enter on Windows? For many other apps, Shift+Enter does newlines and Ctrl+Enter often submits. It's quite confusing to have the opposite behaviour.", "I also think Shift-Enter would be more natural on Linux too, Alt is used in many terminal emulators for different purposes (I use if for making a new pane for example)", "Assigned this to myself as https://github.com/deepankarsharma is working on it but I'm not able to assign it to him.", "Is `\\` `enter` still supposed to move to a new line in gemini-cli?", "Hey! Any news here? Do we have temporary solution?", "workaround: `ctrl` + `j`", "Here is what I had to configure in my iTerm2 to make multiline pastes and Shift-Enter work correctly:\n\nFirst, I needed to turn on the \"Terminal may enable paste bracketing\" option in the profile. See the screenshot below. This fixed multiline pastes. Before this any newline in the pasted text would trigger entering the prompt. I think this option should actually be enabled by default, but it was disabled for me, so I had to turn it back.\n\n<img width=\"1958\" height=\"1270\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ca601add-8b2a-4882-9dbd-bcfc3f301377\" />\n\nSecond, I created a key mapping from Shift-Enter to \"\\n\", see the screenshot below. This allowed me to use Shift-Enter to enter new lines in the prompt. This mapping is what Claude Code creates automatically, but with Gemini CLI you need to create it manually.\n\n<img width=\"1854\" height=\"1138\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8aa9614f-c86a-42b6-9e5c-bcc310e0b3c0\" />" ],
      "repository" : {
        "description" : "An open-source AI agent that brings the power of Gemini directly into your terminal.",
        "homepage" : "",
        "name" : "gemini-cli",
        "fullName" : "google-gemini/gemini-cli",
        "htmlUrl" : "https://github.com/google-gemini/gemini-cli",
        "gitUrl" : "git://github.com/google-gemini/gemini-cli.git",
        "sshUrl" : "git@github.com:google-gemini/gemini-cli.git",
        "cloneUrl" : "https://github.com/google-gemini/gemini-cli.git",
        "owner" : {
          "login" : "google-gemini",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5999,
        "stargazersCount" : 63648,
        "watchersCount" : 63648,
        "size" : 18267,
        "openIssuesCount" : 1398,
        "subscribersCount" : 311,
        "pushedAt" : "2025-07-25T00:19:30Z",
        "languages" : {
          "TypeScript" : 2800004,
          "Dockerfile" : 1354,
          "Shell" : 1112,
          "Makefile" : 1336,
          "JavaScript" : 87062
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to make Shift+Enter work as Enter but keep user control, allowing users to introduce an Enter without ceding focus to the LLM and still be in typing mode.",
      "validationOrRequirement" : "The issue requires a mechanism to introduce an Enter without ceding focus to the LLM and still be in typing mode. The Shift+Enter combination is the most natural, but other alternatives are also considered. The issue also discusses the need for a workaround or a pull request to support Shift+Enter in certain terminals.",
      "attemptedFixes" : "The author tried a code-only fix by teaching the application to listen for a different key combination, Shift+Down, which often sends a unique sequence on other terminals. The proof-of-concept did not work. The author also found that the default macOS Terminal strips the Shift modifier information from both the Enter key and the arrow keys, making a code-only fix unfeasible on this specific platform.",
      "otherNotes" : "This issue is about making Shift+Enter work as Enter but keep user control, also discusses the limitations of default macOS Terminal and other terminals, and the need for a code-only fix or a workaround. It also mentions the need for a pull request to support Shift+Enter in Warp Terminal.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406798
  }, {
    "issueDTO" : {
      "id" : 2766142492,
      "title" : "BUG: CustomBusinessDay not respecting calendar",
      "url" : "https://github.com/pandas-dev/pandas/issues/60647",
      "repositoryName" : "pandas-dev/pandas",
      "description" : "### Pandas version checks\n\n- [X] I have checked that this issue has not already been reported.\n\n- [X] I have confirmed this bug exists on the [latest version](https://pandas.pydata.org/docs/whatsnew/index.html) of pandas.\n\n- [ ] I have confirmed this bug exists on the [main branch](https://pandas.pydata.org/docs/dev/getting_started/install.html#installing-the-development-version-of-pandas) of pandas.\n\n\n### Reproducible Example\n\n```python\nfrom pandas.tseries.offsets import CustomBusinessDay\r\nimport pandas_market_calendars as mcal\r\n\r\nnyse = mcal.get_calendar('NYSE')\r\nus_bd = CustomBusinessDay(calendar=nyse)\r\n\r\ndate_range = pd.date_range('2024-12-20', periods=10, freq=us_bd)\r\ncorrect_schedule = nyse.schedule(start_date='2024-12-23', end_date='2025-01-10')\n```\n\n\n### Issue Description\n\nCustomBusinessDay is not properly showing the correct calendar holiday dates. When displaying date_range in the code above you'll see that 2024-12-25 is being included which was a market holiday and is not shown in correct_schedule in the code above.\n\n### Expected Behavior\n\nI would expect for us_bd to respect the dates in 'correct_schedule' and not include market holidays as it has in the past. When running todays date minus 1 us_bd it is showing new years day which also should be excluded and the correct result should yield '2024-12-31'\n\n### Installed Versions\n\nINSTALLED VERSIONS\r\n------------------\r\ncommit                : f538741432edf55c6b9fb5d0d496d2dd1d7c2457\r\npython                : 3.10.13.final.0\r\npython-bits           : 64\r\nOS                    : Windows\r\nOS-release            : 10\r\nVersion               : 10.0.19045\r\nmachine               : AMD64\r\nprocessor             : Intel64 Family 6 Model 207 Stepping 2, GenuineIntel\r\nbyteorder             : little\r\nLC_ALL                : None\r\nLANG                  : None\r\nLOCALE                : English_United States.1252\r\n\r\npandas                : 2.2.0\r\nnumpy                 : 1.26.4\r\npytz                  : 2023.3\r\ndateutil              : 2.8.2\r\nsetuptools            : 68.2.2\r\npip                   : 23.3.1\r\nCython                : 3.0.8\r\npytest                : 8.3.3\r\nhypothesis            : None\r\nsphinx                : None\r\nblosc                 : None\r\nfeather               : None\r\nxlsxwriter            : None\r\nlxml.etree            : None\r\nhtml5lib              : None\r\npymysql               : None\r\npsycopg2              : None\r\njinja2                : 3.1.3\r\nIPython               : 8.21.0\r\npandas_datareader     : None\r\nadbc-driver-postgresql: None\r\nadbc-driver-sqlite    : None\r\nbs4                   : 4.12.3\r\nbottleneck            : None\r\ndataframe-api-compat  : None\r\nfastparquet           : None\r\nfsspec                : 2023.6.0\r\ngcsfs                 : None\r\nmatplotlib            : 3.8.2\r\nnumba                 : None\r\nnumexpr               : 2.10.1\r\nodfpy                 : None\r\nopenpyxl              : 3.1.2\r\npandas_gbq            : None\r\npyarrow               : 15.0.0\r\npyreadstat            : None\r\npython-calamine       : None\r\npyxlsb                : None\r\ns3fs                  : None\r\nscipy                 : 1.12.0\r\nsqlalchemy            : None\r\ntables                : None\r\ntabulate              : None\r\nxarray                : None\r\nxlrd                  : 2.0.1\r\nzstandard             : None\r\ntzdata                : 2024.1\r\nqtpy                  : None\r\npyqt5                 : None",
      "updatedAt" : 1753387762.000000000,
      "user" : "benmgrant",
      "userHtmlUrl" : "https://github.com/benmgrant",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/193506539?v=4",
      "labels" : [ "Bug", "Frequency", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for the report. The CustomBusinessDay takes an `np.busdaycalendar`, but the object your passing is not an instance of this class. It is subsequently ignored. I'm not familiar with the package, but `pandas_market_calendar` has a `date_range` function - should you not be using this instead?\r\n\r\nOn the pandas side, I think we should raise when a calendar that is not an `np.busdaycalender` is passed instead of silently ignoring it.", "@benmgrant - This is expected behavior as @rhshadrach pointed out however there should be a message if a wrong object type is passed. The `CustomBusinessDay` function's `calendar` parameter takes the `busdaycalendar` object as an input. \r\n\r\nAlternate solution : You can fix this by using the following code snippet -` us_bd = nyse.holidays()` directly instead of calling the `CustomBusinessDay` as this returns the right object that can be read by the `date_range` function. \r\n\r\nComplete code:\r\n\r\n```\r\nfrom pandas.tseries.offsets import CustomBusinessDay\r\nimport pandas_market_calendars as mcal\r\n\r\nnyse = mcal.get_calendar('NYSE')\r\nus_bd = nyse.holidays()\r\n\r\ndate_range = pd.date_range('2024-12-23', periods=10, freq=us_bd)\r\ncorrect_schedule = nyse.schedule(start_date='2024-12-23', end_date='2025-01-10')\r\n```\r\n\r\nHope this helps in the mean time. I will create a PR to raise a warning message when a wrong object is passed to `CustomBusinessDay`\r\n\r\n ", "> I will create a PR to raise a warning message when a wrong object is passed to `CustomBusinessDay`\r\n\r\nI think we should raise an error, not a warning message.", "> > I will create a PR to raise a warning message when a wrong object is passed to `CustomBusinessDay`\r\n> \r\n> I think we should raise an error, not a warning message.\r\n\r\nI tried this. It ends up failing some unit tests that pass a non-`np.busdaycalendar` object to `CustomBusinessDay`, but the documentation for CustomBusinessDay lists the type of `calendar` as `np.busdaycalendar`, so another change is needed elsewhere. I think we should raise a warning for now and open another PR for this inconsistency.", "The underlying code that extracts the holidays from `calendar` is in `_get_calendar()` in pandas/_libs/tslibs/offsets.pyx:\r\n\r\n```\r\nif isinstance(calendar, np.busdaycalendar):\r\n        if not holidays:\r\n            holidays = tuple(calendar.holidays)\r\n        elif not isinstance(holidays, tuple):\r\n            holidays = tuple(holidays)\r\n        else:\r\n            # trust that calendar.holidays and holidays are\r\n            # consistent\r\n            pass\r\n        return calendar, holidays\r\n\r\n    if holidays is None:\r\n        holidays = []\r\n    try:\r\n        holidays = holidays + calendar.holidays().tolist()\r\n    except AttributeError:\r\n        pass\r\n```\r\nIt is written to handle a `calendar` that isn't an `np.busdaycalendar` but has a .holidays() method. Problem is, the try-except block presumably is meant to check for .holidays() existing, but it also excepts when the method does exist but whatever is returned by .holidays() doesn't have a tolist() method.\r\n\r\nIn this situation, `nyse.holidays()` is a `CustomBusinessDay`, but `CustomBusinessDay` itself doesn't have a `tolist()` method. So it seems like the best solution is to either add a `tolist()` method to it or one of its superclasses, or fix `pandas_market_calendars` so that `nyse.holidays()` returns a `DatetimeIndex` as done by the built-in holiday calendars in pandas.", "> It is written to handle a `calendar` that isn't an `np.busdaycalendar`\r\n\r\nThis goes back to:\r\n\r\nhttps://github.com/jbrockmendel/pandas/commit/68f626872676604f34190580df23d9653a389e03#diff-4fa7fdc555f07dc10c337a388c6a8a8f357bd861cd31171e5c2daa3ca673665eR815\r\n\r\nwhere it also accepted `pd.HolidayCalendar`. This was removed in #46920. I think the intention here is to only support `np.busdaycalendar`.", "So, if I understand correctly, it should be removed and should only accept `np.busdaycalendar`?", "@tomascortes - yes, that is my current understanding. If there are any other thoughts they are always welcome!", "@VishalSindham  are you working on this? I would like to take it otherwise ", "take", "take", "Hi @mindofVishesh are you working on this? I would like to take it otherwise", "take", "Hey everyone,\n\nI???d like to work on #60647 (???CustomBusinessDay not respecting calendar???).\nI???m planning to have CustomBusinessDay throw a TypeError if the passed-in object isn???t an np.busdaycalendar, and them add a unit test in tests/tseries/test_offsets.py to cover it.\n\nIs this still up for grabs? If so, could someone please assign it to me? Thanks!", "Hi! I???d like to work on this bug ??? assigning myself now.", "take\n" ],
      "repository" : {
        "description" : "Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more",
        "homepage" : "https://pandas.pydata.org",
        "name" : "pandas",
        "fullName" : "pandas-dev/pandas",
        "htmlUrl" : "https://github.com/pandas-dev/pandas",
        "gitUrl" : "git://github.com/pandas-dev/pandas.git",
        "sshUrl" : "git@github.com:pandas-dev/pandas.git",
        "cloneUrl" : "https://github.com/pandas-dev/pandas.git",
        "owner" : {
          "login" : "pandas-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18716,
        "stargazersCount" : 46087,
        "watchersCount" : 46087,
        "size" : 370472,
        "openIssuesCount" : 3744,
        "subscribersCount" : 1112,
        "pushedAt" : "2025-07-24T20:02:20Z",
        "languages" : {
          "Smarty" : 8852,
          "Dockerfile" : 6015,
          "Shell" : 21760,
          "CSS" : 7370,
          "C" : 354816,
          "Meson" : 12525,
          "HTML" : 457849,
          "XSLT" : 1196,
          "Cython" : 1391478,
          "Python" : 20997424
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "CustomBusinessDay is not respecting the calendar holidays. When displaying date_range, 2024-12-25 is being included which was a market holiday and is not shown in correct_schedule.",
      "validationOrRequirement" : "The CustomBusinessDay function's calendar parameter takes the busdaycalendar object as an input. It should only accept np.busdaycalendar.",
      "attemptedFixes" : "The issue was not properly fixed yet, but an alternate solution was suggested: using the holidays() method directly instead of calling the CustomBusinessDay. Also, a PR was suggested to raise a warning message when a wrong object is passed to CustomBusinessDay, but then it was decided to raise an error instead.",
      "otherNotes" : "The CustomBusinessDay is not properly showing the correct calendar holiday dates. The CustomBusinessDay takes an np.busdaycalendar, but the object your passing is not an instance of this class. It is subsequently ignored.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406804
  }, {
    "issueDTO" : {
      "id" : 3254826026,
      "title" : "[Feature]: Implement Light/Dark Mode Toggle for Website UI",
      "url" : "https://github.com/techxninjas/techxninjas-client/issues/20",
      "repositoryName" : "techxninjas/techxninjas-client",
      "description" : "\nFeature Request\n\nTo improve accessibility and user experience, especially during night-time browsing, a dark/light mode toggle feature would be a great addition.\n\nProposed Solution:\n- Add a toggle switch (e.g., in navbar or top-right corner) to switch between dark and light themes.\n- Store the user's preference using localStorage so it persists on reload.\n- Apply theme classes to body and main containers using Vue reactivity or simple JavaScript logic.\n- Ensure all text and background colors switch correctly in both modes.\n\nAcceptance Criteria:\n- Smooth toggle between dark and light themes.\n- The selected theme should persist even after reloading the page.\n- All text, icons, and background elements should adapt accordingly.\n- Fully responsive across devices.\n\nTech Stack:\nVue.js (or JavaScript if applicable), CSS, localStorage\n\nLabels:\nGSSoC???25, feature, enhancement, UI, good first issue\n",
      "updatedAt" : 1753387735.000000000,
      "user" : "AnushkaGupta0504",
      "userHtmlUrl" : "https://github.com/AnushkaGupta0504",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/216834128?v=4",
      "labels" : [ "UI/UX Enhancement", "Level 1", "gssoc25", "good first issue", "Feature Request" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I???d love to work on this issue as part of GSSoC'25. Please assign it to me.", "@AnushkaGupta0504 start working on this issue", "Is it available can i work on it?", "@Gaurav075 I'd love to work on this issue, please assigned this issue to me . ", "Hi @AnushkaGupta0504,  \nI would like to work on this issue.  \nPlease assign it to me.  \n\n" ],
      "repository" : {
        "description" : "Official Repo of TechXNinjas ??? A student-first community platform built with React.js (Typescript), Next.js, Tailwind CSS, and Express.js. Contribute, collaborate, and grow with real-world open source experience.",
        "homepage" : "https://techxninjas-client.vercel.app",
        "name" : "techxninjas-client",
        "fullName" : "techxninjas/techxninjas-client",
        "htmlUrl" : "https://github.com/techxninjas/techxninjas-client",
        "gitUrl" : "git://github.com/techxninjas/techxninjas-client.git",
        "sshUrl" : "git@github.com:techxninjas/techxninjas-client.git",
        "cloneUrl" : "https://github.com/techxninjas/techxninjas-client.git",
        "owner" : {
          "login" : "techxninjas",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 33,
        "stargazersCount" : 16,
        "watchersCount" : 16,
        "size" : 1777,
        "openIssuesCount" : 36,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-24T19:07:08Z",
        "languages" : {
          "TypeScript" : 648806,
          "CSS" : 7696,
          "JavaScript" : 1386,
          "HTML" : 3709
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a light/dark mode toggle feature for the website UI, including a toggle switch, storage of user preference using localStorage, and application of theme classes using Vue reactivity or JavaScript logic.",
      "validationOrRequirement" : "The acceptance criteria includes smooth toggle between dark and light themes, persistence of the selected theme after reloading the page, adaptation of all text, icons, and background elements, and full responsiveness across devices.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is a feature request to implement a light/dark mode toggle for the website UI, with the goal of improving accessibility and user experience, especially during night-time browsing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406809
  }, {
    "issueDTO" : {
      "id" : 218617604,
      "title" : "Undo/redo support in editor",
      "url" : "https://github.com/Mudlet/Mudlet/issues/707",
      "repositoryName" : "Mudlet/Mudlet",
      "description" : "It would be really good if people could undo all actions in Mudlet's editor:\r\n\r\n![image](https://user-images.githubusercontent.com/110988/235861804-593c6899-a82a-4f02-bf19-72809c90dbcb.png)\r\n\r\nThis would be particularly helpful in case an item is deleted or moved somewhere else by accident.\r\n\r\nLaunchpad Details: [#LP1664710](https://bugs.launchpad.net/bugs/1664710) Vadim Peretokin - 2017-02-14 20:31:12 +0000",
      "updatedAt" : 1753387682.000000000,
      "user" : "vadi2",
      "userHtmlUrl" : "https://github.com/vadi2",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/110988?v=4",
      "labels" : [ "bounty-200", "\uD83D\uDC8E Bounty", "wishlist", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Qt has an Undo framework that we should use for this: http://doc.qt.io/qt-5/qundo.html", "Is that specifically to do with script content in the editor - if so how well is it integrated into the edbee widget that we now use - doesn't that have it's own undo system (or perhaps it uses the Qt one anyway)?", "That is for undoing creation/deletion/moving of items themselves. Deleting stuff by accident is a common problem, and adding a warning pop-up is not the right way to solve that - it'll still happen. The right way is to allow people to undo any mistake.", "Just a couple of requests regarding the undo feature:\r\n\r\n1 - It would be great if not only deletions, but any changes could be undone.\r\n\r\nSometimes I'll make a change to a script or alias that will be just as bad as a deletion and want to undo it, but there's no way to do that currently if I've already clicked to another alias, trigger, or script.\r\n\r\n2 - It would also be great if not only the deletion of items, but also the deletion of groups could be undone.\r\n\r\n3 - Being able to perform a single undo would be nice, but even better would be multiple (or maybe even infinite) levels of undo.  This is useful because as a user I don't always recognize that I'll need to undo until I might have already performed a number of deletions or changes and want to go back a number of steps.\r\n", "I noticed that `Ctrl+Z` will undo changes in the code/script editor when your changing or writing code.\r\n\r\nBut if you realize you went to far back with multiple `Ctrl+Z` there is no way to go forward (redo) it should be `Ctrl+Y` but does not seem to do anything.\r\n\r\nUPDATE: under windows `Ctrl+Y` does actually perform the REDO, and under linux the key binding for Redo is Ctrl+Shift+Z\r\n\r\nUnless I am missing something, Everything that was being asked for in this issue has been solved.... ", "@xekon wrote:\r\n> Unless I am missing something, Everything that was being asked for in this issue has been solved....\r\n\r\n`Ctrl + Z` does work nicely but only if you are talking about deleting content as in certain lines in a script box, maybe all of them. Like @diamond-lizard said, it only works until you open a different script. Even if you come back to the original script immediately, you can't undo anything anymore. It also won't work at all against deleting a whole script item or group.", "/bounty $50", "## \uD83D\uDC8E $300 bounty [??? Mudlet](https://console.algora.io/org/Mudlet)\n\n\uD83D\uDD28 See [instructions](https://wiki.mudlet.org/w/Compiling_Mudlet) for compiling Mudlet\n\n### Steps to solve:\n1. **Start working**: Comment `/attempt #707`\n2. **Submit work**: Create a pull request including `/claim #707` in the PR body to claim the bounty\n2. **Attach proof**: Include a screencast in the PR that fully tests the new functionality\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://docs.algora.io/bounties/payments#supported-countries-regions)\n\nThank you for contributing to Mudlet/Mudlet!\n\n**[Add a bounty](https://console.algora.io/org/Mudlet/bounties/community?fund=Mudlet%2FMudlet%23707)** ??? **[Share on socials](https://twitter.com/intent/tweet?text=%24300+bounty%21+%F0%9F%92%8E+https%3A%2F%2Fgithub.com%2FMudlet%2FMudlet%2Fissues%2F707&related=algoraio)**\n\n<table>\n<thead>\n<tr>\n<th>Attempt</th>\n<th>Started (GMT+0)</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\uD83D\uDD34 @Narottamchy</td>\n<td>Aug 19, 2023, 12:32:31 PM</td>\n<td>WIP</td>\n</tr>\n<tr>\n<td>\uD83D\uDFE2 @psp-4</td>\n<td>Oct 19, 2023, 5:02:13 AM</td>\n<td>WIP</td>\n</tr>\n<tr>\n<td>\uD83D\uDFE2 @atari2600tim</td>\n<td>Dec 11, 2023, 7:44:03 PM</td>\n<td>WIP</td>\n</tr>\n<tr>\n<td>\uD83D\uDD34 @feliciien</td>\n<td>Mar 17, 2024, 4:06:54 PM</td>\n<td>WIP</td>\n</tr>\n<tr>\n<td>\uD83D\uDFE2 @coder1152</td>\n<td></td>\n<td><a href=\"https://github.com/Mudlet/Mudlet/pull/7447\">#7447</a></td>\n</tr>\n</tbody>\n</table>", "I would love to work on this", "/attempt\r\n", "/attempt #707\n\n<details id=\"algora-options\">\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cli994w9g0010l80fk8bkio4s/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n", "/attempt #707\n\n<details id=\"algora-options\">\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cli994w9g0010l80fk8bkio4s/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n", "/bounty $200", "/attempt #707\n\n<details id=\"algora-options\">\n  <summary>Options</summary>\n  <ul>\n    <li>\n      <a href=\"https://console.algora.io/api/bounties/cli994w9g0010l80fk8bkio4s/cancel-attempt\">\n        Cancel my attempt\n      </a>\n    </li>\n  </ul>\n</details>\n", "> [!NOTE]\n> The user @psp-4 is already attempting to complete issue #707 and claim the bounty. We recommend checking in on @psp-4's progress, and potentially collaborating, before starting a new solution.", "@atari2600tim Are you still attempting this? I'd like to attempt if you aren't.", "I have the functionality right now and plan to have it presentable in a few days", "Okay, thank you!", "Any progress?", "Not that we have seen, but there is an outstanding bounty available to pick up on this.", "/attempt #707\n\n<div id=\"algora\" />\n\n| [Algora profile](https://console.algora.io/@/feliciien) | Completed bounties | Tech | Active attempts | Options |\n| --- | --- | --- | --- | --- |\n| @feliciien | 5 bounties from 1 project | <div align=\"center\">MDX, Rust, <br />JavaScript & more</div> | <div align=\"center\"></div> | [Cancel attempt](https://console.algora.io/api/bounties/cli994w9g0010l80fk8bkio4s/cancel-attempt) |", "\uD83D\uDCA1 @coder1152 submitted a [pull request](https://github.com/Mudlet/Mudlet/pull/7447) that claims the bounty. You can [visit your bounty board](https://console.algora.io/org/Mudlet/bounties) to reward.", "/bounty $300", "> /bounty $300\r\n\r\nCan i have the quick note of what are the issues have finished and what are needed to work on. ", "Hey, all of it still needs working on.", "Hi, I have just tested the undo/redo version 32bit on Windows11 and it works well, but the functionality is limited to the active element only.\r\n\r\nWhen I write a package and switch often from a trigger to a script, then back to a label, ecc. Every time I change element the undo/redo command list is empty.\r\n\r\nI don't know if this behaviour is by design or not, but having a separate undo/redo list for every item (almost until the editor windows is opened) should be very usefulll.", "Hey @wiploo, can you help us test the latest commit?  Also please put comments into that PR so the developer can track issues relevant to that code.  Thanks!", "Bounty still active?", "@vadi2 is it still open? ", "Still open, but there is a pretty advanced PR j. https://github.com/Mudlet/Mudlet/pull/7447", "@002harshit @kpo8 @ArtiomGusev just an FYI, the bounty for undo/redo is open and there aren't any PRs outstanding with it - so feel free to give it a go.\n\n", "@vadi2 I am interested in giving it a go" ],
      "repository" : {
        "description" : "?????? A cross-platform, open source, and super fast MUD client with scripting in Lua",
        "homepage" : "https://mudlet.org",
        "name" : "Mudlet",
        "fullName" : "Mudlet/Mudlet",
        "htmlUrl" : "https://github.com/Mudlet/Mudlet",
        "gitUrl" : "git://github.com/Mudlet/Mudlet.git",
        "sshUrl" : "git@github.com:Mudlet/Mudlet.git",
        "cloneUrl" : "https://github.com/Mudlet/Mudlet.git",
        "owner" : {
          "login" : "Mudlet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 294,
        "stargazersCount" : 806,
        "watchersCount" : 806,
        "size" : 187164,
        "openIssuesCount" : 554,
        "subscribersCount" : 32,
        "pushedAt" : "2025-07-25T00:53:56Z",
        "languages" : {
          "Dockerfile" : 3238,
          "C++" : 5829239,
          "Shell" : 84823,
          "CSS" : 6298,
          "C" : 10418,
          "CMake" : 67898,
          "Objective-C++" : 5503,
          "Linker Script" : 124,
          "QMake" : 84788,
          "JavaScript" : 4385,
          "Lua" : 887764,
          "Objective-C" : 2060
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to implement undo and redo functionality in Mudlet's editor, allowing users to undo any changes made to scripts, aliases, or other elements in the editor.",
      "validationOrRequirement" : "The issue requires the ability to undo not only deletions, but any changes, and also to have multiple levels of undo.",
      "attemptedFixes" : "Some attempts have been made to solve this issue, but it seems that they are still in progress. There is a pull request #7447 that claims the bounty, but it's not clear if it fully addresses all the requirements.",
      "otherNotes" : "Qt has an Undo framework that we should use for this: http://doc.qt.io/qt-5/qundo.html. The issue is not fully solved as Ctrl+Z only works until you open a different script, and Ctrl+Y doesn't work for redo. There are still some limitations and edge cases to be handled.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406815
  }, {
    "issueDTO" : {
      "id" : 3142864691,
      "title" : "Add Flux CICD support",
      "url" : "https://github.com/kitops-ml/kitops/issues/898",
      "repositoryName" : "kitops-ml/kitops",
      "description" : "**Describe the problem you're trying to solve**\nMany large companies (financial, health) use fluxcd (and its fluxcd controlplane) for Kubernetes deployment and automation. As it is much easier and has a higher performant engine it would be great if kitops also support cicd with fluxcd.\n",
      "updatedAt" : 1753387410.000000000,
      "user" : "suse-coder",
      "userHtmlUrl" : "https://github.com/suse-coder",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/190763341?v=4",
      "labels" : [ "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Can you not use the kit CLI from within a Flux pipeline? Is there a particular use case that you feel needs a native integration?", "I guess. Maybe just add Flux support to the website (as currently there is an example for argo)", "I'll try and get something documented in the next few weeks...", "Found this: https://docs.google.com/document/d/14Olk0Pb37NeIEIWBINEidu7R7HmxpZ09tZhoy4RZHAI/edit?usp=sharing", "Any thoughts on the doc Jwilliamsr linked? @suse-coder \n" ],
      "repository" : {
        "description" : "An open source DevOps tool for packaging and versioning AI/ML models, datasets, code, and configuration into an OCI artifact.",
        "homepage" : "https://KitOps.org",
        "name" : "kitops",
        "fullName" : "kitops-ml/kitops",
        "htmlUrl" : "https://github.com/kitops-ml/kitops",
        "gitUrl" : "git://github.com/kitops-ml/kitops.git",
        "sshUrl" : "git@github.com:kitops-ml/kitops.git",
        "cloneUrl" : "https://github.com/kitops-ml/kitops.git",
        "owner" : {
          "login" : "kitops-ml",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 123,
        "stargazersCount" : 1083,
        "watchersCount" : 1083,
        "size" : 51609,
        "openIssuesCount" : 32,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-21T20:10:01Z",
        "languages" : {
          "TypeScript" : 16356,
          "Dockerfile" : 4208,
          "Shell" : 12265,
          "CSS" : 1910,
          "Awk" : 1246,
          "Vue" : 63332,
          "JavaScript" : 23409,
          "Go" : 414754,
          "HTML" : 1491,
          "Python" : 561
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to add Flux CICD support to kitops, which would be beneficial for large companies that use Fluxcd for Kubernetes deployment and automation.",
      "validationOrRequirement" : "The requirement is to support CICD with Fluxcd, which is considered a high-performing engine for Kubernetes deployment and automation.",
      "attemptedFixes" : "The author mentioned trying to get something documented in the next few weeks, and a suggestion to add Flux support to the website, similar to the example for Argo.",
      "otherNotes" : "The issue is about adding Flux CICD support, with potential use cases mentioned in the comments, and a link to a Google document for further discussion.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406820
  }, {
    "issueDTO" : {
      "id" : 2753533716,
      "title" : "Document `nargo info --profile-execution`",
      "url" : "https://github.com/noir-lang/noir/issues/6905",
      "repositoryName" : "noir-lang/noir",
      "description" : "### Problem\n\nThe current docs partly describes the possible values of `nargo info --profile-execution`, but not what it is useful for: https://noir-lang.org/docs/dev/reference/nargo_commands#nargo-info\n\n![Image](https://github.com/user-attachments/assets/d13dd384-18f3-4ef5-9ca8-294e9ae4c4ae)\n\n### Happy Case\n\nDocument the flag [in-line](https://github.com/noir-lang/noir/pull/8718#issuecomment-2944418025).\n\n### Additional Context\n\nFlag introduced in https://github.com/noir-lang/noir/pull/6396\n\n### Project Impact\n\nNice-to-have\n\n### Would you like to submit a PR for this Issue?\n\nNo",
      "updatedAt" : 1753387263.000000000,
      "user" : "Savio-Sou",
      "userHtmlUrl" : "https://github.com/Savio-Sou",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/72797635?v=4",
      "labels" : [ "documentation", "help wanted", "nargo", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! May I try to resolve this issue? ", "Hey @asterite ! Can you check out my PR?" ],
      "repository" : {
        "description" : "Noir is a domain specific language for zero knowledge proofs",
        "homepage" : "https://noir-lang.org",
        "name" : "noir",
        "fullName" : "noir-lang/noir",
        "htmlUrl" : "https://github.com/noir-lang/noir",
        "gitUrl" : "git://github.com/noir-lang/noir.git",
        "sshUrl" : "git@github.com:noir-lang/noir.git",
        "cloneUrl" : "https://github.com/noir-lang/noir.git",
        "owner" : {
          "login" : "noir-lang",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 312,
        "stargazersCount" : 1126,
        "watchersCount" : 1126,
        "size" : 805465,
        "openIssuesCount" : 637,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-24T21:38:18Z",
        "languages" : {
          "TypeScript" : 207417,
          "Dockerfile" : 626,
          "C++" : 462368,
          "Shell" : 31637,
          "Rust" : 9289707,
          "JavaScript" : 9443,
          "Gnuplot" : 199,
          "Ruby" : 3351,
          "Noir" : 1727831
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document `nargo info --profile-execution` with its usefulness",
      "validationOrRequirement" : "Document the flag in-line, partly describes the possible values of `nargo info --profile-execution` but not what it is useful for",
      "attemptedFixes" : "PR submitted by @asterite",
      "otherNotes" : "Flag introduced in https://github.com/noir-lang/noir/pull/6396, Nice-to-have, https://github.com/noir-lang/noir/pull/8718#issuecomment-2944418025",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406824
  }, {
    "issueDTO" : {
      "id" : 3261061006,
      "title" : "Footer visual differences to penpot design",
      "url" : "https://github.com/EXXETA/trufos/issues/466",
      "repositoryName" : "EXXETA/trufos",
      "description" : "**Is your feature request related to a problem? Please describe.**\n\nCurrently the footer in the sidebar looks different from the penpot design.\n\n**Describe the solution you'd like**\n\nWe should adjust the implementation so that it matches the penpot design.\n\n**Additional context**\n\nCurrently we don't yet have a modal for application settings (which is different to collection settings). When working on this ticket you can either disable the settings button or you can make it open the collection settings as well.\n\nYou can take a look at the design by opening our [penpot board](https://penpot.soulka.de/#/workspace?page-id=855e2698-a41c-806d-8006-8ac4e95f73e2&file-id=88a057e2-ffe4-81cb-8005-c2e9c63649bf&team-id=88a057e2-ffe4-81cb-8005-bf2df0f05306&layout=layers) and logging in with the user `info@trufos.com` and password `password`.\n\n<img width=\"738\" height=\"244\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/51a2cf8b-1df0-4abf-a303-6665b6688b4f\" />",
      "updatedAt" : 1753387095.000000000,
      "user" : "kwerber",
      "userHtmlUrl" : "https://github.com/kwerber",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29689569?v=4",
      "labels" : [ "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A modern, open source REST API client",
        "homepage" : "https://exxeta.github.io/trufos/",
        "name" : "trufos",
        "fullName" : "EXXETA/trufos",
        "htmlUrl" : "https://github.com/EXXETA/trufos",
        "gitUrl" : "git://github.com/EXXETA/trufos.git",
        "sshUrl" : "git@github.com:EXXETA/trufos.git",
        "cloneUrl" : "https://github.com/EXXETA/trufos.git",
        "owner" : {
          "login" : "EXXETA",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 41,
        "watchersCount" : 41,
        "size" : 5833,
        "openIssuesCount" : 32,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T16:08:41Z",
        "languages" : {
          "TypeScript" : 438036,
          "CSS" : 4412,
          "JavaScript" : 5800,
          "HTML" : 220
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Adjust the footer in the sidebar to match the Penpot design",
      "validationOrRequirement" : "Adjust the implementation to match the Penpot design",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to a problem with the footer in the sidebar not matching the Penpot design. The solution is to adjust the implementation to match the design. Additional context includes the absence of a modal for application settings, and the possibility of disabling the settings button or making it open the collection settings as well.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406828
  }, {
    "issueDTO" : {
      "id" : 3255675651,
      "title" : "Add pool swap",
      "url" : "https://github.com/bitaxeorg/ESP-Miner/issues/1159",
      "repositoryName" : "bitaxeorg/ESP-Miner",
      "description" : "Add a button to swap primary and secondary pool for simplicity",
      "updatedAt" : 1753386801.000000000,
      "user" : "WantClue",
      "userHtmlUrl" : "https://github.com/WantClue",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/86001033?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "can i add it for you @WantClue ?", "> can i add it for you [@WantClue](https://github.com/WantClue) ?\n\nplease PR it if you do have some code" ],
      "repository" : {
        "description" : "A bitcoin ASIC miner for the ESP32",
        "homepage" : null,
        "name" : "ESP-Miner",
        "fullName" : "bitaxeorg/ESP-Miner",
        "htmlUrl" : "https://github.com/bitaxeorg/ESP-Miner",
        "gitUrl" : "git://github.com/bitaxeorg/ESP-Miner.git",
        "sshUrl" : "git@github.com:bitaxeorg/ESP-Miner.git",
        "cloneUrl" : "https://github.com/bitaxeorg/ESP-Miner.git",
        "owner" : {
          "login" : "bitaxeorg",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 258,
        "stargazersCount" : 657,
        "watchersCount" : 657,
        "size" : 4926,
        "openIssuesCount" : 139,
        "subscribersCount" : 41,
        "pushedAt" : "2025-07-24T20:01:51Z",
        "languages" : {
          "TypeScript" : 135949,
          "Dockerfile" : 1420,
          "CSS" : 16736,
          "Shell" : 6683,
          "C" : 561751,
          "CMake" : 5354,
          "SCSS" : 254018,
          "Makefile" : 255,
          "JavaScript" : 1276,
          "HTML" : 55712,
          "Python" : 11839
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a button to swap primary and secondary pool for simplicity",
      "validationOrRequirement" : "none mentioned",
      "attemptedFixes" : "no attempts or blockers mentioned in the issue",
      "otherNotes" : "PR is requested if a contributor has some code to add the feature",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406830
  }, {
    "issueDTO" : {
      "id" : 3261047739,
      "title" : "Collection Modal visual differences to penpot design",
      "url" : "https://github.com/EXXETA/trufos/issues/465",
      "repositoryName" : "EXXETA/trufos",
      "description" : "**Is your feature request related to a problem? Please describe.**\n\nCurrently the collection settings modal does not yet look like the penpot design concept.\n\n**Describe the solution you'd like**\n\nWe should adjust the current implementation so that it matches the design.\n\n**Additional context**\n\nYou can take a look at the design by opening our [penpot board](https://penpot.soulka.de/#/workspace?page-id=adb45dd5-8c83-80f0-8006-895ed54d4b82&file-id=88a057e2-ffe4-81cb-8005-c2e9c63649bf&team-id=88a057e2-ffe4-81cb-8005-bf2df0f05306&layout=layers&board-id=adb45dd5-8c83-80f0-8006-895eddec13ad) and logging in with the user `info@trufos.com` and password `password`.\n\n<img width=\"2880\" height=\"2048\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3073de99-9722-4429-b2c6-029a4f3dff02\" />",
      "updatedAt" : 1753386362.000000000,
      "user" : "kwerber",
      "userHtmlUrl" : "https://github.com/kwerber",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29689569?v=4",
      "labels" : [ "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A modern, open source REST API client",
        "homepage" : "https://exxeta.github.io/trufos/",
        "name" : "trufos",
        "fullName" : "EXXETA/trufos",
        "htmlUrl" : "https://github.com/EXXETA/trufos",
        "gitUrl" : "git://github.com/EXXETA/trufos.git",
        "sshUrl" : "git@github.com:EXXETA/trufos.git",
        "cloneUrl" : "https://github.com/EXXETA/trufos.git",
        "owner" : {
          "login" : "EXXETA",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 41,
        "watchersCount" : 41,
        "size" : 5833,
        "openIssuesCount" : 32,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T16:08:41Z",
        "languages" : {
          "TypeScript" : 438036,
          "CSS" : 4412,
          "JavaScript" : 5800,
          "HTML" : 220
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Adjust the collection settings modal to match the penpot design concept",
      "validationOrRequirement" : "Match the current implementation with the penpot design concept",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the collection settings modal not matching the penpot design concept. The solution is to adjust the current implementation to match the design. Additional context includes a link to the penpot board and a screenshot.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406833
  }, {
    "issueDTO" : {
      "id" : 3246881452,
      "title" : "ValueError: You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time",
      "url" : "https://github.com/huggingface/transformers/issues/39542",
      "repositoryName" : "huggingface/transformers",
      "description" : "### System Info\n\n- `transformers` version: 4.53.2\n- Platform: **Ubuntu 22.04** Linux 5.15.0-139-generic\n-  **Python 3.10.18** + ipykernel 6.29.5\n- Pytorch 2.7.1+cu118\n\n### Who can help?\n\n@ArthurZucker \n@SunMarc \n\n### Information\n\n- [ ] The official example scripts\n- [x] My own modified scripts\n\n### Tasks\n\n- [ ] An officially supported task in the `examples` folder (such as GLUE/SQuAD, ...)\n- [x] My own task or dataset (give details below)\n\n### Reproduction\n\n&emsp;I want to build a new MT model with  **bert-based encoder** and a **decoder from opus-mt-en-zh** (loaded as `MarianMTModel`), BUT when I execute `Trainer.train()`, It report ValueError: `You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time`. This is code about my model and trainer.\n&emsp;Thanks for helping!\n\n```Python\n# ManchuBERT Encoder + Opus-MT-zh Decoder\n\nimport torch\nfrom torch import nn\nfrom transformers.modeling_outputs import Seq2SeqLMOutput\n\n\ndef get_extended_attention_mask(attention_mask, input_shape, device, dtype=torch.float32):\n    \"\"\"\n    attention_mask: [B, seq_len]  \n    return:        [B, 1, 1, seq_len] \n    \"\"\"\n    mask = attention_mask[:, None, None, :]        # [B, 1, 1, seq_len]\n    mask = mask.to(dtype=dtype)\n    mask = (1.0 - mask) * -10000.0\n    return mask\n\n\nclass ManchuZhMT(nn.Module):\n    def __init__(self, bert, marian):\n        super().__init__()\n        self.decoder_embeddings = marian.model.decoder.embed_tokens\n        self.embeddings = bert.embeddings\n        self.encoder = bert.encoder\n        self.decoder = marian.model.decoder\n        self.lm_head = marian.lm_head\n        self.final_logits_bias = marian.final_logits_bias\n        self.config = marian.config\n\n    def forward(self,\n                input_ids=None,\n                attention_mask=None,\n                decoder_input_ids=None,\n                decoder_attention_mask=None,\n                labels=None,\n                **kwargs):\n\n\n        hidden_states = self.embeddings(input_ids=input_ids)\n        attention_mask = attention_mask.to(dtype=torch.float32)\n\n        extended_mask = get_extended_attention_mask(attention_mask, input_ids.shape, input_ids.device)\n\n        enc_out = self.encoder(hidden_states=hidden_states,\n                               attention_mask=extended_mask,\n                               return_dict=True)\n\n        dec_out = self.decoder(\n                               input_ids=decoder_input_ids,\n                               attention_mask=decoder_attention_mask,\n                               encoder_hidden_states=enc_out.last_hidden_state,\n                               encoder_attention_mask=extended_mask,\n                               return_dict=True)\n\n        logits = self.lm_head(dec_out.last_hidden_state) + self.final_logits_bias\n\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n\n        return Seq2SeqLMOutput(loss=loss, logits=logits)\n\n    def prepare_inputs_for_generation(self, *args, **kwargs):\n        return self.decoder.prepare_inputs_for_generation(*args, **kwargs)\n\n    def _prepare_encoder_decoder_kwargs_for_generation(self, *args, **kwargs):\n        return self.decoder._prepare_encoder_decoder_kwargs_for_generation(*args, **kwargs)\n\nmodel = ManchuZhMT(manchu_model, chn_model)\nprint(model)\n\n# freeze Decoder + LM Head \nfor p in model.decoder.parameters():\n    p.requires_grad = False\nfor p in model.lm_head.parameters():\n    p.requires_grad = False\n```\n\n```Python\n# Add LoRA for Encoder\nfrom peft import LoraConfig, get_peft_model, TaskType\n\nnum_layers = len(model.encoder.layer)\ntarget_modules = []\nfor i in range(num_layers):\n    target_modules.extend([\n        f\"encoder.layer.{i}.attention.self.query\",\n        f\"encoder.layer.{i}.attention.self.key\",\n        f\"encoder.layer.{i}.attention.self.value\",\n        f\"encoder.layer.{i}.attention.output.dense\",\n        f\"encoder.layer.{i}.intermediate.dense\",\n        f\"encoder.layer.{i}.output.dense\",\n    ])\n\nlora_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM, \n    target_modules=target_modules,\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n```\n\n```Python\n# Start Train!\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=\"./lora_with_bert\",\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=10,\n    learning_rate=3e-4,\n    fp16=True,\n    save_strategy=\"epoch\",\n    predict_with_generate=True,\n    logging_steps=100,\n    report_to=\"none\",\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_ds[\"train\"],\n    eval_dataset=tokenized_ds[\"val\"],\n    tokenizer=manchu_tok,\n)\ntrainer.train()\ntrainer.save_model(\"./lora_with_bert/final\")\n```\n\n\n### Expected behavior\n\nI expected the script to train normally just as using `opus-mt-en-zh` only and get the lora checkpoint.",
      "updatedAt" : 1753386333.000000000,
      "user" : "xjackzenvey",
      "userHtmlUrl" : "https://github.com/xjackzenvey",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/124496973?v=4",
      "labels" : [ "Good First Issue", "Usage", "bug", "trainer" ],
      "state" : "OPEN",
      "comments" : [ "\n\nHi! I had a look at your custom `ManchuZhMT` model.  \nThe `ValueError: You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time` comes from the fact that your `forward` always passes `decoder_input_ids` to the Marian decoder, while **Trainer + PEFT (LoRA)** may inject a `decoder_inputs_embeds` entry into `**kwargs`. When both reach the decoder, Transformers raises that validation error.\n\n**Minimal fix in your custom model:** drop one of the two before calling `self.decoder` (keeping `decoder_input_ids` is the simplest). For example:\n\n```python\ndef forward(\n    self,\n    input_ids=None,\n    attention_mask=None,\n    decoder_input_ids=None,\n    decoder_attention_mask=None,\n    labels=None,\n    **kwargs,\n):\n    ...\n    # Remove conflicting argument if both are present\n    if \"decoder_inputs_embeds\" in kwargs and decoder_input_ids is not None:\n        kwargs.pop(\"decoder_inputs_embeds\")\n\n    dec_out = self.decoder(\n        input_ids=decoder_input_ids,\n        attention_mask=decoder_attention_mask,\n        encoder_hidden_states=enc_out.last_hidden_state,\n        encoder_attention_mask=extended_mask,\n        return_dict=True,\n        **kwargs,\n    )\n    ...\n````\n\nAfter adding this guard, `trainer.train()` should run normally and produce your LoRA checkpoint.\n\nIf you prefer using embeddings explicitly, you could instead set `decoder_input_ids=None` and keep `decoder_inputs_embeds`.\n\nLet me know if you???d like a small PR adding a defensive check on the library side; happy to help adjust anything if needed. Thanks!\n\n\n", "Opened PR #39566: **Ignore `decoder_inputs_embeds` when `decoder_input_ids` are present**.\n\nIt adds a small guard in `Seq2SeqTrainer.compute_loss` and a test to prevent the `ValueError`.  \nHappy to adjust if you prefer a different location for the fix. Thanks!\n", "@JoseAlvarezMedina \nThanks for your help. I edit my `ManchuZhMT` and add `kwargs = {}` (for debug).\n**However,** The `ValueError` still exists, So I found the code in `file transformers/models/marian/modeling_marian.py, line 992`:\n```Python\n        # retrieve input_ids and inputs_embeds\n        if (input_ids is None) ^ (inputs_embeds is not None):\n            raise ValueError(\"You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\")\n        elif input_ids is not None:\n            input = input_ids\n            input_shape = input.shape\n            input_ids = input_ids.view(-1, input_shape[-1])\n        elif inputs_embeds is not None:\n            input_shape = inputs_embeds.size()[:-1]\n            input = inputs_embeds[:, :, -1]\n        else:\n            raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n```\nBy Debugging, I found that both my `decoder_input_ids` and `decoder_inputs_embeds` is `None`, as the screenshot below:\n\n<img width=\"1692\" height=\"1313\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/90baacd7-588f-4422-af88-31f46c9ae097\" />\n\nSo maybe the ValueError is caused by the process that `Seq2SeqTrainer`  generate `decoder_input_ids`, or my JSONL Loader(below)?\n```Python\nfrom datasets import load_dataset\n\nmax_len = 256\nbatch_size = 16\n\nraw_ds = load_dataset(\"json\", data_files={\"train\":\"train.jsonl\",\"val\":\"val.jsonl\"})\n\ndef tokenize(batch):\n    model_inputs = manchu_tok(\n        batch[\"source\"],\n        max_length=max_len,\n        truncation=True,\n        padding=\"max_length\"\n    )\n    with chn_tok.as_target_tokenizer():\n        labels = chn_tok(\n            batch[\"target\"],\n            max_length=max_len,\n            truncation=True,\n            padding=\"max_length\"\n        )\n    model_inputs[\"labels\"] = [\n        [(t if t != chn_tok.pad_token_id else -100) for t in label]\n        for label in labels[\"input_ids\"]\n    ]\n    return model_inputs\n\ntokenized_ds = raw_ds.map(tokenize, batched=True)\n```\nIs there any solutions? Thanks\uD83D\uDE23", "Hi, I see this is closed! Has it been resolved?", "@Rocketknight1 emm It haven't been solved yet, and I seemed to close it by mistake.\n\n> Hi, I see this is closed! Has it been resolved?\n\n", "Just took a look - this issue is quite difficult to resolve because it depends on your custom code, and so it's hard for me to figure out if it's a bug in our code or in yours!" ],
      "repository" : {
        "description" : "\uD83E\uDD17 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
        "homepage" : "https://huggingface.co/transformers",
        "name" : "transformers",
        "fullName" : "huggingface/transformers",
        "htmlUrl" : "https://github.com/huggingface/transformers",
        "gitUrl" : "git://github.com/huggingface/transformers.git",
        "sshUrl" : "git@github.com:huggingface/transformers.git",
        "cloneUrl" : "https://github.com/huggingface/transformers.git",
        "owner" : {
          "login" : "huggingface",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 29761,
        "stargazersCount" : 147407,
        "watchersCount" : 147407,
        "size" : 338537,
        "openIssuesCount" : 1892,
        "subscribersCount" : 1156,
        "pushedAt" : "2025-07-24T18:37:49Z",
        "languages" : {
          "Dockerfile" : 42942,
          "C++" : 19093,
          "Shell" : 1838,
          "C" : 7703,
          "Makefile" : 4377,
          "Cython" : 3635,
          "Python" : 68164404,
          "Cuda" : 204021,
          "Jsonnet" : 937
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to resolve the ValueError: You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time when executing Trainer.train().",
      "validationOrRequirement" : "The author is trying to build a new MT model with a bert-based encoder and a decoder from opus-mt-en-zh. The model should be able to train normally and produce a LoRA checkpoint.",
      "attemptedFixes" : "The author has tried to fix the issue by dropping one of the two conflicting arguments before calling the decoder. However, the issue still exists. The author has also tried to debug the issue and found that both decoder_input_ids and decoder_inputs_embeds are None. The issue has been opened and is still open.",
      "otherNotes" : "This issue is about ValueError: You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time. The author is trying to build a new MT model with a bert-based encoder and a decoder from opus-mt-en-zh. The error occurs when executing Trainer.train(). The issue has been opened and is still open.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406840
  }, {
    "issueDTO" : {
      "id" : 3261038497,
      "title" : "X-Taint Header does not expect or accept compliant JSON",
      "url" : "https://github.com/SAP/project-foxhound/issues/324",
      "repositoryName" : "SAP/project-foxhound",
      "description" : "The X-Taint Header looks like it is JSON, i.e., `X-Taint: [{ begin: 4, end: 8, source: \"e2e\" }, { begin: 17, end: 20, source: \"e2e\" }]` but it has a key difference to *real* JSON. It only accepts unquoted keys, i.e., `JSON.stringify(taints)` will not produce a valid value for the `X-Taint header`.\n\nA helper function to transform it into the pseudo JSON is, e.g., the following:\n\n```javascript\nfunction formatXTaintEntry(taint) {\n  let entries = [];\n  if(Object.hasOwn(taint, \"begin\")) {\n    entries.push(`begin: ${taint.begin}`);\n  } else {\n    throw new Error(\"Missing begin key\");\n  }\n  if(Object.hasOwn(taint, \"end\")) {\n    entries.push(`end: ${taint.end}`);\n  } else {\n    throw new Error(\"Missing end key\");\n  }\n  if(Object.hasOwn(taint, \"source\")) {\n    entries.push(`source: \"${taint.source}\"`);\n  } else {\n    throw new Error(\"Missing source key\");\n  }\n  return `{ ${entries.join(\", \")} }`;\n}\n\nfunction formatXTaint(taints) {\n  let xtaint_entries = [];\n  for(const taint of taints) {\n    xtaint_entries.push(formatXTaintEntry(taint));\n  }\n  return `[${xtaint_entries.join(\", \")}]`;\n}\n```\n\nThis is just an inconvenience, but I plan to resolve this by changing the parser for [Taint Ranges](https://github.com/SAP/project-foxhound/blob/main/taint/Taint.cpp#L1192) to accept either format after submission of my dissertation. As I am currently probably the only user of this feature, and this should remain backwards compatible if someone adopts it, this should only make life easier for any user.",
      "updatedAt" : 1753386054.000000000,
      "user" : "leeN",
      "userHtmlUrl" : "https://github.com/leeN",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/49810?v=4",
      "labels" : [ "end-to-end tainting", "refactoring", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A web browser with dynamic data-flow tracking enabled in the Javascript engine and DOM, based on Mozilla Firefox (https://github.com/mozilla-firefox/firefox). It can be used to identify insecure data flows or data privacy leaks in client-side web applications.",
        "homepage" : "",
        "name" : "project-foxhound",
        "fullName" : "SAP/project-foxhound",
        "htmlUrl" : "https://github.com/SAP/project-foxhound",
        "gitUrl" : "git://github.com/SAP/project-foxhound.git",
        "sshUrl" : "git@github.com:SAP/project-foxhound.git",
        "cloneUrl" : "https://github.com/SAP/project-foxhound.git",
        "owner" : {
          "login" : "SAP",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 114,
        "watchersCount" : 114,
        "size" : 5157791,
        "openIssuesCount" : 57,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-21T13:18:44Z",
        "languages" : {
          "GDB" : 5718,
          "CMake" : 85368,
          "M4" : 519370,
          "Go" : 14155,
          "HTML" : 229539639,
          "NSIS" : 566437,
          "Groovy" : 8995,
          "Pawn" : 5519,
          "IDL" : 2619752,
          "Befunge" : 6280,
          "SCSS" : 301761,
          "Gnuplot" : 710,
          "Pascal" : 6780,
          "Assembly" : 7039249,
          "Python" : 29383122,
          "PowerShell" : 5881,
          "Yacc" : 2517,
          "Jinja" : 875,
          "Rust" : 14705845,
          "Objective-C++" : 637989,
          "SWIG" : 3312,
          "Fluent" : 970694,
          "Perl" : 541372,
          "Ragel" : 35253,
          "AIDL" : 12985,
          "RenderScript" : 3698,
          "Scilab" : 99,
          "Starlark" : 66196,
          "Batchfile" : 30560,
          "Meson" : 85483,
          "Swift" : 16097,
          "Mako" : 1006,
          "C#" : 126138,
          "C" : 113377273,
          "Makefile" : 2777879,
          "DIGITAL Command Language" : 64988,
          "Stylus" : 82,
          "TypeScript" : 8879646,
          "Shell" : 2738408,
          "R" : 1064,
          "sed" : 1562,
          "Awk" : 6178,
          "JavaScript" : 286815659,
          "Objective-C" : 388870,
          "PHP" : 35367,
          "Ruby" : 9501,
          "GLSL" : 1318425,
          "Raku" : 21544,
          "Java" : 5088231,
          "C++" : 294388241,
          "CSS" : 3204220,
          "TeX" : 382211,
          "NASL" : 133375,
          "XSLT" : 18509,
          "Kotlin" : 23472035,
          "WebIDL" : 151333,
          "Dockerfile" : 67288,
          "CoffeeScript" : 623,
          "Euphoria" : 1960,
          "Linker Script" : 97,
          "Roff" : 539948,
          "HLSL" : 26023,
          "Lex" : 11373
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "X-Taint Header does not expect or accept compliant JSON",
      "validationOrRequirement" : "X-Taint Header should only accept unquoted keys",
      "attemptedFixes" : "helper function to transform it into the pseudo JSON is provided",
      "otherNotes" : "This is just an inconvenience, but I plan to resolve this by changing the parser for Taint Ranges to accept either format after submission of my dissertation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406843
  }, {
    "issueDTO" : {
      "id" : 3193656378,
      "title" : "[Bug]: The search API Key gets reset when you save settings",
      "url" : "https://github.com/All-Hands-AI/OpenHands/issues/9497",
      "repositoryName" : "All-Hands-AI/OpenHands",
      "description" : "### Is there an existing issue for the same bug? (If one exists, thumbs up or comment on the issue instead).\n\n- [x] I have checked the existing issues.\n\n### Describe the bug and reproduction steps\n\n* Add a search API Key and save changes.\n* Then change something in the settings. Let's say you change the LLM Provider and Model\n* Click Save Changes.\n* The Search API Key gets reset\n\n### OpenHands Installation\n\nDocker command in README\n\n### OpenHands Version\n\n_No response_\n\n### Model Name\n\n_No response_\n\n### Operating System\n\nNone\n\n### Logs, Errors, Screenshots, and Additional Context\n\n_No response_",
      "updatedAt" : 1753385850.000000000,
      "user" : "mamoodi",
      "userHtmlUrl" : "https://github.com/mamoodi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/169627366?v=4",
      "labels" : [ "settings", "bug", "openhands", "good first issue", "OH UI/UX" ],
      "state" : "OPEN",
      "comments" : [ "This looks like a **straightforward bug** that should be relatively manageable to fix. The issue has a clear, reproducible problem: the search API key gets wiped out whenever settings are saved, even when modifying unrelated configuration like LLM provider settings.\n\n**What's clear from the report:**\nThe reproduction steps are well-defined - add a search API key, change any other setting, save, and the API key disappears. This suggests a classic form handling issue where either the search API key field isn't being properly included in the save operation, or there's a state management problem where the key gets overwritten during the settings update process.\n\n**Technical factors to consider:**\nThis is likely a UI/UX issue in the settings form logic. The problem could stem from a few common patterns - maybe the form is only serializing visible or \"dirty\" fields, or there's separate state management for different setting categories that aren't being merged properly. It could also be a simple oversight where the search API key field isn't included in the save payload.\n\n**What needs investigation:**\nYou'll want to examine the settings form component and trace through the save flow. Check how form data is collected, whether all fields are being included in the request, and how the backend processes the settings update. Look at the network requests when saving to see if the API key is even being sent.\n\n**Next steps:**\nStart by reproducing the issue locally, then inspect the settings save functionality in the frontend code. Check the form serialization logic and the API call that handles settings updates. This feels like the kind of bug where the fix might be adding a single field to a form data object or ensuring proper state merging.", "I'm on it! mamoodi can [track my progress at all-hands.dev](https://app.all-hands.dev/conversations/cd964620c9db45c08a0a4241c0e73aa4)", "@mamoodi is this still an issue? It looks like the PR above was closed.", "Yep @michaldorsett still an issue. The PR was not merged.", "@mamoodi why not? is it that the bot did not actually resolve it? ", "@michaldorsett no it wasn't successful. The settings page is a little intertwined and I think it's going to go through an overhaul at some point so didn't want to pursue it further since it's a minor bug.", "@mamoodi So perhaps it's best to remove the `good first issue` label, and somehow mark this as `backlog`?" ],
      "repository" : {
        "description" : "\uD83D\uDE4C OpenHands: Code Less, Make More",
        "homepage" : "https://all-hands.dev",
        "name" : "OpenHands",
        "fullName" : "All-Hands-AI/OpenHands",
        "htmlUrl" : "https://github.com/All-Hands-AI/OpenHands",
        "gitUrl" : "git://github.com/All-Hands-AI/OpenHands.git",
        "sshUrl" : "git@github.com:All-Hands-AI/OpenHands.git",
        "cloneUrl" : "https://github.com/All-Hands-AI/OpenHands.git",
        "owner" : {
          "login" : "All-Hands-AI",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 7213,
        "stargazersCount" : 61105,
        "watchersCount" : 61105,
        "size" : 218181,
        "openIssuesCount" : 397,
        "subscribersCount" : 420,
        "pushedAt" : "2025-07-24T22:47:02Z",
        "languages" : {
          "TypeScript" : 1472971,
          "Dockerfile" : 8120,
          "Shell" : 116789,
          "Jinja" : 80292,
          "CSS" : 8337,
          "Makefile" : 15534,
          "JavaScript" : 34600,
          "HTML" : 1849,
          "Python" : 5163132
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The search API key gets reset when you save settings.",
      "validationOrRequirement" : "The search API key gets reset when you save settings.",
      "attemptedFixes" : "The PR above was closed, and the author didn't want to pursue it further since it's a minor bug.",
      "otherNotes" : "The issue has a clear, reproducible problem: the search API key gets wiped out whenever settings are saved, even when modifying unrelated configuration like LLM provider settings. The problem could stem from a few common patterns - maybe the form is only serializing visible or 'dirty' fields, or there's separate state management for different setting categories that aren't being merged properly.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406848
  }, {
    "issueDTO" : {
      "id" : 2177623744,
      "title" : "[Problem] Recent file list issues",
      "url" : "https://github.com/FreeCAD/FreeCAD/issues/12842",
      "repositoryName" : "FreeCAD/FreeCAD",
      "description" : "### Is there an existing issue for this?\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Problem description\r\n\r\nFrom the FreeCAD Day 2024 Complaint Session:\r\n**There is no obvious way to clear recent file list**\r\nThere's no obvious way to clear the recent part. You should be able to remove the entire history or remove individual entries.\r\n\r\n**Recent file list is far to aggressive, it contains files reference by project**\r\nThe current implementation of recently opened files is far too aggressive. Open up a document with a bunch of linked documents it will swamp your recent file list with everything.\r\nSo the recent file history contains documents that you didn't explicitly choose to open, but for reference by other files.\r\n\r\nIt is also beneficial to pin certain Documents to the top of the recent file list e.g. favorites or templates.\r\n\r\n\r\n### Full version info\r\n\r\n```shell\r\nOS: Windows 11 build 22631\r\nWord size of FreeCAD: 64-bit\r\nVersion: 0.22.0dev.36277 (Git)\r\nBuild type: Release\r\nBranch: main\r\nHash: 9e1903d46112b3660bf10c6a4537d728101d560b\r\nPython 3.10.13, Qt 5.15.8, Coin 4.0.2, Vtk 9.2.6, OCC 7.6.3\r\nLocale: German/Germany (de_DE)\r\nInstalled mods: \r\n  * 3DfindIT 1.2.0\r\n  * BIM 2021.12.0\r\n  * CfdOF 1.25.2\r\n  * CurvedShapes 1.0.5\r\n  * Curves 0.6.23\r\n  * Defeaturing 1.2.2\r\n  * fasteners 0.5.12\r\n  * FEMbyGEN 2.1.0\r\n  * freecad.gears 1.2.0\r\n  * freecad_metal_workbench 0.0.1\r\n  * OpenDark 2023.12.17\r\n  * sheetmetal 0.4.2\r\n```\r\n\r\n\r\n### Subproject(s) affected?\r\n\r\nCore\r\n\r\n### Anything else?\r\n\r\nRelated: #12565\r\n\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's Code of Conduct",
      "updatedAt" : 1753385749.000000000,
      "user" : "maxwxyz",
      "userHtmlUrl" : "https://github.com/maxwxyz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6246609?v=4",
      "labels" : [ "Topic: User Interface", "Mod: Core", "Good first issue", "Type: Feature", "Type: Has workaround" ],
      "state" : "OPEN",
      "comments" : [ "> The current implementation of recently opened files is far too aggressive. Open up a document with a bunch of linked documents it will swamp your recent file list with everything.\r\n> So the recent file history contains documents that you didn't explicitly choose to open, but for reference by other files.\r\n\r\n@PaddleStroke is this getting fixed with #12406?", "I don't think so because OP does not mention assembly. So I guess this\r\nbehavior also happens with partial loading (though I can't test right now)\r\n\r\nOn Sun, Mar 10, 2024, 10:48 Thomas D. ***@***.***> wrote:\r\n\r\n> The current implementation of recently opened files is far too aggressive.\r\n> Open up a document with a bunch of linked documents it will swamp your\r\n> recent file list with everything.\r\n> So the recent file history contains documents that you didn't explicitly\r\n> choose to open, but for reference by other files.\r\n>\r\n> @PaddleStroke <https://github.com/PaddleStroke> is this getting fixed\r\n> with #12406 <https://github.com/FreeCAD/FreeCAD/pull/12406>?\r\n>\r\n> ???\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/FreeCAD/FreeCAD/issues/12842#issuecomment-1987164131>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AEYO6MJ7IXUPBHEFIBTXWALYXQT6BAVCNFSM6AAAAABEO2HPKCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOBXGE3DIMJTGE>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n", "For simple users just searching for a way how to do this, even if it's not part of the user interface:\r\nGo to Tools > Edit Parameters ...\r\nThen BaseApp > Preferences > RecentFiles\r\n\r\nYou can edit or delete any entries there. You must restart FreeCAD to see the changes.", "> \n> From the FreeCAD Day 2024 Complaint Session: **There is no obvious way to clear recent file list** There's no obvious way to clear the recent part. You should be able to remove the entire history or remove individual entries.\n> \n> **Recent file list is far to aggressive, it contains files reference by project** The current implementation of recently opened files is far too aggressive. Open up a document with a bunch of linked documents it will swamp your recent file list with everything. So the recent file history contains documents that you didn't explicitly choose to open, but for reference by other files.\n> \n> It is also beneficial to pin certain Documents to the top of the recent file list e.g. favorites or templates.\n\nA suggestion that could help to reduce the impact of this problem is to add a user selected filter for which file types are included in the recent file list. This could be a list of the sypported file types with a check box next to each type.\n\nFor me, I would only like to see .FCStd files so I would uncheck the other supported file types from the filter list. Other people might only want to see recent .STL files or recent .DWG files so they could select those that they would like to see.\n\nFor example:\n\nRecent File List Filter\n\n_ All Files\n_ FreeCAD (*.FCStd)\n_ 3D Studio mesh (*.3ds)\n...\n_ Web page (*.html, *.xhtml)\n\nAlso, a vote for the option to pin a project to the RFL, as that could help some times as well.", "\n\n\n\n\n\n\n\n\n\n\n> \n> It is also beneficial to pin certain Documents to the top of the recent file list e.g. favorites or templates.\n> \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI have never seen software utilizing this concept. @maxwxyz, can you provide an example or a screenshot?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n" ],
      "repository" : {
        "description" : "Official source code of FreeCAD, a free and opensource multiplatform 3D parametric modeler.",
        "homepage" : "https://www.freecad.org",
        "name" : "FreeCAD",
        "fullName" : "FreeCAD/FreeCAD",
        "htmlUrl" : "https://github.com/FreeCAD/FreeCAD",
        "gitUrl" : "git://github.com/FreeCAD/FreeCAD.git",
        "sshUrl" : "git@github.com:FreeCAD/FreeCAD.git",
        "cloneUrl" : "https://github.com/FreeCAD/FreeCAD.git",
        "owner" : {
          "login" : "FreeCAD",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4688,
        "stargazersCount" : 25545,
        "watchersCount" : 25545,
        "size" : 2199715,
        "openIssuesCount" : 3197,
        "subscribersCount" : 547,
        "pushedAt" : "2025-07-25T00:16:00Z",
        "languages" : {
          "Yacc" : 23579,
          "C++" : 42517998,
          "CSS" : 8551,
          "C" : 1163472,
          "CMake" : 625944,
          "Max" : 605,
          "Makefile" : 6434,
          "QMake" : 1123,
          "HTML" : 82718,
          "NSIS" : 134853,
          "Shell" : 58950,
          "Batchfile" : 12099,
          "JavaScript" : 14016,
          "OpenSCAD" : 774,
          "Objective-C" : 6019,
          "Lex" : 111781,
          "Python" : 36855528,
          "GLSL" : 2097
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The recent file list is far too aggressive and contains files reference by project, and there is no obvious way to clear the recent part",
      "validationOrRequirement" : "The recent file list should be able to clear the entire history or remove individual entries, and it should not contain files reference by project",
      "attemptedFixes" : "No specific fixes mentioned, but workaround exists",
      "otherNotes" : "Related issue #12565, workaround exists by going to Tools > Edit Parameters > BaseApp > Preferences > RecentFiles, can edit or delete entries, must restart FreeCAD to see changes. Suggested feature: add user-selected filter for file types in recent file list, and option to pin projects to recent file list.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406852
  }, {
    "issueDTO" : {
      "id" : 2421612971,
      "title" : "List notes don't appear if the list item becomes a redirect",
      "url" : "https://github.com/internetarchive/openlibrary/issues/9600",
      "repositoryName" : "internetarchive/openlibrary",
      "description" : "### Problem\n\n#### Relevant URL(s)\r\ne.g. https://openlibrary.org/people/m_diabox/lists/OL255093L/Policiers_Thrillers\n\n### Reproducing the bug\n\n1. Go to e.g. https://openlibrary.org/people/m_diabox/lists/OL255093L/Policiers_Thrillers\r\n\r\n* Expected behavior: The first book should have a note\r\n* Actual behavior: No note is on the first book! Compare with https://openlibrary.org/people/m_diabox/lists/OL255093L.json?_raw=true\r\n\n\n### Context\n\n- Browser (Chrome, Safari, Firefox, etc):\r\n- OS (Windows, Mac, etc):\r\n- Logged in (Y/N): Y\r\n- Environment (prod, dev, local): prod\r\n\n\n### Notes from this Issue's Lead\n\n#### Proposal & constraints\r\n<!-- What is the proposed solution / implementation? Is there a precedent of this approach succeeding elsewhere? -->\r\n\r\n#### Related files\r\n<!-- Files related to this issue; this is super useful for new contributors who might want to help! If you're not sure, leave this blank; a maintainer will add them. -->\r\n\r\n#### Stakeholders\r\n<!-- @ tag stakeholders of this bug -->\r\n<hr>\r\n\r\n#### Instructions for Contributors\r\n<!-- Please leave the following reminder section as is to help new contributors and add instructions where necessary -->\r\n\r\n- Please [run these commands](https://github.com/internetarchive/openlibrary/wiki/Git-Cheat-Sheet#working-on-your-branch) to ensure your repository is up to date **before** [creating a new branch](https://github.com/internetarchive/openlibrary/wiki/Git-Cheat-Sheet#making-changes-and-creating-a-pull-request) to work on this issue and **each time after** pushing code to Github, because the pre-commit bot may add commits to your PRs upstream.",
      "updatedAt" : 1753385693.000000000,
      "user" : "cdrini",
      "userHtmlUrl" : "https://github.com/cdrini",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6251786?v=4",
      "labels" : [ "Good First Issue", "Fellowship Opportunity", "Lead: @cdrini", "Type: Bug", "Priority: 2", "Needs: Breakdown" ],
      "state" : "OPEN",
      "comments" : [ "Whoops responded on wrong issue" ],
      "repository" : {
        "description" : "One webpage for every book ever published!",
        "homepage" : "https://openlibrary.org",
        "name" : "openlibrary",
        "fullName" : "internetarchive/openlibrary",
        "htmlUrl" : "https://github.com/internetarchive/openlibrary",
        "gitUrl" : "git://github.com/internetarchive/openlibrary.git",
        "sshUrl" : "git@github.com:internetarchive/openlibrary.git",
        "cloneUrl" : "https://github.com/internetarchive/openlibrary.git",
        "owner" : {
          "login" : "internetarchive",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1583,
        "stargazersCount" : 5773,
        "watchersCount" : 5773,
        "size" : 99535,
        "openIssuesCount" : 877,
        "subscribersCount" : 174,
        "pushedAt" : "2025-07-24T23:21:11Z",
        "languages" : {
          "MDX" : 900,
          "Dockerfile" : 5593,
          "Shell" : 99314,
          "CSS" : 2800,
          "PLpgSQL" : 16061,
          "Makefile" : 2625,
          "JavaScript" : 635427,
          "Vue" : 208922,
          "HTML" : 701123,
          "Less" : 298302,
          "Python" : 2564724
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the bug where list notes do not appear when a list item becomes a redirect.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description.",
      "attemptedFixes" : "No specific attempted fixes or blockers mentioned in the description.",
      "otherNotes" : "The issue is related to list notes not appearing when a list item becomes a redirect.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406855
  }, {
    "issueDTO" : {
      "id" : 2953718667,
      "title" : "Support colima for metaflow-dev",
      "url" : "https://github.com/Netflix/metaflow/issues/2362",
      "repositoryName" : "Netflix/metaflow",
      "description" : "https://outerboundsco.slack.com/archives/C02116BBNTU/p1743005916467389",
      "updatedAt" : 1753385662.000000000,
      "user" : "savingoyal",
      "userHtmlUrl" : "https://github.com/savingoyal",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/763451?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I'd like to work on this! I use Colima myself and understand the pain point. I'll start by analyzing the current Docker Desktop detection logic in metaflow-dev and propose a solution that supports both Docker Desktop and Colima. Will have a PR ready soon." ],
      "repository" : {
        "description" : "Build, Manage and Deploy AI/ML Systems",
        "homepage" : "https://metaflow.org",
        "name" : "metaflow",
        "fullName" : "Netflix/metaflow",
        "htmlUrl" : "https://github.com/Netflix/metaflow",
        "gitUrl" : "git://github.com/Netflix/metaflow.git",
        "sshUrl" : "git@github.com:Netflix/metaflow.git",
        "cloneUrl" : "https://github.com/Netflix/metaflow.git",
        "owner" : {
          "login" : "Netflix",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 866,
        "stargazersCount" : 9286,
        "watchersCount" : 9286,
        "size" : 44917,
        "openIssuesCount" : 355,
        "subscribersCount" : 294,
        "pushedAt" : "2025-07-24T22:00:58Z",
        "languages" : {
          "TypeScript" : 17832,
          "R" : 133424,
          "Shell" : 4232,
          "CSS" : 3291,
          "Starlark" : 21404,
          "Makefile" : 13737,
          "JavaScript" : 3346,
          "HTML" : 37324,
          "Svelte" : 66290,
          "Jupyter Notebook" : 15773,
          "Python" : 4334536
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support colima for metaflow-dev",
      "validationOrRequirement" : "supports both Docker Desktop and Colima",
      "attemptedFixes" : "analyzing the current Docker Desktop detection logic in metaflow-dev and proposing a solution that supports both Docker Desktop and Colima",
      "otherNotes" : "https://outerboundsco.slack.com/archives/C02116BBNTU/p1743005916467389",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406858
  }, {
    "issueDTO" : {
      "id" : 2916740189,
      "title" : "[Bounty $500] Align model tasks by referencing Huggingface tasks",
      "url" : "https://github.com/tenstorrent/tt-forge-fe/issues/1449",
      "repositoryName" : "tenstorrent/tt-forge-fe",
      "description" : "Modify the current model tasks in forge and restructure it based on huggingface tasks overview. Below is a reference of huggingface tasks:\n```\nnlp_text_cls\n nlp_token_cls\n nlp_qa\n nlp_causal_lm\n nlp_masked_lm\n nlp_translation\n nlp_summarization\n nlp_multi_choice\n audio_cls\n audio_asr\n cv_image_cls\n cv_image_seg\n cv_video_cls\n cv_object_det\n cv_zs_object_det\n cv_zs_image_cls\n cv_depth_est\n cv_img_to_img\n cv_image_fe\n cv_mask_gen\n cv_keypoint_det\n cv_know_distill\n mm_image_capt\n mm_doc_qa\n mm_visual_qa\n mm_tts\n mm_image_ttt\n mm_video_ttt\n```",
      "updatedAt" : 1753385595.000000000,
      "user" : "meenakshiramanathan1",
      "userHtmlUrl" : "https://github.com/meenakshiramanathan1",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/170527885?v=4",
      "labels" : [ "bounty", "good first issue", "bounty_difficulty/easy" ],
      "state" : "OPEN",
      "comments" : [ "Hey @Shubhamsaboo ,\nCan you please assign me this issue.", "Hey @SydAayaat!\n\nHappy to assign you to this.\n\nBe sure that you read over the [BOUNTY TERMS](https://docs.tenstorrent.com/bounty_terms.html), as you agree to all of them by picking up this issue.\n\nIf we haven't received any communication from you in a two week period, we will re-assign the issue, and you will no longer be eligible for completion of this bounty.\n\nIf you have any questions feel free to ping me here on this issue! Look forward to seeing your submission.", "@SydAayaat, thanks for picking up this bounty! Feel free to ping me if you need any help or assistance! \n\nAlso, once you get some WIP Draft PR, feel free to share it for early feedback :)))", "Hi @SydAayaat just checking in.  Please provide a quick status update if you're still working on this.", "@nvukobratTT @cguerreroTT I would like to work on this if the assigned contributor got inactive\n\n> If we haven't received any communication from you in a two week period, we will re-assign the issue, and you will no longer be eligible for completion of this bounty.\n\nAccording to this I think this can be reassigned and Keeping me in queue ", "Hi @nvukobratTT @Shubhamsaboo , may I work on this? I think its pretty closely tied to my recently merged [PR](https://github.com/tenstorrent/tt-forge-fe/pull/2100) around the same subject of the issue, would be able to knock this out pretty quick with the context I have while I wait for my latest [PR](https://github.com/tenstorrent/tt-forge-fe/pull/2345) to get reviewed. ", "I am in the queue to get assigned ???\uD83D\uDE04", "Its just that my current [PR](https://github.com/tenstorrent/tt-forge-fe/pull/2345) is being reviewed and I'm not active on any other issues. And my previous [PR](https://github.com/tenstorrent/tt-forge-fe/pull/2100) was closely related to this task. Perharps you could settle this @Shubhamsaboo ?", "Un-assigning @SydAayaat as we have not heard back.\n\nHi @varshith257, since you're already working on another issue I will assign this to @brymut.\n\nHi @brymut, be sure that you read over the [BOUNTY TERMS](https://docs.tenstorrent.com/bounty_terms.html), as you agree to all of them by picking up this issue.\n\nIf we haven't received any communication from you in a two week period, we will re-assign the issue, and you will no longer be eligible for completion of this bounty.\n\nI've also followed up internally to help get your open PR reviewed and merged as soon as possible.", "@cguerreroTT This bounty is completed can we please award @brymut the bounty? We have the PR and will merge it on our end after we fix some CI infra issues. Thank you! ", "Will do @staylorTT\n\nGreat work @brymut on completing another bounty!  I'll follow up with you in email for payment.", "> Will do [@staylorTT](https://github.com/staylorTT)\n> \n> Great work [@brymut](https://github.com/brymut) on completing another bounty! I'll follow up with you in email for payment.\n\nThanks @cguerreroTT, awaiting email \uD83D\uDC4D" ],
      "repository" : {
        "description" : "The TT-Forge FE is a graph compiler designed to optimize and transform computational graphs for deep learning models, enhancing their performance and efficiency.",
        "homepage" : "https://docs.tenstorrent.com/tt-forge-fe/",
        "name" : "tt-forge-fe",
        "fullName" : "tenstorrent/tt-forge-fe",
        "htmlUrl" : "https://github.com/tenstorrent/tt-forge-fe",
        "gitUrl" : "git://github.com/tenstorrent/tt-forge-fe.git",
        "sshUrl" : "git@github.com:tenstorrent/tt-forge-fe.git",
        "cloneUrl" : "https://github.com/tenstorrent/tt-forge-fe.git",
        "owner" : {
          "login" : "tenstorrent",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 46,
        "watchersCount" : 46,
        "size" : 90064,
        "openIssuesCount" : 412,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-24T20:40:36Z",
        "languages" : {
          "C++" : 1799003,
          "Shell" : 38582,
          "CMake" : 15461,
          "MLIR" : 2707,
          "Python" : 17574895
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Align model tasks by referencing Huggingface tasks, restructure the current model tasks in forge",
      "validationOrRequirement" : "Read over the BOUNTY TERMS, agree to all of them by picking up the issue, and provide a quick status update if still working on the issue.",
      "attemptedFixes" : "The issue was reassigned from @SydAayaat to @brymut, and then the PR was merged after fixing some CI infra issues.",
      "otherNotes" : "Bounty of $500, restructure model tasks in forge based on Huggingface tasks overview, references provided. The issue was reassigned multiple times due to inactivity of the assigned contributor.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406863
  }, {
    "issueDTO" : {
      "id" : 2437700439,
      "title" : "[BUG] A large negative number(e.g. -LONG_MAX) in HRANDFIELD/ZRANDMEMBER can easily cause Valkey to crash.",
      "url" : "https://github.com/valkey-io/valkey/issues/844",
      "repositoryName" : "valkey-io/valkey",
      "description" : "**Describe the bug**\r\n\r\nWhen using the **HRANDFIELD** or **ZRANDMEMBER** commands, if an extremely negative value(e.g. -LONG_MAX) is provided, the memory will continue to rise and eventually cause Redis to crash.\r\n\r\n**To reproduce**\r\n\r\nHRANDFIELD hash -9223372036854775807\r\n\r\n**Expected behavior**\r\n\r\nIMHO, it is more reasonable to set a limit on **count** according to the memory limit or the actual size of the hash table to prevent Redis from crashing. This can prevent crashes caused by careless and incorrect use. If a user really needs to sample a lot of elements that allow duplicates, he can achieve the same purpose by calling the command multiple times.\r\n\r\n",
      "updatedAt" : 1753385584.000000000,
      "user" : "cjx-zar",
      "userHtmlUrl" : "https://github.com/cjx-zar",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/56825069?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "this is a known issue, https://github.com/redis/redis/issues/11671. we should be able to have a configuration item to limit these such loops.\r\n", "@madolson i see you marked this, what do we want to do here? Adding a new configuration item that limit the loop, default value is LONG_MAX? I remember discussing this with Oran, and the old conclusion is that he seemed like wasn't leaning in that direction so we drop this at that time.", "Hey @madolson  if this issue is still up I would like to contribute in this ", "Hi @madolson, I saw this comment of yours https://github.com/redis/redis/pull/11676#issuecomment-1370388862 where you state that you would be fine with an approach of limiting the number of results by some factor.\r\n\r\nMaybe we could add a configuration option that specifies that factor value, where value `0` corresponds to no limit (current behavior).\r\n\r\nIf you're fine with this approach, I can implement it.", "Pinging @madolson on https://github.com/valkey-io/valkey/issues/844#issuecomment-2355151596", "I did mark it apparently. It looked like an issue we could add a configuration for. We could also just disconnect the client and stop looping if such an action would generate a very large amount of memory." ],
      "repository" : {
        "description" : "A flexible distributed key-value database that is optimized for caching and other realtime workloads.",
        "homepage" : "https://valkey.io",
        "name" : "valkey",
        "fullName" : "valkey-io/valkey",
        "htmlUrl" : "https://github.com/valkey-io/valkey",
        "gitUrl" : "git://github.com/valkey-io/valkey.git",
        "sshUrl" : "git@github.com:valkey-io/valkey.git",
        "cloneUrl" : "https://github.com/valkey-io/valkey.git",
        "owner" : {
          "login" : "valkey-io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 948,
        "stargazersCount" : 22341,
        "watchersCount" : 22341,
        "size" : 141452,
        "openIssuesCount" : 481,
        "subscribersCount" : 119,
        "pushedAt" : "2025-07-23T05:44:01Z",
        "languages" : {
          "Smarty" : 1053,
          "Shell" : 20171,
          "C++" : 6111,
          "C" : 7653237,
          "CMake" : 36078,
          "Makefile" : 27010,
          "JavaScript" : 953,
          "Tcl" : 2581091,
          "Ruby" : 30538,
          "Python" : 52806
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to prevent Redis from crashing when using the HRANDFIELD or ZRANDMEMBER commands with extremely negative values, by setting a limit on the count according to the memory limit or the actual size of the hash table.",
      "validationOrRequirement" : "A configuration item to limit the loop, default value is LONG_MAX, with a suggested approach of limiting the number of results by some factor.",
      "attemptedFixes" : "Adding a new configuration item that limits the loop, default value is LONG_MAX was discussed but not implemented. A suggestion to disconnect the client and stop looping if an action would generate a very large amount of memory was also mentioned.",
      "otherNotes" : "This issue is a known issue, referenced in https://github.com/redis/redis/issues/11671. There is a discussion about adding a configuration item to limit the loop, with suggestions for a default value and alternative approaches.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406869
  }, {
    "issueDTO" : {
      "id" : 3261013057,
      "title" : "[Asana] Get-Task-Strories",
      "url" : "https://github.com/PipedreamHQ/pipedream/issues/17794",
      "repositoryName" : "PipedreamHQ/pipedream",
      "description" : "**Is there a specific app this action is for?**\n[Asana] Get-Task-Stories\n\n**Please provide a link to the relevant API docs for the specific service / operation.**\nhttps://developers.asana.com/reference/stories\nhttps://forum.asana.com/t/get-comments/76983\n\n---\n\nCurrently, there???s no direct API endpoint in Asana specifically for retrieving only comments.\nHowever, Asana???s /tasks/{task_gid}/stories endpoint returns all stories (which includes comments, status updates, system messages, etc.) for a given task. To extract comments, we???d need to call this endpoint and then filter for items where type: \"comment\".\n\nIt would be very helpful to have a native Pipedream action like ASANA-GET-TASK-STORIES that calls this endpoint and optionally filters for just comments.\n\nLet me know if this is something that could be added ??? happy to provide more context if needed!\n\nThanks so much!",
      "updatedAt" : 1753385539.000000000,
      "user" : "frankwon11",
      "userHtmlUrl" : "https://github.com/frankwon11",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/74140181?v=4",
      "labels" : [ "help wanted", "action", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Connect APIs, remarkably fast.  Free for developers.",
        "homepage" : "https://pipedream.com",
        "name" : "pipedream",
        "fullName" : "PipedreamHQ/pipedream",
        "htmlUrl" : "https://github.com/PipedreamHQ/pipedream",
        "gitUrl" : "git://github.com/PipedreamHQ/pipedream.git",
        "sshUrl" : "git@github.com:PipedreamHQ/pipedream.git",
        "cloneUrl" : "https://github.com/PipedreamHQ/pipedream.git",
        "owner" : {
          "login" : "PipedreamHQ",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5419,
        "stargazersCount" : 10247,
        "watchersCount" : 10247,
        "size" : 608233,
        "openIssuesCount" : 4153,
        "subscribersCount" : 276,
        "pushedAt" : "2025-07-25T00:33:00Z",
        "languages" : {
          "TypeScript" : 1313176,
          "MDX" : 1185411,
          "Dockerfile" : 295,
          "CSS" : 4596,
          "Shell" : 2688,
          "Makefile" : 270,
          "JavaScript" : 25500208,
          "HTML" : 568,
          "Jupyter Notebook" : 22765
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a native Pipedream action (ASANA-GET-TASK-STORIES) that calls the /tasks/{task_gid}/stories endpoint and optionally filters for just comments",
      "validationOrRequirement" : "Provide a link to the relevant API docs for the specific service/operation",
      "attemptedFixes" : "Currently, there's no direct API endpoint in Asana for retrieving only comments",
      "otherNotes" : "Asana's /tasks/{task_gid}/stories endpoint returns all stories, which includes comments, status updates, system messages, etc.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406873
  }, {
    "issueDTO" : {
      "id" : 3260590255,
      "title" : "feature: docs and md files need updating - moving from kubernetes slack org to cncf slack org",
      "url" : "https://github.com/kubestellar/kubestellar/issues/3122",
      "repositoryName" : "kubestellar/kubestellar",
      "description" : "### Feature Description\n\nwe are moving our slack channel \"kubestellar-dev\" from the kubernetes to the cncf slack organization. We have more flexibility and permissions to organize our teams and send reminders for important community events.\n\n### Proposed Solution\n\neverywhere in the kubestellar.io docs and the various MD files in the repo where there is a reference to:\n\nhttps://kubernetes.slack.com/archives/C058SUSL5AA\n\nit should be changed to:\n\nhttps://cloud-native.slack.com/archives/C097094RZ3M\n\n### Want to contribute?\n\n- [ ] I would like to work on this issue.\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1753385521.000000000,
      "user" : "clubanderson",
      "userHtmlUrl" : "https://github.com/clubanderson",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/407614?v=4",
      "labels" : [ "help wanted", "kind/feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@clubanderson I will take the issue.", "But, are we immediately moving to cncf slack or there is some time left ?", "awesome @greninja517 Thank you!", "6 month transition", "I just updated our kubestellar.io/agenda with the new community inviter and slack channel\n\nnew community inviter is\n\nhttps://communityinviter.com/apps/cloud-native/cncf", "In docs, we need to update community inviter URL as well.", "yes - the inviter url is in my comment above.", "@clubanderson The shortcut URL [https://kubestellar.io/slack](https://kubestellar.io/slack) points to the old Kubernetes Slack Channel. Since this url is managed by maintainers so it should be updated to point to new CNCF slack channel, instead of hardcoding the new CNCF channel in the docs or in the repo.", "yep - thats on me - I am taking care of it outside this issue/pr" ],
      "repository" : {
        "description" : "KubeStellar - a flexible solution for multi-cluster configuration management for edge, multi-cloud, and hybrid cloud",
        "homepage" : "https://kubestellar.io",
        "name" : "kubestellar",
        "fullName" : "kubestellar/kubestellar",
        "htmlUrl" : "https://github.com/kubestellar/kubestellar",
        "gitUrl" : "git://github.com/kubestellar/kubestellar.git",
        "sshUrl" : "git@github.com:kubestellar/kubestellar.git",
        "cloneUrl" : "https://github.com/kubestellar/kubestellar.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 163,
        "stargazersCount" : 438,
        "watchersCount" : 438,
        "size" : 209303,
        "openIssuesCount" : 211,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-24T19:02:58Z",
        "languages" : {
          "Smarty" : 2184,
          "Dockerfile" : 1303,
          "Shell" : 192050,
          "Makefile" : 14208,
          "Go" : 642298,
          "Python" : 30022
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update references to the old Kubernetes Slack channel to the new CNCF Slack channel in the kubestellar.io docs and MD files.",
      "validationOrRequirement" : "Update community inviter URL in docs, update shortcut URL https://kubestellar.io/slack to point to new CNCF slack channel.",
      "attemptedFixes" : "The author is taking care of updating the shortcut URL outside of this issue.",
      "otherNotes" : "The community inviter URL needs to be updated in the docs as well, and the shortcut URL https://kubestellar.io/slack needs to be updated to point to the new CNCF slack channel.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406877
  }, {
    "issueDTO" : {
      "id" : 2445840002,
      "title" : "Make it easier to open multiple repositories in one workspace",
      "url" : "https://github.com/coder/vscode-coder/issues/333",
      "repositoryName" : "coder/vscode-coder",
      "description" : "Currently, if you try to open a workspace it will automatically launch the folder configured in the API response.\r\n\r\nIf there is no default folder, then the plugin will ask you to open a recent folder that has been opened before in that workspace.\r\n\r\nIf there are no recents, then it opens a blank window, and from there you can open a directory through File > Open.\r\n\r\nThe default folder stuff works fine if you have one repository per workspace, but how can we make it easier to open multiple repositories?\r\n\r\nOne idea is that we can ask to open a recent, but we can also show an option that allows you to pick any arbitrary file path.\r\n\r\nAnother idea is to somehow get a list of all the repositories on the workspace and then ask the user which to open, but this would require more brainstorming.  Those directories would need to come from the API somehow.  Maybe something on the template?\r\n\r\nOpen to other ideas.",
      "updatedAt" : 1753385428.000000000,
      "user" : "code-asher",
      "userHtmlUrl" : "https://github.com/code-asher",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/45609798?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "The code in question: \r\n\r\nhttps://github.com/coder/vscode-coder/blob/c6e7f3630b3bf51c0cd4719dc3c55d1d913dde9f/src/commands.ts#L517-L524\r\n\r\nI think the strategy is:\r\n\r\n1. Add a description saying these are the folders that have been opened before on this workspace, and would you like to open one of them?\r\n2. Add a \"open new\" button that launches a file picker and lets you pick any directory on the remote, if possible.  I am not sure something like this is built in.  Like the \"show local\" button but reversed.", "The ability to set a home folder like you can with the Jetbrains Gateway would be very nice. Currently every time you open the workspace you have to open the folder once VSCode launches", "Related to #245 and the https://registry.coder.com/modules/vscode-desktop module can open a workspace file when `folder` is set to the path of a [`.code-workspace`](https://code.visualstudio.com/docs/editor/multi-root-workspaces#_workspace-file) file.\n" ],
      "repository" : {
        "description" : "Open any Coder workspace in VS Code with a single click.",
        "homepage" : null,
        "name" : "vscode-coder",
        "fullName" : "coder/vscode-coder",
        "htmlUrl" : "https://github.com/coder/vscode-coder",
        "gitUrl" : "git://github.com/coder/vscode-coder.git",
        "sshUrl" : "git@github.com:coder/vscode-coder.git",
        "cloneUrl" : "https://github.com/coder/vscode-coder.git",
        "owner" : {
          "login" : "coder",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28,
        "stargazersCount" : 95,
        "watchersCount" : 95,
        "size" : 16557,
        "openIssuesCount" : 63,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-24T23:05:47Z",
        "languages" : {
          "TypeScript" : 207065,
          "Shell" : 4893,
          "JavaScript" : 1840,
          "Nix" : 516
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Make it easier to open multiple repositories in one workspace",
      "validationOrRequirement" : "The ability to set a home folder like you can with the Jetbrains Gateway would be very nice.",
      "attemptedFixes" : "Add a description saying these are the folders that have been opened before on this workspace, and would you like to open one of them? Add a \"open new\" button that launches a file picker and lets you pick any directory on the remote, if possible.",
      "otherNotes" : "The issue is related to #245 and the https://registry.coder.com/modules/vscode-desktop module can open a workspace file when `folder` is set to the path of a [.code-workspace](https://code.visualstudio.com/docs/editor/multi-root-workspaces#_workspace-file) file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406883
  }, {
    "issueDTO" : {
      "id" : 3224375955,
      "title" : "[FEA] Update the `libcudf-example` conda package to preserve directories",
      "url" : "https://github.com/rapidsai/cudf/issues/19360",
      "repositoryName" : "rapidsai/cudf",
      "description" : "**Is your feature request related to a problem? Please describe.**\nCurrently when I install libcudf examples like this:\n```\nconda install rapidsai-nightly::libcudf-example=25.08\ncd \"${CONDA_PREFIX}/bin/examples\"\n```\nI get a mess of executables all in the same folder like this:\n```\n(all_cuda-128_arch-aarch64) root@6646ca20c022:/opt/conda/envs/all_cuda-128_arch-aarch64/bin/examples/libcudf# ls -lrt\ntotal 7008\n-rw-r--r-- 2 root conda     408 Jul 11 20:12 names.csv\n-rw-r--r-- 2 root conda    1251 Jul 11 20:12 info.csv\n-rw-r--r-- 2 root conda     614 Jul 11 20:12 example.parquet\n-rw-r--r-- 2 root conda     700 Jul 11 20:12 example.json\n-rw-r--r-- 2 root conda    1899 Jul 11 20:12 4stock_5day.csv\n-rwxr-xr-x 1 root root   181896 Jul 11 22:19 basic_example\n-rwxr-xr-x 1 root root   263936 Jul 11 22:19 branching\n-rwxr-xr-x 1 root root   262736 Jul 11 22:19 branching_public\n-rwxr-xr-x 1 root root   260480 Jul 11 22:19 brc\n-rwxr-xr-x 1 root root   261144 Jul 11 22:19 brc_chunks\n-rwxr-xr-x 1 root root   263704 Jul 11 22:19 brc_pipeline\n-rwxr-xr-x 1 root root  1850744 Jul 11 22:19 custom_optimized\n-rwxr-xr-x 1 root root   728600 Jul 11 22:19 custom_prealloc\n-rwxr-xr-x 1 root root   794152 Jul 11 22:19 custom_with_malloc\n-rwxr-xr-x 1 root root   192824 Jul 11 22:19 deduplication\n-rwxr-xr-x 1 root root   196312 Jul 11 22:19 int_output\n-rwxr-xr-x 1 root root   262672 Jul 11 22:19 libcudf_apis\n-rwxr-xr-x 1 root root   197840 Jul 11 22:19 output\n-rwxr-xr-x 1 root root   265360 Jul 11 22:19 output_public\n-rwxr-xr-x 1 root root   269144 Jul 11 22:19 parquet_io\n-rwxr-xr-x 1 root root   343824 Jul 11 22:19 parquet_io_multithreaded\n-rwxr-xr-x 1 root root   263936 Jul 11 22:19 preallocated\n-rwxr-xr-x 1 root root   265272 Jul 11 22:19 preallocated_public\n```\n\nWith the data files and executables all combined in one folder, it's hard to make sense of which example is which and how to run them.\n\n**Describe the solution you'd like**\nLet's preserve the directory structure that we have in the examples source code folder in the conda package as well. Or something similar.\n\n<img width=\"369\" height=\"732\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/542d5434-c866-484d-b466-148793c454dc\" />\n\n",
      "updatedAt" : 1753385418.000000000,
      "user" : "GregoryKimball",
      "userHtmlUrl" : "https://github.com/GregoryKimball",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12725111?v=4",
      "labels" : [ "libcudf", "feature request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Should be straightforward, we'd just have to [update the install prefix in this script](https://github.com/rapidsai/cudf/blob/26e6b2b47fd2d35642e7535de6bf289249573e79/cpp/examples/build.sh#L56).", "If we change the \"INSTALL_PREFIX\" variable,  only the root/parent path is updated. However, the internal directory structure remains disorganized as before.\n\nTo maintain a consistent directory layout (like the one shown above), each example folder's install command must be updated with a hardcoded DESTINATION path in its respective CMakeLists.txt file.\n\nFor ex,\n\nhttps://github.com/rapidsai/cudf/blob/26e6b2b47fd2d35642e7535de6bf289249573e79/cpp/examples/basic/CMakeLists.txt#L26\n\n\n```\ninstall(TARGETS basic_example DESTINATION bin/examples/libcudf)\ninstall(FILES ${CMAKE_CURRENT_LIST_DIR}/4stock_5day.csv DESTINATION bin/examples/libcudf)\n```\n\nto\n\n```\ninstall(TARGETS basic_example DESTINATION bin/examples/libcudf/basic)\ninstall(FILES ${CMAKE_CURRENT_LIST_DIR}/4stock_5day.csv DESTINATION bin/examples/libcudf/basic)\n```", "Hmm yeah I was hoping to simply omit the destination keyword altogether but I suppose since these are example binaries we can't just install into standard directories based on a prefix, we do have to specify on a per-install command basis where we want things to go." ],
      "repository" : {
        "description" : "cuDF - GPU DataFrame Library ",
        "homepage" : "https://docs.rapids.ai/api/cudf/stable/",
        "name" : "cudf",
        "fullName" : "rapidsai/cudf",
        "htmlUrl" : "https://github.com/rapidsai/cudf",
        "gitUrl" : "git://github.com/rapidsai/cudf.git",
        "sshUrl" : "git@github.com:rapidsai/cudf.git",
        "cloneUrl" : "https://github.com/rapidsai/cudf.git",
        "owner" : {
          "login" : "rapidsai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 960,
        "stargazersCount" : 9070,
        "watchersCount" : 9070,
        "size" : 167796,
        "openIssuesCount" : 1086,
        "subscribersCount" : 157,
        "pushedAt" : "2025-07-24T23:41:47Z",
        "languages" : {
          "Java" : 2612771,
          "Dockerfile" : 954,
          "C++" : 13580598,
          "Shell" : 104572,
          "C" : 6037,
          "CMake" : 166776,
          "HTML" : 2351,
          "Jupyter Notebook" : 1371,
          "Cython" : 915403,
          "Python" : 8698738,
          "Cuda" : 7741022
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the `libcudf-example` conda package to preserve directories, currently executables and data files are combined in one folder, making it hard to distinguish between examples and how to run them.",
      "validationOrRequirement" : "Preserve the directory structure that exists in the examples source code folder in the conda package, or something similar.",
      "attemptedFixes" : "Update the install prefix in the script to preserve the directory structure, but this only updates the root/parent path, and the internal directory structure remains disorganized.",
      "otherNotes" : "Currently when installing libcudf examples, executables and data files are combined in one folder, making it hard to distinguish between examples and how to run them. To maintain a consistent directory layout, each example folder's install command must be updated with a hardcoded DESTINATION path in its respective CMakeLists.txt file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406888
  }, {
    "issueDTO" : {
      "id" : 3220268570,
      "title" : "Filter source_tree for changed files when using --git-diff-branch",
      "url" : "https://github.com/mufeedvh/code2prompt/issues/176",
      "repositoryName" : "mufeedvh/code2prompt",
      "description" : "Right now the entire source_tree is generated unless files are explicitly excluded, would be great if only diffed files would show up in the source tree to avoid consuming so many tokens?\n\nThanks a lot for this project, it's super helpful :)",
      "updatedAt" : 1753385400.000000000,
      "user" : "ViktorJT",
      "userHtmlUrl" : "https://github.com/ViktorJT",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15237362?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @ViktorJT, \n\nIt sounds to be an interesting idea. We could only gather the context from diffed files. \n\nTherefore, it won't be in the tree AND not in the actual codebase content. Or do you want to include only diffed files in the tree and include the whole codebase in the content ?\n\nDo I understand your idea properly ?", "Ah great!\n\nI was thinking more how --include already works: where both the source tree and codebase content are filtered by a pattern unless the full directory flag is passed?\n\nThe problem I'm trying to solve is that my source tree output is quite large and takes up too many tokens :)" ],
      "repository" : {
        "description" : "A CLI tool to convert your codebase into a single LLM prompt with source tree, prompt templating, and token counting.",
        "homepage" : "https://code2prompt.dev",
        "name" : "code2prompt",
        "fullName" : "mufeedvh/code2prompt",
        "htmlUrl" : "https://github.com/mufeedvh/code2prompt",
        "gitUrl" : "git://github.com/mufeedvh/code2prompt.git",
        "sshUrl" : "git@github.com:mufeedvh/code2prompt.git",
        "cloneUrl" : "https://github.com/mufeedvh/code2prompt.git",
        "owner" : {
          "login" : "mufeedvh",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 338,
        "stargazersCount" : 6094,
        "watchersCount" : 6094,
        "size" : 3863,
        "openIssuesCount" : 17,
        "subscribersCount" : 36,
        "pushedAt" : "2025-07-21T21:36:07Z",
        "languages" : {
          "MDX" : 338508,
          "TypeScript" : 682,
          "CSS" : 4520,
          "Rust" : 175539,
          "Astro" : 33503,
          "Handlebars" : 19980,
          "JavaScript" : 5687,
          "Python" : 18245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Generate source_tree only with changed files when using --git-diff-branch to avoid consuming too many tokens",
      "validationOrRequirement" : "Filter source_tree for changed files when using --git-diff-branch",
      "attemptedFixes" : "We could only gather the context from diffed files. Therefore, it won't be in the tree AND not in the actual codebase content.",
      "otherNotes" : "Thanks a lot for this project, it's super helpful :)",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406892
  }, {
    "issueDTO" : {
      "id" : 1863792904,
      "title" : "Update documentation",
      "url" : "https://github.com/grafana/x-ray-datasource/issues/198",
      "repositoryName" : "grafana/x-ray-datasource",
      "description" : "- [ ] CONTRIBUTING: `yarn watch` doesn???t exist though it instructs you to use that command\r\n- [ ] CONTRIBUTING: Suggests running `go get -u github.com/grafana/grafana-plugin-sdk-go` to build the backend for some reason? Is this required or outdated information?\r\n- [ ] CONTRIBUTING: Should add the release and go workspace info\r\n- [ ] README: Explore link and second Node graph panel link in https://github.com/grafana/x-ray-datasource#service-map do not go anywhere\r\n- [ ] README: Alerting link in https://github.com/grafana/x-ray-datasource#alerting also doesn???t go anywhere\r\n- [ ] README: Provision Grafana link in https://github.com/grafana/x-ray-datasource#configure-the-data-source-with-provisioning also broken\r\n- [ ] [Cross-Account Observability: Getting started](https://github.com/grafana/x-ray-datasource#configure-the-data-source-with-provisioning) cryptically says ???add two API actions to the IAM policy??? and the link that probably used to go to the actions is broken. Also the configuration link in the comment block is not written correctly and isn???t rendering.\r\n- [ ] README: [Pricing section](https://github.com/grafana/x-ray-datasource#pricing) is a quote block for some reason",
      "updatedAt" : 1753385360.000000000,
      "user" : "kevinwcyu",
      "userHtmlUrl" : "https://github.com/kevinwcyu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19530599?v=4",
      "labels" : [ "datasource/X-Ray", "prio/medium", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This issue has been automatically marked as stale because it has not had activity in the last year. It will be closed in 30 days if no further activity occurs. Please feel free to leave a comment if you believe the issue is still relevant. Thank you for your contributions!" ],
      "repository" : {
        "description" : "AWS X-Ray data source",
        "homepage" : "",
        "name" : "x-ray-datasource",
        "fullName" : "grafana/x-ray-datasource",
        "htmlUrl" : "https://github.com/grafana/x-ray-datasource",
        "gitUrl" : "git://github.com/grafana/x-ray-datasource.git",
        "sshUrl" : "git@github.com:grafana/x-ray-datasource.git",
        "cloneUrl" : "https://github.com/grafana/x-ray-datasource.git",
        "owner" : {
          "login" : "grafana",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 11,
        "stargazersCount" : 38,
        "watchersCount" : 38,
        "size" : 136250,
        "openIssuesCount" : 15,
        "subscribersCount" : 141,
        "pushedAt" : "2025-07-24T11:34:31Z",
        "languages" : {
          "TypeScript" : 185534,
          "Dockerfile" : 2428,
          "Shell" : 388,
          "JavaScript" : 5297,
          "Go" : 126216
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update documentation for the x-ray-datasource repository, specifically for the CONTRIBUTING, README, and Pricing sections, as well as the Cross-Account Observability: Getting started guide, to fix broken links and outdated information.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments.",
      "otherNotes" : "Issue is automatically marked as stale due to inactivity for a year, will be closed in 30 days if no further activity occurs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406896
  }, {
    "issueDTO" : {
      "id" : 3022786452,
      "title" : "Test Windows build",
      "url" : "https://github.com/tractordev/wanix/issues/180",
      "repositoryName" : "tractordev/wanix",
      "description" : "The plan was to release with a Windows build, but we ran into issues actually testing it. In part, we don't have Windows easily available. \n\nIf somebody wants to try:\n\n```sh\nGOOS=windows GOARCH=amd64 GOARGS=\"-tags noconsole,nomount\" make wasm-go wanix\n```\n\nAnd run with resulting executable (`./wanix`):\n\n```sh\n./wanix serve\n```\n\n",
      "updatedAt" : 1753385320.000000000,
      "user" : "progrium",
      "userHtmlUrl" : "https://github.com/progrium",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/647?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Use UTM on a Mac or Linux \n\nIt???s fantastic for testing windows \n\nI have a bootstrapper written in golang and will release it that bootstraps your virtual os to install go, git,ssh etc automatically. \n\nSo you can just call go run etc and e writhing just works ", "Yea, UTM is great. So is QEMU. We could even use v86 to run Windows, so in theory in Wanix itself. We'll have something set up for future releases. Until then, or until we need to, if anybody is interested in Windows support, doing this for us will move things forward.", "I can help as I run windows , mac, Linux and FreeBSD locally inside UTM .\n\nAll my stuff has to work for end user on all of them , without all bootstrapping . Mostly scientist users .. ", "Literally just need somebody to compile and run on Windows and tell us it compiled fine and works." ],
      "repository" : {
        "description" : "A virtual environment kit for the local-first web, inspired by Plan 9",
        "homepage" : "https://wanix.sh",
        "name" : "wanix",
        "fullName" : "tractordev/wanix",
        "htmlUrl" : "https://github.com/tractordev/wanix",
        "gitUrl" : "git://github.com/tractordev/wanix.git",
        "sshUrl" : "git@github.com:tractordev/wanix.git",
        "cloneUrl" : "https://github.com/tractordev/wanix.git",
        "owner" : {
          "login" : "tractordev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 23,
        "stargazersCount" : 553,
        "watchersCount" : 553,
        "size" : 7182,
        "openIssuesCount" : 29,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-25T00:04:36Z",
        "languages" : {
          "Dockerfile" : 2733,
          "Shell" : 1694,
          "CSS" : 727,
          "C" : 3287,
          "Rust" : 1049,
          "Makefile" : 4333,
          "JavaScript" : 65734,
          "Go" : 219906,
          "Zig" : 1636,
          "HTML" : 594
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to test the Windows build of Wanix, which has been delayed due to lack of easy access to Windows.",
      "validationOrRequirement" : "The requirement is to compile and run the code on Windows and report if it compiles fine and works.",
      "attemptedFixes" : "The author mentions a bootstrapper written in Go that can automatically install Go, Git, SSH, etc. on a virtual OS, making it easier to test on different platforms.",
      "otherNotes" : "The issue is about testing a Windows build, but it's been difficult due to lack of easy access to Windows. The author suggests using UTM, QEMU, or v86 to run Windows, and offers to help with testing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406901
  }, {
    "issueDTO" : {
      "id" : 3022478099,
      "title" : "Call xterm addon-fit `.fit()` when window resizes",
      "url" : "https://github.com/tractordev/wanix/issues/177",
      "repositoryName" : "tractordev/wanix",
      "description" : "Currently, the terminal can get out of sync with the window size, causing unnecessary wrapping:\n\n![Image](https://github.com/user-attachments/assets/5fc459d7-8737-4bd1-ba63-926f49f017ba)\n\nWe need a ResizeObserver (or window.onresize event) to call .fit(): https://github.com/xtermjs/xterm.js/blob/master/demo/client.ts#L337",
      "updatedAt" : 1753385314.000000000,
      "user" : "canadaduane",
      "userHtmlUrl" : "https://github.com/canadaduane",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/129?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A virtual environment kit for the local-first web, inspired by Plan 9",
        "homepage" : "https://wanix.sh",
        "name" : "wanix",
        "fullName" : "tractordev/wanix",
        "htmlUrl" : "https://github.com/tractordev/wanix",
        "gitUrl" : "git://github.com/tractordev/wanix.git",
        "sshUrl" : "git@github.com:tractordev/wanix.git",
        "cloneUrl" : "https://github.com/tractordev/wanix.git",
        "owner" : {
          "login" : "tractordev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 23,
        "stargazersCount" : 553,
        "watchersCount" : 553,
        "size" : 7182,
        "openIssuesCount" : 29,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-25T00:04:36Z",
        "languages" : {
          "Dockerfile" : 2733,
          "Shell" : 1694,
          "CSS" : 727,
          "C" : 3287,
          "Rust" : 1049,
          "Makefile" : 4333,
          "JavaScript" : 65734,
          "Go" : 219906,
          "Zig" : 1636,
          "HTML" : 594
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Call xterm addon-fit .fit() when window resizes",
      "validationOrRequirement" : "Use ResizeObserver or window.onresize event to call .fit()",
      "attemptedFixes" : "ResizeObserver or window.onresize event needs to be used to call .fit(): https://github.com/xtermjs/xterm.js/blob/master/demo/client.ts#L337",
      "otherNotes" : "The terminal can get out of sync with the window size, causing unnecessary wrapping.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406904
  }, {
    "issueDTO" : {
      "id" : 3022282489,
      "title" : "Not listing all files in large directories",
      "url" : "https://github.com/tractordev/wanix/issues/175",
      "repositoryName" : "tractordev/wanix",
      "description" : "Somebody noted they don't see a `workerctl` when listing `/bin`. However, `cat /bin/workerctl` does list it. `ls -1 /bin` suspiciously ends at files starting with \"r\". `ls -1 /bin | wc -l` reports 273, when using devtools helpers `list(\"#shell/bin\")` returns 408 items. \n\nThis suggests the 9P path to the VFS is cutting off directory listings. ",
      "updatedAt" : 1753385295.000000000,
      "user" : "progrium",
      "userHtmlUrl" : "https://github.com/progrium",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/647?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "could be caused by chunking behavior in readdir() call\n\ntimebox this, and if it's more than the estimate then put it off until the next sprint." ],
      "repository" : {
        "description" : "A virtual environment kit for the local-first web, inspired by Plan 9",
        "homepage" : "https://wanix.sh",
        "name" : "wanix",
        "fullName" : "tractordev/wanix",
        "htmlUrl" : "https://github.com/tractordev/wanix",
        "gitUrl" : "git://github.com/tractordev/wanix.git",
        "sshUrl" : "git@github.com:tractordev/wanix.git",
        "cloneUrl" : "https://github.com/tractordev/wanix.git",
        "owner" : {
          "login" : "tractordev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 23,
        "stargazersCount" : 553,
        "watchersCount" : 553,
        "size" : 7182,
        "openIssuesCount" : 29,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-25T00:04:36Z",
        "languages" : {
          "Dockerfile" : 2733,
          "Shell" : 1694,
          "CSS" : 727,
          "C" : 3287,
          "Rust" : 1049,
          "Makefile" : 4333,
          "JavaScript" : 65734,
          "Go" : 219906,
          "Zig" : 1636,
          "HTML" : 594
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Not listing all files in large directories",
      "validationOrRequirement" : "None specified",
      "attemptedFixes" : "Timebox this, and if it's more than the estimate then put it off until the next sprint.",
      "otherNotes" : "The issue suggests that the 9P path to the VFS is cutting off directory listings, which could be caused by chunking behavior in readdir() call.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406907
  }, {
    "issueDTO" : {
      "id" : 1700351287,
      "title" : "Automate extension releases to VS Code Marketplace and Open VSX Regsitry",
      "url" : "https://github.com/coder/vscode-coder/issues/97",
      "repositoryName" : "coder/vscode-coder",
      "description" : "Currently, I believe GitHub release artifacts have to be manually submitted to the VS Code Marketplace. Can we automate this so they are always in sync?",
      "updatedAt" : 1753385178.000000000,
      "user" : "bpmct",
      "userHtmlUrl" : "https://github.com/bpmct",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22407953?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@stirby we could prioritise this, or maybe it's already done @code-asher?", "Not already done; the releases are infrequent enough that it has been easier to just upload the vsix manually but automation would be nice if we can spare the cycles to work on it", "Let's close this as unplanned for now. ", "Reopening as we now also publish to OpenVSX and automating can actually save time.\n\n\nThere is a sample workflow available here: https://github.com/EclipseFdn/publish-extensions/blob/master/docs/exampleCI.yaml" ],
      "repository" : {
        "description" : "Open any Coder workspace in VS Code with a single click.",
        "homepage" : null,
        "name" : "vscode-coder",
        "fullName" : "coder/vscode-coder",
        "htmlUrl" : "https://github.com/coder/vscode-coder",
        "gitUrl" : "git://github.com/coder/vscode-coder.git",
        "sshUrl" : "git@github.com:coder/vscode-coder.git",
        "cloneUrl" : "https://github.com/coder/vscode-coder.git",
        "owner" : {
          "login" : "coder",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28,
        "stargazersCount" : 95,
        "watchersCount" : 95,
        "size" : 16557,
        "openIssuesCount" : 63,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-24T23:05:47Z",
        "languages" : {
          "TypeScript" : 207065,
          "Shell" : 4893,
          "JavaScript" : 1840,
          "Nix" : 516
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Automate extension releases to VS Code Marketplace and Open VSX Registry",
      "validationOrRequirement" : "The releases are infrequent enough that manual uploading has been sufficient, but automation would be beneficial if the necessary cycles can be spared.",
      "attemptedFixes" : "The issue was initially closed as unplanned, but was reopened after considering the benefits of automation for publishing to OpenVSX.",
      "otherNotes" : "The issue is about automating the process of releasing extensions to the VS Code Marketplace and Open VSX Registry, with a sample workflow available.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406911
  }, {
    "issueDTO" : {
      "id" : 1862127874,
      "title" : "move workspace/agent buttons",
      "url" : "https://github.com/coder/vscode-coder/issues/129",
      "repositoryName" : "coder/vscode-coder",
      "description" : "![image](https://github.com/coder/vscode-coder/assets/57866459/fc7c2ac0-cb8a-4ef7-91c4-a29903c6ee0e)\r\n\r\n---\r\n\r\nI think it would be better UX-wise if the run buttons were at the same place.\r\nI expect to be able to go from run button to run button, and it isn't the case currently, and I find it pretty unintuitive.\r\n\r\nI think the icons should be in the following order:\r\n|  |   | | | |\r\n|---------------|---|----------|-----------|-----|\r\n| **Workspace** |   | settings | open page | run |\r\n| **Agents**    |   |          |           | run |",
      "updatedAt" : 1753385139.000000000,
      "user" : "phorcys420",
      "userHtmlUrl" : "https://github.com/phorcys420",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/57866459?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Open any Coder workspace in VS Code with a single click.",
        "homepage" : null,
        "name" : "vscode-coder",
        "fullName" : "coder/vscode-coder",
        "htmlUrl" : "https://github.com/coder/vscode-coder",
        "gitUrl" : "git://github.com/coder/vscode-coder.git",
        "sshUrl" : "git@github.com:coder/vscode-coder.git",
        "cloneUrl" : "https://github.com/coder/vscode-coder.git",
        "owner" : {
          "login" : "coder",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 28,
        "stargazersCount" : 95,
        "watchersCount" : 95,
        "size" : 16557,
        "openIssuesCount" : 63,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-24T23:05:47Z",
        "languages" : {
          "TypeScript" : 207065,
          "Shell" : 4893,
          "JavaScript" : 1840,
          "Nix" : 516
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Move workspace/agent buttons to improve UX and navigation",
      "validationOrRequirement" : "UX improvement, intuitive navigation between run buttons",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is about improving UX by moving workspace/agent buttons to the same place, making it easier to navigate between run buttons. The author suggests a specific order for the icons.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406913
  }, {
    "issueDTO" : {
      "id" : 2057879099,
      "title" : "Decorator type signatures not recognized by pyright",
      "url" : "https://github.com/pytest-dev/pytest-asyncio/issues/731",
      "repositoryName" : "pytest-dev/pytest-asyncio",
      "description" : "...and [according to pyright upstream](https://github.com/microsoft/pyright/issues/3497#issuecomment-1134850832), this is a bug in mypy, rather than in pyright.\r\n\r\nType-checking pytest-asyncio itself yields a great many errors, starting with:\r\n\r\n```none\r\npytest-asyncio/pytest_asyncio/plugin.py:57:60 - error: Type variable \"_R\" has no meaning in this context (reportGeneralTypeIssues)\r\npytest-asyncio/pytest_asyncio/plugin.py:57:36 - error: TypeVar bound type cannot be generic\r\npytest-asyncio/pytest_asyncio/plugin.py:60:65 - error: Type variable \"_R\" has no meaning in this context (reportGeneralTypeIssues)\r\npytest-asyncio/pytest_asyncio/plugin.py:60:37 - error: TypeVar bound type cannot be generic\r\n```\r\n\r\n...and type-checking a project that uses pytest-asyncio's decorators with `reportUntypedFunctionDecorator` set in pyright's configuration:\r\n\r\n```\r\nerror: Untyped function decorator obscures type of function; ignoring decorator (reportUntypedFunctionDecorator)\r\n```\r\n\r\n---\r\n\r\nI suspect that the option of _either_ passing the function to be used as a fixture as a direct argument to `fixture()` _or_ returning a function that acts as a proper decorator adds complexity here. If it's not possible to be pyright-friendly with the existing calling convention flexibility, might it make sense to offer a less-flexible, more explicitly-typed alternative?",
      "updatedAt" : 1753379042.000000000,
      "user" : "charles-dyfis-net",
      "userHtmlUrl" : "https://github.com/charles-dyfis-net",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22370?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks. Pytest-asyncio is currently type checked with an outdated version of mypy. There's an issue to update the type checker: #596\r\n\r\nI assume it would be helpful to also type check with pyright in the CI.\r\n\r\nSince pytest-asyncio v0.23 has functional issues that break some users' test suites, the typing issue you describe is not at the top of my priorities list at the moment. I hope you understand!", "@charles-dyfis-net pytest-asyncio-0.23.5a0 fixed some typing issues and removed the unbound type variable `_R` in the process. Can you try the pre release and check if it resolves your issue?", "We're not running clean, but the specific issue this ticket was filed for is no longer present:\r\n\r\n```\r\npytest-asyncio/pytest_asyncio/plugin.py\r\n  pytest-asyncio/pytest_asyncio/plugin.py:401:13 - error: Argument of type \"Node | None\" cannot be assigned to parameter \"parent\" of type \"Node\" in function \"from_parent\"\r\n  ????Type \"Node | None\" cannot be assigned to type \"Node\"\r\n  ????????\"None\" is incompatible with \"Node\" (reportGeneralTypeIssues)\r\n  pytest-asyncio/pytest_asyncio/plugin.py:652:30 - error: Cannot access member \"__original_collect\" for type \"Module\"\r\n  ????Member \"__original_collect\" is unknown (reportGeneralTypeIssues)\r\npytest-asyncio/tests/test_is_async_test.py\r\n  pytest-asyncio/tests/test_is_async_test.py:77:8 - error: Operator \"<\" not supported for types \"tuple[Literal[7], Literal[4], Literal[0]]\" and \"tuple[Literal[7], Literal[2]]\" (reportGeneralTypeIssues)\r\n  pytest-asyncio/tests/test_is_async_test.py:80:10 - error: Operator \"<\" not supported for types \"tuple[Literal[7], Literal[4], Literal[0]]\" and \"tuple[Literal[8]]\" (reportGeneralTypeIssues)\r\npytest-asyncio/tests/hypothesis/test_base.py\r\n  pytest-asyncio/tests/hypothesis/test_base.py:8:24 - error: \"given\" is unknown import symbol (reportGeneralTypeIssues)\r\n  pytest-asyncio/tests/hypothesis/test_base.py:8:31 - error: \"strategies\" is unknown import symbol (reportGeneralTypeIssues)\r\n6 errors, 0 warnings, 0 informations \r\n```", "Thanks for checking.\r\n\r\nResolving this issue would make for suitable first contribution to pytest-asyncio. I don't necessarily mean you, but anyone who is interested in working on this.\r\n\r\nIf anyone wants to open a PR, I would expect:\r\n* A [pyright pre-commit hook](https://github.com/RobertCraigie/pyright-python?tab=readme-ov-file#pre-commit) to be added to `.pre-commit-config.yaml`. This will run pyright on every commit and prevent this kind of issue in the future\r\n* the `docs` and `tests` folders to be excluded from the pyright type check (see configuration of the `mypy` pre-commit hook)\r\n* The two typing errors to be fixed", "Hello, I am a new programmer, and would like to contribute to this issue. This will be my first open-source contribution. Thank You!", "Hi @RoddyCodes, thanks for the initiative! We appreciate your contribution.\n\nLet us know, if you get stuck or need any additional information.", "Unfortunately, there is an issue with pre-commit and pyright. https://github.com/RobertCraigie/pyright-python/issues/345" ],
      "repository" : {
        "description" : "Asyncio support for pytest",
        "homepage" : "https://pytest-asyncio.readthedocs.io",
        "name" : "pytest-asyncio",
        "fullName" : "pytest-dev/pytest-asyncio",
        "htmlUrl" : "https://github.com/pytest-dev/pytest-asyncio",
        "gitUrl" : "git://github.com/pytest-dev/pytest-asyncio.git",
        "sshUrl" : "git@github.com:pytest-dev/pytest-asyncio.git",
        "cloneUrl" : "https://github.com/pytest-dev/pytest-asyncio.git",
        "owner" : {
          "login" : "pytest-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 162,
        "stargazersCount" : 1535,
        "watchersCount" : 1535,
        "size" : 940,
        "openIssuesCount" : 48,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-22T04:21:19Z",
        "languages" : {
          "Makefile" : 715,
          "Python" : 140323
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To make pytest-asyncio type-checkable with pyright, either passing the function to be used as a fixture as a direct argument to `fixture()` or returning a function that acts as a proper decorator. A less-flexible, more explicitly-typed alternative might be considered if the current calling convention flexibility is not possible.",
      "validationOrRequirement" : "A [pyright pre-commit hook] to be added to `.pre-commit-config.yaml` to run pyright on every commit, excluding the `docs` and `tests` folders from the pyright type check, and fixing the two typing errors.",
      "attemptedFixes" : "The pre-release pytest-asyncio-0.23.5a0 fixed some typing issues and removed the unbound type variable `_R` in the process. It's suggested to try the pre-release and check if it resolves the issue.",
      "otherNotes" : "The issue is related to type-checking pytest-asyncio itself, and also a project that uses pytest-asyncio's decorators with pyright's configuration. There's an issue to update the type checker: #596. The issue is not at the top of the priority list due to other functional issues.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406926
  }, {
    "issueDTO" : {
      "id" : 3244384348,
      "title" : "Make find-and-replace matches start at the position of the caret before Ctrl+F was pressed",
      "url" : "https://github.com/WebCoder49/code-input/issues/156",
      "repositoryName" : "WebCoder49/code-input",
      "description" : "Currently, if no find-and-replace query has been executed before, the first match found will be the first in all the code. The expected result mirrored in IDEs is starting at the first match after the position of the caret, which is so expected that I would classify the current behaviour as a bug.\n\nAs the FindAndReplace plugin is user-facing UI, not an API, changing this is not a breaking change.",
      "updatedAt" : 1753378999.000000000,
      "user" : "WebCoder49",
      "userHtmlUrl" : "https://github.com/WebCoder49",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/69071853?v=4",
      "labels" : [ "area:existing-plugin", "bug", "good first issue", "priority:medium" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Lightweight, customisable, editable *syntax-highlighted textareas* + plugins",
        "homepage" : "https://css-tricks.com/creating-an-editable-textarea-that-supports-syntax-highlighted-code/",
        "name" : "code-input",
        "fullName" : "WebCoder49/code-input",
        "htmlUrl" : "https://github.com/WebCoder49/code-input",
        "gitUrl" : "git://github.com/WebCoder49/code-input.git",
        "sshUrl" : "git@github.com:WebCoder49/code-input.git",
        "cloneUrl" : "https://github.com/WebCoder49/code-input.git",
        "owner" : {
          "login" : "WebCoder49",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 26,
        "stargazersCount" : 202,
        "watchersCount" : 202,
        "size" : 434,
        "openIssuesCount" : 26,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-24T14:13:47Z",
        "languages" : {
          "CSS" : 17902,
          "Shell" : 7132,
          "JavaScript" : 201609,
          "HTML" : 17305
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Make find-and-replace matches start at the position of the caret before Ctrl+F was pressed, which is the expected behavior in IDEs.",
      "validationOrRequirement" : "No specific validations or requirements mentioned.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to the FindAndReplace plugin, which is user-facing UI and not an API, so changing this is not a breaking change.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406929
  }, {
    "issueDTO" : {
      "id" : 3145535052,
      "title" : "Add an option to automatically update the BREE to the highest of all dependencies",
      "url" : "https://github.com/eclipse-pde/eclipse.pde/issues/1813",
      "repositoryName" : "eclipse-pde/eclipse.pde",
      "description" : "Currently PDE warns the user if one of the dependencies has a higher BREE than declared in the manifest. If one open the manifest, then there is even a quick-fix provided to update it.\n\nIt would be good to have the same in the \"Organize Manifest\" Wizard, so it can be applied in batch to many projects and in combination with the new [tycho-cleancode:manifest](https://tycho.eclipseprojects.io/doc/main/tycho-cleancode-plugin/manifest-mojo.html) mojo.",
      "updatedAt" : 1753378982.000000000,
      "user" : "laeubi",
      "userHtmlUrl" : "https://github.com/laeubi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1331477?v=4",
      "labels" : [ "organize-manifest", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "\"I'm working on this\"", "> \"I'm working on this\"\n\nThank you and welcome. Are you a student from CodeDays?\n\nThe following pages should help you to get started:\n- https://github.com/eclipse-ide/\n- https://github.com/eclipse-pde/eclipse.pde?tab=readme-ov-file#how-to-contribute\n\n", "Yes am a student from CodeDays!\n\n [linkedin.com/in/jose-rodriguez-5b7a062b8](https://www.linkedin.com/in/jose-rodriguez-5b7a062b8?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3Bz87EVdH%2BSLiolWMfHFx1HA%3D%3D)", "Hello, my teammates @JoseRodriguez26  @GreetingsEarthling and I (from CodeDay) have the following questions:\n\nIn the `OrganizeManifestsProcessor.java` file, there are a series of protected boolean variables declared near the top of the `OrganizeManifestsProcessor` class. We believe a change needs to be made here: adding a boolean variable for our update BREE feature. We have been mimicking the **Remove Useless Files** feature because it is a feature that also has something to do with altering files. Can you please confirm this assumption?\n\nHowever, we noticed that some boolean values are initialized to `true` while others are initialized to `false`. \n\nWith the help of Claude.ai, we came to the understanding that the boolean initialization values reflect the default behavior that the processor should have when run without explicit configuration. \n`true`: for ???conservative, safe cleanup operations???\n`false`: for ???potentially destructive, performance-intensive, or structure-changing operations???\n\nOur hypothesis is that our boolean variable `fUpdateBREE` should be initialized to `false` since changing the BREE in a manifest across projects:\n\n- alters the project???s runtime requirements and compatibility promises\n\n- could break compatibility with existing deployment environments that expect a lower Java version\n\nIs our understanding correct? If not, is there an explanation for it?", "> Our hypothesis is that our boolean variable `fUpdateBREE` should be initialized to `false` since changing the BREE in a manifest across projects:\n> \n>     * alters the project???s runtime requirements and compatibility promises\n> \n>     * could break compatibility with existing deployment environments that expect a lower Java version\n> \n> \n> Is our understanding correct? If not, is there an explanation for it?\n\nYes that sounds good. Besides the points you already mentioned, a third point is also compatibility with existing configurations. Users are often not happy if the results change (with a new version) without changing the configuration, unless it's always for their best. But in this case I think the new option should be turned off by default.", "Reusing Quick Fix Logic for BREE Update in Organize Manifest Wizard\n\nHello team,\n\nMy group @sderazo @GreetingsEarthling (from CodeDay) and I have identified three methods ( checkBREE(), getHighestEE(), getHighestBREE() ) related to the existing BREE quick fix located in the file `BundleErrorReporter.java` within the package org.eclipse.pde.internal.core.builders. \n\nWe discovered these methods by examining the call hierarchy from a file, `ReplaceExecEnvironment.java` which we understood made replacements of execution environments, located in the org.eclipse.pde.internal.ui.correction package. \n\nOur plan is to reuse logic of the methods checkBree(), getHighestEE(), & getHighestBREE() by removing the methods from `BundleErrorReporter.java` and copying them over to another java file which will serve as a utility file. \n\nThough we are unsure of which package we will place this java file that contains the 3 methods, our best guess is that it will remain within the org.eclipse.pde.internal.core.builders package.\n\nAside from our doubts of where to place this utility file, we plan to reuse the logic in a method of ours within `OrganizeManifest.java`.\n\nThe key question is: Where should we place these three methods to avoid redundancy in our code? Which package would be the best fit for them, and is this reuse approach recommended overall?\n\nThanks for your advice!" ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "eclipse.pde",
        "fullName" : "eclipse-pde/eclipse.pde",
        "htmlUrl" : "https://github.com/eclipse-pde/eclipse.pde",
        "gitUrl" : "git://github.com/eclipse-pde/eclipse.pde.git",
        "sshUrl" : "git@github.com:eclipse-pde/eclipse.pde.git",
        "cloneUrl" : "https://github.com/eclipse-pde/eclipse.pde.git",
        "owner" : {
          "login" : "eclipse-pde",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 118,
        "stargazersCount" : 32,
        "watchersCount" : 32,
        "size" : 133312,
        "openIssuesCount" : 286,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T22:05:55Z",
        "languages" : {
          "Java" : 26040945,
          "CSS" : 18383,
          "Shell" : 4197,
          "JavaScript" : 7081,
          "HTML" : 1162730,
          "XSLT" : 20815
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add an option to automatically update the BREE to the highest of all dependencies in the Organize Manifest Wizard.",
      "validationOrRequirement" : "The boolean variable fUpdateBREE should be initialized to false since changing the BREE in a manifest across projects alters the project's runtime requirements and compatibility promises, could break compatibility with existing deployment environments that expect a lower Java version, and compatibility with existing configurations.",
      "attemptedFixes" : "The team is planning to reuse logic of the methods checkBree(), getHighestEE(), & getHighestBREE() by removing them from BundleErrorReporter.java and copying them over to a utility file.",
      "otherNotes" : "The issue is about adding an option to automatically update the BREE to the highest of all dependencies in the Organize Manifest Wizard. It's a good first issue with labels organize-manifest and good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406935
  }, {
    "issueDTO" : {
      "id" : 3216189970,
      "title" : "Allow graceful degradation into textarea when there's no JavaScript / support for code-input",
      "url" : "https://github.com/WebCoder49/code-input/issues/134",
      "repositoryName" : "WebCoder49/code-input",
      "description" : "I'm thinking:\n```html\n<code-input language=\"javascript\" placeholder=\"JavaScript code, highlighted\"><textarea data-code-input-fallback placeholder=\"JavaScript code, not highlighted\">// This is a demo file\nconsole.log(\"Hello, World!\");\n</textarea></code-input>\n```\n\nIf this syntax (including the data-code-input-fallback) conflicts with anyone's usage so far I'll be incredibly surprised; if HTML is written inside a code-input and contains a textarea[data-code-input-fallback], the `<`s can be replaced with `&lt;`s.\n\nVery little code: just detect the textarea, transfer its value to the code-input value if it's present, and transfer textareaSyncAttributes to the code-input if the code-input doesn't already have them. CSS must be updated to override invisible text in textarea[data-code-input-fallback] - maybe always make it black on white.\n\nThis is useful because code-input can be used with HTML forms and no extra JavaScript.",
      "updatedAt" : 1753378971.000000000,
      "user" : "WebCoder49",
      "userHtmlUrl" : "https://github.com/WebCoder49",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/69071853?v=4",
      "labels" : [ "area:core", "enhancement", "good first issue", "priority:medium" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Lightweight, customisable, editable *syntax-highlighted textareas* + plugins",
        "homepage" : "https://css-tricks.com/creating-an-editable-textarea-that-supports-syntax-highlighted-code/",
        "name" : "code-input",
        "fullName" : "WebCoder49/code-input",
        "htmlUrl" : "https://github.com/WebCoder49/code-input",
        "gitUrl" : "git://github.com/WebCoder49/code-input.git",
        "sshUrl" : "git@github.com:WebCoder49/code-input.git",
        "cloneUrl" : "https://github.com/WebCoder49/code-input.git",
        "owner" : {
          "login" : "WebCoder49",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 26,
        "stargazersCount" : 202,
        "watchersCount" : 202,
        "size" : 434,
        "openIssuesCount" : 26,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-24T14:13:47Z",
        "languages" : {
          "CSS" : 17902,
          "Shell" : 7132,
          "JavaScript" : 201609,
          "HTML" : 17305
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow code-input to degrade gracefully into a textarea when JavaScript is not available, supporting code-input with HTML forms without extra JavaScript.",
      "validationOrRequirement" : "detect the textarea, transfer its value to the code-input value if it's present, and transfer textareaSyncAttributes to the code-input if the code-input doesn't already have them.",
      "attemptedFixes" : "",
      "otherNotes" : "Code-input should support graceful degradation into textarea when JavaScript is not available, and the code should be highlighted in a textarea with a fallback placeholder. The code should be able to replace &lt; with &lt; and handle textareaSyncAttributes.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406940
  }, {
    "issueDTO" : {
      "id" : 3228666488,
      "title" : "\uD83D\uDC1EYouTube Playlists",
      "url" : "https://github.com/code-charity/youtube/issues/3038",
      "repositoryName" : "code-charity/youtube",
      "description" : "### Concise Description\n\nYouTube Playlist thumbnails have gone all weird.\n\n<img width=\"1551\" height=\"776\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4025f805-ebf9-4d3c-82eb-3ec11510e396\" />\n\n### Browser/s\n\nFirefox\n\n### Other Browser:\n\n140.0.4\n\n### 'Steps to reproduce' - Which of our features is required for the bug to happen?\n\nI opened a playlist and saw this. I disabled the extension and without needing to refresh the page, the thumbnails went back to normal.\n\n### Since when?\n\n11th July Evening, I first saw this.\n\n### Does the bug still happen when you log out of YouTube?\n\nNone\n\n### ..No? Then please paste your yt.config_.EXPERIMENT_FLAGS. Twice (With the error & Without)\n\n_No response_\n\n### Are any errors or related log-messages shown in the Browser-Console? (F12)\n\n_No response_\n\n### Tested as the only active extension? (incognito mode or another browser users):\n\nNone\n\n### Expected preferred behavior:\n\nNon-weirdness\n\n### ImprovedTube Version\n\n4.1320\n\n### Your Settings (From the Extension's `???`-Hamburger menu > Settings > Backup & reset > Export settings)\n\nI have played around turning off settings I have changed and nothing has worked.\n\n### Your YouTube-Document\n\n_No response_\n\n### OS / Device:\n\nStandard Desktop running Linux Mint",
      "updatedAt" : 1753378965.000000000,
      "user" : "boirfanman",
      "userHtmlUrl" : "https://github.com/boirfanman",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/220726503?v=4",
      "labels" : [ "Bug", "help wanted", "good first issue", "up-for-grabs" ],
      "state" : "OPEN",
      "comments" : [ "Hey, new to open source and would love to help investigate this issue. I'll try to reproduce bug on my setup and see what part of extension causes thumbnail glitch.\n", "@adipatil-13  Did you manage to find out anything? It is still happening but only on Linux. Windows 11 24H2 seems to not have the issue for me.\n\nAre you using Mint 22.1 to research? I have probably used the zoom function (ctrl+up) to make the YouTube pages a little larger. On Windows here it is on 120%. I can check Mint later.", "I'm also experiencing the same issue on Windows 11 24H2. Only happens in Firefox 140.0.4. Chrome version seems to be working fine.", "> I'm also experiencing the same issue on Windows 11 24H2. Only happens in Firefox 140.0.4. Chrome version seems to be working fine.\n\n\nHuh. Mine is fine. Same 24H2 and 140.0.4. I wonder why it's done that to yours on Windows.", "Also having this issue on Brave Brower, Chrome seems ok but who wants to use that ", "Same here, this is happening to me too. It's not just playlist, in the Home tab of a channel, the For You, Videos, etc rows also have this cropped zoomed in view as well. \n\nImprovedTube Version 4.1320\n\nZen browser (Firefox fork) 1.14.5b (Firefox 140.0.4) (64-bit)\n\nWindows 10 22H2\n\n[improvedtube.json](https://github.com/user-attachments/files/21333626/improvedtube.json)", "I've noticed the Home page of a channel having the problem, too but only on my Linux. Windows for me is totally fine on Firefox.\n\nThis is weird. Is there anything Zen Browser does to the Firefox options that I have changed manually that could effect it?\n\nI manually change 'browser.enable_automatic_image_resizing' and 'browser.enable_click_image_resizing' in about:config within Firefox every time I have installed it. It is the only things I change in about:config. Maybe I haven't done this on my Linux yet; I have just started using it.\n\nDoes Zen Browser have options for theses toggles within the settings? Or does it come with these already modified?", "Zen has those in about:config. Both of them are true on Zen. I don't tweak any settings directly in about:config though, so I assume that's the default on Zen. I also still have a Firefox install and both of them are true as well. \n\nEdit: I just tried a fresh add-on install on Firefox. Without changing anything, the videos are not stretched. I changed \"Thumbnails per Row\" (General > Thumbnails) to 6, and videos are still not stretched. But importing the same settings from Zen to Firefox produced the bugs. Resetting the settings, the bug isn't produced. ", "Alright. So it must be a setting in our 'Improve YouTube!' addons. Something we changed a while back and is now causing the problem.\n\nI had an old settings backup from 12th October 2024 which I ported over to the Linux installed Firefox. I think it was before the issues with thumbnails. I have exported the Windows settings and had a look at the differences between them.\n\nHere is a list of the differences. The problem must surely be here:\n\n### **These below are new in the .json file. Changes I have made in the Windows version since the last backup, which are not in the Linux version**\n\n\"header_hide_logo\":false,\n\"header_position\":\"normal\",\n\"hide_clip_button\":\"hidden\",\n\"hide_save_button\":\"normal\",\n\"player_autoplay_button\":false,\n\"player_cinema_mode_button\":false,\n\"player_forced_volume\":false,\n\"player_loudness_normalization\":true,\n\"player_popup_button\":false,\n\"player_repeat_button\":false,\n\"player_volume\":9,\n\"remove_member_only\":true,\n\"title_version\":true,\n\n### **These below are the differences in settings that exist in both .json files**\n\n\"hide_share_button\":\"icons_only\", changed to \"hide_share_button\":\"hidden\",\n\"lastDarkTheme\":\"night\", changed to \"lastDarkTheme\":\"sunset\",\n\"lastLightTheme\":\"custom\", changed to \"lastLightTheme\":\"desert\",\n\"player_color\":\"amber\", changed to \"player_color\":\"default\",\n\"theme\":\"night\", changed to \"theme\":\"sunset\",\n\nThis is a good place to start I think.\n\nI also reloaded the old settings to the windows version and all seems to be fine with those settings, too. Which I was hoping would not be the case. Some interaction between settings and browser and OS makes it more complicated to diagnose.", "Ok so I fixed the Linux YouTube Playlists last night.\n\n- First, I backed up my settings from Windows Improve YouTube\n- Went to my broken Linux version\n- Opened Improve YouTube settings and clicked _backup&reset_ > _reset all settings_ \n- Opened a new tab and went to a playlist; it was fixed\n- Then I imported the settings I backed up earlier\n- Opened a new tab and checked the playlist and it still worked fine\n\nIt still worked today after booting up so looks like this fixed it for me.\n\nIf you backup your settings, reset them, then re-import them, checking playlists between each step; it may fix it for you, too.\n\nIf not, try switching to the settings in the last post above, that have changed between both .json files and repeat the steps.\n\nHopefully someone can piece together why first resetting and then re-importing my newer .json file fixed this weirdness.\nIf just saving, resetting, re-importing fixes others' playlists, we can rule out the change in settings between backups at least.", "I'm experiencing this issue as of today, with thumbnails stretched as wide as the layout allows in both playlists and channel pages. This issue started happening right after I accidentally changed the \"Thumbnails per row\" setting (for which there's no reset button turn back the default behavior). Any value I set to it doesn't affect this issue.\n\nTried backing up my settings, clearing all settings in the extension using the \"Reset all settings\" button inside the extension's backup settings, and modifying my settings.json file to remove the thumbnails setting before loading it back to the extension. However, while the number of thumbnails per row returned to the normal value used by youtube, the stretched thumbnails still appear, even though I removed the setting that caused this issue.\n\nMight try later to fully reinstall the extension and see if that works. \n\nBrowser: Firefox 140 on Linux.\n\nUpdate: Clearing extension settings while on a channel page instantly fixes the problem, but as soon as I import my settings again, the issue reappears. Reinstalling didn't work either, since it pulled my synchronized settings.\n\nUpdate 2: Ended up just resetting extension settings and restoring my configuration manually. Tried checking the json for any extraneous settings that might have been changed, but nothing stood out as the source for the issue. Clearing cookies didn't help either, just in case.", "Same here, reset settings and restoring my configuration manually and the bug isn't reproduced. Have to hard refresh a couple times for theming to properly change, but again, bug not reproduced. ", "> Same here, reset settings and restoring my configuration manually and the bug isn't reproduced. Have to hard refresh a couple times for theming to properly change, but again, bug not reproduced.\n\n\nSo the issue is fixed for you then? No synchronisation, manual backup, reset settings, check a playlist, re-import settings, restart browser, check playlist. No messing with settings or .json file in between any steps.\nThat's what seems to work for me.\n\nI have 'four thumbnails per row' on Windows and 'five' on Linux. They are both fine. Changing them after this is fixed may break it again. I am not willing to do that. This bug ruins YouTube for me, I use playlists a lot.", "Yes, the issues are fixed for me. \n\nhttps://github.com/code-charity/youtube/issues/3038#issuecomment-3105638055\n\nIn here, this is on a different device, a W11 laptop, with Zen as well. Fresh install of improved youtube (IY), everything is fine. Imported my .json file I shared in this issue post, bugged playlist and home channel. reset settings, everything fine again. manually set via GUI, not by json file, like the bugged set up from my first device. everything is fine, playlist and channel home not bugged. \n\nNow in my first device, the W10 PC, I reset settings, import the new settings on the W11 laptop. issue is fixed. playlist and channel home not bugged. changed the number per row to 8 just for extreme. still not bugged. \n\nno messing with json file because I don't really know json, and also don't really want to try it lol. ", "@91grayjay  Ok, cool. So it seems like something was changed in an Improve YouTube update that our old settings didn't like. Maybe the way to fix it for everyone, is to have the Add-on (somehow) backup all settings, reset them and then re-apply them.\n\nI'm not sure how because it needs to ask for an extra permission to backup the settings. Possibly export to memory first instead?\nI wonder how many people this has effected that dropped the Add-on because it is the easy fix?" ],
      "repository" : {
        "description" : "Open YouTube & Video browser-extension [top~1] Enrich your experience&choice!\uD83E\uDDF0200+options; clever features\uD83D\uDCCCset&forget\uD83D\uDCCCLongest-standing. Join\uD83E\uDDE9us?\uD83D\uDC68???\uD83D\uDC69???\uD83D\uDC67???\uD83D\uDC67  ??? {playback|content discovery|player|extra buttons|distractions|related videos|shorts|ads|quality|codec|full tab|full screen}",
        "homepage" : "http://improvedtube.com",
        "name" : "youtube",
        "fullName" : "code-charity/youtube",
        "htmlUrl" : "https://github.com/code-charity/youtube",
        "gitUrl" : "git://github.com/code-charity/youtube.git",
        "sshUrl" : "git@github.com:code-charity/youtube.git",
        "cloneUrl" : "https://github.com/code-charity/youtube.git",
        "owner" : {
          "login" : "code-charity",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 657,
        "stargazersCount" : 3848,
        "watchersCount" : 3848,
        "size" : 11907,
        "openIssuesCount" : 928,
        "subscribersCount" : 274,
        "pushedAt" : "2025-07-19T15:33:09Z",
        "languages" : {
          "CSS" : 282473,
          "JavaScript" : 536753,
          "HTML" : 4280,
          "Python" : 11326
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to resolve the issue of YouTube playlist thumbnails being distorted and zoomed in on Firefox 140.0.4 and Linux, which is caused by changes made in an Improve YouTube update.",
      "validationOrRequirement" : "The issue is specific to Firefox 140.0.4 and Linux, and may be related to changes made in an Improve YouTube update. The fix requires backing up settings, resetting them, and then re-applying them.",
      "attemptedFixes" : "Various attempts were made to fix the issue, including resetting settings, re-importing settings, and reinstalling the extension. The issue was eventually fixed by resetting settings and re-importing them, but not without some trial and error.",
      "otherNotes" : "The issue seems to be caused by changes made in an Improve YouTube update, which is not compatible with old settings. The fix involves backing up settings, resetting them, and then re-applying them. This is not a straightforward process and requires extra permission to backup settings. Some users may have dropped the add-on due to this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406947
  }, {
    "issueDTO" : {
      "id" : 3260700466,
      "title" : "GoToLine invalid status action is inaccessible",
      "url" : "https://github.com/WebCoder49/code-input/issues/159",
      "repositoryName" : "WebCoder49/code-input",
      "description" : "When the line number entered into the GoToLine box is invalid, it will turn red. Using colour only to signify this makes it invisible to screenreaders and could also be bad for some kinds of colourblind users. After this, pressing enter does nothing with no explanation.\n\nA message should be shown to both screenreaders and the screen when it is invalid:\n* the easiest way to do this is to **replace the custom JavaScript validation of `input[type=text]` with HTML form validation of `input[type=number]`**, and use the `min` and `max` *as well as JavaScript validation methods as many minor browsers show range validation clearly* ([source](https://caniuse.com/input-number)).",
      "updatedAt" : 1753378935.000000000,
      "user" : "WebCoder49",
      "userHtmlUrl" : "https://github.com/WebCoder49",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/69071853?v=4",
      "labels" : [ "priority:high", "area:existing-plugin", "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Lightweight, customisable, editable *syntax-highlighted textareas* + plugins",
        "homepage" : "https://css-tricks.com/creating-an-editable-textarea-that-supports-syntax-highlighted-code/",
        "name" : "code-input",
        "fullName" : "WebCoder49/code-input",
        "htmlUrl" : "https://github.com/WebCoder49/code-input",
        "gitUrl" : "git://github.com/WebCoder49/code-input.git",
        "sshUrl" : "git@github.com:WebCoder49/code-input.git",
        "cloneUrl" : "https://github.com/WebCoder49/code-input.git",
        "owner" : {
          "login" : "WebCoder49",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 26,
        "stargazersCount" : 202,
        "watchersCount" : 202,
        "size" : 434,
        "openIssuesCount" : 26,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-24T14:13:47Z",
        "languages" : {
          "CSS" : 17902,
          "Shell" : 7132,
          "JavaScript" : 201609,
          "HTML" : 17305
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to make the GoToLine invalid status action accessible by showing a message to both screenreaders and the screen when the entered line number is invalid.",
      "validationOrRequirement" : "Replace custom JavaScript validation with HTML form validation, using the 'min' and 'max' attributes, and also JavaScript validation methods.",
      "attemptedFixes" : "No attempts or blockers are mentioned in the description or comments.",
      "otherNotes" : "This issue is related to an existing plugin and is considered a good first issue, making it a suitable task for new contributors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406951
  }, {
    "issueDTO" : {
      "id" : 3247198340,
      "title" : "Implement AI-powered challenge recommendations",
      "url" : "https://github.com/opensource-society/CodeClip/issues/18",
      "repositoryName" : "opensource-society/CodeClip",
      "description" : "**Description**: Create a basic recommendation system that suggests challenges based on user's completion history and difficulty progression using localStorage data analysis.\n**Acceptance Criteria**:\n???\t??? Analyze user patterns\n???\t??? Generate recommendations\n???\t??? Display recommended challenges\n???\t??? Track recommendation accuracy\n\uD83D\uDE80 Advanced Tips: Focus on complex functionality, error handling, and scalable code architecture. Consider security and performance implications.\n?????? Estimated Time: 8-16 hours\n",
      "updatedAt" : 1753378702.000000000,
      "user" : "adityai0",
      "userHtmlUrl" : "https://github.com/adityai0",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/97042972?v=4",
      "labels" : [ "enhancement", "gssoc2025", "good first issue", "level 3" ],
      "state" : "OPEN",
      "comments" : [ "Please Assign me this issue", "I'd like to take on this issue and build a recommendation engine that\n\n- Tracks user progress via localStorage\n- Analyzes completion patterns and difficulty levels\n- Suggests next challenges based on learning curve\n- Measures accuracy to improve over time", "Hi, I???m confident in handling the logic and user behavior insights for this task and would love to be assigned. I???ll ensure it???s efficient, scalable, and well-structured.", "I'm able to implementing a basic recommendation system using localStorage data, analyzing user behavior and difficulty progression. I???ll ensure recommendations are generated effectively and displayed cleanly, while also tracking their accuracy. I???ll focus on clean, scalable architecture with error handling and performance in mind. kindly assign me this issue..?", "Hi ,\nI hope you're doing well!\nI came across the issue regarding implementing a basic recommendation system based on user challenge completion and difficulty progression using localStorage data. I find this feature really interesting and would love to contribute to it under GSSoC.\nI'm confident in working with JavaScript and localStorage, and I???ll ensure to focus on proper data analysis, recommendation logic, and performance. I???ll also handle edge cases and aim for clean, scalable code.\n\nPlease assign this issue to me if it's still available.\n\nLooking forward to your response!\n\n\n", "Hi! \uD83D\uDC4B This is a very interesting issue and I would love to work on it. I'm participating in **GSSoC'25** and excited to implement the challenge recommendation system with localStorage data analysis, tracking, and suggestions.\n\nPlease assign it to me if it???s available. Thanks! \uD83D\uDE0A\n", "i would like to contribute on this . please assign this to me ", "I can fix this issue as a gssoc contributor I have expertise in html CSS and js and I  have marked many projects relatedd ai like AI Chatbot @adityai0 ", "hi! I would like to contribute on this, can you please assign me the issue.", "Hi @adityai0 \uD83D\uDC4B,\n\nI'm really excited about this issue and would love the opportunity to implement it. With a strong foundation in JavaScript and experience working on browser-based applications, I'm confident I can build a scalable and efficient recommendation system that analyzes localStorage patterns, tracks performance metrics, and suggests relevant challenges with clarity and precision.\n\nI'll ensure the solution includes:\nModular and maintainable architecture\nProper error handling and performance optimizations\nA user-friendly UI component to display recommendations\nTracking logic to monitor accuracy and improve suggestions over time\nI've also contributed to similar logic in previous projects involving recommendation engines and client-side data analysis.\n\nI'd love to take this on???please assign me if possible! \n\nThanks!\n\n" ],
      "repository" : {
        "description" : "CodeClip is a comprehensive coding challenge platform built with HTML, CSS, and JavaScript, designed specifically for GSSoC contributors and the broader coding community.",
        "homepage" : "https://opensource-society.github.io/CodeClip/",
        "name" : "CodeClip",
        "fullName" : "opensource-society/CodeClip",
        "htmlUrl" : "https://github.com/opensource-society/CodeClip",
        "gitUrl" : "git://github.com/opensource-society/CodeClip.git",
        "sshUrl" : "git@github.com:opensource-society/CodeClip.git",
        "cloneUrl" : "https://github.com/opensource-society/CodeClip.git",
        "owner" : {
          "login" : "opensource-society",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 90,
        "stargazersCount" : 27,
        "watchersCount" : 27,
        "size" : 1475,
        "openIssuesCount" : 75,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-24T17:15:19Z",
        "languages" : {
          "CSS" : 40699,
          "JavaScript" : 18676,
          "HTML" : 146258
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a basic recommendation system that suggests challenges based on user's completion history and difficulty progression using localStorage data analysis",
      "validationOrRequirement" : "Analyze user patterns, Generate recommendations, Display recommended challenges, Track recommendation accuracy, Modular and maintainable architecture, Proper error handling and performance optimizations, User-friendly UI component to display recommendations, Tracking logic to monitor accuracy and improve suggestions over time",
      "attemptedFixes" : "Tracks user progress via localStorage, analyzes completion patterns and difficulty levels, suggests next challenges based on learning curve, measures accuracy to improve over time",
      "otherNotes" : "Implement AI-powered challenge recommendations, analyze user patterns, generate recommendations, display recommended challenges, track recommendation accuracy, focuses on complex functionality, error handling, and scalable code architecture, considers security and performance implications, estimated time: 8-16 hours",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406956
  }, {
    "issueDTO" : {
      "id" : 564894425,
      "title" : "Add support for `OVERLAPS` Predicate",
      "url" : "https://github.com/partiql/partiql-lang-kotlin/issues/183",
      "repositoryName" : "partiql/partiql-lang-kotlin",
      "description" : "Add support for `OVERLAPS` Predicate",
      "updatedAt" : 1753378657.000000000,
      "user" : "therapon",
      "userHtmlUrl" : "https://github.com/therapon",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/284529?v=4",
      "labels" : [ "SpecCompliance", "enhancement", "good first issue", "M" ],
      "state" : "OPEN",
      "comments" : [ "SQL1999 spec reference for `OVERLAPS` -- https://web.cecs.pdx.edu/~len/sql1999.pdf#page=342." ],
      "repository" : {
        "description" : "PartiQL libraries and tools in Kotlin.",
        "homepage" : "https://partiql.org/",
        "name" : "partiql-lang-kotlin",
        "fullName" : "partiql/partiql-lang-kotlin",
        "htmlUrl" : "https://github.com/partiql/partiql-lang-kotlin",
        "gitUrl" : "git://github.com/partiql/partiql-lang-kotlin.git",
        "sshUrl" : "git@github.com:partiql/partiql-lang-kotlin.git",
        "cloneUrl" : "https://github.com/partiql/partiql-lang-kotlin.git",
        "owner" : {
          "login" : "partiql",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 67,
        "stargazersCount" : 546,
        "watchersCount" : 546,
        "size" : 17901,
        "openIssuesCount" : 262,
        "subscribersCount" : 21,
        "pushedAt" : "2025-07-24T20:48:02Z",
        "languages" : {
          "Java" : 672504,
          "Shell" : 748,
          "ANTLR" : 50836,
          "HTML" : 103438,
          "Kotlin" : 2742638
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for `OVERLAPS` Predicate in partiql-lang-kotlin",
      "validationOrRequirement" : "Compliance with SQL1999 spec for `OVERLAPS` Predicate",
      "attemptedFixes" : "No attempts or blockers mentioned in the issue",
      "otherNotes" : "SQL1999 spec reference for `OVERLAPS` provided in comments",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406959
  }, {
    "issueDTO" : {
      "id" : 1250060589,
      "title" : "Improve documentation how to setup and use a kopia server",
      "url" : "https://github.com/kopia/kopia/issues/1982",
      "repositoryName" : "kopia/kopia",
      "description" : "I'm pretty new to kopia and really impressed! In general the documentation is really good and easy to understand fro me. Thank you very much for all you work!\r\n\r\nHowever, now I tried to setup a kopia server and there are some things I missed at https://kopia.io/docs/repository-server/ so these points could be improved. (I might provide a PR for the documentation ... once I understand the details ... :smiley:)\r\n\r\n* Explain the process of setting up a kopia server\r\n  * Explain requirements to run a server\r\n  * `kopia server start`, link to https://kopia.io/docs/reference/command-line/common/server-start/\r\n  * Explain TLS setup (*)\r\n  * Remember to open the port in case a firewall is used (e.g. on linux with ufw using: `sudo ufw allow 51515 comment 'kopia server via https'`)\r\n  * Create user accounts\r\n  * Will the server start automatically on machine boot (e.g. register a service)? Or do I need to do this myself?\r\n* It seems that `kopia server start` does not start the server in the background, but instead provides the server itself. I did expect it otherwise, so it might be mentioned. I guess now, the server won't be started automatically then, right?\r\n* what does `kopia server snapshot` (cancel / pause / resume) do? I don't understand the explanation on https://kopia.io/docs/reference/command-line/common/server-snapshot/\r\n\r\n(*) Could it be that the headings level got messed up? It looks like \"Auto-Generated TLS Certificate\" is a sub heading of \"Configuring Allowed Users - Kopia v0.7\":\r\n\r\n* [Configuring Allowed Users - Kopia v0.8](https://kopia.io/docs/repository-server/#configuring-allowed-users---kopia-v08)\r\n* [Configuring Allowed Users - Kopia v0.7](https://kopia.io/docs/repository-server/#configuring-allowed-users---kopia-v07)\r\n  * [Auto-Generated TLS Certificate](https://kopia.io/docs/repository-server/#auto-generated-tls-certificate)\r\n  * ...\r\n\r\nBut when I read more carefully, it talks about kopia v0.8 as well, so I guess there is a top level heading missing?\r\n\r\n-----\r\nSome more experiences during my first steps, as hints how the documentation could be improved:\r\n\r\nHow can I print the fingerprint again in case I missed to write it down when it was created?\r\n\r\nOnce I started a kopia server, I try to connect (on server machine):\r\n\r\n```\r\n$ kopia server status --server-cert-fingerprint xxx\r\nkopia: error: unable to list sources: 400 Bad Request, try --help\r\n```\r\nThis error message is not really helpful and should at least be explained.\r\nBut when connection from a remote machine this **did** work:\r\n\r\n```\r\n$ kopia repository connect server --url https://<server>:51515 --server-cert-fingerprint xxx\r\n```\r\n\r\nWhen I try to get the server status from a remote machine, this fails as well:\r\n\r\n```\r\n$ kopia server status --address https://<server>:51515 --server-cert-fingerprint xxx\r\nkopia: error: unable to list sources: 401 Unauthorized, try --help\r\n```\r\n\r\n(BTW: Seems to be inconsistent to use `--address` here and `--url` at other places. Or does it have different semantics?)\r\n\r\nAlso, when I try to open the server web UI in a browser, the credentials I created before using `kopia server user add` are not accepted.\r\n\r\n-----\r\n\r\nWhen I try to sync a local repo to the server I also get an error:\r\n\r\n```\r\n$ kopia repository sync-to server --url https://<server>:51515 --server-cert-fingerprint xxx\r\nkopia: error: expected command but got \"server\", try --help\r\n```\r\n\r\nIs syncing to a server not supported or did I miss something here? It did work when I tried `filesystem` or `sftp`.\r\n\r\n-----\r\n$ kopia --version\r\n0.10.7 build: 5d87d817335f6d547e094ab80062113dc3a1fdf4 from: kopia/kopia",
      "updatedAt" : 1753378594.000000000,
      "user" : "ptandler",
      "userHtmlUrl" : "https://github.com/ptandler",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/934595?v=4",
      "labels" : [ "documentation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I'm also trying to understand the `kopia server snapshot` usage", "> How can I print the fingerprint again in case I missed to write it down when it was created?\r\n\r\nThis is not generated. This is the \"cleaned up\" fingerprint of the TLS certificate:\r\n\r\n`openssl x509 -noout -fingerprint -sha256 -in <public.crt> | sed 's/://g' | cut -f 2 -d =`", "I think the problem here goes beyond just documentation. The server seems to be variously broken and/or very problematic to work with. I've spent the last couple of days beating my head against the server with the following results:\r\n\r\n---\r\n\r\nIt's confusing that some `server` commands accept control params for directly accessing a remote server (also noting the inconsistent use of the params `--url` and `--address` accross various subcommands, as above), whereas others do not, and appear to require connecting to a repository before they can be used. This can maybe be aided by documentation, but the CLI would be much more usable if all server operations were implemented on the control API, or alternatively (and much less preferably), operations that actually operate on the respository were put under a nested subcommand, ie `server repository users list` or something.\r\n\r\n---\r\n \r\n- The `server status` command on the host does not work, always returns `400 Bad Request`.\r\n- The `server status` command executed remotely, using the correct control username and password returns `400 Bad Request`\r\n- The `server status` command specifies that it reads the env vars `KOPIA_SERVER_USERNAME` and `KOPIA_SERVER_PASSWORD` as the values for the args `--server-control-username` and `--server-control-password` respectively, however the variables for the control user when starting the server are `KOPIA_CONTROL_USER` and `KOPIA_CONTROL_PASSWORD`, resulting in conflicts for configuration via env.\r\n- The KOPIA_CONTROL_USER variable name is inconsistent with the KOPIA_SERVER_USER*NAME* variable name (and the latter format should be preferred as it's consistent with the argument names `--server-control-username`/`--server-username`).\r\n\r\n---\r\n\r\n- The `server refresh` command on the host does not work, always returns `400 Bad Request`.\r\n- The `server refresh` command executed remotely, using the correct control username and password returns `400 Bad Request`\r\n- The `server refresh` command specifies that it reads the env vars `KOPIA_SERVER_USERNAME` and `KOPIA_SERVER_PASSWORD` as the values for the args `--server-control-username` and `--server-control-password` respectively, however the variables for the control user when starting the server are `KOPIA_CONTROL_USER` and `KOPIA_CONTROL_PASSWORD`, resulting in conflicts for configuration via env.\r\n- The KOPIA_CONTROL_USER variable name is inconsistent with the KOPIA_SERVER_USER*NAME* variable name (and the latter format should be preferred as it's consistent with the argument names `--server-control-username`/`--server-username`).\r\n\r\nIt's possible all the control-api commands produce these results, but the above two are the ones that I tested.\r\n\r\n---\r\n\r\nI could not find any way to get both the CLI and the server to see that they're connected to a repository other than to first create the repository from the CLI (e.g. `kopia respository create ...`), then to log into the server web UI and connect the repository from there too. This is quite confusing - is the server not using the same configs as the CLI or something?\r\n\r\n---\r\n\r\nAfter creating a user via `kopia server users add user@host`, connecting to the repository on a client `kopia repository connect server ...`, and receiving the expected response:\r\n\r\n```\r\nConnecting to server 'https://127.0.0.1:51515' as 'user@host'...\r\nConnected to repository API Server.\r\n\r\nNOTICE: Kopia will check for updates on GitHub every 7 days, starting 24 hours after first use.\r\nTo disable this behavior, set environment variable KOPIA_CHECK_FOR_UPDATES=false\r\nAlternatively you can remove the file \"/home/user/.config/kopia/repository.config.update-info.json\".\r\n```\r\n\r\nNo repository commands work:\r\n\r\n```\r\n$ kopia snapshot create /home/user/tmp\r\nERROR failed to open repository: unable to establish session for purpose=: error establishing session: unable to initialize session: rpc error: code = PermissionDenied desc = access denied for user@host: EOF\r\nERROR open repository: unable to open repository: unable to establish session for purpose=: error establishing session: unable to initialize session: rpc error: code = PermissionDenied desc = access denied for user@host: EOF\r\n$ kopia snapshot list\r\nERROR failed to open repository: unable to establish session for purpose=: error establishing session: unable to initialize session: rpc error: code = PermissionDenied desc = access denied for user@host: EOF\r\nERROR open repository: unable to open repository: unable to establish session for purpose=: error establishing session: unable to initialize session: rpc error: code = PermissionDenied desc = access denied for user@host: EOF\r\n$ kopia repository status\r\nERROR failed to open repository: unable to establish session for purpose=: error establishing session: unable to initialize session: rpc error: code = PermissionDenied desc = access denied for user@host: EOF\r\nERROR open repository: unable to open repository: unable to establish session for purpose=: error establishing session: unable to initialize session: rpc error: code = PermissionDenied desc = access denied for user@host: EOF\r\n```\r\n\r\nMaybe this is because the `server refresh` command is broken and can't be executed, however restarting the server also has no impact, and `repository connect` succeeds so I suspect this is a more fundamental problem.\r\n\r\nI tried enabling ACLs but they made no difference.\r\n\r\n---\r\nSo my steps to this point, performed on Kopia v0.13.0 (I'm doing dev locally, so the server host here is a docker container, but AFAICT this is all equally valid for a hand-rolled server install):\r\n1. On server host, bring up server via `kopia server start ...`\r\n2. On server host, create local repository via `kopia repository create filesystem ...`\r\n3. On server Web UI, connect local repository\r\n4. On server host, create a user via `kopia server users add ...`\r\n5. On client, connect repository via `kopia repository connect ...`\r\n6. Fail\r\n\r\nAt this point I think I've exhausted all the options I can find as a user, without putting my dev hat on and going to try to hack the code. It doesn't help that the `debug` log level rarely seems to output anything more than the `info` level, which outputs the bare minimum - decent logging would probably make diagnosing this stuff vastly easier.", "Also some UX adjustments would be nice. For example `kopia server users add User@Host` will gladly prompt for a password, twice, only to stop you with\r\n\r\n```console\r\n$ kopia server users add User@Host\r\nEnter new password for user User@Host:\r\nRe-enter new password for verification:\r\nERROR error setting user profile: username must be specified as lowercase 'user@hostname'\r\n```\r\n\r\nSame happens with `kopia repository connect server --url=http://somehost:51515`. It validates arguments only after prompting for credentials.\r\n\r\n```console\r\n$ kopia repository connect server --url=http://localhost:51515\r\nConnecting to server 'http://localhost:51515' as 'username@hostname'...\r\nEnter password to open repository:\r\n\r\nERROR failed to open repository: invalid server address, must be 'https://host:port'\r\nERROR error connecting to API server: invalid server address, must be 'https://host:port'\r\n```\r\n---\r\n\r\nAs a side question: is there a reason why Kopia connects to the repository server over HTTPS only? I've seen a generic \"due to gRPC\" answer [here](https://kopia.discourse.group/t/cant-connect-to-insecure-repository-server/871/3), but no further explanation. There was an issue about the same topic, but it went stale: #1215. A quick google search reveals that gRPC can work over plain HTTP. See e.g. grpc/grpc-go#555", "I want to report that I am also experiencing \"permission denied\" errors when connecting to a Kopia server over TLS. Having followed the documentation quite closely.\r\n\r\n```\r\nkopia repo connect server --url=https://192.168.1.106:51515 --server-cert-fingerprint ####\r\n```\r\n```\r\n[info] ERROR failed to open repository: unable to establish session for purpose=: error establishing session: unable to initialize session: rpc error: code = PermissionDenied desc = access denied for ####@#####: EOF\r\n```\r\n\r\nThis error message occurs on the client (Windows 11), but on the server host (macOS) nothing comes up in the stdout.", "Also, can we get _actual_ docker environment variables instead of this command line argument stuff shoehorned into a compose file?\r\n\r\n```\r\nKOPIA_PASSWORD=\"<password-for-the-repository>\" \\\r\nKOPIA_SERVER_CONTROL_PASSWORD=\"<server-control-password>\" \\\r\n  kopia server start \\\r\n    --tls-generate-cert \\\r\n    --tls-cert-file ~/my.cert \\\r\n    --tls-key-file ~/my.key \\\r\n    --address 0.0.0.0:51515 \\\r\n    --server-control-username control\r\n```\r\n\r\nHaving to mix mounted volumes with absolute cert file paths when there are often already mount points for these is quite patchy and there is no reason to do so.\r\n\r\nAdditionally, there should absolutely be documented accepted environment variables by the container like many other docker apps have.\r\n\r\nhttps://github.com/imagegenius/docker-kopia?tab=readme-ov-file#parameters\r\n\r\nhttps://immich.app/docs/install/environment-variables/\r\n\r\nand of course, no mention in the documentation to go the very common path of no-tls on a secure home network. The client works without it, but the server just throws errors that it is expecting TLS.\r\n\r\n`Connect Error: INTERNAL: internal server error: connect error: error opening repository: error connecting to API server: unable to establish session for purpose=: error establishing session: Session(): rpc error: code = Unavailable desc = connection error: desc = \"transport: authentication handshake failed: tls: first record does not look like a TLS handshake\"`", "I was wondering about \"GRPC needs TLS\" too, so I asked my friend ClaudeAI about it:\r\n\r\n> Let me clarify this:\r\n>\r\n>gRPC does not strictly require TLS (Transport Layer Security). You can run gRPC without TLS in what's called \"plaintext\" mode. However, using TLS with gRPC is highly recommended and considered best practice for several reasons:\r\n>\r\n>1. Security: TLS provides encryption and authentication\r\n>2. Modern browser requirements: Web browsers require TLS for HTTP/2, which gRPC uses\r\n>3. Production environments: Most production deployments require TLS for security\r\n>\r\n>You can use gRPC without TLS in:\r\n>- Development environments\r\n>- Testing scenarios\r\n>- **Internal networks where security requirements are different**\r\n>- Situations where performance is critical and the network is already secured\r\n\r\nBesides that there is this fingerprint being used to identify or validate the server, which would need a replacement when running without TLS.", "Official docs on how running a repository server it's like a dog chasing its nail. I know this is an open source free project but how is it possible that there's no one who can explain the correct sequence to have a repository server correctly up and running with some clients putting their snapshots there? I have faced all errors reported above and the best suggestion you have on the forum is to look at some YouTube videos... really? Clear documentation is a must and unfortunately many awesome open source projects have not it.", "Hello +1 here\n\n3h i fight with docs with help on AI to try to do (what i think should be) a simple case : to have root creating backups and one user to consult. with the recommandation to use a local Kopia Server.\n\nInfos are splitted in several parts and pages, melded with others infos.\nAnd for example \"starting a server page\" even don't mention the server start command.\n\nI think too that this kind of basic case should be covered simply in a one page. Like local userland only, local with Server and differents users (like root + users), local with docker, remote (if not simple to add the exception in other cases).\n\nI see the problem to provides one page full example of the most basics cases will lead to duplicate some informations in case to update (and then risk to forget to update one command or option change), but doc should be primary user-oriented, and not everyone able to read all the docs, identify all the subparts to take from all thos pages to make the global picture.\n\nOk, if someone wanna create a strange exceptional scenario, but not for a simple architecture.\n", "I am in the same boat.\nI am trying to set up the official Docker image as a Backup Server.\nI have created a repository on the server filesystem. The only way to connect to it from the CLI however is\n`kopia repository connect filesystem --path=PATH --password=REPOPASSWORD`\n`Connected to repository.`\nAnd yet if i try to run `kopia server user list`\nit errors out \n`ERROR failed to open repository: unable to create format manager: invalid repository password\nERROR open repository: unable to open repository: unable to create format manager: invalid repository password`\n\nThe documentation is a mix of outdated and partially missing information and nothing seems consistent at all.\nHow am i supposed to create users if i can't connect to a repo? \n" ],
      "repository" : {
        "description" : "Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.",
        "homepage" : "https://kopia.io",
        "name" : "kopia",
        "fullName" : "kopia/kopia",
        "htmlUrl" : "https://github.com/kopia/kopia",
        "gitUrl" : "git://github.com/kopia/kopia.git",
        "sshUrl" : "git@github.com:kopia/kopia.git",
        "cloneUrl" : "https://github.com/kopia/kopia.git",
        "owner" : {
          "login" : "kopia",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 506,
        "stargazersCount" : 10306,
        "watchersCount" : 10306,
        "size" : 32636,
        "openIssuesCount" : 621,
        "subscribersCount" : 56,
        "pushedAt" : "2025-07-24T00:11:08Z",
        "languages" : {
          "Dockerfile" : 964,
          "Shell" : 26481,
          "Makefile" : 33648,
          "SCSS" : 62,
          "JavaScript" : 42323,
          "Go" : 4113849,
          "HTML" : 15848
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to improve the documentation on how to set up and use a Kopia server, specifically about setting up the server, TLS setup, user accounts, and troubleshooting common issues.",
      "validationOrRequirement" : "The documentation should provide clear instructions and requirements for setting up and using a Kopia server, including setting up the server, TLS setup, user accounts, and troubleshooting common issues. The author has identified several inconsistencies and errors in the documentation that need to be addressed.",
      "attemptedFixes" : "The author has tried various commands and configurations, including creating a repository, connecting to the server, and creating user accounts, but has encountered errors and inconsistencies. The author has also tried to debug the issues and has provided detailed error messages.",
      "otherNotes" : "The issue is about improving the documentation on how to set up and use a Kopia server, specifically about setting up the server, TLS setup, user accounts, and troubleshooting common issues. The author has provided detailed steps and error messages to help with debugging and testing.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406966
  }, {
    "issueDTO" : {
      "id" : 2974948115,
      "title" : "Add og:image and description for Bluesky",
      "url" : "https://github.com/rubyevents/rubyevents/issues/667",
      "repositoryName" : "rubyevents/rubyevents",
      "description" : "It looks like we don't have OG images and descriptions setup up for all social media platforms or all pages/views. This is on Bluesky for the root path:\n\n![image](https://github.com/user-attachments/assets/6533c58e-25ca-4e57-b2c1-b5406098b6b0)",
      "updatedAt" : 1753378430.000000000,
      "user" : "marcoroth",
      "userHtmlUrl" : "https://github.com/marcoroth",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6411752?v=4",
      "labels" : [ "enhancement", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "I could add the meta tags. Is there a higher resolution logo that I can use as `og:image`?" ],
      "repository" : {
        "description" : "On a mission to index all Ruby events.",
        "homepage" : "https://rubyevents.org",
        "name" : "rubyevents",
        "fullName" : "rubyevents/rubyevents",
        "htmlUrl" : "https://github.com/rubyevents/rubyevents",
        "gitUrl" : "git://github.com/rubyevents/rubyevents.git",
        "sshUrl" : "git@github.com:rubyevents/rubyevents.git",
        "cloneUrl" : "https://github.com/rubyevents/rubyevents.git",
        "owner" : {
          "login" : "rubyevents",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 111,
        "stargazersCount" : 471,
        "watchersCount" : 471,
        "size" : 78641,
        "openIssuesCount" : 79,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T21:55:44Z",
        "languages" : {
          "Dockerfile" : 2919,
          "CSS" : 7253,
          "Shell" : 2751,
          "JavaScript" : 32839,
          "HTML" : 228953,
          "Ruby" : 447975
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add og:image and description for Bluesky",
      "validationOrRequirement" : "add og:image and description for all social media platforms and all pages/views for the root path on Bluesky",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "higher resolution logo required for og:image, meta tags to be added",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406969
  }, {
    "issueDTO" : {
      "id" : 2533045848,
      "title" : "[Bug]: Mac OS VFS: Exclamation mark on sync status but no easy way to tell what's wrong",
      "url" : "https://github.com/nextcloud/desktop/issues/7152",
      "repositoryName" : "nextcloud/desktop",
      "description" : "### ?????? Before submitting, please verify the following: ??????\n\n- [X] This is a **bug**, not a question or a configuration issue.\n- [X] This issue is **not** already reported on Github (I've searched it).\n- [X] Nextcloud Server and Desktop Client are **up to date**. See [Server Maintenance and Release Schedule](https://github.com/nextcloud/server/wiki/Maintenance-and-Release-Schedule) and [Desktop Releases](https://nextcloud.com/install/#install-clients) for supported versions.\n- [X] I agree to follow Nextcloud's [Code of Conduct](https://nextcloud.com/contribute/code-of-conduct/)\n\n### Bug description\n\nOn the 3.14-macOS-vfs clients that we are using, we often see the exclamation mark icon on the status bar. Hovering on it, it says the vfs sync had an issue.\r\nHowever, opening the settings panel and clicking on \"Create debug archive\" freezes the UI and the Nextcloud process becomes unresponsive. This seems to be related (kind of a side effect) to the sync issue itself, because when the sync status is OK, it's possible to generate the debug archive without freezes.\r\n\r\nThe problem is, I have no clue on what the problem is and therefore haven't found a way to prevent/work around it.\r\n...\r\n\n\n### Steps to reproduce\n\n1. Have the client running for at least some hours.\r\n2. The client shows an exclamation mark on the status bar, complaining the last sync had an issue.\r\n3. Open the settings panel and click on \"Create debug archive\"\r\n...\r\n\n\n### Expected behavior\n\nThe debug archive should be created.\r\nObserved behaviour: the panel hangs and the process becomes unresponsive, I have to kill it.\r\nSeems similar to what happened a few versions back, on opening the settings panel, where the process froze and needed to be killed. \r\n...\r\n\n\n### Which files are affected by this bug\n\n-\n\n### Operating system\n\nmacOS\n\n### Which version of the operating system you are running.\n\nSonoma 14.6.1\n\n### Package\n\nOfficial macOS 12+ universal pkg\n\n### Nextcloud Server version\n\n29.0.6\n\n### Nextcloud Desktop Client version\n\n3.14.0-vfs\n\n### Is this bug present after an update or on a fresh install?\n\nUpdated from a minor version (ex. 3.4.2 to 3.4.4)\n\n### Are you using the Nextcloud Server Encryption module?\n\nEncryption is Disabled\n\n### Are you using an external user-backend?\n\n- [ ] Default internal user-backend\n- [ ] LDAP/ Active Directory\n- [ ] SSO - SAML\n- [ ] Other\n\n### Nextcloud Server logs\n\n_No response_\n\n### Additional info\n\n_No response_",
      "updatedAt" : 1753378254.000000000,
      "user" : "marcotrevisan",
      "userHtmlUrl" : "https://github.com/marcotrevisan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5240630?v=4",
      "labels" : [ "os: :apple: macOS", "feature: :minidisc: virtual filesystem", "good first issue", "0. Needs triage" ],
      "state" : "OPEN",
      "comments" : [ "By reopening the client (i.e. quitting and relaunching the app) brings back the sync status to OK. \r\nThe debug archive contains some errors, in the current case: \r\n\r\nVery frequently:\r\n`Nil deleted metadatas received in change read at https://.../remote.php/dav/files/user for user: user https://...`\r\n\r\nMuch less frequently:\r\n`err: Error while sending authentication request to nextcloud: Error while connecting to nextcloud: error sending request for url (https://.../index.php/apps/notify_push/uid`\r\n\r\nand also:\r\n`1 depth read of url https://.../remote.php/dav/files/user did not complete successfully, error: Impossibile trovare un server con il nome host specificato.` (this looks like a DNS lookup failure)\r\n", "Last but not least: if possible, it would be great to add timestamps at the beginning of each line in the debug log file. ", "This issue might be related to #7240 and hopefully closed by it as well.", "@claucambra I need to add more info to this issue about the client behaviour.\nThe 3.14.0 and 3.14.1 versions (mac OS vfs) seem to bring back a performance issue that makes the client almost unusable, at least on our shares, which are fairly large.\nThe FileProviderExt process is often consuming 100% of one core. I don't know if this is a known issue.\nI had to revert to 3.13.4 which doesn't seem suffer from this problem (it does suffer from other issues however, which are solved by 3.14.0).\n\nThe console log shows some error lines and among those, I saw some \"watchdog\" like messages about high CPU consumption by the FileProviderExt process.\nSo I wonder wether the exclamation mark can arise because of a timeout in sync time or a stop because of too high CPU consumption? \n\nThe end result is that FInder is often (not always) very slow in opening folders that were not previously opened, and also in opening files, I guess this happens simply because the FIleProviderExt process is busy.\n\nLet me know if you need console logs, I'll attach them.\nThanks and regards,", "I've opened #7326 for the Finder slowdown problem, adding more info.", "I am on version 3.15.3 with VFS. I also have a permanent exclamation mark in the status bar. It does not go away when restarting Nextcloud.\n\nI note that under the Virtual file sync tab in settings, Local storage use is reported as 0.00 GB, and the Evict materialised files window does not list any files, despite having downloaded and used several files in the Finder extension.\n\nI checked the debug archive and found these errors repeat quite frequently:\n\n```\n2025-03-04 10:43:05:694 [ info nextcloud.gui.mac.fileprovider.settingscontroller /var/folders/yr/9dx0mtfj7kdf4725tmcz6md80000gp/T/macos-27804/src/gui/macOS/fileprovidersettingscontroller_mac.mm:257 ]:\tFetching materialised files storage usage\n2025-03-04 10:43:05:792 [ warning nextcloud.gui.mac.fileprovider.settingscontroller /var/folders/yr/9dx0mtfj7kdf4725tmcz6md80000gp/T/macos-27804/src/gui/macOS/fileprovidersettingscontroller_mac.mm:261 ]:\tCould not get file provider domains: The application cannot be used right now. Will try again in 2 secs\n```\n\nThere don't appear to be any other warnings in the log or any further context to this warning.", "On 3.16.6 and same issue. MacOS 13.7.6\nI logged out, quit and completely removed the folders from my system and restarted and re-set up the syncing. No change.", "> I am on version 3.15.3 with VFS. I also have a permanent exclamation mark in the status bar. It does not go away when restarting Nextcloud.\n> \n> I note that under the Virtual file sync tab in settings, Local storage use is reported as 0.00 GB, and the Evict materialised files window does not list any files, despite having downloaded and used several files in the Finder extension.\n> \n> I checked the debug archive and found these errors repeat quite frequently:\n> \n> ```\n> 2025-03-04 10:43:05:694 [ info nextcloud.gui.mac.fileprovider.settingscontroller /var/folders/yr/9dx0mtfj7kdf4725tmcz6md80000gp/T/macos-27804/src/gui/macOS/fileprovidersettingscontroller_mac.mm:257 ]:\tFetching materialised files storage usage\n> 2025-03-04 10:43:05:792 [ warning nextcloud.gui.mac.fileprovider.settingscontroller /var/folders/yr/9dx0mtfj7kdf4725tmcz6md80000gp/T/macos-27804/src/gui/macOS/fileprovidersettingscontroller_mac.mm:261 ]:\tCould not get file provider domains: The application cannot be used right now. Will try again in 2 secs\n> ```\n> \n> There don't appear to be any other warnings in the log or any further context to this warning.\n\ni have the exact same problem. Although files do appear to transfer main group folders dont ever update and do not display on the mac\n\nmy logs show the same error message and i have several clients on windows working fine " ],
      "repository" : {
        "description" : "\uD83D\uDCBB Desktop sync client for Nextcloud",
        "homepage" : "https://nextcloud.com/install/#install-clients",
        "name" : "desktop",
        "fullName" : "nextcloud/desktop",
        "htmlUrl" : "https://github.com/nextcloud/desktop",
        "gitUrl" : "git://github.com/nextcloud/desktop.git",
        "sshUrl" : "git@github.com:nextcloud/desktop.git",
        "cloneUrl" : "https://github.com/nextcloud/desktop.git",
        "owner" : {
          "login" : "nextcloud",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 840,
        "stargazersCount" : 3320,
        "watchersCount" : 3320,
        "size" : 561622,
        "openIssuesCount" : 915,
        "subscribersCount" : 108,
        "pushedAt" : "2025-07-24T17:09:22Z",
        "languages" : {
          "C++" : 5528614,
          "C" : 48516,
          "CMake" : 273744,
          "Objective-C++" : 142000,
          "QMake" : 545,
          "NSIS" : 131944,
          "QML" : 253104,
          "Shell" : 19975,
          "JavaScript" : 1949,
          "Objective-C" : 39426,
          "Swift" : 156929,
          "Nix" : 4501,
          "Ruby" : 7726,
          "Python" : 30698
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The debug archive contains some errors, in the current case: Very frequently: Nil deleted metadatas received in change read at https://.../remote.php/dav/files/user for user: user https://... Much less frequently: err: Error while sending authentication request to nextcloud: Error while connecting to nextcloud: error sending request for url (https://.../index.php/apps/notify_push/uid and also: 1 depth read of url https://.../remote.php/dav/files/user did not complete successfully, error: Impossibile trovare un server con il nome host specificato. (this looks like a DNS lookup failure) The problem is, I have no clue on what the problem is and therefore haven't found a way to prevent/work around it.",
      "validationOrRequirement" : "The issue is not already reported on Github, the Nextcloud Server and Desktop Client are up to date, and the issue is not a question or a configuration issue.",
      "attemptedFixes" : "The debug archive contains some errors, in the current case: Very frequently: Nil deleted metadatas received in change read at https://.../remote.php/dav/files/user for user: user https://... Much less frequently: err: Error while sending authentication request to nextcloud: Error while connecting to nextcloud: error sending request for url (https://.../index.php/apps/notify_push/uid and also: 1 depth read of url https://.../remote.php/dav/files/user did not complete successfully, error: Impossibile trovare un server con il nome host specificato. (this looks like a DNS lookup failure) Reverting to 3.13.4, restarting the client, adding timestamps at the beginning of each line in the debug log file, and attaching console logs.",
      "otherNotes" : "The debug archive contains some errors, in the current case: Very frequently: Nil deleted metadatas received in change read at https://.../remote.php/dav/files/user for user: user https://... Much less frequently: err: Error while sending authentication request to nextcloud: Error while connecting to nextcloud: error sending request for url (https://.../index.php/apps/notify_push/uid and also: 1 depth read of url https://.../remote.php/dav/files/user did not complete successfully, error: Impossibile trovare un server con il nome host specificato. (this looks like a DNS lookup failure) The 3.14.0 and 3.14.1 versions (mac OS vfs) seem to bring back a performance issue that makes the client almost unusable, at least on our shares, which are fairly large. The FileProviderExt process is often consuming 100% of one core. I don't know if this is a known issue. I had to revert to 3.13.4 which doesn't seem suffer from this problem (it does suffer from other issues however, which are solved by 3.14.0). The console log shows some error lines and among those, I saw some \"watchdog\" like messages about high CPU consumption by the FileProviderExt process. So I wonder wether the exclamation mark can arise because of a timeout in sync time or a stop because of too high CPU consumption? The end result is that FInder is often (not always) very slow in opening folders that were not previously opened, and also in opening files, I guess this happens simply because the FIleProviderExt process is busy.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406991
  }, {
    "issueDTO" : {
      "id" : 3215414346,
      "title" : "dns-update (rfc2136) over TCP (rfc1035)",
      "url" : "https://github.com/cert-manager/cert-manager/issues/7849",
      "repositoryName" : "cert-manager/cert-manager",
      "description" : "**Is your feature request related to a problem? Please describe.**\n<!--A clear and concise description of what the problem is-->\nI need to contact a remote dns server to perform dns updates (rfc2136) over TCP (rfc1035) instead of UDP.\n\nSee https://datatracker.ietf.org/doc/html/rfc2136\n>    2.1 - Transport Issues\n> \n>    An update transaction may be carried in a UDP datagram, if the\n>    request fits, or in a TCP connection (at the discretion of the\n>    requestor).  When TCP is used, the message is in the format described\n>    in [RFC1035 4.2.2].\n\nThis is supported by the nsupdate cli\n\nhttps://linux.die.net/man/8/nsupdate\n> By default nsupdate uses UDP to send update requests to the name server. The -v option makes nsupdate use a TCP connection. This may be preferable when a batch of update requests is made. \n\n**Describe the solution you'd like**\n\nA new `protocol` key in the rfc2136 section of issuer CRD that triggers use of the dns client support for tcp\n\nhttps://github.com/miekg/dns/blob/96a6b9c19dd7b14558793fa557a62cfd3da5282d/client.go#L49-L72\n\n> ```go\n> // A Client defines parameters for a DNS client.\n> type Client struct {\n> \tNet       string      // if \"tcp\" or \"tcp-tls\" (DNS over TLS) a TCP query will be initiated, otherwise an UDP one (default is \"\" for UDP)\n> //...\n> \tTsigSecret   map[string]string // secret(s) for Tsig map[<zonename>]<base64 secret>, zonename must be in canonical form (lowercase, fqdn, see RFC 4034 Section 6.2)\n> \tTsigProvider TsigProvider      // An implementation of the TsigProvider interface. If defined it replaces TsigSecret and is used for all TSIG operations.\n> \n> }\n> ```\n\n\n```yaml\napiVersion: cert-manager.io/v1\nkind: Issuer\nmetadata:\n  name: example-issuer\nspec:\n  acme:\n    ...\n    solvers:\n    - dns01:\n        rfc2136:\n          nameserver: <address of authoritative nameserver configured above>\n          protocol: tcp # one of \"udp\", \"tcp\". Defaults to udp when unset\n          tsigKeyName: <key name used in `dnssec-keygen`, use something semantically meaningful in both environments>\n          tsigAlgorithm: HMACSHA512 // should be matched to the algo you chose in `dnssec-keygen`\n          tsigSecretSecretRef:\n            name: <the name of the k8s secret holding the TSIG key.. not the key itself!>\n            key: <name of the key *inside* the secret>\n```\n\n**Describe alternatives you've considered**\n<!--A clear and concise description of any alternative solutions or features you've considered.-->\n\n**Additional context**\n<!--Add any other context about the feature request here.-->\n\nCurrently, I understand that cert manager does not allow setting the dns `Client.Net = \"tcp\"` in https://github.com/cert-manager/cert-manager/blob/83911aa1d31dc75b112bc722b6b64a951592b6f0/pkg/issuer/acme/dns/rfc2136/rfc2136.go#L129-L139\n\n\n**Environment details (remove if not applicable)**:\n- Kubernetes version:  1.30 (k3s)\n- Cloud-provider/provisioner: rfc2136\n- cert-manager version: 1.16.3\n- Install method: e.g., helm/static manifests\n\n\n/kind feature\n",
      "updatedAt" : 1753377638.000000000,
      "user" : "gberche-orange",
      "userHtmlUrl" : "https://github.com/gberche-orange",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4748380?v=4",
      "labels" : [ "area/acme/dns01", "kind/feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@gberche-orange I am interested to work on this and was looking at the dns code.. we probably could use the `ExchangeWithConn` func to create our connection if its tcp. How do you think we can test this? ", "Thanks @hjoshi123 for your interest in this feature !\n\n> How do you think we can test this?\n\nI'm not yet familar with the current automated tests in cert manager, but I guess this could be tested automatically with starting a go-lang udp dns server. \n\nBesides, I'm happy to test a cert-manager tarball OCI image in our environment if this can help.", "/assign" ],
      "repository" : {
        "description" : "Automatically provision and manage TLS certificates in Kubernetes",
        "homepage" : "https://cert-manager.io",
        "name" : "cert-manager",
        "fullName" : "cert-manager/cert-manager",
        "htmlUrl" : "https://github.com/cert-manager/cert-manager",
        "gitUrl" : "git://github.com/cert-manager/cert-manager.git",
        "sshUrl" : "git@github.com:cert-manager/cert-manager.git",
        "cloneUrl" : "https://github.com/cert-manager/cert-manager.git",
        "owner" : {
          "login" : "cert-manager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2226,
        "stargazersCount" : 12996,
        "watchersCount" : 12996,
        "size" : 93584,
        "openIssuesCount" : 204,
        "subscribersCount" : 151,
        "pushedAt" : "2025-07-24T13:36:46Z",
        "languages" : {
          "Dockerfile" : 5532,
          "Shell" : 67087,
          "Makefile" : 170401,
          "Go" : 5082272,
          "Mustache" : 9186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement support for DNS updates over TCP (rfc2136) instead of UDP in cert-manager.",
      "validationOrRequirement" : "The feature requires a new `protocol` key in the rfc2136 section of issuer CRD that triggers use of the dns client support for tcp, and possibly testing with a go-lang udp dns server or cert-manager tarball OCI image.",
      "attemptedFixes" : "The author suggests using the `ExchangeWithConn` func to create a connection if it's tcp, and testing this feature with a go-lang udp dns server or by testing a cert-manager tarball OCI image in the environment.",
      "otherNotes" : "The issue is related to performing DNS updates over TCP (rfc2136) instead of UDP, which is supported by the nsupdate cli. The solution proposed is a new `protocol` key in the rfc2136 section of issuer CRD that triggers use of the dns client support for tcp.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753406998
  }, {
    "issueDTO" : {
      "id" : 3260628068,
      "title" : "Bump the sigs.k8s.io/gateway-api-inference-extension dep to v0.5.0",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11765",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "Bump the https://github.com/kgateway-dev/kgateway/blob/main/go.mod#L50C2-L50C45 direct dependency to use the v0.5.0 tag instead of a pre-release tag.",
      "updatedAt" : 1753377460.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @danehans ", "Additionally, update the epp.yaml that references the us-central1-docker.pkg.dev/k8s-staging-images/gateway-api-inference-extension/epp:v0.5.0-rc.2 image and replace with the v0.5.0 tag." ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 543,
        "stargazersCount" : 4653,
        "watchersCount" : 4653,
        "size" : 211827,
        "openIssuesCount" : 562,
        "subscribersCount" : 100,
        "pushedAt" : "2025-07-24T19:33:09Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16895,
          "Rust" : 20712,
          "Makefile" : 32755,
          "JavaScript" : 435,
          "Go" : 4121797,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Bump the sigs.k8s.io/gateway-api-inference-extension dep to v0.5.0",
      "validationOrRequirement" : "Bump the https://github.com/kgateway-dev/kgateway/blob/main/go.mod#L50C2-L50C45 direct dependency to use the v0.5.0 tag instead of a pre-release tag.",
      "attemptedFixes" : "",
      "otherNotes" : "cc @danehans, Additionally, update the epp.yaml that references the us-central1-docker.pkg.dev/k8s-staging-images/gateway-api-inference-extension/epp:v0.5.0-rc.2 image and replace with the v0.5.0 tag.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407003
  }, {
    "issueDTO" : {
      "id" : 3259911648,
      "title" : "Add Color Effects to Dark Mode Toggle Button",
      "url" : "https://github.com/techxninjas/techxninjas-client/issues/65",
      "repositoryName" : "techxninjas/techxninjas-client",
      "description" : "The current dark mode toggle button works functionally but lacks engaging visual feedback. Enhancing it with subtle color transitions, hover effects, or glow animations will make the interaction more intuitive and visually appealing.",
      "updatedAt" : 1753377360.000000000,
      "user" : "Verma-MK",
      "userHtmlUrl" : "https://github.com/Verma-MK",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/150913782?v=4",
      "labels" : [ "Level 1", "gssoc25", "good first issue", "Feature Request" ],
      "state" : "OPEN",
      "comments" : [ "Assign this to me.", "I noticed the recent issue about enhancing the dark mode toggle button???s visual feedback. I???d be glad to contribute by adding smooth color transitions, hover effects, and subtle animations to improve the user experience.\nCould you please assign this issue to me? I look forward to enhancing the UI and making the toggle more engaging.", "@Verma-MK \n@Adbhutha10 \n\nGuys please share in details! Please go with the formal issue creation format, so we can understand, what do you want to contribute?" ],
      "repository" : {
        "description" : "Official Repo of TechXNinjas ??? A student-first community platform built with React.js (Typescript), Next.js, Tailwind CSS, and Express.js. Contribute, collaborate, and grow with real-world open source experience.",
        "homepage" : "https://techxninjas-client.vercel.app",
        "name" : "techxninjas-client",
        "fullName" : "techxninjas/techxninjas-client",
        "htmlUrl" : "https://github.com/techxninjas/techxninjas-client",
        "gitUrl" : "git://github.com/techxninjas/techxninjas-client.git",
        "sshUrl" : "git@github.com:techxninjas/techxninjas-client.git",
        "cloneUrl" : "https://github.com/techxninjas/techxninjas-client.git",
        "owner" : {
          "login" : "techxninjas",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 33,
        "stargazersCount" : 16,
        "watchersCount" : 16,
        "size" : 1777,
        "openIssuesCount" : 36,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-24T19:07:08Z",
        "languages" : {
          "TypeScript" : 648806,
          "CSS" : 7696,
          "JavaScript" : 1386,
          "HTML" : 3709
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Enhance the dark mode toggle button's visual feedback with color transitions, hover effects, and animations to make the interaction more intuitive and visually appealing",
      "validationOrRequirement" : "Formal issue creation format is required to understand the contribution details",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments",
      "otherNotes" : "The issue is about enhancing the dark mode toggle button's visual feedback with smooth color transitions, hover effects, and subtle animations to improve the user experience. Assignee requested to be assigned to this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407006
  }, {
    "issueDTO" : {
      "id" : 3260625825,
      "title" : "Push Notifications: Append `-test` suffix to channels when setting `TEST` is true",
      "url" : "https://github.com/digitalfabrik/integreat-cms/issues/3808",
      "repositoryName" : "digitalfabrik/integreat-cms",
      "description" : "### Motivation\n<!-- A clear and concise description of what the motivation for the new feature is, and what problem it is solving. -->\nOur test instance of Integreat CMS is intentionally held very similar to the production environment. There are only some configuration differences, but e.g. the `DEBUG` setting is still `False`, while the database is periodically cloned over to be able to reproduce bugs that appear under very specific circumstances. This practice has made it hard to ensure push notifications sent from within the test system don't land on real end users devices. Our existing attempts are contradictory and insufficient.\n\n### Proposed Solution\n<!-- A clear and concise description of the feature you would like to add, and how it solves the motivating problem. -->\nWe use the `TEST` setting to display a banner that makes users aware that they are on a test instance and avoid confusion with the real system. When it is set, also\n- Append the `-test` suffix to FCM channels whenever a push notification is being sent out\n\n\n### Alternatives\n<!-- A clear and concise description of any alternative solutions or features you've considered, and why you're proposed solution is better. -->\n\n- Use **different credentials** / a different project for Firebase Cloud Messaging\n  This was our original proposal that would require minimal effort on our side, but is infeasible for the app to implement. Which push notification application key an app belongs to cannot be set at runtime but has to be baked in as part of the build process. A separate FCM project for tests would require a separate app for testing, which requires a whole lot of effort, makes the testing considerably less trustworthy and also cumbersome.\n- Continue with the **current approach** of using the same credentials for both systems and rely on push notifications to only be triggered for the region *Testumgebung*\n  This means that we will continue to be susceptible to miscommunication and confusion. The test system advertises it is a test system through the banner, but the FCM server does not care which systems sent push notifications originate from ??? they are delivered to any device subscribed to the channel.\n\n### User Story\n<!-- A clear description of the User Stories that should be achieved by the new feature. The User Stories should follow this pattern: -->\nAs a *tester, dev or other team member* I want *be able to click around on the test instance without having to worry about accidentally directly affecting real end users* so that *I do not cause incidents and the trust in Integreat CMS to drop*.\n\n\n### Additional Context\n<!-- Add any other information about the feature request here. -->\n\n\n### Design Requirements\n<!-- If the customization includes input from our design team, the detailed requirements will be collected here. Note: These will exist mainly in German to simplify internal communication. -->\n\n### Related Issues\n<!-- A collection of all issues that are related to this issue and could be useful. -->\n<!-- Please also include the related integreat-app issues, if possible. -->\n<!-- If the app issue does not exist yet, ping Toni on Mattermost to create one and then link it here. -->\n- #1043 \n- https://github.com/digitalfabrik/integreat-app/issues/3301\n\n### Summary of discussion and updates to the description\n<!-- Summarize the discussion if a long conversation was made that changed something. E.g. -->\n<!-- - <TIMESTAMP>: Discussed UX of the modal and decided that a two-stage flow would be best after all. Updated the link to this alternative design and changed the spec for the new ajax endpoint accordingly -->\n<!-- Leave this section blank during the initial issue creation. -->\n",
      "updatedAt" : 1753377348.000000000,
      "user" : "PeterNerlich",
      "userHtmlUrl" : "https://github.com/PeterNerlich",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10530729?v=4",
      "labels" : [ "blocks-app", "feature", "ready", "effort: low", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Simplified content management back end for the Integreat App - a multilingual information platform for newcomers",
        "homepage" : "https://digitalfabrik.github.io/integreat-cms/",
        "name" : "integreat-cms",
        "fullName" : "digitalfabrik/integreat-cms",
        "htmlUrl" : "https://github.com/digitalfabrik/integreat-cms",
        "gitUrl" : "git://github.com/digitalfabrik/integreat-cms.git",
        "sshUrl" : "git@github.com:digitalfabrik/integreat-cms.git",
        "cloneUrl" : "https://github.com/digitalfabrik/integreat-cms.git",
        "owner" : {
          "login" : "digitalfabrik",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 42,
        "stargazersCount" : 60,
        "watchersCount" : 60,
        "size" : 497295,
        "openIssuesCount" : 361,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-24T14:38:35Z",
        "languages" : {
          "TypeScript" : 382402,
          "Dockerfile" : 427,
          "Shell" : 71249,
          "CSS" : 22235,
          "SCSS" : 17784,
          "JavaScript" : 51713,
          "HTML" : 787482,
          "Nix" : 4570,
          "Python" : 3038568
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to ensure push notifications sent from the test instance of Integreat CMS do not land on real end users' devices, and to avoid confusion with the real system.",
      "validationOrRequirement" : "The TEST setting must be true to append the '-test' suffix to FCM channels.",
      "attemptedFixes" : "The alternatives considered were using different credentials / a different project for Firebase Cloud Messaging, which is infeasible, and continuing with the current approach, which would still lead to miscommunication and confusion.",
      "otherNotes" : "The issue is about appending a '-test' suffix to FCM channels when the TEST setting is true, to avoid confusion with real end users. The current approach of using the same credentials for both systems and relying on push notifications to only be triggered for the test region is not sufficient.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407012
  }, {
    "issueDTO" : {
      "id" : 3232172963,
      "title" : "Add optional input description",
      "url" : "https://github.com/langgenius/dify/issues/22441",
      "repositoryName" : "langgenius/dify",
      "description" : "### Self Checks\n\n- [x] I have searched for existing issues [search for existing issues](https://github.com/langgenius/dify/issues), including closed ones.\n- [x] I confirm that I am using English to submit this report (????????????????????? [Language Policy](https://github.com/langgenius/dify/issues/1542)).\n- [x] [FOR CHINESE USERS] ??????????????????????????? Issue?????????????????????????????????:)\n- [x] Please do not modify this template :) and fill in all the required fields.\n\n### 1. Is this request related to a challenge you're experiencing? Tell me about your story.\n\nSince workflows can be transformed into tools and MCP servers.\nConsidering that in both cases, a description of the input parameter is useful.\nConsidering that the Frontend app could benefit from this enhancement too...\n\n\nwhat about adding a description field to inputs ? it could be used to automatically populate descriptions in MCP, tools, UI\n\n### 2. Additional context or comments\n\n_No response_\n\n### 3. Can you help us with this feature?\n\n- [ ] I am interested in contributing to this feature.",
      "updatedAt" : 1753377307.000000000,
      "user" : "DavideDelbianco",
      "userHtmlUrl" : "https://github.com/DavideDelbianco",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/37332069?v=4",
      "labels" : [ "\uD83D\uDCAA enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "What I meant was to have a description in the inputs Start Node:\n\n<img width=\"467\" height=\"584\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/858c3e68-b75d-45ca-b8a3-3d5476468241\" />\n\nto reuse that description for workflow as tool:\n\n<img width=\"630\" height=\"536\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7348351e-e49d-490b-802f-45bed23fe9e1\" />\n\nand MCP server config:\n\n<img width=\"504\" height=\"404\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4259004d-d18e-4497-866e-43fab701e889\" />\n\ndidn't consider the description in the agent -> tool section that could use that description too", "pls review @DavideDelbianco  @crazywoola \nhttps://github.com/langgenius/dify/pull/22658", "pls check once @crazywoola ", "@DavideDelbianco  let me know if something else is required here" ],
      "repository" : {
        "description" : "Production-ready platform for agentic workflow development.",
        "homepage" : "https://dify.ai",
        "name" : "dify",
        "fullName" : "langgenius/dify",
        "htmlUrl" : "https://github.com/langgenius/dify",
        "gitUrl" : "git://github.com/langgenius/dify.git",
        "sshUrl" : "git@github.com:langgenius/dify.git",
        "cloneUrl" : "https://github.com/langgenius/dify.git",
        "owner" : {
          "login" : "langgenius",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16463,
        "stargazersCount" : 108287,
        "watchersCount" : 108287,
        "size" : 106201,
        "openIssuesCount" : 788,
        "subscribersCount" : 660,
        "pushedAt" : "2025-07-25T00:55:09Z",
        "languages" : {
          "TypeScript" : 11963370,
          "MDX" : 889613,
          "Dockerfile" : 4231,
          "CSS" : 176931,
          "Shell" : 19844,
          "SCSS" : 21945,
          "Makefile" : 1304,
          "JavaScript" : 1430866,
          "PHP" : 6106,
          "HTML" : 102368,
          "Mako" : 518,
          "Python" : 7312026
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add an optional input description to reuse it for workflow, tool, and MCP server config.",
      "validationOrRequirement" : "Description of the input parameter is useful for workflows, tools, and UI; description should be reusable for workflow, tool, and MCP server config.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned.",
      "otherNotes" : "No response in comments section.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407015
  }, {
    "issueDTO" : {
      "id" : 3194838233,
      "title" : "Failed to call btrfs",
      "url" : "https://github.com/facebookincubator/below/issues/8252",
      "repositoryName" : "facebookincubator/below",
      "description" : "below logs a lot of \"Failed call to btrfs\". Also the btrfs tab in the system view is empty.\n\nRunning strace on it, I see it `statfs`s all btrfs files systems, but then `ioctl(BTRFS_IOC_TREE_SEARCH_V2)`s the `/` directory which in this case is not an btrfs but an an ext4. See the trace below.\n\nThis may be related to setting \n\nhttps://github.com/facebookincubator/below/blob/d38faa150d6dd5d744423afdf2a905b958cc0a15/below/btrfs/src/lib.rs#L61\n\nbut I have no idea what this does. And as far as I see, this is also not configurable for users.\n\n  Thank you very much for your help\n\n--\n\n`strace below -d record`\n\n```\n[...]\nstatfs(\"/some/btrfs/path\", {f_type=BTRFS_SUPER_MAGIC, f_bsize=4096, f_blocks=50778611712, f_bfree=38901619985, f_bavail=38899946353, f_files=0, f_ffree=0, f_fsid={val=[0x8d567fd0, 0xeb4cf9e8]}, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOATIME}) = 0\nstatfs(\"/some/other/btrfs/path\", {f_type=BTRFS_SUPER_MAGIC, f_bsize=4096, f_blocks=57125990400, f_bfree=39094000758, f_bavail=39062837470, f_files=0, f_ffree=0, f_fsid={val=[0xe3ab0791, 0xdeb1605f]}, f_namelen=255, f_frsize=4096, f_flags=ST_VALID|ST_NOATIME}) = 0\nbrk(0x55701a85d000)                     = 0x55701a85d000\nopenat(AT_FDCWD, \"/\", O_RDONLY|O_CLOEXEC) = 9\nioctl(9, BTRFS_IOC_TREE_SEARCH_V2, {key={tree_id=BTRFS_CHUNK_TREE_OBJECTID, min_objectid=0, max_objectid=UINT64_MAX, min_offset=0, max_offset=UINT64_MAX, min_transid=0, max_transid=UINT64_MAX, min_type=0, max_type=255, nr_items=4294967295}, buf_size=16384}) = -1 ENOTTY (Inappropriate ioctl for device)\nclose(9)                                = 0\nwrite(2, \"Jul 02 06:52:09.241\", 19Jul 02 06:52:09.241)     = 19\nwrite(2, \" \", 1 )                        = 1\nwrite(2, \"ERRO\", 4ERRO)                     = 4\nwrite(2, \" \", 1 )                        = 1\nwrite(2, \"Failed call to btrfs\", 20Failed call to btrfs)    = 20\nwrite(2, \"\\n\", 1\n)                       = 1\n[...]\n```",
      "updatedAt" : 1753377247.000000000,
      "user" : "frukto",
      "userHtmlUrl" : "https://github.com/frukto",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6838890?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi, sorry for the slow response. Can you share with me your `/etc/below/below.conf`? I just want to confirm that you've explicitly set `enable_btrfs_stats = true` as I don't believe it should be the default.\n\nYou're right that the collector right now assumes the btrfs fs to monitor is the `/` and is not configurable. Are you looking to monitor the filesystem space of a non-root fs?", "Here is my `below.conf `:\n\n```\n# cat /etc/below/below.conf \nenable_btrfs_stats = true\nbtrfs_samples = 1\n```\n\nYes i want to monitor several btrfs, but in my case `/` is ext4.", "Understood - right now there's no option to do this. I'll list this issue as an enhancement request - it's relatively simple to make the btrfs paths configurable." ],
      "repository" : {
        "description" : "A time traveling resource monitor for modern Linux systems",
        "homepage" : "",
        "name" : "below",
        "fullName" : "facebookincubator/below",
        "htmlUrl" : "https://github.com/facebookincubator/below",
        "gitUrl" : "git://github.com/facebookincubator/below.git",
        "sshUrl" : "git@github.com:facebookincubator/below.git",
        "cloneUrl" : "https://github.com/facebookincubator/below.git",
        "owner" : {
          "login" : "facebookincubator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 74,
        "stargazersCount" : 1399,
        "watchersCount" : 1399,
        "size" : 5020,
        "openIssuesCount" : 22,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-24T22:07:21Z",
        "languages" : {
          "Dockerfile" : 2676,
          "Shell" : 1061,
          "Rust" : 1881284,
          "C" : 5773,
          "Roff" : 106836,
          "Python" : 6822
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Failed to call btrfs, btrfs tab in system view is empty",
      "validationOrRequirement" : "enable_btrfs_stats = true should be set explicitly in /etc/below/below.conf",
      "attemptedFixes" : "the author is looking to monitor several btrfs but in their case / is ext4, no option to make btrfs paths configurable",
      "otherNotes" : "the issue is related to setting https://github.com/facebookincubator/below/blob/d38faa150d6dd5d744423afdf2a905b958cc0a15/below/btrfs/src/lib.rs#L61 but it's not configurable for users",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407019
  }, {
    "issueDTO" : {
      "id" : 3260595210,
      "title" : "Test additional types in property tests",
      "url" : "https://github.com/paradedb/paradedb/issues/2903",
      "repositoryName" : "paradedb/paradedb",
      "description" : "### What feature are you requesting?\n\nCurrently the property tests only cover string columns: we should expand their generated dataset to cover other types, and then include those types in generated `WHERE`, `GROUP BY`, and `ORDER BY` statements.\n\n### Why are you requesting this feature?\n\nTo increase test coverage, particularly for `GROUP BY`, post #2893.\n\n### What is your proposed implementation for this feature?\n\n1. Add a column type enum/struct to use as input to [the generated dataset](https://github.com/paradedb/paradedb/blob/485cc173af493200c98474f48841973dd3b4d24b/tests/tests/qgen.rs#L33), and to the `arb_*` generators which take column arguments.\n    * Bonus: add a boolean to the enum/struct to indicate whether it should be indexed, and add some unindexed columns. Enable `paradedb.enable_filter_pushdown` to ensure that the scan is actually used.\n2. Adjust the generated `WHERE` clauses to use appropriate operators for those types, including range queries. See https://docs.paradedb.com/documentation/full-text/filtering\n    * Currently we always use `@@@`, and that is relied upon in some cases to trigger the scan. We should probably remove that reliance by forcing the custom scan to be used via `paradedb.enable_custom_scan_without_operator`.\n\n### Full Name:\n\nStu Hood\n\n### Affiliation:\n\nParadeDB",
      "updatedAt" : 1753377206.000000000,
      "user" : "stuhood",
      "userHtmlUrl" : "https://github.com/stuhood",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/46740?v=4",
      "labels" : [ "feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "ParadeDB is a modern Elasticsearch alternative built on Postgres. Built for real-time, update-heavy workloads.",
        "homepage" : "https://paradedb.com",
        "name" : "paradedb",
        "fullName" : "paradedb/paradedb",
        "htmlUrl" : "https://github.com/paradedb/paradedb",
        "gitUrl" : "git://github.com/paradedb/paradedb.git",
        "sshUrl" : "git@github.com:paradedb/paradedb.git",
        "cloneUrl" : "https://github.com/paradedb/paradedb.git",
        "owner" : {
          "login" : "paradedb",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 258,
        "stargazersCount" : 7504,
        "watchersCount" : 7504,
        "size" : 17040,
        "openIssuesCount" : 76,
        "subscribersCount" : 42,
        "pushedAt" : "2025-07-24T23:45:11Z",
        "languages" : {
          "Dockerfile" : 10633,
          "Shell" : 6263,
          "Rust" : 2146016,
          "PLpgSQL" : 141557,
          "Makefile" : 1933
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "expand property tests to cover other types, include those types in generated WHERE, GROUP BY, and ORDER BY statements",
      "validationOrRequirement" : "add a boolean to the enum/struct to indicate whether it should be indexed, add some unindexed columns, enable paradedb.enable_filter_pushdown to ensure that the scan is actually used",
      "attemptedFixes" : "add a column type enum/struct to use as input to generated dataset, adjust generated WHERE clauses to use appropriate operators for those types, including range queries",
      "otherNotes" : "increase test coverage, particularly for GROUP BY, post #2893, add a column type enum/struct, adjust generated WHERE clauses to use appropriate operators for those types, including range queries, enable paradedb.enable_filter_pushdown, paradedb.enable_custom_scan_without_operator",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407025
  }, {
    "issueDTO" : {
      "id" : 3158233635,
      "title" : "Incorrect nullability on IApiRequestFormatMetadataProvider.GetSupportedContentTypes",
      "url" : "https://github.com/dotnet/aspnetcore/issues/62405",
      "repositoryName" : "dotnet/aspnetcore",
      "description" : "### Is there an existing issue for this?\n\n- [x] I have searched the existing issues\n\n### Describe the bug\n\nThe `contentType` parameter in `Microsoft.AspNetCore.Mvc.ApiExplorer.IApiRequestFormatMetadataProvider.GetSupportedContentTypes` is annotated as non-nullable. However, `null` is explicitly being passed from `DefaultApiDescriptionProvider.GetSupportedFormats` [here](https://github.com/dotnet/aspnetcore/blob/ef0da55f8881c41d9828c857a592551d58cbf785/src/Mvc/Mvc.ApiExplorer/src/DefaultApiDescriptionProvider.cs#L435).\n\nThis causes crashes in our custom implementation of `IApiRequestFormatMetadataProvider.GetSupportedContentTypes`, which doesn't expect a `null` content type.\n\nPlease correct the nullability of this parameter, and potentially related places where applicable.\n\n### Expected Behavior\n\nThe `contentType` parameter to be annotated as nullable.\n\n### Steps To Reproduce\n\nRegister a custom implementation of `IInputFormatter` with the following implementation:\n```c#\ninternal sealed class ExampleApiRequestFormatMetadataProvider : IInputFormatter, IApiRequestFormatMetadataProvider\n{\n    public bool CanRead(InputFormatterContext context)\n    {\n        return false;\n    }\n\n    public Task<InputFormatterResult> ReadAsync(InputFormatterContext context)\n    {\n        throw new UnreachableException();\n    }\n\n    public IReadOnlyList<string> GetSupportedContentTypes(string contentType, Type objectType)\n    {\n        ArgumentNullException.ThrowIfNull(contentType); // <--- crash here\n        ArgumentNullException.ThrowIfNull(objectType);\n\n        return [];\n    }\n}\n```\n\nLoad the OpenAPI document using Swashbuckle, for the following API controller:\n```c#\n[Route(\"[controller]\")]\npublic sealed class ExampleController : ControllerBase\n{\n    [HttpPut]\n    public IActionResult Put([FromBody] string name)\n    {\n        string result = $\"Hi, {name}\";\n        return Ok(result);\n    }\n}\n```\n\n### Exceptions (if any)\n\n_No response_\n\n### .NET Version\n\n.NET 8 and 9 on Windows / Visual Studio\n\n### Anything else?\n\n![Image](https://github.com/user-attachments/assets/4d4572e4-f544-42c3-80eb-408bf83e8482)\n\n![Image](https://github.com/user-attachments/assets/cbb5ac02-f107-44cc-9c9a-1ecb8ecadf09)",
      "updatedAt" : 1753377106.000000000,
      "user" : "bkoelman",
      "userHtmlUrl" : "https://github.com/bkoelman",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10324372?v=4",
      "labels" : [ "area-mvc", "help wanted", "feature-openapi", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Jumping to the interface definition, it's actually documented as such:\n\n```c#\n/// <param name=\"contentType\">\n/// The content type for which the supported content types are desired, or <c>null</c> if any content\n/// type can be used.\n```", "Method `IApiResponseTypeMetadataProvider.GetSupportedContentTypes` has the same problem. Its `contentType` parameter should also be nullable.", "@bkoelman Happy to review a PR to update the nullability annotations and react to them here.", "Thanks. I'll try to find some time, though I wouldn't mind if someone else picked this up. Perhaps label with \"help wanted\" and \"good first issue\"?", "Looks like this issue has been identified as a candidate for community contribution. If you're considering sending a PR for this issue, look for the `Summary Comment` link in the issue description. That comment has been left by an engineer on our team to help you get started with handling this issue. You can learn more about our Help Wanted process [here](https://aka.ms/aspnet/processes/help-wanted)\n<!-- Policy app identification https://img.shields.io/static/v1?label=PullRequestIssueManagement. -->" ],
      "repository" : {
        "description" : "ASP.NET Core is a cross-platform .NET framework for building modern cloud-based web applications on Windows, Mac, or Linux.",
        "homepage" : "https://asp.net",
        "name" : "aspnetcore",
        "fullName" : "dotnet/aspnetcore",
        "htmlUrl" : "https://github.com/dotnet/aspnetcore",
        "gitUrl" : "git://github.com/dotnet/aspnetcore.git",
        "sshUrl" : "git@github.com:dotnet/aspnetcore.git",
        "cloneUrl" : "https://github.com/dotnet/aspnetcore.git",
        "owner" : {
          "login" : "dotnet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 10410,
        "stargazersCount" : 36899,
        "watchersCount" : 36899,
        "size" : 366275,
        "openIssuesCount" : 3789,
        "subscribersCount" : 1434,
        "pushedAt" : "2025-07-25T00:15:26Z",
        "languages" : {
          "C#" : 60644415,
          "PowerShell" : 317972,
          "Java" : 568974,
          "C++" : 1244944,
          "CSS" : 104309,
          "C" : 124045,
          "CMake" : 14853,
          "HTML" : 1673332,
          "TypeScript" : 1178863,
          "Dockerfile" : 423,
          "Shell" : 181419,
          "Batchfile" : 26222,
          "SCSS" : 12,
          "JavaScript" : 175738,
          "Lua" : 4904,
          "ASP.NET" : 109,
          "F#" : 6234,
          "Less" : 12,
          "Python" : 13176
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Correct the nullability of the contentType parameter in IApiRequestFormatMetadataProvider.GetSupportedContentTypes, and potentially related places where applicable.",
      "validationOrRequirement" : "The contentType parameter should be annotated as nullable.",
      "attemptedFixes" : "None mentioned in the issue description",
      "otherNotes" : "The issue is related to nullability of the contentType parameter in IApiRequestFormatMetadataProvider.GetSupportedContentTypes, and potentially related places where applicable. The parameter is currently annotated as non-nullable, but null is being passed from DefaultApiDescriptionProvider.GetSupportedFormats.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407029
  }, {
    "issueDTO" : {
      "id" : 2432470504,
      "title" : "Add CodeQL query to check for memset calls",
      "url" : "https://github.com/open-quantum-safe/liboqs/issues/1868",
      "repositoryName" : "open-quantum-safe/liboqs",
      "description" : "This would prevent new instances of #1866 from being introduced into the codebase.\n\nSuggested by @trailofbits in Week 1 of their audit of `liboqs`.",
      "updatedAt" : 1753377060.000000000,
      "user" : "SWilson4",
      "userHtmlUrl" : "https://github.com/SWilson4",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/39264796?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @SWilson4 can I work on this issue" ],
      "repository" : {
        "description" : "C library for prototyping and experimenting with quantum-resistant cryptography",
        "homepage" : "https://openquantumsafe.org/",
        "name" : "liboqs",
        "fullName" : "open-quantum-safe/liboqs",
        "htmlUrl" : "https://github.com/open-quantum-safe/liboqs",
        "gitUrl" : "git://github.com/open-quantum-safe/liboqs.git",
        "sshUrl" : "git@github.com:open-quantum-safe/liboqs.git",
        "cloneUrl" : "https://github.com/open-quantum-safe/liboqs.git",
        "owner" : {
          "login" : "open-quantum-safe",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 587,
        "stargazersCount" : 2375,
        "watchersCount" : 2375,
        "size" : 170981,
        "openIssuesCount" : 101,
        "subscribersCount" : 88,
        "pushedAt" : "2025-07-16T07:47:16Z",
        "languages" : {
          "C++" : 38372,
          "Shell" : 20315,
          "C" : 36036534,
          "CMake" : 448471,
          "Nix" : 2787,
          "Assembly" : 13401107,
          "Python" : 175288,
          "Cuda" : 19141
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Prevent new instances of #1866 from being introduced into the codebase",
      "validationOrRequirement" : "Add CodeQL query to check for memset calls",
      "attemptedFixes" : "",
      "otherNotes" : "This issue was suggested by @trailofbits in Week 1 of their audit of liboqs and is considered a good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407031
  }, {
    "issueDTO" : {
      "id" : 3260609705,
      "title" : "ValType toString surprising behavior",
      "url" : "https://github.com/dylibso/chicory/issues/990",
      "repositoryName" : "dylibso/chicory",
      "description" : "Noticed when printing function signatures, `ValType.ExternRef` prints as `RefNull[-17]` which is a little confusing.",
      "updatedAt" : 1753377023.000000000,
      "user" : "andreaTP",
      "userHtmlUrl" : "https://github.com/andreaTP",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5792097?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Native JVM WebAssembly runtime",
        "homepage" : "https://chicory.dev",
        "name" : "chicory",
        "fullName" : "dylibso/chicory",
        "htmlUrl" : "https://github.com/dylibso/chicory",
        "gitUrl" : "git://github.com/dylibso/chicory.git",
        "sshUrl" : "git@github.com:dylibso/chicory.git",
        "cloneUrl" : "https://github.com/dylibso/chicory.git",
        "owner" : {
          "login" : "dylibso",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 56,
        "stargazersCount" : 892,
        "watchersCount" : 892,
        "size" : 44394,
        "openIssuesCount" : 27,
        "subscribersCount" : 20,
        "pushedAt" : "2025-07-24T19:13:55Z",
        "languages" : {
          "C#" : 58,
          "Java" : 1448345,
          "Dockerfile" : 2997,
          "Shell" : 8846,
          "C" : 1083,
          "Rust" : 1063,
          "WebAssembly" : 82917,
          "JavaScript" : 1560,
          "Go" : 259,
          "Swift" : 989,
          "Kotlin" : 132
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to investigate and resolve the surprising behavior of `ValType.ExternRef` when printing function signatures.",
      "validationOrRequirement" : "The issue description does not mention any specific validations or requirements.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to the printing of function signatures in the `ValType.ExternRef` context, specifically the unexpected output of `RefNull[-17]`.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407035
  }, {
    "issueDTO" : {
      "id" : 3260607019,
      "title" : "Commit Frequency Secs option does not work",
      "url" : "https://github.com/microsoft/garnet/issues/1313",
      "repositoryName" : "microsoft/garnet",
      "description" : "### Describe the bug\n\n--compaction-freq option via command line doesn't work when I have it enabled. I was able to RCA and it looks like current code reuses the same copmaction method for checkpointing and even when compaction background task calls it, it early exits because it thinks checkpointing called compaction.\n\n### Steps to reproduce the bug\n\nRun GarnetServer with --compaction-freq 10 and whatever compaction type you want. Put a debug in the compaction method and see how it early exits.\n\n### Expected behavior\n\nCompaction should run at interval\n\n### Screenshots\n\n_No response_\n\n### Release version\n\n_No response_\n\n### IDE\n\n_No response_\n\n### OS version\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753376972.000000000,
      "user" : "hamdaankhalid",
      "userHtmlUrl" : "https://github.com/hamdaankhalid",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/42720645?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Garnet is a remote cache-store from Microsoft Research that offers strong performance (throughput and latency), scalability, storage, recovery, cluster sharding, key migration, and replication features. Garnet can work with existing Redis clients.",
        "homepage" : "https://microsoft.github.io/garnet/",
        "name" : "garnet",
        "fullName" : "microsoft/garnet",
        "htmlUrl" : "https://github.com/microsoft/garnet",
        "gitUrl" : "git://github.com/microsoft/garnet.git",
        "sshUrl" : "git@github.com:microsoft/garnet.git",
        "cloneUrl" : "https://github.com/microsoft/garnet.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 586,
        "stargazersCount" : 11367,
        "watchersCount" : 11367,
        "size" : 4555358,
        "openIssuesCount" : 41,
        "subscribersCount" : 70,
        "pushedAt" : "2025-07-25T00:06:33Z",
        "languages" : {
          "C#" : 12008506,
          "PowerShell" : 55926,
          "Smarty" : 1772,
          "Dockerfile" : 1967,
          "C++" : 121161,
          "CSS" : 2193,
          "Shell" : 410,
          "C" : 167,
          "Batchfile" : 850,
          "CMake" : 2670,
          "JavaScript" : 12994
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Commit Frequency Secs option does not work, expected compaction to run at interval",
      "validationOrRequirement" : "compaction-freq 10 and compaction type",
      "attemptedFixes" : "RCA of the issue",
      "otherNotes" : "compaction-freq option via command line doesn't work when enabled, issue with code reusing same compaction method for checkpointing and compaction background task",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407037
  }, {
    "issueDTO" : {
      "id" : 3259450257,
      "title" : "[MCP] Bluesky",
      "url" : "https://github.com/activepieces/activepieces/issues/8505",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview\n\nBluesky is a decentralized social network built on the AT Protocol, enabling users to post, share, like, and engage with content.  \nThis integration empowers AI agents and workflows to automate posts, engagements, and content monitoring.\n\n---\n\n## ?????? Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n**Contributors based in India: please check your eligibility for receiving payments through your Stripe account before submitting, as this may affect your ability to get paid.**\n\n\n---\n\n## \uD83D\uDEA8 Triggers\n\n| **Trigger**                        | **Use Case** |\n|-----------------------------------|--------------|\n| **New Posts by Author**           | Fires when a selected author creates a new post. |\n| **New Follower on Account**       | Fires when someone new follows your account. |\n| **New Timeline Posts**           | Fires when new posts appear in your \"Following\" feed (chronological). |\n| **New Post (with Search Options)**| Fires when a new post matches given search criteria (mentions, tags, keywords). |\n\n---\n\n## \uD83D\uDEE0??? Write Actions\n\n| **Action Item**   | **Use Case** |\n|-------------------|--------------|\n| **Create Post**    | Publish a new post with text, embeds, images, video, hashtags, language, and threading options. |\n| **Like Post**      | Like a specific post by its URI. |\n| **Repost Post**    | Repost (boost) a specific post by its URI. |\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Action Item** | **Use Case** |\n|------------------|--------------|\n| **Find Post** | Retrieve a single post's details using its URL/URI. |\n| **Find Thread**      | Retrieve a full thread, including parent posts and replies, up to 100 deep. |\n\n---\n\n## \uD83D\uDCDA API Reference\n\n- [Bluesky API Documentation](https://docs.bsky.app/docs/tutorials/creating-a-post)\n\n---\n\n## \uD83E\uDDEA Test Account Access\n\n- You can test Bluesky integrations by creating an account at https://bsky.app/.\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
      "updatedAt" : 1753376760.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "$100", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-851/mcp-bluesky\">AP-851 [MCP] Bluesky</a></p>", "/bounty $100", "## \uD83D\uDC8E $100 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8505` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8505` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @Pranjal6955 | Jul 24, 2025, 11:49:18 AM | #8509 | [Reward](https://algora.io/claims/Rz2DLJV3GfZCMMbw) |\n| \uD83D\uDFE2 @Sanket6652 | Jul 24, 2025, 05:02:34 PM | #8513 | [Reward](https://algora.io/claims/XWSekuGMWmtttuG9) |", "/attempt #8505" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2245,
        "stargazersCount" : 15953,
        "watchersCount" : 15953,
        "size" : 303244,
        "openIssuesCount" : 395,
        "subscribersCount" : 99,
        "pushedAt" : "2025-07-24T23:50:49Z",
        "languages" : {
          "TypeScript" : 14822092,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 72085,
          "Shell" : 3862,
          "JavaScript" : 14477,
          "HTML" : 212991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to integrate Bluesky with Activepieces, enabling AI agents and workflows to automate posts, engagements, and content monitoring.",
      "validationOrRequirement" : "The integration must be submitted as a Piece following the Activepieces architecture and must adhere to the guidelines provided. The contributor should also provide a short demo video of their changes in their pull request.",
      "attemptedFixes" : "The issue has already been attempted by @Pranjal6955 and @Sanket6652, who have submitted their solutions and received rewards. The current attempt is #8505.",
      "otherNotes" : "This issue is related to the integration of Bluesky, a decentralized social network, with Activepieces, an open-source AI automation platform. It requires contributors to submit their work as a Piece following the Activepieces architecture and to review the Piece Development Guidelines before starting development. Contributors based in India should check their eligibility for receiving payments through their Stripe account.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407044
  }, {
    "issueDTO" : {
      "id" : 1309880276,
      "title" : "Add async constructor for Materials with image textures",
      "url" : "https://github.com/CesiumGS/cesium/issues/10566",
      "repositoryName" : "CesiumGS/cesium",
      "description" : "A [Material](https://cesium.com/learn/cesiumjs/ref-doc/Material.html) instance currently gives no indication of whether its textures are loaded or not. This makes unit testing difficult. \r\n\r\nFor example, the following test will fail since the image is not loaded before the scene renders:\r\n```javascript\r\nit(\"renders blue from a blue texture\", function () {\r\n  primitive.appearance.material = Material.fromType(\"Image\", { \r\n    image: \"./Data/Images/Blue.png\"\r\n  });\r\n  scene.primitives.add(primitive);\r\n  // ... Set camera view, etc...\r\n\r\n  expect(scene).toRender([0, 0, 255, 255]);\r\n  // Error: Expected to render [0,0,255,255], but actually rendered [255,255,255,255].\r\n});\r\n```\r\n\r\nSome [current tests](https://github.com/CesiumGS/cesium/blob/dc28421ff2f52871629299d00f310ee796f63833/Specs/Scene/MaterialSpec.js#L634-L643) fix the problem by waiting for a change in the length of the `material._loadedImages` array, but this is complicated to set up.\r\n\r\nProposal: add a static method `Material.fromUrl` returning a Promise. The Promise would resolve to a new Material instance with all textures ready for use. The above test would become:\r\n```javascript\r\nit(\"renders blue from a blue texture\", async function () {\r\n  const material = await Material.fromUrl({\r\n    type: \"Image\",\r\n    image: \"./Data/Images/Blue.png\",\r\n   });\r\n  primitive.appearance.material = material;\r\n  scene.primitives.add(primitive);\r\n  // ... Set camera view, etc...\r\n\r\n  expect(scene).toRender([0, 0, 255, 255]);\r\n});\r\n```\r\n",
      "updatedAt" : 1753376563.000000000,
      "user" : "jjhembd",
      "userHtmlUrl" : "https://github.com/jjhembd",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/41167620?v=4",
      "labels" : [ "category - architecture / api", "type - cleanup", "good first issue", "onramping" ],
      "state" : "OPEN",
      "comments" : [ "hello jjhembd\r\ni am a beginner in open source world\r\ncan you please tell me exact location of code[related to this issue] in files\r\nso that i can work on that", "Hello @gaurav8y785675474,\r\n\r\nThe new function should be added to `packages/engine/Source/Scene/Material.js`.\r\n\r\nThen search the unit tests for occurrences of `material._loadedImages`. That should be replaces with the async/await pattern shown above.", "Hi, I???m a part of the Flagship program for JTC. I would like to work on this issue ticket, please! This is a great opportunity to test my abilities.", "@wesleykebrown Sounds great!", "I've been working on this for a while locally and wanted to ask some questions!\n\nQuestions I have for solution paths:\n\n1. Could the tests be modified to use `pollToPromise`?\n1. With the image urls, there's a nested call in generated functions from `createTexture2DUpdateFunction` ([here](https://github.com/CesiumGS/cesium/blob/main/packages/engine/Source/Scene/Material.js#L787C10-L787C39)]. When interacting with `_loadedImages`, this function's path can either be synchronous or asynchronous. The asynchronous path has potentially multiple `.then` calls, which is probably what's causing the test issue. For improving this, should this and its parent functions be refactored to have a split async/sync path depending on if there's a \"url\" passed as an arg to a constructor? This would be a lot of refactoring.\n1. The variant of above is making every function async and returning the promise chains but that's even worse.\n\n<details>\n<summary>\nQuestions I have for code understanding in this starbucks (hidden cuz its like, optional and I'm fun)\n</summary>\n\n1. I've been reading the [coding guide](https://github.com/CesiumGS/cesium/blob/main/Documentation/Contributors/CodingGuide/README.md) & I wanted to ask where this `Material` falls in the range of low-level to high-level\n1. From the coding guide, it suggests writing code similar to what already exists. Unfortunately, for the `fromUrl` results in the repo, they're wildly different implementations. Mine more closely resembles [the more recently updated one of them](https://github.com/CesiumGS/cesium/blob/main/packages/engine/Source/Scene/SingleTileImageryProvider.js), but it is postfixed with `Provider`, and I wasn't sure if that had any implications\n1. I saw in the op the example fix has a parameter structure breaking with the `fromUrl` tradition: having `url` be the first param. Would it be ok to have `url` be the first param or was that intended as its considered `image` as a nested property within the `Material` spec?\n1. Also looking at other implementations of fromUrl, they're all public. Since the intention here is for improving testing, would it make sense to break from that here and have it be private or no?\n</details>\n\nThanks", "we are actually facing a similar challenge, but in a custom material using fabrics. would your solution also work for this?\n\ni hacked a quick prototype where i used an `imageLoaded` event that would emit on `update` for every loaded image with the uniformId. the benefit of this, i thought, was a) that i can change the uniform and wait for the new texture to be loaded again without having to create a new material and b) the code changes where minimal: a total of three lines. BUT, you have to actually call update on the material. \n\nmaybe there is an inbetween solution that could take care of both the `await Material.fromUrl('my.png')` and `new Material({ fabric: { type: 'MyFabric', uniforms: { tex: myCanvas }, source: '' } })`. ", "If the only purpose of `Material.fromUrl` is to make unit testing easier, why don't we instead make some sort of `imageReady` flag and event that Material creators can listen for? Unit tests could enter a poll loop on the ready flag, or register a listener which performs the `expects` validation steps.\n\nI could see it being useful in other places in the codebase to have a flag that indicates an image is loaded. On the other hand - do we have use cases where we'd want to asynchronously load an image from a URL?", "This sounds related to (although not \"the same as\") the changes that had been done in https://github.com/CesiumGS/cesium/blob/main/CHANGES.md#1107---2023-07-03 . There, the move was generally to change existing cases of \"ready flags\" and events into actual promises, but no strong opinion on the `Material.fromUrl` case from my side.\n ", "I see. In that case, maybe we should just store an array of promises (of images to load) in the material class, and expose a public getter so that users can await those promises? Users can continue to make materials as before - via the constructor or `.fromType` - but can subsequently await the images loading.\n\nWe could also then allow users to (optionally) pass in functions to call on resolving the promise, etc.", "I might be lacking some context for the Material API in particular. It sounds like the suggested `Material.fromUrl` function is not _necessarily_ intended _only_ for tests, but could also be useful in other contexts. Conversely, people might want to have finer control, to optionally wait for (and/or be informed about) the image loading process, but I might be lacking the imagination about why they could want this. For the example of\n```\n  primitive.appearance.material = Material.fromType(\"Image\", { \n    image: \"./Data/Images/Blue.png\"\n  });\n```\nit looks like it can hardly make sense to use this material _without_ the image (this could cause... you know... some white flashing and such \uD83D\uDE2C ). But I think that images can also be \"composed\" and contain _multiple_ external images, and being able to track this with dedicated promises for each image sounds pretty involved (for the implementation, _and_ for the client who wants to use it).\n\nFrom the description until now, it sounds like a \"blanket\"-function like `fromType`**`Async`** could make sense: It creates whatever has to be created, returns a promise, and when it's done, it's done. But maybe there are use-cases for the \"fine-grained\" promises as well.\n", "> dedicated promises for each image sounds pretty involved\n\nIs it? If the `Material` class holds an array of image promises that's gettable, couldn't the user simply `Promise.all(theArray)` to wait for all of them?", "I'm not necessarily arguing against an async constructor, for what it's worth. Just playing devil's advocate to try to understand *exactly* what we want here, before wasting effort building something we don't.\n\nI do think something like `.fromTypeAsync` would be nice to have as part of the Material interface. It *will* be a larger refactor effort, though (an overdue one, to be fair).", "> couldn't the user simply `Promise.all(theArray)` to wait for all of them?\n\nSure, but then I'd ... (also play devil's advocate, and) ... ask a few questions \uD83D\uDE42 \n\nFrom the user's perspective, when the user wants to wait, as in \"Just give me that material!\", then there are these options:\n```javascript\nconst material = await Material.fromTypeAsync(type, { ... });\n```\nvs.\n```javascript\nconst material = Material.fromType(type, { ... });\n\n// Important: Wait for it!\nawait Promise.all(material.getImagePromises());\n```\nIt's a tad less convenient, and new users could easily miss that call. \n\nAnd... does the material even _contain_ images? Maybe, maybe not. That array of promises might be empty...\n\nAlso, offering that array of promises is exposing something that - to my very limited understanding of how that API is commonly used  - could very well remain hidden, unless there is a _strong_ reason why a user should _explicitly_ be able to do something like\n`material.getImagePromises()[42].then(...);`\n(And I can hardly imagine why a user should want to do that - maybe I'm overlooking something...)\n\n(The case where a user does something like `material.getImagePromises()[42] = undefined;` may look contrived, but for the sake of \"information hiding\" etc., it may be worth mentioning that this would be _possible_)\n\nEven _if_ this array is accessible: The user does not even _know_ what each element of this array represents. I'd have to dig through https://github.com/CesiumGS/cesium/wiki/Fabric and try out a few things, but from my understanding there can be materials that involve multiple images...\n```\n{ \n    imageA: \"./Data/Images/Red.png\"\n....\n    imageB: \"./Data/Images/Blue.png\"\n}\n```\nWill the array of promises contain the promises of each of them, in declaration order? \n\n---\n\nNote that I'm also not (strongly) arguing for or against one thing, except for the \"high-level\" points:  \n\n1. the API should be _easy to use_, and _hard to misuse_\n2. when in doubt, leave it out\n\n", "\uD83D\uDC4D\uD83C\uDFFB I buy it :) Will update this thread when I have a better understanding of the refactoring that would be necessary to make an async material constructor.", "Don't spend time and effort until this is confirmed. I'm not making decisions. I'm not arguing. I'm just trying to lay out pros and cons.\n", "Just some thoughts as I'm going through the Material API (will probably edit this comment as I have more):\n- A material can have submaterials. If a material is created via `fromTypeAsync`, I think that implies the submaterials would have to be handled similarly... recursively. That's pretty challenging, as submaterials are created from the Material constructor itself, which cannot be marked async.\n- The solution here needs to continue to allow users to change material textures. \n- The solution should make it easy to add other asynchronous operations to `Material.js` that need to be waited on in an async constructor, in the future.\n- Would be nice if the solution did not duplicate code / might require refactoring out loading logic into more easily callable functions.\n- Is the solution acceptably \"async\" if it requires that the `Material` have an `Update` call before being truly \"ready\"?\n- What do we do about `HTMLVideoElement`, `OffscreenCanvas`, etc. that aren't explicitly fetched in Material.js?", "So, this is more challenging than I anticipated, but not impossible. It just requires making some design choices that I'd like input on.\n\nLet me lay out the challenge first. There are currently two operations that are asynchronous in `Material` - loading images for 2D textures, and for cubemaps. They both occur via functors that are called from the `Update` loop. For example [this function](https://github.com/CesiumGS/cesium/blob/668c2050e19756a0effbd0ddaa613a350dbf30b3/packages/engine/Source/Scene/Material.js#L787-L789) creates a function which is called every Update to potentially load new images, if uniforms have changed.\n\nSo, the asynchronous parts of Material aren't even kicked off on construction - they're kicked off on the first update. This makes it hard to extract them into async functions that can be called in an async constructor.\n\nHere are three approaches I've considered:\n1. We extract the image loading logic into async functions, and call those explicitly in a new async constructor. \n2. We create a `ready` flag and event, which gets set / fires when everything is loaded the first time. The async constructor returns a promise which resolves on this event. To the user, it just looks like a regular promise that can be `await`'ed.\n3. We mark `initializeMaterial` (and downstream calls all the way to `createUniform`) as `async`, and after [creating each updater function](https://github.com/CesiumGS/cesium/blob/668c2050e19756a0effbd0ddaa613a350dbf30b3/packages/engine/Source/Scene/Material.js#L1061), we immediately call and `await` it. The constructor would *not* `await` the `initializeMaterial` function (it can't since it's a constructor, but it shouldn't anyway). Instead, it stores the promise as a member variable. The new async constructor can await this promise.\n\nThe first approach sounds appealing because it doesn't require a ready flag/event pattern, but the logic in the uniform updaters (like `createTexture2DUpdateFunction`) is so complex that it would be really hard to do without any regressions. It's also not very future-proof; adding new async ops to Material would require adding them to the async constructor as well. I briefly tried this approach but got the ick as the rabbit hole of refactoring went ever deeper.\n\nThe second approach is honestly not bad, imo. It's probably the simplest in terms of refactoring, but ready flags are apparently an anti-pattern we're trying to move away from.\n\nI think the third approach is the cleanest, and I tried doing something in this vein until I realized that one of the updater's requires `context`, which is only available in `Update` - ugh! If it's possible to extract the (limited) need for `context`, this is what I'd want to do. [Here's the only use that's really blocking](https://github.com/CesiumGS/cesium/blob/668c2050e19756a0effbd0ddaa613a350dbf30b3/packages/engine/Source/Scene/Material.js#L817-L820).", "I'm like some of the `Material` functionality that is supposed to be pulled out: I'm lacking some `context` \uD83E\uDD21 \n\nThat context issue sounds pretty fundamental, and for me, raises the question about how _any_ of these three approaches should work.\n\nIt sounds like the material could only become `ready` when the images are loaded and the textures are created. And it sounds like this _requires_ the `update` function to be called. If this is correct, then I wonder: When someone does\n`const material = await Material.createAsync(...);`\nin a sandcastle (and nothing else), then there is no time and place where `update` is called at all, and it would wait forever (?). I think that _requring_ the `context` in any context where something `async` is supposed to happen brings us between a rock and a hard place: \"I'd like to render (and call `update`), but for that, I need the material - which is waiting for the `update` call to happen\". (Am I overlooking something obvious here...?)\n\nThe point about the changing uniforms: \n\nEven if there was that magic\n`const material = await Material.createAsync(...);`\nfunction that worked perfectly, one could ask what should happen when\n`material.thatUniform = \"newImage.png\";`\nis called. It has to wait for that PNG to be loaded, and then create the texture (using the `context`), and there is no time and place where one could \"wait\". The only solution for that is to do what is already done for the \"white flashing\" case - namely, keep what is there, until the \"new\" things is ready, and then switch it. \n\nCombining both points: There seem to be these two use-cases:\n\n1. load at construction time (and resolve a promise when it's done)\n2. load when a uniform changes (and switch out some 'texture' when it's done)\n\nIt might be possible to structure this in a way so that both paths use largely the same code. But that would require a clean separation of concerns. I've seen that (single!) 150-line-\"updater\" function that, as usual, is documented with\n```\n\n```\nand that suggest that this might not be so easy So while separating \"whatever should happen async\" and \"whatever needs the context\" sounds like the only viable path here, I'm aware that there are unforeseeable refactoring efforts hidden in that high-level statement. \n\n(I probably have to take a closer look at the actual code here...)\n", "having haphazardly solved this for our custom material (as seen [here](https://github.com/virtualcitySYSTEMS/map-core/blob/c0dbbd41c1fe04587254467cbb69f9abd4986362/src/panorama/panoramaTileMaterial.ts#L298) where  i basically hack the update function to do that which i couldn't using just the Material API) i would like to add some \"insights\".\n\n1. the context is needed to create the texture. it is _not_ however needed to load / create / manipulate the image data and bring it into a form where you can actually pass it to webgl. to get rid of the \"white flashing\" bit (which was my main use case, the other being that i only want to do a certain bit of my shader, if an image is even set), waiting on the image data to be loaded and setting a uniform to `true` once it is (in my case, lacking API, in my custom update function) was enough.\n2. the major problem i see with the `.createAsync` approach, is that it assumes a very strict life cycle: create, view, dispose. as @javagl points out, this is not the case. i can change a uniform when ever. to me, this would call for some kind of event API, something a long the lines of `imageStateChanged`, which gets passed the uniform key and the state of the image `loading`, `failed` or `ready`. this i could then use as follows:\n```js\n// create my custom image\nconst material = new Material({ \n  fabric: { \n    type: 'MyMultiImage', \n    uniforms: { u_imageA: './a.png', u_ImageB: './b.png', u_aReady: false, u_bReady: false },\n  },\n});\n\n// handle image ready state here. \nmaterial.imageStateChanged.addEventListener((uniformKey, state) => {\n    const  ready = state === 'ready';\n    if (uniformKey === 'u_imageA') {\n      material.uniforms.u_aReady = ready;\n   } else if (uniformKey === 'u_ImageB') {\n      material.uniforms.u_bReady = ready;\n   }\n});\n\n// oh, something changed my texutre. no worries, my event handler\n// will take care to change the ready flag to false and wait for the new image to be loaded\nsetTimeout(() => {\n  material.uniforms.u_imageA = './other_a.png';\n}, 2000)\n```\nthose are my two cents, hope this helps further your designs.\n\nPS my approach would need some tweaking to handle the Material.DefaultImageId which i have been using as an `undefined` value.", "To @bkuster's comments:\n\n> the context is needed to create the texture. it is not however needed to load / create / manipulate the image data\n\nThis is the \"issue\" I ran into above. The context is really only needed for the texture; it may be possible to do a refactor where my 3rd approach above works, if not for the `new Texture(...context...);` piece.\n\n> this would call for some kind of event API, something a long the lines of `imageStateChanged`\n\nI'm not entirely against this idea. It might be right for this situation. BUT, if we ever add other asynchronous operations to the Material initialization, this would no longer be sufficient. And what about for cubemap-based materials, where there are *6* images to load? \n\nAlso, with a [recent fix](https://github.com/CesiumGS/cesium/pull/12722), Materials shouldn't flash white anymore when changing properties of an existing material. Only when doing an initial load; so a `fromTypeAsync` that awaits the initial load ought to cover our needs. (?)\n\nTo @javagl: \n\n> There seem to be these two use-cases...\n\nI'm not so sure, honestly. Is there a use case for asynchronous uniform switching? Or is the load-and-switch sufficient for that? For new Materials, it's certainly not sufficient. For one thing, we've already identified that we want a truly asynchronous constructor for better unit testing, right?", "I think you're right, @javagl, that my second approach would create an infinite loop of waiting for an Update that never happens... I thought maybe the render loop happens in a separate thread, but looks like not?", "If [the HTMLVideoElement block](https://github.com/CesiumGS/cesium/blob/668c2050e19756a0effbd0ddaa613a350dbf30b3/packages/engine/Source/Scene/Material.js#L801-L833) is extracted to its own updater function, then nothing else will be dependent on `context` in the other updaters, and approach 3 might work. Going to play around a bit with this.\n\n(Of course, still open to the idea that maybe we don't want an `async` constructor at all, but instead an `imagesReady` event or something like that)", "> Is there a use case for asynchronous uniform switching?\n\nMaybe that was a misunderstanding. From what I see, uniform switching is always \"asynchronous\", When the uniform is changed, the object/material already is displayed, with its \"initial state\". And I could not imagine what a user might want to \"wait for\" here after switching the uniform. \n\nSure, the user might be _informed_ (with an event) when the new image is loaded, but that's the broader point: \n\nThat `material.imageStateChanged.addEventListener` that was suggested there right now is something that focussed on an _internal_ aspect, namely setting that other uniform (to avoid some sort of flickering). \n\nBut _if_ such a mechanism was in place, then it could also be used for handling asynchronicity. (\"Handling\" as in ~\"making it synchronous, await-able\"). This is what my \"use-cases\" referred to, and that _\"...both paths use largely the same code\"_. \n\nIf we had this magic listener, then this could probably be used to avoid the flickering (internally), with pseudocode\n```javascript\nthis.imageStateChanged.addEventListener((....) => {\n  if (image is ready) { \n    // \"Atomically\" swap the internal structures - this is roughly what was done\n    // with that swapping of the \"oldPrimitive\" and the new primitive, mentioned\n    // in https://github.com/CesiumGS/cesium/issues/1640#issuecomment-3024929262\n    discard(old image texture);\n    use(new image texture); \n  }\n});\n```\nAnd the same could be used for that async contruction (pesudocode again):\n```javascript\nMaterial.fromAsync() { \n  const material = create();\n  const promise = pending(material);\n  material.this.imageStateChanged.addEventListener((...) => {\n    if (everything ready) {\n      promise.resolve();    \n    }\n  });\n  return promise;\n});\n```\n\n(This could, in theory, even be applied for some `setUniformAsync` that returns a promise that resolves when the newly set image was loaded, but as I said: There may not be much use for that. At this point, one could rather consider \"pulling that out\", and offering some `material.setUniform(\"image.png\", theActualImageThatWasAlreadyLoaded);` or so, but maybe that's a bit of a stretch)...)\n\nI think that one of the most important aspects for all this is trying to more cleanly separate 1. the image loading and 2. \"the part that needs the `context`\", but can imagine that this could be a considerable effort. (I'm advocating for a hint in the coding guide, that no function should have more than 50 lines of code, just to avoid these ominous 150-line-`update` functions that are \"doing various things\". I'm not sure how easy it is to even isolate that part that needs the context, given corner cases like cubemaps, videos, and whatnot...)\n\n\n\n\n\n\n\n\n\n\n\n", "> I'm advocating for a hint in the coding guide, that no function should have more than 50 lines of code\n\n+100000. How about like 30 lol. Or at least single-purpose. And no nested conditionals more than 2 layers deep. Or super-duper compound conditionals.", "@javagl \n\n```JS\nMaterial.fromAsync() { \n  const material = create();\n  const promise = pending(material);\n  material.this.imageStateChanged.addEventListener((...) => {\n    if (everything ready) {\n      promise.resolve();    \n    }\n  });\n  return promise;\n});\n```\n\nThis is what I was sort of what I was suggesting in my 2nd bullet in [this comment](https://github.com/CesiumGS/cesium/issues/10566#issuecomment-3111564508) but I think it causes an infinite hang? Because if a user awaits this, no Update ever gets called, so the image is never ready.\n\nThey could subscribe to the `imageStateChanged` event though - or, better yet, subscribe to a `materialReady` event.", "This sounds like it might be related to your earlier [comment, about the material waiting for an update](https://github.com/CesiumGS/cesium/issues/10566#issuecomment-3113518129). But just _loading_ the image (i.e. sending out a request and being informed about the response) should be independent of the `update` calls. \n\nI just hacked together a toy example in NodeJS with a `fetch` for an image that triggers an event when the response arrives, and turning that into a promise to ensure that the (dummy) Material is ready, and that seemed to work. But this does not mean that there may not be quirks in the material or all the resource handling that cause this to ~\"not work as expected\". I'd have to dig into the code to see what could be wrong there, but is there anything happening in the `update` that could depend on this? E.g. could it be that the image requests are _only sent out(!)_ during the `update` calls? If they are sent out ~\"from the constructor\", then I think that this should work...\n\n\n", "> But just loading the image (i.e. sending out a request and being informed about the response) should be independent of the update calls\n\nUnfortunately not, without some refactoring. The request to load an image gets kicked off from the Update loop\n\n> E.g. could it be that the image requests are only sent out(!) during the update calls? \n\nYeah, that :) " ],
      "repository" : {
        "description" : "An open-source JavaScript library for world-class 3D globes and maps :earth_americas:",
        "homepage" : "https://cesium.com/cesiumjs/",
        "name" : "cesium",
        "fullName" : "CesiumGS/cesium",
        "htmlUrl" : "https://github.com/CesiumGS/cesium",
        "gitUrl" : "git://github.com/CesiumGS/cesium.git",
        "sshUrl" : "git@github.com:CesiumGS/cesium.git",
        "cloneUrl" : "https://github.com/CesiumGS/cesium.git",
        "owner" : {
          "login" : "CesiumGS",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3639,
        "stargazersCount" : 14063,
        "watchersCount" : 14063,
        "size" : 779069,
        "openIssuesCount" : 1504,
        "subscribersCount" : 476,
        "pushedAt" : "2025-07-25T00:21:26Z",
        "languages" : {
          "TypeScript" : 11079,
          "CSS" : 55918,
          "JavaScript" : 22719298,
          "HTML" : 1962249,
          "GLSL" : 537408,
          "Python" : 4899
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The goal of this issue is to add an `async` constructor to the `Material` class, which will allow for asynchronous image loading and notification of the material when the image is ready.",
      "validationOrRequirement" : "The material should be able to load images asynchronously and notify the user when the image is ready, allowing for better unit testing and easier use in complex scenarios.",
      "attemptedFixes" : "Several contributors have tried to solve this issue, including proposing an `async` constructor, extracting the image loading logic into a separate function, and using an `imageStateChanged` event to notify the material when the image is ready.",
      "otherNotes" : "Various comments and ideas from contributors, including a potential solution involving an `imageStateChanged` event, concerns about the complexity of the current implementation, and suggestions for refactoring and separating concerns.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407050
  }, {
    "issueDTO" : {
      "id" : 2494190635,
      "title" : "\uD83D\uDE4F Help wanted: Deprecate old plugin backends ",
      "url" : "https://github.com/backstage/backstage/issues/26353",
      "repositoryName" : "backstage/backstage",
      "description" : "**TL;DR** make sure that `createRouter` and other exports are marked as deprecated. For the majority of packages there should only be one default export of the backend plugin itself. The `@backstage/backend-common` package is deprecated so usages of that package should also be avoided.\r\n\r\nBackstage???s [new backend system](https://backstage.io/docs/backend-system/) is ready for general use; we are now asking for a full transition over to the new backend system, which involves [stop supporting the old system](https://backstage.io/docs/backend-system/building-plugins-and-modules/migrating/#remove-support-for-the-old-backend-system). By old system we mean having exports of `createRouter` and related types. There should only need to be one export like [this](https://github.com/backstage/backstage/blob/5d92499845e60e154b80481a679bfa3ec12f0dfb/plugins/notifications-backend/src/index.ts#L16) in the backend plugin???s `index.ts` file.\r\n\r\n## How do I help?\r\n\r\nRun `yarn backstage-repo-tools lint legacy-backend-exports` in the repository to get a full report of packages that require action.\r\n\r\n### Phase 1\r\n\r\n#### Ensure that plugins contain a default export\r\n\r\nEnsure that there is a default export of the backend plugin in `index.ts`, see [this example](https://github.com/backstage/backstage/blob/5d92499845e60e154b80481a679bfa3ec12f0dfb/plugins/notifications-backend/src/index.ts#L16).\r\n\r\nIf the plugin previously had a default export in `plugins/<plugin-id>/src/alpha.ts`, make sure that that export is deprecated and that the default export is moved to the non-alpha `index.ts` instead.\r\n\r\n#### Deprecate `createRouter`, `RouterOptions` and similar types.\r\n\r\nHere???s an [example](https://github.com/backstage/backstage/pull/26078) of a plugin???s `createRouter` being deprecated.\r\n\r\n```diff\r\n/**\r\n+ * @deprecated Please migrate to the new backend system as this will be removed in the future.\r\n * @public\r\n * */\r\nexport async function createRouter(\r\n  options: RouterOptions,\r\n): Promise<express.Router> {\r\n```\r\n\r\n### Phase 2\r\n\r\n#### Remove deprecated exports\r\n\r\nEnsure that deprecations have been out for at one mainline release before proceeding with removal of all deprecated exports. Removing exports from one release to another is not recommended \r\n\r\nThe complete migration story for a backend plugin (including deprecation) is also mentioned in our [docs](https://backstage.io/docs/backend-system/building-plugins-and-modules/migrating#remove-support-for-the-old-backend-system).\r\n\r\nIf you take on migrating a backend plugin, feel free to add a comment in this issue to avoid duplicate work.\r\n\r\nWe plan to have all `createRouter` exports and `@backstage/backend-common` usages removed by the end of this year. Your help would be much appreciated!\r\n\r\n",
      "updatedAt" : 1753376254.000000000,
      "user" : "jhaals",
      "userHtmlUrl" : "https://github.com/jhaals",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/68980?v=4",
      "labels" : [ "priority:contrib-needed", "domain:backend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey, I have started to work on `plugins/user-settings-backend` in #26584", "Just started working on the app-backend plugin. Since `createRootLogger` is used for much of the [test cases in the plugins](https://github.com/backstage/backstage/blob/17ecea82239f25a4ee89f9c59fe43e735d1c80a2/plugins/app-backend/src/service/appPlugin.test.ts#L34), should this be swapped out for what's found [here](https://backstage.io/docs/backend-system/core-services/logger/), and how? \r\n\r\n\r\n", "@kenilkevadiya sure! This is completely open to contributions :pray: \r\n\r\n@itsalam that particular call that you're linking to can hopefully be removed alltogether as the side effect of it should no longer be needed. More generally the root logger can be replaced by the equivalent mock service: https://backstage.io/docs/backend-system/building-plugins-and-modules/testing/#mock-services", "Hello @Rugvip, I'm working on the `catalog-backend-module-puppetdb`, which doesn't have a `/plugin` directory with the plugin we would normally export by default. It has a default export in the `alpha.ts` file as follows:\r\n\r\n```typescript\r\nexport { default } from './module';\r\n```\r\nIn this case, do we simply deprecate the `alpha.ts` export and add the same line to the `index.ts`? The `index.ts` file is exporting everything in the `/providers` and `/puppet` directories, and I'm not sure if we want to limit or change what gets exported to the users.\r\n\r\nThank you!", "I believe that getting rid of `@backstage/backend-common` package usages would also reduce occurrences of Vulnerability (CVE-2024-21534)\r\n\r\nThere is a vulnerability with severity 9.3 in jsonpath-plus <= 10.0.7. See https://security.snyk.io/vuln/SNYK-JS-JSONPATHPLUS-7945884\r\n\r\n`@backstage/backend-common` package is using `@kubernetes/client-node` package which is using vulnerable `jsonpath-plus@npm:7.2.0`", "I would like to work on this", "I see that the command `yarn backstage-repo-tools lint legacy-backend-exports` does is showing `??? createRouter is NOT deprecated` for those plugins, in which createRouter has already been deprecated. I've created an issue (#27668) with additional details about this problem.", "Hello! I???d like to work on this. \n\nWas going to start migrating `plugins/techdocs-backend`, but I saw that [PR #29022](https://github.com/backstage/backstage/pull/29022) touched on it slightly while migrating search-backend ??? but createRouter is still present, and @backstage/backend-common is still in use.\n\nJust checking if anyone is already working on this or if I can go ahead.", "Hi @j1bulbul, feel free to run with `techdocs-backend`. I have looked at this in the past and it's a bit tricky so keep that in mind when you start to work on it. \uD83D\uDC4D \n\nThe PR you listed was focused on just Search and only touched TechDocs as there was some deprecated Search code in there that needed to be removed as part of that work.", "> Hi [@j1bulbul](https://github.com/j1bulbul), feel free to run with `techdocs-backend`. I have looked at this in the past and it's a bit tricky so keep that in mind when you start to work on it. \uD83D\uDC4D\n> \n> The PR you listed was focused on just Search and only touched TechDocs as there was some deprecated Search code in there that needed to be removed as part of that work.\n\nOkay noted, will give it a go \uD83D\uDC4D ", "Hi @j1bulbul, I'm terribly sorry, I missed this comment on my PR - https://github.com/backstage/backstage/pull/29022#discussion_r1989474772 - when I followed up here. I'm actually going to move forward with this but if you want to try and collaborate in my PR on this happy to have another set of eyes helping me spot anything I missed or that might be wrong. Again, sorry for the confusion on my part. \uD83D\uDE22 ", "Hey @awanlin, no worries at all! Happy to take a look once you???ve pushed the changes. I looked into it earlier and yeah I see what you mean about this being tricky. It???d be helpful to see how you approach it - might take on another one soon if there are still plugins that need deprecating/migrating and haven???t been picked up yet.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.", "Hope to gain some eyeballs please: In  `plugins/kubernetes-backend`, there seems to be a few side-effect imports of `@backstage/backend-common`, e.g. this one: \nhttps://github.com/backstage/backstage/blob/ab209e4964ee90de5899e8269f6255243d51e811/plugins/kubernetes-backend/src/cluster-locator/CatalogClusterLocator.test.ts#L17\n\nI guess that some time ago, `@backstage/backend-common` had side effects, but I'm not sure if we can proceed to remove it now. As I don't have familiarity on how the side effect was used, hope to get some context from us \uD83D\uDE4F\n\nTogether with my #30352, that would remove usage in the biggest backend plugins that users will import \uD83C\uDF89\n\nI'm invested and can help to create the MR for `kubernetes-backend` too. Like #28969, we are using Trivy scan and there's this nagging vulnerability that will go away once we no longer depends on `@backstage/backend-common`.", "Can I try working on this issue ?\n", "> Can I try working on this issue ?\n\n@Ayushmore1214 oooh awesome! \uD83C\uDF89 I would be interested to see this moves \uD83D\uDE4F\n\nAs @Rugvip [says](https://github.com/backstage/backstage/issues/26353#issuecomment-2373497777):\n> This is completely open to contributions \uD83D\uDE4F\n\n", "Sorry for inconvenience @Teo-ShaoWei , I will be busy for next 5-7 days , If someone else likes to work on this issue till then plz assign them Thank you !" ],
      "repository" : {
        "description" : "Backstage is an open framework for building developer portals",
        "homepage" : "https://backstage.io/",
        "name" : "backstage",
        "fullName" : "backstage/backstage",
        "htmlUrl" : "https://github.com/backstage/backstage",
        "gitUrl" : "git://github.com/backstage/backstage.git",
        "sshUrl" : "git@github.com:backstage/backstage.git",
        "cloneUrl" : "https://github.com/backstage/backstage.git",
        "owner" : {
          "login" : "backstage",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 6681,
        "stargazersCount" : 30806,
        "watchersCount" : 30806,
        "size" : 12647358,
        "openIssuesCount" : 489,
        "subscribersCount" : 238,
        "pushedAt" : "2025-07-24T19:27:37Z",
        "languages" : {
          "MDX" : 482307,
          "PowerShell" : 698,
          "CSS" : 449146,
          "Handlebars" : 42736,
          "Makefile" : 5192,
          "Mustache" : 22321,
          "HTML" : 10780,
          "TypeScript" : 21445027,
          "HCL" : 1581,
          "Dockerfile" : 11011,
          "Shell" : 5657,
          "SCSS" : 12343,
          "JavaScript" : 412437
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to deprecate old plugin backends and migrate to the new backend system. This involves marking exports as deprecated, removing deprecated exports, and avoiding usages of the `@backstage/backend-common` package. The goal is to have all `createRouter` exports and `@backstage/backend-common` usages removed by the end of the year.",
      "validationOrRequirement" : "The issue requires that all plugins contain a default export, `createRouter` and related types should be deprecated, and usages of `@backstage/backend-common` package should be avoided. The issue also requires that all deprecations have been out for at least one mainline release before proceeding with removal of all deprecated exports.",
      "attemptedFixes" : "Several attempts have been made to migrate backend plugins, including deprecation and removal of exports. Some plugins have already been partially migrated, but there are still many plugins that need to be migrated.",
      "otherNotes" : "The issue is about deprecating old plugin backends and migrating to the new backend system. It involves marking exports as deprecated, removing deprecated exports, and avoiding usages of the `@backstage/backend-common` package. The issue also mentions a vulnerability in `@kubernetes/client-node` package.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407059
  }, {
    "issueDTO" : {
      "id" : 3259215982,
      "title" : "[MCP] Podio",
      "url" : "https://github.com/activepieces/activepieces/issues/8503",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview\n\nPodio is a collaborative work and project management platform that allows teams to build flexible apps, manage workflows, and track tasks and communications.  \nThis integration empowers AI agents and workflows to automate processes around items, tasks, activities, and user actions in Podio.\n\n---\n\n## ?????? Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n**Contributors based in India: please check your eligibility for receiving payments through your Stripe account before submitting, as this may affect your ability to get paid.**\n\n---\n\n## \uD83D\uDEA8 Triggers\n\n| **Trigger**                | **Use Case** |\n|---------------------------|--------------|\n| **New Item**              | Fires when a new item (record/entry) is created in an app. |\n| **New Task**              | Fires when a new task is added to any workspace. |\n| **New Activity**          | Fires when any activity occurs in a stream (e.g., status change). |\n| **Item Updated**          | Fires when an existing item is updated (excluding comments). |\n| **New Organization**      | Fires when a new organization is created. |\n| **New Workspace**         | Fires when a new workspace is added. |\n\n---\n\n## \uD83D\uDEE0??? Write Actions\n\n| **Action Item**                 | **Use Case** |\n|--------------------------------|--------------|\n| **Create Item**               | Create a new record in a Podio app. |\n| **Update Item**               | Update fields on an existing item. |\n| **Create Task**               | Add a new task to an item or workspace. |\n| **Update Task**               | Modify an existing task???s details or status. |\n| **Attach File**               | Upload and attach a file to an item/task/comment. |\n| **Create Comment**            | Post a comment on an item or task. |\n| **Create Status Update**      | Add a status to an item or workspace stream. |\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Action Item**         | **Use Case** |\n|-------------------------|--------------|\n| **Find Item**           | Retrieve a single item by ID or field value. |\n| **Find Task**           | Retrieve a task by ID for further updates. |\n\n---\n\n## \uD83D\uDCDA API Reference\n\n- [Podio API Documentation](https://developers.podio.com/api-key)\n\n---\n\n## \uD83E\uDDEA Test Account Access\n\n- You can test Podio APIs by creating a free account at [Podio.com](https://podio.com/).\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
      "updatedAt" : 1753376241.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "$100", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-850/mcp-podio\">AP-850 [MCP] Podio</a></p>", "/bounty $100", "## \uD83D\uDC8E $100 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8503` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8503` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @Va16hav07 | Jul 24, 2025, 09:52:32 AM | WIP |  |\n| \uD83D\uDFE2 @dhvll | Jul 24, 2025, 10:09:19 AM | WIP |  |\n| \uD83D\uDFE2 @Pranjal6955 | Jul 24, 2025, 10:36:24 AM | WIP |  |\n| \uD83D\uDFE2 @MAVRICK-1 | Jul 24, 2025, 03:29:53 PM | #8512 | [Reward](https://algora.io/claims/5wXCqiqFWcx2JBK2) |", "/attempt #8503", "/attempt #8503" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2245,
        "stargazersCount" : 15953,
        "watchersCount" : 15953,
        "size" : 303244,
        "openIssuesCount" : 395,
        "subscribersCount" : 99,
        "pushedAt" : "2025-07-24T23:50:49Z",
        "languages" : {
          "TypeScript" : 14822092,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 72085,
          "Shell" : 3862,
          "JavaScript" : 14477,
          "HTML" : 212991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Integrate Podio with Activepieces to empower AI agents and workflows to automate processes around items, tasks, and user actions in Podio.",
      "validationOrRequirement" : "The integration must be submitted as a Piece following the Activepieces architecture, and contributors must review the Piece Development Guidelines before starting development. Additionally, contributors based in India must check their eligibility for receiving payments through their Stripe account before submitting.",
      "attemptedFixes" : "Several attempts have been made by @Va16hav07, @dhvll, @Pranjal6955, and @MAVRICK-1, but no solution has been provided yet. The attempts are marked as WIP (Work In Progress).",
      "otherNotes" : "The issue is about integrating Podio with Activepieces, a collaborative work and project management platform. The main goal is to empower AI agents and workflows to automate processes around items, tasks, and user actions in Podio. The integration requires the submission of a Piece following the Activepieces architecture, and contributors are encouraged to review the Piece Development Guidelines before starting development.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407067
  }, {
    "issueDTO" : {
      "id" : 3128861677,
      "title" : "Add class-based-component folder README with context about outdated practice",
      "url" : "https://github.com/Techtonica/curriculum/issues/2372",
      "repositoryName" : "Techtonica/curriculum",
      "description" : "### Page where problem found?\n\n[Class Based Component Folder](https://github.com/Techtonica/curriculum/tree/main/react-js/class-based-components)\n\n### Type of problem\n\nClass components should not be the participant's go to application of React components, but rather than taking out this curriculum some context should be provided\n\n### Suggested Solution\n\nAudit the [class based components content](https://github.com/Techtonica/curriculum/tree/39c5f943ae607de83bb2613e8a1a5bedae2f7a6e/react-js/class-based-components)\n- [ ] add an intro readme that points to each of the folder's files\n- [ ] add context about why class components are outdated, their original usage, and why it is good to be aware of when maintaining codebases",
      "updatedAt" : 1753376159.000000000,
      "user" : "daaimah123",
      "userHtmlUrl" : "https://github.com/daaimah123",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/41805952?v=4",
      "labels" : [ "no-eng-required", "EASY", "GSSoC", "onlydust-wave", "hacktoberfest", "hackathon", "good first issue", "BEGINNER", "100daysofcode" ],
      "state" : "OPEN",
      "comments" : [ "Hi,\n\nI would love to work on this issue.\n\nI'm ready to audit the current class-based component content and implement the suggested solutions. This involves creating a clear introductory README for the folder and, importantly, adding the necessary context about why class components are outdated, their original use, and why understanding them is still valuable for maintaining projects.\n\nMy significant experience with both React class and functional components makes me confident I can deliver a clear and effective update to this part of the curriculum.\n\nThank you.\n\nRecommended by [OnlyDust](https://onlydust.com/) for outstanding experience and quality contributions.", "Hi @suzy-g38 \uD83D\uDC4B\uD83C\uDFFE nice to virtually meet you! Thank you for expressing interest in doing the work for this issue.\n\nPlease kindly confirm that you have:\n- [ ] gone through our [contributor's guide](https://github.com/Techtonica/curriculum/blob/main/CONTRIBUTING.md)\n- [ ] have completed the volunteer form\n- [ ] agreed to our code of conduct\n\nOnce I have your confirmation, I will grant you write access to the repo. For now, I have assigned this issue to you via \"Only Dust Wave\" hackathon. \uD83D\uDE03 Looking forward to your contribution." ],
      "repository" : {
        "description" : "This repo contains the curriculum of Techtonica, a tech training program for women and non-binary adults with low incomes.",
        "homepage" : "",
        "name" : "curriculum",
        "fullName" : "Techtonica/curriculum",
        "htmlUrl" : "https://github.com/Techtonica/curriculum",
        "gitUrl" : "git://github.com/Techtonica/curriculum.git",
        "sshUrl" : "git@github.com:Techtonica/curriculum.git",
        "cloneUrl" : "https://github.com/Techtonica/curriculum.git",
        "owner" : {
          "login" : "Techtonica",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 514,
        "stargazersCount" : 631,
        "watchersCount" : 631,
        "size" : 36448,
        "openIssuesCount" : 71,
        "subscribersCount" : 41,
        "pushedAt" : "2025-07-24T19:44:06Z",
        "languages" : {
          "CSS" : 5810,
          "Shell" : 1876,
          "JavaScript" : 108915,
          "HTML" : 20618,
          "Python" : 27024,
          "EJS" : 968
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a README to the Class-Based Component folder with context about outdated practices and provide an introduction to each file.",
      "validationOrRequirement" : "Confirmation of going through the contributor's guide, completing the volunteer form, and agreeing to the code of conduct is required before granting write access to the repo.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is related to the Class-Based Component folder in the curriculum, and the suggested solution involves creating a README with context about outdated practices and adding an intro to each file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407071
  }, {
    "issueDTO" : {
      "id" : 3128994500,
      "title" : "Evaluate project criteria is clear",
      "url" : "https://github.com/Techtonica/curriculum/issues/2388",
      "repositoryName" : "Techtonica/curriculum",
      "description" : "### Page where problem found?\n\n## Full Time Programs' Project Links:\n- Week 1. Recipe Page ([phase 1](https://github.com/Techtonica/curriculum/blob/main/projects/recipe-page/phase-1-html-prompt.md) & [phase 2](https://github.com/Techtonica/curriculum/blob/main/projects/recipe-page/phase-2-css-prompt.md))\n- Week 2. Recipe Page ([phase 3](https://github.com/Techtonica/curriculum/blob/main/projects/recipe-page/phase-3-bootstrap-prompt.md) and [phase 4](https://github.com/Techtonica/curriculum/blob/main/projects/recipe-page/phase-4-DOM-Manipulation.md))\n- Week 3. Portfolio / Resume Page ([phase 1](https://github.com/Techtonica/curriculum/blob/main/projects/portfolio/portfolio-webpage-1.md), [phase 2](https://github.com/Techtonica/curriculum/blob/main/projects/portfolio/portfolio-webpage-2.md), [phase 3](https://github.com/Techtonica/curriculum/blob/main/projects/portfolio/portfolio-webpage-3.md))\n- Week 4. [Games App](https://github.com/Techtonica/curriculum/blob/main/projects/js-html-games.md) (JavaScript)\n- Week 5. [Games App](https://github.com/Techtonica/curriculum/blob/main/projects/react-game.md) (React)\n- Week 6. [RESTful API](https://github.com/Techtonica/curriculum/blob/main/projects/rest-api-project.md)\n- Week 7. [Weather App](https://github.com/Techtonica/curriculum/blob/main/projects/weather-app.md)\n- Week 8. [Game/Quiz App](https://github.com/Techtonica/curriculum/blob/main/projects/week8GameREADME.md) (Testing Introduced)\n- Week 9. [Eventonica](https://github.com/Techtonica/curriculum/tree/main/projects/eventonica-updated)\n- Week 10. [Endangered Animals](https://github.com/Techtonica/curriculum/blob/main/projects/mern-pern-project.md)\n- Week 11. 2 mini projects in 1 week! [Contact List](https://github.com/Techtonica/curriculum/blob/main/projects/pern-contact-list-app.md) and choice of [Weather App](https://github.com/Techtonica/curriculum/blob/main/projects/pern-weather-app.md) or [Game App](https://github.com/Techtonica/curriculum/blob/main/projects/pern-game-app.md)\n- Week 12. [Blog App](https://github.com/Techtonica/curriculum/tree/main/projects/blog-app)\n- Weeks 13 - 18. [Final Project](https://github.com/Techtonica/curriculum/tree/main/projects/final-project)\n\n### Type of problem\n\nSome participants find themselves confused about what is required of each project and what will be evaluated\n\n### Suggested Solution\n\n- [ ] Evaluate each week's project README. \n- [ ] Ensure all project requirements are clearly stated and its clear what is required of the project, ensure that it is clear the areas that staff will be evaluating. \n- [ ] Best practice should be clearly stated as apart of requirements\n    - [ ] committing frequently, \n    - [ ] participating in PR code reviews and feedback iteration, \n    - [ ] collaboration, \n    - [ ] clean code and formatting",
      "updatedAt" : 1753376146.000000000,
      "user" : "daaimah123",
      "userHtmlUrl" : "https://github.com/daaimah123",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/41805952?v=4",
      "labels" : [ "no-eng-required", "EASY", "onlydust-wave", "good first issue", "Program Staff", "BEGINNER" ],
      "state" : "OPEN",
      "comments" : [ "Hey,\n\nI would love to work on this issue. \n\nI love Techtonica's mission to empower women and non-binary adults through tech training, and I'd love to contribute to such a meaningful cause.\n\nI'm confident I can help improve the curriculum's clarity, making the learning experience even more effective and supportive for Techtonica's participants. Please let me know how I can get started!\n\nThank you.\n\nRecommended by [OnlyDust](https://onlydust.com/) for outstanding experience and quality contributions.", "Hi @suzy-g38 \uD83D\uDC4B\uD83C\uDFFE nice to virtually meet you! Thank you for expressing interest in doing the work for this issue.\n\nPlease kindly confirm that you have:\n- [ ] gone through our [contributor's guide](https://github.com/Techtonica/curriculum/blob/main/CONTRIBUTING.md)\n- [ ] have completed the volunteer form\n- [ ] agreed to our code of conduct\n\nOnce I have your confirmation, I will grant you write access to the repo. For now, I have assigned this issue to you via \"Only Dust Wave\" hackathon. \uD83D\uDE03 Looking forward to your contribution." ],
      "repository" : {
        "description" : "This repo contains the curriculum of Techtonica, a tech training program for women and non-binary adults with low incomes.",
        "homepage" : "",
        "name" : "curriculum",
        "fullName" : "Techtonica/curriculum",
        "htmlUrl" : "https://github.com/Techtonica/curriculum",
        "gitUrl" : "git://github.com/Techtonica/curriculum.git",
        "sshUrl" : "git@github.com:Techtonica/curriculum.git",
        "cloneUrl" : "https://github.com/Techtonica/curriculum.git",
        "owner" : {
          "login" : "Techtonica",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 514,
        "stargazersCount" : 631,
        "watchersCount" : 631,
        "size" : 36448,
        "openIssuesCount" : 71,
        "subscribersCount" : 41,
        "pushedAt" : "2025-07-24T19:44:06Z",
        "languages" : {
          "CSS" : 5810,
          "Shell" : 1876,
          "JavaScript" : 108915,
          "HTML" : 20618,
          "Python" : 27024,
          "EJS" : 968
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Evaluate project criteria is clear, to make the learning experience even more effective and supportive for Techtonica's participants",
      "validationOrRequirement" : "evaluate each week's project README, ensure all project requirements are clearly stated, ensure that it is clear the areas that staff will be evaluating, best practice should be clearly stated as apart of requirements",
      "attemptedFixes" : "none mentioned in the description",
      "otherNotes" : "Some participants find themselves confused about what is required of each project and what will be evaluated, suggested solution includes evaluating each week's project README, ensuring all project requirements are clearly stated, and best practices should be clearly stated as part of requirements",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407075
  }, {
    "issueDTO" : {
      "id" : 2644268864,
      "title" : "User Interface - GUI",
      "url" : "https://github.com/SGCODEX/Music-Recommendation-Using-Facial-Expressions/issues/4",
      "repositoryName" : "SGCODEX/Music-Recommendation-Using-Facial-Expressions",
      "description" : "Creating a beautiful user-friendly GUI to enhance the user experience using any GUI library on `/code/ui_interfaces/app_PySimpleGUI.py`",
      "updatedAt" : 1753376123.000000000,
      "user" : "SGCODEX",
      "userHtmlUrl" : "https://github.com/SGCODEX",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/64886313?v=4",
      "labels" : [ "gssoc25", "good first issue", "level 2" ],
      "state" : "OPEN",
      "comments" : [ "@SGCODEX \r\ni wanted to fix this \r\nplease assign it to me under SWOC label..", "@SGCODEX \r\nI want to contibute to this issue, kindly consider assigning this issue to me under SWOC.", "Hey everyone, this issue is open for contributions again now.", "Hi @SGCODEX ,\nCould you please assign this to me under GSSoC'25? . Looking forward to contributing!\nThanks!", "Hi @SGCODEX  \uD83D\uDC4B\n\nI???d love to work on this issue! Could you please assign it to me?\nI???m participating in GSSoC '25 and this looks like a great task to contribute to.\n\nThanks in advance!", "Heyy @IqraS-gif @Sanskriti10247 , Please complete the assigned issues first and then comment again here. Will assign then. Thank you.", "Hi @SGCODEX ,\n\nI noticed the task related to creating a beautiful, user-friendly GUI to enhance user experience.\n\nI???d love to contribute to this and work with a GUI library to improve the project???s interface. May I take up this task?\n\nLooking forward to your approval!", "Heyy @Shreyashahu, Sure please go ahead. Please copy `/code/ui_interfaces/app_PySimpleGUI.py` file in `/code/new_models/` directory and make your changes and rename the file as `app_PySimpleGUI_withui.py`", "Hi @SGCODEX,\nI???m interested in the task of creating a beautiful, user-friendly GUI to enhance the user experience using a GUI library. Since it???s already assigned, could I still contribute to this, or I would be happy to take up any other issues." ],
      "repository" : {
        "description" : "This Python-based AI project utilizes OpenCV for facial recognition and a pre-trained deep learning model to analyze facial expressions. By identifying your current mood, the system leverages YouTube's search capabilities to recommend music that aligns with your emotions.",
        "homepage" : "https://music-recommendation-using-facial-expressions-latest.streamlit.app/",
        "name" : "Music-Recommendation-Using-Facial-Expressions",
        "fullName" : "SGCODEX/Music-Recommendation-Using-Facial-Expressions",
        "htmlUrl" : "https://github.com/SGCODEX/Music-Recommendation-Using-Facial-Expressions",
        "gitUrl" : "git://github.com/SGCODEX/Music-Recommendation-Using-Facial-Expressions.git",
        "sshUrl" : "git@github.com:SGCODEX/Music-Recommendation-Using-Facial-Expressions.git",
        "cloneUrl" : "https://github.com/SGCODEX/Music-Recommendation-Using-Facial-Expressions.git",
        "owner" : {
          "login" : "SGCODEX",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 34,
        "stargazersCount" : 31,
        "watchersCount" : 31,
        "size" : 744,
        "openIssuesCount" : 26,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-24T05:40:14Z",
        "languages" : {
          "Python" : 46357
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Creating a beautiful user-friendly GUI to enhance the user experience using a GUI library on `/code/ui_interfaces/app_PySimpleGUI.py`.",
      "validationOrRequirement" : "The contributor is expected to use a GUI library to create a beautiful user-friendly GUI and enhance the user experience.",
      "attemptedFixes" : "None mentioned, but some contributors have shown interest in taking up the task.",
      "otherNotes" : "The task is to create a beautiful user-friendly GUI to enhance the user experience using a GUI library on `/code/ui_interfaces/app_PySimpleGUI.py`. The contributor is requested to copy the file in `/code/new_models/` directory and rename it as `app_PySimpleGUI_withui.py`.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407080
  }, {
    "issueDTO" : {
      "id" : 2587939585,
      "title" : "Replace zeros with dashes when referring to user balances",
      "url" : "https://github.com/balancer/frontend-monorepo/issues/54",
      "repositoryName" : "balancer/frontend-monorepo",
      "description" : "To make it easier for users to scan their balances within the My Liquidity section of the Pool Detail page, replace zero amounts with a 'n-dash'.\n\n![Image](https://github.com/balancer/frontend-monorepo/assets/149399376/79cbea2b-43b6-4d8f-92fd-c0ae687b9195)\n\nAlso note: there is a separate ticket to replace 'My APR' with 'My pool share', so you don't need to do that update as part of this ticket. \n\n\n----\n\nA second spot to add the same logic is in the Add liquidity preview screen:\n\n![Image](https://github.com/balancer/frontend-monorepo/assets/149399376/967815a9-7c17-42e6-9d70-02541aadaf58)\n\n",
      "updatedAt" : 1753376079.000000000,
      "user" : "uiuxxx",
      "userHtmlUrl" : "https://github.com/uiuxxx",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/149399376?v=4",
      "labels" : [ "UX improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @uiuxxx??@garethfuller \uD83D\uDC4B\n\nIs the ???replace???0???with????????? tweak still open?  \nIf yes, I can add the n???dash for zero balances in **My???Liquidity** and the **Add???Liquidity preview** screens and open a quick PR.\n\nLet me know!\n\nThanks,  \nVadim??Nicolai\n", "@nicolad ??? hello! \n\nYes, this is still open and would appreciate your help here.", "Thanks @uiuxxx \nAppreciate your reply, please assign me to avoid double effort if someone else will start at the same time", "created this draft, this is my first PR here, I don't know a lot of things yet, will appreciate feedback and will rewrite/ refactor as needed\n\nhttps://github.com/balancer/frontend-monorepo/pull/1389" ],
      "repository" : {
        "description" : "Balancer frontend apps and packages. Includes the official Balancer web application.",
        "homepage" : "https://balancer.fi",
        "name" : "frontend-monorepo",
        "fullName" : "balancer/frontend-monorepo",
        "htmlUrl" : "https://github.com/balancer/frontend-monorepo",
        "gitUrl" : "git://github.com/balancer/frontend-monorepo.git",
        "sshUrl" : "git@github.com:balancer/frontend-monorepo.git",
        "cloneUrl" : "https://github.com/balancer/frontend-monorepo.git",
        "owner" : {
          "login" : "balancer",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 21,
        "watchersCount" : 21,
        "size" : 108448,
        "openIssuesCount" : 71,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T18:42:20Z",
        "languages" : {
          "TypeScript" : 4630914,
          "CSS" : 13282,
          "JavaScript" : 8940
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To make it easier for users to scan their balances within the My Liquidity section of the Pool Detail page, replace zero amounts with a 'n-dash'.",
      "validationOrRequirement" : "Replace zero amounts with a 'n-dash' in **My Liquidity** and the **Add Liquidity preview** screens.",
      "attemptedFixes" : "The issue is still open and waiting for a fix, with a proposed solution to add the n-dash for zero balances in **My Liquidity** and the **Add Liquidity preview** screens.",
      "otherNotes" : "There is a separate ticket to replace 'My APR' with 'My pool share', so this update is not part of this ticket.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407085
  }, {
    "issueDTO" : {
      "id" : 3260562358,
      "title" : "Update sidebar icons",
      "url" : "https://github.com/elementary/calculator/issues/287",
      "repositoryName" : "elementary/calculator",
      "description" : "### What Happened?\n\nCalculator uses the old non-fd.o `pane-show-symbolic` and  `pane-hide-symbolic` icons\n\n### Steps to Reproduce\n\nhttps://github.com/elementary/calculator/blob/c20e967965896b56567a489a45f529f4054c0673/src/MainWindow.vala#L93\n\n### Expected Behavior\n\nThese should be replaced with `view-sidebar-end-symbolic` which is now in Granite\n\n### OS Version\n\n8.x (Circe)\n\n### OS Architecture\n\namd64 (on most hardwares)\n\n### Session Type\n\nSecure Session (Wayland)\n\n### Software Version\n\nLatest release (I have run all updates)\n\n### Log Output\n\n```shell\n\n```\n\n### Hardware Info\n\n_No response_",
      "updatedAt" : 1753376037.000000000,
      "user" : "danirabbit",
      "userHtmlUrl" : "https://github.com/danirabbit",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7277719?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Calculator app designed for elementary OS",
        "homepage" : "https://elementary.io",
        "name" : "calculator",
        "fullName" : "elementary/calculator",
        "htmlUrl" : "https://github.com/elementary/calculator",
        "gitUrl" : "git://github.com/elementary/calculator.git",
        "sshUrl" : "git@github.com:elementary/calculator.git",
        "cloneUrl" : "https://github.com/elementary/calculator.git",
        "owner" : {
          "login" : "elementary",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 30,
        "stargazersCount" : 84,
        "watchersCount" : 84,
        "size" : 4270,
        "openIssuesCount" : 28,
        "subscribersCount" : 28,
        "pushedAt" : "2025-07-24T17:07:13Z",
        "languages" : {
          "Meson" : 3008,
          "Vala" : 70506
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the sidebar icons in the Calculator app to use the new icons from Granite.",
      "validationOrRequirement" : "Replace the old icons with the new ones from Granite.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to the use of old icons in the Calculator app, specifically `pane-show-symbolic` and `pane-hide-symbolic`, which should be replaced with `view-sidebar-end-symbolic` from Granite.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407088
  }, {
    "issueDTO" : {
      "id" : 3260552311,
      "title" : "Rename \"Display in Tree\" table option to \"Locate in Tree\" or \"Find in Tree\"",
      "url" : "https://github.com/zowe/zowe-explorer-vscode/issues/3771",
      "repositoryName" : "zowe/zowe-explorer-vscode",
      "description" : "**Is your feature request related to a problem? Please describe.**\n\nCame up during a UX review of the new data sets table view - we should consider renaming the option so its more clear to folks. Since this also exists in the jobs table view, I've separated this request into its own enhancement.\n\n**Describe the solution you'd like**\n\nRename the option \"Display in Tree\" to \"Locate in Tree\" or \"Find in Tree\" (we can decide which is better).\n\n**Describe alternatives you've considered**\n\nKeep it as-is, its not that different from using the locate/find phrasing",
      "updatedAt" : 1753375847.000000000,
      "user" : "traeok",
      "userHtmlUrl" : "https://github.com/traeok",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/86500639?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thank you for raising this enhancement request.\nThe community has 90 days to vote on it.\nIf the enhancement receives at least 10 upvotes, it is added to our development backlog.\nIf it receives fewer votes, the issue is closed." ],
      "repository" : {
        "description" : "Visual Studio Code Extension for Zowe, which lets users interact with z/OS Data Sets, Unix System Services, and Jobs on a remote mainframe instance. Powered by Zowe SDKs.",
        "homepage" : "",
        "name" : "zowe-explorer-vscode",
        "fullName" : "zowe/zowe-explorer-vscode",
        "htmlUrl" : "https://github.com/zowe/zowe-explorer-vscode",
        "gitUrl" : "git://github.com/zowe/zowe-explorer-vscode.git",
        "sshUrl" : "git@github.com:zowe/zowe-explorer-vscode.git",
        "cloneUrl" : "https://github.com/zowe/zowe-explorer-vscode.git",
        "owner" : {
          "login" : "zowe",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 104,
        "stargazersCount" : 178,
        "watchersCount" : 178,
        "size" : 186650,
        "openIssuesCount" : 291,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-25T00:39:02Z",
        "languages" : {
          "TypeScript" : 4549835,
          "CSS" : 7035,
          "Shell" : 362,
          "Rust" : 86533,
          "Gherkin" : 15462,
          "JavaScript" : 24273,
          "HTML" : 3760
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rename the option 'Display in Tree' to 'Locate in Tree' or 'Find in Tree' for clarity",
      "validationOrRequirement" : "rename option, keep it as-is is an alternative",
      "attemptedFixes" : "none",
      "otherNotes" : "Came up during a UX review of the new data sets table view, also exists in the jobs table view",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407090
  }, {
    "issueDTO" : {
      "id" : 3183647611,
      "title" : "Support for Granite-speech-3.3-8b",
      "url" : "https://github.com/nbonamy/witsy/issues/295",
      "repositoryName" : "nbonamy/witsy",
      "description" : "**Is your feature request related to a problem? Please describe.**\nSupport for Granite Speech in the 8b and 2b versions: \n\nhttps://huggingface.co/ibm-granite/granite-speech-3.3-8b\n\nhttps://huggingface.co/ibm-granite/granite-speech-3.3-2b\n\n**Describe the solution you'd like**\nImplement a solution like with the whisper models where the user can download the granite models and use them for Speech To Text. \n\n**Describe alternatives you've considered**\nThe granite models rank first on Open ASR amd are thus better than the currently implemented Whisper models for local transcription.  \n\nhttps://huggingface.co/spaces/hf-audio/open_asr_leaderboard \n\nI have not found an API provider , but asked for one at the huggingface forum. \n\nThe big 8b model has high demand for VRAM but the small one with only 2b should run on most computers. \n\n**Additional context**\nPlease add an emoji under this thread, maybe than we will have an API provider later which would bring Wotsy users the great model independent of their hardware. It will probably be cheap too since it is an open source model. Here the link - please add a rocket: \nhttps://huggingface.co/spaces/huggingface/InferenceSupport/discussions/2927\n\n",
      "updatedAt" : 1753375509.000000000,
      "user" : "MyButtermilk",
      "userHtmlUrl" : "https://github.com/MyButtermilk",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/153296172?v=4",
      "labels" : [ "later", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "According to IBM they are working on an API: https://huggingface.co/ibm-granite/granite-speech-3.3-8b/discussions/9 ", "Granite is now available as API over at Replicate: \nhttps://replicate.com/ibm-granite/granite-speech-3.3-8b \n\nimport Replicate from \"replicate\";\nconst replicate = new Replicate();\n\nconst input = {\n    audio: [\"https://replicate.delivery/pbxt/NMdAjCoC0WiNKkHIIbSsmssPEXujCRSDIjg9LlJYkt5BGs8d/10226_10111_000000.wav\"],\n    prompt: \"Transcribe the speech into written form.\"\n};\n\nfor await (const event of replicate.stream(\"ibm-granite/granite-speech-3.3-8b\", { input })) {\n  process.stdout.write(`${event}`)\n};\n\nor\n\nprediction=$(\n    curl --silent --show-error https://api.replicate.com/v1/models/ibm-granite/granite-speech-3.3-8b/predictions \\\n\t\t\t--request POST \\\n    \t--header \"Authorization: Bearer $REPLICATE_API_TOKEN\" \\\n    \t--header \"Content-Type: application/json\" \\\n    \t--data @- <<'EOM'\n{\n\t\"stream\": true,\n\t\"input\": {\n      \"audio\": [\n        \"https://replicate.delivery/pbxt/NMdAjCoC0WiNKkHIIbSsmssPEXujCRSDIjg9LlJYkt5BGs8d/10226_10111_000000.wav\"\n      ],\n      \"prompt\": \"Transcribe the speech into written form.\"\n\t}\n}\nEOM\n)\n\nstream_url=$(printf \"%s\" \"$prediction\" | jq -r .urls.stream)\n\ncurl --silent --show-error --no-buffer \"$stream_url\" \\\n    --header \"Accept: text/event-stream\" \\\n    --header \"Cache-Control: no-store\"\n\n", "I've been working on trying to locally implement it but having some trouble because apparently it must be in ONNX format to use with nodejs and O3's Python conversion scripts are not working yet.", "Maybe this helps. It is for Voxtral, but the same idea \nhttps://huggingface.co/spaces/webml-community/Voxtral-WebGPU/tree/main" ],
      "repository" : {
        "description" : "Witsy: desktop AI assistant / universal MCP client",
        "homepage" : "https://witsyai.com",
        "name" : "witsy",
        "fullName" : "nbonamy/witsy",
        "htmlUrl" : "https://github.com/nbonamy/witsy",
        "gitUrl" : "git://github.com/nbonamy/witsy.git",
        "sshUrl" : "git@github.com:nbonamy/witsy.git",
        "cloneUrl" : "https://github.com/nbonamy/witsy.git",
        "owner" : {
          "login" : "nbonamy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 109,
        "stargazersCount" : 1334,
        "watchersCount" : 1334,
        "size" : 25357,
        "openIssuesCount" : 16,
        "subscribersCount" : 14,
        "pushedAt" : "2025-07-25T00:47:32Z",
        "languages" : {
          "TypeScript" : 1335524,
          "PowerShell" : 2610,
          "CSS" : 58776,
          "Shell" : 1503,
          "Makefile" : 4262,
          "Vue" : 762287,
          "JavaScript" : 9197,
          "HTML" : 997
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a solution to support Granite Speech in the 8b and 2b versions, allowing users to download the models and use them for Speech To Text.",
      "validationOrRequirement" : "The issue requires implementing a solution similar to Whisper models, and the models must be in ONNX format to use with nodejs. The big 8b model has high demand for VRAM, but the small 2b model should run on most computers.",
      "attemptedFixes" : "The author has been trying to locally implement it but is having trouble because the models must be in ONNX format to use with nodejs and O3's Python conversion scripts are not working yet.",
      "otherNotes" : "The issue is related to adding support for Granite-speech-3.3-8b and 2b versions, with a focus on implementing a solution similar to Whisper models. The models rank first on Open ASR and are considered better than the currently implemented Whisper models for local transcription. The big 8b model has high demand for VRAM, but the small 2b model should run on most computers. IBM is working on an API, and Granite is now available as an API over at Replicate. The issue also mentions local implementation and ONNX format requirements.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407099
  }, {
    "issueDTO" : {
      "id" : 3260428245,
      "title" : "Make `AsyncScalarUDFImpl::invoke_async_with_args` consistent with `ScalarUDFImpl::invoke_with_args` ",
      "url" : "https://github.com/apache/datafusion/issues/16896",
      "repositoryName" : "apache/datafusion",
      "description" : "@findepi noted that `AsyncScalarUDFImpl::invoke_async_with_args` is inconsistent with `ScalarUDFImpl::invoke_async_with_args` \r\n\r\nHere is `AsyncScalarUDFImpl::invoke_async_with_args`:\r\n\r\nhttps://github.com/apache/datafusion/blob/dbc03fa4f6d47c8f3b97f3a3d979945b2b7ccce7/datafusion/expr/src/async_udf.rs#L49-L54\r\n\r\n\r\n`ScalarUDFImpl::invoke_with_args` \r\n\r\nhttps://github.com/apache/datafusion/blob/d553ffdff88ff62fc0cd29d5bb924771e7c6c904/datafusion/expr/src/udf.rs#L557\r\n\r\nSpecifically I think they should both return a `ColumnarValue `\r\n\r\nWhy ArrayRef instead of ColumnarValue?\r\nIs this inconsistency warranted?\r\n\r\n_Originally posted by @findepi in https://github.com/apache/datafusion/pull/16846#discussion_r2221434436_\r\n            ",
      "updatedAt" : 1753375505.000000000,
      "user" : "alamb",
      "userHtmlUrl" : "https://github.com/alamb",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/490673?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "take" ],
      "repository" : {
        "description" : "Apache DataFusion SQL Query Engine",
        "homepage" : "https://datafusion.apache.org/",
        "name" : "datafusion",
        "fullName" : "apache/datafusion",
        "htmlUrl" : "https://github.com/apache/datafusion",
        "gitUrl" : "git://github.com/apache/datafusion.git",
        "sshUrl" : "git@github.com:apache/datafusion.git",
        "cloneUrl" : "https://github.com/apache/datafusion.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1554,
        "stargazersCount" : 7522,
        "watchersCount" : 7522,
        "size" : 153992,
        "openIssuesCount" : 1507,
        "subscribersCount" : 112,
        "pushedAt" : "2025-07-24T20:21:11Z",
        "languages" : {
          "Dockerfile" : 1594,
          "Shell" : 97567,
          "Rust" : 19276492,
          "JavaScript" : 2339,
          "HTML" : 320,
          "Python" : 50415
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Make `AsyncScalarUDFImpl::invoke_async_with_args` consistent with `ScalarUDFImpl::invoke_with_args` by returning a `ColumnarValue` instead of `ArrayRef`",
      "validationOrRequirement" : "inconsistency between `AsyncScalarUDFImpl::invoke_async_with_args` and `ScalarUDFImpl::invoke_with_args` should be fixed",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "Originally posted by @findepi in https://github.com/apache/datafusion/pull/16846#discussion_r2221434436_",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407103
  }, {
    "issueDTO" : {
      "id" : 3260315040,
      "title" : "Refactor codebase to use value parameters instead of pointers where appropriate",
      "url" : "https://github.com/google/go-github/issues/3644",
      "repositoryName" : "google/go-github",
      "description" : "Many methods in the codebase, such as:\n\n```go\n\nfunc (s *RepositoriesService) CreateRelease(ctx context.Context, owner, repo string, release *RepositoryRelease) (*RepositoryRelease, *Response, error)\n```\n\nuse pointer parameters (e.g. `*RepositoryRelease`) even when the function doesn't mutate the input. This appears to be a result of convention or copy-paste, not a performance-driven choice.\n\nFor instance, in `CreateRelease`, the `RepositoryRelease` struct is relatively large (~15+ fields), but most of its fields are pointers themselves. As such, passing it by value would have negligible performance impact in typical API usage. Moreover, value semantics would improve clarity, especially for required arguments that aren't modified.\n\nTo improve API design consistency and safety, we should:\n\n- Audit method signatures that accept pointer structs as input\n- Change them to accept values when:\n\n  - The input is required (not optional)\n\n  - The function does not modify the input\n\n- Optionally introduce dedicated input structs for specific operations (e.g. `CreateRepositoryRelease` with only the fields needed for creation)\n\nNote: This would be a breaking change and should be handled carefully, possibly across multiple PRs.\n\n_Originally posted by @gmlewis in https://github.com/google/go-github/pull/3636#discussion_r2228429223_\n            ",
      "updatedAt" : 1753375358.000000000,
      "user" : "alexandear",
      "userHtmlUrl" : "https://github.com/alexandear",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3228886?v=4",
      "labels" : [ "enhancement", "Breaking API Change", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Go library for accessing the GitHub v3 API",
        "homepage" : "https://pkg.go.dev/github.com/google/go-github/v74/github",
        "name" : "go-github",
        "fullName" : "google/go-github",
        "htmlUrl" : "https://github.com/google/go-github",
        "gitUrl" : "git://github.com/google/go-github.git",
        "sshUrl" : "git@github.com:google/go-github.git",
        "cloneUrl" : "https://github.com/google/go-github.git",
        "owner" : {
          "login" : "google",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2146,
        "stargazersCount" : 10867,
        "watchersCount" : 10867,
        "size" : 9897,
        "openIssuesCount" : 36,
        "subscribersCount" : 209,
        "pushedAt" : "2025-07-24T19:03:11Z",
        "languages" : {
          "Shell" : 4009,
          "Go" : 4692832
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor codebase to use value parameters instead of pointers where appropriate, improve API design consistency and safety",
      "validationOrRequirement" : "Audit method signatures, change to accept values when input is required and not modified, introduce dedicated input structs for specific operations",
      "attemptedFixes" : "Audit method signatures, change them to accept values when input is required and not modified, optionally introduce dedicated input structs",
      "otherNotes" : "This would be a breaking change and should be handled carefully, possibly across multiple PRs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407106
  }, {
    "issueDTO" : {
      "id" : 3125691879,
      "title" : "Switch to `uv`",
      "url" : "https://github.com/tqec/tqec/issues/607",
      "repositoryName" : "tqec/tqec",
      "description" : "Since we are working towards utilizing `ruff` and `ty` from Astral in #589 and #585, it would be better to completely migrate towards the entire toolchain. \n\n`uv` is designed to replace `pip`, `poetry`, `virtualenv`, etc. For more, see https://docs.astral.sh/uv/\n\nNote that this also requires updating the various CI/CD workflows in `.github/workflows`. Once this project relies on `uv`, we also want to ensure the readme, installation, and contributing guides in the documentation are updated accordingly. ",
      "updatedAt" : 1753375167.000000000,
      "user" : "purva-thakre",
      "userHtmlUrl" : "https://github.com/purva-thakre",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/66048318?v=4",
      "labels" : [ "non-quantum", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Design automation software tools for Topological Quantum Error Correction",
        "homepage" : "https://tqec.github.io/tqec/",
        "name" : "tqec",
        "fullName" : "tqec/tqec",
        "htmlUrl" : "https://github.com/tqec/tqec",
        "gitUrl" : "git://github.com/tqec/tqec.git",
        "sshUrl" : "git@github.com:tqec/tqec.git",
        "cloneUrl" : "https://github.com/tqec/tqec.git",
        "owner" : {
          "login" : "tqec",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 69,
        "stargazersCount" : 260,
        "watchersCount" : 260,
        "size" : 58799,
        "openIssuesCount" : 53,
        "subscribersCount" : 14,
        "pushedAt" : "2025-07-22T09:21:37Z",
        "languages" : {
          "Shell" : 2321,
          "Python" : 1418400
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Switch to `uv` to replace `pip`, `poetry`, `virtualenv`, etc. and utilize `ruff` and `ty` from Astral",
      "validationOrRequirement" : "completely migrate towards the entire toolchain, updating CI/CD workflows and documentation",
      "attemptedFixes" : "",
      "otherNotes" : "This issue is related to #589 and #585, and requires updating CI/CD workflows in .github/workflows, as well as updating the readme, installation, and contributing guides in the documentation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407110
  }, {
    "issueDTO" : {
      "id" : 3109130517,
      "title" : "[Remove Vuetify from Studio] 'Request more space' form error banner in Settings - Storage",
      "url" : "https://github.com/learningequality/studio/issues/5082",
      "repositoryName" : "learningequality/studio",
      "description" : "<!---HEADER START-->\n\n<img height=\"20px\" src=\"https://i.imgur.com/0ZZG9qx.jpeg\">\n\n\uD83D\uDE42 Looking for an issue? Welcome! This issue is open for contribution. If this is the first time you???re requesting an issue, please:\n\n- **Read <a href=\"https://learningequality.org/contributing-to-our-open-code-base/\" target=\"_blank\">Contributing guidelines</a>** carefully. **Pay extra attention to [Using generative AI](https://learningequality.org/contributing-to-our-open-code-base/#using-generative-ai)**. **Pull requests and comments that don???t follow the guidelines won???t be answered.**\n- **Confirm that you???ve read the guidelines** in your comment.\n\n<img height=\"20px\" src=\"https://i.imgur.com/0ZZG9qx.jpeg\">\n\n<!---HEADER END-->\n\n\nSub-issue of https://github.com/learningequality/studio/issues/5060.\n\n**Complexity: Low**\n\n## Summary\n\nRemove Vuetify from 'Request more space' form error banner in _Settings > Storage_.\n\n![Image](https://github.com/user-attachments/assets/409292e5-860f-4a8f-b3df-5f01246f0dd9)\n\n\n`shared/views/Banner` that is built with Vuetify components is used for the banner. To remove this dependency from `Storage/RequestForm`, **create a new `shared/views/StudioBanner` component that doesn't use Vuetify. Then use `StudioBanner` in `Storage/RequestForm` instead of `Banner`. Do not modifify `shared/views/Banner`.**\n\n**`StudioBanner` requirements**\n\n- Expected usage example:\n\n```vue\n// RequestForm.vue\n\n<StudioBanner\n  v-if=\"Boolean(errorCount())\"\n  error\n>\n  {{ errorText() }}\n</StudioBanner>\n```\n\n- Interface and implementation doesn't map exactly to that of `Banner`, and is limited only to logic that is needed for the request form\n- [KDS theme `palette.red.v_100`](https://design-system.learningequality.org/colors#palette-red-v_100) is used for red background color\n- Dynamic error display is preserved: If the banner is showing 9 errors, and then one of them is fixed, the banner immediatelly shows there is 8 errors, even before re-submitting the form.\n\n## How to get there\n\n- Login as `user@a.com` with password `a`\n- Go to _Settings > Storage_\n- In _'Request more space'_ section, click _'Open form'_ button\n- Submit the form without filling required fields\n\n## Guidance\n\n- Read [the project](https://github.com/learningequality/studio/issues/5060) this issue is part of\n\n## Out of Scope\n\n- Do not refactor any other areas of the codebase\n- Do not modify `Banner`\n- Do not migrate all `Banner` logic to `StudioBanner`. Focus on areas that are needed for this particular place and as specified above.\n\n## Expected UI/UX changes\n\n- Minor visual differences naturally stemming from the use of KDS\n  - Very slightly different shade of red \n\n## Acceptance criteria\n\n**General**\n\n- [ ] The specification above is followed.\n- [ ] Except for \"Expected UI/UX changes,\" there are no functional or visual differences in user experience.\n- [ ] All user interactions are manually tested with no regressions.\n- [ ] Pull request includes screenshots.\n\n**a11y and i18n**\n\nSee [the project](https://github.com/learningequality/studio/issues/5060)'s \"Guidance\" for useful references.\n\n- [ ] Implementation meets a11y standards\n- [ ] All components are LTR and RTL compliant\n- [ ] All user-facing strings are translated properly\n- [ ] The `notranslate` class been added to elements that shouldn't be translated by Google Chrome's automatic translation feature (e.g. user-generated text)\n- [ ] Mobile experience is reasonable\n\n**Unit tests**\n- [ ] If there is a unit test suite already, it is meaningfully updated (even if tests don't fail)\n- [ ] If there is no unit test suite, a new one is created. Do not use obsolete `@vue/test-utils` approach. Instead, use [Vue Testing Library](https://kolibri-dev.readthedocs.io/en/develop/frontend_architecture/unit_testing.html).",
      "updatedAt" : 1753374665.000000000,
      "user" : "MisRob",
      "userHtmlUrl" : "https://github.com/MisRob",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13509191?v=4",
      "labels" : [ "help wanted", "DEV: frontend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello maintainers, \nI???ve read the contributing guidelines and would like to work on this issue. Please assign it to me.\nThanks! \uD83D\uDE42", "Lovely, thanks! Assigning now.", "Thanks a lot @MisRob ???it's now assigned \uD83D\uDE42!", "Hi @MisRob \uD83D\uDC4B,\n\nI've opened a PR to address this issue: #5091 \n\n- ??? Implemented `StudioBanner.vue` without Vuetify\n\n- ??? Replaced Vuetify `Banner` in `RequestForm.vue`\n\n- ??? Added unit test: `studioBanner.spec.js`\n\n- ??? Included screenshots and verified dynamic behavior\n\n- ??? Followed all [Contributing Guidelines](https://github.com/learningequality/studio/blob/develop/CONTRIBUTING.md)\n\nPlease let me know if any changes are needed.\nThank you.", "Thanks @NihalShinde4933, we will review", "Hi @MisRob \nI'd like to propose adding a banner component to KDS, which would support types like default, error, information, and warning. We could then utilize this component across the applications." ],
      "repository" : {
        "description" : "Content curation tools for Kolibri",
        "homepage" : "https://studio.learningequality.org/",
        "name" : "studio",
        "fullName" : "learningequality/studio",
        "htmlUrl" : "https://github.com/learningequality/studio",
        "gitUrl" : "git://github.com/learningequality/studio.git",
        "sshUrl" : "git@github.com:learningequality/studio.git",
        "cloneUrl" : "https://github.com/learningequality/studio.git",
        "owner" : {
          "login" : "learningequality",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 213,
        "stargazersCount" : 142,
        "watchersCount" : 142,
        "size" : 225996,
        "openIssuesCount" : 344,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-24T15:15:10Z",
        "languages" : {
          "Dockerfile" : 2211,
          "CSS" : 13352,
          "Shell" : 5274,
          "Gherkin" : 141136,
          "SCSS" : 253848,
          "Makefile" : 8225,
          "JavaScript" : 1739088,
          "Vue" : 1413426,
          "Mustache" : 3769,
          "HTML" : 261490,
          "Python" : 2367899
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove Vuetify from 'Request more space' form error banner in Settings > Storage, create a new `shared/views/StudioBanner` component that doesn't use Vuetify, and use `StudioBanner` in `Storage/RequestForm` instead of `Banner`.",
      "validationOrRequirement" : "The requirements for `StudioBanner` are: expected usage example, interface and implementation, limited to logic needed for the request form, using KDS theme `palette.red.v_100` for red background color, and dynamic error display. The `StudioBanner` should not be refactored to match the exact implementation of `Banner`.",
      "attemptedFixes" : "A PR #5091 has been opened to address this issue, which includes implementing `StudioBanner.vue` without Vuetify, replacing Vuetify `Banner` in `RequestForm.vue`, adding unit test, including screenshots, and verifying dynamic behavior.",
      "otherNotes" : "This issue is open for contribution, please follow the contributing guidelines and confirm that you've read them in your comment. This issue is a sub-issue of #5060. The complexity of this issue is low.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407117
  }, {
    "issueDTO" : {
      "id" : 2449294109,
      "title" : "argocd.argoproj.io/auto-label-cluster-info doesn't work on eks clusters",
      "url" : "https://github.com/argoproj/argo-cd/issues/19385",
      "repositoryName" : "argoproj/argo-cd",
      "description" : "**Describe the bug**\r\n\r\nWhen labeling cluster secretes with `argocd.argoproj.io/auto-label-cluster-info=true` `argocd.argoproj.io/kubernetes-version` does not get set on EKS clusters because the minor version reported by the api server ends in a `+`. eg `29+`\r\n\r\n**To Reproduce**\r\n\r\nLabel a cluster secret with `argocd.argoproj.io/auto-label-cluster-info=true`\r\n\r\n**Expected behavior**\r\n\r\nArgo should add the `argocd.argoproj.io/kubernetes-version` label automatically with the clusters k8s version\r\n\r\n**Version**\r\n\r\n```shell\r\nargocd: v2.11.4+e1284e1\r\n  BuildDate: 2024-07-02T23:16:22Z\r\n  GitCommit: e1284e19e03c9abab2ea55314b14b1e0381c4045\r\n  GitTreeState: clean\r\n  GoVersion: go1.22.4\r\n  Compiler: gc\r\n  Platform: darwin/arm64\r\nargocd-server: v2.11.4+e1284e1\r\n  BuildDate: 2024-07-02T19:17:02Z\r\n  GitCommit: e1284e19e03c9abab2ea55314b14b1e0381c4045\r\n  GitTreeState: clean\r\n  GoVersion: go1.21.10\r\n  Compiler: gc\r\n  Platform: linux/amd64\r\n  Kustomize Version: v5.2.1 2023-10-19T20:13:51Z\r\n  Helm Version: v3.14.4+g81c902a\r\n  Kubectl Version: v0.26.11\r\n  Jsonnet Version: v0.20.0\r\n```\r\n\r\n",
      "updatedAt" : 1753374607.000000000,
      "user" : "charles-teese-telestream",
      "userHtmlUrl" : "https://github.com/charles-teese-telestream",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/161481914?v=4",
      "labels" : [ "type:bug", "component:argo-cd", "bug", "version:2.11", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Maybe worth a `good-first-issue` label? Selfishly waiting for a fix, having to do this manually after upgrades is a pain and has a risk of being missed.  Now that this is baked into some app/appset configs I'm managing. \uD83D\uDE2C ", "Hi, I???m interested in working on this. Could you please assign it to me or let me know if someone is already working on it? Thanks!", "@shadimani-msys feel free to work on it, I don't currently have the time to do so", "@shadimani-msys Any updates? \n", "@BHAVISHYA2005 are you interested to work on this?\n\nAlso,  reading the issue description it looks like the issue might be related to how we are handling the kubeversion.  \n\nhttps://github.com/argoproj/argo-cd/pull/22650", "Yes , I'd be glad to take it on.", "@BHAVISHYA2005 Working on it ??? delayed as I was held up with another task.\n", "Reproduction Attempt and Findings\nHi team  ??? I attempted to reproduce this issue using a newer EKS version and recent Argo CD versions. Here are my findings:\n\nEnvironment Details\n```\nArgo CD CLI version: v2.14.11+8283115\n\nArgo CD Server version: v2.14.6+fe2a6e9\n```\n\n\nEKS Kubernetes version:\n\n```\n {\n  \"major\": \"1\",\n  \"minor\": \"32\",\n  \"gitVersion\": \"v1.32.3-eks-4096722\",\n  \"platform\": \"linux/amd64\"\n}\n\n```\n\nCluster added using:\n\n` argocd cluster add arn:aws:eks:us-east-1:---------:cluster/Test`\n\n\n\nSteps Taken\nCreated an EKS cluster with version 1.32.\n\n\nInstalled Argo CD and accessed via port-forward.\n\nLogged in with:\n\n` argocd login localhost:8080 --username admin --password <password> --insecure`\n\nAdded the EKS cluster using the argocd cluster add command.\n\nLabeled the secret with:\n\n` kubectl -n argocd label secret <cluster-secret-name> argocd.argoproj.io/auto-label-cluster-info=true --overwrite`\n\nInspected the cluster secret labels using:\n\n` kubectl -n argocd get secret <cluster-secret-name> -o json | jq '.metadata.labels'`\n\n\nObservations\nThe \"minor\" version string returned by the API was \"32\" ??? no + character present.\n\n\nHowever, the secret did not get the expected label `argocd.argoproj.io/kubernetes-version.`\n\n\nThe labels observed were:\n\n```\n {\n  \"argocd.argoproj.io/auto-label-cluster-info\": \"true\",\n  \"argocd.argoproj.io/secret-type\": \"cluster\"\n}\n\n```\nImplication\nThis suggests the issue may not be limited to minor versions with a trailing +, as originally described. The label argocd.argoproj.io/kubernetes-version was still not set even when the version string was clean (\"32\"), indicating a possible regression or change in behavior in more recent Argo CD versions (2.14.x+).\n\n@charles-teese-telestream As per the observations above ,Can you please give me a suggestions.\n\n\n\n\n", "Hi @nitishfy  We are not able to reproduce the issue \n\n# Steps taken\n\nThis document details the steps to reproduce the issue, but we are not able to reproduce the same once the app is deployed via argocd.\n\n## Prerequisites\n\n- AWS CLI installed and configured\n- kubectl installed\n- Access to AWS EKS cluster\n\n## Environment Setup\n\nCheck AWS CLI version:\n\n```bash\nroot@master-node:~# aws --version\naws-cli/2.15.21 Python/3.11.6 Linux/5.15.0-122-generic exe/x86_64.ubuntu.20 prompt/off\n```\n\nAWS credentials configuration in ~/.bashrc:\n\n```bash\nroot@master-node:~# cat ~/.bashrc | grep AWS\nexport AWS_ACCESS_KEY_ID=<Your Access KeyID>\nexport AWS_SECRET_ACCESS_KEY=<Your Secret Access Key>\n```\n\n## Kubernetes Configuration\n\nCheck current Kubernetes context:\n\n```bash\nroot@master-node:~# kubectl config get-contexts\nCURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE\n*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin\n```\n\nUpdate kubeconfig to use EKS cluster:\n\n```bash\nroot@master-node:~# aws eks update-kubeconfig  --region ap-south-1 --name my-eks-cluster --kubeconfig ~/eks-config\nAdded new context arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster to /root/eks-config\n```\n\nVerify contexts (still showing the original context):\n\n```bash\nroot@master-node:~# kubectl config get-contexts\nCURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE\n*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin\nroot@master-node:~#\n```\n\nSet KUBECONFIG environment variable to use the EKS config:\n\n```bash\nroot@master-node:~# export KUBECONFIG=/root/eks-config\n```\n\nVerify context is now set to EKS:\n\n```bash\nroot@master-node:~# kubectl config get-contexts\nCURRENT   NAME                                                         CLUSTER                                                      AUTHINFO                                                     NAMESPACE\n*         arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster   arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster   arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster\n```\n\n## Cluster Verification\n\nCheck pods across all namespaces:\n\n```bash\nroot@master-node:~# kubectl get pods -A\nNAMESPACE     NAME                           READY   STATUS    RESTARTS   AGE\nkube-system   aws-node-vdpq5                 2/2     Running   0          6m6s\nkube-system   coredns-6799d65cb-njvv4        1/1     Running   0          7m9s\nkube-system   coredns-6799d65cb-qfjmh        1/1     Running   0          7m9s\nkube-system   eks-pod-identity-agent-6jw4m   1/1     Running   0          6m6s\nkube-system   kube-proxy-6w9gd               1/1     Running   0          6m6s\n```\n\nCheck nodes:\n\n```bash\nroot@master-node:~# kubectl get nodes\nNAME                                           STATUS   ROLES    AGE   VERSION\nip-172-31-19-158.ap-south-1.compute.internal   Ready    <none>   93s   v1.32.3-eks-473151a\nip-172-31-35-36.ap-south-1.compute.internal    Ready    <none>   31m   v1.32.3-eks-473151a\n```\n\n## ArgoCD Installation\n\nCreate ArgoCD namespace:\n\n```bash\nroot@master-node:~# kubectl create namespace argocd\nnamespace/argocd created\n```\n\nInstall ArgoCD:\n\n```bash\nroot@master-node:~# kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/v2.11.4/manifests/install.yaml\ncustomresourcedefinition.apiextensions.k8s.io/applications.argoproj.io created\ncustomresourcedefinition.apiextensions.k8s.io/applicationsets.argoproj.io created\ncustomresourcedefinition.apiextensions.k8s.io/appprojects.argoproj.io created\nserviceaccount/argocd-application-controller created\nserviceaccount/argocd-applicationset-controller created\nserviceaccount/argocd-dex-server created\nserviceaccount/argocd-notifications-controller created\nserviceaccount/argocd-redis created\nserviceaccount/argocd-repo-server created\nserviceaccount/argocd-server created\nrole.rbac.authorization.k8s.io/argocd-application-controller created\nrole.rbac.authorization.k8s.io/argocd-applicationset-controller created\n............................\n```\n\nVerify ArgoCD pods:\n\n```bash\nroot@master-node:~# kubectl get pods -n argocd\nNAME                                                READY   STATUS    RESTARTS   AGE\nargocd-application-controller-0                     1/1     Running   0          1m\nargocd-applicationset-controller-67cd76f67c-4k4r2   1/1     Running   0          2m\nargocd-dex-server-86c6559749-9l7j2                  1/1     Running   0          2m\nargocd-notifications-controller-9fddc77fc-lgxlg     1/1     Running   0          2m\nargocd-redis-74f7455b85-pjd7t                       1/1     Running   0          2m\nargocd-repo-server-8c9f5b79f-h4b5r                  1/1     Running   0          2m\nargocd-server-85f5dbf8-tvscg                        1/1     Running   0          2m\n```\n\n## ArgoCD CLI Setup\n\nDownload ArgoCD CLI:\n\n```bash\nroot@master-node:~# curl -sSL -o argocd https://github.com/argoproj/argo-cd/releases/download/v2.11.4/argocd-linux-amd64\n```\n\nVerify download:\n\n```bash\nroot@master-node:~# ls -la | grep argocd\n-rw-r--r--  1 root root 162150482 May 19 13:24 argocd\n```\n\nCurrent date:\n\n```bash\nroot@master-node:~# date\nMonday 19 May 2025 01:24:17 PM IST\n```\n\nMake ArgoCD CLI executable and move to PATH:\n\n```bash\nroot@master-node:~# chmod +x argocd\nroot@master-node:~# sudo mv argocd /usr/local/bin/\n```\n\nCheck ArgoCD version:\n\n```bash\nroot@master-node:~# argocd version\nargocd: v2.11.4+e1284e1\n  BuildDate: 2024-07-02T19:36:34Z\n  GitCommit: e1284e19e03c9abab2ea55314b14b1e0381c4045\n  GitTreeState: clean\n  GoVersion: go1.21.11\n  Compiler: gc\n  Platform: linux/amd64\nFATA[0000] Failed to establish connection to localhost:8084: dial tcp 127.0.0.1:8084: connect: connection refused\n```\n\n## ArgoCD Server Access\n\nStart port forwarding to access ArgoCD server:\n\n```bash\nroot@master-node:~# kubectl port-forward svc/argocd-server -n argocd 8084:443\nForwarding from 127.0.0.1:8084 -> 8080\nForwarding from [::1]:8084 -> 8080\nHandling connection for 8084\nHandling connection for 8084\n```\n\n## Terminal 2: ArgoCD Configuration\n\nSet KUBECONFIG environment variable:\n\n```bash\nroot@master-node:~# export KUBECONFIG=/root/eks-config\n```\n\nVerify context:\n\n```bash\nroot@master-node:~# kubectl config get-contexts\nCURRENT   NAME                                                         CLUSTER                                                      AUTHINFO                                                     NAMESPACE\n*         arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster   arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster   arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster\n```\n\nCheck ArgoCD version:\n\n```bash\nroot@master-node:~# argocd version\nargocd: v2.11.4+e1284e1\n  BuildDate: 2024-07-02T19:36:34Z\n  GitCommit: e1284e19e03c9abab2ea55314b14b1e0381c4045\n  GitTreeState: clean\n  GoVersion: go1.21.11\n  Compiler: gc\n  Platform: linux/amd64\nargocd-server: v2.11.4+e1284e1\n```\n\nGet ArgoCD admin password:\n\n```bash\nroot@master-node:~# kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath=\"{.data.password}\" | base64 -d\n-ZuGHO12l2MKXzb0root@master-node:~#\n```\n\nLogin to ArgoCD:\n\n```bash\nroot@master-node:~# argocd login localhost:8084 --username admin --password -ZuGHO12l2MKXzb0 --insecure\n'admin:login' logged in successfully\nContext 'localhost:8084' updated\n```\n\nList clusters:\n\n```bash\nroot@master-node:~# argocd cluster list\nSERVER                          NAME        VERSION  STATUS  MESSAGE  PROJECT\nhttps://kubernetes.default.svc  in-cluster\n```\n\nVerify context again:\n\n```bash\nroot@master-node:~# kubectl config get-contexts\nCURRENT   NAME                                                         CLUSTER                                                      AUTHINFO                                                     NAMESPACE\n*         arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster   arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster   arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster\n```\n\nAdd EKS cluster to ArgoCD:\n\n```bash\nroot@master-node:~# argocd cluster add arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster\nWARNING: This will create a service account `argocd-manager` on the cluster referenced by context `arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster` with full cluster level privileges. Do you want to continue [y/N]? y\nINFO[0003] ServiceAccount \"argocd-manager\" created in namespace \"kube-system\"\nINFO[0003] ClusterRole \"argocd-manager-role\" created\nINFO[0003] ClusterRoleBinding \"argocd-manager-role-binding\" created\nINFO[0008] Created bearer token secret for ServiceAccount \"argocd-manager\"\nCluster 'https://0DC1AC3870140A19C1376067B1796445.gr7.ap-south-1.eks.amazonaws.com' added\n```\n\nVerify clusters:\n\n```bash\nroot@master-node:~# argocd cluster list\nSERVER                                                                     NAME                                                        VERSION  STATUS      MESSAGE                                                  PROJECT\nhttps://0DC1AC3870140A19C1376067B1796445.gr7.ap-south-1.eks.amazonaws.com  arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster           Unknown     Cluster has no applications and is not being monitored.\nhttps://kubernetes.default.svc                                             in-cluster                                                  1.32     Successful\n```\n\nCheck ArgoCD API resources:\n\n```bash\nroot@master-node:~# kubectl api-resources | grep argo\napplications                        app,apps           argoproj.io/v1alpha1              true         Application\napplicationsets                     appset,appsets     argoproj.io/v1alpha1              true         ApplicationSet\nappprojects                         appproj,appprojs   argoproj.io/v1alpha1              true         AppProject\n```\n\n## Create ArgoCD Application\n\nApplication YAML file:\n\n```bash\nroot@master-node:~# cat argocd_app.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: first-argocd-demo-app\n  namespace: argocd\nspec:\n  project: default\n\n  source:\n    repoURL: https://github.com/anveshmuppeda/argo-cd-demo\n    targetRevision: HEAD\n    path: development\n\n  destination:\n    server: https://0DC1AC3870140A19C1376067B1796445.gr7.ap-south-1.eks.amazonaws.com\n    namespace: argocd-demo\n\n  syncPolicy:\n    syncOptions:\n    - CreateNamespace=true\n\n    automated:\n      selfHeal: true\n      prune: true\n```\n\nCheck cluster secret labels:\n\n```bash\nroot@master-node:~# kubectl -n argocd get secrets | grep cluster\ncluster-0dc1ac3870140a19c1376067b1796445.gr7.ap-south-1.eks.amazonaws.com-1205810769   Opaque   3      20m\n\nroot@master-node:~# kubectl -n argocd get secret cluster-0dc1ac3870140a19c1376067b1796445.gr7.ap-south-1.eks.amazonaws.com-1205810769 -o json | jq '.metadata.labels'\n{\n  \"argocd.argoproj.io/secret-type\": \"cluster\"\n}\n```\n\nCheck for existing applications:\n\n```bash\nroot@master-node:~# kubectl get apps -n argocd\nNo resources found in argocd namespace.\n```\n\nCreate ArgoCD application:\n\n```bash\nroot@master-node:~# kubectl create -f argocd_app.yaml\napplication.argoproj.io/first-argocd-demo-app created\n```\n\nMonitor application status:\n\n```bash\nroot@master-node:~# kubectl get apps -n argocd -w\nNAME                    SYNC STATUS   HEALTH STATUS\nfirst-argocd-demo-app   Synced        Healthy\n^C\n```\n\nVerify clusters again:\n\n```bash\nroot@master-node:~#  argocd cluster list\nSERVER                                                                     NAME                                                        VERSION  STATUS      MESSAGE  PROJECT\nhttps://0DC1AC3870140A19C1376067B1796445.gr7.ap-south-1.eks.amazonaws.com  arn:aws:eks:ap-south-1:<Account ID>:cluster/my-eks-cluster  1.32     Successful\nhttps://kubernetes.default.svc                                             in-cluster                                                  1.32     Successful\n```\n\nCheck cluster secret labels again:\n\n```bash\nroot@master-node:~# kubectl -n argocd get secret cluster-0dc1ac3870140a19c1376067b1796445.gr7.ap-south-1.eks.amazonaws.com-1205810769 -o json | jq '.metadata.labels'\n{\n  \"argocd.argoproj.io/secret-type\": \"cluster\"\n}\n```\n\nAdd auto-label to cluster secret:\n\n```bash\nroot@master-node:~# kubectl label secret cluster-0dc1ac3870140a19c1376067b1796445.gr7.ap-south-1.eks.amazonaws.com-1205810769 -n argocd argocd.argoproj.io/auto-label-cluster-info=true\nsecret/cluster-0dc1ac3870140a19c1376067b1796445.gr7.ap-south-1.eks.amazonaws.com-1205810769 labeled\n```\n\nVerify label was added:\n\n```bash\nroot@master-node:~# kubectl -n argocd get secret cluster-0dc1ac3870140a19c1376067b1796445.gr7.ap-south-1.eks.amazonaws.com-1205810769 -o json | jq '.metadata.labels'\n{\n  \"argocd.argoproj.io/auto-label-cluster-info\": \"true\",\n  \"argocd.argoproj.io/secret-type\": \"cluster\"\n}\n```\n\nCheck labels again (after auto-labeling took effect):\n\n```bash\nroot@master-node:~# kubectl -n argocd get secret cluster-0dc1ac3870140a19c1376067b1796445.gr7.ap-south-1.eks.amazonaws.com-1205810769 -o json | jq '.metadata.labels'\n{\n  \"argocd.argoproj.io/auto-label-cluster-info\": \"true\",\n  \"argocd.argoproj.io/kubernetes-version\": \"1.32\",\n  \"argocd.argoproj.io/secret-type\": \"cluster\"\n}\n```\n\nAction:\nGood to close this issue, If our findings are right.\n", "@shadimani-msys some context to possibly help with your investigation. We are also seeing this on some EKS clusters which need updating. They are currently running on kubernetes version 1.30, whereas your testing ran on an up-to-date 1.32 which might be why you're struggling to replicate?\n\nLogs from our application controller:\n```\nFailed to update cluster labels: Secret \\\"cluster-abc\\\" is invalid: metadata.labels: Invalid value: \\\"1.30+\\\": a valid label must be an empty string or consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyValue',  or 'my_value',  or '12345', regex used for validation is '(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])?')\n```\n\nIf possible, repeating your exercise but deliberately setting the kubernetes version to 1.30 might help replicate the issue.", "I can confirm, aws seems to have fixed their version reporting in 1.31 or 1.32. So this is only an issue for EKS clusters <=1.30." ],
      "repository" : {
        "description" : "Declarative Continuous Deployment for Kubernetes",
        "homepage" : "https://argo-cd.readthedocs.io",
        "name" : "argo-cd",
        "fullName" : "argoproj/argo-cd",
        "htmlUrl" : "https://github.com/argoproj/argo-cd",
        "gitUrl" : "git://github.com/argoproj/argo-cd.git",
        "sshUrl" : "git@github.com:argoproj/argo-cd.git",
        "cloneUrl" : "https://github.com/argoproj/argo-cd.git",
        "owner" : {
          "login" : "argoproj",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 6209,
        "stargazersCount" : 20156,
        "watchersCount" : 20156,
        "size" : 138292,
        "openIssuesCount" : 3717,
        "subscribersCount" : 183,
        "pushedAt" : "2025-07-24T14:26:52Z",
        "languages" : {
          "CSS" : 2209,
          "Procfile" : 10164,
          "Makefile" : 25368,
          "Go" : 7193080,
          "Mustache" : 1066,
          "HTML" : 895,
          "TypeScript" : 1356519,
          "Dockerfile" : 15719,
          "Shell" : 61221,
          "Starlark" : 6864,
          "SCSS" : 98248,
          "JavaScript" : 6255,
          "Lua" : 261518
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about argocd.argoproj.io/auto-label-cluster-info not working on EKS clusters due to minor version reporting.",
      "validationOrRequirement" : "The issue seems to be related to how Argo CD handles the kubeversion. The label argocd.argoproj.io/kubernetes-version was not set even when the version string was clean. The issue is not limited to minor versions with a trailing +, as originally described.",
      "attemptedFixes" : "The issue was reproduced by creating an EKS cluster with version 1.32 and running Argo CD on it. The auto-labeling feature was tried but it did not work. The issue was also reproduced by setting the Kubernetes version to 1.30. The logs from the application controller showed an error message saying that the secret is invalid due to an invalid label.",
      "otherNotes" : "The issue is about argocd.argoproj.io/auto-label-cluster-info not working on EKS clusters due to minor version reporting. The issue seems to be related to how Argo CD handles the kubeversion. The label argocd.argoproj.io/kubernetes-version was not set even when the version string was clean. The issue is not limited to minor versions with a trailing +, as originally described. The auto-labeling feature does not work on EKS clusters <=1.30 due to AWS's version reporting.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407127
  }, {
    "issueDTO" : {
      "id" : 3256824623,
      "title" : "[BUG] Snapshot % complete calculate is incorrect",
      "url" : "https://github.com/opensearch-project/opensearch-migrations/issues/1687",
      "repositoryName" : "opensearch-project/opensearch-migrations",
      "description" : "### What is the bug?\nWhen we use the migration assistant to take create a snapshot via `console snapshot create`, the percent completed stat from the `status` command are incorrectly computed under the following circumstances:\n\n- a previous snapshot already exists (eg. `ma-snapshot-1`)\n- the snapshot that is being created is an incremental one (eg. `ma-snapshot-2`)\n\n\n### What are your migration environments?\nOpensearch 2.17\n\n### How can one reproduce the bug?\n- create a snapshot using the migration assistant \n- update the snapshot config to change the snapshot name (so that we can take another incremental snapshot)\n- create a snapshot using the migration assistant a second time\n- check the progress using `console snapshot status --deep-check`\n- the output should be as follows (which is incorrect)\n```\nSUCCESS\nSnapshot is SUCCESS.\nPercent completed: 16.40%\nData GiB done: 56.060/341.817\nTotal shards: 747\nSuccessful shards: 747\nFailed shards: 0\nStart time: 2025-07-23 15:07:44\nDuration: 0h 2m 58s\nAnticipated duration remaining: 0h 15m 12s\nThroughput: 320.84 MiB/sec\n```\n\n### What is the expected behavior?\nThe expected behavior should be that the % completion should be 100% as evident from the opensearch APIs:\n\n```\nGET _snapshot/migration_assistant_repo/ma-snapshot-2/_status\n\n# excluding unnecessary fields\n\n{\n  \"snapshots\": [\n    {\n      \"state\": \"SUCCESS\",\n      \"include_global_state\": true,\n      \"shards_stats\": {\n        \"initializing\": 0,\n        \"started\": 0,\n        \"finalizing\": 0,\n        \"done\": 747,\n        \"failed\": 0,\n        \"aborted\": 0,\n        \"total\": 747\n      },\n      \"stats\": {\n        \"incremental\": {\n          \"file_count\": 3896,\n          \"size_in_bytes\": 60194325053\n        },\n        \"total\": {\n          \"file_count\": 36365,\n          \"size_in_bytes\": 367023410293\n        },\n        \"start_time_in_millis\": 1753283264535,\n        \"time_in_millis\": 178921\n      }\n    }\n  ]\n}\n```\n\n### Do you have any additional context?\nWe should compute the progress from the incremental stats if present.",
      "updatedAt" : 1753374549.000000000,
      "user" : "sudosaket",
      "userHtmlUrl" : "https://github.com/sudosaket",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7578512?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @sudosaket, thank you for reporting this and for the clear reproduction steps!\n\nYou???re right, this is a great catch. When dealing with incremental snapshots, the current progress computation in `console snapshot status --deep-check` doesn???t account for the consecutive nature of the operation. As you???ve pointed out, although the OpenSearch APIs show the snapshot has completed successfully with all shards done, the Migration Assistant CLI still reports incomplete progress due to relying on total snapshot size instead of incremental stats.\n\nI???ve also added a dedicated [task](https://opensearch.atlassian.net/browse/MIGRATIONS-2655) within our internal [Jira Epic](https://opensearch.atlassian.net/browse/MIGRATIONS-2531) to fix this specific progress reporting issue by switching to the incremental snapshot statistics when available.\n\nHaving said that, it is going to be a lower priority fix at this point because user experience is going to change soon with the [Delta Snapshots](https://github.com/opensearch-project/opensearch-migrations/issues/1452) update.", "Sounds good! This update is scheduled for within 3 months?", "@sudosaket Thanks for creating this issue, there could definitely be improvements here.  If you wanted to see an update sooner, what do you think about making a contribution?  Here is a [[link]](https://github.com/opensearch-project/opensearch-migrations/blob/0e26d2d6af52358a6b2d6103c91b3cd397c784dc/TrafficCapture/dockerSolution/src/main/docker/migrationConsole/lib/console_link/console_link/models/snapshot.py#L253) to where the logic for the snapshot status message is defined." ],
      "repository" : {
        "description" : "Migrate, upgrade, compare, and replicate OpenSearch clusters with ease.",
        "homepage" : "https://aws.amazon.com/solutions/implementations/migration-assistant-for-amazon-opensearch-service/",
        "name" : "opensearch-migrations",
        "fullName" : "opensearch-project/opensearch-migrations",
        "htmlUrl" : "https://github.com/opensearch-project/opensearch-migrations",
        "gitUrl" : "git://github.com/opensearch-project/opensearch-migrations.git",
        "sshUrl" : "git@github.com:opensearch-project/opensearch-migrations.git",
        "cloneUrl" : "https://github.com/opensearch-project/opensearch-migrations.git",
        "owner" : {
          "login" : "opensearch-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 35,
        "stargazersCount" : 54,
        "watchersCount" : 54,
        "size" : 15063,
        "openIssuesCount" : 45,
        "subscribersCount" : 12,
        "pushedAt" : "2025-07-24T17:52:14Z",
        "languages" : {
          "TypeScript" : 501938,
          "Smarty" : 14599,
          "Java" : 3031736,
          "Dockerfile" : 17523,
          "Shell" : 71163,
          "Jinja" : 15925,
          "JavaScript" : 30449,
          "Groovy" : 54246,
          "Python" : 567812
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The snapshot percent complete calculate is incorrect when using the migration assistant to take create a snapshot via `console snapshot create` under the following circumstances: a previous snapshot already exists (eg. `ma-snapshot-1`) and the snapshot that is being created is an incremental one (eg. `ma-snapshot-2`). The expected behavior should be that the % completion should be 100% as evident from the opensearch APIs.",
      "validationOrRequirement" : "Opensearch 2.17",
      "attemptedFixes" : "A dedicated [task](https://opensearch.atlassian.net/browse/MIGRATIONS-2655) within our internal [Jira Epic](https://opensearch.atlassian.net/browse/MIGRATIONS-2531) to fix this specific progress reporting issue by switching to the incremental snapshot statistics when available.",
      "otherNotes" : "When dealing with incremental snapshots, the current progress computation in `console snapshot status --deep-check` doesn???t account for the consecutive nature of the operation. As you???ve pointed out, although the OpenSearch APIs show the snapshot has completed successfully with all shards done, the Migration Assistant CLI still reports incomplete progress due to relying on total snapshot size instead of incremental stats. A dedicated [task](https://opensearch.atlassian.net/browse/MIGRATIONS-2655) within our internal [Jira Epic](https://opensearch.atlassian.net/browse/MIGRATIONS-2531) to fix this specific progress reporting issue by switching to the incremental snapshot statistics when available. Having said that, it is going to be a lower priority fix at this point because user experience is going to change soon with the [Delta Snapshots](https://github.com/opensearch-project/opensearch-migrations/issues/1452) update. If you wanted to see an update sooner, what do you think about making a contribution?  Here is a [[link]](https://github.com/opensearch-project/opensearch-migrations/blob/0e26d2d6af52358a6b2d6103c91b3cd397c784dc/TrafficCapture/dockerSolution/src/main/docker/migrationConsole/lib/console_link/console_link/models/snapshot.py#L253) to where the logic for the snapshot status message is defined.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407142
  }, {
    "issueDTO" : {
      "id" : 3245625752,
      "title" : "Add Swagger API Documentation to Docs site",
      "url" : "https://github.com/AOSSIE-Org/PictoPy/issues/476",
      "repositoryName" : "AOSSIE-Org/PictoPy",
      "description" : "https://blueswen.github.io/mkdocs-swagger-ui-tag/ ([Github](https://github.com/blueswen/mkdocs-swagger-ui-tag))\n\nUsing the above project, we want to display our backend APIs. So from now on, this [page](https://aossie-org.github.io/PictoPy/backend/backend_python/api/) in our docs should look like this [page](https://blueswen.github.io/mkdocs-swagger-ui-tag/pet-store/) \n\nTo generate the JSON file and keep it updated, we need to run this code so that every time the FastAPI server starts, the JSON file is updated automatically.\n\n<img width=\"410\" height=\"285\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6132c98a-10ac-4696-af27-0f3ed5e068c9\" />\n\n",
      "updatedAt" : 1753374535.000000000,
      "user" : "rahulharpal1603",
      "userHtmlUrl" : "https://github.com/rahulharpal1603",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/51887323?v=4",
      "labels" : [ "documentation", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi Rahul ,\nI would love to work on this and I  have experience documenting with swagger as well. Can I please be assigned to this?", "> Hi Rahul , I would love to work on this and I have experience documenting with swagger as well. Can I please be assigned to this?\n\nSure @Anjali-Kan, please go ahead!", "Great! Working on it then  \uD83D\uDE04 ", "Hi, I also want to work on this issue and I would love to do that can i do that ??\nPlease assign me this issue \n" ],
      "repository" : {
        "description" : "An Image sorter that sorts photos based on face encodings in it.",
        "homepage" : "https://aossie-org.github.io/PictoPy/",
        "name" : "PictoPy",
        "fullName" : "AOSSIE-Org/PictoPy",
        "htmlUrl" : "https://github.com/AOSSIE-Org/PictoPy",
        "gitUrl" : "git://github.com/AOSSIE-Org/PictoPy.git",
        "sshUrl" : "git@github.com:AOSSIE-Org/PictoPy.git",
        "cloneUrl" : "https://github.com/AOSSIE-Org/PictoPy.git",
        "owner" : {
          "login" : "AOSSIE-Org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 173,
        "stargazersCount" : 77,
        "watchersCount" : 77,
        "size" : 220796,
        "openIssuesCount" : 79,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-13T09:47:57Z",
        "languages" : {
          "TypeScript" : 281923,
          "PowerShell" : 12482,
          "Dockerfile" : 2307,
          "Shell" : 10313,
          "CSS" : 7541,
          "Rust" : 48311,
          "Batchfile" : 565,
          "JavaScript" : 1314,
          "HTML" : 376,
          "Python" : 131612
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add Swagger API Documentation to Docs site, specifically to display backend APIs on the page https://aossie-org.github.io/PictoPy/backend/backend_python/api/ and make it look like the page https://blueswen.github.io/mkdocs-swagger-ui-tag/pet-store/",
      "validationOrRequirement" : "None mentioned in the description or comments",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "To generate the JSON file and keep it updated, we need to run this code so that every time the FastAPI server starts, the JSON file is updated automatically.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407146
  }, {
    "issueDTO" : {
      "id" : 3259152553,
      "title" : "The cloud-init service failed to start automatically under the openEuler system",
      "url" : "https://github.com/canonical/cloud-init/issues/6329",
      "repositoryName" : "canonical/cloud-init",
      "description" : "# Bug report\n<!-- bug description explaining unmet expectation or use-case -->\nThe cloud-init service failed to start automatically under the openeuler system.\n\n## Steps to reproduce the problem\n<!--Provide any applicable user-data, config, commandline or procedure to reproduce this problem -->\n1. systemctl enable cloud-init-local cloud-init\n2. reboot\n3. systemctl status cloud-init\n\n## Environment details\n- Cloud-init version:   24.1.4\n- Operating System Distribution:  openEuler 2203\n- Cloud provider, platform or installer type:  VM on Proxmox\n\n## logs\n<!--\nPlease provide either the applicable excerpt of /var/log/cloud-init.log representing the failure or attach cloud-init-logs.tar.gz obtained by running `sudo cloud-init collect-logs`. Add `--include-userdata` if there is no sensitive information in your user data.\n-->\n\n[root@openeuler-2203-cloud-init ~]# systemctl status cloud-init\n??? cloud-init.service - Initial cloud-init job (metadata service crawler)\n     Loaded: loaded (/usr/lib/systemd/system/cloud-init.service; enabled; vendor preset: disabled)\n     Active: inactive (dead)\n\n[root@openeuler-2203-cloud-init ~]# dmesg | grep cloud\n[    7.946722] systemd[1]: Hostname set to \\<openeuler-2203-cloud-init\\>.\n[    8.060676] (sd-executor)[600]: /usr/lib/systemd/system-generators/cloud-init-generator failed with exit status 3.\n\n[root@openeuler-2203-cloud-init ~]# /usr/lib/systemd/system-generators/cloud-init-generator \n/usr/lib/systemd/system-generators/cloud-init-generator: line 51: /usr/libexec/cloud-init/ds-identify: No such file or directory\n\nI found that the main branch also has this problem!",
      "updatedAt" : 1753374316.000000000,
      "user" : "qingshanxiao292311",
      "userHtmlUrl" : "https://github.com/qingshanxiao292311",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/41766985?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "# Problem location\n\n[root@openeuler-2203-cloud-init ~]# dmesg | grep cloud-init\n[    7.946722] systemd[1]: Hostname set to \\<openeuler-2203-cloud-init\\>.\n[    8.060676] (sd-executor)[600]: /usr/lib/systemd/system-generators/cloud-init-generator failed with exit status 3.\n\n[root@openeuler-2203-cloud-init ~]# /usr/lib/systemd/system-generators/cloud-init-generator \n/usr/lib/systemd/system-generators/cloud-init-generator: line 51: /usr/libexec/cloud-init/ds-identify: No such file or directory\n\ncat /usr/lib/systemd/system-generators/cloud-init-generator\n```\n  1 #!/bin/sh\n  2 set -f\n  3 \n  4 LOG=\"\"\n  5 DEBUG_LEVEL=1\n  6 LOG_D=\"/run/cloud-init\"\n  7 LOG_F=\"/run/cloud-init/cloud-init-generator.log\"\n  8 ENABLE=\"enabled\"\n  9 DISABLE=\"disabled\"\n 10 RUN_ENABLED_FILE=\"$LOG_D/$ENABLE\"\n 11 RUN_DISABLED_FILE=\"$LOG_D/$DISABLE\"\n 12 CLOUD_TARGET_NAME=\"cloud-init.target\"\n 13 # lxc sets 'container', but lets make that explicitly a global\n 14 CONTAINER=\"${container}\"\n 15 \n 16 # start: template section\n 17 CLOUD_SYSTEM_TARGET=\"/lib/systemd/system/cloud-init.target\"\n 18     dsidentify=\"/usr/libexec/cloud-init/ds-identify\"\n 19 # end: template section\n 20 \n 21 debug() {\n 22     local lvl=\"$1\"\n 23     shift\n 24     [ \"$lvl\" -gt \"$DEBUG_LEVEL\" ] && return\n 25     if [ -z \"$LOG\" ]; then\n 26         { [ -d \"$LOG_D\" ] || mkdir -p \"$LOG_D\"; } &&\n 27             { : > \"$LOG_F\"; } >/dev/null 2>&1 && LOG=\"$LOG_F\" ||\n 28             LOG=\"/dev/kmsg\"\n 29     fi\n 30     echo \"$@\" >> \"$LOG\"\n 31 }\n 32 \n 33 main() {\n 34     local normal_d=\"$1\" early_d=\"$2\" late_d=\"$3\"\n 35     local target_name=\"multi-user.target\" gen_d=\"$early_d\"\n 36     local link_path=\"$gen_d/${target_name}.wants/${CLOUD_TARGET_NAME}\"\n 37     local ds=\"\" ret=\"\"\n 38 \n 39     debug 1 \"$0 normal=$normal_d early=$early_d late=$late_d\"\n 40     debug 2 \"$0 $*\"\n 41 \n 42     # ds=found => enable\n 43     # ds=notfound => disable\n 44     # <any> => disable\n 45     debug 1 \"checking for datasource\"\n 46 \n 47     if [ ! -x \"$dsidentify\" ]; then\n 48         debug 1 \"no ds-identify in $dsidentify\"\n 49         ds=0\n 50     fi\n 51     $dsidentify\n 52     ds=$?\n 53     debug 1 \"ds-identify rc=$ds\"\n 54 \n.......\n101 }\n102 \n103 main \"$@\"\n```\n\n\nAccording to log:  /usr/libexec/cloud-init/ds-identify: No such file or directory.\nMake sure the /usr/libexec/cloud-init directory does not exist.\n\n## View 24.1.x source code \n\n### 1. cloud-init-generator.tmpl\nThe script cloud-init-generator is generated by cloud-init-generator.tmpl\nhttps://github.com/canonical/cloud-init/blob/2d20f8b33f0f3e11f947e8e36d037605b1ff5d76/systemd/cloud-init-generator.tmpl#L16-L32\n\nThe existence of the openeuler element causes dsidentify to be assigned to /usr/libexec/cloud-init/ds-identify on line 25\n\n### 2. setup.py \nds-identify is installed to the specified path through setup.py.\n\nIn the openeuler system, the default `USR_LIB_EXEC` path is `usr/lib`\nhttps://github.com/canonical/cloud-init/blob/2d20f8b33f0f3e11f947e8e36d037605b1ff5d76/setup.py#L181-L201\n\nThe installation path of ds-identify is `/USR_LIB_EXEC/cloud-init`\nhttps://github.com/canonical/cloud-init/blob/2d20f8b33f0f3e11f947e8e36d037605b1ff5d76/setup.py#L272\nhttps://github.com/canonical/cloud-init/blob/2d20f8b33f0f3e11f947e8e36d037605b1ff5d76/setup.py#L277-L290\n\nso ds-identify installed to `/usr/lib/cloud-init` directory, don't installed to `/usr/libexec/cloud-init` directory.\n\n# Solution\ndelete \"openeuler\" on line 24 in the file cloud-init-generate.tmpl\nhttps://github.com/canonical/cloud-init/blob/2d20f8b33f0f3e11f947e8e36d037605b1ff5d76/systemd/cloud-init-generator.tmpl#L24 ", "Good analysis @qingshanxiao292311 thank you!\n\nI agree with your approach and your note here about openeuler using /usr/lib/cloud-init instead of /usr/libexec/cloud-init will also inform our ongoing work to shift upstream cloud-init away from setuptools via setup.py to meson build system https://github.com/canonical/cloud-init/pull/6326.\n\nIf you are able to open a PR with this proposed solution, we can get that into the next cloud-init 25.2 release." ],
      "repository" : {
        "description" : "Official upstream for the cloud-init: cloud instance initialization",
        "homepage" : "https://cloud-init.io/",
        "name" : "cloud-init",
        "fullName" : "canonical/cloud-init",
        "htmlUrl" : "https://github.com/canonical/cloud-init",
        "gitUrl" : "git://github.com/canonical/cloud-init.git",
        "sshUrl" : "git@github.com:canonical/cloud-init.git",
        "cloneUrl" : "https://github.com/canonical/cloud-init.git",
        "owner" : {
          "login" : "canonical",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 974,
        "stargazersCount" : 3337,
        "watchersCount" : 3337,
        "size" : 41472,
        "openIssuesCount" : 539,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-24T17:20:35Z",
        "languages" : {
          "Shell" : 147276,
          "Makefile" : 4390,
          "Python" : 6357784
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The cloud-init service failed to start automatically under the openEuler system.",
      "validationOrRequirement" : "The cloud-init service should start automatically under the openEuler system.",
      "attemptedFixes" : "The author found that the main branch also has this problem. The author suggests that the solution is to delete the openeuler element on line 24 in the file cloud-init-generator.tmpl.",
      "otherNotes" : "The issue is about the cloud-init service failed to start automatically under the openEuler system. The problem is caused by the existence of the openeuler element in the cloud-init-generator.tmpl file, which assigns dsidentify to /usr/libexec/cloud-init/ds-identify. This path does not exist. The solution is to delete the openeuler element on line 24 in the file cloud-init-generator.tmpl.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407152
  }, {
    "issueDTO" : {
      "id" : 3253638352,
      "title" : "Puzzle Roadmap Page",
      "url" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game/issues/579",
      "repositoryName" : "DistinctCodes/NFT-Scavenger-Hunt-Game",
      "description" : "**Description:**\nCreate the Puzzle roadmap page for a visual roadmap of upcoming puzzles and events. Great for anticipation and community buzz.\n\n**Components:**\n\n* Timeline or horizontal scroll\n* Puzzle previews with release dates\n",
      "updatedAt" : 1753374315.000000000,
      "user" : "yusuftomilola",
      "userHtmlUrl" : "https://github.com/yusuftomilola",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/52901501?v=4",
      "labels" : [ "NEXTJS", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hello maintainers, can I handle this please?" ],
      "repository" : {
        "description" : "A gamified blockchain application built on the StarkNet ecosystem that combines educational puzzles with NFT rewards. Players can solve riddles and blockchain-related challenges to earn unique NFTs while learning about the StarkNet ecosystem.",
        "homepage" : "",
        "name" : "NFT-Scavenger-Hunt-Game",
        "fullName" : "DistinctCodes/NFT-Scavenger-Hunt-Game",
        "htmlUrl" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game",
        "gitUrl" : "git://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "sshUrl" : "git@github.com:DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "cloneUrl" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "owner" : {
          "login" : "DistinctCodes",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 124,
        "stargazersCount" : 32,
        "watchersCount" : 32,
        "size" : 6874,
        "openIssuesCount" : 15,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-22T17:39:19Z",
        "languages" : {
          "TypeScript" : 873552,
          "CSS" : 235,
          "Cairo" : 73927,
          "JavaScript" : 106288
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create the Puzzle roadmap page for a visual roadmap of upcoming puzzles and events.",
      "validationOrRequirement" : "The issue requires a timeline or horizontal scroll component and puzzle previews with release dates.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to NEXTJS and frontend development, and is labeled as a good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407154
  }, {
    "issueDTO" : {
      "id" : 3253555600,
      "title" : "[Bug] <entire website is broken i think",
      "url" : "https://github.com/opensource-society/CodeClip/issues/72",
      "repositoryName" : "opensource-society/CodeClip",
      "description" : "## Description\nthe css of the website is not applied clearly. \n## Steps to Reproduce\n<!-- . -->\n\n## Expected Behavior\nthe website need to look cleaner \n\n## Actual Behavior\ncompletely  broken \n\n## Screenshots / Media\n just checkout the original  website link . \n\n## Environment\n- OS:\n- Browser (if applicable):\n- Application Version:\n\n## Additional Context\n<!-- Any other information or links. -->\n",
      "updatedAt" : 1753374297.000000000,
      "user" : "Srivarshan-T",
      "userHtmlUrl" : "https://github.com/Srivarshan-T",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/140912234?v=4",
      "labels" : [ "bug", "gssoc2025", "good first issue", "level 1" ],
      "state" : "OPEN",
      "comments" : [ "Kindly please assign me this issue\nI'll check for the error and rectify it", "@adityai0  review my pull request i guess i fixed the webstie " ],
      "repository" : {
        "description" : "CodeClip is a comprehensive coding challenge platform built with HTML, CSS, and JavaScript, designed specifically for GSSoC contributors and the broader coding community.",
        "homepage" : "https://opensource-society.github.io/CodeClip/",
        "name" : "CodeClip",
        "fullName" : "opensource-society/CodeClip",
        "htmlUrl" : "https://github.com/opensource-society/CodeClip",
        "gitUrl" : "git://github.com/opensource-society/CodeClip.git",
        "sshUrl" : "git@github.com:opensource-society/CodeClip.git",
        "cloneUrl" : "https://github.com/opensource-society/CodeClip.git",
        "owner" : {
          "login" : "opensource-society",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 90,
        "stargazersCount" : 27,
        "watchersCount" : 27,
        "size" : 1475,
        "openIssuesCount" : 75,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-24T17:15:19Z",
        "languages" : {
          "CSS" : 40699,
          "JavaScript" : 18676,
          "HTML" : 146258
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the broken website and ensure the CSS is applied correctly.",
      "validationOrRequirement" : "The issue requires the website to look cleaner, and the CSS to be applied correctly.",
      "attemptedFixes" : "The issue has been assigned to @adityai0, who has mentioned that they will review the pull request.",
      "otherNotes" : "The issue is about the entire website being broken, with the CSS not being applied clearly. The expected behavior is a cleaner-looking website, but the actual behavior is a completely broken website.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407158
  }, {
    "issueDTO" : {
      "id" : 3249367435,
      "title" : "[bug] 2 adjustments to the comment menu bar",
      "url" : "https://github.com/ONEARMY/community-platform/issues/4358",
      "repositoryName" : "ONEARMY/community-platform",
      "description" : "**Context**\n<img width=\"227\" height=\"222\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5d7e7a00-8f92-4035-a4b8-5775e5c4e5e4\" />\nYou can see this menu in all the comment sections now.\n\n\n**Describe the bug**\n1. When I am following replies and I click the menu, for a split-second you can see the \"Follow replies\" option first. This can be quite confusing. ![Image](https://github.com/user-attachments/assets/fbeb84f5-217e-48b3-a039-c777e34cc235)\n2. When I open the menu, and I click outside, nothing happens - for users can be quite frustrating. ![Image](https://github.com/user-attachments/assets/b7cb59dc-947c-43e7-8900-9bdd0b7895b7)\n\n**Expected behaviour**\n1. No glitch for a split-second\n2. Close the menu when clicking outside \n",
      "updatedAt" : 1753374276.000000000,
      "user" : "dalibormrska",
      "userHtmlUrl" : "https://github.com/dalibormrska",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/35503298?v=4",
      "labels" : [ "Good first issue", "Mod: Discussions \uD83D\uDCAC", "Type: \uD83D\uDC1B Bug", "Help wanted" ],
      "state" : "OPEN",
      "comments" : [ "Hi I would like to work on this issue and solve this bug", "Cool, lemme tag @benfurber. ", "Awesome, welcome and thanks @Koppeks!", "Just to let you know, I was unable to access to the frontend project due an error requiring Supabase `yarn run start`.\nI needed to install all the necessary to access the full project Yarn, Docker, Supabase cli, then start both backend and frontend. \n\nI will start now to address this issue \uD83D\uDCAA", "@Koppeks Just realised we're using `react-foco` else where in the app, so probably best to use that for the show/hide.", "The clicks outside the dropdown are already fixed. The real issue is how to remove the flickering in the dropdown follow/unfollow state. I suspect that the problem is the amount of prop drilling in the component itself and the AuthWrapper being executed after the first render. \n\nMy solution was to make a followButtonContextProvider and give context to the comment about the following state. I will roll with it and see if that fixes the issue\n\n\n", "@Koppeks Apologies, I'd only scanned the issue before.\n\nLet's do a couple of things.\n\n1. Let's have a PR for the outside dropdown click please.\n2. Think more about the flickering issue before trying any changes.\n\nThe 'flickering', or more to the point, an incorrect display for a still loading state, is an issue with all the following buttons currently. A context is probably a good idea for all of a users' subscriptions. But first let's think about the loading state. I'm inclined to say for the moment that nothing should be displayed and then have it as a design task to design a better UI as a follow-up activity.\n\nThoughts?", "Sure thing, I will create a new issue and push the solution. \n\nAfter seeing some of the code I thought about some solutions that didn't work for me.\n\n1- Make `hasUserSubscribed` prop in `<FollowButton>` always true, that in theory should stop the incorrect display.\n2- Create a state inside `<FollowButtonAction>` to check if the fetch of the subscribe status `await subscribersService.isSubscribed(...)`, then use that state to render the final result when completely fetched.\n3- Make a context provider for this particular button, having `hasUserSubscribed` as main priority. (I didn't get to test it properly).\n4- Also as a sidenote inline computing also could be part of the problem `someProp={x ? z : y}`.\n\nSome extra solutions that may work:\n\n1- Create either local or session storage for comments and retrieve that information as the user navigates. For example, request see post 32 and retrieve all commentsId and ask if the user is following or not, it will take some time to load the first time, then the following requests would be faster.\n2- Create a global state, basically do the same as the first solution, but with `useContext` or `Zustand`.\n\nLet me know if you want to try some of those yourself or what is the plan" ],
      "repository" : {
        "description" : "A platform to build useful communities that aim to tackle global problems",
        "homepage" : "https://platform.onearmy.earth",
        "name" : "community-platform",
        "fullName" : "ONEARMY/community-platform",
        "htmlUrl" : "https://github.com/ONEARMY/community-platform",
        "gitUrl" : "git://github.com/ONEARMY/community-platform.git",
        "sshUrl" : "git@github.com:ONEARMY/community-platform.git",
        "cloneUrl" : "https://github.com/ONEARMY/community-platform.git",
        "owner" : {
          "login" : "ONEARMY",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 451,
        "stargazersCount" : 1301,
        "watchersCount" : 1301,
        "size" : 253765,
        "openIssuesCount" : 49,
        "subscribersCount" : 43,
        "pushedAt" : "2025-07-24T13:52:04Z",
        "languages" : {
          "TypeScript" : 2129950,
          "Dockerfile" : 12189,
          "CSS" : 18822,
          "Shell" : 743,
          "PLpgSQL" : 78531,
          "JavaScript" : 26068,
          "HTML" : 9460
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to resolve the bug with the comment menu bar, specifically with the 'Follow replies' option. The issue is caused by a glitch that displays the 'Follow replies' option for a split-second before it disappears, and by the menu not closing when clicking outside.",
      "validationOrRequirement" : "The issue requires the ability to remove the flickering in the dropdown follow/unfollow state. The author suggests using react-foco to show/hide the dropdown. The issue also requires the ability to close the menu when clicking outside.",
      "attemptedFixes" : "The author attempted to fix the issue by making a followButtonContextProvider and giving context to the comment about the following state. Other potential solutions were also discussed, including making hasUserSubscribed prop in <FollowButton> always true, creating a state inside <FollowButtonAction> to check if the fetch of the subscribe status, and making a context provider for this particular button.",
      "otherNotes" : "The issue is with the comment menu bar, specifically with the 'Follow replies' option. The main issue is the flickering in the dropdown follow/unfollow state. The author suggests creating a followButtonContextProvider to give context to the comment about the following state. Other potential solutions were discussed in the comments.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407167
  }, {
    "issueDTO" : {
      "id" : 2939338971,
      "title" : "[FEA] Change `parquet_read_decode` to use uncompressed files",
      "url" : "https://github.com/rapidsai/cudf/issues/18349",
      "repositoryName" : "rapidsai/cudf",
      "description" : "**Is your feature request related to a problem? Please describe.**\n`parquet_read_decode` is a great benchmark to highlight decoder performance. However, some of the files show high latency in nvCOMP. We should change this benchmark to use uncompressed files by default.\n\nhttps://github.com/rapidsai/cudf/blob/9665d073f26a6ab77076a8df9c443dc7abffde84/cpp/benchmarks/io/parquet/parquet_reader_input.cpp#L352\n\n**Describe the solution you'd like**\nWe could either create a compression axis defaulting to NONE and supporting NONE, Snappy, ZSTD. Or we could just hard-code the default to NONE.\n\n**Describe alternatives you've considered**\nUsing profiles to extract the decoding part of the reader calls\n\n",
      "updatedAt" : 1753374200.000000000,
      "user" : "GregoryKimball",
      "userHtmlUrl" : "https://github.com/GregoryKimball",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12725111?v=4",
      "labels" : [ "cuIO", "libcudf", "feature request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@GregoryKimball Between your two proposed approaches, creating a compression axis offers more flexibility. As I got you we literally can make:\n\n```\n// Change from:\nNVBENCH_BENCH_TYPES(BM_parquet_read_data, NVBENCH_TYPE_AXES(d_type_list))\n  .set_name(\"parquet_read_decode\")\n  .set_type_axes_names({\"data_type\"})\n  .add_string_axis(\"io_type\", {\"DEVICE_BUFFER\"})\n  .set_min_samples(4)\n  .add_int64_axis(\"cardinality\", {0, 1000})\n  .add_int64_axis(\"run_length\", {1, 32});\n```\n\n```\n// Change to:\nNVBENCH_BENCH_TYPES(BM_parquet_read_data, NVBENCH_TYPE_AXES(d_type_list))\n  .set_name(\"parquet_read_decode\")\n  .set_type_axes_names({\"data_type\"})\n  .add_string_axis(\"io_type\", {\"DEVICE_BUFFER\"})\n  .add_string_axis(\"compression_type\", {\"NONE\", \"SNAPPY\", \"ZSTD\"})  // Add this line\n  .set_min_samples(4)\n  .add_int64_axis(\"cardinality\", {0, 1000})\n  .add_int64_axis(\"run_length\", {1, 32});\n```\n\n\nThis option gives flexibility to run benchmarks with different compression types. Hardcode option is simpler but only allows using NONE compression.\n\n```\n// Change from:\nauto const compression = cudf::io::compression_type::SNAPPY;\n```\n```\n// Change to:\nauto const compression = cudf::io::compression_type::NONE;\n```\n\nIf this makes sense could I approach this issue? Thanks in advance ", "Thank you @gmivan for this suggestion. Yes, we could certainly add an axis. \n\nI would probably start with a single axis value running by default, with Snappy and Zstd available at runtime but not run by default, e.g.:\n`.add_string_axis(\"compression_type\", {\"NONE\"})`\n\nWe would love your help!" ],
      "repository" : {
        "description" : "cuDF - GPU DataFrame Library ",
        "homepage" : "https://docs.rapids.ai/api/cudf/stable/",
        "name" : "cudf",
        "fullName" : "rapidsai/cudf",
        "htmlUrl" : "https://github.com/rapidsai/cudf",
        "gitUrl" : "git://github.com/rapidsai/cudf.git",
        "sshUrl" : "git@github.com:rapidsai/cudf.git",
        "cloneUrl" : "https://github.com/rapidsai/cudf.git",
        "owner" : {
          "login" : "rapidsai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 960,
        "stargazersCount" : 9070,
        "watchersCount" : 9070,
        "size" : 167796,
        "openIssuesCount" : 1086,
        "subscribersCount" : 157,
        "pushedAt" : "2025-07-24T23:41:47Z",
        "languages" : {
          "Java" : 2612771,
          "Dockerfile" : 954,
          "C++" : 13580598,
          "Shell" : 104572,
          "C" : 6037,
          "CMake" : 166776,
          "HTML" : 2351,
          "Jupyter Notebook" : 1371,
          "Cython" : 915403,
          "Python" : 8698738,
          "Cuda" : 7741022
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Change `parquet_read_decode` to use uncompressed files by default, allowing for flexibility in running benchmarks with different compression types.",
      "validationOrRequirement" : "Adding a string axis to the NVBENCH_BENCH_TYPES function to include compression types, and updating the compression type accordingly.",
      "attemptedFixes" : "Creating a compression axis defaulting to NONE and supporting NONE, Snappy, ZSTD was proposed as a solution, and hard-coding the default to NONE was also suggested.",
      "otherNotes" : "Using profiles to extract the decoding part of the reader calls was considered as an alternative solution.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407171
  }, {
    "issueDTO" : {
      "id" : 548273882,
      "title" : "Request to include channel in <amp-youtube>",
      "url" : "https://github.com/ampproject/amphtml/issues/26304",
      "repositoryName" : "ampproject/amphtml",
      "description" : "This probably won't be on the top of anyone's list of things to fix... but I imagine it wouldn't be hard to implement!\r\n\r\nI wanted to implement a YouTube embed that linked to a YouTube channel. AFAIK you can't do this with a param, but you can do it with the method described [on the support forum](https://support.google.com/youtube/forum/AAAAiuErobUTOLiiakr_-g/?hl=en&gpf=d/category-topic/youtube/how-to-use-youtube-features/TOLiiakr_-g):\r\n\r\n`<script src=\"http://www.gmodules.com/ig/ifr?url=http://www.google.com/ig/modules/youtube.xml&amp;up_channel=YourChannelName&amp;synd=open&amp;w=320&amp;h=390&amp;title=&amp;border=%23ffffff%7C3px%2C1px+solid+%23999999&amp;output=js\"></script>`\r\n\r\nWhaddya think?",
      "updatedAt" : 1753374200.000000000,
      "user" : "morsssss",
      "userHtmlUrl" : "https://github.com/morsssss",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29419498?v=4",
      "labels" : [ "Type: DevX", "Component: amp-youtube", "P3: When Possible", "WG: components", "good first issue", "Type: Feature Request" ],
      "state" : "OPEN",
      "comments" : [ "Can I take this issue", "@Alucard17 Feel free, thanks for contributing to AMP!", "can i take this issue\r\n", "@sujay2306 Sure thing!", "Please share the video. Could you let me know if you'd like to share a YouTube video link or a YouTube channel link, and where you'd like me to add the link?\r\n", "Is the issuue still open?\r\nCan I work on it @caroqliu ", "@caroqliu  can  I work on this issue?", "Hi, is this still open ? can i work on it @caroqliu ?", "@caroqliu can I work on this ?", "Hey @caroqliu , is this issue still open? I'm interested in contributing!", "@caroqliu Can I take the issue if it still exist??", "Just noticing all these kind offers to take this on. Please feel free to do it! I'm not actively involved with this project anymore, and I don't know if @caroqliu is.", "Hi @caroqliu, I am a beginner and would like to work on this issue.  \nCould you please assign it to me? Thank you!\n", "I want to work on this issue\n", "i did work on it and ill be pushing it soon\n", "if this still open, below is a modern approach, using thumbnail, logo, or banner image and linke it: \n\n<a href=\"https://www.youtube.com/c/YourChannelName\" target=\"_blank\" rel=\"noopener\">\n  <img src=\"https://img.youtube.com/vi/YOUR_VIDEO_ID/0.jpg\" alt=\"Visit our YouTube Channel\" />\n</a>", "Hi @caroqliu, can i solve this issue", "Hey folks - if you want to do this, submit a PR!" ],
      "repository" : {
        "description" : "The AMP web component framework.",
        "homepage" : "https://amp.dev",
        "name" : "amphtml",
        "fullName" : "ampproject/amphtml",
        "htmlUrl" : "https://github.com/ampproject/amphtml",
        "gitUrl" : "git://github.com/ampproject/amphtml.git",
        "sshUrl" : "git@github.com:ampproject/amphtml.git",
        "cloneUrl" : "https://github.com/ampproject/amphtml.git",
        "owner" : {
          "login" : "ampproject",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : false,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3974,
        "stargazersCount" : 14900,
        "watchersCount" : 14900,
        "size" : 966230,
        "openIssuesCount" : 963,
        "subscribersCount" : 625,
        "pushedAt" : "2025-07-18T15:56:56Z",
        "languages" : {
          "TypeScript" : 127540,
          "Yacc" : 28669,
          "C++" : 1752885,
          "CSS" : 516617,
          "Shell" : 19741,
          "Starlark" : 34728,
          "C" : 256,
          "JavaScript" : 18582834,
          "Go" : 6528,
          "HTML" : 2115707,
          "Python" : 64581
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a YouTube embed that links to a YouTube channel in the amp-youtube component.",
      "validationOrRequirement" : "The requirement is to implement a YouTube embed that links to a YouTube channel, and the modern approach uses thumbnail, logo, or banner image and links it.",
      "attemptedFixes" : "The issue has multiple attempts to work on it, including one that is ready to be pushed soon. A PR is also requested.",
      "otherNotes" : "The issue is about implementing a YouTube embed that links to a YouTube channel, and there are multiple attempts to work on it. A modern approach is also provided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407175
  }, {
    "issueDTO" : {
      "id" : 3253625426,
      "title" : "Connect Socials Page",
      "url" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game/issues/574",
      "repositoryName" : "DistinctCodes/NFT-Scavenger-Hunt-Game",
      "description" : "**Description:**\nAllow linking GitHub, Twitter, Discord. Useful for community rewards.\n",
      "updatedAt" : 1753374122.000000000,
      "user" : "yusuftomilola",
      "userHtmlUrl" : "https://github.com/yusuftomilola",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/52901501?v=4",
      "labels" : [ "NEXTJS", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "i can handle this  " ],
      "repository" : {
        "description" : "A gamified blockchain application built on the StarkNet ecosystem that combines educational puzzles with NFT rewards. Players can solve riddles and blockchain-related challenges to earn unique NFTs while learning about the StarkNet ecosystem.",
        "homepage" : "",
        "name" : "NFT-Scavenger-Hunt-Game",
        "fullName" : "DistinctCodes/NFT-Scavenger-Hunt-Game",
        "htmlUrl" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game",
        "gitUrl" : "git://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "sshUrl" : "git@github.com:DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "cloneUrl" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "owner" : {
          "login" : "DistinctCodes",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 124,
        "stargazersCount" : 32,
        "watchersCount" : 32,
        "size" : 6874,
        "openIssuesCount" : 15,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-22T17:39:19Z",
        "languages" : {
          "TypeScript" : 873552,
          "CSS" : 235,
          "Cairo" : 73927,
          "JavaScript" : 106288
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to allow linking GitHub, Twitter, and Discord to the Socials Page.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to connecting social media pages such as GitHub, Twitter, and Discord, which is useful for community rewards.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407178
  }, {
    "issueDTO" : {
      "id" : 3258273134,
      "title" : "Manually starting the cloud-init service in the openEuler system fails",
      "url" : "https://github.com/canonical/cloud-init/issues/6327",
      "repositoryName" : "canonical/cloud-init",
      "description" : "# Bug report\n<!-- bug description explaining unmet expectation or use-case -->\nManually starting the cloud-init service in the openeuler system fails\n\n## Steps to reproduce the problem\n<!--Provide any applicable user-data, config, commandline or procedure to reproduce this problem -->\n\n1. systemctl start cloud-init-local \n2. systemctl start cloud-init\n\n## Environment details\n- Cloud-init version:   24.1.4\n- Operating System Distribution:   openeuler 2203\n- Cloud provider, platform or installer type:  VM on Proxmox\n\n## logs\n<!--\nPlease provide either the applicable excerpt of /var/log/cloud-init.log representing the failure or attach cloud-init-logs.tar.gz obtained by running `sudo cloud-init collect-logs`. Add `--include-userdata` if there is no sensitive information in your user data.\n-->\n```\n[root@openeuler-2203-cloud-init ~]# systemctl start cloud-init\nJob for cloud-init.service failed because the control process exited with error code.\nSee \"systemctl status cloud-init.service\" and \"journalctl -xeu cloud-init.service\" for details.\n\n[root@openeuler-2203-cloud-init ~]# systemctl status cloud-init\n?? cloud-init.service - Initial cloud-init job (metadata service crawler)\n     Loaded: loaded (/usr/lib/systemd/system/cloud-init.service; enabled; vendor preset: disabled)\n     Active: failed (Result: exit-code) since Thu 2025-07-24 10:42:51 CST; 1min 16s ago\n    Process: 2258 ExecStart=/opt/xclient/python/bin/cloud-init init (code=exited, status=1/FAILURE)\n   Main PID: 2258 (code=exited, status=1/FAILURE)\n\nJul 24 10:42:50 openeuler-2203-cloud-init cloud-init[2261]: ci-info: +-------+-------------+---------+-----------+-------+\nJul 24 10:42:50 openeuler-2203-cloud-init cloud-init[2261]: ci-info: |   1   |  fe80::/64  |    ::   |  enp0s18  |   U   |\nJul 24 10:42:50 openeuler-2203-cloud-init cloud-init[2261]: ci-info: |   3   |    local    |    ::   |  enp0s18  |   U   |\nJul 24 10:42:50 openeuler-2203-cloud-init cloud-init[2261]: ci-info: |   4   |  multicast  |    ::   |  enp0s18  |   U   |\nJul 24 10:42:50 openeuler-2203-cloud-init cloud-init[2261]: ci-info: +-------+-------------+---------+-----------+-------+\nJul 24 10:42:51 openeuler-2203-cloud-init cloud-init[2261]: 2025-07-24 02:42:51,306 - cloud.py[WARNING]: No template found in /etc/cloud/templates for template named hosts.openeuler\nJul 24 10:42:51 openeuler-2203-cloud-init cloud-init[2261]: 2025-07-24 02:42:51,307 - util.py[WARNING]: Running module update_etc_hosts (<module 'cloudinit.config.cc_update_etc_hosts' from '/opt/xclient/python/lib/python3.12/site-packages/cloud_init-24.1.4-py3.12.egg/cloudinit/config/cc_update_etc_hosts.py'>) failed\nJul 24 10:42:51 openeuler-2203-cloud-init systemd[1]: cloud-init.service: Main process exited, code=exited, status=1/FAILURE\nJul 24 10:42:51 openeuler-2203-cloud-init systemd[1]: cloud-init.service: Failed with result 'exit-code'.\nJul 24 10:42:51 openeuler-2203-cloud-init systemd[1]: Failed to start Initial cloud-init job (metadata service crawler).\n\n```\n\nI found that the main branch also has this problem!",
      "updatedAt" : 1753374015.000000000,
      "user" : "qingshanxiao292311",
      "userHtmlUrl" : "https://github.com/qingshanxiao292311",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/41766985?v=4",
      "labels" : [ "bug", "hacktoberfest", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "# Problem location\n\nAccording to log:  cloud.py[WARNING]: No template found in /etc/cloud/templates for template named hosts.openeuler.\nExecute ls -l /etc/cloud/templates, and indeed no such file is found in the /etc/cloud/templates/ directory.\n\n## View 24.1.x source code \n\nTrack source code based on log errors(No template found in /etc/cloud/templates for template named hosts.openeuler): \n1. https://github.com/canonical/cloud-init/blob/2d20f8b33f0f3e11f947e8e36d037605b1ff5d76/cloudinit/cloud.py#L73-L82\n\n2. https://github.com/canonical/cloud-init/blob/2d20f8b33f0f3e11f947e8e36d037605b1ff5d76/cloudinit/config/cc_update_etc_hosts.py#L121-L123\n\n3. cloud.distro.osfamily  \n    It's value is \"openeuler\" in openeuler system\n    https://github.com/canonical/cloud-init/blob/2d20f8b33f0f3e11f947e8e36d037605b1ff5d76/cloudinit/distros/openeuler.py#L9\n\n## Track\n1. openeuler is removed from the list corresponding to redhat and made into a separate key in cloudinit/distros/__init__.py file\n   https://github.com/canonical/cloud-init/pull/1895\n2. modify \"openEuler\" to \"openeuler\"  in cloudinit/distros/__init__.py file\n   https://github.com/canonical/cloud-init/pull/4317\n\nBefore this patch https://github.com/canonical/cloud-init/pull/1895,  \"openEuler\" belongs to redhat,  the value of cloud.distro.osfamily  is \"redhat\" in openeuler system,  the file looked for is the host.redhat.tmpl file in the /etc/cloud/templates/ directory, and the file exists, so there is no problem.\n\n# Solution\nAdd a hosts.openeuler.tmpl file in the cloudint/templates directory.\n```\n## template:jinja\n{#\nThis file /etc/cloud/templates/hosts.openeuler.tmpl is only utilized\nif enabled in cloud-config.  Specifically, in order to enable it\nyou need to add the following to config:\n  manage_etc_hosts: True\n-#}\n# Your system has configured 'manage_etc_hosts' as True.\n# As a result, if you wish for changes to this file to persist\n# then you will need to either\n# a.) make changes to the master file in /etc/cloud/templates/hosts.openeuler.tmpl\n# b.) change or remove the value of 'manage_etc_hosts' in\n#     /etc/cloud/cloud.cfg or cloud-config from user-data\n#\n# The following lines are desirable for IPv4 capable hosts\n127.0.0.1 {{fqdn}} {{hostname}}\n127.0.0.1 localhost.localdomain localhost\n127.0.0.1 localhost4.localdomain4 localhost4\n\n# The following lines are desirable for IPv6 capable hosts\n::1 {{fqdn}} {{hostname}}\n::1 localhost.localdomain localhost\n::1 localhost6.localdomain6 localhost6\n```", "Thank you for filing this issue and making cloud-init better.\n\nCreating this separate template file does look like the correct approach at the moment given that we are treating OpenEuler as a unique osfamily and not a redhat derivative. Given that the openeuler tmpl is not functionally different redhat, and many other host.*.tmpl are functionally equivalent (just comment or white-space differences), I wonder if I more generalized approach would be to add an optional `default_tmpl: str` param to  cloudinit.cloud.get_template_name. Calls to get_template_name could optionally fallback to a common distro-independent `templates/hosts.tmpl` if a specialized distro-or os-familiy-specific template file does not exist. This would allow us to reuse the same template file for multiple distributions and avoid  having to cut-n-paste the same template  for all supported distros.\n\nIf you feel like there is time to put up a pull request we would help shepherd that into upstream cloud-init. Either approach would work:\n1. Add template/hosts.openeuler.tmpl  addition or\n2. a fallback option that'd allow both redhat and openeuler to use templates/hosts.tmpl with a diff like the following diff (untested)\n```diff\n\niff --git a/cloudinit/cloud.py b/cloudinit/cloud.py\nindex ae079d485..0777d7bf0 100644\n--- a/cloudinit/cloud.py\n+++ b/cloudinit/cloud.py\n@@ -70,14 +70,20 @@ class Cloud:\n         \"\"\"\n         return self._runners.run(name, functor, args, freq, clear_on_fail)\n \n-    def get_template_filename(self, name):\n+    def get_template_filename(\n+        self, name: str, default_name: str = None\n+    ) -> Optional[str]:\n         fn = self.paths.template_tpl % (name)\n         if not os.path.isfile(fn):\n-            LOG.warning(\n-                \"No template found in %s for template named %s\",\n-                os.path.dirname(fn),\n-                name,\n-            )\n+            if default_name:\n+                fn = self.paths.template_tpl % (default_name)\n+            if not os.path.isfile(fn)\n+                LOG.warning(\n+                    \"No template found in %s for template named %s or %s\",\n+                    os.path.dirname(fn),\n+                    name,\n+                    default_name,\n+                )\n             return None\n         return fn\n \ndiff --git a/cloudinit/config/cc_update_etc_hosts.py b/cloudinit/config/cc_update_etc_hosts.py\nindex 1b9847c25..b721d22fb 100644\n--- a/cloudinit/config/cc_update_etc_hosts.py\n+++ b/cloudinit/config/cc_update_etc_hosts.py\n@@ -47,7 +47,7 @@ def handle(name: str, cfg: Config, cloud: Cloud, args: list) -> None:\n \n         # Render from a template file\n         tpl_fn_name = cloud.get_template_filename(\n-            \"hosts.%s\" % (cloud.distro.osfamily)\n+            \"hosts.%s\" % (cloud.distro.osfamily), \"hosts\"\n         )\n         if not tpl_fn_name:\n             raise RuntimeError(\n```", "I've added this issue to 25.2 delayed release target. We expect to cut upstream 25.2 when we clear publication of another security fix this week." ],
      "repository" : {
        "description" : "Official upstream for the cloud-init: cloud instance initialization",
        "homepage" : "https://cloud-init.io/",
        "name" : "cloud-init",
        "fullName" : "canonical/cloud-init",
        "htmlUrl" : "https://github.com/canonical/cloud-init",
        "gitUrl" : "git://github.com/canonical/cloud-init.git",
        "sshUrl" : "git@github.com:canonical/cloud-init.git",
        "cloneUrl" : "https://github.com/canonical/cloud-init.git",
        "owner" : {
          "login" : "canonical",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 974,
        "stargazersCount" : 3337,
        "watchersCount" : 3337,
        "size" : 41472,
        "openIssuesCount" : 539,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-24T17:20:35Z",
        "languages" : {
          "Shell" : 147276,
          "Makefile" : 4390,
          "Python" : 6357784
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Manually starting the cloud-init service in the openEuler system fails due to a missing template file 'hosts.openeuler.tmpl' in the /etc/cloud/templates directory.",
      "validationOrRequirement" : "The cloud-init service should be able to start on an openEuler system without failing due to a missing template file.",
      "attemptedFixes" : "The problem was identified as a missing template file 'hosts.openeuler.tmpl' in the /etc/cloud/templates directory. The solution is to add this file to the templates directory.",
      "otherNotes" : "The issue is related to the cloud-init service failing to start on an openEuler system due to a missing template file. The template file 'hosts.openeuler.tmpl' is not found in the /etc/cloud/templates directory.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407184
  }, {
    "issueDTO" : {
      "id" : 3254800443,
      "title" : "Add tests for <AnchorTitle> component",
      "url" : "https://github.com/OWASP/Nest/issues/1796",
      "repositoryName" : "OWASP/Nest",
      "description" : " Write unit tests for the `<AnchorTitle>` React component to ensure expected behavior, edge case handling, and rendering logic.\n\n## Essential Test Coverage Checklist\n\n- [ ] **Renders without crashing**  \n- [ ] **Conditional rendering logic**  \n- [ ] **Prop-based behavior** ??? different props affect output  \n- [ ] **Event handling** ??? simulate user actions and verify callbacks  \n- [ ] **State changes / internal logic**  \n- [ ] **Default values and fallbacks**  \n- [ ] **Text and content rendering**  \n- [ ] **Error states / edge cases**  \n- [ ] **Accessibility roles and labels**  \n\n\n## Test Reference  \nYou can refer to the `AutoScrollToTop.test.tsx` file for an example of structure and best practices.  \nTo explore more examples, see the full component tests folder.\n",
      "updatedAt" : 1753373957.000000000,
      "user" : "kasya",
      "userHtmlUrl" : "https://github.com/kasya",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5873153?v=4",
      "labels" : [ "frontend-tests", "gssoc25", "enhancement", "good first issue", "level 2" ],
      "state" : "OPEN",
      "comments" : [ "I would like to work on it .please assign it to me .!!" ],
      "repository" : {
        "description" : "Your gateway to OWASP. Discover, engage, and help shape the future!",
        "homepage" : "https://nest.owasp.org",
        "name" : "Nest",
        "fullName" : "OWASP/Nest",
        "htmlUrl" : "https://github.com/OWASP/Nest",
        "gitUrl" : "git://github.com/OWASP/Nest.git",
        "sshUrl" : "git@github.com:OWASP/Nest.git",
        "cloneUrl" : "https://github.com/OWASP/Nest.git",
        "owner" : {
          "login" : "OWASP",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 127,
        "stargazersCount" : 107,
        "watchersCount" : 107,
        "size" : 277308,
        "openIssuesCount" : 112,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T19:15:06Z",
        "languages" : {
          "TypeScript" : 604537,
          "Dockerfile" : 4478,
          "Jinja" : 19164,
          "CSS" : 6717,
          "Shell" : 161,
          "Makefile" : 12753,
          "JavaScript" : 6838,
          "HTML" : 222,
          "Python" : 1284784
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add tests for the `<AnchorTitle>` component to ensure expected behavior, edge case handling, and rendering logic.",
      "validationOrRequirement" : "Write unit tests for the `<AnchorTitle>` React component to ensure expected behavior, edge case handling, and rendering logic.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue description provides a checklist of essential test coverage, and the test reference suggests looking at the AutoScrollToTop.test.tsx file for an example and the full component tests folder for more examples.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407187
  }, {
    "issueDTO" : {
      "id" : 3140167711,
      "title" : "[Bug] The 'Export(API)' menu seems always visible no matter whether Dev mode is on or off.",
      "url" : "https://github.com/Comfy-Org/ComfyUI_frontend/issues/4140",
      "repositoryName" : "Comfy-Org/ComfyUI_frontend",
      "description" : "I don't know if it is expected, but the 'Export(API)' menu seems always visible no matter whether Dev mode is on or off.\n\nhttps://github.com/user-attachments/assets/3a65eed2-74b9-43bd-b435-0d767c554409\n\nOr is this not its correct use? I'm currently writing about the settings section docs. If it's not for making the 'Export (API)' menu visible, what is its proper purpose?\n\n???Issue is synchronized with this [Notion page](https://www.notion.so/Issue-4140-Bug-The-Export-API-menu-seems-always-visible-no-matter-whether-Dev-mode-is-on-or--2106d73d36508186b598e49c1aabcfa1) by [Unito](https://www.unito.io)\n",
      "updatedAt" : 1753373920.000000000,
      "user" : "comfyui-wiki",
      "userHtmlUrl" : "https://github.com/comfyui-wiki",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/192523189?v=4",
      "labels" : [ "area:settings", "has repro", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! I'm looking for a good first issue, please let me know if I can take this on. " ],
      "repository" : {
        "description" : "Official front-end implementation of ComfyUI",
        "homepage" : "https://www.comfy.org/",
        "name" : "ComfyUI_frontend",
        "fullName" : "Comfy-Org/ComfyUI_frontend",
        "htmlUrl" : "https://github.com/Comfy-Org/ComfyUI_frontend",
        "gitUrl" : "git://github.com/Comfy-Org/ComfyUI_frontend.git",
        "sshUrl" : "git@github.com:Comfy-Org/ComfyUI_frontend.git",
        "cloneUrl" : "https://github.com/Comfy-Org/ComfyUI_frontend.git",
        "owner" : {
          "login" : "Comfy-Org",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 329,
        "stargazersCount" : 1219,
        "watchersCount" : 1219,
        "size" : 180007,
        "openIssuesCount" : 420,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-25T00:54:35Z",
        "languages" : {
          "TypeScript" : 3319527,
          "CSS" : 22418,
          "Vue" : 688905,
          "JavaScript" : 33170,
          "HTML" : 836,
          "Python" : 456
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The 'Export(API)' menu is always visible regardless of whether Dev mode is on or off, and the issue is unclear about its correct use.",
      "validationOrRequirement" : "No specific validations or requirements mentioned.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is synchronized with a Notion page by Unito.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407190
  }, {
    "issueDTO" : {
      "id" : 2096492193,
      "title" : "docs: little updates",
      "url" : "https://github.com/ag2ai/faststream/issues/1167",
      "repositoryName" : "ag2ai/faststream",
      "description" : "Add to [this section](https://faststream.airt.ai/latest/getting-started/subscription/annotation/#json-basic-serialization)\n* [ ] partial body consuming example (https://github.com/airtai/faststream/pull/890#issuecomment-1835856313)\n* [ ] detail serialization rule notice (#1152)\n* [ ] edit [FastAPI broker section](https://faststream.airt.ai/latest/getting-started/integrations/fastapi/#accessing-the-broker-object) to use context (also test it with multiple routers)",
      "updatedAt" : 1753373855.000000000,
      "user" : "Lancetnik",
      "userHtmlUrl" : "https://github.com/Lancetnik",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/44573917?v=4",
      "labels" : [ "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @Lancetnik is this still in scope or is context being transitioned to fast_depends? I am trying to figure out how to best manage dependencies which must live within both fastapi and faststream router, for now context seems to be the best option. could you please let me know if this is changing?", "@MrPranav101 this Issue related to documentation only, don't worry\r\nI just want to refactor code example to use context instead of global object" ],
      "repository" : {
        "description" : "FastStream is a powerful and easy-to-use Python framework for building asynchronous services interacting with event streams such as Apache Kafka, RabbitMQ, NATS and Redis.",
        "homepage" : "https://faststream.ag2.ai/latest/",
        "name" : "faststream",
        "fullName" : "ag2ai/faststream",
        "htmlUrl" : "https://github.com/ag2ai/faststream",
        "gitUrl" : "git://github.com/ag2ai/faststream.git",
        "sshUrl" : "git@github.com:ag2ai/faststream.git",
        "cloneUrl" : "https://github.com/ag2ai/faststream.git",
        "owner" : {
          "login" : "ag2ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 253,
        "stargazersCount" : 4208,
        "watchersCount" : 4208,
        "size" : 38847,
        "openIssuesCount" : 114,
        "subscribersCount" : 26,
        "pushedAt" : "2025-07-24T18:29:27Z",
        "languages" : {
          "Shell" : 4576,
          "Python" : 2489159
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update documentation for faststream by refactoring code examples to use context instead of global objects, specifically for the FastAPI broker section and testing with multiple routers.",
      "validationOrRequirement" : "None mentioned in the comments or description.",
      "attemptedFixes" : "None mentioned in the comments or description.",
      "otherNotes" : "Context transition to fast_depends is being considered, but this issue is still related to documentation and refactoring code examples to use context instead of global objects.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407193
  }, {
    "issueDTO" : {
      "id" : 3257898446,
      "title" : "Policy CRDs are missing required label",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11754",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "### kgateway version\n\nv2.1.0-main\n\n### Kubernetes Version\n\nv1.32.2\n\n### Describe the bug\n\nPolilcy CRDs require label `gateway.networking.k8s.io/policy: inherited|direct` according to https://gateway-api.sigs.k8s.io/geps/gep-713/#standard-label-on-crd-objects\n\nThe BackendConfigPolicy doesn't include that label \nhttps://github.com/kgateway-dev/kgateway/blob/main/install/helm/kgateway-crds/templates/gateway.kgateway.dev_backendconfigpolicies.yaml#L7-L9\n\n\n### Expected Behavior\n\nexpected label `gateway.networking.k8s.io/policy: Direct`\n\n### Steps to reproduce the bug\n\nN/A\n\n### Additional Environment Detail\n\n_No response_\n\n### Additional Context\n\n_No response_",
      "updatedAt" : 1753373710.000000000,
      "user" : "nikolasmatt",
      "userHtmlUrl" : "https://github.com/nikolasmatt",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11150898?v=4",
      "labels" : [ "Good First Issue", "Type: Bug" ],
      "state" : "OPEN",
      "comments" : [ "/assign" ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 543,
        "stargazersCount" : 4653,
        "watchersCount" : 4653,
        "size" : 211827,
        "openIssuesCount" : 562,
        "subscribersCount" : 100,
        "pushedAt" : "2025-07-24T19:33:09Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16895,
          "Rust" : 20712,
          "Makefile" : 32755,
          "JavaScript" : 435,
          "Go" : 4121797,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Policy CRDs are missing required label",
      "validationOrRequirement" : "required label 'gateway.networking.k8s.io/policy: inherited|direct' according to https://gateway-api.sigs.k8s.io/geps/gep-713/#standard-label-on-crd-objects",
      "attemptedFixes" : "N/A",
      "otherNotes" : "kgateway version v2.1.0-main, Kubernetes Version v1.32.2, BackendConfigPolicy missing label",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407197
  }, {
    "issueDTO" : {
      "id" : 1771352671,
      "title" : "Nuxt auto redirects to wrong URL when serving nuxt app from different URL",
      "url" : "https://github.com/nuxt/nuxt/issues/21716",
      "repositoryName" : "nuxt/nuxt",
      "description" : "### Environment\r\n\r\n- Operating System: `Darwin`\r\n- Node Version:     `v18.15.0`\r\n- Nuxt Version:     `3.5.2`\r\n- Nitro Version:    `2.4.1`\r\n- Package Manager:  `pnpm@8.5.1`\r\n- Builder:          `vite`\r\n- User Config:      `app`, `appConfig`, `typescript`, `build`, `devtools`, `vite`\r\n- Runtime Modules:  `-`\r\n- Build Modules:    `-`\r\n\r\n### Reproduction\r\n\r\nhttps://github.com/jd-solanki/nuxt-playground\r\n\r\n### Describe the bug\r\n\r\nWe are building admin templates using nuxt & I would like to deploy single nuxt app to multiple URLs like `/nuxt-app/demo-1`, `/nuxt-app/demo-2`.\r\n\r\nI configured nginx to server the nuxt app at two different URLs and I guess it's even working but somehow nuxt automatically redirects me to wrong URL. (`http://localhost/nuxt-app/demo-1/` => `http://localhost/nuxt-app/demo/-1/`) \uD83E\uDD37\uD83C\uDFFB????????? \r\n\r\nThis makes it impossible to serve nuxt app from multiple URLs like we do with normal apps.\r\n\r\n### Additional context\r\n\r\nAfter spending 2 days for learning docker & providing reproduction, You can try demo in docker to easily recreate the environment, I have added the steps in the repo README.\r\n\r\n### Logs\r\n\r\n_No response_",
      "updatedAt" : 1753373648.000000000,
      "user" : "jd-solanki",
      "userHtmlUrl" : "https://github.com/jd-solanki",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/47495003?v=4",
      "labels" : [ "\uD83C\uDF70 p2-nice-to-have", "workaround available", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I haven't confirmed, but for now, you can likely add this plugin to your project as `~/plugins/prevent-redirection.client.ts`:\r\n\r\n```js\r\nexport default defineNuxtPlugin({\r\n  order: -40,\r\n  setup: (nuxtApp) => {\r\n    delete nuxtApp.payload.path\r\n  }\r\n})\r\n```\r\n\r\n**Edit**: It might be a better solution to instead set your `baseURL` (at runtime) to the path where you want to serve the app.\r\n\r\nNote that the behaviour to allow Nuxt apps to run as expected when loaded from a different URL, such as when loaded from Google cache. So perhaps we might allow this behaviour to be configurable, or document how to turn it off with a custom plugin.", "I am having a similar issue, I am currently trying to setup a subdomain that points to pages in my nuxt project. For example I am trying to point subdomain.domain2.com to www.domain1.com/dir/page/. When I go to the subdomain, the correct page loads, however it only lasts around 1 second and then it appears that a redirect happens and the root index page loads. Do I have something wrong in my NGINX config or does nuxt 3 redirect  the route if the paths don't match?\r\n\r\nI tried the above plugin with no luck\r\n\r\n```\r\nserver {\r\n    listen 80;\r\n    listen [::]:80;\r\n\r\n    listen 443 ssl;\r\n    listen [::]:443 ssl;\r\n\r\n    server_name subdomain.domain2.com;\r\n\r\n    ssl_certificate /etc/ssl/certs/wildcard.sslcert.com.crt;\r\n    ssl_certificate_key /etc/ssl/certs/wildcard.sslcert.com.key;\r\n\r\n    root /var/www/static;\r\n\r\n    index index.html index.php index.htm index.nginx-debian.html;\r\n\r\n    location / {\r\n            autoindex off;\r\n\r\n            proxy_ssl_name $proxy_host;\r\n            proxy_ssl_server_name on;\r\n\r\n            proxy_cookie_domain domain1.com $host;\r\n\r\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\r\n            proxy_set_header X-Real-IP $remote_addr;\r\n\r\n            proxy_pass_request_headers on;\r\n            proxy_pass https://www.domain1.com/dir/page/;\r\n            proxy_buffering on;\r\n\r\n            proxy_cache off;\r\n    }\r\n}\r\n```", "Just a small update here, I recently updated Nuxt from 3.52 to 3.65 and the above issue has disappeared. The page now loads correctly however instead of staying at the route of the URL i.e. (subdomain.domain2.com) it shows the path of the page (subdomain.domain2.com/path/to/page). \r\n\r\nIs there anything I can do to prevent this from happening?", "I wouldn't advise it.\n\nBut if you absolutely need to, you can follow my steps above to prevent the redirection: https://github.com/nuxt/nuxt/issues/21716#issuecomment-1604560916", "Thank you for the quick response @danielroe, would you be able to guide me in a way I could update the baseURL at runtime? Would I use server middleware or something along those lines?", "@mattgrah-am You can set `NUXT_APP_BASE_URL` as an environment variable.", "I encountered the same problem a few days ago, and I managed to solve it using a head script, as described here: https://github.com/nuxt/nuxt/discussions/32730\n\n```ts\n// nuxt.config.ts\n\nexport default defineNuxtConfig({\n  ssr: true,\n  app: {\n    head: {\n      script: [\n        {\n          textContent: `window.__NUXT__.path = window.location.pathname + window.location.search`,\n          tagPosition: 'bodyClose',\n        },\n      ],\n    },\n  },\n});\n```\n\n@danielroe  I tried your plugin solution and **it doesn't work** with Nuxt **3.17.4**\nThe value of `nuxtApp.payload.path` when the plugin setup function is called is already `undefined` so it doesn't have any effect.\n\nMaybe allowing this behavior to be configurable, as you suggested earlier, might be a good idea.\n\n\n ```ts\n// plugins/prevent-redirection.client.js\nexport default defineNuxtPlugin({\n  order: -40,\n  setup: (nuxtApp) => {\n    console.log('nuxtApp.payload.path:', nuxtApp.payload.path); // prints undefined\n    delete nuxtApp.payload.path;\n  },\n});\n```\n", "**Edit**: Renaming the plugin `plugins/prevent-redirection.client.js` into `plugins/prevent-redirection.server.js` works for me \uD83E\uDD73 \n\nThe plugin idea was not a bad idea but the server has to execute it instead of the client.", "@bokub are you sure you're not doing something different from my example? (it's written for a different use case from yours) I'm pretty sure it should work.", "@danielroe Well, I copy/pasted your example without changing anything, and it didn't work.\n\nRenaming it `.server.js` prevents the URL from changing on pageload, which is what I'm trying to achieve\n\n<img width=\"1048\" height=\"314\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/01193f11-9496-4f66-b53d-76292ea7e0d2\" />\n\nN.B:  In my use case, I need multiple dynamic URLs to display the exact same page, and I use a Cloudflare worker for that. I'm not sure how it's different from the use case of this issue\n\nFeel free to ask if you want me to try some different approaches or print some logs \uD83D\uDE42 " ],
      "repository" : {
        "description" : "The Intuitive Vue Framework.",
        "homepage" : "https://nuxt.com",
        "name" : "nuxt",
        "fullName" : "nuxt/nuxt",
        "htmlUrl" : "https://github.com/nuxt/nuxt",
        "gitUrl" : "git://github.com/nuxt/nuxt.git",
        "sshUrl" : "git@github.com:nuxt/nuxt.git",
        "cloneUrl" : "https://github.com/nuxt/nuxt.git",
        "owner" : {
          "login" : "nuxt",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5319,
        "stargazersCount" : 57743,
        "watchersCount" : 57743,
        "size" : 125357,
        "openIssuesCount" : 849,
        "subscribersCount" : 787,
        "pushedAt" : "2025-07-24T18:11:03Z",
        "languages" : {
          "TypeScript" : 1579995,
          "Dockerfile" : 468,
          "Shell" : 2931,
          "JavaScript" : 30115,
          "Vue" : 15826,
          "HTML" : 27177
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to find a way to deploy a single Nuxt app to multiple URLs like `/nuxt-app/demo-1`, `/nuxt-app/demo-2` without Nuxt auto-redirecting to the wrong URL.",
      "validationOrRequirement" : "The issue seems to be with Nuxt's behavior of automatically redirecting to the wrong URL. The user needs to find a way to prevent this redirection or configure Nuxt to allow running the app from a different URL.",
      "attemptedFixes" : "The user has tried a few solutions, including adding a plugin to prevent redirection, but it didn't work. The user has also tried setting the `baseURL` at runtime, but it didn't work either. The user has also mentioned that the issue has disappeared after updating Nuxt from 3.52 to 3.65, but the page still redirects to the root index page instead of staying at the route of the URL.",
      "otherNotes" : "The issue is about Nuxt auto-redirecting to the wrong URL when serving the app from a different URL. The user is trying to deploy a single Nuxt app to multiple URLs like `/nuxt-app/demo-1`, `/nuxt-app/demo-2`. The issue seems to be with Nuxt's behavior of automatically redirecting to the wrong URL. The user has tried a few solutions, including a plugin to prevent redirection, but it didn't work. The issue has been reported and discussed in the GitHub issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407207
  }, {
    "issueDTO" : {
      "id" : 3177038432,
      "title" : "Fix workflow triggers on the action_lint.yaml workflow",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11488",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "The action_lint.yaml workflow is currently triggered whenever a YAML file within the .github directory has been modified:\n\n```\nname: pr-github-workflow-lint\n\non:\n  pull_request:\n    paths:\n      - .github/*.yaml\n      - .github/*.yml\npermissions:\n  contents: read\n```\n\nGiven this job isn't required, we risk the chance silently breaking this action, regressing main, and the result is that PRs that touch the .github/ directory fail this action regardless of whether they are related to linting failures.",
      "updatedAt" : 1753373600.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 543,
        "stargazersCount" : 4653,
        "watchersCount" : 4653,
        "size" : 211827,
        "openIssuesCount" : 562,
        "subscribersCount" : 100,
        "pushedAt" : "2025-07-24T19:33:09Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16895,
          "Rust" : 20712,
          "Makefile" : 32755,
          "JavaScript" : 435,
          "Go" : 4121797,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix workflow triggers on the action_lint.yaml workflow to prevent silent breaking and regression of main.",
      "validationOrRequirement" : "The workflow should not be triggered by YAML file modifications in .github directory.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The action_lint.yaml workflow is triggered by YAML file modifications in .github directory, which is unnecessary and may break the action, regressing main and failing PRs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407210
  }, {
    "issueDTO" : {
      "id" : 3197300205,
      "title" : "Remove commented out tests in .github/workflows/nightly-tests.yaml",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11575",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "These tests were relevant to the 1.x project and are no longer implemented on the 2.x front. I think we should remove them & re-introduce if there's a need.",
      "updatedAt" : 1753373534.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "https://github.com/kgateway-dev/kgateway/blob/main/.github/workflows/nightly-tests.yaml#L27-L42 & https://github.com/kgateway-dev/kgateway/blob/main/.github/workflows/nightly-tests.yaml#L67-L212" ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 543,
        "stargazersCount" : 4653,
        "watchersCount" : 4653,
        "size" : 211827,
        "openIssuesCount" : 562,
        "subscribersCount" : 100,
        "pushedAt" : "2025-07-24T19:33:09Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16895,
          "Rust" : 20712,
          "Makefile" : 32755,
          "JavaScript" : 435,
          "Go" : 4121797,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove commented out tests in .github/workflows/nightly-tests.yaml",
      "validationOrRequirement" : "Remove commented out tests in .github/workflows/nightly-tests.yaml",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Tests were relevant to 1.x project and are no longer implemented on 2.x front",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407212
  }, {
    "issueDTO" : {
      "id" : 1103246562,
      "title" : "MeanVarianceNormalization without division by zero",
      "url" : "https://github.com/onnx/onnx/issues/3947",
      "repositoryName" : "onnx/onnx",
      "description" : "# Bug Report\r\n\r\n### Is the issue related to model conversion?\r\nYes: While converting LayerNorm to onnx using MeanVarianceNormalization\r\n\r\n### Describe the bug\r\nWithout Variance in the input data I get out NaN. But the outcome should be zero. Look like division by zero. \r\n\r\nMaybe it works as designed, then this is more a feature request for a parameter epsilon: epsilon = 0 as now, and with some small epsilon division by epsilon instead of zero..\r\n\r\n### System information\r\n- OS Platform and Distribution (Windows 11): \r\n- ONNX version:  1.10.2\r\n- Protobuf version: 3 \r\n \r\n",
      "updatedAt" : 1753373508.000000000,
      "user" : "enpasos",
      "userHtmlUrl" : "https://github.com/enpasos",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9622808?v=4",
      "labels" : [ "no-stale", "bug", "topic: operator", "contributions welcome", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Well apparently the original Layer Norm did nt propose to add an epsilon:\r\nhttps://arxiv.org/pdf/1607.06450.pdf\r\nNow in \"real life\", most add :\r\nhttps://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html\r\nThere is a batchNorm op\r\nhttps://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization\r\na meanVarNorm op:\r\nhttps://github.com/onnx/onnx/blob/main/docs/Operators.md#MeanVarianceNormalization\r\nbut still no layerNorm : \r\nhttps://github.com/onnx/onnx/issues/2379\r\n", "For MeanVarianceNormalization, adding an epsilon attribute makes sense.", "> For MeanVarianceNormalization, adding an epsilon attribute makes sense.\n\n@gramalingam: Concur.\n\nWe encountered the missing epsilon while implementing the [Chromium WebNN backend atop ORT](https://chromium-review.googlesource.com/c/chromium/src/+/6758777). ONNX's other normalization operators have an epsilon parameter. So it's aberrant that just MVN is missing it (which would let us shave off ~100 lines of decomposition code).\n\n- ??? [`BatchNormalization`](https://onnx.ai/onnx/operators/onnx__BatchNormalization.html)\n- ??? [`GroupNormalization`](https://onnx.ai/onnx/operators/onnx__GroupNormalization.html)\n- ??? [`InstanceNormalization`](https://onnx.ai/onnx/operators/onnx__InstanceNormalization.html)\n- ??? [`LayerNormalization`](https://onnx.ai/onnx/operators/onnx__LayerNormalization.html)\n- ??? [`MeanVarianceNormalization`](https://onnx.ai/onnx/operators/onnx__MeanVarianceNormalization.html)\n- ??? [`RMSNormalization`](https://onnx.ai/onnx/operators/onnx__RMSNormalization.html)\n\nReopening (rather than creating a new one)." ],
      "repository" : {
        "description" : "Open standard for machine learning interoperability",
        "homepage" : "https://onnx.ai/",
        "name" : "onnx",
        "fullName" : "onnx/onnx",
        "htmlUrl" : "https://github.com/onnx/onnx",
        "gitUrl" : "git://github.com/onnx/onnx.git",
        "sshUrl" : "git@github.com:onnx/onnx.git",
        "cloneUrl" : "https://github.com/onnx/onnx.git",
        "owner" : {
          "login" : "onnx",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3772,
        "stargazersCount" : 19316,
        "watchersCount" : 19316,
        "size" : 56244,
        "openIssuesCount" : 301,
        "subscribersCount" : 435,
        "pushedAt" : "2025-07-24T21:36:52Z",
        "languages" : {
          "PowerShell" : 1371,
          "C++" : 2812721,
          "Shell" : 2433,
          "C" : 1905,
          "Batchfile" : 424,
          "CMake" : 27602,
          "PureBasic" : 2310548,
          "Python" : 3189558
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add an epsilon parameter to MeanVarianceNormalization to avoid division by zero and ensure correct output when the input data has no variance.",
      "validationOrRequirement" : "The issue is related to model conversion, specifically while converting LayerNorm to onnx using MeanVarianceNormalization. The requirement is to add an epsilon parameter to MeanVarianceNormalization to avoid division by zero.",
      "attemptedFixes" : "Adding an epsilon attribute to MeanVarianceNormalization makes sense, as other normalization operators have this parameter.",
      "otherNotes" : "The issue is related to model conversion, specifically while converting LayerNorm to onnx using MeanVarianceNormalization. The bug is that without variance in the input data, the output becomes NaN. This might be intended behavior, but it could be a feature request to add an epsilon parameter to avoid division by zero.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407218
  }, {
    "issueDTO" : {
      "id" : 98546859,
      "title" : "DOC/ERR: better error message on unsuccessful datetime parsing",
      "url" : "https://github.com/pandas-dev/pandas/issues/10720",
      "repositoryName" : "pandas-dev/pandas",
      "description" : "exceptions that are raised on unsuccessful datetime/timedelta parsing should add this:\n\n`you can coerce to NaT by passing errors='coerce'`\n\ncomment at the end: https://github.com/pydata/pandas/pull/10674\n",
      "updatedAt" : 1753373503.000000000,
      "user" : "jreback",
      "userHtmlUrl" : "https://github.com/jreback",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/953992?v=4",
      "labels" : [ "Error Reporting", "Enhancement", "good first issue", "Datetime" ],
      "state" : "OPEN",
      "comments" : [ "I was looking at this today, what actually does need to be changed in the code? I'm having trouble understanding the logic that would need this error? Does anyone have an example?\n", "The idea is that when an error is raised by `to_datetime` (all different cases when a the string cannot be parsed), you get an additional message saying that you can use `errors='coerce'` to coerce to NaT and in this way suppress the error.\n\nE.g.:\n\n```\nIn [6]: pd.to_datetime('something', errors='raise')\n\nValueError: Unknown string format\n```\n\ncould say something like \"ValueError: Unknown string format. You can coerce errors to NaT by passing errors='coerce'\"\n", "@springcoil so there are lots of tests that assert errors using `to_datetime`. Ideallly would go thru those and see what they produce, and fix those that are not either context sensitive (e.g. maybe can give a more informative message), and also add that you can pass `error='coerce'` to get a `NaT` if desired.\n\nmost of these tests are in `tseries/tests/test_timeseries.py`\n", "Hello, can I participate here ?", "@baevpetr go for it", "take", "I want to clarify: after calling `pd.to_datetime('some_nonsense', errors='raise')` we get:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/pandas/core/arrays/datetimes.py\", line 1979, in objects_to_datetime64ns\r\n    values, tz_parsed = conversion.datetime_to_datetime64(data)\r\n  File \"pandas/_libs/tslibs/conversion.pyx\", line 200, in pandas._libs.tslibs.conversion.datetime_to_datetime64\r\n    raise TypeError(f'Unrecognized value type: {type(val)}')\r\nTypeError: Unrecognized value type: <class 'str'>\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-18-3148d274c504>\", line 1, in <module>\r\n    pd.to_datetime('some_nonsense', errors='raise')\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/pandas/util/_decorators.py\", line 208, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\", line 796, in to_datetime\r\n    result = convert_listlike(np.array([arg]), box, format)[0]\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\", line 463, in _convert_listlike_datetimes\r\n    allow_object=True,\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/pandas/core/arrays/datetimes.py\", line 1984, in objects_to_datetime64ns\r\n    raise e\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/pandas/core/arrays/datetimes.py\", line 1975, in objects_to_datetime64ns\r\n    require_iso8601=require_iso8601,\r\n  File \"pandas/_libs/tslib.pyx\", line 465, in pandas._libs.tslib.array_to_datetime\r\n    1) datetime64[ns] data\r\n  File \"pandas/_libs/tslib.pyx\", line 688, in pandas._libs.tslib.array_to_datetime\r\n    if is_coerce:\r\n  File \"pandas/_libs/tslib.pyx\", line 822, in pandas._libs.tslib.array_to_datetime_object\r\n    return oresult, None\r\n  File \"pandas/_libs/tslib.pyx\", line 813, in pandas._libs.tslib.array_to_datetime_object\r\n    oresult[i] = <object>NaT\r\n  File \"pandas/_libs/tslibs/parsing.pyx\", line 225, in pandas._libs.tslibs.parsing.parse_datetime_string\r\n    try:\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/dateutil/parser/_parser.py\", line 1358, in parse\r\n    return DEFAULTPARSER.parse(timestr, **kwargs)\r\n  File \"/home/bmth/anaconda3/envs/pandas-dev/lib/python3.7/site-packages/dateutil/parser/_parser.py\", line 649, in parse\r\n    raise ValueError(\"Unknown string format:\", timestr)\r\nValueError: ('Unknown string format:', 'some_nonsense')\r\n```\r\n`ValueError` raised in `dateutil/parser/_parser.py` (line 649):\r\n```\r\n        if res is None:\r\n            raise ValueError(\"Unknown string format:\", timestr)\r\n\r\n        if len(res) == 0:\r\n            raise ValueError(\"String does not contain a date:\", timestr)\r\n```\r\nand we catch it in `pandas/core/arrays/datetimes.py` (line 1968):\r\n```\r\n    try:\r\n        result, tz_parsed = tslib.array_to_datetime(\r\n            data,\r\n            errors=errors,\r\n            utc=utc,\r\n            dayfirst=dayfirst,\r\n            yearfirst=yearfirst,\r\n            require_iso8601=require_iso8601,\r\n        )\r\n    except ValueError as e:\r\n        try:\r\n            values, tz_parsed = conversion.datetime_to_datetime64(data)\r\n            # If tzaware, these values represent unix timestamps, so we\r\n            #  return them as i8 to distinguish from wall times\r\n            return values.view(\"i8\"), tz_parsed\r\n        except (ValueError, TypeError):\r\n            raise e\r\n```\r\nFor now I see variants:\r\n1) Append '_you can coerce to NaT by passing errors='coerce'_' for both of `ValueError`s.\r\n2) Distinguish them based on the message.\r\n3) *fix my assumption if I talking some nonsense.", "@baevpetr without looking at it _too_ closely, I'm tentatively ruling out variant 3.\r\n\r\nAs the person volunteering to put in the time to improve this, you get to choose your preferred approach.", "31ead07b49466f5c02dc2849274f405c86f31319", "Just ping @jbrockmendel or @jreback or @jorisvandenbossche.", "Ping you guys one more time)\r\n@jbrockmendel or @jreback or @jorisvandenbossche.", "@baevpetr if you want to put up a PR much easier to see and comment", "take", "@MomIsBestFriend for my understanding, why did you close your PR? It looked like decent changes for this ticket. Was there anything unclear for you? I can help out if you want if time is the issue for you.", "I'm not able to work on this issue right now and tried to unassign myself by deleting my last comment. But that didn't work. Please, this issue is open for whoever is available or wants to take it.", "take\n", "> I'm not able to work on this issue right now and tried to unassign myself by deleting my last comment. But that didn't work. Please, this issue is open for whoever is available or wants to take it.\n\nHi @vuinguyen, I would be interested in taking a look. However, you may need to unassign first by heading to the 'Assignees' section and clicking your profile to remove? Unsure if that works for you but seems I can't assign it to myself in the meantime.", "@vee-16 I tried to click on my profile to remove myself, but that didn't work for me. \n\n@jbrockmendel @mroeschke can you help us? @vee-16 would like to work on this issue, but I cannot unassign myself from it.\n\nThanks for your help!\n\n> > I'm not able to work on this issue right now and tried to unassign myself by deleting my last comment. But that didn't work. Please, this issue is open for whoever is available or wants to take it.\n> \n> Hi [@vuinguyen](https://github.com/vuinguyen), I would be interested in taking a look. However, you may need to unassign first by heading to the 'Assignees' section and clicking your profile to remove? Unsure if that works for you but seems I can't assign it to myself in the meantime.\n\n", "Try now.", "take", "> Try now.\n\n@jbrockmendel thanks" ],
      "repository" : {
        "description" : "Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more",
        "homepage" : "https://pandas.pydata.org",
        "name" : "pandas",
        "fullName" : "pandas-dev/pandas",
        "htmlUrl" : "https://github.com/pandas-dev/pandas",
        "gitUrl" : "git://github.com/pandas-dev/pandas.git",
        "sshUrl" : "git@github.com:pandas-dev/pandas.git",
        "cloneUrl" : "https://github.com/pandas-dev/pandas.git",
        "owner" : {
          "login" : "pandas-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18716,
        "stargazersCount" : 46087,
        "watchersCount" : 46087,
        "size" : 370472,
        "openIssuesCount" : 3744,
        "subscribersCount" : 1112,
        "pushedAt" : "2025-07-24T20:02:20Z",
        "languages" : {
          "Smarty" : 8852,
          "Dockerfile" : 6015,
          "Shell" : 21760,
          "CSS" : 7370,
          "C" : 354816,
          "Meson" : 12525,
          "HTML" : 457849,
          "XSLT" : 1196,
          "Cython" : 1391478,
          "Python" : 20997424
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to improve error messages for unsuccessful datetime and timedelta parsing in pandas by suggesting that the error can be suppressed by passing `errors='coerce'` to return NaT.",
      "validationOrRequirement" : "The issue requires reviewing tests in `tseries/tests/test_timeseries.py` to see what they produce and fix those that are not context-sensitive.",
      "attemptedFixes" : "The author suggests adding a message to the error message saying that the error can be suppressed by passing `errors='coerce'` to return NaT. There are also some discussion about how to distinguish between different types of errors and how to handle them.",
      "otherNotes" : "The issue is about improving error messages for unsuccessful datetime and timedelta parsing in pandas. The idea is to add a message suggesting that the error can be suppressed by passing `errors='coerce'` to return NaT. The author suggests reviewing tests in `tseries/tests/test_timeseries.py` to see what they produce and fix those that are not context-sensitive. The issue has been open for a while and has had some discussion about how to approach the fix.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407226
  }, {
    "issueDTO" : {
      "id" : 1776239817,
      "title" : "AttributeError: This 'LabelEncoder' has no attribute 'set_output'",
      "url" : "https://github.com/scikit-learn/scikit-learn/issues/26711",
      "repositoryName" : "scikit-learn/scikit-learn",
      "description" : "### Describe the bug\n\nI tried to call **'set_output'** from LabelEncoder object and got the AttributeError.\r\n\r\n[The document](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) says sklearn.preprocessing.LabelEncoder has **'set_output'** method, but it was not working.\r\n\r\nSoon I found most of other **'set_output'** available estimators inherits both of sklearn.base.OneToOneFeatureMixin and sklearn.base.TransformerMinxin\r\n\r\nHowerver, [LabelEncoder](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/preprocessing/_label.py) only inherits the TransformerMinxin.\r\n\r\n```python\r\nclass LabelEncoder(TransformerMixin, BaseEstimator):\r\n```\r\n\r\n</br>\r\n\r\nFunction **'set_output'** seems available when **'_auto_wrap_is_configured'** is True. [(utils._set_output.py)](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/utils/_set_output.py)\r\n\r\n```python\r\n    @available_if(_auto_wrap_is_configured)\r\n    def set_output(self, *, transform=None):\r\n        \"\"\"Set output container.\r\n\r\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\r\n        for an example on how to use the API.\r\n\r\n        Parameters\r\n        ----------\r\n        transform : {\"default\", \"pandas\"}, default=None\r\n            Configure output of `transform` and `fit_transform`.\r\n\r\n            - `\"default\"`: Default output format of a transformer\r\n            - `\"pandas\"`: DataFrame output\r\n            - `None`: Transform configuration is unchanged\r\n\r\n        Returns\r\n        -------\r\n        self : estimator instance\r\n            Estimator instance.\r\n        \"\"\"\r\n        if transform is None:\r\n            return self\r\n\r\n        if not hasattr(self, \"_sklearn_output_config\"):\r\n            self._sklearn_output_config = {}\r\n\r\n        self._sklearn_output_config[\"transform\"] = transform\r\n        return self\r\n```\r\n\r\n</br>\r\n\r\nThen estimator should have **'get_feature_names_out'** to make **'_auto_wrap_is_configured'** returns True. [(utils._set_output.py)](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/utils/_set_output.py)\r\n\r\n```python\r\ndef _auto_wrap_is_configured(estimator):\r\n    \"\"\"Return True if estimator is configured for auto-wrapping the transform method.\r\n\r\n    `_SetOutputMixin` sets `_sklearn_auto_wrap_output_keys` to `set()` if auto wrapping\r\n    is manually disabled.\r\n    \"\"\"\r\n    auto_wrap_output_keys = getattr(estimator, \"_sklearn_auto_wrap_output_keys\", set())\r\n    return (\r\n        hasattr(estimator, \"get_feature_names_out\")\r\n        and \"transform\" in auto_wrap_output_keys\r\n    )\r\n```\r\n\r\n</br>\r\n\r\n To have **'get_feature_names_out'** attr, estimator should inherit OneToOneFeatureMixin as I think. [(base.py)](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/base.py)\r\n\r\n```python\r\nclass OneToOneFeatureMixin:\r\n    \"\"\"Provides `get_feature_names_out` for simple transformers.\r\n\r\n    This mixin assumes there's a 1-to-1 correspondence between input features\r\n    and output features, such as :class:`~preprocessing.StandardScaler`.\r\n    \"\"\"\r\n\r\n    def get_feature_names_out(self, input_features=None):\r\n        \"\"\"Get output feature names for transformation.\r\n\r\n        Parameters\r\n        ----------\r\n        input_features : array-like of str or None, default=None\r\n            Input features.\r\n\r\n            - If `input_features` is `None`, then `feature_names_in_` is\r\n              used as feature names in. If `feature_names_in_` is not defined,\r\n              then the following input feature names are generated:\r\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\r\n            - If `input_features` is an array-like, then `input_features` must\r\n              match `feature_names_in_` if `feature_names_in_` is defined.\r\n\r\n        Returns\r\n        -------\r\n        feature_names_out : ndarray of str objects\r\n            Same as input features.\r\n        \"\"\"\r\n        check_is_fitted(self, \"n_features_in_\")\r\n        return _check_feature_names_in(self, input_features)\r\n```\r\n\r\n</br>\r\n\r\nI want to know that it is kind of a bug, or the document says wrong information.\n\n### Steps/Code to Reproduce\n\n```python\r\nfrom sklearn.preprocessing import LabelEncoder\r\n\r\nLabelEncoder().set_output()\r\n```\n\n### Expected Results\n\nNo error is thrown\n\n### Actual Results\n\n```python\r\n--------------------------------------------------------------------------------\r\nAttributeError                                 Traceback (most recent call last)                        \r\n/tmp/ipykernel_16765/3091610596.py in <module>\r\n---> 1 LabelEncoder().set_output()\r\n\r\n~/.local/lib/python3.8/site-packages/sklearn/utils/_available_if.py in __get__(self, obj, owner)\r\n      31        # this is to allow access to the docstrings.\r\n      32        if not self.check(obj):\r\n--->  33            raise attr_err\r\n      34        out = MethodType(self.fn, obj)\r\n      35\r\nAttributeError: This 'LabelEncoder' has no attribute 'set_output'\r\n```\r\n            \r\n             \r\n            \n\n### Versions\n\n```shell\n1.2.2\n```\n",
      "updatedAt" : 1753373453.000000000,
      "user" : "Clarit7",
      "userHtmlUrl" : "https://github.com/Clarit7",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/55811781?v=4",
      "labels" : [ "Bug", "Documentation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Not entirely sure what we want here since the `LabelEncoder` and `LabelBinarizer` are dedicated to transforming the target `y` and not the input `X`. For consistency reasons, it might make sense to output a Series or a DataFrame, however, the part of the feature names does not make any sense.\r\n\r\n@thomasjpfan any thoughts on this one?", "@glemaitre Thanks for replying. Then, should 'set_output' be removed from the document?", "Not for the moment, I would like to have thought of some @scikit-learn/core-devs on the issue to know what we consider the way forward here.", "Apparently `LabelEncoder` is not meant to be used on 2D inputs:\r\n\r\n```python\r\nIn [2]: import numpy as np\r\n\r\nIn [3]: labels = np.asarray([\"a\", \"a\", \"b\"])\r\n\r\nIn [4]: from sklearn.preprocessing import LabelEncoder\r\n\r\nIn [5]: LabelEncoder().fit_transform(labels)\r\nOut[5]: array([0, 0, 1])\r\n\r\nIn [6]: LabelEncoder().fit_transform(labels.reshape(-1, 1))\r\n/Users/ogrisel/code/scikit-learn/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\r\n  y = column_or_1d(y, warn=True)\r\nOut[6]: array([0, 0, 1])\r\n```\r\n\r\nso I would never expect to output a 2D datastructure like `pandas.DataFrame` but we could output a `pandas.Series` if the input is also a `Series` and preserve its name.\r\n\r\nBut this is quite different from the usual `get_feature_names_out` logic.", "Maybe we should remove `set_output` from the doc for this class as a short term fix and decide later if we want to implement it or not for this transformer.", "Maybe inheriting from `sklearn.base.OneToOneFeatureMixin` is wrong for this estimator?", "The `set_output` API was not designed to work with the label encoders. The `set_output` method entry should not be a part of the API docs.", "@thomasjpfan What is your recommended action to solve this issue?", "Could it be that the issue is related to the [@available_if](https://github.com/scikit-learn/scikit-learn/blob/02da144bff9521a9b4a683b27e3886f9e8680343/sklearn/utils/_set_output.py#L219) decorator? \r\n\r\nMaybe the doc building workflow does not how to interpret such a decorator (which should evaluate to `False` for the `LabelEncoder`).", "> Maybe the doc building workflow does not how to interpret such a decorator\r\n\r\nThis is the issue. From memory, Sphinx will recognize everything that is defined in code. When I was debugging this, I did not find a way to hide the method from Sphinx. ", "> When I was debugging this, I did not find a way to hide the method from Sphinx.\n\ntechnically one case use the exclude-members option to hide certain methods\n\nhttps://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html#directive-option-autoclass-exclude-members", "/take", "I???ve looked into this, and indeed the root of the problem is how the [@available_if](https://github.com/scikit-learn/scikit-learn/blob/543092020dc1bfa42b7722c9245b53cf277fe1b4/sklearn/utils/_available_if.py#L57) decorator works, as even though it makes `LabelEncoder().set_output` raise AttributeError, `set_output` is still in `dir(LabelEncoder)`, and `LabelEncoder.set_output` does give back the `_SetOutputMixin.set_output` method. So sphinx will find it as a member of the class to be documented ([see here](https://github.com/sphinx-doc/sphinx/blob/ca043c3ccdc88ae5d30e4527382fe0c8bd5e2a88/sphinx/ext/autodoc/__init__.py#L1968)).\n\nI see a few possible ways to remove the documentation:\n\n- I think the best solution would be to separate [`TransformerMixin`](https://github.com/scikit-learn/scikit-learn/blob/543092020dc1bfa42b7722c9245b53cf277fe1b4/sklearn/base.py#L801) and [`_SetOutputMixin`](https://github.com/scikit-learn/scikit-learn/blob/543092020dc1bfa42b7722c9245b53cf277fe1b4/sklearn/utils/_set_output.py#L347) (and expose the latter too), so have the `set_output` method opt-in instead of opt-out, but that would be a breaking change.\n\n- Adding `:exclude-members: set_output` to the [doc template](scikit-learn/doc/templates/base.rst) as @Remi-Gau suggested, but then it's never documented (maybe would be good as a temporary solution?).\n\n- For classes that don???t want to implement `set_output`, we could override it by one raising NotImplementedError (and having a docstring that makes sphinx skip it, by adding `:meta private:`), although that kind of goes against the magic using the `available_if` decorator and the `auto_wrap_output_keys` param. (Other such classes are LabelBinarizer, MultiLabelBinarizer, HashingVectorizer and TfidfTransformer.)\n\nWays that don???t work (currently):\n\n- In sphinx, one can connect a method to call back when autodoc is deciding wether a member should be documented or skipped [like here](https://github.com/scikit-learn/scikit-learn/blob/bde701db13cebd5d5ed0bc049fb0bc9693c6c5dc/doc/conf.py#L848), but unfortunately (as of 8.1.3), is only gets the member method and not the parent class, so it???s not really possible to distinguish the `set_output` method of a class that has it or not, because it still exists in the cases when it???s not callable, and it???s the same function object (except maybe using inspect???).\n\n- Trying to remove the method with `delattr(LabelEncoder, \"set_output\")` raises AttributeError.\n\nAre there any preferences?", "There is a similar issue with linked PRs in https://github.com/scikit-learn/scikit-learn/issues/28558. In particular https://github.com/scikit-learn/scikit-learn/pull/28749 was on a good trajectory to solving this but then the original PR creator closed it. Maybe worth restarting that PR\n\nThe issue solves a different, but I think, related problem: the fact that tab completion and `dir(some_estimator)` will list methods that don't exist because the default `__dir__` implementation doesn't understand the `available_if` decorator", "???Hi, I???d like to work on this. Can I take it????\n", "> ???Hi, I???d like to work on this. Can I take it????\n\nOk!", "/unassign\n", "@student-ChestaVashishtha  I don't know how I can unassign myself. Maybe you can take it by commenting \"/take\" nontheless?", "/take", "/take\n" ],
      "repository" : {
        "description" : "scikit-learn: machine learning in Python",
        "homepage" : "https://scikit-learn.org",
        "name" : "scikit-learn",
        "fullName" : "scikit-learn/scikit-learn",
        "htmlUrl" : "https://github.com/scikit-learn/scikit-learn",
        "gitUrl" : "git://github.com/scikit-learn/scikit-learn.git",
        "sshUrl" : "git@github.com:scikit-learn/scikit-learn.git",
        "cloneUrl" : "https://github.com/scikit-learn/scikit-learn.git",
        "owner" : {
          "login" : "scikit-learn",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 26079,
        "stargazersCount" : 62762,
        "watchersCount" : 62762,
        "size" : 173737,
        "openIssuesCount" : 2185,
        "subscribersCount" : 2137,
        "pushedAt" : "2025-07-24T10:36:54Z",
        "languages" : {
          "C++" : 147428,
          "Shell" : 46980,
          "CSS" : 13133,
          "C" : 41895,
          "Meson" : 32297,
          "Makefile" : 1034,
          "JavaScript" : 1730,
          "Cython" : 728806,
          "Python" : 12556187
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about the incorrect documentation of the LabelEncoder class, specifically the 'set_output' method. The method is not implemented for this class, and the documentation should be updated to reflect this.",
      "validationOrRequirement" : "The issue is related to the documentation of the LabelEncoder class, and the fact that the 'set_output' method is not implemented for this class. The documentation should be updated to reflect this.",
      "attemptedFixes" : "The issue has been discussed, and a few possible solutions have been proposed, including separating TransformerMixin and _SetOutputMixin, adding :exclude-members: set_output to the doc template, and overriding set_output with NotImplementedError. However, none of these solutions have been implemented yet.",
      "otherNotes" : "The issue is related to the LabelEncoder not having the 'set_output' method, and the documentation incorrectly stating that it does. The 'set_output' method is not implemented for LabelEncoder, and it's not clear if it should be implemented or not. The issue is also related to the [@available_if](https://github.com/scikit-learn/scikit-learn/blob/02da144bff9521a9b4a683b27e3886f9e8680343/sklearn/utils/_set_output.py#L219) decorator, which is causing the method to be listed in the documentation even though it's not actually implemented.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407235
  }, {
    "issueDTO" : {
      "id" : 1745977398,
      "title" : "TransformedTargetRegressor forces 1d y shape to regressor",
      "url" : "https://github.com/scikit-learn/scikit-learn/issues/26530",
      "repositoryName" : "scikit-learn/scikit-learn",
      "description" : "### Describe the bug\r\n\r\nI experience the following error when using TransformedTargetRegressor with my skorch model:\r\nValueError: The target data shouldn't be 1-dimensional but instead have 2 dimensions, with the second dimension having the same size as the number of regression targets (usually 1). Please reshape your target data to be 2-dimensional (e.g. y = y.reshape(-1, 1).\r\n\r\n#### After checking the Source Code this lead me the the following unexpected behaivor which makes little sense:\r\n\r\nIf TransformedTargetRegressor is fitted with with a 2d dimensional y, it will still be transformed to a 1d dimensional output\r\n\r\ny should have the same input and output shapes with a TransformedTargetRegressor or there should be an init argument to disable the change of the input shape\r\n(Yes, internally it gets casted to 2d, but I???m talking about the In and Outputs) \r\n\r\nhttps://github.com/scikit-learn/scikit-learn/blob/364c77e04/sklearn/compose/_target.py#L20\r\nTransformedTargetRegressor-->fit\r\n\r\n```python\r\n        if y.ndim == 1:\r\n            y_2d = y.reshape(-1, 1)\r\n        else:\r\n            y_2d = y\r\n        self._fit_transformer(y_2d)\r\n\r\n[...]\r\n\r\n        if y_trans.ndim == 2 and y_trans.shape[1] == 1:\r\n            y_trans = y_trans.squeeze(axis=1)\r\n```\r\nBut in the end we squeeze it back into a 1d which causes issues for models which expect a 2d input of y\r\ny was 2d in the beginning for a reason\r\n\r\n### **The following code would solve this:**\r\n```\r\n        if y_trans.ndim == 2 and y_trans.shape[1] == 1 and y.ndim==1:  #only squeeze back to 1d if y is 1d\r\n            y_trans = y_trans.squeeze(axis=1)\r\n```\r\n\r\nThis could only create an issue where the y input was for some reason 2d but should be 1d for the regressor. \r\nIn this case an attribute would be nice\r\n```\r\n        if y_trans.ndim == 2 and y_trans.shape[1] == 1 and self.output_dim == 1:\r\n            y_trans = y_trans.squeeze(axis=1)\r\n```\r\n\r\nAlso in TransformedTargetRegressor-->predict the results dont get squeezed after the prediction of the estimator - only if the original input shape was 1, in that case it is squeezed\r\n\r\nSo the result looks as expected, but only if the regressor takes a 1d y\r\nIf the estimator expects a 2d y the code fails\r\n\r\n### Steps/Code to Reproduce\r\n\r\n```python\r\nregressor = TransformedTargetRegressor(\r\n    transformer=MinMaxScaler()\r\n)\r\nX, y = np.random.rand(10, 10), np.expand_dims(np.random.rand(10), 1)\r\nregressor.fit(X, y)\r\n```\r\n\r\n### Expected Results\r\n\r\nThe shape of y stays the same as the input OR there is a attribute which allows the choice of  (1d or original)  or (1d or 2d)\r\n\r\ninput | internal | output\r\n2d ???> 2d ???> 2d\r\n1d ???> 2d ???> 1d\r\n\r\n### Actual Results\r\n\r\nthe regressor gets just a 1d array even through y was specifically set to 2d\r\n(I don't know how to extract these results without an debugger)\r\n\r\nIt works for this example because the default regressor is used, but when using it with other models they might need the 2nd dimention of y, because it was specifically reshaped  (-1,1)\r\n\r\ninput | internal | output\r\n2d ???> 2d ???> 1d    THIS creates issues for the regressive which is passed to the Transformer if it expects a 2d array because a 2d y was given \r\n1d ???> 2d ???> 1d\r\n\r\n### Versions\r\n\r\n```shell\r\nSystem:\r\n    python: 3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]\r\nexecutable: /anaconda/envs/azureml_py310_sdkv2/bin/python\r\n   machine: Linux-5.15.0-1017-azure-x86_64-with-glibc2.31\r\n\r\nPython dependencies:\r\n      sklearn: 1.1.3\r\n          pip: 22.1.2\r\n   setuptools: 61.2.0\r\n        numpy: 1.23.2\r\n        scipy: 1.9.0\r\n       Cython: None\r\n       pandas: 1.4.3\r\n   matplotlib: 3.6.2\r\n       joblib: 1.2.0\r\nthreadpoolctl: 3.1.0\r\n```\r\n",
      "updatedAt" : 1753373377.000000000,
      "user" : "Daniel3009",
      "userHtmlUrl" : "https://github.com/Daniel3009",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/63856880?v=4",
      "labels" : [ "Bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "The reason for the reshaping is explained in the [documentation note](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html#sklearn.compose.TransformedTargetRegressor.fit):\r\n\r\n> Internally, the target y is always converted into a 2-dimensional array to be used by scikit-learn transformers. At the time of prediction, the output will be reshaped to have the same number of dimensions as y.\r\n\r\nUsually, we always consider `y` being of shape `(n_samples,)` for single target or `(n_samples, n_outputs)` otherwise but apparently it is not something that we enforce or that we are consistent with:\r\n\r\n```python\r\nIn [17]: LinearRegression().fit(X, y).predict(X)\r\nOut[17]: \r\narray([[0.24711583],\r\n       [0.74242216],\r\n       [0.55222396],\r\n       [0.84829166],\r\n       [0.17998768],\r\n       [0.0245152 ],\r\n       [0.22000849],\r\n       [0.61546997],\r\n       [0.1222009 ],\r\n       [0.48522966]])\r\n\r\nIn [18]: from sklearn.ensemble import RandomForestRegressor\r\n\r\nIn [19]: RandomForestRegressor().fit(X, y).predict(X)\r\n<ipython-input-19-52a4ba3e81e7>:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\r\n  RandomForestRegressor().fit(X, y).predict(X)\r\nOut[19]: \r\narray([0.33050337, 0.57584412, 0.52647597, 0.61801084, 0.29033987,\r\n       0.16826488, 0.32458667, 0.4966041 , 0.17528285, 0.45642003])\r\n```\r\n\r\nHere, the linear model would work as expected but the tree will make the conversion and raise a warning.\r\n\r\nSo in a meta-estimator, it makes it even more complex. I assume that a possibility is to convert to a 1D-vector and warn because it will work with all scikit-learn models. We could also raise an error and not warn at all.\r\n\r\n", "Yes, internally y is converted to 2d always.\r\n\r\nThe issue is the following behaviour I added in the post above: \r\n\r\nExpected\r\ninput | internal | output\r\n2d ???> 2d ???> 2d\r\n1d ???> 2d ???> 1d\r\nY doesn???t change shape between Input and Output \r\n\r\nActual Currently\r\ninput | internal | output\r\n2d ???> 2d ???> 1d XXXX\r\n1d ???> 2d ???> 1d\r\nY output is always 1d even though the dimension gets saved ", "We should be fixing the `TransformedTargetRegressor` to tolerate this case.\r\nWe can see later regarding the consistency across regressors later on.", "@glemaitre I was checking this and it seems that we might need to add a new attribute to handle this. This is because I saw that the docs of some of the regressors specify that y can only be 1d or of shape (n_samples,). What do you think?", "> a new attribute to handle this\r\n\r\nUntil it is a private attribute this is fine. We would need to catch potential warnings.", "> > a new attribute to handle this\r\n> \r\n> Until it is a private attribute this is fine. We would need to catch potential warnings.\r\n\r\nActually I meant to suggest a new parameter not an attribute. Sorry about using the wrong terminology. Basically we can add a new parameter like preserve_y_dim which is False by default and only if some underlying regressor only takes 2d input the user can specify this parameter to be True. Then if the y is 2d by default it won't be squeezed to 1d.", "> Actually I meant to suggest a new parameter not an attribute\r\n\r\nI am under the impression that this is not a parameter that a user would take care of. I think that we should instead be having good default behaviour.", "/take", "/take", "/take", "/take" ],
      "repository" : {
        "description" : "scikit-learn: machine learning in Python",
        "homepage" : "https://scikit-learn.org",
        "name" : "scikit-learn",
        "fullName" : "scikit-learn/scikit-learn",
        "htmlUrl" : "https://github.com/scikit-learn/scikit-learn",
        "gitUrl" : "git://github.com/scikit-learn/scikit-learn.git",
        "sshUrl" : "git@github.com:scikit-learn/scikit-learn.git",
        "cloneUrl" : "https://github.com/scikit-learn/scikit-learn.git",
        "owner" : {
          "login" : "scikit-learn",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 26079,
        "stargazersCount" : 62762,
        "watchersCount" : 62762,
        "size" : 173737,
        "openIssuesCount" : 2185,
        "subscribersCount" : 2137,
        "pushedAt" : "2025-07-24T10:36:54Z",
        "languages" : {
          "C++" : 147428,
          "Shell" : 46980,
          "CSS" : 13133,
          "C" : 41895,
          "Meson" : 32297,
          "Makefile" : 1034,
          "JavaScript" : 1730,
          "Cython" : 728806,
          "Python" : 12556187
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is that TransformedTargetRegressor forces the y shape to be 1d, even when it's initially 2d, which can cause issues for regressors that expect a 2d y shape",
      "validationOrRequirement" : "y should have the same input and output shapes with a TransformedTargetRegressor or there should be an init argument to disable the change of the input shape",
      "attemptedFixes" : "Adding a new attribute or parameter to handle this case, possibly 'preserve_y_dim' to allow 2d y shape",
      "otherNotes" : "TransformedTargetRegressor forces 1d y shape to regressor, expecting 2d y shape instead",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407240
  }, {
    "issueDTO" : {
      "id" : 3189270357,
      "title" : "[Tootles] `/metadata` endpoint returns an unexpected 500 error",
      "url" : "https://github.com/tinkerbell/tinkerbell/issues/231",
      "repositoryName" : "tinkerbell/tinkerbell",
      "description" : "In Tootles, when `/metadata` endpoint is hit and there is no corresponding Hardware object, the \"hack\" frontend will return a 500 error. This should be a `404` not found instead.\n\nreference: https://github.com/tinkerbell/tinkerbell/blob/main/tootles/internal/frontend/hack/hack.go#L32-L36",
      "updatedAt" : 1753373368.000000000,
      "user" : "jacobweinstock",
      "userHtmlUrl" : "https://github.com/jacobweinstock",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12081036?v=4",
      "labels" : [ "tootles", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Bare metal provisioning engine, supporting network and ISO booting, BMC interactions, metadata service, and workflow engine.",
        "homepage" : "https://tinkerbell.org",
        "name" : "tinkerbell",
        "fullName" : "tinkerbell/tinkerbell",
        "htmlUrl" : "https://github.com/tinkerbell/tinkerbell",
        "gitUrl" : "git://github.com/tinkerbell/tinkerbell.git",
        "sshUrl" : "git@github.com:tinkerbell/tinkerbell.git",
        "cloneUrl" : "https://github.com/tinkerbell/tinkerbell.git",
        "owner" : {
          "login" : "tinkerbell",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 62,
        "watchersCount" : 62,
        "size" : 46898,
        "openIssuesCount" : 9,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-24T20:58:53Z",
        "languages" : {
          "Smarty" : 412,
          "Shell" : 19549,
          "C" : 3494,
          "Makefile" : 15864,
          "Go" : 985494,
          "Nix" : 854
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "the `/metadata` endpoint in Tootles returns an unexpected 500 error when there is no corresponding Hardware object",
      "validationOrRequirement" : "return a 404 not found instead of a 500 error",
      "attemptedFixes" : "",
      "otherNotes" : "reference: https://github.com/tinkerbell/tinkerbell/blob/main/tootles/internal/frontend/hack/hack.go#L32-L36",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407243
  }, {
    "issueDTO" : {
      "id" : 3248609924,
      "title" : "Tie validator onboarding secrets to a party hint and improve UI",
      "url" : "https://github.com/hyperledger-labs/splice/issues/1603",
      "repositoryName" : "hyperledger-labs/splice",
      "description" : "Currently onboarding secrets work like this:\n\n1. The SV generates a random secret. This is what is persisted on ledger in the onboarding contract as base64 encoding.\n2. We base64 encode that together with the sv party id https://github.com/hyperledger-labs/splice/blob/4aa2cea6202f1d7ac6e773d89933489438d07f0b/apps/sv/src/main/scala/org/lfdecentralizedtrust/splice/sv/admin/http/HttpSvHandler.scala#L85. Note that this is not currently persisted. The sv party id never changes so we can generate it on the fly as needed.\n3. This is then shared with the validator operator.\n4. When the validator onboards we validate the SV party against the SV app and the secret against the on-ledger state.\n\nThe party hint is slightly different in that we need to persist it contrary to the sv party.\n\nConcretely I would expect we can accomplish this by:\n\n1. Extend the SV UI to specify a party hint when generating an onboarding secret.\n2. When creating the on-ledger ``ValidatorOnboarding` contract don't just include the random secret but include the full JSON object as a secret `{\"sv\": ???, \"validator_party_hint\": \"???\", \"secret\": \"\"}` in the `candidateSecret` field of the contract (no Daml changes required that way).\n3. When decoding, check if the first character is a `{` which must be the case for the JSON encoding and can never be the case for the old base64 encoding so we can be backwards compatible with existing secrets. If it is, decode it as json, otherwise decode it as the old format.\n4. When decoding as the new format, validate the secret against the party hint in `/v0/onboard/validator`. If it mismatch, fail, otherwise continue.\n\nIn addition to that:\nIn the SV UI, provide a way to copy not just a secret but a text consisting of:\n\n```\nyour secret: base64 encoded json secret\nnetwork: dev/test/mainnet\nsv sponsor url: sv sponsor url they need to use in their onboarding\nexpiration: time with UTC offset\n```\n\nThis can be used by the SV sponsor to copy directly into a slack message to send to the  validator they are trying to onboard.",
      "updatedAt" : 1753373244.000000000,
      "user" : "moritzkiefer-da",
      "userHtmlUrl" : "https://github.com/moritzkiefer-da",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/45630097?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "For the output: please add the secret expiration with UTC offset" ],
      "repository" : {
        "description" : "Reference applications for funding, operating, and incentivizing the use of a decentralized, public Canton synchronizer. Includes the Amulet reference application for creating native payment utilities for Canton synchronizers and Daml applications.",
        "homepage" : "",
        "name" : "splice",
        "fullName" : "hyperledger-labs/splice",
        "htmlUrl" : "https://github.com/hyperledger-labs/splice",
        "gitUrl" : "git://github.com/hyperledger-labs/splice.git",
        "sshUrl" : "git@github.com:hyperledger-labs/splice.git",
        "cloneUrl" : "https://github.com/hyperledger-labs/splice.git",
        "owner" : {
          "login" : "hyperledger-labs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 33,
        "watchersCount" : 33,
        "size" : 158109,
        "openIssuesCount" : 647,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-25T00:18:16Z",
        "languages" : {
          "Smarty" : 29501,
          "Java" : 553700,
          "CSS" : 1064,
          "Scala" : 31557447,
          "PLpgSQL" : 37746,
          "Makefile" : 34417,
          "HTML" : 8747,
          "Jsonnet" : 3948,
          "TypeScript" : 1818059,
          "Dockerfile" : 20740,
          "Shell" : 456913,
          "Batchfile" : 3479,
          "JavaScript" : 41424,
          "Haskell" : 1032659,
          "Nix" : 83392,
          "Python" : 410362
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Tie validator onboarding secrets to a party hint and improve UI by extending the SV UI to specify a party hint when generating an onboarding secret, persisting the party hint on the ledger, and decoding the secret as JSON if it starts with a `{` character",
      "validationOrRequirement" : "validate the secret against the party hint in `/v0/onboard/validator`",
      "attemptedFixes" : "no fixes mentioned in the issue",
      "otherNotes" : "For the output: please add the secret expiration with UTC offset",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407247
  }, {
    "issueDTO" : {
      "id" : 3259003936,
      "title" : "[Feature]: Fix Mobile Event Card Overflow on Smaller Screens",
      "url" : "https://github.com/Bhavya1352/eventmappr/issues/260",
      "repositoryName" : "Bhavya1352/eventmappr",
      "description" : "### Description:\nOn smaller devices, the event cards overflow beyond the screen width, causing horizontal scrolling. This affects the user experience negatively, especially on phones.\n\n### Steps to Reproduce:\n1. Open the website on a mobile device (or emulate in browser dev tools).\n2. Navigate to the event cards section.\n3. Notice the horizontal scrolling or content spilling out.\n\n### Expected Behavior:\nEvent cards should be fully responsive and contained within the screen width without any horizontal scrolling.\n\n### Possible Fix:\n- Use `overflow-x: hidden` on parent container if applicable.\n- Use `max-width: 100%` and ensure cards use `flex-wrap` or `grid` correctly.\n- Adjust `padding`/`margin` on mobile viewports using media queries.\n\n### Tech Stack:\n- React.js\n- Tailwind CSS\n\n### Additional Context:\nThis issue is critical for improving mobile responsiveness and usability.",
      "updatedAt" : 1753373180.000000000,
      "user" : "abdey53",
      "userHtmlUrl" : "https://github.com/abdey53",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/118340181?v=4",
      "labels" : [ "Intermediate", "enhancement", "good first issue", "GSSOC25" ],
      "state" : "OPEN",
      "comments" : [ "Hey! I'm interested in working on this issue as part of GSSoC'24. Kindly assign it to me if it's available. Thank you! \uD83D\uDE4C\n", "I would love to work on this as part of GSSoC'25. @Bhavya1352 ", "hello @Bhavya1352 I find that soo please assign me that this is my first contribution of GSSOC soo plz" ],
      "repository" : {
        "description" : null,
        "homepage" : "https://eventmappr.vercel.app",
        "name" : "eventmappr",
        "fullName" : "Bhavya1352/eventmappr",
        "htmlUrl" : "https://github.com/Bhavya1352/eventmappr",
        "gitUrl" : "git://github.com/Bhavya1352/eventmappr.git",
        "sshUrl" : "git@github.com:Bhavya1352/eventmappr.git",
        "cloneUrl" : "https://github.com/Bhavya1352/eventmappr.git",
        "owner" : {
          "login" : "Bhavya1352",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 69,
        "stargazersCount" : 34,
        "watchersCount" : 34,
        "size" : 25214,
        "openIssuesCount" : 35,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T15:40:40Z",
        "languages" : {
          "CSS" : 156316,
          "JavaScript" : 457887,
          "HTML" : 96609
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix Mobile Event Card Overflow on Smaller Screens, to improve mobile responsiveness and usability",
      "validationOrRequirement" : "Ensure event cards are fully responsive and contained within the screen width without any horizontal scrolling",
      "attemptedFixes" : "Use `overflow-x: hidden` on parent container if applicable, Use `max-width: 100%` and ensure cards use `flex-wrap` or `grid` correctly, Adjust `padding`/`margin` on mobile viewports using media queries",
      "otherNotes" : "This issue is critical for improving mobile responsiveness and usability, and is suitable for good first issue and GSSOC25.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407251
  }, {
    "issueDTO" : {
      "id" : 3258891528,
      "title" : "[Feature]: Use of pincode or a landmark for Historical Places Explorer.",
      "url" : "https://github.com/Bhavya1352/eventmappr/issues/259",
      "repositoryName" : "Bhavya1352/eventmappr",
      "description" : "### \uD83D\uDCCC Is your feature request related to a problem?\nWhen using historical places explorer on pc or laptop the location is not accurate or doesn't show any significant places.\n\n### \uD83D\uDCA1 Describe the Solution\nInstead of only having, the option to find location from the location feature, we can also add a feature where a user can enter his **_pincode or a particular landmark_** instead of relying on location from gps.\n\n\n",
      "updatedAt" : 1753373137.000000000,
      "user" : "asr1325",
      "userHtmlUrl" : "https://github.com/asr1325",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/39804984?v=4",
      "labels" : [ "Intermediate", "enhancement", "good first issue", "GSSOC25" ],
      "state" : "OPEN",
      "comments" : [ " I would love to work on this issue can you assign it to me. @Bhavya1352 ", "Hey! I'm interested in working on this issue as part of GSSoC'24. Kindly assign it to me if it's available. Thank you! \uD83D\uDE4C @Bhavya1352 \n" ],
      "repository" : {
        "description" : null,
        "homepage" : "https://eventmappr.vercel.app",
        "name" : "eventmappr",
        "fullName" : "Bhavya1352/eventmappr",
        "htmlUrl" : "https://github.com/Bhavya1352/eventmappr",
        "gitUrl" : "git://github.com/Bhavya1352/eventmappr.git",
        "sshUrl" : "git@github.com:Bhavya1352/eventmappr.git",
        "cloneUrl" : "https://github.com/Bhavya1352/eventmappr.git",
        "owner" : {
          "login" : "Bhavya1352",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 69,
        "stargazersCount" : 34,
        "watchersCount" : 34,
        "size" : 25214,
        "openIssuesCount" : 35,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T15:40:40Z",
        "languages" : {
          "CSS" : 156316,
          "JavaScript" : 457887,
          "HTML" : 96609
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add an option for users to enter their pincode or a particular landmark instead of relying on GPS location for more accurate location results in the Historical Places Explorer.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to a problem with the location accuracy of the Historical Places Explorer on PC or laptop, and a potential solution is to add an option for users to enter their pincode or a particular landmark instead of relying on GPS location.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407255
  }, {
    "issueDTO" : {
      "id" : 3163906923,
      "title" : "Implement support for ARC-62 for the ASA Circulating Supply",
      "url" : "https://github.com/algorandfoundation/algokit-lora/issues/448",
      "repositoryName" : "algorandfoundation/algokit-lora",
      "description" : "# Implement support for ARC-62 for the ASA Circulating Supply\n\n## Description\n\nAlgorand Standard Asset (ASA) `total` supply is _defined_ upon ASA creation. Creating an ASA on the ledger _does not_ imply its `total` supply is immediately \"minted\" or \"circulating.  [ARC-62](https://arc.algorand.foundation/assets/arc-0062/) proposes a standard ABI _read-only_ method (getter) to provide the circulating supply of an ASA.\n\nLora currently provides just the *total supply* on the ASA page. Other explorers (i.e., Pera Explorer) have already adopted ARC-62 to provide the ASA _circulating supply_. We want to fill the gap by adding the *circulating supply* field to the Lora Asset page for the ASAs conforming to ARC-62.\n\nThe ARC-62 specifications define the standard interface of the [ABI getter](https://arc.algorand.foundation/ARCs/arc-0062#abi-method)  (`arc62_get_circulating_supply`), which an Application implements and the clients (e.g., wallets, explorers, etc.) call. The ASA must declare the Application ID to inform clients about discovering the ASA's Circulating Supply App provider.\n\n ARC-62 defines two ways to declare the *binding* between the **ASA ID** and its **Circulating Supply App ID**:\n\n- **On Creation**: the binding is declared off-chain *on asset creation*, as the `arc62` Asset Trait in ASA metadata through ARC-3 or ARC-19. Lora already supports ARC-3 traits recognition, so implementing this feature can leverage it. An [example](https://lora.algokit.io/testnet/asset/741524548) deployed on TestNet.\n- **Retroactive**: the binding is declared on-chain history _after asset creation_, with a standard ARC-2 message issued by the Asset Manager with an `AssetConfig` transaction. Lora already supports ARC-2 message recognition, so implementing this feature can leverage it. An [example](https://lora.algokit.io/testnet/transaction/OEKYBPLUWUGE2BOQ2A77QNYKXEN5VMAUWYELUYH4RCP2Z2IAHHWA) deployed on TestNet.\n\nLora must be able to provide information about the ASA circulating supply in both cases.\n\n> Other ASA ID/App ID bindings declared via on-chain state (as opposed to off-chain or on-chain history) could be added in the future.\n\n## Acceptance Criteria\n\n### Must Have\n\n1. ??? The Asset page of an ASA conforming to ARC-62 via ARC-2 **MUST** include the *Circulating Supply* field.\n1. ??? The Asset page of an ASA conforming to ARC-62 via ARC-3 **MUST** include the *Circulating Supply* field.\n1. ??? For ARC-3 binding, the implementation must leverage the existing Lora ARC-3 Asset Trait feature.\n1. ??? For ARC-2 binding, the implementation must leverage the existing Lora ARC-2 message feature.\n1. ??? For ARC-2 binding, the implementation must leverage the existing Lora Asset Reconfiguration classifier.\n\n### Should Have\n\n7. ??? The Asset page of an ASA conforming to ARC-62 via ARC-19 **SHOULD** include the *Circulating Supply* field.\n\n### Testing\n\n8. ??? Unit Tests covering ARC-3 and ARC-2 scenarios.\n8. ??? ARC-2 Integration Test with the Asset `741524580` on deployed TestNet, the Circulating Supply **MUST** be `41`.\n8. ??? ARC-3 Integration Test with the Asset `741524548` on deployed TestNet, the Circulating Supply **MUST** be `1`.\n\n## Technical Details\n\nThe ARC-62 standard ABI Getter interface is [available here](https://arc.algorand.foundation/ARCs/arc-0062#abi-method).\n\nThe AppSpec of the ARC-62 reference implementation is [available here](https://arc.algorand.foundation/assets/arc-0062/smart_contracts/artifacts/circulating_supply/CirculatingSupply.arc56.json); it can be used to deploy a Circulating Supply App for Unit Tests.\n\n### Implementation Plan\n\n#### Phase 1: ARC-3\n\nIf the ASA declares the Application ID as `arc-62` trait as ARC-3 metadata:\n\n- Lora simulates the call to the `arc62_get_circulating_supply` getter exposed by the Application using the ASA ID as an argument (the call should use automatic resource population);\n- Lora displays the result of the getter method as `Circulating Supply` field on the ASA page.\n\n#### Phase 2: ARC-2\n\nIf the ASA declares the Application ID as ARC-2 standard messages, with dApp name `arc62`, in an `AssetConfig` transaction:\n\n- Lora considers the *latest valid* ARC-62 message in the history of the `AssetConfig` transactions for that ASA and reads the Application ID.\n- Lora simulates the call to the `arc62_get_circulating_supply` getter exposed by the Application using the ASA ID as an argument (the call should use automatic resource population);\n- Lora displays the result of the getter method as `Circulating Supply` field on the ASA page.\n\n#### Phase 5: Testing & Documentation\n\n5. **Add unit tests** in `src/tests/utils/` for the ARC-62 feature.\n5. Manual Testing to make sure this [example](https://lora.algokit.io/testnet/asset/741524548) TestNet in Lora is the same as it in [Pera Explorer](https://testnet.explorer.perawallet.app/asset/741524548/)\n\n\n### Technical Considerations\n\n- **Backward Compatibility**: Ensure existing functionality isn't broken.\n- **Fallback Strategy**: Default to `Not Available` for the `Circulating Supply` value if the ASA does not conform to ARC-62.\n\n### Resources\n\n- [ARC-62](https://arc.algorand.foundation/ARCs/arc-0062)\n- [ARC-3](https://arc.algorand.foundation/ARCs/arc-0003)\n- [ARC-2](https://arc.algorand.foundation/ARCs/arc-0002)\n\n[ARC-62]: https://algorandfoundation.atlassian.net/browse/ARC-62?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ\n[ARC-62]: https://algorandfoundation.atlassian.net/browse/ARC-62?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",
      "updatedAt" : 1753373123.000000000,
      "user" : "lempira",
      "userHtmlUrl" : "https://github.com/lempira",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12114015?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : null,
        "homepage" : "https://lora.algokit.io",
        "name" : "algokit-lora",
        "fullName" : "algorandfoundation/algokit-lora",
        "htmlUrl" : "https://github.com/algorandfoundation/algokit-lora",
        "gitUrl" : "git://github.com/algorandfoundation/algokit-lora.git",
        "sshUrl" : "git@github.com:algorandfoundation/algokit-lora.git",
        "cloneUrl" : "https://github.com/algorandfoundation/algokit-lora.git",
        "owner" : {
          "login" : "algorandfoundation",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 20,
        "watchersCount" : 20,
        "size" : 6060,
        "openIssuesCount" : 22,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-24T20:23:17Z",
        "languages" : {
          "TypeScript" : 2056518,
          "CSS" : 8953,
          "Shell" : 3487,
          "Rust" : 1712,
          "JavaScript" : 3524,
          "HTML" : 623144,
          "Python" : 2150
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement support for ARC-62 for the ASA Circulating Supply, providing a standard ABI read-only method to provide the circulating supply of an ASA, and adding the circulating supply field to the Lora Asset page for ASAs conforming to ARC-62.",
      "validationOrRequirement" : "The issue requires that the Asset page of an ASA conforming to ARC-62 via ARC-2 or ARC-3 must include the Circulating Supply field. It also requires leveraging existing Lora features, such as ARC-3 Asset Trait and ARC-2 message recognition.",
      "attemptedFixes" : "The implementation plan includes two phases: Phase 1 for ARC-3 and Phase 2 for ARC-2. The plan also involves adding unit tests, manual testing, and documentation.",
      "otherNotes" : "The issue aims to implement support for ARC-62 for the ASA Circulating Supply, which provides a standard ABI read-only method to provide the circulating supply of an ASA. It involves adding the circulating supply field to the Lora Asset page for ASAs conforming to ARC-62, using either ARC-3 or ARC-2 binding methods.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407263
  }, {
    "issueDTO" : {
      "id" : 3255813025,
      "title" : "[Feature] Allow to configure PersistentVolumeClaimRetentionPolicy",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/1347",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "**Is your feature request related to a problem? Please describe.**\n\nWe use `mariadb-operator` to provision relatively short-lived (weeks to months) `MariaDB` instances. When deleting those instances the `PersistentVolumeClaim` created by the `StatefulSet` remains.  We understand that this is the desired behavior for most use-cases. However, for our use-case we would like to be able to configure whether the `PersistentVolumeClaim` gets deleted.\n\n**Describe the solution you'd like**\n\nIn Kubernetes 1.32 the [PersistentVolumeClaim retention][1] feature became stable and is enabled by default. The `mariadb-operator` already allows to configure some aspects of the `PersistentVolumeClaim` used for `MariaDB` via the [`PersistentVolumeClaimSpec` type][2]. We would therefore like to suggest to allow configuring `PersistentVolumeClaim` retention using this type. This should be as simple as adding a field `PersistentVolumeClaimRetentionPolicy` to `PersistentVolumeClaimSpec` and then using it during reconciliation.\n\nIf there is interest in such a feature we would be happy to provide a PR.\n\n**Describe alternatives you've considered**\n\n- Ephemeral storage. But we would like the data to be retained if the pod restarts.\n- Deletion within our own automation. Would always be possible. But maybe this request valuable for other users as well.\n\n**Environment details**:\n- Kubernetes version: 1.33.1\n- Kubernetes distribution: Talos\n- MariaDB Operator version: 0.38.1\n- MariaDB Server version: 11.4.5\n\n\n[1]: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention\n[2]: https://pkg.go.dev/github.com/mariadb-operator/mariadb-operator/api/v1alpha1#PersistentVolumeClaimSpec\n\n",
      "updatedAt" : 1753373100.000000000,
      "user" : "fhofherr",
      "userHtmlUrl" : "https://github.com/fhofherr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/509071?v=4",
      "labels" : [ "feature", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey! This is something we are willing to support given that it has been [declared stable, and that is enabled by default in 1.32](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention).\n\nFor the implementation we could:\n- Introduce a new `persistentVolumeClaimRetentionPolicy` in our `Storage` type\nhttps://github.com/mariadb-operator/mariadb-operator/blob/c95dd1ad8d341e4aae5c0af94ab4a471690b5abb/api/v1alpha1/mariadb_types.go#L66\n\n- Propagate the field in the `StatefulSet` builder:\nhttps://github.com/mariadb-operator/mariadb-operator/blob/c95dd1ad8d341e4aae5c0af94ab4a471690b5abb/pkg/builder/statefulset_builder.go#L56\n\nWill be worth adding some tests in the `StatefulSet` builder for checking this.\n\nAdditionally, to avoid causing issues in older Kubernetes versions, I suggest only adding this field to the `StatefulSet` when the version is 1.32 or older. We could extend/leverage the following packages:\n- https://github.com/mariadb-operator/mariadb-operator/blob/main/pkg/discovery/discovery.go\n- https://github.com/mariadb-operator/mariadb-operator/blob/main/pkg/version/version.go\n\nand the following function:\n- https://pkg.go.dev/k8s.io/client-go@v0.33.3/discovery#DiscoveryClient.ServerVersion\n\nContributions are welcome!" ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow to configure PersistentVolumeClaimRetentionPolicy in mariadb-operator",
      "validationOrRequirement" : "The PersistentVolumeClaim retention feature became stable and is enabled by default in Kubernetes 1.32. The mariadb-operator already allows configuring some aspects of the PersistentVolumeClaim used for MariaDB via the PersistentVolumeClaimSpec type.",
      "attemptedFixes" : "Introduce a new persistentVolumeClaimRetentionPolicy in Storage type, propagate the field in the StatefulSet builder, and add some tests in the StatefulSet builder for checking this. Also, suggest adding this field to the StatefulSet when the version is 1.32 or older.",
      "otherNotes" : "The feature request is related to a problem where PersistentVolumeClaim created by StatefulSet remains after deleting the MariaDB instances. The solution is to allow configuring PersistentVolumeClaim retention using PersistentVolumeClaimSpec type.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407268
  }, {
    "issueDTO" : {
      "id" : 3138454398,
      "title" : "Change `run-test` to `run`",
      "url" : "https://github.com/opensearch-project/opensearch-benchmark/issues/875",
      "repositoryName" : "opensearch-project/opensearch-benchmark",
      "description" : "### Is your feature request related to a problem? Please describe\n\nIn OSB 2.0.0, `execute-test` will be `run-test`. \n\n### Describe the solution you'd like\n\nWe can enhance the user experience by:\n- Changing `run-test` to `run`. This should not change the execution flow.\n- If a user supplies old terminology like `execute-test`, add clear messages like \"Did you mean `run`?\"\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753373095.000000000,
      "user" : "IanHoang",
      "userHtmlUrl" : "https://github.com/IanHoang",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/51065478?v=4",
      "labels" : [ "2.0.0", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Is OSB 2.0.0 changing `execute-test` to `run-test` or `run`? I see in the alpha branch it's `run-test`", "I would like to contribute to this one. Can you assign this to me? Thank you!", "@neuenfeldttj Yes, we've already made the changes but decided we want to simplify `run-test` to `run` in the CLI. ", "@aman825 I've assigned this to you. Should be a straight-forward fix. Let us know if you need help or if you want us to review your PR" ],
      "repository" : {
        "description" : "OpenSearch Benchmark - a community driven, open source project to run performance tests for OpenSearch",
        "homepage" : "https://opensearch.org/docs/latest/benchmark/",
        "name" : "opensearch-benchmark",
        "fullName" : "opensearch-project/opensearch-benchmark",
        "htmlUrl" : "https://github.com/opensearch-project/opensearch-benchmark",
        "gitUrl" : "git://github.com/opensearch-project/opensearch-benchmark.git",
        "sshUrl" : "git@github.com:opensearch-project/opensearch-benchmark.git",
        "cloneUrl" : "https://github.com/opensearch-project/opensearch-benchmark.git",
        "owner" : {
          "login" : "opensearch-project",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 102,
        "stargazersCount" : 122,
        "watchersCount" : 122,
        "size" : 9157,
        "openIssuesCount" : 170,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T16:21:28Z",
        "languages" : {
          "Dockerfile" : 2014,
          "Shell" : 15349,
          "Jinja" : 7783,
          "Makefile" : 4014,
          "Python" : 2864051
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Change run-test to run, enhancing user experience by providing clear messages for old terminology",
      "validationOrRequirement" : "No response",
      "attemptedFixes" : "No response",
      "otherNotes" : "OSB 2.0.0 is changing execute-test to run-test, but will simplify run-test to run in the CLI.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407271
  }, {
    "issueDTO" : {
      "id" : 3257490850,
      "title" : "Use `cargo-udeps` to check unused deps",
      "url" : "https://github.com/GreptimeTeam/greptimedb/issues/6578",
      "repositoryName" : "GreptimeTeam/greptimedb",
      "description" : "### What type of enhancement is this?\n\nRefactor\n\n### What does the enhancement do?\n\n#### Backgroud\n\nThe current project has some unused dependencies. We can use [`cargo-udeps`](https://github.com/est31/cargo-udeps) to find out and remove them, for example:\n\n```\ncargo udeps --workspace --all-targets --output json \n```\n\nThe following things should be done for using `cargo-udeps` as one of the check processes:\n\n1. Add the new Makefile target to wrap the `cargo-udeps`, for example, `make check-udeps`;\n\n2. Remove the current unused deps based on the output of `1`;\n\n3. Integrate the `make check-udeps` in GitHub Actions `develop` workflow;\n\n#### Why do we need to remove unused dependencies?\n\n1. Keep clean and easy to maintain;\n2. Avoid the potential circular dependency;\n\n### Implementation challenges\n\n_No response_",
      "updatedAt" : 1753372844.000000000,
      "user" : "zyy17",
      "userHtmlUrl" : "https://github.com/zyy17",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1625098?v=4",
      "labels" : [ "good first issue", "C-enhancement" ],
      "state" : "OPEN",
      "comments" : [ "@zyy17  Could you please assign this issue to me?", "@Arshdeep54 Already assigned. Feel free to ask anything if something is unclear \uD83D\uDE0A" ],
      "repository" : {
        "description" : "Open-source, cloud-native, unified observability database for metrics, logs and traces, supporting SQL/PromQL/Streaming. Available on GreptimeCloud.",
        "homepage" : "https://greptime.com/",
        "name" : "greptimedb",
        "fullName" : "GreptimeTeam/greptimedb",
        "htmlUrl" : "https://github.com/GreptimeTeam/greptimedb",
        "gitUrl" : "git://github.com/GreptimeTeam/greptimedb.git",
        "sshUrl" : "git@github.com:GreptimeTeam/greptimedb.git",
        "cloneUrl" : "https://github.com/GreptimeTeam/greptimedb.git",
        "owner" : {
          "login" : "GreptimeTeam",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 390,
        "stargazersCount" : 5407,
        "watchersCount" : 5407,
        "size" : 63013,
        "openIssuesCount" : 200,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-24T10:26:25Z",
        "languages" : {
          "TypeScript" : 18683,
          "Dockerfile" : 10036,
          "Shell" : 19802,
          "Rust" : 16801354,
          "Makefile" : 9148,
          "Nix" : 1507,
          "Python" : 8004
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to refactor the project to use `cargo-udeps` to check and remove unused dependencies.",
      "validationOrRequirement" : "The enhancement should add a new Makefile target to wrap `cargo-udeps`, remove current unused deps based on the output, and integrate `make check-udeps` in the GitHub Actions `develop` workflow.",
      "attemptedFixes" : "No attempted fixes or blockers are mentioned in the description or comments.",
      "otherNotes" : "The current project has unused dependencies, and the enhancement aims to use `cargo-udeps` to find and remove them. The enhancement includes adding a new Makefile target, removing unused deps, and integrating the new target in the GitHub Actions `develop` workflow. The implementation challenges are unknown.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407276
  }, {
    "issueDTO" : {
      "id" : 3252492598,
      "title" : "Claude Code Action Fails Due to Missing id-token: write Permission",
      "url" : "https://github.com/llm4s/llm4s/issues/108",
      "repositoryName" : "llm4s/llm4s",
      "description" : "In [Elvan's recent PR](https://github.com/llm4s/llm4s/actions/runs/16412163467/job/46369538739?pr=107), the claude-code-action fails with an error when trying to fetch the OIDC token:\n\n```\nError message: Unable to get ACTIONS_ID_TOKEN_REQUEST_URL env variable\n...\nError: Could not fetch an OIDC token. Did you remember to add `id-token: write` to your workflow permissions?\n```\n\n\nThis was from the work we did on Saturday to integrate Claude for automatic PR reviews. The failure here is blocking even simple doc-only PRs, which should not happen.\n\nObservations:\nThe Claude code action is attempting to request an OIDC token but fails due to missing GitHub Actions environment variables.\nThe message clearly states the root issue: missing id-token: write permission.\nAlso observed: an additional \"Bad credentials\" error from a curl request, likely due to misconfigured GitHub authentication.\n\nSuggested Fixes:\n1. Update workflow permissions in the GitHub Actions YAML file:\n```\npermissions:\n  id-token: write\n  contents: read\n```\n2.Ensure any token-based API calls (e.g., with curl or Octokit) are using valid credentials or fallback tokens when id-token isn???t available.\n3.Graceful fallback in Claude review action for doc-only PRs , consider skipping OIDC token if unnecessary.\n\nNext Steps\n1. Add the correct permissions to the llm4s GitHub Action workflows.\n2. Confirm Claude action works on non-code PRs.\n3. Consider fail-soft behavior or bypass for documentation-only changes.",
      "updatedAt" : 1753372833.000000000,
      "user" : "kannupriyakalra",
      "userHtmlUrl" : "https://github.com/kannupriyakalra",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/39022252?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Update: \nPR #117 tried widening the scope of claude code review for the branches of forked repos.\nWe plan to use both OIDC + GITHUB_TOKEN fallback approach.\n\n- External PRs (forked repos) will wait for maintainer to comment `@claude` in the created PR to execute claude code review manually.\n- While trusted PRs created from main repo (llm4s/llm4s.git) will run claude automatically in the CI flow.\n\nCheck the executed [CI flow](https://github.com/llm4s/llm4s/actions/runs/16491775065) run on external PR.\n\ncc: @rorygraves " ],
      "repository" : {
        "description" : "Agentic  and LLM Programming in Scala",
        "homepage" : "",
        "name" : "llm4s",
        "fullName" : "llm4s/llm4s",
        "htmlUrl" : "https://github.com/llm4s/llm4s",
        "gitUrl" : "git://github.com/llm4s/llm4s.git",
        "sshUrl" : "git@github.com:llm4s/llm4s.git",
        "cloneUrl" : "https://github.com/llm4s/llm4s.git",
        "owner" : {
          "login" : "llm4s",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 21,
        "stargazersCount" : 86,
        "watchersCount" : 86,
        "size" : 10450,
        "openIssuesCount" : 28,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-23T09:31:50Z",
        "languages" : {
          "Shell" : 1857,
          "Scala" : 337393
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the error in the Claude code action due to missing `id-token: write` permission, which is blocking even simple doc-only PRs.",
      "validationOrRequirement" : "The root issue is missing `id-token: write` permission, and an additional 'Bad credentials' error from a curl request, likely due to misconfigured GitHub authentication.",
      "attemptedFixes" : "Suggested Fixes: 1. Update workflow permissions in the GitHub Actions YAML file: `permissions: id-token: write, contents: read`. 2. Ensure any token-based API calls (e.g., with curl or Octokit) are using valid credentials or fallback tokens when id-token isn???t available. 3. Graceful fallback in Claude review action for doc-only PRs, consider skipping OIDC token if unnecessary.",
      "otherNotes" : "The issue was observed in the work done on Saturday to integrate Claude for automatic PR reviews, and it's blocking even simple doc-only PRs. The Claude code action is attempting to request an OIDC token but fails due to missing GitHub Actions environment variables.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407283
  }, {
    "issueDTO" : {
      "id" : 2565035203,
      "title" : "\uD83D\uDC1B Bug Report:  Inconsistency in User Verification Status between Email and Phone Number",
      "url" : "https://github.com/appwrite/console/issues/1392",
      "repositoryName" : "appwrite/console",
      "description" : "### \uD83D\uDC5F Reproduction steps\n\n- To trigger this bug, begin by accessing the Auth, \r\n- Create a new user account and navigate to the user profile to verify the account. \r\n- Start the verification process for both the email address and the phone number associated with the user account. Initially, verify the email address, which should proceed smoothly. \r\n- Next, attempt to verify the phone number, Despite the successful verification of the email address, the system incorrectly indicates that the user is unverified when verifying the phone number. \r\n- In an attempt to rectify this inconsistency, proceed to unverify the phone number. Unexpectedly, the system now displays an alert indicating that the user is verified, contradicting the initial indication of being unverified.\n\n### \uD83D\uDC4D Expected behavior\n\n- When the user hits **Verify Phone**, the alert should confirm that the `user is verified`.\r\n- When the user hits **Unverify Phone**, the alert should confirm that the `user is unverified`.\n\n### \uD83D\uDC4E Actual Behavior\n\nWhen attempting to **verify the phone numbe**r, an alert incorrectly states that the `user is unverified`. \r\nHowever, when attempting to **unverify the phone**, the system incorrectly indicates that the `user is verified.`\n\n### \uD83C\uDFB2 Appwrite version\n\nVersion 1.4.x\n\n### \uD83D\uDCBB Operating system\n\nWindows\n\n### \uD83E\uDDF1 Your Environment\n\n_No response_\n\n### \uD83D\uDC40 Have you spent some time to check if this issue has been raised before?\n\n- [X] I checked and didn't find similar issue\n\n### \uD83C\uDFE2 Have you read the Code of Conduct?\n\n- [X] I have read the [Code of Conduct](https://github.com/appwrite/.github/blob/main/CODE_OF_CONDUCT.md)",
      "updatedAt" : 1753372690.000000000,
      "user" : "gurjeetsinghvirdee",
      "userHtmlUrl" : "https://github.com/gurjeetsinghvirdee",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/73753957?v=4",
      "labels" : [ "product / auth", "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "https://github.com/appwrite/appwrite/assets/73753957/d393de11-ff8a-4ba9-aa97-0d8e5623f94c", "Reproducible on `1.5.4` too.", "@gurjeetsinghvirdee, thanks for raising this issue! \uD83D\uDE4F\uD83C\uDFFC Let me confirm with the team.", "We want to update the alerts to be specific to say:\n\n> XYZ's email has been verified\n> XYZ's email has been unverified\n> XYZ's phone has been verified\n> XYZ's phone has been unverified\n\n> [!NOTE]\n> The \"s\" should only be there if the name does not end with s. For example, if the user's name was \"Charles\", it should be \"Charles' email has been verified\"\n\nFYI, the code that needs to be updated is here:\n\nhttps://github.com/appwrite/console/blob/6748b1425f038bb8ec31ebbcb3284236d6ca4aa5/src/routes/(console)/project-%5Bproject%5D/auth/user-%5Buser%5D/updateStatus.svelte#L15-L54", "Hi, assuming that the previous PR has some issues since it hasn't been merged so far. Can I take over this issue?", "@pushkar707 \nSince it doesn't merge that doesn't mean the PR have issues, PRs been merged according to the priority level! ", "Hi, I am working on this!\n", "Hi, I'm working on this.", "> Hi, I'm working on this.\n\nOur team was able to reproduce the bug:\n\n\"When attempting to verify the phone number, an alert incorrectly states that the user is unverified.\nHowever, when attempting to unverify the phone, the system incorrectly indicates that the user is verified.\"\n\nThis looked like a condition logic flaw to us.  We then found the condition that was causing the flaw [here](https://github.com/appwrite/console/blob/main/src/routes/(console)/project-%5Bregion%5D-%5Bproject%5D/auth/user-%5Buser%5D/updateStatus.svelte#L49)\n\nWhich was missing a bang.\n\n[stnguyen90](https://github.com/stnguyen90) mentioned the desired behavior:\n\tXYZ's email has been verified\n\tXYZ's email has been unverified\n\tXYZ's phone has been verified\n\tXYZ's phone has been unverified\nNote:\n  The \"s\" should only be there if the name does not end with s. For example, if the user's name was \"Charles\", it should be \"Charles' email has been verified\"\n\nWe implemented a solution that met these requirements by changing this [code](https://github.com/appwrite/console/blob/main/src/routes/(console)/project-%5Bregion%5D-%5Bproject%5D/auth/user-%5Buser%5D/updateStatus.svelte#L48-L50)\n\nTo this code:\n`message: ${$user.name || $user.email || $user.phone || 'The account'}${( $user.name || $user.email || $user.phone || 'The account' ).endsWith('s') ? \"'\" : \"'s\"} email has been ${!$user.emailVerification ? 'unverified' : 'verified'},`\n\nOur team then implemented the same solution to updateVerificationEmail() as well, as seen [here](https://github.com/appwrite/console/pull/2112/files)\n\nThis solution can be tested just as [gurjeetsinghvir](https://github.com/gurjeetsinghvirdee) shows in the video posted to this issue.  Under a project, select Auth. In Auth, select or create a user that has both an email and a phone number. Select the 'Verify account' option and then verify the phone number and email. The correct alerts will be displayed.\n\nHere is out PR: [fix-1392](https://github.com/appwrite/console/pull/2112)\n\nDid we approach this issue correctly?  Shoutouts to my teammate @anthonythang1", "@toukirkhan would love to get an update or status here, thank you :)\n\n@MicahHeneveld , my apologies for the misunderstanding, Toukirkhan already mentioned he's working on it (and sent me a DM about it that his team is also working on it with him to prepare a PR). I just forgot to assign it on time. If Toukirkhan cancels or does not continue, we will review your PR next.\n\nWe also updated the contributor guide to be more clear on the proper steps before putting in a PR for next time, since there were 3 people working on a PR the same time. (not a bad thing, right?) :)  I appreciate your efforts and hoping to see more from ya :) " ],
      "repository" : {
        "description" : "The Console that makes Appwrite tick from the browser  \uD83D\uDDA5",
        "homepage" : "https://appwrite.io",
        "name" : "console",
        "fullName" : "appwrite/console",
        "htmlUrl" : "https://github.com/appwrite/console",
        "gitUrl" : "git://github.com/appwrite/console.git",
        "sshUrl" : "git@github.com:appwrite/console.git",
        "cloneUrl" : "https://github.com/appwrite/console.git",
        "owner" : {
          "login" : "appwrite",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 180,
        "stargazersCount" : 371,
        "watchersCount" : 371,
        "size" : 103760,
        "openIssuesCount" : 177,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T23:55:11Z",
        "languages" : {
          "TypeScript" : 599194,
          "Dockerfile" : 1392,
          "CSS" : 4220,
          "JavaScript" : 3830,
          "HTML" : 2136,
          "Svelte" : 3341537
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Inconsistency in User Verification Status between Email and Phone Number: The system incorrectly indicates that the user is unverified when verifying the phone number, and incorrectly indicates that the user is verified when unverifying the phone number.",
      "validationOrRequirement" : "When the user hits **Verify Phone**, the alert should confirm that the `user is verified`. When the user hits **Unverify Phone**, the alert should confirm that the `user is unverified`.",
      "attemptedFixes" : "Our team was able to reproduce the bug: When attempting to verify the phone number, an alert incorrectly states that the user is unverified. However, when attempting to unverify the phone, the system incorrectly indicates that the user is verified. We then found the condition that was causing the flaw [here](https://github.com/appwrite/console/blob/main/src/routes/(console)/project-%5Bregion%5D-%5Bproject%5D/auth/user-%5Buser%5D/updateStatus.svelte#L49) Which was missing a bang.",
      "otherNotes" : "The code that needs to be updated is here: https://github.com/appwrite/console/blob/6748b1425f038bb8ec31ebbcb3284236d6ca4aa5/src/routes/(console)/project-%5Bproject%5D/auth/user-%5Buser%5D/updateStatus.svelte#L15-L54",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407292
  }, {
    "issueDTO" : {
      "id" : 3176311643,
      "title" : "Update Conversation API Docs with the Latest Changes",
      "url" : "https://github.com/dapr/docs/issues/4687",
      "repositoryName" : "dapr/docs",
      "description" : "The following changes needs to be reflected in Conversation API docs:\n\n- Implementation of tool calling support ([#8816](https://github.com/dapr/dapr/issues/8816)).\n",
      "updatedAt" : 1753372682.000000000,
      "user" : "bibryam",
      "userHtmlUrl" : "https://github.com/bibryam",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/513159?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Sorry if i asked a silly question, is this issue more suitable in the docs repository? If so, i am willing to summarize these changes and submit a PR there", "I took a further look and it seems preliminary work for this issue has not yet been fully completed. So I will come back later to see is there any progress.", "@Vickko Yes, please wait to move on this until the upstream PR has been merged into dapr/dapr as it's a bit fluid now.", "> The following changes needs to be reflected in Conversation API docs:\n\n> Promotion of the Conversation API from alpha to beta (https://github.com/dapr/dapr/issues/8784).\n> Addition of streaming response support (https://github.com/dapr/dapr/issues/8813).\n> Implementation of tool calling support (https://github.com/dapr/dapr/issues/8816).\n\n@bibryam can you pls update the scope of this issue to reflect just the tool calling support? In addition, can you pls provide an update on the docs updates? I think you mentioned starting on them? Where are you at with them? Any help needed? Can we add an assignee pls?" ],
      "repository" : {
        "description" : "Dapr user documentation, used to build docs.dapr.io",
        "homepage" : "https://docs.dapr.io",
        "name" : "docs",
        "fullName" : "dapr/docs",
        "htmlUrl" : "https://github.com/dapr/docs",
        "gitUrl" : "git://github.com/dapr/docs.git",
        "sshUrl" : "git@github.com:dapr/docs.git",
        "cloneUrl" : "https://github.com/dapr/docs.git",
        "owner" : {
          "login" : "dapr",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 767,
        "stargazersCount" : 1008,
        "watchersCount" : 1008,
        "size" : 364772,
        "openIssuesCount" : 154,
        "subscribersCount" : 54,
        "pushedAt" : "2025-07-24T08:36:38Z",
        "languages" : {
          "Shell" : 111,
          "SCSS" : 7848,
          "JavaScript" : 1116,
          "HTML" : 36629,
          "Python" : 1054
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update Conversation API Docs with the Latest Changes, specifically implementing tool calling support and reflecting other changes in the docs.",
      "validationOrRequirement" : "The issue requires the implementation of tool calling support, promotion of the Conversation API from alpha to beta, and addition of streaming response support in the Conversation API docs.",
      "attemptedFixes" : "Preliminary work for this issue has not yet been fully completed. The issue author is waiting for the upstream PR to be merged into dapr/dapr before proceeding.",
      "otherNotes" : "The issue description provides a list of changes that need to be reflected in the Conversation API docs. The changes include promotion of the Conversation API from alpha to beta, addition of streaming response support, and implementation of tool calling support. The issue author is willing to summarize the changes and submit a PR to the docs repository.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407298
  }, {
    "issueDTO" : {
      "id" : 2536875338,
      "title" : "Add storefront configuration to the sell item transaction",
      "url" : "https://github.com/onflow/nft-storefront/issues/104",
      "repositoryName" : "onflow/nft-storefront",
      "description" : "### Description\r\n\r\nCurrently, an account has to run the setup account transaction to configure their Storefront before they can sell an item. But this step can be consolidated in the [sell_item transaction](https://github.com/onflow/nft-storefront/blob/main/transactions/sell_item.cdc) to avoid inadvertent reverts, allowing users to simply run a single listing transaction.",
      "updatedAt" : 1753372589.000000000,
      "user" : "sisyphusSmiling",
      "userHtmlUrl" : "https://github.com/sisyphusSmiling",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/108043524?v=4",
      "labels" : [ "SC-Eng", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A general-purpose Cadence contract for trading NFTs on Flow",
        "homepage" : null,
        "name" : "nft-storefront",
        "fullName" : "onflow/nft-storefront",
        "htmlUrl" : "https://github.com/onflow/nft-storefront",
        "gitUrl" : "git://github.com/onflow/nft-storefront.git",
        "sshUrl" : "git@github.com:onflow/nft-storefront.git",
        "cloneUrl" : "https://github.com/onflow/nft-storefront.git",
        "owner" : {
          "login" : "onflow",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 55,
        "stargazersCount" : 103,
        "watchersCount" : 103,
        "size" : 1119,
        "openIssuesCount" : 5,
        "subscribersCount" : 45,
        "pushedAt" : "2025-07-24T17:51:05Z",
        "languages" : {
          "Shell" : 233,
          "Makefile" : 933,
          "Go" : 1306,
          "Cadence" : 248610
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Consolidate storefront configuration in the sell item transaction to simplify the listing process and avoid inadvertent reverts.",
      "validationOrRequirement" : "The sell item transaction should be able to configure the storefront without requiring a separate setup account transaction.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is about consolidating the setup account transaction with the sell item transaction to avoid inadvertent reverts and simplify the listing process for users.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407301
  }, {
    "issueDTO" : {
      "id" : 2309135199,
      "title" : "Use general token interface types and V2 standards features in storefront transactions",
      "url" : "https://github.com/onflow/nft-storefront/issues/95",
      "repositoryName" : "onflow/nft-storefront",
      "description" : "### Issue to be solved\n\nNow that we have more general token types with the V2 standards, we should update the standard storefront transactions to use generic types and use Burner\n\n### Suggest A Solution\n\n* Remove `ExampleToken` and `ExampleNFT` from the storefront transactions\r\n* Use `{FungibleToken.Vault}` and `{NonFungibleToken.Collection}`, for example\r\n* Use `Burner` when we destroy tokens \n\n### What are you currently working on that this is blocking?\n\n_No response_",
      "updatedAt" : 1753372569.000000000,
      "user" : "joshuahannan",
      "userHtmlUrl" : "https://github.com/joshuahannan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7407828?v=4",
      "labels" : [ "SC-Eng", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A general-purpose Cadence contract for trading NFTs on Flow",
        "homepage" : null,
        "name" : "nft-storefront",
        "fullName" : "onflow/nft-storefront",
        "htmlUrl" : "https://github.com/onflow/nft-storefront",
        "gitUrl" : "git://github.com/onflow/nft-storefront.git",
        "sshUrl" : "git@github.com:onflow/nft-storefront.git",
        "cloneUrl" : "https://github.com/onflow/nft-storefront.git",
        "owner" : {
          "login" : "onflow",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 55,
        "stargazersCount" : 103,
        "watchersCount" : 103,
        "size" : 1119,
        "openIssuesCount" : 5,
        "subscribersCount" : 45,
        "pushedAt" : "2025-07-24T17:51:05Z",
        "languages" : {
          "Shell" : 233,
          "Makefile" : 933,
          "Go" : 1306,
          "Cadence" : 248610
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update storefront transactions to use general token interface types and V2 standards features.",
      "validationOrRequirement" : "Use generic types and V2 standards features, remove specific token types (ExampleToken and ExampleNFT) from storefront transactions.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description or comments.",
      "otherNotes" : "Issue is about updating storefront transactions to use general token interface types and V2 standards features, and removing specific token types.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407304
  }, {
    "issueDTO" : {
      "id" : 1862177690,
      "title" : "\"Scan a shared QR code\" text consistency and add? help text?",
      "url" : "https://github.com/openwallet-foundation-labs/learner-credential-wallet/issues/494",
      "repositoryName" : "openwallet-foundation-labs/learner-credential-wallet",
      "description" : "@alexfigtree Update 6/18/25: Only change needed for this ticket is as follows:\n\nOn the Share Credential page (left screenshot below), page still shows: \"Scan a shared QR code\". Should read \"Share via QR code\" instead. All instances of this QR share button should be checked.\n\nQR code button wording through the \"Add Credential\" --> \"Scan QR Code\" page (right screenshot) does NOT need to be changed.\n_______________________________________________________________________\n\nFor the \"Scan a shared QR code\" function from the Bottom Nav Share screen, text should be consistent between the Share screen and QR code Scanner screens. Not sure which is better.\n\nAlso, recommend adding a one sentence help text as to what this is / how it's supposed to be used.\n\n**Bottom Nav Share Screen (left) and QR code Scanner Screen (right)**\n<img src=\"https://github.com/digitalcredentials/learner-credential-wallet/assets/752326/a0ed479a-f016-46e6-9619-423751f4f6e6\" width=30%><img src=\"https://github.com/digitalcredentials/learner-credential-wallet/assets/752326/5b3a9469-c02f-4edd-8640-085a22bfc702\" width=30%>",
      "updatedAt" : 1753372147.000000000,
      "user" : "bmuramatsu",
      "userHtmlUrl" : "https://github.com/bmuramatsu",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/752326?v=4",
      "labels" : [ "comms", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Why is the scan function apart of the \"share\" menu if the purpose of the scan is to view or import a credential (not share one from the users perspective). ", "Dependent on Deep Linking for QR codes\r\n[#627](https://github.com/openwallet-foundation-labs/learner-credential-wallet/issues/627)", "#627 has been fixed", "QR Code scanner page now reads: \"Scan a QR code from your issuer to request your credentials.\".  QR code share button on Share Credential page still shows: \"Scan a shared QR code\". Should read \"Share via QR code\" instead." ],
      "repository" : {
        "description" : "Learner Credential Wallet is a cross-platform iOS and Android mobile application for storing and sharing digital learner credentials.",
        "homepage" : "https://lcw.app",
        "name" : "learner-credential-wallet",
        "fullName" : "openwallet-foundation-labs/learner-credential-wallet",
        "htmlUrl" : "https://github.com/openwallet-foundation-labs/learner-credential-wallet",
        "gitUrl" : "git://github.com/openwallet-foundation-labs/learner-credential-wallet.git",
        "sshUrl" : "git@github.com:openwallet-foundation-labs/learner-credential-wallet.git",
        "cloneUrl" : "https://github.com/openwallet-foundation-labs/learner-credential-wallet.git",
        "owner" : {
          "login" : "openwallet-foundation-labs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 38,
        "stargazersCount" : 73,
        "watchersCount" : 73,
        "size" : 5548,
        "openIssuesCount" : 96,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-24T15:41:08Z",
        "languages" : {
          "TypeScript" : 552494,
          "JavaScript" : 7231
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the 'Scan a shared QR code' function from the Bottom Nav Share screen to have consistent text between the Share screen and QR code Scanner screens, and add a one sentence help text as to what this is/how it's supposed to be used.",
      "validationOrRequirement" : "Consistent text between the Share screen and QR code Scanner screens.",
      "attemptedFixes" : "QR code share button on Share Credential page still shows: 'Scan a shared QR code'. Should read 'Share via QR code' instead.",
      "otherNotes" : "The issue is dependent on Deep Linking for QR codes and has been fixed in issue #627.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407309
  }, {
    "issueDTO" : {
      "id" : 3256799433,
      "title" : "[ENH] test coverage for `gen_imgs`",
      "url" : "https://github.com/dswah/pyGAM/issues/387",
      "repositoryName" : "dswah/pyGAM",
      "description" : "The python module `gen_imgs` in root is not covered by tests.\n\nTests for this file should be added.",
      "updatedAt" : 1753372069.000000000,
      "user" : "fkiraly",
      "userHtmlUrl" : "https://github.com/fkiraly",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7985502?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello @fkiraly , Can I work on this task ? " ],
      "repository" : {
        "description" : "[HELP REQUESTED] Generalized Additive Models in Python",
        "homepage" : "https://pygam.readthedocs.io",
        "name" : "pyGAM",
        "fullName" : "dswah/pyGAM",
        "htmlUrl" : "https://github.com/dswah/pyGAM",
        "gitUrl" : "git://github.com/dswah/pyGAM.git",
        "sshUrl" : "git@github.com:dswah/pyGAM.git",
        "cloneUrl" : "https://github.com/dswah/pyGAM.git",
        "owner" : {
          "login" : "dswah",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 181,
        "stargazersCount" : 905,
        "watchersCount" : 905,
        "size" : 16351,
        "openIssuesCount" : 135,
        "subscribersCount" : 28,
        "pushedAt" : "2025-07-24T17:33:22Z",
        "languages" : {
          "Python" : 326986
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The python module `gen_imgs` in root is not covered by tests. Tests for this file should be added.",
      "validationOrRequirement" : "Tests for this file should be added",
      "attemptedFixes" : "",
      "otherNotes" : "Hello @fkiraly , Can I work on this task ?",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407311
  }, {
    "issueDTO" : {
      "id" : 1708689937,
      "title" : "Let's document: systemd",
      "url" : "https://github.com/tldr-pages/tldr/issues/10191",
      "repositoryName" : "tldr-pages/tldr",
      "description" : "https://systemd.io\n\n### OS: Linux\n\n## Commands:\n\n- [x] bootctl ??? #5418\n- [x] busctl ??? #10271\n- [x] coredumpctl ??? #5421\n- [x] homectl ??? #5688\n- [x] hostnamectl ??? #1369\n- [ ] importctl\n- [x] journalctl ??? #113\n- [x] kernel-install ??? #10919, #10923\n- [x] localectl ??? #7272\n- [x] loginctl ??? #9188\n- [x] machinectl ???#10920\n- [x] mount.ddi **(symlink to `systemd-dissect`)** ??? #11622\n- [x] networkctl ??? #10091\n- [x] oomctl ??? #10107\n- [x] portablectl ??? #11212\n- [x] resolvectl ??? #7484\n- [x] run0 ??? #13263\n- [x] systemctl ??? #112\n- [x] systemd-ac-power ??? #10196\n- [x] systemd-analyze ??? #844\n- [x] systemd-ask-password ??? #10824\n- [x] systemd-cat ??? #10194\n- [x] systemd-cgls??? #10933\n- [x] systemd-cgtop ???#10934\n- [x] systemd-confext **(symlink to `systemd-sysext`)** ??? #11479\n- [x] systemd-creds ??? #10936\n- [x] systemd-cryptenroll ??? #10731\n- [x] systemd-cryptsetup ??? #15064\n- [x] systemd-delta ??? #10388\n- [x] systemd-detect-virt ??? #10723\n- [x] systemd-dissect ??? #11414\n- [x] systemd-escape???#10937\n- [x] systemd-firstboot ??? #10493\n- [ ] systemd-home-fallback-shell\n- [x] systemd-hwdb ??? #10510\n- [x] systemd-id128 ??? #11514\n- [x] systemd-inhibit ??? #10879\n- [x] systemd-machine-id-setup ??? #11447\n- [x] systemd-mount ??? #10509\n- [x] systemd-notify ??? #10618\n- [x] systemd-nspawn ??? #11358, #11398\n- [x] systemd-path ??? #10622\n- [x] systemd-repart???#10880\n- [x] systemd-resolve **(symlink to `resolvectl`)** ???  #11543\n- [x] systemd-run ??? #9949\n- [x] systemd-socket-activate ??? #11221\n- [x] systemd-stdio-bridge ??? #11330\n- [x] systemd-sysext ??? #10724 \n- [x] systemd-sysusers ??? #10693\n- [x] systemd-tmpfiles ??? #10670\n- [x] systemd-tty-ask-password-agent ??? #10656\n- [x] systemd-umount **(symlink to `systemd-mount`)** ??? #10509\n- [x] timedatectl ??? #546\n- [x] udevadm ??? #6478\n- [x] userdbctl ??? #10662\n- [ ] varlinkctl",
      "updatedAt" : 1753371909.000000000,
      "user" : "acuteenvy",
      "userHtmlUrl" : "https://github.com/acuteenvy",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/126529524?v=4",
      "labels" : [ "new command", "let's document", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi can this issue be assigned to me?", "> Hi can this issue be assigned to me?\r\n\r\nAssigned, Feel free to create PRs for the missing commands.\r\n\r\nEdit. I have unassigned you so that others can create PRs too for the remaining pages.", "Added for systemd-notify", "PR for systemd-cryptenroll is ~~Work in Progress~~Done. #10731 \r\n\r\n~~Currently, there are well over 8 examples, so I need to remove many of them (and make some other changes to conform to the guidelines). However, I would be happy to get some opinions on which examples should be removed (or how to combine some of them) as I am not sure, I'll be able to get below about 10 or 12 without leaving relevant examples out. And I kind of don't think It should only be up to me to decide what examples TLDR wants to show for systemd-cryptenroll. Thank you very much.~~", "Are you still looking for help on these commands? I can add a few this week.", "> Are you still looking for help on these commands? I can add a few this week.\r\n\r\nYes, feel free to work the commands that don't have open/merged PRs yet.", "will help on this", "PR for kernel-install: https://github.com/tldr-pages/tldr/pull/10919", "Document ` systemd-socket-activate`\r\n\r\nCheck it out: https://github.com/tldr-pages/tldr/pull/11221\r\n", "Hi @kbdharun can you reassign as I have submitted a pull request and will be working on the rest", "systemd-confext and systemd-sysext seems to be similar @kbdharun @gutjuri @sebastiaanspeck \r\nFrom the docs I see this\r\nsystemd-confext  concept follows the same principle as the [systemd-sysext(1)](https://www.freedesktop.org/software/systemd/man/latest/systemd-sysext.html#) functionality but instead of working on /usr and /opt, confext will extend only /etc. Files and directories contained in the confext images outside of the /etc/ hierarchy are not merged, and hence have no effect when included in the image. Formats for these images are of the same as sysext images. The merged hierarchy will be mounted with \"nosuid\" and (if not disabled via --noexec=false) \"noexec\".", "@kbdharun @gutjuri @sebastiaanspeck @acuteenvy \r\nCan we close this issue or does alias pages needs to be added for the ones that are having symlink but no page", "It or only two pages, maybe for the completeness, also add those two before closing the issue.", "Reopening this page as I noticed it was missing a couple of tools. \nThe full list of tools can be listed on Arch with `pacman -Ql systemd | grep -iE /usr/bin`.\nI wasn't able to find this list anywhere on the internet." ],
      "repository" : {
        "description" : "\uD83D\uDCDA Collaborative cheatsheets for console commands",
        "homepage" : "https://tldr.sh",
        "name" : "tldr",
        "fullName" : "tldr-pages/tldr",
        "htmlUrl" : "https://github.com/tldr-pages/tldr",
        "gitUrl" : "git://github.com/tldr-pages/tldr.git",
        "sshUrl" : "git@github.com:tldr-pages/tldr.git",
        "cloneUrl" : "https://github.com/tldr-pages/tldr.git",
        "owner" : {
          "login" : "tldr-pages",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4570,
        "stargazersCount" : 56519,
        "watchersCount" : 56519,
        "size" : 38054,
        "openIssuesCount" : 232,
        "subscribersCount" : 387,
        "pushedAt" : "2025-07-24T18:22:25Z",
        "languages" : {
          "Shell" : 18090,
          "CSS" : 1056,
          "JavaScript" : 1896,
          "Markdown" : 12665860,
          "Python" : 57544
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Documenting systemd commands, specifically listing the available commands and their descriptions.",
      "validationOrRequirement" : "The issue requires documentation of systemd commands, and the author is looking for contributors to help with the task.",
      "attemptedFixes" : "PRs have been submitted for some of the commands, such as systemd-cryptenroll, kernel-install, and systemd-socket-activate. There are also comments discussing how to remove or combine examples.",
      "otherNotes" : "The issue is about documenting systemd commands, and the author is looking for help from contributors. There are multiple comments discussing which examples should be removed, and how to combine some of them. The issue is still open, and the author is looking for help on the remaining commands that don't have open/merged PRs yet.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407316
  }, {
    "issueDTO" : {
      "id" : 846435491,
      "title" : "Let's document: aws",
      "url" : "https://github.com/tldr-pages/tldr/issues/5653",
      "repositoryName" : "tldr-pages/tldr",
      "description" : "- [ ] accessanalyzer ???\n- [ ] acm ???\n- [x] acm-pca ??? #13327\n- [ ] alexaforbusiness ???\n- [ ] amplify ???\n- [ ] amplifybackend ???\n- [ ] apigateway ???\n- [ ] apigatewaymanagementapi ???\n- [ ] apigatewayv2 ???\n- [ ] appconfig ???\n- [ ] appflow ???\n- [ ] appintegrations ???\n- [ ] application-autoscaling ???\n- [ ] application-insights ???\n- [ ] appmesh ???\n- [ ] appstream ???\n- [ ] appsync ???\n- [ ] athena ???\n- [ ] auditmanager ???\n- [ ] autoscaling ???\n- [ ] autoscaling-plans ???\n- [x] backup ??? #9369\n- [x] batch ??? #10570, #10591\n- [ ] braket ???\n- [ ] budgets ???\n- [x] ce ??? #13354\n- [ ] chime ???\n- [x] cloud9 ??? #10627\n- [ ] clouddirectory\n- [x] cloudformation ??? #10116\n- [ ] cloudfront ???\n- [ ] cloudhsm ???\n- [ ] cloudhsmv2 ???\n- [ ] cloudsearch ???\n- [ ] cloudsearchdomain ???\n- [ ] cloudtrail ???\n- [x] cloudwatch ??? #10614\n- [x] codeartifact ??? #11224\n- [ ] codebuild ???\n- [x] codecommit ??? #9202\n- [ ] codeguru-reviewer ???\n- [ ] codeguruprofiler ???\n- [ ] codepipeline ???\n- [ ] codestar ???\n- [ ] codestar-connections ???\n- [ ] codestar-notifications ???\n- [ ] cognito-identity ???\n- [x] cognito-idp ??? #9032\n- [ ] cognito-sync ???\n- [ ] comprehend ???\n- [ ] comprehendmedical ???\n- [ ] compute-optimizer ???\n- [ ] configservice ???\n- [x] configure ??? #8808\n- [ ] connect ???\n- [ ] connect-contact-lens ???\n- [ ] connectparticipant ???\n- [x] cur ??? #6133\n- [ ] customer-profiles ???\n- [ ] databrew ???\n- [ ] dataexchange ???\n- [ ] datapipeline ???\n- [ ] datasync ???\n- [ ] dax ???\n- [ ] deploy ???\n- [ ] detective ???\n- [ ] devicefarm ???\n- [ ] devops-guru ???\n- [ ] directconnect ???\n- [ ] discovery ???\n- [ ] dlm ???\n- [ ] dms ???\n- [ ] docdb ???\n- [ ] ds ???\n- [x] dynamodb ??? #11570\n- [ ] dynamodbstreams ???\n- [ ] ebs ???\n- [x] ec2 ???#4661\n- [ ] ec2-instance-connect ???\n- [x] ecr ??? #6134\n- [ ] ecr-public ???\n- [x] ecs ??? #4661\n- [ ] efs ???\n- [x] eks ??? #11577\n- [ ] elastic-inference ???\n- [ ] elasticache ???\n- [ ] elasticbeanstalk ???\n- [ ] elastictranscoder ???\n- [ ] elb ???\n- [ ] elbv2 ???\n- [ ] emr ???\n- [ ] emr-containers ???\n- [ ] es ???\n- [ ] events ???\n- [ ] firehose ???\n- [ ] fms ???\n- [ ] forecast ???\n- [ ] forecastquery ???\n- [ ] frauddetector ???\n- [ ] fsx ???\n- [ ] gamelift ???\n- [ ] glacier ???\n- [ ] globalaccelerator ???\n- [x] glue ??? #4740\n- [ ] greengrass ???\n- [ ] groundstation ???\n- [ ] guardduty ???\n- [ ] health ???\n- [ ] healthlake ???\n- [x] help ??? #6446 \n- [x] history ??? #8805\n- [ ] honeycode ???\n- [x] iam ??? #4662 \n- [ ] identitystore ???\n- [ ] imagebuilder ???\n- [ ] importexport ???\n- [ ] inspector ???\n- [ ] iot ???\n- [ ] iot-data ???\n- [ ] iot-jobs-data ???\n- [ ] iot1click-devices ???\n- [ ] iot1click-projects ???\n- [ ] iotanalytics ???\n- [ ] iotevents ???\n- [ ] iotevents-data ???\n- [ ] iotsecuretunneling ???\n- [ ] iotsitewise ???\n- [ ] iotthingsgraph ???\n- [ ] ivs ???\n- [x] kafka ??? #11696\n- [x] kendra ??? #13315\n- [x] kinesis ??? #4510\n- [ ] kinesis-video-archived-media ???\n- [ ] kinesis-video-media ???\n- [ ] kinesis-video-signaling ???\n- [ ] kinesisanalytics ???\n- [ ] kinesisanalyticsv2 ???\n- [ ] kinesisvideo ???\n- [ ] kms ???\n- [ ] lakeformation ???\n- [x] lambda ??? #4774\n- [ ] lex-models\n- [ ] lex-runtime\n- [ ] license-manager\n- [x] lightsail ??? #8934\n- [ ] logs ???\n- [ ] lookoutvision ???\n- [ ] machinelearning ???\n- [ ] macie ???\n- [ ] macie2 ???\n- [ ] managedblockchain ???\n- [ ] marketplace-catalog ???\n- [ ] marketplace-entitlement ???\n- [ ] marketplacecommerceanalytics ???\n- [ ] mediaconnect ???\n- [ ] mediaconvert ???\n- [ ] medialive ???\n- [ ] mediapackage ???\n- [ ] mediapackage-vod ???\n- [ ] mediastore ???\n- [ ] mediastore-data ???\n- [ ] mediatailor ???\n- [ ] meteringmarketplace ???\n- [ ] mgh ???\n- [ ] migrationhub-config ???\n- [ ] mobile ???\n- [ ] mq ???\n- [ ] mturk ???\n- [ ] mwaa ???\n- [ ] neptune ???\n- [ ] network-firewall ???\n- [ ] networkmanager ???\n- [ ] opsworks ???\n- [ ] opsworks-cm ???\n- [ ] organizations ???\n- [ ] outposts ???\n- [ ] personalize ???\n- [ ] personalize-events ???\n- [ ] personalize-runtime ???\n- [ ] pi ???\n- [ ] pinpoint ???\n- [ ] pinpoint-email ???\n- [ ] pinpoint-sms-voice ???\n- [ ] polly ???\n- [x] pricing ??? #8804\n- [ ] qldb ???\n- [ ] qldb-session ???\n- [x] quicksight ??? #4738\n- [ ] ram ???\n- [x] rds ??? #6547\n- [ ] rds-data ???\n- [ ] redshift ???\n- [ ] redshift-data ???\n- [ ] rekognition ???\n- [ ] resource-groups ???\n- [ ] resourcegroupstaggingapi ???\n- [ ] robomaker ???\n- [x] route53 ??? #8606 \n- [ ] route53domains ???\n- [ ] route53resolver ???\n- [x] s3 (This command has a separate issue page #8406 to track it's subcommands) \n- [x] s3api ??? #6132\n- [ ] s3control ???\n- [ ] s3outposts ???\n- [ ] sagemaker ???\n- [ ] sagemaker-a2i-runtime ???\n- [ ] sagemaker-edge ???\n- [ ] sagemaker-featurestore-runtime ???\n- [ ] sagemaker-runtime ???\n- [ ] savingsplans ???\n- [ ] schemas ???\n- [ ] sdb ???\n- [x] secretsmanager ??? #6131\n- [ ] securityhub ???\n- [ ] serverlessrepo ???\n- [ ] service-quotas ???\n- [ ] servicecatalog ???\n- [ ] servicecatalog-appregistry ???\n- [ ] servicediscovery ???\n- [x] ses ??? #7136\n- [ ] sesv2 ???\n- [ ] shield ???\n- [ ] signer ???\n- [ ] sms ???\n- [ ] snowball ???\n- [x] sns ??? #12259\n- [x] sqs ??? #9085\n- [ ] ssm ???\n- [x] sso ??? #14115\n- [ ] sso-admin ???\n- [ ] sso-oidc ???\n- [ ] stepfunctions ???\n- [ ] storagegateway ???\n- [x] sts ??? #8669\n- [ ] support ???\n- [ ] swf ???\n- [ ] synthetics ???\n- [ ] textract ???\n- [ ] timestream-query ???\n- [ ] timestream-write ???\n- [ ] transcribe ???\n- [ ] transfer ???\n- [ ] translate ???\n- [ ] waf ???\n- [ ] waf-regional ???\n- [ ] wafv2 ???\n- [ ] workdocs ???\n- [ ] worklink ???\n- [x] workmail  ??? #9058\n- [ ] workmailmessageflow ???\n- [ ] workspaces ???\n- [ ] xray ???",
      "updatedAt" : 1753371898.000000000,
      "user" : "Waples",
      "userHtmlUrl" : "https://github.com/Waples",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25055666?v=4",
      "labels" : [ "new command", "let's document", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@bl-ue whenever you are bored :P #HelpWanted :p", "Haha @Waples did you happen to see this: #5212?", "@Waples it looks like you might have removed all occurences of the letter `o` in the above command list \uD83D\uDE04, e.g. `alexafrbusiness`, `wrkmailmessageflw`, `applicatin-autscaling`", "> @Waples it looks like you might have removed all occurences of the letter `o` in the above command list , e.g. `alexafrbusiness`, `wrkmailmessageflw`, `applicatin-autscaling`\r\n\r\nOwh haha, think i was a bit too agressive with my `%s/\\so^/g` ish replace then xD will fix that in a second @bl-ue \r\n", "Fixed it =D\r\n", "@bl-ue didn't see that issue before, but that goes in a bit too deep with ALL the commands. \r\nI was thinking more like, for example [aws-ec2.md](https://github.com/tldr-pages/tldr/blob/master/pages/common/aws-ec2.md).", "You're right, that's why I closed it.  But I wanted to link it for reference \uD83D\uDC4D\uD83C\uDFFB ", "I'm gonna make some time today to add at least 15 examples, but I don't know what the best course of action is, a seperate branch for every page added or in one big PR ? \r\n@bl-ue  what ya want", "The former @Waples.  Please open 1 PR per new page.  It makes it easier to review the changes.\r\n\r\nIt would certainly be great if we could document all of the `aws` subcommands???I'd say they're probably looked for often \uD83E\uDD37\uD83C\uDFFB ", "Organization status, here I come. xD", "> I'd say they're probably looked for often \uD83E\uDD37\uD83C\uDFFB\r\nsounds a bit sarcastic xD", "Haha no I wasn't intended to be sarcastic actually :)", "Oh wow, that's an _enormous_ list @Waples! I'd suggest starting small, and opening just 1 or 2 PRs for 1 or 2 pages at a time to get used to the tldr page syntax if you haven't already got experience with the review process.", "Starting one on secrets manager now.", "Starting s3api and cur", "Might do ecs and eks next, everyone loves container orchestration.", "And do `ecr` ??? I'm going to upload some Docker images to ECR _just_ today, and it would be cool to know how to use `aws ecr`! \uD83D\uDE42", "I will start on ecr first then.", "It's a spiderweb. You need a tldr of docker-login for a tldr or aws ecr.", "This actually brings up an important question.\r\nThe authoritative documentation is more complete (eg. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecr/index.html), however, the quick start guide https://docs.aws.amazon.com/AmazonECR/latest/userguide/ is much more useful to get to know a new tool. It would deviate from the standard, but pages that include both would be more useful.", "Also need to add a short one for docker-tag", "And docker-image....\r\n\r\n\r\nDOCUMENT ALL THE THINGS!!! :D", "Hmm, I'm not really sure.  The first page does provide a lot more information directly related to the CLI (36 addition subcommands). The second page is tuned for beginners but isn't actually about the CLI.\r\n\r\nI'm probably inclined to keep the first link, because it seems like a user who goes to that link might be looking for more info on how to use the tool itself, but there's equal argument for both links, so I'm chasing my own tail here. \uD83D\uDE05", "The second link mirrors the same steps for cli and gui.", "I would suggest that for more information links subpages of <https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecr/index.html> (e.g. <https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecr/get-lifecycle-policy-preview.html>) are more directly relevant to each individual page.\r\n\r\nThe generic user guide looks useful, but not specifically to the `aws` subcommand being documented.", "Thanks @sbrl, I agree.", "> And docker-image....\r\n> \r\n> DOCUMENT ALL THE THINGS!!! :D\r\n\r\nIt's already there, my mistake, my package manager just didn't have the latest version of tldr.", "rds #6547", "Thanks for all your work @258204 !\r\nI've been very busy (work/private), hence why I didn't add anything so far to my \"todo\" list.\r\nI'll take a look at the state of the AWS API tomorrow, to see if new services need to be added to the list.\r\nI might have some time tomorrow to write some tldr pages, time will tell.", "aws sts #8669 ", "aws pricing #8804", "aws history #8805", "aws configure #8808", "Hi! I'll work on sqs command file", "aws-sqs: add page #9085", "Thank you @piraces @bryanmg for all your work! ", "Note to self: check if the list still up to date with the v2 (and beta v3) version of aws-cli", "First timer trying to help.\r\n\r\naws-batch: add page #10591", "aws-cloudwatch: add page #10614", "aws-cloud9: add page #10627 ", "Can I work on this?\r\n", "> Can I work on this?\r\n\r\nSure", "I am new to open source, could you please guide me? and what are the things I should follow in order to solve this issue ", "I'm new. Can I help?\r\n\r\naws-codeartifact: add page https://github.com/tldr-pages/tldr/pull/11224", "Hey, @Sourav-Kumar-Panda, @nkzren! You don't need to ask - just open a pull request with a new page :-)", "Update from myself: I might do some work with `Sagemaker` in the near future (on boto3 level), so I might document something for those items.", "Hey, @Waples , please check the PR #11570", "aws-eks: add page. #11577 ", "When looking at https://docs.aws.amazon.com/cli/latest/, there is a note about a new CLI version:\n\n> [!NOTE]\n> You are viewing the documentation for an older major version of the AWS CLI (version 1).\n> AWS CLI version 2, the latest major version of AWS CLI, is now stable and recommended for general use. To view this page for the AWS CLI version 2, click [here](https://awscli.amazonaws.com/v2/documentation/api/latest/index.html).\n\nShould we update the pages to match the new version?", "> Should we update the pages to match the new version?\r\n\r\nYeah, we should also check for any changed syntax and update it (if a subcommand/flag got deprecated we should mention it is only available in v1).", "Don't forget to reference this PR's number in any PRs you open @sebastiaanspeck :-)", "@Waples adding this to the aws terraform. Writing the aws terraform initator files: https://github.com/sablokgaurav/hashicorp_instance_initiator/blob/main/terraform_aws.sh for merging into the tldr pages. ", "Just as an FYI, I have been ill / busy for a long while, but I do still weekly check how the process is going. Thank you all for giving you're time to fill the stupidly long list of items.\r\n\r\nI will be more aware of ongoing work / MR/PRs etc from now on again, now my health has improved (beware xD). ", "> Just as an FYI, I have been ill / busy for a long while, but I do still weekly check how the process is going. Thank you all for giving you're time to fill the stupidly long list of items.\r\n> \r\n> I will be more aware of ongoing work / MR/PRs etc from now on again, now my health has improved (beware xD).\r\n\r\nGood to have you back! :D ", "> > Just as an FYI, I have been ill / busy for a long while, but I do still weekly check how the process is going. Thank you all for giving you're time to fill the stupidly long list of items.\r\n> > I will be more aware of ongoing work / MR/PRs etc from now on again, now my health has improved (beware xD).\r\n> \r\n> Good to have you back! :D\r\n\r\nthanks bruv ^^ feeling allot better now. Lets document some stuff haha\r\n", "At the time of writing, I don't even know myself anymore if this list is complete and compatible with v3 (and v4-beta).\r\n\r\nNote to self: investigate this.\r\n\r\nAnd again, thank you all for helping with this massive project.\r\n\r\n// Florian", "Good morning, I am new to open source contributions. I saw this project and I am interested in contributing, how can I get started, whether for this issue or another?", "> Good morning, I am new to open source contributions. I saw this project and I am interested in contributing, how can I get started, whether for this issue or another?\n\nRead [CONTRIBUTING.md](https://github.com/tldr-pages/tldr/blob/main/CONTRIBUTING.md) and [Style Guide](https://github.com/tldr-pages/tldr/blob/main/contributing-guides/style-guide.md). This will make it easier both for you and maintainers.\n\nIf you speak lang other than English, consider translating the pages, it's the most easy way to get started.\n\nConsider adding examples to existing pages to practice before creating new pages, but creating a new page is welcome too.\n\nCheck this [tutorial](https://github.com/firstcontributions/first-contributions) to learn GitHub and Git.", "aws-sso: add page https://github.com/tldr-pages/tldr/pull/14115", "> aws-sso: add page https://github.com/tldr-pages/tldr/pull/14115\n\nThanks! Added to the list " ],
      "repository" : {
        "description" : "\uD83D\uDCDA Collaborative cheatsheets for console commands",
        "homepage" : "https://tldr.sh",
        "name" : "tldr",
        "fullName" : "tldr-pages/tldr",
        "htmlUrl" : "https://github.com/tldr-pages/tldr",
        "gitUrl" : "git://github.com/tldr-pages/tldr.git",
        "sshUrl" : "git@github.com:tldr-pages/tldr.git",
        "cloneUrl" : "https://github.com/tldr-pages/tldr.git",
        "owner" : {
          "login" : "tldr-pages",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4570,
        "stargazersCount" : 56519,
        "watchersCount" : 56519,
        "size" : 38054,
        "openIssuesCount" : 232,
        "subscribersCount" : 387,
        "pushedAt" : "2025-07-24T18:22:25Z",
        "languages" : {
          "Shell" : 18090,
          "CSS" : 1056,
          "JavaScript" : 1896,
          "Markdown" : 12665860,
          "Python" : 57544
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document all AWS commands and subcommands, providing a comprehensive and easy-to-follow guide for users.",
      "validationOrRequirement" : "The issue requires a thorough review of the AWS CLI documentation and the creation of new pages for each command and subcommand.",
      "attemptedFixes" : "Several contributors have attempted to add pages for various AWS commands, but the issue remains incomplete.",
      "otherNotes" : "This issue aims to document all AWS commands and subcommands, with a focus on providing a comprehensive and easy-to-follow guide for users.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407321
  }, {
    "issueDTO" : {
      "id" : 3247992054,
      "title" : "Improve options menu for default view",
      "url" : "https://github.com/twentyhq/twenty/issues/13306",
      "repositoryName" : "twentyhq/twenty",
      "description" : "# Current behavior\n\nSome users don't understand why they cannot create a kanban view in the `View Options Menu` of a `default view` (or why they cannot use the group by or delete this view) ??? The default view is a view you cannot persist filter or layout modification on so you would always have a view with all the records of an object available.\n\n<img width=\"367\" height=\"333\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/83b507a4-16f1-4e38-8034-f89a60f2f6cd\" />\n\n# Desired Behavior\n\n<img width=\"629\" height=\"506\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/403db326-af73-4d34-a5ec-71be6ae7b5ef\" />\n\n\n- display \"default view\" in the menu header instead of \"All\" (just in the options menu - keep things as they are in the view switcher)\n- Add a lock to explain this view isn't customizable\n- Remove the options that are not available for the default view\n- Add a \"Create a custom view\" CTA\n\nhttps://www.figma.com/design/xt8O9mFeLl46C5InWwoMrN/Twenty?node-id=70615-186990&t=VI6vS6s8k55CRAJw-11",
      "updatedAt" : 1753371894.000000000,
      "user" : "Bonapara",
      "userHtmlUrl" : "https://github.com/Bonapara",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19412894?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey! I am new to open source and would love to contribute. This issue looks interesting could you assign it to me so that i could work on it?", "Hi @ankitdeveloper7, maybe you can find an easier good first issue if it's your first contribution? Thanks for contributing to OSS!", "hi @Bonapara , I had some queries around this issue.\n1) If we remove the Group, Layout and Delete View it won't be available  in all the sections such as Companies, People etc.\n2) What action do you want in Create a Custom view option?\n3) I created the Create a custom view option but the icon [(IconLayoutGrid)](https://tabler.io/icons/icon/layout-grid-add) cannot be imported to twenty/ui/display because it is autogenerated. Do you want the same icon or any other icon can be used which is already present in the code.", "Hi @prynsh \n\n1. We only want to remove them/display the above menu for \"Default views\" (where Group, Layout and Delete View  are grayed out). To use them, people should create a custom view from the \"Create a custom view\" CTA\n2. `Create a custom view` should duplicate the default view and open this new view options menu focused on the view name : \n\n<img width=\"506\" height=\"477\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/633aea67-89e9-4710-ab71-5a6320964fea\" />\n\nhttps://www.figma.com/design/xt8O9mFeLl46C5InWwoMrN/Twenty?node-id=43710-119534&t=hi8DdtTxo0fuFQRL-11\n\n3. can you use https://tabler.io/icons/icon/layout instead?\n\nThanks a lot!", "hi @Bonapara ,\nBelow is the demo for the change requested.\nThis works?\n\nhttps://github.com/user-attachments/assets/c20fff30-10d2-40fd-ac0b-c91ca4e7c710", "Hi @prynsh, did it generate a new view? If so, it looks good! Could we add a number after the view name to indicate it's a new view? For example, in your video: `All People (1)`?", "Yes, it generates a new view. Below is the demo for it . This is what was required?\nI did not get the number part here. Number as in how many views one has created?\n\nDemo:\n\nhttps://github.com/user-attachments/assets/39e97eff-17eb-46df-a02c-325c6366c737\n\n" ],
      "repository" : {
        "description" : "Building a modern alternative to Salesforce, powered by the community.",
        "homepage" : "https://twenty.com",
        "name" : "twenty",
        "fullName" : "twentyhq/twenty",
        "htmlUrl" : "https://github.com/twentyhq/twenty",
        "gitUrl" : "git://github.com/twentyhq/twenty.git",
        "sshUrl" : "git@github.com:twentyhq/twenty.git",
        "cloneUrl" : "https://github.com/twentyhq/twenty.git",
        "owner" : {
          "login" : "twentyhq",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3865,
        "stargazersCount" : 34414,
        "watchersCount" : 34414,
        "size" : 347090,
        "openIssuesCount" : 193,
        "subscribersCount" : 157,
        "pushedAt" : "2025-07-25T00:04:15Z",
        "languages" : {
          "TypeScript" : 23752375,
          "MDX" : 250778,
          "HCL" : 19327,
          "Dockerfile" : 6684,
          "Shell" : 14942,
          "CSS" : 4566,
          "Makefile" : 2909,
          "JavaScript" : 39322,
          "HTML" : 5346
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve the options menu for the default view by making it clear that it is a view that cannot be customized, and provide a way for users to create a custom view.",
      "validationOrRequirement" : "Remove the options that are not available for the default view, display 'default view' in the menu header instead of 'All', add a lock to explain this view isn't customizable, and add a 'Create a custom view' CTA.",
      "attemptedFixes" : "The 'Create a custom view' CTA was implemented, but the icon could not be imported because it is autogenerated. Instead, the icon https://tabler.io/icons/icon/layout can be used.",
      "otherNotes" : "The default view is a view that cannot persist filter or layout modification, so users would always have a view with all the records of an object available. Users are confused about why they cannot create a kanban view in the View Options Menu of a default view.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407327
  }, {
    "issueDTO" : {
      "id" : 777508790,
      "title" : "Let's document! vcpkg & conan edition",
      "url" : "https://github.com/tldr-pages/tldr/issues/5070",
      "repositoryName" : "tldr-pages/tldr",
      "description" : "[vcpkg](https://github.com/microsoft/vcpkg) and [conan](https://conan.io/) are popular C++ package managers.  I've used both myself.  I've written pages for each of them, but in reality they probably need a page for each sub command since there are many.\n\nvcpkg:\n\n- [x] vcpkg https://github.com/tldr-pages/tldr/pull/12295\n- [ ] `contact`\n- [ ] `create`\n- [ ] `depend-info`\n- [ ] `edit`\n- [ ] `env`\n- [ ] `export`\n- [ ] `hash`\n- [ ] `help`\n- [ ] `help`\n- [ ] `install`\n- [ ] `integrate`\n- [ ] `list`\n- [ ] `owns`\n- [ ] `remove`\n- [ ] `remove`\n- [ ] `search`\n- [ ] `update`\n- [ ] `upgrade`\n- [ ] `version`\n- [ ] `x-history` (this is alpha, hence `x-`)\n\nconan:\n- [x] conan https://github.com/tldr-pages/tldr/pull/5008\n- [ ] `alias`\n- [ ] `build`\n- [ ] `config`\n- [ ] `copy`\n- [ ] `create`\n- [ ] `download`\n- [ ] `editable`\n- [ ] `export-pkg`\n- [ ] `export`\n- [x] `frogarian` (#5081)\n- [ ] `get`\n- [ ] `help`\n- [ ] `imports`\n- [ ] `info`\n- [ ] `inspect`\n- [ ] `install`\n- [ ] `lock`\n- [ ] `new`\n- [ ] `package`\n- [ ] `profile`\n- [ ] `remote`\n- [ ] `remove`\n- [ ] `search`\n- [ ] `source`\n- [ ] `test`\n- [ ] `upload`\n- [ ] `user`\n- [ ] `workspace`",
      "updatedAt" : 1753371882.000000000,
      "user" : "bl-ue",
      "userHtmlUrl" : "https://github.com/bl-ue",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/54780737?v=4",
      "labels" : [ "new command", "let's document", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "\uD83D\uDCDA Collaborative cheatsheets for console commands",
        "homepage" : "https://tldr.sh",
        "name" : "tldr",
        "fullName" : "tldr-pages/tldr",
        "htmlUrl" : "https://github.com/tldr-pages/tldr",
        "gitUrl" : "git://github.com/tldr-pages/tldr.git",
        "sshUrl" : "git@github.com:tldr-pages/tldr.git",
        "cloneUrl" : "https://github.com/tldr-pages/tldr.git",
        "owner" : {
          "login" : "tldr-pages",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4570,
        "stargazersCount" : 56519,
        "watchersCount" : 56519,
        "size" : 38054,
        "openIssuesCount" : 232,
        "subscribersCount" : 387,
        "pushedAt" : "2025-07-24T18:22:25Z",
        "languages" : {
          "Shell" : 18090,
          "CSS" : 1056,
          "JavaScript" : 1896,
          "Markdown" : 12665860,
          "Python" : 57544
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document vcpkg and conan, two popular C++ package managers, by creating pages for each of their sub-commands.",
      "validationOrRequirement" : "The issue does not specify any specific requirements or validations, but it does include a list of sub-commands for vcpkg and conan that need to be documented.",
      "attemptedFixes" : "The issue links to two existing pull requests for vcpkg and conan, indicating that some work has already been done on documenting these package managers.",
      "otherNotes" : "The issue aims to document vcpkg and conan, two popular C++ package managers, by creating pages for each of their sub-commands.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407332
  }, {
    "issueDTO" : {
      "id" : 3214532123,
      "title" : "Define `hashCode` as a lazy val",
      "url" : "https://github.com/typelevel/otel4s/issues/1007",
      "repositoryName" : "typelevel/otel4s",
      "description" : "We can experiment with the following encoding:\n```scala\n@threadUnsafe\noverride final lazy val hashCode: Int = Hash[X].hash(this)\n```\n\nCurrently, we recalculate hashCode every time. ",
      "updatedAt" : 1753371864.000000000,
      "user" : "iRevive",
      "userHtmlUrl" : "https://github.com/iRevive",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6395483?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "what types are regularly getting hashed for which this is a concern?", "A few items are getting hashed regularly in the SDK modules:\n- SpanContext\n- TraceState (part of the SpanContext hash)\n- TraceFlags (part of the SpanContext hash)\n- Attributes\n- Attribute (part of the Attributes hash)\n- AttributeKey (part of the Attribute hash)\n- MetricDescriptor\n- sdk.InstrumentationScope\n- sdk.context.Context.Key\n" ],
      "repository" : {
        "description" : "An OpenTelemetry library for Scala based on Cats-Effect",
        "homepage" : "https://typelevel.org/otel4s",
        "name" : "otel4s",
        "fullName" : "typelevel/otel4s",
        "htmlUrl" : "https://github.com/typelevel/otel4s",
        "gitUrl" : "git://github.com/typelevel/otel4s.git",
        "sshUrl" : "git@github.com:typelevel/otel4s.git",
        "cloneUrl" : "https://github.com/typelevel/otel4s.git",
        "owner" : {
          "login" : "typelevel",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 43,
        "stargazersCount" : 193,
        "watchersCount" : 193,
        "size" : 6101,
        "openIssuesCount" : 31,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-24T15:32:44Z",
        "languages" : {
          "Jinja" : 13997,
          "Shell" : 10,
          "Scala" : 3522219,
          "Nix" : 804
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Define `hashCode` as a lazy val to avoid recalculating it every time",
      "validationOrRequirement" : "None mentioned",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "Few types are regularly getting hashed, including SpanContext, TraceState, TraceFlags, Attributes, Attribute, AttributeKey, MetricDescriptor, sdk.InstrumentationScope, and sdk.context.Context.Key",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407334
  }, {
    "issueDTO" : {
      "id" : 3260357896,
      "title" : "JLink.flash() raises JLinkEraseException on JLINKARM_EndDownload() errors",
      "url" : "https://github.com/square/pylink/issues/241",
      "repositoryName" : "square/pylink",
      "description" : "JLINKARM_EndDownload() return values are\n\n-1 Generic error\n-2 Error during compare phase (checking if flash content already matches the programming data)\n-3 Error during program/erase phase\n-4 Error during verification phase.\n\nwhich correspond to errors.JLinkFlashException, not errors.JLinkEraseException",
      "updatedAt" : 1753371830.000000000,
      "user" : "chanqueo",
      "userHtmlUrl" : "https://github.com/chanqueo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4894814?v=4",
      "labels" : [ "bug", "beginner", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Good catch! Looks like I put the wrong thing in `flash()` but the right thing in `flash_write()`." ],
      "repository" : {
        "description" : "Python Library for device debugging/programming via J-Link",
        "homepage" : "https://pylink.readthedocs.io/en/latest/",
        "name" : "pylink",
        "fullName" : "square/pylink",
        "htmlUrl" : "https://github.com/square/pylink",
        "gitUrl" : "git://github.com/square/pylink.git",
        "sshUrl" : "git@github.com:square/pylink.git",
        "cloneUrl" : "https://github.com/square/pylink.git",
        "owner" : {
          "login" : "square",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 135,
        "stargazersCount" : 386,
        "watchersCount" : 386,
        "size" : 492,
        "openIssuesCount" : 81,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-21T14:28:21Z",
        "languages" : {
          "C" : 30203,
          "GDB" : 1835,
          "Linker Script" : 19830,
          "Gherkin" : 8219,
          "Makefile" : 8017,
          "Assembly" : 37869,
          "Python" : 739627
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "JLink.flash() raises JLinkEraseException on JLINKARM_EndDownload() errors",
      "validationOrRequirement" : "JLink.flash() should not raise JLinkEraseException on JLINKARM_EndDownload() errors",
      "attemptedFixes" : "No attempted fixes mentioned",
      "otherNotes" : "The wrong thing was put in `flash()` but the right thing in `flash_write()`",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407337
  }, {
    "issueDTO" : {
      "id" : 2040548673,
      "title" : "Programmatic Interface to Ponder",
      "url" : "https://github.com/ponder-sh/ponder/issues/513",
      "repositoryName" : "ponder-sh/ponder",
      "description" : "Allow for a TypeScript API for interactive with ponder. This might be as simple as exporting the ponder class from the `index.ts` entrypoint. Some benefits include end to end tests and easier benchmarking.",
      "updatedAt" : 1753371711.000000000,
      "user" : "kyscott18",
      "userHtmlUrl" : "https://github.com/kyscott18",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/43524469?v=4",
      "labels" : [ "Good first issue", "T: Feature" ],
      "state" : "OPEN",
      "comments" : [ "+1", "e2e testing going to be wild. We need this!\n+1\n", "As a workaround this we could use `docker` and `testcontainers`. Basically this can be a good candidate for a new guide in documentation: \"how to run ponder during tests run\".\n\nHere's quick example on how it would look like from tests perspective: https://node.testcontainers.org/quickstart/usage/. But it might also make sense to guide on how to setup a docker container with ponder because I remember I had some issues with this (it was couple months ago)", "I currently think of using only the indexing part of ponder and utilizing inside another application. Being able to start ponder programmatically could be very beneficial." ],
      "repository" : {
        "description" : "The backend framework for crypto apps",
        "homepage" : "https://ponder.sh",
        "name" : "ponder",
        "fullName" : "ponder-sh/ponder",
        "htmlUrl" : "https://github.com/ponder-sh/ponder",
        "gitUrl" : "git://github.com/ponder-sh/ponder.git",
        "sshUrl" : "git@github.com:ponder-sh/ponder.git",
        "cloneUrl" : "https://github.com/ponder-sh/ponder.git",
        "owner" : {
          "login" : "ponder-sh",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 178,
        "stargazersCount" : 889,
        "watchersCount" : 889,
        "size" : 30284,
        "openIssuesCount" : 87,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-24T23:23:24Z",
        "languages" : {
          "TypeScript" : 2430920,
          "Shell" : 161,
          "Solidity" : 4967,
          "JavaScript" : 23654
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow for a TypeScript API for interacting with ponder",
      "validationOrRequirement" : "export ponder class from the index.ts entrypoint, end to end tests, easier benchmarking",
      "attemptedFixes" : "using docker and testcontainers, setup a docker container with ponder",
      "otherNotes" : "e2e testing going to be wild, need this!, workaround: use docker and testcontainers, create guide for documentation, example: https://node.testcontainers.org/quickstart/usage/",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407341
  }, {
    "issueDTO" : {
      "id" : 3260252978,
      "title" : "Officially deprecate `airflow.security.permissions`",
      "url" : "https://github.com/apache/airflow/issues/53716",
      "repositoryName" : "apache/airflow",
      "description" : "### Description\n\nThe proposal for this issue: we should add deprecation warnings for the `airflow.security.permissions` module so the deprecation status is unambiguous to end users of Airflow 3.x who may currently rely on that module. These warnings should indicate that the newer standards to migrate to are as follows:\n\n* `airflow.security.permissions.ACTION_CAN_*` constants -> [`ResourceMethod`](https://github.com/apache/airflow/blob/main/airflow-core/src/airflow/api_fastapi/auth/managers/base_auth_manager.py#L66) (and [`ExtendedResourceMethod`](https://github.com/apache/airflow/blob/main/airflow-core/src/airflow/api_fastapi/auth/managers/base_auth_manager.py#L68))\n* `airflow.security.permissions.RESOURCE_*` constants -> relevant definitions under [`resource_details.py`](https://github.com/apache/airflow/blob/3.0.3/airflow-core/src/airflow/api_fastapi/auth/managers/models/resource_details.py)\n\n### Use case/motivation\n\nAs part of the Auth Manager interface rollout, the older `airflow.security.permissions` module has been superseded by the newer `ResourceMethod` and `airflow.api_fastapi.auth.managers.models.resource_details` standards. As such, the usage of `airflow.security.permissions` should probably be phased out over the longterm. \n\nObviously, the full decommissioning of that module will require broader coordination, and future updates within the FAB auth manager, along with ample warnings and communication to users who may still rely on the older permissions module. The motivation for this issue is to start surfacing those warnings now.\n\n### Related issues\n\nThis came up in the very helpful thread here: https://github.com/apache/airflow/issues/51971\n\n### Are you willing to submit a PR?\n\n- [x] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [x] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)\n",
      "updatedAt" : 1753371656.000000000,
      "user" : "zach-overflow",
      "userHtmlUrl" : "https://github.com/zach-overflow",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4951117?v=4",
      "labels" : [ "area:auth", "good first issue", "kind:feature" ],
      "state" : "OPEN",
      "comments" : [ "cc @vincbeck ", "Good idea. And deprecation should have clear indication about all that moving to FAB provider. People are currently quite confused that all the things that they relied on in Airflow as RBAC are now in FAB. I think we should use all the opportunity to communicate it", "> Good idea. And deprecation should have clear indication about all that moving to FAB provider. People are currently quite confused that all the things that they relied on in Airflow as RBAC are now in FAB. I think we should use all the opportunity to communicate it\n\nExactly. The reason we cannot remove this module (yet) is this is still used by many users in their plugins. If I remember well, I deleted this module when working on AF3 but we received many complaints from users that they need it. But definitely, adding deprecation warnings would at least make it clear to users that they should use the one in FAB provider and not this one." ],
      "repository" : {
        "description" : "Apache Airflow - A platform to programmatically author, schedule, and monitor workflows",
        "homepage" : "https://airflow.apache.org/",
        "name" : "airflow",
        "fullName" : "apache/airflow",
        "htmlUrl" : "https://github.com/apache/airflow",
        "gitUrl" : "git://github.com/apache/airflow.git",
        "sshUrl" : "git@github.com:apache/airflow.git",
        "cloneUrl" : "https://github.com/apache/airflow.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15362,
        "stargazersCount" : 41230,
        "watchersCount" : 41230,
        "size" : 419309,
        "openIssuesCount" : 1522,
        "subscribersCount" : 763,
        "pushedAt" : "2025-07-24T23:09:06Z",
        "languages" : {
          "Java" : 1443,
          "Jinja" : 76192,
          "CSS" : 15733,
          "Go" : 63158,
          "HTML" : 43330,
          "Jupyter Notebook" : 7288,
          "TypeScript" : 2168833,
          "HCL" : 3786,
          "Dockerfile" : 119789,
          "Shell" : 232889,
          "JavaScript" : 329955,
          "Mako" : 2684,
          "Python" : 42616717
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "add deprecation warnings for the `airflow.security.permissions` module so the deprecation status is unambiguous to end users of Airflow 3.x who may currently rely on that module",
      "validationOrRequirement" : "clear indication about all that moving to FAB provider, users should use the one in FAB provider and not this one",
      "attemptedFixes" : "adding deprecation warnings",
      "otherNotes" : "The reason we cannot remove this module (yet) is this is still used by many users in their plugins. If I remember well, I deleted this module when working on AF3 but we received many complaints from users that they need it. But definitely, adding deprecation warnings would at least make it clear to users that they should use the one in FAB provider and not this one.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407346
  }, {
    "issueDTO" : {
      "id" : 1051191869,
      "title" : "[Tracker] Implement all `numpy.*` APIs in CuPy",
      "url" : "https://github.com/cupy/cupy/issues/6078",
      "repositoryName" : "cupy/cupy",
      "description" : "Implement GPU version of `numpy.*` functions in `cupy.*` namespace.\n\nThis is a tracker issue that lists the remaining `numpy.*` APIs (see also: [comparison table](https://docs.cupy.dev/en/latest/reference/comparison.html#module-level)). I've categorized them based on difficulty so that new contributors can pick the right task. Your contribution is highly welcomed and appreciated!\n\n# List of APIs\n\n## Very Easy\n- [x] `numpy.asfarray` (#6085)\n- [x] `numpy.byte_bounds` (hint: `ndarray.data.ptr`) (#7015)\n- [x] `numpy.format_float_positional` (#6308)\n- [x] `numpy.format_float_scientific` (#6474)\n- [x] `numpy.ndarray.searchsorted` (#7059)\n- [ ] Alias: `numpy.bool`, `numpy.long`, `numpy.ulong`, `numpy.isdtype`\n\n## Easy\n- [x] `numpy.apply_over_axes` (#8177)\n- [x] `numpy.array_equiv` (#6254)\n- [x] `numpy.asarray_chkfinite` (#6275)\n- [x] `numpy.fabs` (#6282)\n- [x] `numpy.float_power` (#6371)\n- [x] `numpy.heaviside` (#6798)\n- [x] `numpy.isneginf` (#6089)\n- [x] `numpy.isposinf` (#6089)\n- [x] `numpy.mask_indices` (#6156)\n- [x] `numpy.real_if_close` (#6475)\n- [x] `numpy.setdiff1d` (#6433)\n- [x] `numpy.setxor1d` (#6582)\n- [x] `numpy.tril_indices` & `numpy.tril_indices_from` (#6305)\n- [x] `numpy.triu_indices` & `numpy.triu_indices_from` (#6316)\n- [x] `numpy.union1d` (#6357)\n- [ ] `numpy.bitwise_count`\n- [ ] `numpy.cumulative_prod`\n- [ ] `numpy.cumulative_sum`\n- [ ] `numpy.matrix_transpose`\n- [ ] `numpy.vecdot`\n- [ ] `numpy.linalg.diagonal`\n- [ ] `numpy.linalg.matmul`\n- [ ] `numpy.linalg.matrix_norm`\n- [ ] `numpy.linalg.matrix_transpose`\n- [ ] `numpy.linalg.outer`\n- [ ] `numpy.linalg.svdvals`\n- [ ] `numpy.linalg.tensordot`\n- [ ] `numpy.linalg.trace`\n- [ ] `numpy.linalg.vecdot`\n- [ ] `numpy.linalg.vector_norm`\n- [ ] `numpy.lib.format.*`\n- [x] `numpy.lib.stride_tricks.sliding_window_view` (#6956, #7575)\n- [ ] `numpy.emath.*` (`numpy.lib.scimath.*`) (#7295)\n\n## Medium\n- [ ] `numpy.block`\n- [ ] `numpy.unstack`\n- [x] `numpy.delete` (#7359)\n- [ ] `numpy.geomspace` (#9082)\n- [ ] `numpy.insert` (#6597)\n- [x] `numpy.put_along_axis` (#8199)\n- [x] `numpy.row_stack` (#6312)\n- [ ] `numpy.spacing`\n- [x] `numpy.vander` (#6279)\n- [x] `numpy.linalg.eig` (#8980)\n- [x] `numpy.linalg.eigvals` (#8980)\n\n## Medium to Hard\n- [ ] `numpy.histogram_bin_edges`\n- [x] `numpy.ediff1d` (#6280)\n- [x] `numpy.intersect1d` (#6402, #6407)\n- [ ] `numpy.nanpercentile`\n- [ ] `numpy.nanquantile`\n- [ ] `numpy.ndarray.ctypes` (note: needs design discussion)\n- [ ] `numpy.ndarray.getfield`\n- [ ] `numpy.ndarray.resize`\n- [ ] `numpy.ndarray.setfield`\n- [ ] `numpy.polynomial.*`\n- [x] `numpy.poly` (#3547, #6697)\n- [ ] `numpy.polyder` (#6469)\n- [ ] `numpy.polydiv` (#3780)\n- [ ] `numpy.polyint`\n- [x] `numpy.trapz` (#6107)\n- [x] `numpy.linalg.cond` (#9140)\n- [ ] `numpy.linalg.multi_dot` (#6358)\n- [ ] `numpy.random.Generator.*` (see the dedicated tracker issue for details: https://github.com/cupy/cupy/issues/4557)\n\n## Low priority\n\n### Iterator functions\n- [ ] `numpy.ndenumerate`\n- [ ] `numpy.nditer`\n- [ ] `numpy.nested_iters`\n\n### Help functions\n- [ ] `numpy.info`\n- [ ] `numpy.lookfor`\n- [ ] `numpy.source`\n\n### Internal functions\n- [ ] `numpy.deprecate`\n- [ ] `numpy.deprecate_with_doc`\n\n### Dtype APIs - need to filter types unsupported by CuPy\n- [ ] `numpy.maximum_sctype`\n- [ ] `numpy.cast` (undocumented API) (hint: see `numpy/core/numerictypes.py`)\n- [ ] `numpy.typecodes` (undocumented API)\n- [ ] `numpy.sctypeDict` (undocumented API)\n- [ ] `numpy.sctypes` (undocumented API)\n- [ ] `numpy.nbytes` (undocumented API)\n\n### Rarely used APIs\n- [ ] `numpy.einsum_path` (#6723)\n- [ ] `numpy.frompyfunc` (maybe just call GUFunc?)\n\n# Steps to Contribute\n\nNote: You will need a GPU environment to develop CuPy.\n\n1. Fork and star :star: the CuPy repository :wink:\n\n1. Pick a function you want to work on. You can find the function in the [NumPy API Reference](https://numpy.org/doc/stable/reference/routines.html) to understand what should be implemented.\n\n1. Implement a function in your branch. If you need help, join [Gitter](https://gitter.im/cupy/community) or just ask for help in this issue.\n\n1. Implement test code.\n\n1. Build CuPy and run tests to confirm that the function runs fine:\n  `pip install --no-build-isolation -e . && pytest tests/cupy_tests/PATH_TO_YOUR_TEST`\n   See the [Contribution Guide](https://docs.cupy.dev/en/latest/contribution.html#unit-testing) for details.\n\n1. Submit a pull-request to the `main` branch. (example: #9140)\n\nSee also:\n* #6324\n* #6692",
      "updatedAt" : 1753371452.000000000,
      "user" : "kmaehashi",
      "userHtmlUrl" : "https://github.com/kmaehashi",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/939877?v=4",
      "labels" : [ "contribution welcome", "good first issue", "cat:feature" ],
      "state" : "OPEN",
      "comments" : [ "Hi @kmaehashi,\r\nI am glad to look into the awesome collection of required APIs. \r\n\r\nI was wondering if other APIs for constant functions like `numpy.inf`, `numpy.ninf` etc can also be added to the `cupy` library. Curious to know your viewpoints. Thanks!\r\n\r\n**NumPy Reference**: https://numpy.org/devdocs/reference/constants.html.", "@khushi-411 Thanks for pull-requests! All constants are imported in CuPy \uD83D\uDE04 \r\n https://github.com/cupy/cupy/blob/v10.0.0rc1/cupy/__init__.py#L56-L73", "cc @leofang @grlee77 @rgommers", "There's a whole bunch of very questionable stuff here, including things that are deprecated. It does not make sense to me to add those. But rather than spend time arguing about that, let me just go work on a PR to remove them from NumPy:)", "Yeah some of the easy and very easy things read that way to me\r\n\r\nThe medium & medium to hard seem ok though (with the exception of the typing stuff)\r\n\r\nThe iterating functions (particularly on GPUs) I'm not sure about, but maybe Leo has thoughts there.\r\n\r\nAnything else stick out to you, Ralf? Does the above sound roughly correct to you or are there other things that stick out?", "@rgommers Could you list what is deprecated/inappropriate? I thought @kmaehashi has avoided listing them.", "`loads` and `ndfromtxt` were already removed in https://github.com/numpy/numpy/pull/19615, so can be removed from the list.\r\n\r\n> The medium & medium to hard seem ok though (with the exception of the typing stuff)\r\n\r\nWith \"typing stuff\" do you mean the dtype-related functions (`cast`, `typecodes`, etc.)? If so, then I agree - that's questionable. Also xref https://github.com/numpy/numpy/issues/17325 for that.\r\n\r\n> The iterating functions (particularly on GPUs) I'm not sure about, but maybe Leo has thoughts there.\r\n>\r\n> Anything else stick out to you, Ralf? Does the above sound roughly correct to you or are there other things that stick out?\r\n\r\nThat sounds about right. The `random` and `linalg` stuff is important, as are some of the medium-hard functions like `put_along_axis`, `nanquantile`, `nanpercentile`, etc.\r\n\r\nAll of the undocumented ones I'd like to get rid of in NumPy.", "> > The medium & medium to hard seem ok though (with the exception of the typing stuff)\r\n> \r\n> With \"typing stuff\" do you mean the dtype-related functions (`cast`, `typecodes`, etc.)? If so, then I agree - that's questionable. Also xref [numpy/numpy#17325](https://github.com/numpy/numpy/issues/17325) for that.\r\n\r\nYeah exactly. Sorry that was vague", "`alen` and `asscalar` will be removed in 1.23.0 (probably, unless it still gets backported to `1.22.x`) by https://github.com/numpy/numpy/pull/20414", "See also:\r\n\r\nhttps://github.com/numpy/numpy/blob/main/numpy/tests/test_public_api.py#L33-L54", "@rgommers Thank you for all the information. I've removed deprecated ones from the list:\r\n\r\n- `numpy.loads`\r\n- `numpy.ndfromtxt`\r\n- `numpy.alen`\r\n- `numpy.asscalar`\r\n- `numpy.ndarray.tostring`\r\n- `numpy.set_numeric_ops`\r\n\r\nAlso marked dtype-related functions as low priority as there's an ongoing discussion in NumPy.", "i also want to contribute in this library but when i seen this all issues are resolved so could you please assign me a tasks", "I've noticed that the automatic domain functions (numpy.emath.* or numpy.lib.scimath.*) seem to be missing from this. Is this a mistake, or are they not supposed to be supported?\r\nhttps://numpy.org/doc/stable/reference/routines.emath.html", "@Nordicus Yes it's just because I overlooked it, thanks for the catch! \uD83D\uDE04 ", "Hi team, I was looking into implementing `cupy.emath.*` and I believe the implementation is pretty simple. And since all our functions `sqrt`, `log`, etc are implemented using ufunc and already support complex numbers it is just a matter of converting any negatives into complex numbers like in numpy with no other changes required. Is my thinking correct? Pardon my negligence if any.", "@pri1311 Hi, I agree it should be that simple.", "hey @kmaehashi , I would like to work on `numpy.ndarray.resize` ", "Hi @rajveer43, sure go ahead.", "> Hi @rajveer43, sure go ahead.\r\n\r\nI know how to add that function but..can you tell the locations i.e. path..where it is needed to be added? I am getting confused actually!\r\n", "@kmaehashi please chek `numpy.lib.stride_tricks.sliding_window_view`. It was implemented and merged in [Add `cupy.lib.stride_tricks.sliding_window_view`](https://github.com/cupy/cupy/pull/7575)", "`numpy.ndarray.itemset` was removed in numpy 2.0, So please remove it from the list.", "Looks like [`put_along_axis`](https://github.com/cupy/cupy/blob/66820586ee1c41013868a8de4977c84f29180bc8/cupy/lib/_shape_base.py#L180) was added in https://github.com/cupy/cupy/pull/8199; however, this API does not appear to be publicly documented in the API docs.", "@kgryte I suppose you are browsing v13 docs. `put_along_axis` is listed here:\nhttps://docs.cupy.dev/en/latest/reference/indexing.html#inserting-data-into-arrays", "Added following APIs to the table.\n\n- `numpy.bitwise_count`\n- `numpy.cumulative_prod`\n- `numpy.cumulative_sum`\n- `numpy.matrix_transpose`\n- `numpy.unstack`\n- `numpy.vecdot`\n- `numpy.linalg.diagonal`\n- `numpy.linalg.matmul`\n- `numpy.linalg.matrix_norm`\n- `numpy.linalg.matrix_transpose`\n- `numpy.linalg.outer`\n- `numpy.linalg.svdvals`\n- `numpy.linalg.tensordot`\n- `numpy.linalg.trace`\n- `numpy.linalg.vecdot`\n- `numpy.linalg.vector_norm`\n", "Hello @kmaehashi \n\nI want to work on implementing numpy.cumulative_sum. Is there a way to get assigned, or should I raise the PR directly ?\n\nThanks !\n", "Hi @vprabhakar12, feel free to open a PR directly.", "Hi! I'd like to work on cupy.bitwise_count as my first contribution. Let me know if it's okay to proceed. Thanks!" ],
      "repository" : {
        "description" : "NumPy & SciPy for GPU",
        "homepage" : "https://cupy.dev",
        "name" : "cupy",
        "fullName" : "cupy/cupy",
        "htmlUrl" : "https://github.com/cupy/cupy",
        "gitUrl" : "git://github.com/cupy/cupy.git",
        "sshUrl" : "git@github.com:cupy/cupy.git",
        "cloneUrl" : "https://github.com/cupy/cupy.git",
        "owner" : {
          "login" : "cupy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 934,
        "stargazersCount" : 10355,
        "watchersCount" : 10355,
        "size" : 45317,
        "openIssuesCount" : 606,
        "subscribersCount" : 129,
        "pushedAt" : "2025-07-24T06:53:48Z",
        "languages" : {
          "PowerShell" : 11176,
          "Dockerfile" : 58990,
          "C++" : 1460973,
          "Shell" : 33553,
          "C" : 1635191,
          "Batchfile" : 38,
          "Cython" : 2095077,
          "Python" : 7362898,
          "Cuda" : 132477
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement GPU versions of various NumPy APIs in CuPy, including functions from `numpy.*` namespace, by categorizing them by difficulty and assigning them to contributors.",
      "validationOrRequirement" : "Contributors should have a GPU environment to develop CuPy. They should also understand the NumPy API Reference to implement the correct functionality. Some APIs may require design discussions or have ongoing discussions in NumPy.",
      "attemptedFixes" : "Some APIs have already been implemented, and others are being worked on. For example, `numpy.lib.stride_tricks.sliding_window_view` was merged in a previous pull request, and `numpy.put_along_axis` was added in a recent pull request. Other APIs, such as `numpy.ediff1d` and `numpy.intersect1d`, are also being worked on.",
      "otherNotes" : "This issue is a tracker for implementing GPU versions of various NumPy APIs in CuPy. It lists remaining APIs categorized by difficulty, with some already implemented. Contributors are welcome to pick a function to work on and submit a pull request.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407353
  }, {
    "issueDTO" : {
      "id" : 3045560220,
      "title" : "[Feature][SQL function]  Enhance SQL Transform `substring`/`substr` functions to support date type fields",
      "url" : "https://github.com/apache/seatunnel/issues/9286",
      "repositoryName" : "apache/seatunnel",
      "description" : "### Search before asking\n\n- [x] I had searched in the [feature](https://github.com/apache/seatunnel/issues?q=is%3Aissue+label%3A%22Feature%22) and found no similar feature requirement.\n\n\n### Description\n\nCurrently, in SeaTunnel's SQL Transform, the `substring` and `substr` functions can only operate on string type fields. However, when trying to extract portions of a date or timestamp field (e.g., only getting the year part from a date), users have to explicitly convert the date field to string first, which is not intuitive and introduces extra complexity.\n\n## Current Behavior\n\nWhen trying to use `substring` function directly on a date field:\n\n```sql\nSELECT substring(update_time, 1, 10) FROM my_table\n```\n\nThis fails because the `substring` function doesn't accept date/timestamp input types.\n\n## Expected Behavior\n\nThe `substring` and `substr` functions should be able to automatically handle date/timestamp types by converting them to a standard string representation before performing the substring operation. For example:\n\n```sql\n-- Should return '2023-01-15' (just the date part)\nSELECT substring(timestamp_column, 1, 10) FROM my_table \n\n-- Should return '2023' (just the year)\nSELECT substring(date_column, 1, 4) FROM my_table\n```\njust like the Database, eg.\n![Image](https://github.com/user-attachments/assets/fb059051-bc8e-4661-ba0f-90a6be8df187)\n\n## Proposed Solution\n\nEnhance the `StringFunction.substring()` method in the SQL Transform implementation to:\n\n1. Check if the input is a date type (Date, Timestamp, LocalDate, LocalDateTime, etc.)\n2. If it is, convert it to a string using a standardized formatter (e.g., `yyyy-MM-dd HH:mm:ss` for timestamps)\n3. Then perform the substring operation as usual\n\n\n## Benefits\n\n1. Improved user experience by allowing direct manipulation of date fields\n2. Alignment with common SQL behavior in popular databases\n\n\n## Affected Component\n\nSQL Transform module in SeaTunnel transforms-v2.\n\n### Usage Scenario\n\n_No response_\n\n### Related issues\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [x] I agree to follow this project's [Code of Conduct](https://www.apache.org/foundation/policies/conduct)\n",
      "updatedAt" : 1753371222.000000000,
      "user" : "davidzollo",
      "userHtmlUrl" : "https://github.com/davidzollo",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15833811?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I would like to contribute to this issue. Can anyone please assign this ticket to me?", "> I would like to contribute to this issue. Can anyone please assign this ticket to me?\n\nI have assigned this feature to you, I'm looking forward to your PR ^_^ ", "@davidzollo I have raised a PR. Can you please help reviewing this?", "> [@davidzollo](https://github.com/davidzollo) I have raised a PR. Can you please help reviewing this?\n\nSorry for review late. I just leave a message for this PR.", "@davidzollo I have commented on the PR. Can you please check and let me know if anything else is required on it?", "This issue has been automatically marked as stale because it has not had recent activity for 30 days. It will be closed in next 7 days if no further activity occurs." ],
      "repository" : {
        "description" : "SeaTunnel is a next-generation super high-performance, distributed, massive data integration tool.",
        "homepage" : "https://seatunnel.apache.org/",
        "name" : "seatunnel",
        "fullName" : "apache/seatunnel",
        "htmlUrl" : "https://github.com/apache/seatunnel",
        "gitUrl" : "git://github.com/apache/seatunnel.git",
        "sshUrl" : "git@github.com:apache/seatunnel.git",
        "cloneUrl" : "https://github.com/apache/seatunnel.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2025,
        "stargazersCount" : 8658,
        "watchersCount" : 8658,
        "size" : 46031,
        "openIssuesCount" : 219,
        "subscribersCount" : 174,
        "pushedAt" : "2025-07-24T11:45:36Z",
        "languages" : {
          "TypeScript" : 107575,
          "Smarty" : 2206,
          "Java" : 21440444,
          "Dockerfile" : 848,
          "Shell" : 40758,
          "Batchfile" : 24358,
          "SCSS" : 7232,
          "JavaScript" : 12629,
          "HTML" : 1128,
          "Python" : 17770
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Enhance SQL Transform's substring/substr functions to support date type fields, allowing direct manipulation of date fields and alignment with common SQL behavior in popular databases.",
      "validationOrRequirement" : "The SQL Transform module in SeaTunnel transforms-v2 should check if the input is a date type and convert it to a string using a standardized formatter before performing the substring operation.",
      "attemptedFixes" : "A PR has been raised, and the author is willing to submit another PR after review.",
      "otherNotes" : "The issue is about enhancing SQL Transform's substring/substr functions to support date type fields, allowing direct manipulation of date fields and alignment with common SQL behavior in popular databases.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407358
  }, {
    "issueDTO" : {
      "id" : 3260136078,
      "title" : "A Dune Dashboard for DAO activity on Builder",
      "url" : "https://github.com/BuilderOSS/nouns-builder/issues/654",
      "repositoryName" : "BuilderOSS/nouns-builder",
      "description" : "**Is your feature request related to a problem? Please describe.**\nThere is currently no way to see what DAOs are driving revenue, activity, and users.\n\n**Describe the solution you'd like**\nGnars suggested a Dune dashboard that tracks auction sales, proposals, treasury sizes, users, what chains DAOs are active on.\n\n**Describe alternatives you've considered**\nOne can go through the Builder app but it is tedious.\n\n**Additional context**\nCould be useful for grants as well.\n",
      "updatedAt" : 1753371093.000000000,
      "user" : "b3nedictvs",
      "userHtmlUrl" : "https://github.com/b3nedictvs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/104435781?v=4",
      "labels" : [ "feature", "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Treasure relate reference : https://www.nouns.com/stats/treasury \n\nIt also could have what kind of transactions the governor are doing \n\nWeekly and monthly auction revenue  \n\nNumber of the proposals made, value transfered through proposals. \n\nTotal ETH generated to builder Dao \n", "https://dune.com/sealaunch/builder-dao-custom-dashboard\n" ],
      "repository" : {
        "description" : "Nouns Builder",
        "homepage" : "https://nouns.build",
        "name" : "nouns-builder",
        "fullName" : "BuilderOSS/nouns-builder",
        "htmlUrl" : "https://github.com/BuilderOSS/nouns-builder",
        "gitUrl" : "git://github.com/BuilderOSS/nouns-builder.git",
        "sshUrl" : "git@github.com:BuilderOSS/nouns-builder.git",
        "cloneUrl" : "https://github.com/BuilderOSS/nouns-builder.git",
        "owner" : {
          "login" : "BuilderOSS",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 52,
        "stargazersCount" : 105,
        "watchersCount" : 105,
        "size" : 11930,
        "openIssuesCount" : 38,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-24T17:24:17Z",
        "languages" : {
          "TypeScript" : 1957170,
          "Shell" : 2167,
          "CSS" : 1547,
          "JavaScript" : 10379,
          "Mustache" : 6069
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a Dune dashboard for DAO activity on Builder to track revenue, activity, and users.",
      "validationOrRequirement" : "A Dune dashboard is suggested as a solution. The dashboard should track auction sales, proposals, treasury sizes, users, and what chains DAOs are active on.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description.",
      "otherNotes" : "The issue is related to a problem where there is no way to see what DAOs are driving revenue, activity, and users. It could be useful for grants as well.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407362
  }, {
    "issueDTO" : {
      "id" : 3164967825,
      "title" : "Add C# SDK examples",
      "url" : "https://github.com/apache/iggy/issues/1891",
      "repositoryName" : "apache/iggy",
      "description" : "Following the reorganization of our examples directory structure (with Rust examples now in `examples/rust/`), we need to create comprehensive C# examples to showcase the Iggy C# SDK capabilities.\n\n### Task\nCreate a new `examples/csharp/` directory with C# examples that demonstrate various usage patterns of the Iggy C# SDK, similar to what we have for Rust.\n\n### Requirements\n- Create examples that mirror the functionality of existing Rust examples where applicable\n- Use .NET 8.0 or later for modern C# features\n- Include a README.md with clear instructions on how to run each example\n- Use C# best practices and idiomatic code\n- Add .csproj files with all required dependencies\n- Consider adding a script to test all examples (similar to `scripts/run-rust-examples-from-readme.sh`)\n\n### Additional Context\n- C# SDK is located in `foreign/csharp/`\n- Reference the Rust examples in `examples/rust/` for feature parity\n- Examples should work with the latest version of the C# SDK\n- Consider using async/await patterns throughout",
      "updatedAt" : 1753370786.000000000,
      "user" : "hubcio",
      "userHtmlUrl" : "https://github.com/hubcio",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5490304?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @hubcio I can work on this! You can assign this to me" ],
      "repository" : {
        "description" : "Apache Iggy: Hyper-Efficient Message Streaming at Laser Speed",
        "homepage" : "https://iggy.apache.org",
        "name" : "iggy",
        "fullName" : "apache/iggy",
        "htmlUrl" : "https://github.com/apache/iggy",
        "gitUrl" : "git://github.com/apache/iggy.git",
        "sshUrl" : "git@github.com:apache/iggy.git",
        "cloneUrl" : "https://github.com/apache/iggy.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 164,
        "stargazersCount" : 2794,
        "watchersCount" : 2794,
        "size" : 53190,
        "openIssuesCount" : 88,
        "subscribersCount" : 27,
        "pushedAt" : "2025-07-24T08:17:44Z",
        "languages" : {
          "C#" : 676580,
          "Smarty" : 3918,
          "Java" : 269726,
          "C++" : 128547,
          "CSS" : 46488,
          "Rust" : 4674766,
          "C" : 4979,
          "CMake" : 44573,
          "Go" : 309180,
          "HTML" : 7143,
          "Svelte" : 183302,
          "Just" : 4005,
          "TypeScript" : 394233,
          "Dockerfile" : 15758,
          "Shell" : 65421,
          "Gherkin" : 1990,
          "JavaScript" : 8703,
          "Python" : 53120
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create comprehensive C# examples to showcase the Iggy C# SDK capabilities",
      "validationOrRequirement" : "Create examples that mirror the functionality of existing Rust examples where applicable, Use .NET 8.0 or later for modern C# features, Include a README.md with clear instructions on how to run each example, Use C# best practices and idiomatic code, Add .csproj files with all required dependencies, Consider adding a script to test all examples",
      "attemptedFixes" : "",
      "otherNotes" : "C# SDK is located in foreign/csharp/, reference Rust examples in examples/rust/ for feature parity, examples should work with latest version of C# SDK, consider using async/await patterns throughout",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407366
  }, {
    "issueDTO" : {
      "id" : 3073427065,
      "title" : "[Remove Vuetify from Studio] Copy token input in Settings - Account",
      "url" : "https://github.com/learningequality/studio/issues/5064",
      "repositoryName" : "learningequality/studio",
      "description" : "<!---HEADER START-->\n\n<img height=\"20px\" src=\"https://i.imgur.com/0ZZG9qx.jpeg\">\n\n\uD83D\uDE42 Looking for an issue? Welcome! This issue is open for contribution. If this is the first time you???re requesting an issue, please:\n\n- **Read <a href=\"https://learningequality.org/contributing-to-our-open-code-base/\" target=\"_blank\">Contributing guidelines</a>** carefully. **Pay extra attention to [Using generative AI](https://learningequality.org/contributing-to-our-open-code-base/#using-generative-ai)**. **Pull requests and comments that don???t follow the guidelines won???t be answered.**\n- **Confirm that you???ve read the guidelines** in your comment.\n\n<img height=\"20px\" src=\"https://i.imgur.com/0ZZG9qx.jpeg\">\n\n<!---HEADER END-->\n\n\nSub-issue of https://github.com/learningequality/studio/issues/5060.\n\n**Complexity: Medium**\n\n## Blocked by\n\nhttps://github.com/learningequality/kolibri-design-system/issues/1030\n\n## Summary\n\nMigrate copy token input in _Settings > Account_ from Vuetify to Kolibri Design System.\n\n<img src=\"https://github.com/user-attachments/assets/22f0ad5f-7a13-4c8b-945a-50191fb74956\" width=\"400\">\n\n`shared/views/CopyToken` that is built with `VTextField` is used for the token. To remove this dependency from `Account/index`, create a new `StudioCopyToken` component with:\n- `KTextbox` as basis\n- `KIconButton` copy button and logic\n- `KCircularLoader` for loading state\n\nThen use `StudioCopyToken` in `Account/index` instead of `CopyToken`.\n\n## How to get there\n\n- Login as `user@a.com` with password `a`\n- Go to _Settings > Account_\n\n## Guidance\n\n- Read [the project](https://github.com/learningequality/studio/issues/5060) this issue is part of\n- When implementing the copy button, pay attention to a11y. Kolibri's [search input clear button](https://github.com/learningequality/kolibri/blob/242459d5062202a3ec6af5056271f91d90beafe5/packages/kolibri-common/components/SearchBox.vue#L20-L40) is a good example.\n\n## Out of Scope\n\n- Do not refactor any other areas of the codebase\n- Do not modify `CopyToken`\n\n## Expected UI/UX changes\n\n- Minor visual differences naturally stemming from the use of KDS\n- When loading, instead of the blue linear loader on the bottom of the input, there will be a circular loader displayed in the place of the input\n\n\n## Acceptance criteria\n\n**General**\n\n- [ ] The specification above is followed.\n- [ ] Except for \"Expected UI/UX changes,\" there are no functional or visual differences in user experience.\n- [ ] All user interactions are manually tested with no regressions.\n- [ ] Pull request includes screenshots.\n\n**a11y and i18n**\n\nSee [the project](https://github.com/learningequality/studio/issues/5060)'s \"Guidance\" for useful references.\n\n- [ ] Implementation meets a11y standards\n- [ ] All components are LTR and RTL compliant\n- [ ] All user-facing strings are translated properly\n- [ ] The `notranslate` class been added to elements that shouldn't be translated by Google Chrome's automatic translation feature (e.g. user-generated text)\n- [ ] Mobile experience is reasonable\n\n**Unit tests**\n- [ ] If there is a unit test suite already, it is meaningfully updated (even if tests don't fail)\n- [ ] If there is no unit test suite, a new one is created. Do not use obsolete `@vue/test-utils` approach. Instead, use [Vue Testing Library](https://kolibri-dev.readthedocs.io/en/develop/frontend_architecture/unit_testing.html).",
      "updatedAt" : 1753370754.000000000,
      "user" : "MisRob",
      "userHtmlUrl" : "https://github.com/MisRob",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13509191?v=4",
      "labels" : [ "community-contribution-in-progress", "help wanted", "DEV: frontend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @MisRob  \uD83D\uDC4B,\n\nI???ve carefully read the [Contributing Guidelines](https://github.com/learningequality/studio/blob/develop/CONTRIBUTING.md), including the section on [using generative AI](https://learningequality.org/contributing-to-our-open-code-base/#using-generative-ai). I???d love to contribute to this issue and would like to request it be assigned to me.\n\nI'll ensure the migration follows all design, accessibility, and implementation expectations outlined above. Looking forward to your guidance!\n\nThanks! \uD83D\uDE4C", "Hi @NihalShinde4933, happy to. Thank you!", "@NihalShinde4933 One thing to note, we haven't yet released Kolibri Design System version that has this update https://github.com/learningequality/kolibri-design-system/issues/1030 in it. But I think it will be released this week and then I will make sure Studio is updated so you have `readonly` available. We'll be in touch. Meanwhile, you can resolve all other work, and temporarily work with `KTextbox` as is.", "Thank you for the heads-up, @MisRob! \uD83D\uDE0A I???ll move ahead with the implementation using `KTextbox` as it currently stands. Once the Kolibri Design System update with `readonly` is released and integrated, I???ll make the necessary adjustments. Looking forward to the update! \uD83D\uDE80", "Hi @NihalShinde4933, please keep an eye on https://github.com/learningequality/studio/pull/5108. After we merge my #5108, just merge the latest `unstable` to your working branch, run `pnpm install` and then you will have KDS version that has `readonly` on `KTextbox` available.", "@NihalShinde4933 are you still planning to work on this?", "Hello @MisRob I've noted that this issue was unassigned from the previous contributor.\nI'd be happy to take it on if it's available.", "Hi @ikalumba, thanks! Yes, I'm happy to assign you.", "Thank you @MisRob \uD83D\uDE80\uD83D\uDE80", "Hi @ikalumba, are you still planning to work on this?", "Hello @MisRob I've been actively working on this however my WSL just recently crashed but I should send a pull request within the next week. \nSorry it has taken longer than expected." ],
      "repository" : {
        "description" : "Content curation tools for Kolibri",
        "homepage" : "https://studio.learningequality.org/",
        "name" : "studio",
        "fullName" : "learningequality/studio",
        "htmlUrl" : "https://github.com/learningequality/studio",
        "gitUrl" : "git://github.com/learningequality/studio.git",
        "sshUrl" : "git@github.com:learningequality/studio.git",
        "cloneUrl" : "https://github.com/learningequality/studio.git",
        "owner" : {
          "login" : "learningequality",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 213,
        "stargazersCount" : 142,
        "watchersCount" : 142,
        "size" : 225996,
        "openIssuesCount" : 344,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-24T15:15:10Z",
        "languages" : {
          "Dockerfile" : 2211,
          "CSS" : 13352,
          "Shell" : 5274,
          "Gherkin" : 141136,
          "SCSS" : 253848,
          "Makefile" : 8225,
          "JavaScript" : 1739088,
          "Vue" : 1413426,
          "Mustache" : 3769,
          "HTML" : 261490,
          "Python" : 2367899
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Migrate copy token input in Settings > Account from Vuetify to Kolibri Design System by creating a new StudioCopyToken component and using KTextbox, KIconButton, and KCircularLoader.",
      "validationOrRequirement" : "The contributor must follow the contributing guidelines, including the section on using generative AI. The implementation must meet a11y standards, be LTR and RTL compliant, and include unit tests.",
      "attemptedFixes" : "The contributor has been working on the issue, but their WSL crashed and they expect to send a pull request within the next week.",
      "otherNotes" : "The issue is a sub-issue of #5060 and is blocked by #1030. The contributor is expected to follow the contributing guidelines, pay attention to a11y and i18n, and use Vue Testing Library for unit tests.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407372
  }, {
    "issueDTO" : {
      "id" : 2979829672,
      "title" : "[Catalog] Localize the catalog app to french",
      "url" : "https://github.com/leboncoin/spark-android/issues/1525",
      "repositoryName" : "leboncoin/spark-android",
      "description" : "Extract every literal strings displayed to the user into a string resource and then translate them into french.",
      "updatedAt" : 1753370706.000000000,
      "user" : "soulcramer",
      "userHtmlUrl" : "https://github.com/soulcramer",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11772084?v=4",
      "labels" : [ "Good first issue", "CatalogApp", "Enhancement" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "??? Simple, Modular & Accessible UI Components for your Android Applications",
        "homepage" : "https://leboncoin.github.io/spark-android/",
        "name" : "spark-android",
        "fullName" : "leboncoin/spark-android",
        "htmlUrl" : "https://github.com/leboncoin/spark-android",
        "gitUrl" : "git://github.com/leboncoin/spark-android.git",
        "sshUrl" : "git@github.com:leboncoin/spark-android.git",
        "cloneUrl" : "https://github.com/leboncoin/spark-android.git",
        "owner" : {
          "login" : "leboncoin",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 31,
        "stargazersCount" : 79,
        "watchersCount" : 79,
        "size" : 11561,
        "openIssuesCount" : 29,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-24T22:52:37Z",
        "languages" : {
          "Kotlin" : 2678419
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Localize the catalog app to French by extracting literal strings and translating them into French.",
      "validationOrRequirement" : "The requirement is to extract every literal string displayed to the user into a string resource and then translate them into French.",
      "attemptedFixes" : "No attempted fixes or blockers are mentioned in the description or comments.",
      "otherNotes" : "The issue is related to localizing the catalog app to French, which involves extracting literal strings displayed to the user and translating them into French.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407375
  }, {
    "issueDTO" : {
      "id" : 3260235148,
      "title" : "Add pre-commit hook to enforce `upload-time` field in `uv.lock`",
      "url" : "https://github.com/meta-llama/llama-stack/issues/2887",
      "repositoryName" : "meta-llama/llama-stack",
      "description" : "### \uD83D\uDE80 Describe the new functionality needed\n\nRight now we see a lot of back-and-forth with the `upload-time` field in our `uv.lock`\n\nThis was first (as far as I know) discussed and observed in https://github.com/meta-llama/llama-stack/pull/2695 and I'm seeing it again in https://github.com/meta-llama/llama-stack/pull/2881\n\nWe should enforce the presence of this field via our pre-commit so the back-and-forth ends\n\n### \uD83D\uDCA1 Why is this needed? What if we don't build it?\n\nUnnecessarily large diffs that add uncertainty to PR changes and extra burden to reviewers\n\n### Other thoughts\n\n_No response_",
      "updatedAt" : 1753370695.000000000,
      "user" : "nathan-weinberg",
      "userHtmlUrl" : "https://github.com/nathan-weinberg",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/31703736?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Composable building blocks to build Llama Apps",
        "homepage" : "https://llama-stack.readthedocs.io",
        "name" : "llama-stack",
        "fullName" : "meta-llama/llama-stack",
        "htmlUrl" : "https://github.com/meta-llama/llama-stack",
        "gitUrl" : "git://github.com/meta-llama/llama-stack.git",
        "sshUrl" : "git@github.com:meta-llama/llama-stack.git",
        "cloneUrl" : "https://github.com/meta-llama/llama-stack.git",
        "owner" : {
          "login" : "meta-llama",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1112,
        "stargazersCount" : 7924,
        "watchersCount" : 7924,
        "size" : 25683,
        "openIssuesCount" : 213,
        "subscribersCount" : 125,
        "pushedAt" : "2025-07-24T23:21:17Z",
        "languages" : {
          "TypeScript" : 233696,
          "Dockerfile" : 870,
          "Shell" : 40375,
          "CSS" : 4168,
          "JavaScript" : 474,
          "Objective-C" : 394,
          "Swift" : 15927,
          "Python" : 3509207
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "add pre-commit hook to prevent back-and-forth with upload-time field in uv.lock",
      "validationOrRequirement" : "enforce presence of upload-time field",
      "attemptedFixes" : "pre-commit hook to enforce upload-time field in uv.lock",
      "otherNotes" : "unnecessarily large diffs add uncertainty to PR changes and extra burden to reviewers",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407378
  }, {
    "issueDTO" : {
      "id" : 3249603482,
      "title" : "[Margin app] Create assets statistic endpoint",
      "url" : "https://github.com/djeck1432/spotnet/issues/927",
      "repositoryName" : "djeck1432/spotnet",
      "description" : "## Guideline\n1. Carefully read the issue description before applying to ensure you have all the necessary information to start working on it.\n2. Write a brief description of how you will approach the task (without using ChatGPT).\n3. Add your Telegram handler in your application (e.g., in OnlyDust or similar)\n4. Write ETA in your application\n\n\n\n## What should I do if I have a problem\n1. Try to google it before asking. Googling is taking major part of dev work \n2. If you couldn't find answer your question with Google, text your question to [dev](https://t.me/spotnet_dev/4) group with your question.\n3. Do not send DM to maintainer, it would be better and faster to ask other contributors in chat \n\n\n## How to prepare PR\n1. Check if your code [smell](https://refactoring.guru/refactoring/smells) good\n2. Add `close #<issue number>` to link your issue with your PR\n3. Do not commit changes that are unrelated to your task\n4. Check after you created PR, if you committed everything\n\n\n## Task Description\n1. In the [admin endpoints](./blob/main/margin/margin_app/app/api/admin.py), add an endpoint called `/assets`. Call the [`Assets statistic` method from this issue](https://github.com/djeck1432/spotnet/issues/906) to retrieve the data. Format the response using pydantic BaseModel.\n2. Add integration tests for it.\n3. Ensure that all tests(workflows) and endpoint works properly.",
      "updatedAt" : 1753370661.000000000,
      "user" : "CBoYXD",
      "userHtmlUrl" : "https://github.com/CBoYXD",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135316445?v=4",
      "labels" : [ "Backend", "onlydust-wave", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "can i request to work on this issue ?\nmy ETA is 8hours " ],
      "repository" : {
        "description" : "Spot Leveraging in the Starknet Ecosystem",
        "homepage" : "https://spotnet.xyz/",
        "name" : "spotnet",
        "fullName" : "djeck1432/spotnet",
        "htmlUrl" : "https://github.com/djeck1432/spotnet",
        "gitUrl" : "git://github.com/djeck1432/spotnet.git",
        "sshUrl" : "git@github.com:djeck1432/spotnet.git",
        "cloneUrl" : "https://github.com/djeck1432/spotnet.git",
        "owner" : {
          "login" : "djeck1432",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 224,
        "stargazersCount" : 21,
        "watchersCount" : 21,
        "size" : 32767,
        "openIssuesCount" : 14,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-14T21:52:44Z",
        "languages" : {
          "TypeScript" : 3596969,
          "Dockerfile" : 2777,
          "CSS" : 80574,
          "Shell" : 1426,
          "Cairo" : 173004,
          "Makefile" : 652,
          "JavaScript" : 224387,
          "HTML" : 2265,
          "Jupyter Notebook" : 6810,
          "Mako" : 1145,
          "Python" : 735914
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create an assets statistic endpoint in the admin endpoints of the Margin app, using the `Assets statistic` method from issue #906, and format the response using pydantic BaseModel. Ensure that all tests and the endpoint work properly.",
      "validationOrRequirement" : "Code should 'smell' good, add `close #<issue number>` to link the issue with the PR, do not commit unrelated changes, and check after creating the PR if everything was committed. Integration tests should also be added.",
      "attemptedFixes" : "None mentioned in the issue description or comments",
      "otherNotes" : "The issue has specific guidelines for contributors, including a brief description of how to approach the task, adding a Telegram handler, and writing an ETA. There are also guidelines for what to do if you have a problem, how to prepare a PR, and a description of the task itself.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407384
  }, {
    "issueDTO" : {
      "id" : 3031644638,
      "title" : "Forking at old block should be better tested",
      "url" : "https://github.com/0xSpaceShard/starknet-devnet/issues/773",
      "repositoryName" : "0xSpaceShard/starknet-devnet",
      "description" : "Here's a scenario that should be tested:\n1. Imagine an origin with `n` blocks\n2. We fork from block `m < n`\n3. The storage of a contract state is changed at `m+1 < n`\n4. We assert that calling the contract in the fork with block_id = latest (or pending) returns the same as origin at `m` (and not at `m+1`)\n\nMake sure this isn't already tested in `test_fork.rs`",
      "updatedAt" : 1753370483.000000000,
      "user" : "FabijanC",
      "userHtmlUrl" : "https://github.com/FabijanC",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/28579396?v=4",
      "labels" : [ "testing", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Mind if I try this one?", "Are you sure this isn't already tested? Also note I made a small (but important) fix to the issue description.", "test_forked_devnet_new_block_has_parent_hash_of_the_origin_block() ???", "There are testing stuff related to fork from genesis block, fork from hash of the origin. I don't see any test related to forking from a m position in the block such as m < n.\n\nCan I start working on this ? ", "It would need to be similar to `test_deploying_on_origin_calling_on_fork`, with an extra block on origin that contains a tx that modifies the contract, but with forking done before that block. Assigning you." ],
      "repository" : {
        "description" : "A local testnet for Starknet... in Rust",
        "homepage" : "https://0xspaceshard.github.io/starknet-devnet/",
        "name" : "starknet-devnet",
        "fullName" : "0xSpaceShard/starknet-devnet",
        "htmlUrl" : "https://github.com/0xSpaceShard/starknet-devnet",
        "gitUrl" : "git://github.com/0xSpaceShard/starknet-devnet.git",
        "sshUrl" : "git@github.com:0xSpaceShard/starknet-devnet.git",
        "cloneUrl" : "https://github.com/0xSpaceShard/starknet-devnet.git",
        "owner" : {
          "login" : "0xSpaceShard",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 76,
        "stargazersCount" : 126,
        "watchersCount" : 126,
        "size" : 12225,
        "openIssuesCount" : 35,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-24T15:50:58Z",
        "languages" : {
          "TypeScript" : 7751,
          "Dockerfile" : 1638,
          "Shell" : 15916,
          "CSS" : 1545,
          "Rust" : 1414418,
          "Solidity" : 17600,
          "Cairo" : 15090,
          "JavaScript" : 89,
          "Python" : 9341
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Test forking at an old block and verify that the contract state is not changed",
      "validationOrRequirement" : "Test that calling the contract in the fork with block_id = latest (or pending) returns the same as origin at `m` (and not at `m+1`).",
      "attemptedFixes" : "None mentioned in the description, but a comment suggests a similar approach to `test_deploying_on_origin_calling_on_fork` with an extra block on origin that contains a tx that modifies the contract, but with forking done before that block.",
      "otherNotes" : "Note: This issue was discussed in comments, including a small fix to the issue description. There are existing tests related to forking from genesis block and fork from hash of the origin, but not forking from a specific block (m < n).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407389
  }, {
    "issueDTO" : {
      "id" : 3235747129,
      "title" : "feature: Remove the need of specifying `kubeflex-operator.install=false`",
      "url" : "https://github.com/kubestellar/kubestellar/issues/3088",
      "repositoryName" : "kubestellar/kubestellar",
      "description" : "### Feature Description\n\nCurrently, when adding WDSes with a second chart or when isntalling the core-chart in a cluster with an existing deployment of KubeFlex, the user has to explicitly set the value `kubeflex-operator.install=false` , which may lead to errors and extra work.\n\n### Proposed Solution\n\nThis is an untested proposed solution:\n\n1. add variable definition in `_helpers..tpl` that detect the existence of kubeflex deployment using `lookup` function\n\nsomething like\n\n```yaml\n{{- define \"kflex_not_installed\" }}\n{{- if lookup <kubeflex deployment> }}\nfalse\n{{- else }}\ntrue\n{{- end }}\n{{- end }}\n```\n\n2. change the `values.yaml` file to set the default value like this\n\n```yaml\nkubeflex-operator:\n  install: {{ include \"kflex_not_installed\" .}}\n```\n\n### Want to contribute?\n\n- [ ] I would like to work on this issue.\n\n### Additional Context\n\nThis would be backwards compatible and would allow to override the default value from the CLI",
      "updatedAt" : 1753370441.000000000,
      "user" : "francostellari",
      "userHtmlUrl" : "https://github.com/francostellari",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/50019234?v=4",
      "labels" : [ "help wanted", "kind/feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @MikeSpreitzer ", "This adds a footgun like the one noted in https://github.com/kubestellar/kubestellar/pull/2935#discussion_r2210253424 , right?", "> This adds a footgun like the one noted in [#2935 (comment)](https://github.com/kubestellar/kubestellar/pull/2935#discussion_r2210253424) , right?\n\nI don't think #2935 has an issue nor should this... assuming that it works as proposed.\nWe would not burden the user to state explicitly if kflex is aready in cluster. The chart would look for it and take appropriate action.", "@Rupam-It Can I look into this issue ?", "> [@Rupam-It](https://github.com/Rupam-It) Can I look into this issue ?\n\nHii @RohanMishra315  thanks for your interest. But before start or assign I will request you come up with a good proposal for it !\nThen start the actuall implementation..", "Hello @Rupam-It  @francostellari ! I would like to express my interest in working on this improvement for the KubeStellar Helm chart. Below is my proposal for enhancing the installation experience:\n\n### Background\n\nCurrently, users must manually set `kubeflex-operator.install=false` when an existing `kubeflex` deployment is present in the cluster. This extra step can be error-prone and may lead to duplicate operator installations.\n\n### Objective\n\nAutomate the detection of any existing `kubeflex` deployment and adjust the installation behavior accordingly. This reduces manual configuration, avoids unnecessary errors, and provides a more seamless experience.\n\n### Proposed Solution\n\n- **Helm Logic Enhancement:**  \n  Implement a helper in `helpers.tpl` that uses the Helm `lookup` function to check for an existing `kubeflex` deployment in all namespaces.\n    - If present, set `kubeflex-operator.install` to `false` by default.\n    - If absent, allow it to install as usual.\n\n- **Dynamic Value Handling:**  \n  Use this auto-detection logic as the new default, while still allowing users to override the value directly.\n\n- **Documentation:**  \n  Update the README and chart documentation to clarify this behavior (auto-detection, manual override, limitations).\n\n- **Testing:**  \n  Add or update test cases to ensure:\n    - No existing deployment ??? operator is installed.\n    - Existing deployment ??? operator is not installed.\n    - User override is always respected.\n\n- **Limitations:**  \n  Document:\n    - Helm 3+ requirement.\n    - RBAC permissions necessary for the `lookup` function to work.\n    - Need for cluster reachability at install/upgrade time.\n\n### Request\n\nIf no one is currently assigned, I would be happy to take ownership of this enhancement. Please let me know if there are any specific considerations, or if you have feedback or preferences regarding the solution or implementation strategy.\n\nThank you for considering my proposal???I look forward to contributing!", "thanks @Akshitha2106 , submit an PR!", "@Akshitha2106 you can work on this issue, I'll take the other one, but if you need any help, feel free to reach out to me !", "@Akshitha2106 are you still working on this issue?" ],
      "repository" : {
        "description" : "KubeStellar - a flexible solution for multi-cluster configuration management for edge, multi-cloud, and hybrid cloud",
        "homepage" : "https://kubestellar.io",
        "name" : "kubestellar",
        "fullName" : "kubestellar/kubestellar",
        "htmlUrl" : "https://github.com/kubestellar/kubestellar",
        "gitUrl" : "git://github.com/kubestellar/kubestellar.git",
        "sshUrl" : "git@github.com:kubestellar/kubestellar.git",
        "cloneUrl" : "https://github.com/kubestellar/kubestellar.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 163,
        "stargazersCount" : 438,
        "watchersCount" : 438,
        "size" : 209303,
        "openIssuesCount" : 211,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-24T19:02:58Z",
        "languages" : {
          "Smarty" : 2184,
          "Dockerfile" : 1303,
          "Shell" : 192050,
          "Makefile" : 14208,
          "Go" : 642298,
          "Python" : 30022
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Remove the need to specify `kubeflex-operator.install=false` when adding WDSes with a second chart or when installing the core-chart in a cluster with an existing deployment of KubeFlex.",
      "validationOrRequirement" : "The requirement is to automate the detection of any existing `kubeflex` deployment and adjust the installation behavior accordingly, reducing manual configuration and avoiding unnecessary errors.",
      "attemptedFixes" : "The proposed solution includes adding a helper in `helpers.tpl` that uses the Helm `lookup` function to check for an existing `kubeflex` deployment in all namespaces, and changing the `values.yaml` file to set the default value accordingly.",
      "otherNotes" : "The issue is about removing the need to specify `kubeflex-operator.install=false` when adding WDSes with a second chart or when installing the core-chart in a cluster with an existing deployment of KubeFlex. The proposed solution involves adding a variable definition in `_helpers..tpl` to detect the existence of kubeflex deployment using `lookup` function and changing the `values.yaml` file to set the default value accordingly.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407397
  }, {
    "issueDTO" : {
      "id" : 3249103997,
      "title" : "vfmadd213sd use incorrectly gated by AVX feature flag",
      "url" : "https://github.com/shader-slang/slangpy/issues/364",
      "repositoryName" : "shader-slang/slangpy",
      "description" : "`src/sgl/core/data_struct.cpp` incorrectly uses the AVX feature flag to gate the use of `vfmadd213sd`, instead of the FMA feature flag, which results in an illegal instruction error on my (old) i7-3820.",
      "updatedAt" : 1753370386.000000000,
      "user" : "jhelferty-nv",
      "userHtmlUrl" : "https://github.com/jhelferty-nv",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29613962?v=4",
      "labels" : [ "bug", "Dev Opened", "Dev Reviewed", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Note to self: try using Claude for this." ],
      "repository" : {
        "description" : "Making it easier to work with slang in python",
        "homepage" : "https://slangpy.shader-slang.org",
        "name" : "slangpy",
        "fullName" : "shader-slang/slangpy",
        "htmlUrl" : "https://github.com/shader-slang/slangpy",
        "gitUrl" : "git://github.com/shader-slang/slangpy.git",
        "sshUrl" : "git@github.com:shader-slang/slangpy.git",
        "cloneUrl" : "https://github.com/shader-slang/slangpy.git",
        "owner" : {
          "login" : "shader-slang",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 22,
        "stargazersCount" : 59,
        "watchersCount" : 59,
        "size" : 26940,
        "openIssuesCount" : 63,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-24T17:05:14Z",
        "languages" : {
          "C++" : 2351774,
          "Shell" : 1506,
          "C" : 1395,
          "Batchfile" : 730,
          "Slang" : 129521,
          "CMake" : 110858,
          "Python" : 1162784
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix illegal instruction error on i7-3820 by correcting the use of vfmadd213sd in src/sgl/core/data_struct.cpp",
      "validationOrRequirement" : "use the FMA feature flag instead of the AVX feature flag",
      "attemptedFixes" : "",
      "otherNotes" : "Note to self: try using Claude for this.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407400
  }, {
    "issueDTO" : {
      "id" : 1774466821,
      "title" : "Conflicting ingressClassName http01 issuer spec and acme.cert-manager.io/http01-ingress-class annotation",
      "url" : "https://github.com/cert-manager/cert-manager/issues/6184",
      "repositoryName" : "cert-manager/cert-manager",
      "description" : "<!--\r\nBugs should be filed for issues encountered whilst operating cert-manager.\r\nYou should first attempt to resolve your issues through the community support\r\nchannels, e.g. Slack, in order to rule out individual configuration errors.\r\nPlease provide as much detail as possible. \r\n-->\r\n\r\n**Describe the bug**:\r\n\r\nWhen \r\n\r\n1. a (Cluster)Issuer is configured with the new `spec.acme.solvers[].http01.ingress.ingressClassName` property to set the default ingress class for challenge solver ingresses (instead of the older `...http01.ingress.class`), \r\n2. and an application ingress tries to override the default ingress class using the [documented](https://cert-manager.io/docs/usage/ingress/#supported-annotations) `acme.cert-manager.io/http01-ingress-class` annotation, \r\n\r\nthe generated Challenge resource will have both `class` and `ingressClassName` set in its spec. This causes a conflict with the status message \"the fields ingressClassName and class cannot be set at the same time\" and fail to create an Ingress resource to solve the HTTP01 challenge.\r\n\r\nStripped-down/redacted example of the Challenge resource created by cert-manager:\r\n\r\n```yaml\r\napiVersion: acme.cert-manager.io/v1\r\nkind: Challenge\r\nmetadata:\r\n  name: testingress-tls-xxxxx-000000000-1111111111\r\n  namespace: acmetest\r\nspec:\r\n  authorizationURL: https://acme-v02.api.letsencrypt.org/acme/authz-v3/00000000000\r\n  dnsName: testingress.example.com\r\n  issuerRef:\r\n    group: cert-manager.io\r\n    kind: ClusterIssuer\r\n    name: my-clusterissuer\r\n  key: >-\r\n    xxxxxxxxxxxxxxx.....\r\n  solver:\r\n    http01:\r\n      ingress:\r\n        class: nginx\r\n        ingressClassName: nginx\r\n  token: yyyyyyyyyyyyyyyy.....\r\n  type: HTTP-01\r\n  url: https://acme-v02.api.letsencrypt.org/acme/chall-v3/00000000000/xxxxxx\r\n  wildcard: false\r\nstatus:\r\n  presented: false\r\n  processing: true\r\n  reason: the fields ingressClassName and class cannot be set at the same time\r\n  state: pending\r\n```\r\n\r\nSetting the old-style `...http01.ingress.class` attribute on the Issuer's solver spec instead of `ingressClassName` avoids the issue and works as expected, but will create challenge solver ingresses with the legacy class annotation instead of the modern ingressClassName spec.\r\n\r\n**Expected behaviour**:\r\n- Either there should be a separate, new and well documented annotation for Ingresses to override the `ingressClassName` instead of the `class` attribute of a Challenge, e.g. something like `acme.cert-manager.io/http01-ingress-ingressclassname`,\r\n- or cert-manager should automatically figure out, based on the configuration of a solver, which type of configuration is set as default, and convert the class name set via Ingress annotation as necessary to replace that default, instead of adding a duplicate/conflicting attribute.\r\n\r\n**Steps to reproduce the bug**:\r\n\r\nStripped-down app ingress manifest:\r\n\r\n```yaml\r\napiVersion: networking.k8s.io/v1\r\nkind: Ingress\r\nmetadata:\r\n  annotations:\r\n    acme.cert-manager.io/http01-ingress-class: nginx\r\n    cert-manager.io/cluster-issuer: my-clusterissuer\r\n  name: testingress\r\n  namespace: acmetest\r\nspec:\r\n  ingressClassName: nginx\r\n  rules:\r\n    - host: testingress.example.com\r\n      http:\r\n        paths: [] # ...\r\n  tls:\r\n    - hosts:\r\n        - testingress.example.com\r\n      secretName: testingress-tls\r\n```\r\n\r\nStripped-down ClusterIssuer manifest:\r\n\r\n```yaml\r\napiVersion: cert-manager.io/v1\r\nkind: ClusterIssuer\r\nmetadata:\r\n  name: dico-clusterissuer\r\nspec:\r\n  acme:\r\n    # ...\r\n    solvers:\r\n      - http01:\r\n          ingress:\r\n            ingressClassName: nginx\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\nThis relates to the new `http01.ingress.ingressClassName` solver spec attribute which got introduced in the recent v1.15 cert-manager version. It's not a regression, but a bug or a missing part with the new feature.\r\n\r\n**Environment details:**:\r\n- Kubernetes version: 1.24.10\r\n- Cloud-provider/provisioner: Azure/AKS\r\n- cert-manager version: v1.12.1\r\n- Install method: official Helm chart\r\n\r\n/kind bug\r\n",
      "updatedAt" : 1753370378.000000000,
      "user" : "dico-harigkev",
      "userHtmlUrl" : "https://github.com/dico-harigkev",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/79320794?v=4",
      "labels" : [ "kind/bug", "area/acme/http01", "priority/important-longterm", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "any updates on this?", "We also have the same problem: our 1500 NS cluster and 150 projects implement a single issuer and use ingress annotations to override ingress class, thus allowing to setup only 1 issuer for several ingress controllers.\r\nWe are also missing:\r\n* either, the issuer being able to spawn the challenge ingress, using the same `ingressClassName` as the app ingress.\r\n* or an annotation such as `acme.cert-manager.io/http01-ingress-ingressclassname` to override the issuer setup and avoid to ask to projects to multiply the number of their issuers. But that would be a duplicate information (`ingressClassName` being already set in the ingress)\r\n", "We also have a similar problem:\r\nIn the previous versions of cert-manager we were using a combination of annotations in the Ingress\r\n```\r\n    acme.cert-manager.io/http01-ingress-class: \"nginx-public\"\r\n    cert-manager.io/cluster-issuer: \"letsencrypt-http\"\r\n```\r\nRecently we updated the cert-manager to the 1.12.3 version and modify the ClusterIssuer to include the `ingressClassName` instead of the `class`.\r\n\r\nWhen the cert-manager try to update a certificate with this two annotations, the cert-manager says \r\n```\r\nerr=\"the fields ingressClassName and class cannot be set at the same time\"\r\n```\r\nand generate a service in nodePort mode.\r\n\r\nWhen we go to the Ingress and delete the `acme.cert-manager.io/http01-ingress-class: \"nginx-public\"` the cert-manager doesn't update the certificate and it's trying to generate the certificate using the service with the nodePort.\r\n\r\nWhen we delete the certificate, automatically the cert-manager generates a new one with the correct properties.\r\n\r\nIt's possible solve this situation without deleting the certificate?", "We are encountering the same issue - its odd since it never happened with one of our other namespaces ingresses but just happening with our main production ingress. Any updates?", "Issues go stale after 90d of inactivity.\nMark the issue as fresh with `/remove-lifecycle stale`.\nStale issues rot after an additional 30d of inactivity and eventually close.\nIf this issue is safe to close now please do so with `/close`.\n/lifecycle stale", "/remove-lifecycle stale", "Issues go stale after 90d of inactivity.\nMark the issue as fresh with `/remove-lifecycle stale`.\nStale issues rot after an additional 30d of inactivity and eventually close.\nIf this issue is safe to close now please do so with `/close`.\n/lifecycle stale", "/remove-lifecycle stale", "Just deployed cert-manager v1.15.1 and the issue is still present!", "@maelvls can you please check this issue - regarding your documentation it should be possible to override the default ingressClass from the cluster issuer: \r\n\r\n```\r\nacme.cert-manager.io/http01-ingress-class: this annotation allows you to configure the ingress class that will be used to solve challenges for this ingress. Customizing this is useful when you are trying to secure internal services, and need to solve challenges using a different ingress class to that of the ingress. If not specified and the acme-http01-edit-in-place annotation is not set, this defaults to the ingress class defined in the Issuer resource.\r\n``` \r\n\r\nThanks", "Even if you remove the ingressClass from your cluster issuer\r\n\r\nbefore: \r\n```\r\n    solvers:\r\n    - http01:\r\n        ingress:\r\n          ingressClassName: nginx-public\r\n ``` \r\n  after: \r\n  ```\r\n      solvers:\r\n    - http01:\r\n        ingress: {}\r\n``` \r\n\r\nand just set the class on your ingress\r\n\r\n``` \r\nacme.cert-manager.io/http01-ingress-class: \"nginx-public\"\r\n``` \r\n\r\nit just sets a `kubernetes.io/ingress.class` annotation on the ingress! This should not happen! Maybe that is the problem ... that the cert-manager should overwrite the ingressClass annotation instead of adding the old kubernetes.io/ingress.class annotation!\r\n\r\nSo if you set the `acme.cert-manager.io/http01-ingress-class:`, cert-manager should SET OR OVERRIDE the `ingressClassName` on the solver ingress instead of setting the old \"kubernetes.io/ingress.class\" annotation!", "I would like to see a resolution to this as well--agree with @discostur's observation that acme.cert-manager.io/http01-ingress-class seems to be setting the \"class\" annotation, not the \"ingressClass\" annotation.", "Issues go stale after 90d of inactivity.\nMark the issue as fresh with `/remove-lifecycle stale`.\nStale issues rot after an additional 30d of inactivity and eventually close.\nIf this issue is safe to close now please do so with `/close`.\n/lifecycle stale", "/remove-lifecycle stale", "Any update on this?", "Running into the same issue.\n\nIs it possible to do a workaround with multiple HTTP01 solvers on the ClusterIssuer, like so?\n\n```yaml\n- http01:\n    ingress:\n      ingressClassName: alternative-nginx\n  selector:\n    # could also be a matchLabel\n    dnsNames:\n      - 'alternative.my-company.com'\n# no selector, as it should be the default if nothing else matches\n- http01:\n    ingress:\n      ingressClassName: nginx\n```", "Any update on this?", "Issues go stale after 90d of inactivity.\nMark the issue as fresh with `/remove-lifecycle stale`.\nStale issues rot after an additional 30d of inactivity and eventually close.\nIf this issue is safe to close now please do so with `/close`.\n/lifecycle stale", "Not stale", "/remove-lifecycle stale", "I have the same problem and everything updated just using traefik in my constellation. Are there any news to this issue?", "Seems like I overlooked the `acme.cert-manager.io/http01-ingress-class` when adding support for `ingressClassName`. I've read another person bumping into this issue in https://github.com/cert-manager/cert-manager/pull/5849#issuecomment-1854655947.\n\nAt first glance, it seems like an actual bug that needs fixing: `acme.cert-manager.io/http01-ingress-class` should set `ingressClassName` rather than setting the `class` field. Not sure about how this plays out in terms of backwards compatibility, but since  `kubernetes.io/ingress.class` has been \"soft deprecated\" in favor of `ingressClassName`, I'd be in favor of making that change.\n\nSeems like an interesting bug to fix, I'll mark this as a good issue." ],
      "repository" : {
        "description" : "Automatically provision and manage TLS certificates in Kubernetes",
        "homepage" : "https://cert-manager.io",
        "name" : "cert-manager",
        "fullName" : "cert-manager/cert-manager",
        "htmlUrl" : "https://github.com/cert-manager/cert-manager",
        "gitUrl" : "git://github.com/cert-manager/cert-manager.git",
        "sshUrl" : "git@github.com:cert-manager/cert-manager.git",
        "cloneUrl" : "https://github.com/cert-manager/cert-manager.git",
        "owner" : {
          "login" : "cert-manager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2226,
        "stargazersCount" : 12996,
        "watchersCount" : 12996,
        "size" : 93584,
        "openIssuesCount" : 204,
        "subscribersCount" : 151,
        "pushedAt" : "2025-07-24T13:36:46Z",
        "languages" : {
          "Dockerfile" : 5532,
          "Shell" : 67087,
          "Makefile" : 170401,
          "Go" : 5082272,
          "Mustache" : 9186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Conflicting ingressClassName http01 issuer spec and acme.cert-manager.io/http01-ingress-class annotation causes a conflict and fails to create an Ingress resource to solve the HTTP01 challenge.",
      "validationOrRequirement" : "Either there should be a separate, new and well-documented annotation for Ingresses to override the `ingressClassName` instead of the `class` attribute of a Challenge, or cert-manager should automatically figure out, based on the configuration of a solver, which type of configuration is set as default, and convert the class name set via Ingress annotation as necessary to replace that default, instead of adding a duplicate/conflicting attribute.",
      "attemptedFixes" : "Setting the old-style `...http01.ingress.class` attribute on the Issuer's solver spec instead of `ingressClassName` avoids the issue and works as expected, but will create challenge solver ingresses with the legacy class annotation instead of the modern ingressClassName spec.",
      "otherNotes" : "The issue relates to the new `http01.ingress.ingressClassName` solver spec attribute introduced in cert-manager v1.15. When a ClusterIssuer is configured with `spec.acme.solvers[].http01.ingress.ingressClassName`, and an application ingress tries to override the default ingress class using the `acme.cert-manager.io/http01-ingress-class` annotation, the generated Challenge resource will have both `class` and `ingressClassName` set in its spec, causing a conflict and failing to create an Ingress resource to solve the HTTP01 challenge.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407410
  }, {
    "issueDTO" : {
      "id" : 3125527306,
      "title" : "Get and plot field decay values after a simulation",
      "url" : "https://github.com/flexcompute/tidy3d/issues/2550",
      "repositoryName" : "flexcompute/tidy3d",
      "description" : "Some users want to get and plot the field decay values after running the simulation to check the convergence. Currently they can print out the log file and visually check the field decay values but there is no way, as far as I know, to get the numerical values of the field decay. \n\nI used a pattern matching script to extract the values from the log string, which seems to work well but maybe we can provide a more user friendly way to do so?\n\n<img width=\"492\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/137724ac-fa21-4c4a-9136-c8d135aa6ca1\" />\n",
      "updatedAt" : 1753370265.000000000,
      "user" : "tomflexcompute",
      "userHtmlUrl" : "https://github.com/tomflexcompute",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/116006359?v=4",
      "labels" : [ "feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "can we store the time series as a xarray.DataArray perhaps? or pandas.DataFrame (although not sure if we can serialize those?)", "The values are stored in a file `\"output/solver_progress.csv\"` which can be downloaded from S3. For historic reasons (I guess) the file is not annotated but this is what it looks like\n\n![Image](https://github.com/user-attachments/assets/f7b93e80-128d-48de-9174-2549c90b9634)\n\nThe columns are: row index, % done, field decay, time step, total number of time steps", "is there a way to just load this file to an array without direct downloading? we could write a simple wrapper for this in the SimulationData", "I guess we could use a tmp file ?", "I was this user, and Tom's code snippet was great. When doing convergence tests and validating a simulation's behavior this is super valuable -- I had a small reflection (which I didn't care about at all) essentially doubling my runtime because it kept the shutoff level above 1e-5.  Plotting it I was able to see where the \"desired\" cutoff level really was. ", "Ideally, the user should have the field decays as another TimeDataArray inside the simulation data (also accessible from its serialized representation), right?\nFrom my perspective, I see 3 alternatives to provide that:\n\n**1)**\nAn obvious quick solution would be to just have a property attribute, parsing the log as already shown by @tomflexcompute.\nBut this seems unsafe as it would rely on the logging format staying like this.\nOn the other hand, the current code relies on this logging format anyway, as the final decay value is already inferred from it.\n\n**2)**\nAlternatively, one could read the field decay values from S3 as pointed out by @momchil-flex.\nThis still seems somewhat hacky and resource-intensive to me, as it would require the following steps:\n\n- download the simulation data from the server\n- deserialize the simulation data\n- load the progress data from the server\n- add the field decay values from the progress data to the simulation data\n- serialize the simulation data\n\nEspecially the steps \"download -> deserialize -> [...] -> serialize\" would cause overhead, which would be costly for memory-intensive simulations and possibly critical for batch jobs.\n\n**3)**\nThe cleanest approach might be that the field decay data should be directly provided by the server, making the additional steps from 2) obsolete and being independent from the logging format.\nFrom the client-side it would just require another field in SimulationData.\n\n\n**Conclusion**\nI think option 3 would be the most elegant choice. If 3 would be too time-consuming and planned for the future, one could consider option 1 as intermediate solution as this logging format is assumed anyway.\nPlease correct me if I missed something. What do you guys think?", "HI @mardolph-ruco. I think your analysis is completely correct. and I agree that 3 is the best solution. Since for now you only have front end access. could you take a stab at implementing option 1 for the time being using tom's solution internally and also including whatever warnings or checks you think might be appropriate? and then I think it should be straightforward later for us to add the backend and hook that into the implementation. \n\nThanks!" ],
      "repository" : {
        "description" : "Fast electromagnetic solver (FDTD) at scale.",
        "homepage" : "https://docs.flexcompute.com/projects/tidy3d/en/latest/",
        "name" : "tidy3d",
        "fullName" : "flexcompute/tidy3d",
        "htmlUrl" : "https://github.com/flexcompute/tidy3d",
        "gitUrl" : "git://github.com/flexcompute/tidy3d.git",
        "sshUrl" : "git@github.com:flexcompute/tidy3d.git",
        "cloneUrl" : "https://github.com/flexcompute/tidy3d.git",
        "owner" : {
          "login" : "flexcompute",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 61,
        "stargazersCount" : 270,
        "watchersCount" : 270,
        "size" : 814879,
        "openIssuesCount" : 215,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-24T20:52:19Z",
        "languages" : {
          "Shell" : 450,
          "Python" : 5564320
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Get and plot field decay values after a simulation, provide a more user-friendly way to get numerical values",
      "validationOrRequirement" : "Provide a more user-friendly way to get field decay values, validate the logging format, ensure the field decay values are accessible from the simulation data",
      "attemptedFixes" : "Option 1: parse log as shown by @tomflexcompute, Option 2: read field decay values from S3, Option 3: provide field decay data directly from server",
      "otherNotes" : "Users want to get and plot field decay values after running simulation, currently no way to get numerical values. Pattern matching script to extract values from log string, but a more user-friendly way is needed. Field decay values stored in 'output/solver_progress.csv' file, which can be downloaded from S3. Alternative solutions: 1) parse log, 2) read from S3, 3) provide field decay data directly from server. Option 3 is considered the most elegant choice.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407417
  }, {
    "issueDTO" : {
      "id" : 3259550488,
      "title" : "[MCP] APITemplate.io",
      "url" : "https://github.com/activepieces/activepieces/issues/8507",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview\n\nAPITemplate.io is a dynamic document automation platform that generates PDFs and images (e.g., banners, infographics, QR codes) from templates and JSON data.  \nThis integration empowers AI agents and workflows to create and manage templated media assets automatically.\n\n---\n\n## ?????? Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n**Contributors based in India: please check your eligibility for receiving payments through your Stripe account before submitting, as this may affect your ability to get paid.**\n\n---\n\n## \uD83D\uDEE0??? Write Actions\n\n| **Action Item**                 | **Use Case** |\n|----------------------------------|--------------|\n| **Create Image**                | Generate an image from a template using JSON overrides (supports dynamic elements such as QR codes). |\n| **Create PDF**                  | Generate a PDF using a template and JSON input. |\n| **Create PDF From HTML**        | Generate a PDF from raw HTML (e.g., invoices built via custom HTML). |\n| **Create PDF From URL**         | Generate a PDF from an external URL (e.g., archiving web content). |\n| **Create PDF (Advanced)**       | Generate a PDF with custom filename, CMYK/color settings, resolution, and template options. |\n| **Delete Object**               | Delete a generated image or PDF (cleanup old outputs). |\n| **Get Account Information**     | Retrieve account details such as usage limits and template quotas. |\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Action Item**        | **Use Case** |\n|------------------------|--------------|\n| **List Objects**       | List previously generated images or PDFs. |\n\n---\n\n## \uD83D\uDCDA API Reference\n\n- [API Documentation](https://apitemplate.io/apiv2/)\n\n---\n\n## \uD83E\uDDEA Test Account Access\n\n- You can test APITemplate.io APIs by signing up at [APITemplate.io](https://apitemplate.io/) and retrieving your API key from the dashboard.  \n\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
      "updatedAt" : 1753370220.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "\uD83D\uDC8E Bounty", "good first issue", "$50" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-853/mcp-apitemplateio\">AP-853 [MCP] APITemplate.io</a></p>", "/bounty $50", "## \uD83D\uDC8E $50 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8507` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8507` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @vishalpatil1899 | Jul 24, 2025, 01:01:59 PM | WIP |  |\n| \uD83D\uDFE2 @MAVRICK-1 | Jul 24, 2025, 03:17:00 PM | #8511 | [Reward](https://algora.io/claims/ksc7zpHu2kU3NQwQ) |", "/attempt #8507\n", "/attempt #8507" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2245,
        "stargazersCount" : 15953,
        "watchersCount" : 15953,
        "size" : 303244,
        "openIssuesCount" : 395,
        "subscribersCount" : 99,
        "pushedAt" : "2025-07-24T23:50:49Z",
        "languages" : {
          "TypeScript" : 14822092,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 72085,
          "Shell" : 3862,
          "JavaScript" : 14477,
          "HTML" : 212991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "APITemplate.io is a dynamic document automation platform that generates PDFs and images (e.g., banners, infographics, QR codes) from templates and JSON data. This integration empowers AI agents and workflows to create and manage templated media assets automatically.",
      "validationOrRequirement" : "This feature must be submitted as a Piece following the Activepieces architecture, and contributors based in India must check their eligibility for receiving payments through their Stripe account before submitting.",
      "attemptedFixes" : "\uD83D\uDFE2 @vishalpatil1899: WIP, \uD83D\uDFE2 @MAVRICK-1: #8511, [Reward](https://algora.io/claims/ksc7zpHu2kU3NQwQ), /attempt #8507, /attempt #8507",
      "otherNotes" : "This integration empowers AI agents and workflows to create and manage templated media assets automatically. Contributors based in India: please check your eligibility for receiving payments through your Stripe account before submitting, as this may affect your ability to get paid. To ensure consistency and maintainability, this feature must be submitted as a Piece following the Activepieces architecture.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407425
  }, {
    "issueDTO" : {
      "id" : 2120228795,
      "title" : "TODO: SQL 2016",
      "url" : "https://github.com/KipData/KiteSQL/issues/130",
      "repositoryName" : "KipData/KiteSQL",
      "description" : "## Feature Request\n\nIf you want to contribute code to KiteSQL and find requirements, you can refer to the following list\n\nThe corresponding test files are attached under the requirements description. The specific location is in the test directory.\ne.g. `E011_02` => `tests/slt/sql_2016/E011_02.slt`\n\nTips: When you complete the requirement and submit the PR, please do not forget to delete the comment corresponding to the Case.\n\n- [x] DataType: DOUBLE PRECISION\n  - E011_02\n  - pr: https://github.com/KipData/FnckSQL/pull/153\n- [x] DataType: REAL\n  - E011_02\n  - pr: https://github.com/KipData/KiteSQL/pull/268\n- [ ] DataType: NUMERIC\n  - E011_03\n- [x] DataType: CHAR/CHARACTER (VARING)\n  - E021_01\n  - E021_02\n  - E021_10\n  - pr: https://github.com/KipData/FnckSQL/pull/174\n- [x] Function: CHARACTER_LENGTH()/CHAR_LENGTH()\n  - E021_04\n  - https://github.com/KipData/FnckSQL/pull/235\n- [x] Function: OCTET_LENGTH()\n  - E021_05\n  - https://github.com/KipData/KiteSQL/pull/264\n- [x] Function: SUBSTRING()\n  - E021_06\n  - pr: https://github.com/KipData/FnckSQL/pull/134\n- [x] Function: LOWER()/UPPER()\n  - E021_08\n  - pr: https://github.com/KipData/FnckSQL/pull/231\n- [x] Function: TRIM()\n  - E021_09\n  - pr: https://github.com/KipData/FnckSQL/pull/211\n- [x] Function: POSITION()\n  - E021_11\n  - pr: https://github.com/KipData/FnckSQL/pull/159\n- [x] Perf: Eliminate duplicate aggregations\n  - E051_01: SELECT DISTINCT A, B FROM TABLE_E051_02_01_06 WHERE A = 1 GROUP BY A, B\n  - pr: https://github.com/KipData/FnckSQL/pull/132\n- [x] TODO: Support AS() on `Select`\n  - E051_07\n  - E051_08\n  - pr: https://github.com/KipData/FnckSQL/pull/131\n- [x] TODO: Support Aliases the result set\n  - E051_08\n  - pr: https://github.com/KipData/FnckSQL/pull/131\n- [x] TODO: Rename columns in the FROM clause\n  - E051_09\n  - pr: https://github.com/KipData/FnckSQL/pull/131\n- [x] TODO: Support `BETWEEN` on `Where`\n  - E061_02\n  - pr: https://github.com/KipData/FnckSQL/pull/133\n- [x] TODO: Support `ESCAPE` on `LIKE`\n  - E061_05\n  - pr: https://github.com/KipData/FnckSQL/pull/135\n- ??? TODO: Support subquery with `ALL/ANY/SOME` on `WHERE`\n  - E061_07\n  - E061_12\n  - sqlparser-rs does not support\n- [x] TODO: Support `EXISTS` on `WHERE`\n  - E061_08\n  - E071_06\n  - pr: https://github.com/KipData/KiteSQL/pull/269\n- [x] TODO: Support Subquery on `WHERE`\n  - E061_09\n  - pr: https://github.com/KipData/FnckSQL/pull/136\n  - dep: https://github.com/KipData/FnckSQL/issues/156\n    - pr: https://github.com/KipData/FnckSQL/pull/164\n- [x] TODO: Support Subquery on `WHERE` with `IN/Not IN`\n  - E061_11\n  - E061_13\n  - pr: https://github.com/KipData/FnckSQL/pull/147\n- [x] TODO: Support `UNION\\UNION DISTINCT`\n  - E071_01\n  - pr: https://github.com/KipData/FnckSQL/pull/139\n- [x] TODO: Support `UNION ALL`\n  - E071_02\n  - pr: https://github.com/KipData/FnckSQL/pull/139\n- [x] TODO: Support `EXCEPT DISTINCT`\n  - E071_03\n  - pr: https://github.com/KipData/KiteSQL/pull/280\n- [ ] TODO: Columns combined via table operators need not have exactly the same data type\n  - E071_05: SELECT A FROM TABLE_E071_05_01_011 UNION ALL SELECT B FROM TABLE_E071_05_01_012\n- [x] TODO: Support `SELECT INTO`\n  - E111\n  - pr: https://github.com/KipData/FnckSQL/pull/141\n- ??? TODO: Support Custom `CONSTRAINT` name\n  - E141_01\n  - KiteSQL does not plan to support constraints\n- [x] TODO: Multiple primary keys\n  - E141_03\n  - E141_08\n  - pr: https://github.com/KipData/FnckSQL/pull/239\n- [ ] DataType: NAME\n  - E141_07\n- [x] Keyword: CURRENT_DATE\n  - E141_07\n  - F051_06\n  - pr: https://github.com/KipData/FnckSQL/pull/181\n- [x] DataType: TIME\n  - E141_07\n  - pr_1: https://github.com/KipData/FnckSQL/pull/181\n  - TODO: https://github.com/KipData/FnckSQL/issues/182\n- [x] DataType: TIMESTAMPE\n  - E141_07\n  - pr: https://github.com/KipData/KiteSQL/pull/271\n- [x] Keyword: CURRENT_TIMESTAMP\n  - E141_07\n  - pr: https://github.com/KipData/KiteSQL/pull/271\n- [ ] Keyword: LOCALTIME\n  - E141_07\n  - F051_07\n- [ ] Keyword: LOCALTIMESTAMP\n  - E141_07\n  - F051_08\n- ??? TODO: Support multiple transaction levels\n  - E152_02\n- [x] TODO: Updatable queries with subqueries\n  - E153\n  - pr: https://github.com/KipData/KiteSQL/pull/263\n- [x] TODO: Support `VIEW` & `CREATE VIEW` & `DROP VIEW`\n  - F031_02\n  - F032_16\n  - pr: https://github.com/KipData/FnckSQL/pull/236\n- [x] TODO: `EXCEPT` with `VIEW`\n  - F081\n  - pr: https://github.com/KipData/FnckSQL/pull/236\n- [x] TODO: `WHERE`, `GROUP BY`, and `HAVING` clauses supported in queries with grouped views\n  - F131_01\n - pr: https://github.com/KipData/FnckSQL/pull/236\n- [x] TODO: Multiple tables supported in queries with grouped views\n  - F131_02\n  - pr: https://github.com/KipData/FnckSQL/pull/236\n- [x] TODO: Set functions supported in queries with grouped views\n  - F131_03\n  - pr: https://github.com/KipData/FnckSQL/pull/236\n- [x] TODO: Subqueries with GROUP BY and HAVING clauses and grouped views\n  -  F131_04\n  - pr: https://github.com/KipData/FnckSQL/pull/236\n- [x] TODO: Support `Using` on `Join`\n  - F041_01\n  - F041_02\n  - F041_03\n  - F041_04\n  - F041_07\n  - pr: https://github.com/KipData/FnckSQL/pull/146\n- [x] TypeString: TIME\n  - F051_02\n  - F051_04\n  - F051_05\n  - pr: https://github.com/KipData/KiteSQL/pull/181\n- [x] TypeString: TIMESTAMPE\n  - F051_03\n  - F051_04\n  - F051_05\n  - pr: https://github.com/KipData/KiteSQL/pull/271\n- [x] TODO: Explicit defaults\n  - F221\n  - pr: https://github.com/KipData/FnckSQL/pull/146\n- [x] TODO: Support `CASE`\n  - F261_01\n  - pr: https://github.com/KipData/FnckSQL/pull/143\n- [x] TODO: Searched CASE\n  - F261_02\n  - pr: https://github.com/KipData/FnckSQL/pull/143\n- [x] Keyword: NULLIF\n  - F261_03\n  - pr: https://github.com/KipData/FnckSQL/pull/143\n- [x] Function: COALESCE\n  - F261_04\n  - pr: https://github.com/KipData/FnckSQL/pull/143\n- [x] TODO: Support Subquery on Select\n  - F471\n  - pr: https://github.com/KipData/FnckSQL/pull/144\n",
      "updatedAt" : 1753370200.000000000,
      "user" : "KKould",
      "userHtmlUrl" : "https://github.com/KKould",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/91525956?v=4",
      "labels" : [ "roadmap", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "SQL as a Function for Rust",
        "homepage" : "",
        "name" : "KiteSQL",
        "fullName" : "KipData/KiteSQL",
        "htmlUrl" : "https://github.com/KipData/KiteSQL",
        "gitUrl" : "git://github.com/KipData/KiteSQL.git",
        "sshUrl" : "git@github.com:KipData/KiteSQL.git",
        "cloneUrl" : "https://github.com/KipData/KiteSQL.git",
        "owner" : {
          "login" : "KipData",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 52,
        "stargazersCount" : 629,
        "watchersCount" : 629,
        "size" : 3309,
        "openIssuesCount" : 22,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-24T16:29:20Z",
        "languages" : {
          "Dockerfile" : 709,
          "Rust" : 1364611
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to provide a TODO list for KiteSQL, covering various features and requirements that need to be implemented.",
      "validationOrRequirement" : "The validation or requirements mentioned in this issue include various TODOs and PRs for different functionalities, such as data types, functions, and query support.",
      "attemptedFixes" : "There are no specific attempted fixes mentioned in this issue, as it is a TODO list.",
      "otherNotes" : "This issue is a TODO list for KiteSQL, covering various features and requirements. It includes multiple TODOs and PRs for different functionalities, such as data types, functions, and query support.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407429
  }, {
    "issueDTO" : {
      "id" : 3259693137,
      "title" : "tpu-client-next: improve logging by adding information about the peer",
      "url" : "https://github.com/anza-xyz/agave/issues/7137",
      "repositoryName" : "anza-xyz/agave",
      "description" : "#### Problem\n\nSome log message do have information about the IP of the peer but some don't which makes it hard to track the messages for a given peer. \nMaybe we can add this information where it makes sense? In tracing, there is `span` but I'm not sure if in `log` something similar exists and since we need to support both, probably having peer IP is enough.\n\n#### Proposed Solution\n",
      "updatedAt" : 1753370192.000000000,
      "user" : "KirillLykov",
      "userHtmlUrl" : "https://github.com/KirillLykov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/687962?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I will take this up." ],
      "repository" : {
        "description" : "Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.",
        "homepage" : "https://www.anza.xyz/",
        "name" : "agave",
        "fullName" : "anza-xyz/agave",
        "htmlUrl" : "https://github.com/anza-xyz/agave",
        "gitUrl" : "git://github.com/anza-xyz/agave.git",
        "sshUrl" : "git@github.com:anza-xyz/agave.git",
        "cloneUrl" : "https://github.com/anza-xyz/agave.git",
        "owner" : {
          "login" : "anza-xyz",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : true,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 614,
        "stargazersCount" : 1222,
        "watchersCount" : 1222,
        "size" : 456811,
        "openIssuesCount" : 676,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-24T23:30:12Z",
        "languages" : {
          "Dockerfile" : 5772,
          "Shell" : 455456,
          "C++" : 18125,
          "Rust" : 22450203,
          "C" : 138899,
          "Linker Script" : 452,
          "Makefile" : 10490,
          "TeX" : 835,
          "Python" : 20303
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve logging by adding information about the peer",
      "validationOrRequirement" : "need to support both tracing and log, peer IP information might be enough",
      "attemptedFixes" : "peer IP information might be added where it makes sense, possibly in tracing or log",
      "otherNotes" : "Some log messages have peer IP information, but some don't, making it hard to track messages for a given peer.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407432
  }, {
    "issueDTO" : {
      "id" : 3214177791,
      "title" : "Unconfirmed characters entered from a Japanese keyboard are difficult to see .",
      "url" : "https://github.com/mozilla-mobile/firefox-ios/issues/27843",
      "repositoryName" : "mozilla-mobile/firefox-ios",
      "description" : "## Steps to reproduce\n???In the OS Settings app, go to General > keyboards and enable \"Japanese - Romaji\".\n\nEnter a Japanese word (_Hiragana_) in the search bar (address bar).\n\n### Expected behavior\nThe characters being entered on the keyboard are easy to see. \n\n### Actual behavior\nJapanese conversion of entered characters Unconfirmed words are black characters with a gray background, making it difficult to see what is being entered from the keyboard.\n\n### Device & build information\n* Device: ? <!--- iPhone model, iOS version -->\niPad Pro 11inch (3rd) / iPadOS 18.5\n* Build version: ? <!--- Visit Settings and scroll down to find the version number -->\nFirefox 140.3 (57709)\n* First seen version: ? <!--- Is this new to this version or have you seen it before? -->\nI recall there being no problem with older versions of Firefox.\n\nAttachments: \n\n<\n\n!--- Screenshots or screen recordings are very helpful for reproducing|width=200,height=183!\n\n-->\n\n![width=200,height=183](https://github.com/user-attachments/assets/d7e9bfae-e3e0-4b74-bfe7-d814c174856c)\n\n:information_source: **Reference Person**\n\n@Foxbolts\n\n\n\n???Issue is synchronized with this [Jira Task](https://mozilla-hub.atlassian.net/browse/FXIOS-12786)\n",
      "updatedAt" : 1753370103.000000000,
      "user" : "Ryo-ryomac",
      "userHtmlUrl" : "https://github.com/Ryo-ryomac",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/85042059?v=4",
      "labels" : [ "Good first issue", "Contributor OK", "Bug \uD83D\uDC1E" ],
      "state" : "OPEN",
      "comments" : [ "This issue has also been pointed out on the Mozillazine.jp forum in Japan.\n\nhttps://forums.mozillazine.jp/viewtopic.php?f=40&t=23209", "@Ryo-ryomac @Foxbolts \nI can take up this issue. \nFrom quick research, we might need to adjust the `layerAutofillText` colors in all theme palettes. \n\nTo solve the issue, I would need the correct color values for `layerAutofillText` for all themes. \nIn current state value of `layerAutofillText `:\n1.  DarkTheme:   FXColors.LightGrey05.withAlphaComponent(0.34)\n2. LightTheme: FXColors.DarkGrey05.withAlphaComponent(0.43)\n3. PrivateTheme: FXColors.Violet60\n\nI believe we should also involve a designer as well to get the correct outcome.", "Hey @aarifsumra, thanks for offering to pick this up - I have assigned the issue to you.\n\n@cwzilla do you have any suggestions here?", "@cwzilla \nWhat color should we use for all the themes to make the text visible?", "Hi @aarifsumra, thanks for looking into this!\n\nThis one's a bit tricky. We spent a long time evaluating the color for the autofill and ultimately landed on the current values. I know it looks quite dark, but it's been reviewed and approved by accessibility. ", "@Foxbolts @Ryo-ryomac \n\nThen in this cases we should close the issue until we have more feedback from users I believe.", "How about identifying unconfirmed Japanese characters not by their background color, but by an underline drawn underneath them? Is there a patent connection?\n\nFirst, regarding Safari, Apple's web browser on iPadOS 18...\n\nIn both Dark and Light modes, the background color of the address bar is dark gray and the characters are white, so they are the same.\n\nUnconfirmed Japanese characters are distinguished from confirmed characters by putting a light underline on the unconfirmed characters.\n\n\nNext, we will look at the case of macOS 15 Sequoia.\n\nComparing Apple's web browsers Safari and Firefox.\nIn both Safari and Firefox, the background color of the address bar and the text color are different in Dark mode and Light mode.\nIn Dark mode, the background color is dark gray and the text color is white.\nIn Light mode, the background color is white and the text color is black.\n\nSafari Identifies unconfirmed characters by putting a faint underline. The color depends on the macOS's \"accent color\" setting.\n\nFirefox Identifies unconfirmed characters by putting an underline. The color does not depend on the macOS's \"accent color\" setting and is the same as the text color.\n" ],
      "repository" : {
        "description" : "Firefox for iOS",
        "homepage" : "",
        "name" : "firefox-ios",
        "fullName" : "mozilla-mobile/firefox-ios",
        "htmlUrl" : "https://github.com/mozilla-mobile/firefox-ios",
        "gitUrl" : "git://github.com/mozilla-mobile/firefox-ios.git",
        "sshUrl" : "git@github.com:mozilla-mobile/firefox-ios.git",
        "cloneUrl" : "https://github.com/mozilla-mobile/firefox-ios.git",
        "owner" : {
          "login" : "mozilla-mobile",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3059,
        "stargazersCount" : 12621,
        "watchersCount" : 12621,
        "size" : 958653,
        "openIssuesCount" : 1790,
        "subscribersCount" : 518,
        "pushedAt" : "2025-07-25T00:54:54Z",
        "languages" : {
          "Dockerfile" : 2034,
          "Shell" : 68462,
          "CSS" : 20168,
          "C" : 943,
          "JavaScript" : 885532,
          "Objective-C" : 11873,
          "Swift" : 14675698,
          "HTML" : 256765,
          "Metal" : 9050,
          "Ruby" : 5885,
          "Python" : 182795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to make unconfirmed characters entered from a Japanese keyboard easy to see.",
      "validationOrRequirement" : "The issue requires the correct color values for `layerAutofillText` for all themes. The color values are currently DarkTheme: FXColors.LightGrey05.withAlphaComponent(0.34), LightTheme: FXColors.DarkGrey05.withAlphaComponent(0.43), and PrivateTheme: FXColors.Violet60.",
      "attemptedFixes" : "The issue has been researched, and it has been suggested to adjust the `layerAutofillText` colors in all theme palettes. It has also been suggested to identify unconfirmed Japanese characters by an underline drawn underneath them.",
      "otherNotes" : "The issue is synchronized with a Jira Task (FXIOS-12786). The issue has been pointed out on the Mozillazine.jp forum in Japan. There is a discussion about involving a designer to get the correct outcome.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407439
  }, {
    "issueDTO" : {
      "id" : 3122821665,
      "title" : "Document high-level roles and functions of the nodes making up the CN",
      "url" : "https://github.com/hyperledger-labs/splice/issues/731",
      "repositoryName" : "hyperledger-labs/splice",
      "description" : "[ This issue was auto-migrated from DA's internal repo (DACH-NY/canton-network-node#14187). Original author: @meiersi-da ]\n\n## What is this about?\r\n\r\nFit this text from @waynecollier-da into the main docs:\r\n\r\n> A Validator is a Participant node that runs the Validator app. The Validator app allows a Participant node to hold and transfer Canton Coin, associate partyIDs with Canton Coin wallets for a given Auth0 userID, and burn Canton Coin to create a traffic balance.\r\n> \r\n> A Super Validator does this plus:\r\n> \r\n> - Operates a synchronizer node in the decentralized synchronizer.  A synchronizer node includes a Sequencer, a Mediator, and an ordering service. The ordering service can be either CometBFT or a postgresql database. Right now the postgresql database isn't supported in production in 3.x (expected in 3.2) and doesn't work in decentralized mode either (that's where you use CometBFT).\r\n> - Operates the Super Validator app, which records work performed by various nodes, and returns to those nodes the records they need in order to mint Canton Coin in return for that work, plus other network governance activities.\r\n> - Operates the Scan database and API\r\n> - Operates the Canton Name Service app.\r\n\r\nThis was prompted by @filmackay asking:\r\n\r\n> I don't quite understand the difference between a super-validator and a validator, other than the fact there is a different sequencer being used (comet-bft v reference).\r\n\r\n*Remove this line once you have selected the correct milestone.*\r\n\r\n## How important is this and why?\r\n\r\nEasier access and learning experience for newcomers, as pointed out by @iggy-da\r\n\r\n",
      "updatedAt" : 1753370049.000000000,
      "user" : "canton-network-da",
      "userHtmlUrl" : "https://github.com/canton-network-da",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/176066934?v=4",
      "labels" : [ "documentation", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "[ from @martinflorian-da ]: Related comment on the public docs: https://github.com/global-synchronizer-foundation/docs/discussions/20#discussioncomment-12568745\n\nWe might also want to respond to that thread and/or close it once this is done.", "I've asked @ethancohen-da to update [deployment.rst](https://github.com/hyperledger-labs/splice/blob/main/docs/src/deployment.rst) using the [doc suggested in the comments](https://github.com/global-synchronizer-foundation/docs/discussions/20#discussioncomment-12568745).\n\n[Draft PR #1040](https://github.com/hyperledger-labs/splice/pull/1040)", "> [Draft PR #1040](https://github.com/hyperledger-labs/splice/pull/1040)\n\nClosed due to staleness but can probably salvage big chunks of that for closing this!", "@martinflorian-da , @waynecollier-da\nIt's proven too difficult for @ethancohen-da to deal with the nix / direnv / sphynx, I'll give it a try." ],
      "repository" : {
        "description" : "Reference applications for funding, operating, and incentivizing the use of a decentralized, public Canton synchronizer. Includes the Amulet reference application for creating native payment utilities for Canton synchronizers and Daml applications.",
        "homepage" : "",
        "name" : "splice",
        "fullName" : "hyperledger-labs/splice",
        "htmlUrl" : "https://github.com/hyperledger-labs/splice",
        "gitUrl" : "git://github.com/hyperledger-labs/splice.git",
        "sshUrl" : "git@github.com:hyperledger-labs/splice.git",
        "cloneUrl" : "https://github.com/hyperledger-labs/splice.git",
        "owner" : {
          "login" : "hyperledger-labs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 33,
        "watchersCount" : 33,
        "size" : 158109,
        "openIssuesCount" : 647,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-25T00:18:16Z",
        "languages" : {
          "Smarty" : 29501,
          "Java" : 553700,
          "CSS" : 1064,
          "Scala" : 31557447,
          "PLpgSQL" : 37746,
          "Makefile" : 34417,
          "HTML" : 8747,
          "Jsonnet" : 3948,
          "TypeScript" : 1818059,
          "Dockerfile" : 20740,
          "Shell" : 456913,
          "Batchfile" : 3479,
          "JavaScript" : 41424,
          "Haskell" : 1032659,
          "Nix" : 83392,
          "Python" : 410362
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Document the high-level roles and functions of the nodes making up the Canton Network (CN), including the differences and responsibilities of Validator and Super Validator nodes, to provide easier access and learning experience for newcomers.",
      "validationOrRequirement" : "Document high-level roles and functions of the nodes making up the CN, specifically Validator and Super Validator nodes, including their differences and responsibilities.",
      "attemptedFixes" : "Draft PR #1040 was created but closed due to staleness. @ethancohen-da was unable to update [deployment.rst](https://github.com/hyperledger-labs/splice/blob/main/docs/src/deployment.rst) due to difficulties with nix / direnv / sphynx.",
      "otherNotes" : "This issue was auto-migrated from DA's internal repo (DACH-NY/canton-network-node#14187).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407444
  }, {
    "issueDTO" : {
      "id" : 2494054694,
      "title" : "`transport/auth/pubkey/known_keys_file` is ignored",
      "url" : "https://github.com/eclipse-zenoh/zenoh/issues/1339",
      "repositoryName" : "eclipse-zenoh/zenoh",
      "description" : "### Describe the bug\n\nhttps://github.com/eclipse-zenoh/zenoh/blob/3579f12e8d8d12b30305a9801c8dfda6b4d8ecc2/io/zenoh-transport/src/unicast/establishment/ext/auth/pubkey.rs#L123\n\n### To reproduce\n\nN/A\n\n### System info\n\n- ref: 3579f12e8d8d12b30305a9801c8dfda6b4d8ecc2",
      "updatedAt" : 1753369891.000000000,
      "user" : "fuzzypixelz",
      "userHtmlUrl" : "https://github.com/fuzzypixelz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/22870404?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "zenoh unifies data in motion, data in-use, data at rest and computations. It carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.",
        "homepage" : "https://zenoh.io",
        "name" : "zenoh",
        "fullName" : "eclipse-zenoh/zenoh",
        "htmlUrl" : "https://github.com/eclipse-zenoh/zenoh",
        "gitUrl" : "git://github.com/eclipse-zenoh/zenoh.git",
        "sshUrl" : "git@github.com:eclipse-zenoh/zenoh.git",
        "cloneUrl" : "https://github.com/eclipse-zenoh/zenoh.git",
        "owner" : {
          "login" : "eclipse-zenoh",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 202,
        "stargazersCount" : 1973,
        "watchersCount" : 1973,
        "size" : 22585,
        "openIssuesCount" : 167,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-25T00:07:38Z",
        "languages" : {
          "Shell" : 2993,
          "Rust" : 5433503
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The `transport/auth/pubkey/known_keys_file` is ignored",
      "validationOrRequirement" : "N/A",
      "attemptedFixes" : "N/A",
      "otherNotes" : "https://github.com/eclipse-zenoh/zenoh/blob/3579f12e8d8d12b30305a9801c8dfda6b4d8ecc2/io/zenoh-transport/src/unicast/establishment/ext/auth/pubkey.rs#L123",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407448
  }, {
    "issueDTO" : {
      "id" : 2082392250,
      "title" : "Add bindings for numeric typeclasses",
      "url" : "https://github.com/agda/agda2hs/issues/262",
      "repositoryName" : "agda/agda2hs",
      "description" : "Currently we are missing support for the following classes:\r\n\r\n- [ ] Real\r\n- [ ] Integral\r\n- [ ] Fractional\r\n- [ ] Floating\r\n- [ ] RealFrac\r\n- [ ] RealFloat\r\n\r\nFor everything up to and including `Fractional` we could be able to give definitions on the Agda side (or steal them from the standard library). For the rest, we should probably just postulate them.",
      "updatedAt" : 1753369763.000000000,
      "user" : "jespercockx",
      "userHtmlUrl" : "https://github.com/jespercockx",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2910371?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I'd like to work on this. Can you assign it to me, please?\r\nShould a file be created for each of these numeric typeclasses, in lib/Haskell/Prim?", "Thank you, assigned! I think having one file per typeclass makes sense, yeah.", "Any progress on this @ndcroos ?" ],
      "repository" : {
        "description" : "Compiling Agda code to readable Haskell",
        "homepage" : "https://agda.github.io/agda2hs",
        "name" : "agda2hs",
        "fullName" : "agda/agda2hs",
        "htmlUrl" : "https://github.com/agda/agda2hs",
        "gitUrl" : "git://github.com/agda/agda2hs.git",
        "sshUrl" : "git@github.com:agda/agda2hs.git",
        "cloneUrl" : "https://github.com/agda/agda2hs.git",
        "owner" : {
          "login" : "agda",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 42,
        "stargazersCount" : 190,
        "watchersCount" : 190,
        "size" : 5561,
        "openIssuesCount" : 71,
        "subscribersCount" : 22,
        "pushedAt" : "2025-07-24T09:57:48Z",
        "languages" : {
          "CSS" : 2104,
          "Shell" : 1611,
          "Makefile" : 2597,
          "Haskell" : 198846,
          "Agda" : 349016,
          "Nix" : 6500
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add bindings for numeric typeclasses",
      "validationOrRequirement" : "Create bindings for the following numeric typeclasses: Real, Integral, Fractional, Floating, RealFrac, RealFloat. Definitions for up to and including Fractional can be given on the Agda side, or stolen from the standard library. The rest should be postulated.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "Labels: enhancement, good first issue. Comments: [Hi, I'd like to work on this. Can you assign it to me, please? Should a file be created for each of these numeric typeclasses, in lib/Haskell/Prim? Thank you, assigned! I think having one file per typeclass makes sense, yeah. Any progress on this @ndcroos ?]",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407453
  }, {
    "issueDTO" : {
      "id" : 2119294199,
      "title" : "BE: Topics: Validate ISR/replication upon creation",
      "url" : "https://github.com/kafbat/kafka-ui/issues/103",
      "repositoryName" : "kafbat/kafka-ui",
      "description" : "It's currently possible to edit a topic so the min iSR > replication factor.",
      "updatedAt" : 1753369726.000000000,
      "user" : "Haarolean",
      "userHtmlUrl" : "https://github.com/Haarolean",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1494347?v=4",
      "labels" : [ "type/bug", "status/triage/completed", "status/confirmed", "scope/frontend", "scope/backend", "hacktoberfest", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @Haarolean , \ncan you please assign me this issue?\n\nI just want to confirm what this issue is: min.insync.replicas should not be allowed to exceed replication factor as it doesn't make any sense. So there should be validation check that prohibits this while creating and updating the topic, right ?\n\n", "> Hi [@Haarolean](https://github.com/Haarolean) , can you please assign me this issue?\n> \n> I just want to confirm what this issue is: min.insync.replicas should not be allowed to exceed replication factor as it doesn't make any sense. So there should be validation check that prohibits this while creating and updating the topic, right ?\n\nI remember there could be some other related things, so you might find some other inconsistencies, so please feel free to take a look!", "@abhishekray323 any luck?", "yeah I was going through all the configurations one by one, it took me some time. Here are the constraints I'm able to come up, will code them now. Let me know, if you have any suggestions on following constraints :\n\nInconsistencies found:\n\n1. Min.insync.replicas < replication factor\n2. \"no of out of sync replica\" is not set to zero if \"unclean.leader.election.enable\" is set to true, because enabling \"unclean.leader.election.enable\" kind of gives idea to developer that I have some out of sync replicas in case any mishappenings happen\n3.  Compression.zstd.level: it should be set only when compression.type is set to ???zstd???, but we are setting it???s value even when compression value is not set to ???zstd???\nSimilarly, compression.gzip.level, and compression.lz4.level should be set when compression.type is set to them.\n\n4.  if cleanup.policy is set to \"compact\" only then , the compaction configuration values like min.cleanable.dirty.ratio, min.compaction.lag.ms and max.compaction.lag.ms matters \n5. [delete.retention.ms] should be set only if cleanup.policy=???compact???\n\n6. [segment.ms]??? local.retention.ms ??? [retention.ms] : It helps prevent confusing configurations that might not behave as the user expects.\n7. Retention.bytes >=Local.retention.bytes >= segment.bytes >= max.message.bytes: \nthe segment size should be greater than the individual message size. Although in UI not able to change ??? max.message.bytes??? value\n\n- If retention enforcement sees that local.retention.bytes is smaller than a single segment, and there???s no room for even one, it will immediately: Mark it for deletion, OR Tier it to remote storage, if enabled. You will have zero local segments, despite having some bytes configured. Kafka can???t do partial segments.\n-retention.bytes governs the total storage (local + remote), so it must be ??? local.retention.bytes" ],
      "repository" : {
        "description" : "Open-Source Web UI for managing Apache Kafka clusters",
        "homepage" : "https://kafbat.io",
        "name" : "kafka-ui",
        "fullName" : "kafbat/kafka-ui",
        "htmlUrl" : "https://github.com/kafbat/kafka-ui",
        "gitUrl" : "git://github.com/kafbat/kafka-ui.git",
        "sshUrl" : "git@github.com:kafbat/kafka-ui.git",
        "cloneUrl" : "https://github.com/kafbat/kafka-ui.git",
        "owner" : {
          "login" : "kafbat",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 155,
        "stargazersCount" : 1281,
        "watchersCount" : 1281,
        "size" : 36756,
        "openIssuesCount" : 220,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-24T12:04:48Z",
        "languages" : {
          "TypeScript" : 1257665,
          "Java" : 1608247,
          "Dockerfile" : 1018,
          "ANTLR" : 17012,
          "Gherkin" : 5886,
          "SCSS" : 27,
          "JavaScript" : 3698,
          "HTML" : 1779
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Validate ISR/replication upon creation to ensure min.insync.replicas does not exceed replication factor",
      "validationOrRequirement" : "Validation check that prohibits min.insync.replicas from exceeding replication factor while creating and updating the topic",
      "attemptedFixes" : "Constraints I'm able to come up, will code them now",
      "otherNotes" : "Inconsistencies found: 1. Min.insync.replicas < replication factor, 2. 'no of out of sync replica' is not set to zero if 'unclean.leader.election.enable' is set to true, 3. Compression.zstd.level should be set only when compression.type is set to 'zstd', 4. cleanup.policy is set to 'compact' only then compaction configuration values matter, 5. [delete.retention.ms] should be set only if cleanup.policy='compact', 6. [segment.ms]??? local.retention.ms ??? [retention.ms], 7. Retention.bytes >=Local.retention.bytes >= segment.bytes >= max.message.bytes",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407460
  }, {
    "issueDTO" : {
      "id" : 2934058593,
      "title" : "User Message Shape Refinement",
      "url" : "https://github.com/VibesDIY/vibes.diy/issues/28",
      "repositoryName" : "VibesDIY/vibes.diy",
      "description" : "\n\n**Description:**\nModify the UI for user messages to have a square corner on the top right, with the rest of the corners remaining rounded as they are now. This is purely a styling change.\n\n",
      "updatedAt" : 1753369667.000000000,
      "user" : "jchris",
      "userHtmlUrl" : "https://github.com/jchris",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/253?v=4",
      "labels" : [ "good first issue", "Vibe Experience" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Generate shareable apps in seconds with the most forkable AI app generator, deployed as single page app",
        "homepage" : "https://vibes.diy",
        "name" : "vibes.diy",
        "fullName" : "VibesDIY/vibes.diy",
        "htmlUrl" : "https://github.com/VibesDIY/vibes.diy",
        "gitUrl" : "git://github.com/VibesDIY/vibes.diy.git",
        "sshUrl" : "git@github.com:VibesDIY/vibes.diy.git",
        "cloneUrl" : "https://github.com/VibesDIY/vibes.diy.git",
        "owner" : {
          "login" : "VibesDIY",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 19,
        "stargazersCount" : 86,
        "watchersCount" : 86,
        "size" : 14922,
        "openIssuesCount" : 42,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-25T00:20:06Z",
        "languages" : {
          "TypeScript" : 866660,
          "Shell" : 12149,
          "CSS" : 11888,
          "JavaScript" : 17826,
          "HTML" : 15675
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Modify the UI for user messages to have a square corner on the top right, with the rest of the corners remaining rounded as they are now.",
      "validationOrRequirement" : "none",
      "attemptedFixes" : "",
      "otherNotes" : "This is purely a styling change.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407462
  }, {
    "issueDTO" : {
      "id" : 3068907197,
      "title" : "Logisim 4.0.0-dev not launching in Windows 10",
      "url" : "https://github.com/logisim-evolution/logisim-evolution/issues/2235",
      "repositoryName" : "logisim-evolution/logisim-evolution",
      "description" : "Hi everyone,\n\nI tried to compile Logisim-evolution today, and it builds, but I got this error when executing the .bat launcher:\n\n```\nPS C:\\Users\\...\\Downloads\\logisim-evolution-main\\logisim-evolution-main\\build\\distributions\\logisim-evolution-4.0.0-dev\\logisim-evolution-4.0.0-dev\\bin> .\\logisim-evolution.bat \nThe input line is too long.\nThe syntax of the command is incorrect.\n```\n\nThe launcher does not work either when launched from explorer.exe.",
      "updatedAt" : 1753369557.000000000,
      "user" : "crossplatformdev",
      "userHtmlUrl" : "https://github.com/crossplatformdev",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1485695?v=4",
      "labels" : [ "bug", "pri -1", "help wanted", "windows", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Could you please be more specific about which exact versions of Windows 10 and OpenJDK distribution you have installed, which Git commit you use and which command did you use to build Logisim-evolution?", "One additional thought regarding the error message \"The input line is too long.\": On Windows, the length of path + filename is often limited with older APIs to approx. 256 characters, which then can yield strange errors in unexpected situations. Your path, from which you call, `logisim-evolution.bat` seems to be quite long, so this could be such a case. Our recommendation is to use the native installer package, we provide as Nightly builds of Logisim-evolution and check whether the issue persists.", "I found the error and I managed to fix it.\n\nThe error occurs both in Powershell and CMD.exe while running the .bat launcher: ***The input line is too long***\n\nThe offending line is this one:\n\n```\nset CLASSPATH=%APP_HOME%\\lib\\logisim-evolution-4.0.0-dev.jar;%APP_HOME%\\lib\\hamcrest-3.0.jar;%APP_HOME%\\lib\\javahelp-2.0.05.jar;%APP_HOME%\\lib\\rsyntaxtextarea-3.6.0.jar;%APP_HOME%\\lib\\nimrod-laf-1.2.jar;%APP_HOME%\\lib\\colorpicker-2.0.1.jar;%APP_HOME%\\lib\\swingx-core-1.6.8.jar;%APP_HOME%\\lib\\swing-checkbox-tree-1.0.2.jar;%APP_HOME%\\lib\\slf4j-simple-2.0.17.jar;%APP_HOME%\\lib\\slf4j-api-2.0.17.jar;%APP_HOME%\\lib\\flatlaf-3.6.jar;%APP_HOME%\\lib\\commons-cli-1.9.0.jar;%APP_HOME%\\lib\\flexmark-all-0.64.8.jar;%APP_HOME%\\lib\\commons-text-1.13.1.jar;%APP_HOME%\\lib\\swingx-autocomplete-1.6.8.jar;%APP_HOME%\\lib\\swingx-action-1.6.8.jar;%APP_HOME%\\lib\\swingx-plaf-1.6.8.jar;%APP_HOME%\\lib\\swingx-graphics-1.6.8.jar;%APP_HOME%\\lib\\swingx-painters-1.6.8.jar;%APP_HOME%\\lib\\flexmark-profile-pegdown-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-abbreviation-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-admonition-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-anchorlink-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-aside-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-enumerated-reference-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-attributes-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-autolink-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-definition-0.64.8.jar;%APP_HOME%\\lib\\flexmark-html2md-converter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-emoji-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-escaped-character-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-footnotes-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gfm-issues-0.64.8.jar;%APP_HOME%\\lib\\flexmark-jira-converter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-youtrack-converter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gfm-strikethrough-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gfm-tasklist-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gfm-users-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-macros-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gitlab-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-jekyll-front-matter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-jekyll-tag-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-media-tags-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-resizable-image-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-ins-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-xwiki-macros-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-superscript-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-tables-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-toc-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-typographic-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-wikilink-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-yaml-front-matter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-youtube-embedded-0.64.8.jar;%APP_HOME%\\lib\\flexmark-pdf-converter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-format-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-ast-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-builder-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-dependency-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-html-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-options-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-sequence-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-collection-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-data-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-misc-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-visitor-0.64.8.jar;%APP_HOME%\\lib\\commons-lang3-3.17.0.jar;%APP_HOME%\\lib\\swingx-common-1.6.8.jar;%APP_HOME%\\lib\\autolink-0.6.0.jar;%APP_HOME%\\lib\\jsoup-1.15.4.jar;%APP_HOME%\\lib\\icu4j-72.1.jar;%APP_HOME%\\lib\\openhtmltopdf-pdfbox-1.0.10.jar;%APP_HOME%\\lib\\openhtmltopdf-rtl-support-1.0.10.jar;%APP_HOME%\\lib\\openhtmltopdf-core-1.0.10.jar;%APP_HOME%\\lib\\annotations-24.0.1.jar;%APP_HOME%\\lib\\graphics2d-0.32.jar;%APP_HOME%\\lib\\pdfbox-2.0.24.jar;%APP_HOME%\\lib\\xmpbox-2.0.24.jar;%APP_HOME%\\lib\\fontbox-2.0.24.jar;%APP_HOME%\\lib\\commons-logging-1.2.jar\n```\n\n\nJust replace it by this:\n\n```set CLASSPATH=%APP_HOME%\\lib\\*```\n\nIIRC, environment variables in Windows cannot exceed 2000 chars. After changing that line, Logisim opens as expected.\n\n![Image](https://github.com/user-attachments/assets/20f163e4-18a1-4fa8-8261-c2d33f47410d)\n\n***Please, change the offending line for the wildcard one.***\nThank you.", "Thanks, @crossplatformdev, for investigating the root cause for your reported issue! It confirms that the issue can be worked around by building/installing Logisim-evolution in a directory with less long path. \n\nAs far as I can see, we currently don't set `CLASSPATH` explicitly in `build.gradle.kts` or anywhere else. This is handled by Gradle and jpackage. https://github.com/gradle/gradle/issues/10114, https://github.com/java9-modularity/gradle-modules-plugin/issues/281, and [this blog post](https://virgo47.wordpress.com/2018/09/14/classpath-too-long-with-spring-boot-and-gradle/) seem to be relevant. The [redocksoft/classpath-to-file-gradle-plugin](https://github.com/redocksoft/classpath-to-file-gradle-plugin) may help to work around this issue.\n\nPRs to fix this issue are welcome! Currently, I don't have the bandwidth to investigate this minor issue further, as it only appears when building Logisim-evolution in deeply nested paths.", "Also this [stack overflow question](https://stackoverflow.com/questions/201816/how-to-set-a-long-java-classpath-in-windows) is relevant.", "@maehne The issue isn???t with the program launch line???it actually fails when setting an environment variable for the classpath JARs.\n\nWhile the theoretical max length for environment variables on Windows is around 32KB, in practice you might hit a 2048-character limit instead:\nhttps://devblogs.microsoft.com/oldnewthing/20100203-00/?p=15083#:~:text=The%20theoretical%20maximum%20length%20of%20an%20environment%20variable%20is%20around%2032%2C760%20characters.\n\nThe original line is over 6000 characters long. Just use the wildcard version I suggested???it???s a simple fix.", "> @maehne The issue isn???t with the program launch line???it actually fails when setting an environment variable for the classpath JARs.\n\n@crossplatformdev: Yes, I know. Unfortunately, we don't have direct control on the content of the batch file wrapper used to start Logisim-evolution on Windows and in consequence to which value the `CLASSPATH` therein gets set. It gets automatically generated by `jpackage`. While looking into this issue, I didn't find any easy/direct way to fix that issue from within the files that we control. The above-mentioned `gradle-modules-plugin` might be a way, however, we don't currently have the time to look into this due to limited resources. PRs to fix the issue are welcome!", "Hi @maehne ,\n\nCould this be of any help?\nhttps://stackoverflow.com/questions/77033288/defining-a-custom-classpath-and-binaries-folder-for-jpackage-executables\nSo you can set `CLASSPATH` to `%APP_HOME%\\lib\\*`?\n\nThank you.", "@crossplatformdev: Thanks for the link! It may be relevant to this issue. You can try to modify the Windows-specific tasks `createMsi`, `createExe`, and `createWindowsPortableZip` in `build.gradle.kts` influence the `CLASSPATH` according to your needs to fix this issue. If you have figured out a good solution, we are open to review and test your PR." ],
      "repository" : {
        "description" : "Digital logic design tool and simulator",
        "homepage" : "",
        "name" : "logisim-evolution",
        "fullName" : "logisim-evolution/logisim-evolution",
        "htmlUrl" : "https://github.com/logisim-evolution/logisim-evolution",
        "gitUrl" : "git://github.com/logisim-evolution/logisim-evolution.git",
        "sshUrl" : "git@github.com:logisim-evolution/logisim-evolution.git",
        "cloneUrl" : "https://github.com/logisim-evolution/logisim-evolution.git",
        "owner" : {
          "login" : "logisim-evolution",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 748,
        "stargazersCount" : 5961,
        "watchersCount" : 5961,
        "size" : 114329,
        "openIssuesCount" : 209,
        "subscribersCount" : 73,
        "pushedAt" : "2025-07-23T13:51:41Z",
        "languages" : {
          "Java" : 6774523,
          "CSS" : 80260,
          "Shell" : 2350,
          "Haskell" : 13002,
          "HTML" : 5519966,
          "templ" : 9293,
          "Tcl" : 11320
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Logisim 4.0.0-dev not launching in Windows 10 due to a long CLASSPATH environment variable.",
      "validationOrRequirement" : "The CLASSPATH environment variable should not exceed the 2048-character limit in Windows.",
      "attemptedFixes" : "The issue was fixed by replacing the long CLASSPATH line with a wildcard version. The offending line was set CLASSPATH=%APP_HOME%\\lib\\logisim-evolution-4.0.0-dev.jar;%APP_HOME%\\lib\\hamcrest-3.0.jar;%APP_HOME%\\lib\\javahelp-2.0.05.jar;%APP_HOME%\\lib\\rsyntaxtextarea-3.6.0.jar;%APP_HOME%\\lib\\nimrod-laf-1.2.jar;%APP_HOME%\\lib\\colorpicker-2.0.1.jar;%APP_HOME%\\lib\\swingx-core-1.6.8.jar;%APP_HOME%\\lib\\swing-checkbox-tree-1.0.2.jar;%APP_HOME%\\lib\\slf4j-simple-2.0.17.jar;%APP_HOME%\\lib\\slf4j-api-2.0.17.jar;%APP_HOME%\\lib\\flatlaf-3.6.jar;%APP_HOME%\\lib\\commons-cli-1.9.0.jar;%APP_HOME%\\lib\\flexmark-all-0.64.8.jar;%APP_HOME%\\lib\\commons-text-1.13.1.jar;%APP_HOME%\\lib\\swingx-autocomplete-1.6.8.jar;%APP_HOME%\\lib\\swingx-action-1.6.8.jar;%APP_HOME%\\lib\\swingx-plaf-1.6.8.jar;%APP_HOME%\\lib\\swingx-graphics-1.6.8.jar;%APP_HOME%\\lib\\swingx-painters-1.6.8.jar;%APP_HOME%\\lib\\flexmark-profile-pegdown-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-abbreviation-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-admonition-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-anchorlink-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-aside-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-enumerated-reference-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-attributes-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-autolink-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-definition-0.64.8.jar;%APP_HOME%\\lib\\flexmark-html2md-converter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-emoji-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-escaped-character-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-footnotes-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gfm-issues-0.64.8.jar;%APP_HOME%\\lib\\flexmark-jira-converter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-youtrack-converter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gfm-strikethrough-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gfm-tasklist-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gfm-users-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-macros-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-gitlab-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-jekyll-front-matter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-jekyll-tag-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-media-tags-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-resizable-image-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-ins-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-xwiki-macros-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-superscript-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-tables-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-toc-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-typographic-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-wikilink-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-yaml-front-matter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-ext-youtube-embedded-0.64.8.jar;%APP_HOME%\\lib\\flexmark-pdf-converter-0.64.8.jar;%APP_HOME%\\lib\\flexmark-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-format-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-ast-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-builder-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-dependency-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-html-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-options-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-sequence-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-collection-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-data-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-misc-0.64.8.jar;%APP_HOME%\\lib\\flexmark-util-visitor-0.64.8.jar;%APP_HOME%\\lib\\commons-lang3-3.17.0.jar;%APP_HOME%\\lib\\swingx-common-1.6.8.jar;%APP_HOME%\\lib\\autolink-0.6.0.jar;%APP_HOME%\\lib\\jsoup-1.15.4.jar;%APP_HOME%\\lib\\icu4j-72.1.jar;%APP_HOME%\\lib\\openhtmltopdf-pdfbox-1.0.10.jar;%APP_HOME%\\lib\\openhtmltopdf-rtl-support-1.0.10.jar;%APP_HOME%\\lib\\openhtmltopdf-core-1.0.10.jar;%APP_HOME%\\lib\\annotations-24.0.1.jar;%APP_HOME%\\lib\\graphics2d-0.32.jar;%APP_HOME%\\lib\\pdfbox-2.0.24.jar;%APP_HOME%\\lib\\xmpbox-2.0.24.jar;%APP_HOME%\\lib\\fontbox-2.0.24.jar;%APP_HOME%\\lib\\commons-logging-1.2.jar",
      "otherNotes" : "The issue is related to the long path length in Windows, and a workaround is to use a wildcard in the CLASSPATH environment variable. The original line is over 6000 characters long, and the theoretical max length for environment variables on Windows is around 32KB, but in practice it might hit a 2048-character limit.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407514
  }, {
    "issueDTO" : {
      "id" : 2121963076,
      "title" : "Lowercase TRUE and FALSE, rename b32 to bool",
      "url" : "https://github.com/pmret/papermario/issues/1169",
      "repositoryName" : "pmret/papermario",
      "description" : "- Make every instance of TRUE/FALSE true/false respectively\n- Replace `b32` with `enum { true, false } bool` (i.e. TRUE/FALSE are not macros anymore, they are enum members)\n- Don't define bool, true, false on C23 or above where stdbool.h could be used instead\n\ne.g.\n```c\n#if __STDC_VERSION__ >= 202311L\n#include <stdbool.h>\n#else\ntypedef enum {\n    false,\n    true\n} bool;\n#endif\n\ntypedef s8 b8;\ntypedef s16 b16;\n// no more b32, TRUE, or FALSE\n ```\n",
      "updatedAt" : 1753369535.000000000,
      "user" : "bates64",
      "userHtmlUrl" : "https://github.com/bates64",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9429556?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "What's the idea here? I'm not sure porting just lowercase true/false to old gcc is worth it. If we really wanted lowercase t/f we could just make macros for them, but I don't see the motivation ", "I meant macros", "I wanna understand. Let's say I see lines like `typedef s32 b32;`. Do I just replace it with `typedef s32 enum { true, false } bool`? The rest seems pretty clear. ", "Hey, welcome to the project! This PR basically involves adding the following to macros.h\n\n```\n#if __STDC_VERSION__ < 202311L\ntypedef enum {\n  false,\n  true\n} bool;\n#endif\n```\n\nand removing https://github.com/pmret/papermario/blob/320ce6595d0fbb378b6f70fbb560b8b83776827c/include/common_structs.h#L27 and changing \"b32\" to \"bool\" in the code.\n\nthen changing all FALSE to false and TRUE to true.\n\nOne exception: please don't modify anything inside src/os or include/PR" ],
      "repository" : {
        "description" : "Decompilation of Paper Mario (2000)",
        "homepage" : "https://papermar.io",
        "name" : "papermario",
        "fullName" : "pmret/papermario",
        "htmlUrl" : "https://github.com/pmret/papermario",
        "gitUrl" : "git://github.com/pmret/papermario.git",
        "sshUrl" : "git@github.com:pmret/papermario.git",
        "cloneUrl" : "https://github.com/pmret/papermario.git",
        "owner" : {
          "login" : "pmret",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 145,
        "stargazersCount" : 1470,
        "watchersCount" : 1470,
        "size" : 158215,
        "openIssuesCount" : 35,
        "subscribersCount" : 41,
        "pushedAt" : "2025-07-06T20:54:42Z",
        "languages" : {
          "Shell" : 12219,
          "C" : 30566746,
          "Linker Script" : 141,
          "PHP" : 143,
          "Nix" : 3891,
          "Assembly" : 166350,
          "Python" : 896267
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to make every instance of TRUE/FALSE lowercase and rename b32 to bool, and to use stdbool.h if the compiler version is C23 or above.",
      "validationOrRequirement" : "The issue requires the PR to only make changes to files outside src/os and include/PR directories, and to use a conditional definition for bool in macros.h.",
      "attemptedFixes" : "The PR involves making changes to macros.h, common_structs.h, and multiple code files to replace TRUE/FALSE with true/false and rename b32 to bool.",
      "otherNotes" : "This PR involves adding a conditional definition for bool to macros.h, removing a specific line from common_structs.h, and changing all instances of TRUE/FALSE to true/false, except for src/os and include/PR directories.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407519
  }, {
    "issueDTO" : {
      "id" : 3257319965,
      "title" : "[Bug]: Resource Explorer does not use correct color in title text and should be renamed \"Object Explorer\"",
      "url" : "https://github.com/kubestellar/ui/issues/1616",
      "repositoryName" : "kubestellar/ui",
      "description" : "### Is there an existing issue for this?\n\n- [x] I have searched the existing issues and couldn't find a duplicate.\n\n### Current Behavior\n\n<img width=\"809\" height=\"672\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/c2856d75-b767-4587-9a08-7c36c475379a\" />\n\n1. title of component is wrong\n2. title text color is wrong\n\n### Expected Behavior\n\n1. change component title to \"Object Explorer\"\n2. update all completed locales to reflect this change\n3. use standard styling for title text\n\n### Steps to Reproduce\n\n1. open ui\n2. navigate to resource explorer in left menu\n3. observe\n\n### Additional Context/Logs\n\n```shell\n\n```",
      "updatedAt" : 1753369271.000000000,
      "user" : "clubanderson",
      "userHtmlUrl" : "https://github.com/clubanderson",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/407614?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@btwshivam ", "@btwshivam can i work on this ?", "@greedy-wudpeckr You can work. I had few more plans. Improve the UI. Similar colors interface with others. Also in dashboard remove that refresh button and add there object finder.", "/assign\n" ],
      "repository" : {
        "description" : "KubeStellar's User Interface",
        "homepage" : "",
        "name" : "ui",
        "fullName" : "kubestellar/ui",
        "htmlUrl" : "https://github.com/kubestellar/ui",
        "gitUrl" : "git://github.com/kubestellar/ui.git",
        "sshUrl" : "git@github.com:kubestellar/ui.git",
        "cloneUrl" : "https://github.com/kubestellar/ui.git",
        "owner" : {
          "login" : "kubestellar",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 148,
        "stargazersCount" : 56,
        "watchersCount" : 56,
        "size" : 8601,
        "openIssuesCount" : 108,
        "subscribersCount" : 10,
        "pushedAt" : "2025-07-24T21:23:12Z",
        "languages" : {
          "TypeScript" : 2560024,
          "Dockerfile" : 4363,
          "Shell" : 4960,
          "CSS" : 4768,
          "Makefile" : 7244,
          "JavaScript" : 5463,
          "Go" : 1176913,
          "HTML" : 345
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the incorrect title and color in the Resource Explorer, and to rename it to 'Object Explorer'.",
      "validationOrRequirement" : "The title of the component should be changed to 'Object Explorer', and the title text color should be updated to match standard styling. The change should also be reflected in all completed locales.",
      "attemptedFixes" : "The issue is labeled as good first issue and help wanted, indicating that it's a beginner-friendly task. @btwshivam and @greedy-wudpeckr have commented on the issue, suggesting improvements and offering to help.",
      "otherNotes" : "The issue has a screenshot attached, and there are comments from @btwshivam and @greedy-wudpeckr discussing the issue and potential improvements. The author is clubanderson and it's in the kubestellar/ui repository.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407525
  }, {
    "issueDTO" : {
      "id" : 3258623483,
      "title" : "[Term Entry] Java Queue: element()",
      "url" : "https://github.com/Codecademy/docs/issues/7366",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `element()` under queue methods in Java. The entry should be in `content/java/concepts/queue/terms/element/element.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that shows an example of the current entry.\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1753369262.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "java", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hey @codecademy-docs i would like to work on this issue, can you please assign this issue to me." ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4100,
        "stargazersCount" : 954,
        "watchersCount" : 954,
        "size" : 136910,
        "openIssuesCount" : 202,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-24T11:33:48Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new term entry for the 'element()' method in Java Queue.",
      "validationOrRequirement" : "The term entry should include a description, syntax, and example, and follow the term entry template, content standards, and markdown style guide.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is about creating a new term entry for the 'element()' method in Java Queue, with a description, syntax, and example. It requires following term entry template, content standards, and markdown style guide. The author is requesting assignment.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407529
  }, {
    "issueDTO" : {
      "id" : 3258629094,
      "title" : "[Term Entry] Java Queue: size()",
      "url" : "https://github.com/Codecademy/docs/issues/7368",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `size()` under queue methods in Java. The entry should be in `content/java/concepts/queue/terms/size/size.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that shows an example of the current entry.\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1753369220.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "java", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hey @codecademy-docs can you please assign this issue to me , i would like to work on this issue." ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4100,
        "stargazersCount" : 954,
        "watchersCount" : 954,
        "size" : 136910,
        "openIssuesCount" : 202,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-24T11:33:48Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new term entry for the Java Queue's size() method, including a description, syntax, and example.",
      "validationOrRequirement" : "Follow the term entry template, content standards, and markdown style guide; Labels: new entry, java, good first issue.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "Please refer to the term entry template, content standards, and markdown style guide when working on the PR for this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407532
  }, {
    "issueDTO" : {
      "id" : 3258626471,
      "title" : "[Term Entry]Java Queue: peek()",
      "url" : "https://github.com/Codecademy/docs/issues/7367",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `peek()` under queue methods in Java. The entry should be in `content/java/concepts/queue/terms/peek/peek.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that shows an example of the current entry.\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1753369198.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "java", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hi @codecademy-docs @mamtawardhani ,\nI want to work on this issue ? Could you please assign this issue to me ? " ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4100,
        "stargazersCount" : 954,
        "watchersCount" : 954,
        "size" : 136910,
        "openIssuesCount" : 202,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-24T11:33:48Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new term entry for the Java Queue's peek() method.",
      "validationOrRequirement" : "The entry should include a description, syntax, and example, and should follow the term entry template, content standards, and markdown style guide.",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments.",
      "otherNotes" : "The issue is about creating a new term entry for the Java Queue's peek() method, including a description, syntax, and example.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407535
  }, {
    "issueDTO" : {
      "id" : 3258633812,
      "title" : "[Term Entry] Java Queue: isEmpty()",
      "url" : "https://github.com/Codecademy/docs/issues/7369",
      "repositoryName" : "Codecademy/docs",
      "description" : "### Reason/inspiration (optional)\n\nWe would like a new entry on the term `isEmpty()` under queue methods in Java. The entry should be in `content/java/concepts/queue/terms/isEmpty/isEmpty.md`\n\nThe entry should include the following:\n\n- A description of the term\n- A ##Syntax section that includes the syntax of the method and its details\n- An ##Example section that shows an example of the current entry.\n\nPlease refer to the [term entry template](https://github.com/Codecademy/docs/blob/main/documentation/term-entry-template.md), [content standards](https://github.com/Codecademy/docs/blob/main/documentation/content-standards.md) and [markdown style guide](https://curriculum-documentation.codecademy.com/content-guidelines/markdown-style-guide/) when working on the PR for this issue.\n\n### Entry Type (select all that apply)\n\nNew Term for Existing Concept Entry\n\n### Code of Conduct\n\n- [x] By submitting this issue, I agree to follow Codecademy Doc's [Code of Conduct](https://github.com/Codecademy/docs/blob/main/.github/CODE_OF_CONDUCT.md).\n\n### For Maintainers\n\n- [x] Labels added\n- [ ] Issue is assigned",
      "updatedAt" : 1753369154.000000000,
      "user" : "codecademy-docs",
      "userHtmlUrl" : "https://github.com/codecademy-docs",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/131702907?v=4",
      "labels" : [ "new entry", "java", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hi @codecademy-docs @mamtawardhani ,\nI want to work on this issue ? Could you please assign this issue to me ? " ],
      "repository" : {
        "description" : "Codecademy Docs is a collection of information for all things code. \uD83D\uDCD5",
        "homepage" : "https://www.codecademy.com/resources/docs",
        "name" : "docs",
        "fullName" : "Codecademy/docs",
        "htmlUrl" : "https://github.com/Codecademy/docs",
        "gitUrl" : "git://github.com/Codecademy/docs.git",
        "sshUrl" : "git@github.com:Codecademy/docs.git",
        "cloneUrl" : "https://github.com/Codecademy/docs.git",
        "owner" : {
          "login" : "Codecademy",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4100,
        "stargazersCount" : 954,
        "watchersCount" : 954,
        "size" : 136910,
        "openIssuesCount" : 202,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-24T11:33:48Z",
        "languages" : {
          "TypeScript" : 4509,
          "Shell" : 72,
          "JavaScript" : 245
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a new term entry for the 'isEmpty()' method under queue methods in Java",
      "validationOrRequirement" : "The entry should include a description, syntax, and example. Refer to the term entry template, content standards, and markdown style guide when working on the PR.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is about creating a new term entry for the 'isEmpty()' method under queue methods in Java. The entry should include a description, syntax, and example. The author is looking for someone to assign the issue to them.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407539
  }, {
    "issueDTO" : {
      "id" : 3002560520,
      "title" : "lint: remove exceptions from staticcheck linter",
      "url" : "https://github.com/argoproj/argo-workflows/issues/14405",
      "repositoryName" : "argoproj/argo-workflows",
      "description" : "# Summary\n\nThere are [three exceptions](https://github.com/argoproj/argo-workflows/blob/fa51c6d382bcf751ef2bd135a85e028171620797/.golangci.yml#L45) in the staticcheck linter.\n\nTo fix these run up a devcontainer, delete one exception and then run `make lint` and fix all the problems repeating until there aren't any.\n\nIn order of fixing\n- [x] #14514 ~~ST1016 - this is just a consistency between the receiver names for methods and makes a lot of sense~~\n- [x] #14520 ~~ST1003 - capitalised variable names is a bit opinionated but I feel worth addressing~~\n- [ ] ST1005 - this is a much bigger job to change all the error messages to comply.\n\n# Use Cases\n\nJust code and style improvements\n\n---\n<!-- Issue Author: Don't delete this message to encourage other users to support your issue! -->\n**Message from the maintainers**:\n\nLove this feature request? Give it a \uD83D\uDC4D. We prioritise the proposals with the most \uD83D\uDC4D.\n\n<!--\n**Beyond this issue**:\n\nAre you a contributor? If not, have you thought about it?\n\nArgo Workflows is seeking more community involvement and ultimately more [Reviewers and Approvers](https://github.com/argoproj/argoproj/blob/main/community/membership.md) to help keep it viable.\nSee [Sustainability Effort](https://github.com/argoproj/argo-workflows/blob/main/community/sustainability_effort.md) for more information.\n-->\n",
      "updatedAt" : 1753368965.000000000,
      "user" : "Joibel",
      "userHtmlUrl" : "https://github.com/Joibel",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1827156?v=4",
      "labels" : [ "type/feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@Joibel, I'm available to work on this.", "@Joibel is this issue still pending? If so, can I work on this?", "@djanjic - are you working on this? If so, which of the items in the list up top?", "@Joibel, I'm working on the first two exceptions. Gonna create two separate PRs for them.", "\n> [@Joibel](https://github.com/Joibel), I'm working on the first two exceptions. Gonna create two separate PRs for them.\n\n2 PRs sounds great!\n\n@d-cryptic do you want to tackle item 3 (ST1005) - it's a bigger and more invasive change?\n", "sure @Joibel ", "@d-cryptic Is it in progress?", "@Jack-R-lantern not so progress from my side, you can assign this to someone else.\nSorry for the inconvenience", "I wouldn't work on this right now: wait for https://github.com/argoproj/argo-workflows/pull/14680 and a follow up from me before doing it as it will touch very similar lines" ],
      "repository" : {
        "description" : "Workflow Engine for Kubernetes",
        "homepage" : "https://argo-workflows.readthedocs.io/",
        "name" : "argo-workflows",
        "fullName" : "argoproj/argo-workflows",
        "htmlUrl" : "https://github.com/argoproj/argo-workflows",
        "gitUrl" : "git://github.com/argoproj/argo-workflows.git",
        "sshUrl" : "git@github.com:argoproj/argo-workflows.git",
        "cloneUrl" : "https://github.com/argoproj/argo-workflows.git",
        "owner" : {
          "login" : "argoproj",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3348,
        "stargazersCount" : 15860,
        "watchersCount" : 15860,
        "size" : 159221,
        "openIssuesCount" : 1247,
        "subscribersCount" : 202,
        "pushedAt" : "2025-07-24T18:30:54Z",
        "languages" : {
          "TypeScript" : 705136,
          "Dockerfile" : 5505,
          "Java" : 2559,
          "Shell" : 14744,
          "Makefile" : 46309,
          "SCSS" : 37354,
          "JavaScript" : 4313,
          "Go" : 4808474,
          "HTML" : 472,
          "Nix" : 114000,
          "Python" : 3639
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to remove exceptions from the staticcheck linter and fix all problems until there aren't any, and create separate PRs for each exception.",
      "validationOrRequirement" : "Remove exceptions from staticcheck linter, fix all problems until there aren't any, and create separate PRs for each exception.",
      "attemptedFixes" : "Two PRs created for the first two exceptions (ST1016 and ST1003), and the third exception (ST1005) is still pending.",
      "otherNotes" : "The issue is related to code and style improvements, and the author is seeking contributors. The issue is being worked on, with two PRs created for the first two exceptions. The third exception, ST1005, is still pending and requires a bigger and more invasive change. The author is waiting for another PR to be merged before tackling this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407545
  }, {
    "issueDTO" : {
      "id" : 2722942688,
      "title" : "user-specific file directory should show user name",
      "url" : "https://github.com/JabRef/jabref/issues/12269",
      "repositoryName" : "JabRef/jabref",
      "description" : "![image](https://user-images.githubusercontent.com/1366654/170995145-bd8f03d0-fae0-41f3-b8db-b2f0130aa6f1.png)\r\n\r\nIt is unclear, which JabRef key is used there.\r\n\r\n***Update**\r\n\r\n- Show tooltip of username and host when hovering on \"User-specific file directory\" and the text box next to it\r\n- Also add a tooltip to LaTeX file directory",
      "updatedAt" : 1753368925.000000000,
      "user" : "koppor",
      "userHtmlUrl" : "https://github.com/koppor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1366654?v=4",
      "labels" : [ "good first issue", "\uD83D\uDCCD Assigned" ],
      "state" : "OPEN",
      "comments" : [ "Proposal: A however on the label \"user-specific file directory\" should show the username.", "Hi @koppor , Soft Eng intern here. I'd like to take a stab at this issue if it's possible. Thanks.", "@jackmcardle99 I assigned you. Should be three lines of code.", "When reading https://github.com/JabRef/jabref/issues/9990, there should also be a proper tool tip on \"LaTeX file directory\". Maybe you can work on that too @jackmcardle99?", "Will get started on both issues this weekend @koppor ", "Hello, I'm a new contributor, and I will carefully read the contribution guidelines. Could you please assign this issue to me? @ThiloteE \r\nU6591996\r\nW-10", "As a general advice for newcomers: check out [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) for a start. Also, [guidelines for setting up a local workspace](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) is worth having a look at.\r\n\r\nFeel free to ask here at GitHub, if you have any issue related questions. If you have questions about how to setup your workspace use JabRef's [Gitter](https://gitter.im/JabRef/jabref) chat. Try to open a (draft) pull-request early on, so that people can see you are working on the issue and so that they can see the direction the pull request is heading towards. This way, you will likely receive valuable feedback.", "In JabRef, when a user is not logged in, there's a need to retrieve the username from the operating system. However, which one should be used?\r\n\r\nUsername: This is the unique identifier of the user within the system. For instance, in the Windows operating system, the username could be \"john_doe,\" while in the Linux operating system, it might be \"jane_smith.\"\r\n\r\nUser's Home Directory: This is the main folder in the file system associated with the user, usually identified by their username. For instance, in the Windows operating system, the main directory might be \"C:\\Users\\john_doe,\" whereas in the Linux operating system, it could be \"/home/jane_smith.\"\r\n\r\nWhich of these should JabRef use to identify the user when they are not logged in? @koppor @ThiloteE Thank you so much for your help.", "I do my change in Display_username branch, before my pull request, just wanna check if my change satisfy the issue's requirement:\r\nNow the username is displayed:\r\n![image](https://github.com/koppor/jabref/assets/125976713/1ee234d3-7962-4f91-ae2c-a3722c0e6370)\r\n\r\nI do several changes in the org.jabref.gui.libraryproperties.general.\r\nsrc/main/java/org/jabref/gui/libraryproperties/general/GeneralPropertiesView.java:\r\n![image](https://github.com/koppor/jabref/assets/125976713/fe741c42-6090-4eac-82e5-7c0ae77e928e)\r\norg/jabref/gui/libraryproperties/general/GeneralProperties.fxml\r\n![image](https://github.com/koppor/jabref/assets/125976713/e56d4077-0051-45b2-9992-196e1bafefce)\r\nsrc/main/java/org/jabref/gui/libraryproperties/general/GeneralPropertiesViewModel.java\r\n![image](https://github.com/koppor/jabref/assets/125976713/a300e252-4df0-4444-bfeb-0651835138d4)\r\n\r\n@koppor @ThiloteE \r\n", "> In JabRef, when a user is not logged in, there's a need to retrieve the username from the operating system. However, which one should be used?\r\n> \r\n> Username: This is the unique identifier of the user within the system. For instance, in the Windows operating system, the username could be \"john_doe,\" while in the Linux operating system, it might be \"jane_smith.\"\r\n> \r\n> User's Home Directory: This is the main folder in the file system associated with the user, usually identified by their username. For instance, in the Windows operating system, the main directory might be \"C:\\Users\\john_doe,\" whereas in the Linux operating system, it could be \"/home/jane_smith.\"\r\n> \r\n> Which of these should JabRef use to identify the user when they are not logged in? @koppor @ThiloteE Thank you so much for your help.\r\n\r\n![image](https://github.com/koppor/jabref/assets/125976713/08726058-4eb4-455c-a794-db804c239934)\r\n", "> In JabRef, when a user is not logged in, there's a need to retrieve the username from the operating system. However, which one should be used?\r\n\r\nJabRef already handles this. It uses the log in user name of the current user. As you outlined, this is different from the laptop / PC / workstation / ... one uses.\r\n\r\nThe shown graphics looks like a debug version.\r\n\r\nPlease implement as follows:\r\n\r\nImplement a hover on user-specific file directory. If the mouse is on hower, JabRef displays: `user: {username}, host: {hostname}`.\r\n\r\nPlease DO NOT modify the field content. This is the place, where the user configures their directory.", "\r\n![589e2a9a049ace9deb4f7ab3096b275](https://github.com/koppor/jabref/assets/125976713/a0974dda-ca84-451e-b31e-029fcbca4cd9)\r\n\r\nThis is the presentation of this pull request. I am still confused about the log in user, because even though I have read the documentation, I still cannot find where to log in JabRef.\r\n\r\n\r\n> > In JabRef, when a user is not logged in, there's a need to retrieve the username from the operating system. However, which one should be used?\r\n> \r\n> JabRef already handles this. It uses the log in user name of the current user. As you outlined, this is different from the laptop / PC / workstation / ... one uses.\r\n> \r\n> The shown graphics looks like a debug version.\r\n> \r\n> Please implement as follows:\r\n> \r\n> Implement a hover on user-specific file directory. If the mouse is on hower, JabRef displays: `user: {username}, host: {hostname}`.\r\n> \r\n> Please DO NOT modify the field content. This is the place, where the user configures their directory.\r\n\r\n@koppor @ThiloteE ", "You cannot log in to JabRef, since JabRef is not a multi-user distributed application, but just a desktop application for the current os user to use. But multiple users are working with JabRef, every user has probably his own home directory.\r\nIt is also not of importance, what username JabRef should use, if no user is logged in, because no user could use JabRef, when not logged in to a computer running JabRef.\r\nStill I don't get your question.\r\n\r\nPlease don't use the issue description to present screenshots of your code changes, but put this all into your Pull Request, since this clutters the issue discription with a lot of information that is about your PR and not about the original issue.", "There went sthg wrong, when i tried to resolve merge conflicts with in a PR, sorry for that.", "Hey @koppor , I am just a java enthusiast currently in my college, looking for some good issues to resolve, can you assign this issue to me?\n", "\uD83D\uDC4B Hey @8packcoder, it looks like you're interested in working on this issue! \uD83C\uDF89\n\nIf you'd like to take on this issue, please use the command `/assign-me` to assign yourself.", "/assign-me", "\uD83D\uDC4B Hey @8packcoder, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80\n\n??? Please note, you will be automatically unassigned if the issue isn't closed within **90 days** (by **30 March 2025**). A maintainer can also add the \"**\uD83D\uDCCC Pinned**\"\" label to prevent automatic unassignment.", "/assign-me", "\uD83D\uDC4B Hey @youssefgamal123, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80\n\n??? Please note, you will be automatically unassigned if the issue isn't closed within **45 days** (by **22 April 2025**). A maintainer can also add the \"**\uD83D\uDCCC Pinned**\"\" label to prevent automatic unassignment.", "Hello @koppor ,\n\nI have added the tooltip to show the username on hovering on User-specific file directory , can you please tell me what do you mean by host here in this context? , Do you mean the host of the current running machine?\n\nAlso, for the latex file directory tooltip , what should the tooltip display exactly?\n\n![Image](https://github.com/user-attachments/assets/905b8f68-fc36-4fa6-8107-10af3cbec469)", "> I have added the tooltip to show the username on hovering on User-specific file directory , can you please tell me what do you mean by host here in this context? , Do you mean the host of the current running machine?\n\nDid you check existing code?\n\nPlease look for `org.jabref.logic.FilePreferences#getUserAndHost`\n\nYou can read at `org.jabref.model.database.BibDatabaseContext#getFileDirectories` how the directory is formed.\n\nThis information should be made transparent to the user.\n\n> Also, for the latex file directory tooltip , what should the tooltip display exactly?\n\nPlease try to be a software developer, not just a programmer. Think in options! Then you will maybe see yourself what is the best way.\n\nPLEASE READ ALL THE COMMENTS IN THE ISSUE!!!!\n\nSee https://github.com/JabRef/jabref/issues/12269#issuecomment-2523109820\n\n> Implement a hover on user-specific file directory. If the mouse is on hower, JabRef displays: user: {username}, host: {hostname}.\n\n", "Hello there,\ni want to work on this issue, if this issue is still open please assign it to me. /assign-me\nThank you!!\nHappy coding.", "\uD83D\uDC4B Hey @armycodes, looks like you???re eager to work on this issue???great! \uD83C\uDF89\nIt also looks like you skipped reading our [CONTRIBUTING.md](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md), which explains exactly how to participate. No worries, it happens to the best of us.\nGive it a read, and you???ll discover the ancient wisdom of assigning issues to yourself. Trust me, it???s worth it. \uD83D\uDE80", "/assign-me\n", "\uD83D\uDC4B Hey @armycodes, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80\n\n??? Please note, you will be automatically unassigned if the issue isn't closed within **45 days** (by **26 April 2025**). A maintainer can also add the \"**\uD83D\uDCCC Pinned**\"\" label to prevent automatic unassignment.", "### \uD83D\uDCCB Assignment Update\n\nHi @armycodes, due to inactivity, you have been unassigned from this issue.\n\n<details open>\n<summary>Next steps</summary>\n\n\\\n**If you still want to work on this:**\n- Submit a pull request showing your current state. You will be automatically assigned again.\n- Ask a maintainer to assign you again.\n</details>", "/assign-me", "\uD83D\uDC4B Hey @ER812, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80", "### ??? Assignment Reminder\n\nHi @ER812, this is a friendly reminder about your assignment to this issue.\n\n> [!WARNING]\n> This issue will be **automatically unassigned** in **11 days** if there's no activity.\n\n<details open>\n<summary>How to keep your assignment</summary>\n\n\\\nIf you are working on it, you can prevent automatic unassignment by:\n\n- Submitting a draft PR with your progress\n- Asking for the **\uD83D\uDCCC Pinned** label if you need more time\n</details>\n\nWe appreciate your contribution and are here to help if needed!", "Hello, I saw this feature request was still unimplemented and decided to complete it, but I see the previous assignee hasn't been unassigned despite inactivity. Would I still be okay to submit a pull request?", "/unassign @ER812 ", "/assign @henmesh ", "\uD83D\uDC4B Hey @henmesh, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80", "/assign-me", "\uD83D\uDC4B Hey @pranav0510s, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80", "### \uD83D\uDCCB Assignment Update\n\nHi @pranav0510s, due to inactivity, you have been unassigned from this issue.\n\n<details>\n<summary>Next steps</summary>\n\n\\\n**If you still want to work on this:**\n- Submit a pull request showing your current state. You will be automatically assigned again.\n- Ask a maintainer to assign you again.\n</details>", "/assign-me", "\uD83D\uDC4B Hey @miguel-cordoba, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80" ],
      "repository" : {
        "description" : "Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases",
        "homepage" : "https://www.jabref.org",
        "name" : "jabref",
        "fullName" : "JabRef/jabref",
        "htmlUrl" : "https://github.com/JabRef/jabref",
        "gitUrl" : "git://github.com/JabRef/jabref.git",
        "sshUrl" : "git@github.com:JabRef/jabref.git",
        "cloneUrl" : "https://github.com/JabRef/jabref.git",
        "owner" : {
          "login" : "JabRef",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2881,
        "stargazersCount" : 3953,
        "watchersCount" : 3953,
        "size" : 249443,
        "openIssuesCount" : 578,
        "subscribersCount" : 112,
        "pushedAt" : "2025-07-24T20:20:03Z",
        "languages" : {
          "PowerShell" : 2037,
          "Java" : 11269860,
          "CSS" : 74176,
          "TeX" : 758587,
          "AppleScript" : 1721,
          "XSLT" : 151843,
          "Just" : 1194,
          "Shell" : 9305,
          "Batchfile" : 637,
          "ANTLR" : 9176,
          "BibTeX Style" : 78034,
          "Ruby" : 507,
          "Python" : 22282
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to show the username and host when hovering over the 'User-specific file directory' and 'LaTeX file directory' fields, and to identify the user when they are not logged in using the JabRef key.",
      "validationOrRequirement" : "The issue requires the implementation of a hover effect on the 'User-specific file directory' and 'LaTeX file directory' fields, and the use of the JabRef key to identify the user when they are not logged in.",
      "attemptedFixes" : "Several contributors have attempted to fix the issue by implementing a hover effect on the 'User-specific file directory' and 'LaTeX file directory' fields. Some have also suggested using the JabRef key to identify the user when they are not logged in.",
      "otherNotes" : "The issue is about showing the username and host when hovering over the 'User-specific file directory' and 'LaTeX file directory' fields. The author wants to know which JabRef key is used to identify the user when they are not logged in. The issue has been assigned to several contributors, including @koppor, @ThiloteE, @jackmcardle99, @8packcoder, @youssefgamal123, @armycodes, @ER812, and @henmesh. The issue has also been discussed in the comments, where contributors have shared their thoughts on how to implement the feature.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407555
  }, {
    "issueDTO" : {
      "id" : 3109096881,
      "title" : "[Remove Vuetify from Studio] Storage overview loader in Settings - Storage",
      "url" : "https://github.com/learningequality/studio/issues/5080",
      "repositoryName" : "learningequality/studio",
      "description" : "<!---HEADER START-->\n\n<img height=\"20px\" src=\"https://i.imgur.com/0ZZG9qx.jpeg\">\n\n\uD83D\uDE42 Looking for an issue? Welcome! This issue is open for contribution. If this is the first time you???re requesting an issue, please:\n\n- **Read <a href=\"https://learningequality.org/contributing-to-our-open-code-base/\" target=\"_blank\">Contributing guidelines</a>** carefully. **Pay extra attention to [Using generative AI](https://learningequality.org/contributing-to-our-open-code-base/#using-generative-ai)**. **Pull requests and comments that don???t follow the guidelines won???t be answered.**\n- **Confirm that you???ve read the guidelines** in your comment.\n\n<img height=\"20px\" src=\"https://i.imgur.com/0ZZG9qx.jpeg\">\n\n<!---HEADER END-->\n\n\nSub-issue of https://github.com/learningequality/studio/issues/5060.\n\n**Complexity: Low**\n\n## Summary\n\nMigrate the loader in _Settings > Storage_ from Vuetify to Kolibri Design System.\n\n![Image](https://github.com/user-attachments/assets/2d43448f-8c42-4def-9646-0c629d0868c4)\n\n`shared/views/LoadingText`, which is built with several Vuetify components, is currently used to display the loader. To remove this Vuetify dependency from `Storage/index`, **replace the usage of `LoadingText` in this specific location with `KCircularLoader`. Do not modify `LoadingText` itself**.\n\n## How to get there\n\n- Login as `user@a.com` with password `a`\n- Go to _Settings > Storage_\n- In code, temporarily modify template conditions or set `storageUseByKind` to `false` to display the loader\n\n## Guidance\n\n- Read [the project](https://github.com/learningequality/studio/issues/5060) this issue is part of\n\n## Out of Scope\n\n- Do not refactor any other areas of the codebase\n- Do not modify `LoadingText`\n\n## Expected UI/UX changes\n\n- Minor visual differences naturally stemming from the use of KDS\n  - Easing of animation\n\n## Acceptance criteria\n\n**General**\n\n- [ ] The specification above is followed.\n- [ ] Except for \"Expected UI/UX changes,\" there are no functional or visual differences in user experience.\n- [ ] All user interactions are manually tested with no regressions.\n- [ ] Pull request includes screenshots.\n\n**a11y and i18n**\n\nSee [the project](https://github.com/learningequality/studio/issues/5060)'s \"Guidance\" for useful references.\n\n- [ ] Implementation meets a11y standards\n- [ ] All components are LTR and RTL compliant\n- [ ] All user-facing strings are translated properly\n- [ ] The `notranslate` class been added to elements that shouldn't be translated by Google Chrome's automatic translation feature (e.g. user-generated text)\n- [ ] Mobile experience is reasonable\n\n**Unit tests**\n- [ ] If there is a unit test suite already, it is meaningfully updated (even if tests don't fail)\n- [ ] If there is no unit test suite, a new one is created. Do not use obsolete `@vue/test-utils` approach. Instead, use [Vue Testing Library](https://kolibri-dev.readthedocs.io/en/develop/frontend_architecture/unit_testing.html).",
      "updatedAt" : 1753368901.000000000,
      "user" : "MisRob",
      "userHtmlUrl" : "https://github.com/MisRob",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13509191?v=4",
      "labels" : [ "community-contribution-in-progress", "help wanted", "DEV: frontend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I have read the contribution guidelines please assign this issue to me", "Thanks @Kartikayy007, assigning", "Hi @Kartikayy007, are you still planning to work on this?" ],
      "repository" : {
        "description" : "Content curation tools for Kolibri",
        "homepage" : "https://studio.learningequality.org/",
        "name" : "studio",
        "fullName" : "learningequality/studio",
        "htmlUrl" : "https://github.com/learningequality/studio",
        "gitUrl" : "git://github.com/learningequality/studio.git",
        "sshUrl" : "git@github.com:learningequality/studio.git",
        "cloneUrl" : "https://github.com/learningequality/studio.git",
        "owner" : {
          "login" : "learningequality",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 213,
        "stargazersCount" : 142,
        "watchersCount" : 142,
        "size" : 225996,
        "openIssuesCount" : 344,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-24T15:15:10Z",
        "languages" : {
          "Dockerfile" : 2211,
          "CSS" : 13352,
          "Shell" : 5274,
          "Gherkin" : 141136,
          "SCSS" : 253848,
          "Makefile" : 8225,
          "JavaScript" : 1739088,
          "Vue" : 1413426,
          "Mustache" : 3769,
          "HTML" : 261490,
          "Python" : 2367899
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Migrate the loader in Settings > Storage from Vuetify to Kolibri Design System, replacing the usage of LoadingText with KCircularLoader.",
      "validationOrRequirement" : "The issue requires the use of Kolibri Design System instead of Vuetify, and the implementation should meet accessibility standards and be LTR and RTL compliant.",
      "attemptedFixes" : "None mentioned in the issue description, but the author is looking for someone to assign the issue to them.",
      "otherNotes" : "The issue is part of a larger project, and there are specific guidelines and references provided. The author has confirmed reading the guidelines, and there are comments from other contributors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407560
  }, {
    "issueDTO" : {
      "id" : 3255684763,
      "title" : "Make DRF's BrowsableAPIRenderer optional for the API",
      "url" : "https://github.com/wagtail/wagtail/issues/13265",
      "repositoryName" : "wagtail/wagtail",
      "description" : "Summary from core team meeting discussion:\n\n- The admin has an API that is used for the page explorer in the main menu. It???s built using code from the `wagtail.api.v2 app`, but that app is not required to be installed.\n- Problem: if you hit the endpoints directly in the browser without having the `api.v2` and/or `rest_framework` apps installed, you???ll end up with errors about the templates/static files from DRF not being found. For example:  `/admin/api/main/pages/`\n- Should we update Wagtail???s code so that it does not assume those apps are installed, so people can e.g. remove the Pages menu and completely remove DRF from Wagtail?\n  - Answer: no, we likely don???t want to go down this path because this means we???ll have to take into account of such configurations in different places throughout Wagtail\n  - Alternative solution: make it so that the admin API only uses the `JSONRenderer`. This means the routes will always give JSON even when accessed directly from the browser, allowing us to avoid the template/static files error and avoiding the need for the app to be installed. See https://www.django-rest-framework.org/api-guide/renderers/\n\n## Solution\n\nWe need to override `renderer_classes` of the following viewset:\n\nhttps://github.com/wagtail/wagtail/blob/0c3a0b22f0d7dac6d47c1b57a1cc9aefd8f8751e/wagtail/admin/api/views.py#L25\n\nSo that it only uses the `JSONRenderer` if the `rest_framework` app is not installed (and maybe `wagtail.api.v2`? check if this app is really necessary for the API to be used from the browser).\n\nIdeally, we also make it so that the HTMLRenderer is still provided if the necessary apps are installed, so they can still be used in a human-friendly way in the browser for those who install the apps. This can probably be done by turning it into a dynamic `@property` and using `django.apps.apps.is_installed(\"rest_framework\")`. But if this is not possible, then we should only use JSONRenderer.\n\nThen, we need to add tests to ensure that if the necessary apps are not installed, the API response is always in JSON even if the request's `Accept` header prefers HTML, e.g. `text/html,application/xhtml+xml,application/xml`, and perhaps also when the `Accept` header is missing from the request.\n\nHappy to review a PR that does this.\n\n _Originally posted by @laymonage in [#13262](https://github.com/wagtail/wagtail/issues/13262#issuecomment-3106739785)_",
      "updatedAt" : 1753368803.000000000,
      "user" : "laymonage",
      "userHtmlUrl" : "https://github.com/laymonage",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6379424?v=4",
      "labels" : [ "type:Bug", "good first issue", "type:Cleanup/Optimisation" ],
      "state" : "OPEN",
      "comments" : [ "Hi @laymonage , I would like to work on this", "Go ahead, thanks!", "I would work on `BaseAPIViewSet` instead\n\nhttps://github.com/wagtail/wagtail/blob/bb8800927c74207fe7de9f4efca8a8961e2f95ab/wagtail/api/v2/views.py#L37-L38", "You're right, the docs actually state the following:\n\n> Optionally, you may also want to add `rest_framework` to `INSTALLED_APPS`. This would make the API browsable when viewed from a web browser but is not required for basic JSON-formatted output.\n\nhttps://docs.wagtail.org/en/stable/advanced_topics/api/v2/configuration.html#enable-the-app", "@laymonage can anyone make pr on this ", "@blazethunderstorm I'm on it\n" ],
      "repository" : {
        "description" : "A Django content management system focused on flexibility and user experience",
        "homepage" : "https://wagtail.org",
        "name" : "wagtail",
        "fullName" : "wagtail/wagtail",
        "htmlUrl" : "https://github.com/wagtail/wagtail",
        "gitUrl" : "git://github.com/wagtail/wagtail.git",
        "sshUrl" : "git@github.com:wagtail/wagtail.git",
        "cloneUrl" : "https://github.com/wagtail/wagtail.git",
        "owner" : {
          "login" : "wagtail",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 4124,
        "stargazersCount" : 19445,
        "watchersCount" : 19445,
        "size" : 239306,
        "openIssuesCount" : 947,
        "subscribersCount" : 336,
        "pushedAt" : "2025-07-24T14:50:18Z",
        "languages" : {
          "TypeScript" : 622589,
          "MDX" : 271,
          "Dockerfile" : 2038,
          "Jinja" : 537873,
          "Shell" : 6841,
          "CSS" : 2719,
          "SCSS" : 236449,
          "Makefile" : 1428,
          "JavaScript" : 1295914,
          "Python" : 8660495
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Make DRF's BrowsableAPIRenderer optional for the API so that the API can be used without the rest_framework app installed, and still be browsable in the browser if the app is installed.",
      "validationOrRequirement" : "The rest_framework app is not required to be installed, but if it is, the API should still be browsable in the browser.",
      "attemptedFixes" : "Make it so that the admin API only uses the JSONRenderer. This means the routes will always give JSON even when accessed directly from the browser, allowing us to avoid the template/static files error and avoiding the need for the app to be installed.",
      "otherNotes" : "The admin API is used for the page explorer in the main menu, built using code from the wagtail.api.v2 app, but that app is not required to be installed. The problem is that if you hit the endpoints directly in the browser without having the api.v2 and/or rest_framework apps installed, you'll end up with errors about the templates/static files from DRF not being found.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407567
  }, {
    "issueDTO" : {
      "id" : 1362703958,
      "title" : "[ios] account login UI improvements",
      "url" : "https://github.com/organicmaps/organicmaps/issues/3356",
      "repositoryName" : "organicmaps/organicmaps",
      "description" : "![image](https://user-images.githubusercontent.com/50059322/188550133-f9d2947b-85b9-414e-917f-c1eb9df8bb99.jpeg)![image](https://user-images.githubusercontent.com/50059322/188550149-6eabb21e-1950-441a-b3a6-bfb50a287735.jpeg)",
      "updatedAt" : 1753368780.000000000,
      "user" : "TheAdventurer64",
      "userHtmlUrl" : "https://github.com/TheAdventurer64",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/50059322?v=4",
      "labels" : [ "UI", "Good first issue", "iOS", "Editor" ],
      "state" : "OPEN",
      "comments" : [ "See https://github.com/organicmaps/organicmaps/pull/2909 for the Android rework.", "bumping as this is still an issue; @biodranik what modifications would be needed to fix the UI?", "It is already fixed on iOS. @TheAdventurer64 does it still reproduce for you?", "> It is already fixed on iOS. [@TheAdventurer64](https://github.com/TheAdventurer64) does it still reproduce for you?\n\nAdding a comment here since this is still not 100% fixed in June 2025:\n\nIssues that still need fixing:\n* For the first picture, the background is still green\n* Font sizes on the login screen are still inconsistent.", "Let's update/summarize remaining issues here. I also observed some issues when a user is logged in (e.g. no last upload date, the UI hangs when entering logged-in profile on slow connection, etc.)" ],
      "repository" : {
        "description" : "\uD83C\uDF43 Organic Maps is a free Android & iOS offline maps app for travelers, tourists, hikers, and cyclists. It uses crowd-sourced OpenStreetMap data and is developed with love by the community. No ads, no tracking, no data collection, no crapware. Please donate to support the development!",
        "homepage" : "https://organicmaps.app",
        "name" : "organicmaps",
        "fullName" : "organicmaps/organicmaps",
        "htmlUrl" : "https://github.com/organicmaps/organicmaps",
        "gitUrl" : "git://github.com/organicmaps/organicmaps.git",
        "sshUrl" : "git@github.com:organicmaps/organicmaps.git",
        "cloneUrl" : "https://github.com/organicmaps/organicmaps.git",
        "owner" : {
          "login" : "organicmaps",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1132,
        "stargazersCount" : 11517,
        "watchersCount" : 11517,
        "size" : 8092983,
        "openIssuesCount" : 2972,
        "subscribersCount" : 99,
        "pushedAt" : "2025-07-25T00:19:49Z",
        "languages" : {
          "Java" : 1692864,
          "C++" : 18577372,
          "C" : 1930794,
          "Objective-C++" : 815158,
          "CMake" : 209576,
          "DIGITAL Command Language" : 901,
          "Makefile" : 818,
          "M4" : 786,
          "Common Lisp" : 17587,
          "HTML" : 342540,
          "Metal" : 83083,
          "Dockerfile" : 577,
          "Shell" : 42082,
          "Starlark" : 965,
          "Gherkin" : 305230,
          "Objective-C" : 293955,
          "Lua" : 55296,
          "PHP" : 2777,
          "Swift" : 1030279,
          "Roff" : 3323,
          "Ruby" : 70144,
          "Python" : 674939,
          "GLSL" : 79385
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve the UI of the account login feature on iOS.",
      "validationOrRequirement" : "Fix UI inconsistencies on iOS, specifically font sizes and background color of the first picture.",
      "attemptedFixes" : "The issue is already fixed on iOS, but the fix did not extend to Android. The rework for Android is in pull request 2909.",
      "otherNotes" : "Issues that still need fixing include inconsistent font sizes on the login screen and the background of the first picture still being green. Additional issues observed when a user is logged in include no last upload date and UI hangs when entering logged-in profile on slow connection.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407571
  }, {
    "issueDTO" : {
      "id" : 3025968361,
      "title" : "Optimize CI jobs to only run when needed",
      "url" : "https://github.com/maplibre/martin/issues/1811",
      "repositoryName" : "maplibre/martin",
      "description" : "It seems some projects use this style of a CI test to check if any job has failed or not, without explicitly waiting for them to pass/fail/be ignored.\n\n```yaml\n  ci-passed:\n    if: always()\n    needs:  [  <list of CI job names to check>  ]\n    runs-on: ubuntu-latest\n    steps:\n      - if: ${{ contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled') }}\n        run: exit 1\n```\n\nI think we can use the same approach to simplify our CI to only run on relevant changes, while still making our CI ruleset to depend on this one job to tag the PR as passing.",
      "updatedAt" : 1753368672.000000000,
      "user" : "nyurik",
      "userHtmlUrl" : "https://github.com/nyurik",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1641515?v=4",
      "labels" : [ "help wanted", "ci/cd", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "```yaml\nneeds:  [  <list of CI job names to check>  ]\n```\n\nWould it at this poin not be simpler to just add this to the GitHub settings?\nYes, this way PRs can propose additions/removals and reviewing is a bit simpler.\nThough, required checks are marked as such and if we already need to enumerate them, so not much more work..\n\nEdit:\nNo, Frank just no. \uD83E\uDD26\uD83C\uDFFB This would not work for the \"simplify our CI to only run on relevant changes, while still making our CI ruleset to depend on this one job to tag the PR as passing.\"", "> [!NOTE]\n> A job that is skipped will report its status as \"Success\". It will not prevent a pull request from merging, even if it is a required check.\n\nhttps://docs.github.com/en/actions/how-tos/writing-workflows/choosing-when-your-workflow-runs/using-conditions-to-control-job-execution\n\nIt turns out the reason a lot of people do this is more underlying" ],
      "repository" : {
        "description" : "Blazing fast and lightweight PostGIS, MBtiles and PMtiles tile server, tile generation, and mbtiles tooling.",
        "homepage" : "https://martin.maplibre.org",
        "name" : "martin",
        "fullName" : "maplibre/martin",
        "htmlUrl" : "https://github.com/maplibre/martin",
        "gitUrl" : "git://github.com/maplibre/martin.git",
        "sshUrl" : "git@github.com:maplibre/martin.git",
        "cloneUrl" : "https://github.com/maplibre/martin.git",
        "owner" : {
          "login" : "maplibre",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 268,
        "stargazersCount" : 2863,
        "watchersCount" : 2863,
        "size" : 19703,
        "openIssuesCount" : 93,
        "subscribersCount" : 35,
        "pushedAt" : "2025-07-24T14:17:42Z",
        "languages" : {
          "TypeScript" : 91329,
          "Shell" : 29490,
          "CSS" : 2170,
          "Rust" : 672555,
          "JavaScript" : 7648,
          "HTML" : 18833,
          "Just" : 16626
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Optimize CI jobs to only run when needed, simplify our CI to only run on relevant changes, while still making our CI ruleset to depend on this one job to tag the PR as passing.",
      "validationOrRequirement" : "A job that is skipped will report its status as \"Success\". It will not prevent a pull request from merging, even if it is a required check.",
      "attemptedFixes" : "Would it at this point not be simpler to just add this to the GitHub settings?",
      "otherNotes" : "It seems some projects use this style of a CI test to check if any job has failed or not, without explicitly waiting for them to pass/fail/be ignored. It turns out the reason a lot of people do this is more underlying.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407576
  }, {
    "issueDTO" : {
      "id" : 2999976034,
      "title" : "Display the error highlight when question has an invalid value",
      "url" : "https://github.com/getodk/web-forms/issues/375",
      "repositoryName" : "getodk/web-forms",
      "description" : "### Description\n\nDisplay the error highlight when the question is required, the form has not been submitted yet, and there was a value before that got removed. Currently, the highlight isn't applied, and just the error message appears: \n\n<img width=\"700\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/9ceefeea-ff50-480c-b836-9995e6f5c697\" />\n\n\nThe idea is that it always shows the highlight like this:\n\n<img width=\"700\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/93fbb117-d3e3-4d4f-8cc5-fa6e557ede72\" />\n\n---\n\n### Checklist\n- [ ] **Does it need UI/UX design?**\n  - If yes, describe the UI/UX requirements or attach a Figma link in the \"Design\" section.\n- [ ] **Does it need API design?**\n  - If yes, specify the endpoints, methods, or data structures needed.\n- [ ] **Does it need design around state flow?**\n  - If yes, outline the state flow requirements.\n- [ ] **Does it need a test plan?**\n  - If yes, add the test plan as a comment in this task or attach the document.\n---\n\n### User Stories\n<!-- Describe the feature from the user???s perspective using the \"As a... I want... so that...\" format. Add multiple stories if applicable. -->\n\n- **As a** data collector,\n  **I want** to notice when a field has an invalid value easily whenever I set a new value,\n  **so that** I can fix it promptly.\n\n---\n\n### Design\nNA\n\n---\n\n### Dependencies\nNone\n\n---\n\n### Additional Notes\n\n- It was raised and discussed in this PR: https://github.com/getodk/web-forms/pull/363#discussion_r2040003870\n\n\n",
      "updatedAt" : 1753368531.000000000,
      "user" : "latin-panda",
      "userHtmlUrl" : "https://github.com/latin-panda",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/66472237?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@latin-panda  can u assign me this issue", "Hi @VINODvoid, Thanks for picking this up! Post here any questions related to the task." ],
      "repository" : {
        "description" : "ODK Web Forms enables form filling and submission editing of ODK forms in a web browser. It's coming soon! ???",
        "homepage" : "https://getodk.org",
        "name" : "web-forms",
        "fullName" : "getodk/web-forms",
        "htmlUrl" : "https://github.com/getodk/web-forms",
        "gitUrl" : "git://github.com/getodk/web-forms.git",
        "sshUrl" : "git@github.com:getodk/web-forms.git",
        "cloneUrl" : "https://github.com/getodk/web-forms.git",
        "owner" : {
          "login" : "getodk",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 22,
        "watchersCount" : 22,
        "size" : 10355,
        "openIssuesCount" : 160,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-24T18:38:51Z",
        "languages" : {
          "TypeScript" : 2717294,
          "SCSS" : 6719,
          "Vue" : 138134,
          "JavaScript" : 22946,
          "Mustache" : 290,
          "HTML" : 657
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Display the error highlight when a question has an invalid value, making it easier for the data collector to notice and fix the issue promptly.",
      "validationOrRequirement" : "The error highlight should be displayed when the question is required, the form has not been submitted yet, and there was a value before that got removed.",
      "attemptedFixes" : "NA",
      "otherNotes" : "The issue is related to a PR and was discussed in the comments. There are no dependencies and no design requirements. The issue has been assigned to @VINODvoid.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407580
  }, {
    "issueDTO" : {
      "id" : 3235965426,
      "title" : "Create a helper class for working with locks",
      "url" : "https://github.com/shopware/shopware/issues/11302",
      "repositoryName" : "shopware/shopware",
      "description" : "### Technical TODO\n\nIn few places of shopware platform we are using symfony/lock component to manage locks. \nIt's possible to identify two common cases:\n- locking and executing a code or throwing exception\n- blocking until lock is acquired and executing a code\n\nIn this [discussion](https://github.com/shopware/shopware/pull/11229#discussion_r2205872574) we've came to the decision to create a helper class to wrap reusable logic, like properly acquiring/releasing a lock, handling exceptions, prefixing, etc. Discussion also contains PoC implementation.\n\nPlease create helper class and update places using `LockFactory` to use new class where possible.",
      "updatedAt" : 1753368531.000000000,
      "user" : "h1k3r",
      "userHtmlUrl" : "https://github.com/h1k3r",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1944853?v=4",
      "labels" : [ "Good first issue", "priority/low", "domain/framework" ],
      "state" : "OPEN",
      "comments" : [ "It would be nice to have PHP 8 Attribute which you can throw on Controllers, in the attribute constructor you pass an pattern of your lock key. it automatically wraps the controller then on calling" ],
      "repository" : {
        "description" : "Shopware 6 is an open commerce platform based on Symfony Framework and Vue and supported by a worldwide community and more than 3.100 community extensions",
        "homepage" : "https://shopware.com",
        "name" : "shopware",
        "fullName" : "shopware/shopware",
        "htmlUrl" : "https://github.com/shopware/shopware",
        "gitUrl" : "git://github.com/shopware/shopware.git",
        "sshUrl" : "git@github.com:shopware/shopware.git",
        "cloneUrl" : "https://github.com/shopware/shopware.git",
        "owner" : {
          "login" : "shopware",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1109,
        "stargazersCount" : 3109,
        "watchersCount" : 3109,
        "size" : 323110,
        "openIssuesCount" : 1180,
        "subscribersCount" : 101,
        "pushedAt" : "2025-07-24T23:48:56Z",
        "languages" : {
          "TypeScript" : 2212952,
          "CSS" : 70001,
          "Shell" : 21585,
          "Twig" : 4857839,
          "SCSS" : 1036452,
          "JavaScript" : 12949390,
          "Vue" : 2088,
          "PHP" : 34624980,
          "HTML" : 27316,
          "Nix" : 4546,
          "Groovy" : 4150
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a helper class for working with locks, replacing the usage of `LockFactory` in certain places, and update related code to use the new class.",
      "validationOrRequirement" : "The helper class should properly acquire and release locks, handle exceptions, and prefix lock keys.",
      "attemptedFixes" : "A helper class needs to be created to replace the usage of `LockFactory` in certain places.",
      "otherNotes" : "The helper class will wrap reusable logic for managing locks, including acquiring and releasing locks, handling exceptions, and prefixing. A PoC implementation is provided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407584
  }, {
    "issueDTO" : {
      "id" : 2823959517,
      "title" : "Allow directly opening files/folders instead of containing folder in tray search",
      "url" : "https://github.com/nextcloud/desktop/issues/7814",
      "repositoryName" : "nextcloud/desktop",
      "description" : "<!--- Please keep this note for other contributors -->\n\n### How to use GitHub\n\n* Please use the \uD83D\uDC4D [reaction](https://blog.github.com/2016-03-10-add-reactions-to-pull-requests-issues-and-comments/) to show that you are interested into the same feature.\n* Please don't comment if you have no relevant information to add. It's just extra noise for everyone subscribed to this issue.\n* Subscribe to receive notifications on status change and new comments.\n\n---\n\n## Feature request\n\n**Which Nextcloud Version are you currently using:** (see administration page)\n3.15.3 Windows version.\n\n**Describe the solution you'd like**\nI have a folder containing a lot of folders with similar names that I need to manually sort and look through so I would like to search them. I disabled Windows search indexing on my Nextcloud directory because windows kept on downloading files I wanted to only keep online every time I searched for something in the parent folder.\n\nThe search function in the Nextcloud tray menu is able to find the desired sub folder, but clicking the folder only opens the containing folder and not the folder itself. This is useless to me because, as said, there are a lot of different folders and the folder names are too similar.\n\nIt looks like Nextcloud just opens the containing folder for folders or files. It would be nice if there was at least a context open to allow opening folder or files.\n\n**Describe alternatives you've considered**\nOpen folder or file by default and have open containing folder the context menu option, but that risks messing with other people's workflow since open containing folder is the current behavior.",
      "updatedAt" : 1753368306.000000000,
      "user" : "mijioij",
      "userHtmlUrl" : "https://github.com/mijioij",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/154655539?v=4",
      "labels" : [ "1. to develop", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for the feedback, we will look into improving this.", "Currently this feature works as @mijioij wants it to work (as far as I am aware of).\n\nMy folders are structured as follows\n![Image](https://github.com/user-attachments/assets/cce6c3a6-96a0-408d-a99e-1a78aa013608)\n\nAnd when I search I get\n![Image](https://github.com/user-attachments/assets/57c1c6ec-cfed-40be-a3a4-ef00c73cca89)\n\nUpon clicking I am redirected into the folder I clicked on\n![Image](https://github.com/user-attachments/assets/cd7ccc4f-1edd-4e7b-8893-71def69ec3f2)\n\nIs this how you (@mijioij) wanted it to be? Or did I misunderstand?", "@mike0609king That isn't the location in the tray I am talking about. It's the search results after searching an item with the tray menu's search function, not the folder listing under the standard file sync in the tray menu settings. \n\nSide note: When I click a folder under the standard file sync tab, it opens in windows explorer and doesn't open a browser like your example suggests.", "@mijioij I am not sure what you mean in that case. Could you show me a screenshot? ", "@mike0609king Here is where I am talking about:\n\n![Image](https://github.com/user-attachments/assets/73644889-d8af-4b12-bd8c-e48f16dcfa3a)\n\nIf directory structure is \\root\\subdir\\foo and foo is in the above search result, clicking the foo search result won't open explorer at foo, but at subdir.", "@mijioij Thanks for the quick response. I am sure, that I use the same search tray above. Maybe it has been fixed on the current version. Which version are you using? \n\nEDIT: I will also try it out again and take a look at the code for this.", "@mike0609king The pictures you showed are only when you right click tray icon -> settings. I got to the screenshot I showed when I right click the tray icon -> Open main dialog -> enter search term in the search box and search.\n\nI am using version 3.16.6 stable.", "The difference was the Nextcloud version. It seems that the file explorer only opens in Nextcloud 20, because of the different file format for the `resourceUrl`. As far as I am aware we only have that file format\n```\nhttps://<url>/index.php/apps/files/?dir=<dir>&scrollto=<dirname>\n```\nin Nextcloud 20. The other ones send the file path in a separate attribute.\n\nI would then implement the context menu and resolve the bug with the links in this issue.", "@mike0609king It wasn't clear from your comment, is this issue due to behavior from the nextcloud server and you will only fix the bug to work with the newer server or will you fix the bug for compatibility with the older server?" ],
      "repository" : {
        "description" : "\uD83D\uDCBB Desktop sync client for Nextcloud",
        "homepage" : "https://nextcloud.com/install/#install-clients",
        "name" : "desktop",
        "fullName" : "nextcloud/desktop",
        "htmlUrl" : "https://github.com/nextcloud/desktop",
        "gitUrl" : "git://github.com/nextcloud/desktop.git",
        "sshUrl" : "git@github.com:nextcloud/desktop.git",
        "cloneUrl" : "https://github.com/nextcloud/desktop.git",
        "owner" : {
          "login" : "nextcloud",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 840,
        "stargazersCount" : 3320,
        "watchersCount" : 3320,
        "size" : 561622,
        "openIssuesCount" : 915,
        "subscribersCount" : 108,
        "pushedAt" : "2025-07-24T17:09:22Z",
        "languages" : {
          "C++" : 5528614,
          "C" : 48516,
          "CMake" : 273744,
          "Objective-C++" : 142000,
          "QMake" : 545,
          "NSIS" : 131944,
          "QML" : 253104,
          "Shell" : 19975,
          "JavaScript" : 1949,
          "Objective-C" : 39426,
          "Swift" : 156929,
          "Nix" : 4501,
          "Ruby" : 7726,
          "Python" : 30698
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Allow directly opening files/folders instead of containing folder in tray search",
      "validationOrRequirement" : "The user is using Nextcloud 3.15.3 and 3.16.6 stable versions, and the issue is specific to the search function in the tray menu. The user has provided images to demonstrate the issue.",
      "attemptedFixes" : "The user has tried to disable Windows search indexing on their Nextcloud directory and has also considered implementing a context menu option to open the folder or file by default, but this would risk messing with other people's workflow.",
      "otherNotes" : "The issue is related to the search function in the Nextcloud tray menu, where clicking on a folder in the search results only opens the containing folder instead of the desired folder. The user is using Nextcloud 3.15.3 and 3.16.6 stable versions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407589
  }, {
    "issueDTO" : {
      "id" : 2587944351,
      "title" : "New Stake on Aura option within My Liquidity module",
      "url" : "https://github.com/balancer/frontend-monorepo/issues/58",
      "repositoryName" : "balancer/frontend-monorepo",
      "description" : "\nThe problem:\n\nCurrently, we only highlight the option to stake on Aura in the transaction confirmation screen. There is no visibility for this option after the user dismisses the confirmation screen. \n\nThe solution:\n\n1. Add a popover to the Stake button which shows the Balancer and Aura options along with their APRs\n  - This APR should be personalized to the user, based on their veBAL address for Balancer, and the overall Aura APR for that pool\n- 2. If it's easy, append a `^` icon to the button to give a visual cue that there are multiple options behind the button interaction.\n\n\n![Image](https://github.com/user-attachments/assets/28a6af84-6ab1-4515-9018-43f68135121d)\n\n",
      "updatedAt" : 1753368282.000000000,
      "user" : "uiuxxx",
      "userHtmlUrl" : "https://github.com/uiuxxx",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/149399376?v=4",
      "labels" : [ "UX improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @uiuxxx @garethfuller \uD83D\uDC4B\n\nIs this ???Stake on???Aura??? popover still needed?  \nIf yes, I???m happy to implement it:\n\n* Popover on **Stake** button with Balancer (user veBAL APR) + Aura (pool APR) options  \n* Caret (^) icon for visibility\n\nQuick checks:\n1. Source for Aura APR???existing endpoint or add subgraph call?  \n2. Any caching preference for the personalized veBAL APR?  \n3. OK to hide behind a feature flag initially?\n\nLet me know and I???ll start a PR.\n\nThanks,  \nVadim Nicolai\n", "Yes, this is still needed.\n\nHere is a slightly modified design: \n\n<img width=\"1314\" height=\"1068\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5c808348-8249-4ebd-894c-ff794e61a916\" />\n\n### Aura APR\n\n> Source for Aura APR???existing endpoint or add subgraph call?\n\nRegarding Aura APR, please check the code to see how it is being displayed within the \"My liquidity\" module within the Pool Detail page (Note: this only displays only when a user has liquidity in an incentivized pool).\n\n<img width=\"2726\" height=\"1378\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d7dfa362-a590-41cf-9bae-dfd619f022d9\" />\n\n\n### Caching\n> Any caching preference for the personalized veBAL APR?\n\n@agorer ??? any preference here?\n\n### Feature flag\n> OK to hide behind a feature flag initially?\n\nThis is probably unnecessary since the PR will be merged by the team." ],
      "repository" : {
        "description" : "Balancer frontend apps and packages. Includes the official Balancer web application.",
        "homepage" : "https://balancer.fi",
        "name" : "frontend-monorepo",
        "fullName" : "balancer/frontend-monorepo",
        "htmlUrl" : "https://github.com/balancer/frontend-monorepo",
        "gitUrl" : "git://github.com/balancer/frontend-monorepo.git",
        "sshUrl" : "git@github.com:balancer/frontend-monorepo.git",
        "cloneUrl" : "https://github.com/balancer/frontend-monorepo.git",
        "owner" : {
          "login" : "balancer",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 21,
        "watchersCount" : 21,
        "size" : 108448,
        "openIssuesCount" : 71,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T18:42:20Z",
        "languages" : {
          "TypeScript" : 4630914,
          "CSS" : 13282,
          "JavaScript" : 8940
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a popover to the Stake button which shows the Balancer and Aura options along with their APRs, and personalize the APR to the user based on their veBAL address for Balancer and the overall Aura APR for that pool",
      "validationOrRequirement" : "Popover on Stake button with Balancer (user veBAL APR) + Aura (pool APR) options; caret (^) icon for visibility",
      "attemptedFixes" : "Design modification for Stake on Aura popover; checking code for Aura APR display in Pool Detail page",
      "otherNotes" : "Aura APR source: check existing endpoint or add subgraph call; caching: no preference; feature flag: not necessary",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407594
  }, {
    "issueDTO" : {
      "id" : 3259772803,
      "title" : "Rename \"OpenAI\" provider to \"OpenAI (or API compatible)\"",
      "url" : "https://github.com/JabRef/jabref/issues/13585",
      "repositoryName" : "JabRef/jabref",
      "description" : "**Is your suggestion for improvement related to a problem? Please describe.**\n\nJabRef supports custom \"local\" LLMs. This is implemented by supplying a custom API base URL. This is reflected in our user documentation, however it's not plain in settings.\n\n**Describe the solution you'd like**\n\nRename `OpenAI` provider to `OpenAI (or API compatible)`.\n\n**Additional context**\n\n_None._\n",
      "updatedAt" : 1753368278.000000000,
      "user" : "InAnYan",
      "userHtmlUrl" : "https://github.com/InAnYan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13097618?v=4",
      "labels" : [ "component: ai", "good first issue", "\uD83D\uDCCD Assigned", "component: ui" ],
      "state" : "OPEN",
      "comments" : [ "I can work on this but can you provide a little bit more context please maybe the class or what does imply the module being renamed.", "/assign-me", "\uD83D\uDC4B Hey @SalvadorRomo, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80" ],
      "repository" : {
        "description" : "Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases",
        "homepage" : "https://www.jabref.org",
        "name" : "jabref",
        "fullName" : "JabRef/jabref",
        "htmlUrl" : "https://github.com/JabRef/jabref",
        "gitUrl" : "git://github.com/JabRef/jabref.git",
        "sshUrl" : "git@github.com:JabRef/jabref.git",
        "cloneUrl" : "https://github.com/JabRef/jabref.git",
        "owner" : {
          "login" : "JabRef",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2881,
        "stargazersCount" : 3953,
        "watchersCount" : 3953,
        "size" : 249443,
        "openIssuesCount" : 578,
        "subscribersCount" : 112,
        "pushedAt" : "2025-07-24T20:20:03Z",
        "languages" : {
          "PowerShell" : 2037,
          "Java" : 11269860,
          "CSS" : 74176,
          "TeX" : 758587,
          "AppleScript" : 1721,
          "XSLT" : 151843,
          "Just" : 1194,
          "Shell" : 9305,
          "Batchfile" : 637,
          "ANTLR" : 9176,
          "BibTeX Style" : 78034,
          "Ruby" : 507,
          "Python" : 22282
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rename the 'OpenAI' provider to 'OpenAI (or API compatible)' in JabRef's user documentation and settings.",
      "validationOrRequirement" : "No specific validations or requirements mentioned, but it's a good first issue with labels for component: ai and component: ui.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue is related to JabRef's user documentation and settings, specifically renaming the 'OpenAI' provider to 'OpenAI (or API compatible)'.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407598
  }, {
    "issueDTO" : {
      "id" : 3125292899,
      "title" : "Add support for resetting the local persistent cache",
      "url" : "https://github.com/gittuf/gittuf/issues/1023",
      "repositoryName" : "gittuf/gittuf",
      "description" : "#1019 made the local persistent caching feature of gittuf generally available. Users can initialize the cache with `gittuf cache init`.\n\nWe should add functionality to reset the local cache in case of issues or if the user would like to disable the cache. This should mostly be just adding a new command and methods in https://github.com/gittuf/gittuf/blob/main/internal/cache/cache.go#L51 to delete the cache ref.",
      "updatedAt" : 1753368260.000000000,
      "user" : "patzielinski",
      "userHtmlUrl" : "https://github.com/patzielinski",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/70954403?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @patzielinski ,\n\nI wanted to clarify if there???s no need to handle multiple cache references at this point, as I noticed that the `gittuf cache init` command currently creates only a single cache reference. \n\nConsidering this, it seems like the `reset` functionality only needs to deal with this single cache reference for removal (as of now).\n", "I think @shivpratikhande is correct, the gittuf cache init command creates only a single cache reference (refs/gittuf/cache). Therefore, implementing the reset functionality to handle just this single reference is appropriate for now.", "Given the lack of activity, I'm curious if I could contribute to this.", "Hi @Sylani-55, #1026 is open for this, which I'll be updating to get it merged." ],
      "repository" : {
        "description" : "A security layer for Git repositories",
        "homepage" : "https://gittuf.dev",
        "name" : "gittuf",
        "fullName" : "gittuf/gittuf",
        "htmlUrl" : "https://github.com/gittuf/gittuf",
        "gitUrl" : "git://github.com/gittuf/gittuf.git",
        "sshUrl" : "git@github.com:gittuf/gittuf.git",
        "cloneUrl" : "https://github.com/gittuf/gittuf.git",
        "owner" : {
          "login" : "gittuf",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 70,
        "stargazersCount" : 536,
        "watchersCount" : 536,
        "size" : 28485,
        "openIssuesCount" : 109,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-24T19:31:16Z",
        "languages" : {
          "Makefile" : 1240,
          "Go" : 1636119
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add functionality to reset the local cache in case of issues or if the user would like to disable the cache.",
      "validationOrRequirement" : "Handling multiple cache references at this point is not necessary.",
      "attemptedFixes" : "Implementing the reset functionality to handle just this single reference is appropriate for now.",
      "otherNotes" : "The cache initialization command creates only a single cache reference, so the reset functionality only needs to handle this single reference for removal.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407601
  }, {
    "issueDTO" : {
      "id" : 3253508464,
      "title" : "Add Java quiz",
      "url" : "https://github.com/Jadhav124Akshada/Quiz-App-/issues/70",
      "repositoryName" : "Jadhav124Akshada/Quiz-App-",
      "description" : "## Title :  ??? Suggestion - Add Dedicated Java Quiz Section\n\n### Description:\n\nI???d like to propose adding a Java quiz section to this project. This would offer the users to target the practice on the fundamental and advanced Java concepts, helping them prepare effectively for interviews, coding rounds, and academic exams.\n\n\n??? Benefits:\n1.  Covers core Java topics through challenging quiz questions.\n\n2. Enhances the variety of quizzes available in the repo.\n\n3. Supports learners in strengthening their programming skills and boost the confidence.\n\nAlso add labels please and assign me this issue.\n\n_GSSoC Contributor\nSejal Kamble_",
      "updatedAt" : 1753368240.000000000,
      "user" : "Sejal-collection",
      "userHtmlUrl" : "https://github.com/Sejal-collection",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/187588842?v=4",
      "labels" : [ "GSSOC2025", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@Sejal-collection \nI am assigning this issue to you. Please start working on it. Also, make sure to give a star to the repository and fill out the pull request (PR) template properly.\nIf the PR template is not followed properly, I will not merge your pull request.\n\nPlease follow this PR template carefully:\n\n\uD83D\uDCCC What does this PR do?\nA brief summary of the changes you have made.\n\nRelated Issue\nFixes # (mention the issue number here)\n\n\uD83D\uDD27 Type of Change\n Bug fix (non-breaking change)\n\n New feature\n\n Breaking change\n\n Documentation update\n\n??? How Has This Been Tested?\nMention the steps for testing or an overview of the testing process.\n\nInclude environment details (Operating System, browser, Node version, etc.)\n\n\uD83D\uDCF8 Screenshots (if UI changed)\n\uD83D\uDCCA Impact / Performance\nDescribe any performance changes or new dependencies introduced.\n\n??? Checklist\n I have followed the code style guidelines.\n\n I have self-reviewed my code.\n\n I have commented on complex parts of the code.\n\n I have updated or added documentation where necessary.\n\n All tests pass locally.\n\n No new warnings have been introduced.\n\n", "I would like to work on this issue: add java quiz.\nHere's what I plan to do:\nAdd a new Java quiz with well structured beginner to advanced level MCQs.\n\nI want to take this up, please assign it to me and provide the mentors as well..\nLooking forward to contribute!", "I want to work on this issue as a part of GSSoc'25 contributor. Please assign this issue to me.\n", "i would like to work on this issue .Please assign this issue to me\n" ],
      "repository" : {
        "description" : null,
        "homepage" : null,
        "name" : "Quiz-App-",
        "fullName" : "Jadhav124Akshada/Quiz-App-",
        "htmlUrl" : "https://github.com/Jadhav124Akshada/Quiz-App-",
        "gitUrl" : "git://github.com/Jadhav124Akshada/Quiz-App-.git",
        "sshUrl" : "git@github.com:Jadhav124Akshada/Quiz-App-.git",
        "cloneUrl" : "https://github.com/Jadhav124Akshada/Quiz-App-.git",
        "owner" : {
          "login" : "Jadhav124Akshada",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 80,
        "stargazersCount" : 25,
        "watchersCount" : 25,
        "size" : 102,
        "openIssuesCount" : 117,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-23T18:24:15Z",
        "languages" : {
          "CSS" : 8337,
          "JavaScript" : 43356,
          "HTML" : 33765
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add a dedicated Java quiz section to the project, providing users with an opportunity to practice and strengthen their programming skills in Java.",
      "validationOrRequirement" : "The proposal requires a well-structured beginner to advanced level MCQs for the Java quiz. The assignee is expected to follow the code style guidelines, self-review their code, and provide necessary documentation.",
      "attemptedFixes" : "No fixes have been attempted yet, as this is an initial proposal.",
      "otherNotes" : "The issue is part of GSSOC2025 and is labeled as a good first issue. The assignee is expected to follow the pull request template and provide a summary of the changes made, testing steps, and screenshots if necessary.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407606
  }, {
    "issueDTO" : {
      "id" : 3255557104,
      "title" : "[MCP] PDFMonkey",
      "url" : "https://github.com/activepieces/activepieces/issues/8476",
      "repositoryName" : "activepieces/activepieces",
      "description" : "## \uD83E\uDDE9 Product Overview\n\nPDFMonkey is a document automation service that generates PDFs from templates and structured data.  \nThis integration enables workflows and AI agents to generate and manage PDFs automatically.\n\n---\n\n## ?????? Important Note for Contributors\n\nTo ensure consistency and maintainability, this feature must be submitted as a [Piece](https://www.activepieces.com/docs/developers/building-pieces/piece-definition) following the Activepieces architecture. Submissions that do not follow this format will not be accepted. Please make sure to review the [Piece Development Guidelines](https://www.activepieces.com/docs/developers/building-pieces/overview) before starting development.\n\n**Contributors based in India: please check your eligibility for receiving payments through your Stripe account before submitting, as this may affect your ability to get paid.**\n\n\n---\n\n## \uD83D\uDEA8 Triggers\n\n| **Trigger**              | **Use Case** |\n|--------------------------|--------------|\n| **Document Generated**   | Fires when a PDF document generation completes successfully. |\n\n---\n\n## \uD83D\uDEE0??? Write Actions\n\n| **Action Item**          | **Use Case** |\n|--------------------------|--------------|\n| **Generate Document**    | Create a PDF from a specified template and input data (supports simple mapping or custom JSON, line items, metadata, and custom filename). |\n| **Delete Document**      | Remove a PDF document by its ID. |\n\n---\n\n## \uD83D\uDD0D Search Actions\n\n| **Action Item**          | **Use Case** |\n|--------------------------|--------------|\n| **Find Document**        | Retrieve a document???s metadata and URL using its ID. |\n\n---\n\n## \uD83D\uDCDA API Reference\n\n- [PDFMonkey API Documentation](https://docs.pdfmonkey.io/references/api/documents)\n\n---\n\n## \uD83E\uDDEA Test Account Access\n\n- You can test PDFMonkey APIs by signing up at [PDFMonkey](https://pdfmonkey.io/) and creating a workspace and templates for document generation.\n\n---\n\n## \uD83E\uDDD1???\uD83D\uDCBB New to Activepieces?\n\nActivepieces is the leading open source AI automation platform. We have many apps (we call them Pieces), that are available within the builder and as MCPs. These apps are build with our TypeScript framework and are easy to build. Once they're merged to our repo, they will available as pieces in our automation builder and as MCPs to be used with AI agents and MCP clients.\n\nWe welcome contributions and in fact, we get excited over them. Start your journey here: https://www.activepieces.com/docs/developers/building-pieces/overview\n",
      "updatedAt" : 1753368149.000000000,
      "user" : "kishanprmr",
      "userHtmlUrl" : "https://github.com/kishanprmr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/135701940?v=4",
      "labels" : [ "$30", "\uD83D\uDC8E Bounty", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "<p><a href=\"https://linear.app/activepieces/issue/AP-845/mcp-pdfmonkey\">AP-845 [MCP] PDFMonkey</a></p>", "/bounty $30", "## \uD83D\uDC8E $30 bounty [??? Activepieces (YC S22)](https://algora.io/activepieces)\n### Steps to solve:\n1. **Start working**: Comment `/attempt #8476` with your implementation plan\n2. **Submit work**: Create a pull request including `/claim #8476` in the PR body to claim the bounty\n3. **Receive payment**: 100% of the bounty is received 2-5 days post-reward. [Make sure you are eligible for payouts](https://algora.io/docs/payments#supported-countries-regions)\n\n### ??? Important guidelines:\n- \uD83D\uDD0D Before starting, please check if someone is already working on the bounty by reviewing existing comments and pull requests to avoid duplicated efforts. Only one pull request will be merged per bounty, based on overall quality, completeness, adherence to guidelines, and maintainability of the code.\n- To claim a bounty, you need to **provide a short demo video** of your changes in your pull request\n- If anything is unclear, **ask for clarification** before starting as this will help avoid potential rework\n- Low quality AI PRs will not receive review and will be closed\n- Do not ask to be assigned unless you've contributed before\n\nThank you for contributing to activepieces/activepieces!\n\n| Attempt | Started (UTC) | Solution | Actions |\n| --- | --- | --- | --- |\n| \uD83D\uDFE2 @Sanket6652 | Jul 23, 2025, 09:13:04 AM | #8481 | [Reward](https://algora.io/claims/DXXLCqRM5SRvZNhj) |\n| \uD83D\uDFE2 @privatestefans | Jul 23, 2025, 01:04:44 PM | #8484 | [Reward](https://algora.io/claims/jFDv7D5BZSA8TL9x) |", "/attempt #8476" ],
      "repository" : {
        "description" : "AI Agents & MCPs & AI Workflow Automation ??? (280+ MCP servers for AI agents) ??? AI Automation / AI Agent with MCPs ??? AI Workflows & AI Agents ??? MCPs for AI Agents",
        "homepage" : "https://www.activepieces.com",
        "name" : "activepieces",
        "fullName" : "activepieces/activepieces",
        "htmlUrl" : "https://github.com/activepieces/activepieces",
        "gitUrl" : "git://github.com/activepieces/activepieces.git",
        "sshUrl" : "git@github.com:activepieces/activepieces.git",
        "cloneUrl" : "https://github.com/activepieces/activepieces.git",
        "owner" : {
          "login" : "activepieces",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2245,
        "stargazersCount" : 15953,
        "watchersCount" : 15953,
        "size" : 303244,
        "openIssuesCount" : 395,
        "subscribersCount" : 99,
        "pushedAt" : "2025-07-24T23:50:49Z",
        "languages" : {
          "TypeScript" : 14822092,
          "MDX" : 6121,
          "Smarty" : 1832,
          "Dockerfile" : 4373,
          "CSS" : 72085,
          "Shell" : 3862,
          "JavaScript" : 14477,
          "HTML" : 212991
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Integrate PDFMonkey with Activepieces to enable workflows and AI agents to generate and manage PDFs automatically.",
      "validationOrRequirement" : "The feature must be submitted as a Piece following the Activepieces architecture, and contributors must review the Piece Development Guidelines before starting development.",
      "attemptedFixes" : "Some attempts have been made by @Sanket6652 and @privatestefans, but no solution has been provided yet.",
      "otherNotes" : "The issue is about integrating PDFMonkey with Activepieces, a document automation service that generates PDFs from templates and structured data. The feature must be submitted as a Piece following the Activepieces architecture. There are some important guidelines for contributors, such as providing a short demo video of their changes in the pull request and not asking to be assigned unless they've contributed before.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407611
  }, {
    "issueDTO" : {
      "id" : 2941551852,
      "title" : "Implement escaping for keyword separators",
      "url" : "https://github.com/JabRef/jabref/issues/12810",
      "repositoryName" : "JabRef/jabref",
      "description" : "Context: https://github.com/JabRef/jabref/issues/12532#issuecomment-2743855961\n\nJabRef does not support `\\` to be used as escaping for the keyword separator\n\nTask:\n\n1. Add test cases for `\\,` in org.jabref.model.entry.KeywordListTest\n2.  Adapt `org.jabref.model.entry.KeywordList#parse(java.lang.String, java.lang.Character, java.lang.Character)` to implement the escaping \n\n---\n\nThere is code proposed - with good test cases https://github.com/JabRef/jabref/pull/12888/files#diff-405010f9d24d966c1c8d319857c458e7a81761922448a5ff981e645d4ad43efc.\n\nHowever, the review comments were not addressed. --> When working on this address https://github.com/JabRef/jabref/pull/12888#discussion_r2030256080\n",
      "updatedAt" : 1753368071.000000000,
      "user" : "koppor",
      "userHtmlUrl" : "https://github.com/koppor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1366654?v=4",
      "labels" : [ "\uD83D\uDCCC Pinned", "good first issue", "\uD83D\uDCCD Assigned", "\uD83D\uDD14 reminder-sent" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I am new to Opensource. I want to start my work on this. Can I work on this?\n", "/assign-me", "\uD83D\uDC4B Hey @krishnagjsForGit, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80\n\n??? Please note, you will be automatically unassigned if there is not a (draft) pull request within **14 days** (by **07 April 2025**).", "Kindly Find the PR : https://github.com/krishnagjsForGit/jabref/pull/1", "I'm working on this issue. Please assign it to me. PR: #12810\n\n", "### ?????? Issue Already Assigned\n\nHi @Rajas55, this issue is currently assigned to @krishnagjsForGit.\n\n> [!NOTE]\n> If no progress is made within **14 days**, the issue will be automatically unassigned.\n\n<details>\n<summary>Options for contributors</summary>\n\n- **Wait for availability**: The issue may become available if auto-unassigned\n- **Collaborate**: You can ask the assignee if they want help\n- **Maintainer assistance**: A maintainer can add you as co-assignee if appropriate\n</details>", "PR opened to fix this in [#12833](https://github.com/JabRef/jabref/pull/12833). Please review when possible \uD83D\uDE42", "> PR opened to fix this in [#12833](https://github.com/JabRef/jabref/pull/12833). Please review when possible \uD83D\uDE42\n\n\nAlready issue is being worked upon. And PR review is on progress. Why duplicate the efforts?\n", "> PR opened to fix this in [#12833](https://github.com/JabRef/jabref/pull/12833). Please review when possible \uD83D\uDE42\n\nWrong link. Please link the issue from the PR", "> PR opened to fix this in [#12833](https://github.com/JabRef/jabref/pull/12833). Please review when possible \uD83D\uDE42\n\nWrong link. Please link the issue from the PR", "> PR opened to fix this in [#12833](https://github.com/JabRef/jabref/pull/12833). Please review when possible \uD83D\uDE42\n\n@Rajas55 Are you not able to read that someone else is assigned and working on this issue already?", "Hi! I'm a beginner in open source and Java, and I'd like to work on this issue as my first contribution. Can I take this up?\n", "> Hi! I'm a beginner in open source and Java, and I'd like to work on this issue as my first contribution. Can I take this up?\n\nHi, welcome to JabRef. Unfortunately, @krishnagjsForGit is already assigned to the issue. You can check if an issue is assigned to somebody by looking at the right side column:\n\n![Image](https://github.com/user-attachments/assets/4525e39a-5b53-4e3a-b368-61f084eafd7c)\n\nYou may pick any other first issue you like.", "I am new to this project, Can you assign me some task.", "### ?????? Issue Already Assigned\n\nHi @kirthi76, this issue is currently assigned to @krishnagjsForGit.\n\n> [!NOTE]\n> If no progress is made within **14 days**, the issue will be automatically unassigned.\n\n<details>\n<summary>Options for contributors</summary>\n\n- **Wait for availability**: The issue may become available if auto-unassigned\n- **Collaborate**: You can ask the assignee if they want help\n- **Maintainer assistance**: A maintainer can add you as co-assignee if appropriate\n</details>", "I saw the pr by @krishnagjsForGit just now. We should review it. @kirthi76 you can also review...", "Hi! this would be my first OpenSource Project, I would love to take on this one.", "/assign-me\n", "\uD83D\uDC4B Hey @miguel-cordoba, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80", "### ??? Assignment Reminder\n\nHi @miguel-cordoba, this is a friendly reminder about your assignment to this issue.\n\n> [!WARNING]\n> This issue will be **automatically unassigned** in **11 days** if there's no activity.\n\nRemember that you can ask the [JabRef Guru](https://gurubase.io/g/jabref) or [DeepWiki](https://deepwiki.com/JabRef/jabref) about anything regarding JabRef.\nAdditionally, our contributing guide has [hints on creating a pull request](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md#pull-request-process) and a link to our Gitter chat.\n\n<details open>\n<summary>How to keep your assignment</summary>\n\n\\\nIf you are working on it, you can prevent automatic unassignment by:\n\n- Submitting a [draft pull request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests#draft-pull-requests) with your progress within 11 days\n- Asking for the **\uD83D\uDCCC Pinned** label if you need more time\n</details>\n\nWe appreciate your contribution and are here to help if needed!" ],
      "repository" : {
        "description" : "Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases",
        "homepage" : "https://www.jabref.org",
        "name" : "jabref",
        "fullName" : "JabRef/jabref",
        "htmlUrl" : "https://github.com/JabRef/jabref",
        "gitUrl" : "git://github.com/JabRef/jabref.git",
        "sshUrl" : "git@github.com:JabRef/jabref.git",
        "cloneUrl" : "https://github.com/JabRef/jabref.git",
        "owner" : {
          "login" : "JabRef",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2881,
        "stargazersCount" : 3953,
        "watchersCount" : 3953,
        "size" : 249443,
        "openIssuesCount" : 578,
        "subscribersCount" : 112,
        "pushedAt" : "2025-07-24T20:20:03Z",
        "languages" : {
          "PowerShell" : 2037,
          "Java" : 11269860,
          "CSS" : 74176,
          "TeX" : 758587,
          "AppleScript" : 1721,
          "XSLT" : 151843,
          "Just" : 1194,
          "Shell" : 9305,
          "Batchfile" : 637,
          "ANTLR" : 9176,
          "BibTeX Style" : 78034,
          "Ruby" : 507,
          "Python" : 22282
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement escaping for keyword separators in JabRef",
      "validationOrRequirement" : "The issue requires adding test cases for `\textbackslash,` in `org.jabref.model.entry.KeywordListTest`, and adapting the `org.jabref.model.entry.KeywordList#parse` method to implement the escaping. The issue also has specific guidelines for contributors, including exploring the contributing guidelines, setting up a local workspace, and opening a pull request early on.",
      "attemptedFixes" : "There are multiple pull requests related to this issue, including #12833, #12810, and #12888. These pull requests are trying to implement the escaping for keyword separators, but they need to be reviewed and addressed.",
      "otherNotes" : "The issue is about implementing escaping for keyword separators in JabRef, and it is already being worked upon by @krishnagjsForGit. There are multiple pull requests related to this issue, and the assignee is asked to review them. The issue has specific requirements, such as adding test cases and adapting the `org.jabref.model.entry.KeywordList#parse` method. There are also some comments and reminders about the issue, including a warning about automatic unassignment if there is no activity.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407619
  }, {
    "issueDTO" : {
      "id" : 2294547352,
      "title" : "Display language information to pois",
      "url" : "https://github.com/digitalfabrik/integreat-app/issues/2794",
      "repositoryName" : "digitalfabrik/integreat-app",
      "description" : "### Motivation\r\nIn our target group interviews, we (= target group team) got the input, that end users are insecure about going to pois, because they do not know if the language they know are spoken there. As which language is spoken is very different for every location, we want a text field, and hope the cms users will fill it with, e.g. \"on thursday afternoon russian, on other days only german an englisch\", or similar.\r\n\r\n\r\n### Proposed Solution\r\n<!-- A clear and concise description of the feature you would like to add, and how it solves the motivating problem. -->\r\nShow the text that can be entered in the cms for every poi containing information about languages in web and native.\r\n\r\n### Alternatives\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, and why you're proposed solution is better. -->\r\nWe discussed if we just tell the cms users to add this information to the description field, but having this field is a constant reminder and as it is a important feature for the target group, we decided adding this field is the best way to go.\r\n\r\n### User Story\r\n<!-- A clear description of the User Stories that should be achieved by the new feature. The User Stories should follow this pattern:-->\r\nAs a app user I want know if at a poi my language is spoken so that I know if it is worth for me to go there.\r\n\r\n### Additional Context\r\n<!-- Add any other information or screenshots about the feature request here. -->\r\nSee: https://openproject.tuerantuer.org/projects/community-feedback/work_packages/3231/activity\r\n\r\n### Design Requirements\r\n<!-- If the customization includes input from our design team, the detailed requirements will be collected here. Note: These will exist mainly in German to simplify internal communication. -->\r\nNone.\r\n\r\nblocked by https://github.com/digitalfabrik/integreat-cms/issues/2799",
      "updatedAt" : 1753368015.000000000,
      "user" : "ztefanie",
      "userHtmlUrl" : "https://github.com/ztefanie",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18463686?v=4",
      "labels" : [ "Native", "Task", "blocked", "Web", "waiting-for-cms", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Duplicated in https://github.com/digitalfabrik/integreat-app/issues/2822 (might have additional information).", "As discussed with @osmers in https://github.com/digitalfabrik/integreat-cms/issues/2799, the CMS team doesn't have this on their roadmap for the next three months but might implement the API endpoint returning an undefined soon-ish so that we can already work with that. The CMS can then implement the actual adding of languages later on; this would have the advantage of the municipalities being able to see their changes immediately in the app.", "Design is ready and can be found [\uD83D\uDCCC here](https://www.figma.com/design/cA4F2MwHs2LNGviOWUjfE9/Integreat-Tickets-Frontend?node-id=4935-882&t=kGFrHSyaGLrKSPlZ-1). Let me know your thoughts @steffenkleinle @LeandraH ", "LGTM", "Me too, thank you!" ],
      "repository" : {
        "description" : "React JS and React Native App for Integreat ",
        "homepage" : "https://integreat.app",
        "name" : "integreat-app",
        "fullName" : "digitalfabrik/integreat-app",
        "htmlUrl" : "https://github.com/digitalfabrik/integreat-app",
        "gitUrl" : "git://github.com/digitalfabrik/integreat-app.git",
        "sshUrl" : "git@github.com:digitalfabrik/integreat-app.git",
        "cloneUrl" : "https://github.com/digitalfabrik/integreat-app.git",
        "owner" : {
          "login" : "digitalfabrik",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 22,
        "stargazersCount" : 50,
        "watchersCount" : 50,
        "size" : 236077,
        "openIssuesCount" : 120,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-24T13:44:31Z",
        "languages" : {
          "TypeScript" : 1891199,
          "CSS" : 8669,
          "Shell" : 5864,
          "JavaScript" : 23452,
          "Objective-C" : 655,
          "Swift" : 8144,
          "Ruby" : 21143,
          "Kotlin" : 12897,
          "EJS" : 7219
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Display language information to pois, so that end users know if the language they know is spoken at a poi, and can decide if it is worth for them to go there",
      "validationOrRequirement" : "The CMS team doesn't have this on their roadmap for the next three months, but the API endpoint returning an undefined might be implemented soon-ish",
      "attemptedFixes" : "Design is ready and can be found here: https://www.figma.com/design/cA4F2MwHs2LNGviOWUjfE9/Integreat-Tickets-Frontend?node-id=4935-882&t=kGFrHSyaGLrKSPlZ-1",
      "otherNotes" : "The CMS team doesn't have this on their roadmap for the next three months, but the API endpoint returning an undefined might be implemented soon-ish, allowing municipalities to see changes immediately in the app.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407625
  }, {
    "issueDTO" : {
      "id" : 2587941890,
      "title" : "Update chart token colors system",
      "url" : "https://github.com/balancer/frontend-monorepo/issues/56",
      "repositoryName" : "balancer/frontend-monorepo",
      "description" : null,
      "updatedAt" : 1753367663.000000000,
      "user" : "garethfuller",
      "userHtmlUrl" : "https://github.com/garethfuller",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2406506?v=4",
      "labels" : [ "UX improvement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "cc @uiuxxx ", "**The problem:**\n\nCurrently the colors in the pool composition chart on the pool detail page don't reflect the colors of the tokens within the pool. This results in all pools having the same random colored charts, which are not intuitive or meaningful. \n\n**The solution:**\n\nCreate a system to enable us to assign colors to the most popular tokens, which will then be reflected in the pool composition chart whenever the token is within a pool. \n\n**The task:**\n\n- Create a system to assign colors to the most popular tokens. \n- I have assigned colors to some of the most popular tokens below. \n  - This system uses a linear-gradient system for future flexibility. Note: Right now, there is no visible gradient in any of these, since the from and to are the same colors. \n- So essentially, use the linear gradients in the code below to create a system to display these colors when a token is in a pool. \n- If the token is not defined in the list, assign a random color from the already defined colors in `PoolWeightChart.ts) (see screenshot below)\n\nExample `token-colors.ts` file:\n\n\n```\nimport { GqlChain, GqlToken } from '@/lib/shared/services/api/generated/graphql'\n\nconst tokenColors: Record<GqlChain, Record<string, string>> = {\n  [GqlChain.Mainnet]: {\n    '0xeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee':\n      'linear-gradient(180deg, #627EEA 0%, #627EEA 100%)', // 'ETH',\n    '0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2': 'linear-gradient(180deg, # 0%, # 100%)', // 'WETH',\n    '0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48':\n      'linear-gradient(180deg, #2775CA 0%, #2775CA 100%)', // 'USDC',\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #F5AC37 0%, #F5AC37 100%)', // 'DAI',\n    '0xdAC17F958D2ee523a2206206994597C13D831ec7':\n      'linear-gradient(180deg, #50AF95 0%, #50AF95 100%)', // 'USDT',\n    '0x2260FAC5E5542a773Aa44fBCfeDf7C193bc2C599':\n      'linear-gradient(180deg, #F09242 0%, #F09242 100%)', // 'WBTC',\n    '0xba100000625a3754423978a60c9317c58a424e3D':\n      'linear-gradient(180deg, #E7DEBD 0%, #E7DEBD 100%)', // 'BAL',\n    '0xc0c293ce456ff0ed870add98a0828dd4d2903dbf':\n      'linear-gradient(180deg, #8C43D2 0%, #8C43D2 100%)', // 'AURA',\n    '0x616e8bfa43f920657b3497dbf40d6b1a02d4608d':\n      'linear-gradient(180deg, #AB60F3 0%, #AB60F3 100%)', // 'auraBAL',\n    '0x5c6ee304399dbdb9c8ef030ab642b10820db8f56':\n      'linear-gradient(180deg, #D7B554 0%, #D7B554 100%)', // 'B-80BAL-20WETH',\n    '0x7f39c581f595b53c5cb19bd0b3f8da6c935e2ca0':\n      'linear-gradient(180deg, #00A3FF 0%, #00A3FF 100%)', // 'wstETH',\n    '0xae78736cd615f374d3085123a210448e74fc6393':\n      'linear-gradient(180deg, #FF6E2F 0%, #FF6E2F 100%)', // 'rETH',\n    '0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9':\n      'linear-gradient(180deg, #9996FD 0%, #9996FD 100%)', // 'AAVE',\n    '0xbf5495efe5db9ce00f80364c8b423567e58d2110':\n      'linear-gradient(180deg, #ACE731 0%, #ACE731 100%)', // 'ezETH',\n    '0xe07f9d810a48ab5c3c914ba3ca53af14e4491e8a':\n      'linear-gradient(180deg, #F0FF9B 0%, #F0FF9B 100%)', // 'GYD',\n    '0x6810e776880c02933d47db1b9fc05908e5386b96':\n      'linear-gradient(180deg, #3E6957 0%, #3E6957 100%)', // 'GNO',\n    '0x40d16fc0246ad3160ccc09b8d0d3a2cd28ae6c2f':\n      'linear-gradient(180deg, #C8B5F2 0%, #C8B5F2 100%)', // 'GHO',\n  },\n  [GqlChain.Arbitrum]: {\n    '0xFF970A61A04b1cA14834A43f5de4533eBDDB5CC8':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // USDC\n    '0x82af49447d8a07e3bd95bd0d56f35241523fbab1':\n      'linear-gradient(180deg, #33FF57 0%, #33FF57 100%)', // WETH\n    '0x2f2a2543b76a4166549f7aab2e75bef0aefc5b0f':\n      'linear-gradient(180deg, #3357FF 0%, #3357FF 100%)', // WBTC\n    '0x912CE59144191C1204E64559FE8253a0e49E6548':\n      'linear-gradient(180deg, #FF33A1 0%, #FF33A1 100%)', // ARB\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #A133FF 0%, #A133FF 100%)', // DAI\n  },\n  [GqlChain.Base]: {\n    '0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606EB48':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // USDC\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #33FF57 0%, #33FF57 100%)', // DAI\n    '0x853d955aCEf822Db058eb8505911ED77F175b99e':\n      'linear-gradient(180deg, #3357FF 0%, #3357FF 100%)', // FRAX\n    '0x5A98FcBEA516Cf06857215779Fd812CA3beF1B32':\n      'linear-gradient(180deg, #FF33A1 0%, #FF33A1 100%)', // LDO\n  },\n  [GqlChain.Avalanche]: {\n    '0xB31f66AA3C1e785363F0875A1B74E27b85FD66c7':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // WAVAX\n    '0xA7D7079b0FEAD91F3e65f86E8915Cb59c1a4C664':\n      'linear-gradient(180deg, #33FF57 0%, #33FF57 100%)', // USDC.e\n    '0xB97EF9Ef8734C71904D8002F8b6Bc66Dd9c48a6E':\n      'linear-gradient(180deg, #3357FF 0%, #3357FF 100%)', // USDC\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #FF33A1 0%, #FF33A1 100%)', // DAI\n  },\n  [GqlChain.Fantom]: {\n    '0x04068DA6C83AFCFA0e13ba15A6696662335D5B75':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // USDC\n    '0x8D11eC38a3EB5E956B052f67Da8Bdc9bef8Abf3E':\n      'linear-gradient(180deg, #33FF57 0%, #33FF57 100%)', // DAI\n    '0x21be370d5312f44cb42ce377bc9b8a0cef1a4c83':\n      'linear-gradient(180deg, #3357FF 0%, #3357FF 100%)', // WFTM\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #FF33A1 0%, #FF33A1 100%)', // DAI\n  },\n  [GqlChain.Gnosis]: {\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // DAI\n    '0x4e15361fd6b4bb609fa63c81a2be19d873717870':\n      'linear-gradient(180deg, #33FF57 0%, #33FF57 100%)', // FTM\n  },\n  [GqlChain.Optimism]: {\n    '0x4200000000000000000000000000000000000042':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // OP\n    '0x7F5c764cBc14f9669B88837ca1490cCa17c31607':\n      'linear-gradient(180deg, #33FF57 0%, #33FF57 100%)', // USDC\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #3357FF 0%, #3357FF 100%)', // DAI\n  },\n  [GqlChain.Polygon]: {\n    '0x0000000000000000000000000000000000001010':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // MATIC\n    '0x2791Bca1f2de4661ED88A30C99A7a9449Aa84174':\n      'linear-gradient(180deg, #33FF57 0%, #33FF57 100%)', // USDC\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #3357FF 0%, #3357FF 100%)', // DAI\n  },\n  [GqlChain.Zkevm]: {\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // DAI\n  },\n  [GqlChain.Sepolia]: {\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // DAI\n  },\n  [GqlChain.Mode]: {\n    '0x6B175474E89094C44Da98b954EedeAC495271d0F':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // DAI\n  },\n  [GqlChain.Fraxtal]: {\n    '0x853d955aCEf822Db058eb8505911ED77F175b99e':\n      'linear-gradient(180deg, #FF5733 0%, #FF5733 100%)', // FRAX\n  },\n}\n\nexport function getTokenColor(chain: GqlChain, address: string): string | undefined {\n  return tokenColors[chain][address]\n}\n\n```\n\nHere are the fallback colors to use, already defined colors in `PoolWeightChart.ts` which should be used for any tokens not assigned a specific color in the provided code above.\n\n![Image](https://github.com/user-attachments/assets/1e822d99-347f-46b2-b3b7-8477903600b3)\n\n\n\n", "Hi @garethfuller , @uiuxxx , and team \uD83D\uDC4B\n\nIs this issue still active, or has the color???mapping system already been addressed elsewhere?  \nIf it???s still relevant, I???d be happy to take a look and open a PR. \n", "Hi @nicolad \n\nYes, this issue is still active! \n\nWe would apply these token colors in places like the pool composition table within the Pool Detail page, so that would be a good first place for you to apply the new colors.\n\n<img width=\"2754\" height=\"1000\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/34adf1a4-7e0b-4b69-bac0-44b5f699c8d9\" />" ],
      "repository" : {
        "description" : "Balancer frontend apps and packages. Includes the official Balancer web application.",
        "homepage" : "https://balancer.fi",
        "name" : "frontend-monorepo",
        "fullName" : "balancer/frontend-monorepo",
        "htmlUrl" : "https://github.com/balancer/frontend-monorepo",
        "gitUrl" : "git://github.com/balancer/frontend-monorepo.git",
        "sshUrl" : "git@github.com:balancer/frontend-monorepo.git",
        "cloneUrl" : "https://github.com/balancer/frontend-monorepo.git",
        "owner" : {
          "login" : "balancer",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 21,
        "watchersCount" : 21,
        "size" : 108448,
        "openIssuesCount" : 71,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T18:42:20Z",
        "languages" : {
          "TypeScript" : 4630914,
          "CSS" : 13282,
          "JavaScript" : 8940
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update the chart token colors system to reflect the colors of the tokens within the pool, and make it more intuitive and meaningful.",
      "validationOrRequirement" : "Create a system to assign colors to the most popular tokens, and use the linear gradients in the code to create a system to display these colors when a token is in a pool. If the token is not defined in the list, assign a random color from the already defined colors in `PoolWeightChart.ts`.",
      "attemptedFixes" : "The task is to create a system to assign colors to the most popular tokens, and use the linear gradients in the code to create a system to display these colors when a token is in a pool.",
      "otherNotes" : "The issue is about updating the chart token colors system, currently the colors in the pool composition chart on the pool detail page don't reflect the colors of the tokens within the pool, aiming to create a system to enable us to assign colors to the most popular tokens, and use the linear gradients in the code to create a system to display these colors when a token is in a pool. If the token is not defined in the list, assign a random color from the already defined colors in `PoolWeightChart.ts`.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407634
  }, {
    "issueDTO" : {
      "id" : 3251142645,
      "title" : "The logo should redirect to Home page",
      "url" : "https://github.com/itsAnimation/AnimateItNow/issues/33",
      "repositoryName" : "itsAnimation/AnimateItNow",
      "description" : "When clicked on the logo of the project, it should redirect to home page.\n\nhttps://github.com/user-attachments/assets/bced9837-0263-41cb-81c9-c43cce7ed555\n\n\nAssign this issue to me, i would like to work on this.\n\n",
      "updatedAt" : 1753367644.000000000,
      "user" : "sj11105",
      "userHtmlUrl" : "https://github.com/sj11105",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/127857736?v=4",
      "labels" : [ "gssoc25", "level1", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "ok @sj11105 Assigning to you , make it fix for all pages of our project.", "Hi! I'm a GSSoC '25 contributor and would love to work on this issue. Please assign it to me!\n", "Hi @TanishaKesarkar , same here even I am GSSoC'25 contributor ", "I noticed the project list and\nwants to contribute to this project.\nWould you please assign this to me?", "@DivyaJain-DataAnalyst , even I want to contribute to this project , check on the website you will get other issues to raise ", "@sj11105 can I start this?", "I have completed this already , will be raising the PR now ", "Hi I'm Mrunal GSSOC'25 contributer! I'm interested in this task. Could you please assign it to me?\n", "I am Rajshree and would like to work on this under gssoc.Please assign me.", "Hey, I have already raised a PR for this issue." ],
      "repository" : {
        "description" : null,
        "homepage" : "https://animate-it-now.netlify.app/",
        "name" : "AnimateItNow",
        "fullName" : "itsAnimation/AnimateItNow",
        "htmlUrl" : "https://github.com/itsAnimation/AnimateItNow",
        "gitUrl" : "git://github.com/itsAnimation/AnimateItNow.git",
        "sshUrl" : "git@github.com:itsAnimation/AnimateItNow.git",
        "cloneUrl" : "https://github.com/itsAnimation/AnimateItNow.git",
        "owner" : {
          "login" : "itsAnimation",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 149,
        "stargazersCount" : 43,
        "watchersCount" : 43,
        "size" : 6051,
        "openIssuesCount" : 132,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T22:17:11Z",
        "languages" : {
          "CSS" : 30008,
          "JavaScript" : 5805,
          "HTML" : 181155
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The logo should redirect to the home page when clicked.",
      "validationOrRequirement" : "Redirect the logo to the home page for all pages of the project.",
      "attemptedFixes" : "The issue has already been fixed, with a PR to be raised.",
      "otherNotes" : "Multiple contributors have shown interest in working on this issue, including GSSoC '25 contributors. One contributor has already completed the task and will be raising a PR.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407637
  }, {
    "issueDTO" : {
      "id" : 2616362277,
      "title" : "Replace MeshMap icons to new Kanvas logo",
      "url" : "https://github.com/layer5io/layer5/issues/6032",
      "repositoryName" : "layer5io/layer5",
      "description" : "### Current Behavior\r\nOld MeshMap icon is present in the navigation menu\r\n![Screenshot from 2024-10-26 20-47-56](https://github.com/user-attachments/assets/7506585f-2450-436b-b9bf-506b4a88551e)\r\n\r\n\r\n### Desired Behavior\r\nReplace the old icon with new Kanvas hexagonal design in navigation menu.\r\nNOTE : The Kanvas brand kit has been uploaded to [layer5.io/brand](http://layer5.io/brand). It???s also available in the community [shared drive](https://drive.google.com/drive/folders/111gQwmZaA16xZ-gJiH3VPw2UuJJNV7sw?usp=share_link).\r\n\r\n![Screenshot from 2024-10-26 20-54-33](https://github.com/user-attachments/assets/09949e73-7ddb-4548-a1f7-16147c5157b0)\r\n\r\n\r\n\r\n### Screenshots / Mockups\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\r\n### Implementation\r\n<!-- Specifics on the approach to fulfilling the feature request. -->\r\n\r\n### Acceptance Tests\r\n<!-- Stipulations of functional behavior or non-functional items that must be in-place in order for the issue to be closed. -->\r\n\r\n---\r\n<img src=\"https://raw.githubusercontent.com/layer5io/layer5/master/.github/assets/images/layer5/5-light-small.svg\" width=\"24px\" align=\"left\" /><h2>Contributor Resources and <a href=\"https://layer5.io/community/handbook\">Handbook</a></h2>\r\n\r\nThe layer5.io website uses Gatsby, React, and GitHub Pages. Site content is found under the [`master` branch](https://github.com/layer5io/layer5/tree/master).\r\n- \uD83D\uDCDA See [contributing instructions](https://github.com/layer5io/layer5/blob/master/CONTRIBUTING.md).\r\n-  \uD83C\uDFA8 Wireframes and [designs for Layer5 site](https://www.figma.com/file/5ZwEkSJwUPitURD59YHMEN/Layer5-Designs) in Figma [(open invite)](https://www.figma.com/team_invite/redeem/qJy1c95qirjgWQODApilR9)\r\n- \uD83D\uDE4B\uD83C\uDFFE\uD83D\uDE4B\uD83C\uDFFC Questions: [Discussion Forum](https://discuss.layer5.io) and [Community Slack](https://slack.layer5.io).\r\n\r\n<img src=\"https://raw.githubusercontent.com/layer5io/layer5/master/.github/assets/images/buttons/community.webp\" height=\"22px\" align=\"left\" />Join the Layer5 Community by submitting your [community member form](https://layer5.io/newcomer).\r\n",
      "updatedAt" : 1753367632.000000000,
      "user" : "Tharanishwaran",
      "userHtmlUrl" : "https://github.com/Tharanishwaran",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/133676934?v=4",
      "labels" : [ "kind/enhancement", "hacktoberfest", "issue/willfix", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n", "This issue is being automatically closed due to inactivity. However, you may choose to reopen this issue.\n", "@vishalvivekm @LibenHailu What is the status of the issue? Can i work on this?", "Hi @Nidhish-07, Thank you for volunteering, I assume @Tharanishwaran  is working on it if not we will be able to assign you.", "Thank you for your interest, @Nidhish-07! I???m currently not working on this issue actively. You're welcome to take it up. I???m assigning it to you now.", "Hi @Tharanishwaran \uD83D\uDC4B\nI'd love to work on this issue. Could you please assign it to me?\nI???ll follow the contributing guidelines and make sure the design matches the new Kanvas branding.\n", "Hi @Patilpradnesh, sure please go ahead." ],
      "repository" : {
        "description" : "Layer5, expect more from your infrastructure",
        "homepage" : "https://layer5.io",
        "name" : "layer5",
        "fullName" : "layer5io/layer5",
        "htmlUrl" : "https://github.com/layer5io/layer5",
        "gitUrl" : "git://github.com/layer5io/layer5.git",
        "sshUrl" : "git@github.com:layer5io/layer5.git",
        "cloneUrl" : "https://github.com/layer5io/layer5.git",
        "owner" : {
          "login" : "layer5io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1365,
        "stargazersCount" : 937,
        "watchersCount" : 937,
        "size" : 11706603,
        "openIssuesCount" : 139,
        "subscribersCount" : 24,
        "pushedAt" : "2025-07-25T00:29:58Z",
        "languages" : {
          "MDX" : 3549387,
          "Dockerfile" : 679,
          "CSS" : 19435,
          "Shell" : 167,
          "Makefile" : 1647,
          "JavaScript" : 13729809,
          "HTML" : 345971
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Replace MeshMap icons to new Kanvas logo, replacing the old icon with the new Kanvas hexagonal design in the navigation menu.",
      "validationOrRequirement" : "Replace the old MeshMap icon with the new Kanvas hexagonal design in the navigation menu.",
      "attemptedFixes" : "The issue was attempted to be closed due to inactivity, but was reopened by the author.",
      "otherNotes" : "The issue has been automatically marked as stale and will be closed if no further activity occurs. It has also been closed due to inactivity, but can be reopened.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407641
  }, {
    "issueDTO" : {
      "id" : 2558901290,
      "title" : "[Bug] authdelegator CRB creation race condition",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/898",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\r\nBugs should be filed for issues encountered whilst operating mariadb-operator.\r\nPlease provide as much detail as possible. \r\n-->\r\n\r\n**Documentation**\r\n- [ x] I acknowledge that I have read the relevant [documentation](https://github.com/mariadb-operator/mariadb-operator/tree/main/docs).\r\n\r\n**Describe the bug**\r\n<!--\r\nA clear and concise description of what the bug is. \r\nTip: you can use \r\nfor code blocks of your kubectl output or YAML files.\r\n-->\r\n\r\nWhen creating a new cluster on a fresh namespace, this event is _sometimes_ fired once.\r\n\r\n```\r\nownerRef [k8s.mariadb.com/v1alpha1/MariaDB, namespace: , name: mariadb, uid: f6f292f3-62ac-4803-82c4-9268b9a9ef84] does not exist in namespace \"\"\r\n```\r\n\r\nIt looks like a race condition, the CRB creation should occurs after the MariaDB resource is available.\r\n",
      "updatedAt" : 1753367482.000000000,
      "user" : "vixns",
      "userHtmlUrl" : "https://github.com/vixns",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/727336?v=4",
      "labels" : [ "bug", "rbac", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This issue is stale because it has been open 60 days with no activity.", "not stale", "This issue is stale because it has been open 60 days with no activity.", "This issue was closed because it has been stalled for 30 days with no activity.", "not stale, but cannot reopen", "This issue is stale because it has been open 60 days with no activity.", "This issue was closed because it has been stalled for 30 days with no activity." ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The issue is about a race condition in the authdelegator when creating a new cluster on a fresh namespace, where the ownerRef does not exist in the namespace.",
      "validationOrRequirement" : "The CRB creation should occur after the MariaDB resource is available.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "This issue was closed because it has been stalled for 30 days with no activity, but cannot be reopened.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407644
  }, {
    "issueDTO" : {
      "id" : 3057097298,
      "title" : "FE: Consumer lag = 0 when server returns null",
      "url" : "https://github.com/kafbat/kafka-ui/issues/1071",
      "repositoryName" : "kafbat/kafka-ui",
      "description" : "### Issue submitter TODO list\n\n- [x] I've looked up my issue in [FAQ](https://ui.docs.kafbat.io/faq/common-problems)\n- [x] I've searched for an already existing issues [here](https://github.com/kafbat/kafka-ui/issues)\n- [x] I've tried running `main`-labeled docker image and the issue still persists there\n- [x] I'm running a supported version of the application which is listed [here](https://github.com/kafbat/kafka-ui/blob/main/.github/SECURITY.md)\n\n### Describe the bug (actual behavior)\n\nConsumer Lag shows 0 when response from server is null. Bring back from [this](https://github.com/provectus/kafka-ui/issues/4144).\n\n![Image](https://github.com/user-attachments/assets/452f1c62-25f9-46b9-82b1-5d6eab78cb6c)\n\n### Expected behavior\n\nThis should be N/A as I understand because in the list of consumers, it is N/A\n\n![Image](https://github.com/user-attachments/assets/5d161313-ce33-4a92-92cb-1d52c341e71a)\n\n### Your installation details\n\nDocker ghcr.io/kafbat/kafka-ui latest\n\n### Steps to reproduce\n\n- Create topic, producer and consumer\n- Send a message\n- Check the Consumer Lag in consumer detail\n\n### Screenshots\n\n_No response_\n\n### Logs\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753367451.000000000,
      "user" : "quangdutran",
      "userHtmlUrl" : "https://github.com/quangdutran",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/10993669?v=4",
      "labels" : [ "type/bug", "status/triage/completed", "scope/frontend", "good first issue", "area/consumers" ],
      "state" : "OPEN",
      "comments" : [ "Hi quangdutran! \uD83D\uDC4B\n\nWelcome, and thank you for opening your first issue in the repo!\n\nPlease wait for triaging by our maintainers.\n\nAs development is carried out in our spare time, you can support us by sponsoring our activities or even funding the development of specific issues.\n[Sponsorship link](https://github.com/kafbat)\n\nIf you plan to raise a PR for this issue, please take a look at our [contributing guide](https://ui.docs.kafbat.io/development/contributing).", "@Haarolean If you think that this bug is valid, I would suggest a fix like this:\n\nInstead of counting as 0 if consumer lag is not set:\n\nhttps://github.com/kafbat/kafka-ui/blob/main/frontend/src/components/ConsumerGroups/Details/ListItem.tsx#L36\n\nI could check if all consumers having null consumer lag then show N/A, consistent with consumer list. What do you think?", "> [@Haarolean](https://github.com/Haarolean) If you think that this bug is valid, I would suggest a fix like this:\n> \n> Instead of counting as 0 if consumer lag is not set:\n> \n> https://github.com/kafbat/kafka-ui/blob/main/frontend/src/components/ConsumerGroups/Details/ListItem.tsx#L36\n> \n> I could check if all consumers having null consumer lag then show N/A, consistent with consumer list. What do you think?\n\nyeah, let's match the logic from the consumer list. Feel free to raise a PR!", "@Haarolean This looked like not being worked upon so tried to fix it in #1217 " ],
      "repository" : {
        "description" : "Open-Source Web UI for managing Apache Kafka clusters",
        "homepage" : "https://kafbat.io",
        "name" : "kafka-ui",
        "fullName" : "kafbat/kafka-ui",
        "htmlUrl" : "https://github.com/kafbat/kafka-ui",
        "gitUrl" : "git://github.com/kafbat/kafka-ui.git",
        "sshUrl" : "git@github.com:kafbat/kafka-ui.git",
        "cloneUrl" : "https://github.com/kafbat/kafka-ui.git",
        "owner" : {
          "login" : "kafbat",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 155,
        "stargazersCount" : 1281,
        "watchersCount" : 1281,
        "size" : 36756,
        "openIssuesCount" : 220,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-24T12:04:48Z",
        "languages" : {
          "TypeScript" : 1257665,
          "Java" : 1608247,
          "Dockerfile" : 1018,
          "ANTLR" : 17012,
          "Gherkin" : 5886,
          "SCSS" : 27,
          "JavaScript" : 3698,
          "HTML" : 1779
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the Consumer Lag showing 0 when the server returns null.",
      "validationOrRequirement" : "The issue submitter has confirmed that they are running a supported version of the application.",
      "attemptedFixes" : "The issue submitter has suggested a fix, which is to check if all consumers having null consumer lag then show N/A, consistent with consumer list.",
      "otherNotes" : "The issue submitter has followed the recommended steps and has searched for existing issues. The issue is related to the Consumer Lag showing 0 when the server returns null.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407648
  }, {
    "issueDTO" : {
      "id" : 2574000682,
      "title" : "[Bug] MariaDB galera recovery job crashes due to missing user=root argument, causing the MariaDB unrecoverable after crash",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/927",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\r\nBugs should be filed for issues encountered whilst operating mariadb-operator.\r\nPlease provide as much detail as possible. \r\n-->\r\n\r\n**Documentation**\r\n- [x] I acknowledge that I have read the relevant [documentation](https://github.com/mariadb-operator/mariadb-operator/tree/main/docs).\r\n\r\n**Describe the bug**\r\n<!--\r\nA clear and concise description of what the bug is. \r\nTip: you can use \r\n```\r\n<code here>\r\n```\r\nfor code blocks of your kubectl output or YAML files.\r\n-->\r\nWe are running the MariaDB with Gelera. After the MariaDB pods crash, the MariaDB operator automatically starts the MariaDB recovery jobs to recover the crashed MariaDB pods.\r\nHowever, the started MariaDB recovery pods also crashed. From the log of the crashed MariaDB recovery jobs, it seems to be related to the securityContext used to start them.\r\n```\r\n??? mariadbd: Please consult the Knowledge Base to find out how to run mysqld as root!                                                                                                                                                                                         ???\r\n??? 2024-10-04 19:48:38 0 [ERROR] Aborting\r\n```\r\n\r\n**Expected behaviour**\r\n<!--A concise description of what you expected to happen.-->\r\nWe expect the MariaDB pods to be able to recover after the restart.\r\n\r\n**Steps to reproduce the bug**\r\n<!--Steps to reproduce the bug should be clear and easily reproducible to help people\r\ngain an understanding of the problem.-->\r\n\r\n1. First create a MariaDB cluster with Galera enabled, and securityContext set to runAsUser: 0\r\n```yaml\r\napiVersion: k8s.mariadb.com/v1alpha1\r\nkind: MariaDB\r\nmetadata:\r\n  name: test-cluster\r\nspec:\r\n  rootEmptyPassword: true\r\n  storage:\r\n    size: 1Gi\r\n    storageClassName: standard\r\n    resizeInUseVolumes: true\r\n    waitForVolumeResize: true\r\n  galera:\r\n    enabled: true\r\n  replicas: 3\r\n  podSecurityContext:\r\n    runAsUser: 0\r\n```\r\n2. Crash the MariaDB pods, and observe that MariaDB recovery pods are created, but crash immediately. For example, in a Kind testing environment, the pod crashes can be simulated using the Chaos-mesh tool with the following commands:\r\n```sh\r\nhelm repo add chaos-mesh https://charts.chaos-mesh.org\r\n\r\nkubectl create ns chaos-mesh\r\n\r\nhelm install chaos-mesh chaos-mesh/chaos-mesh -n=chaos-mesh --set chaosDaemon.runtime=containerd --set chaosDaemon.socketPath=/run/containerd/containerd.sock --version 2.7.0\r\n\r\nkubectl apply -f -<<EOF\r\napiVersion: chaos-mesh.org/v1alpha1\r\nkind: PodChaos\r\nmetadata:\r\n  name: pod-crash-failure-0\r\nspec:\r\n  action: pod-failure\r\n  duration: 30s\r\n  mode: fixed-percent\r\n  selector:\r\n    labelSelectors:\r\n      app.kubernetes.io/instance: test-cluster\r\n    namespaces:\r\n    - default\r\n  value: '100'\r\nEOF\r\n```\r\n\r\n**Debug information**\r\n\r\nCrashed MariaDB pod log:\r\n```\r\n2024-10-04 19:57:31 0 [Note] WSREP: GMCast version 0\r\n2024-10-04 19:57:31 0 [Note] WSREP: (e43e14ed-bec2, 'tcp://0.0.0.0:4567') listening at tcp://0.0.0.0:4567\r\n2024-10-04 19:57:31 0 [Note] WSREP: (e43e14ed-bec2, 'tcp://0.0.0.0:4567') multicast: , ttl: 1\r\n2024-10-04 19:57:31 0 [Note] WSREP: EVS version 1\r\n2024-10-04 19:57:31 0 [Note] WSREP: gcomm: connecting to group 'mariadb-operator', peer 'test-cluster-0.test-cluster-internal.acto-namespace.svc.cluster.local:,test-cluster-1.test-cluster-internal.acto-namespace.svc.cluster.local:,test-cluster-2.test-cluster-internal.acto-namespace.svc.cluster.local:'\r\n2024-10-04 19:57:31 0 [Note] WSREP: (e43e14ed-bec2, 'tcp://0.0.0.0:4567') Found matching local endpoint for a connection, blacklisting address tcp://10.244.2.7:4567\r\n2024-10-04 19:57:31 0 [Note] WSREP: (e43e14ed-bec2, 'tcp://0.0.0.0:4567') connection established to e297589c-adb1 tcp://10.244.4.8:4567\r\n2024-10-04 19:57:31 0 [Note] WSREP: (e43e14ed-bec2, 'tcp://0.0.0.0:4567') connection established to e40ef111-830d tcp://10.244.1.7:4567\r\n2024-10-04 19:57:32 0 [Note] WSREP: EVS version upgrade 0 -> 1\r\n2024-10-04 19:57:32 0 [Note] WSREP: declaring e297589c-adb1 at tcp://10.244.4.8:4567 stable\r\n2024-10-04 19:57:32 0 [Note] WSREP: declaring e40ef111-830d at tcp://10.244.1.7:4567 stable\r\n2024-10-04 19:57:32 0 [Note] WSREP: PC protocol upgrade 0 -> 1\r\n2024-10-04 19:57:32 0 [Warning] WSREP: no nodes coming from prim view, prim not possible\r\n2024-10-04 19:57:32 0 [Note] WSREP: view(view_id(NON_PRIM,e297589c-adb1,3) memb {\r\n        e297589c-adb1,0\r\n        e40ef111-830d,0\r\n        e43e14ed-bec2,0\r\n} joined {\r\n} left {\r\n} partitioned {\r\n})\r\n2024-10-04 19:57:35 0 [Note] WSREP: (e43e14ed-bec2, 'tcp://0.0.0.0:4567') turning message relay requesting off\r\n2024-10-04 19:58:02 0 [ERROR] WSREP: failed to open gcomm backend connection: 110: failed to reach primary view: 110 (Connection timed out)\r\n         at ./gcomm/src/pc.cpp:connect():160\r\n2024-10-04 19:58:02 0 [ERROR] WSREP: ./gcs/src/gcs_core.cpp:gcs_core_open():221: Failed to open backend connection: -110 (Connection timed out)\r\n2024-10-04 19:58:03 0 [ERROR] WSREP: ./gcs/src/gcs.cpp:gcs_open():1681: Failed to open channel 'mariadb-operator' at 'gcomm://test-cluster-0.test-cluster-internal.acto-namespace.svc.cluster.local,test-cluster-1.test-cluster-internal.acto-namespace.svc.cluster.local,test-cluster-2.test-cluster-internal.acto-namespace.svc.cluster.local': -110 (Connection timed out)\r\n2024-10-04 19:58:03 0 [ERROR] WSREP: gcs connect failed: Connection timed out\r\n2024-10-04 19:58:03 0 [ERROR] WSREP: wsrep::connect(gcomm://test-cluster-0.test-cluster-internal.acto-namespace.svc.cluster.local,test-cluster-1.test-cluster-internal.acto-namespace.svc.cluster.local,test-cluster-2.test-cluster-internal.acto-namespace.svc.cluster.local) failed: 7\r\n2024-10-04 19:58:03 0 [ERROR] Aborting\r\n```\r\n\r\nCrashed MariaDB recovery pod log:\r\n```\r\nmariadbd: Please consult the Knowledge Base to find out how to run mysqld as root!\r\n2024-10-04 19:59:00 0 [ERROR] Aborting\r\n```\r\n\r\n**Environment details**:\r\n- Kubernetes version: v1.29.1\r\n- Kubernetes distribution: KIND\r\n- mariadb-operator version: 0.30.0\r\n- Galera agent (sidecar container): N/A\r\n- Install method: helm\r\n- Install flavor: minimal\r\n\r\n**Additional context**\r\n<!--Add any other context  here.-->\r\n\r\nA potential fix is to add `--user=root` when the recovery job has the podSecurityContext of run as root.",
      "updatedAt" : 1753367443.000000000,
      "user" : "kos-team",
      "userHtmlUrl" : "https://github.com/kos-team",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/172315486?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @kos-team ! Thanks for reporting\r\n\r\nRunning as root is not directly supported by the official images: \r\n```yaml\r\n  podSecurityContext:\r\n    runAsUser: 0\r\n``` \r\n\r\nAs the error message says there are extra steps involved:\r\n```bash\r\nmariadbd: Please consult the Knowledge Base to find out how to run mysqld as root!\r\n2024-10-04 19:59:00 0 [ERROR] Aborting\r\n```\r\n\r\nThis makes the `MariaDB` `Pods` crash and therefore the recovery is triggered. \r\n\r\n> A potential fix is to add --user=root when the recovery job has the podSecurityContext of run as root.\r\n\r\nUnfortunately it is not, the image is used by both the `MariaDB` `Pods` and and the recovery `Pods. None of them support directly running as root.\r\n\r\nWhat is your use case for running as root?", "Hi @mmontes11 thanks for the reply. It seems that the MariaDB pods are able to run in the root mode successfully. It is only the recovery job pods which are crashing.\r\n", "also if you set podSecurityContext e.g. to 1000, the startup of an empty volume does not succeed. the directories are created with root rights", "Managed to reproduce with the following  `MariaDB` resource:\r\n\r\n```yaml\r\napiVersion: k8s.mariadb.com/v1alpha1\r\nkind: MariaDB\r\nmetadata:\r\n  name: mariadb-galera\r\nspec:\r\n  rootPasswordSecretKeyRef:\r\n    name: mariadb\r\n    key: root-password\r\n\r\n  storage:\r\n    size: 1Gi\r\n\r\n  replicas: 3\r\n\r\n  galera:\r\n    enabled: true\r\n\r\n  service:\r\n    type: LoadBalancer\r\n    metadata:\r\n      annotations:\r\n        metallb.universe.tf/loadBalancerIPs: 172.18.0.150\r\n\r\n  primaryService:\r\n    type: LoadBalancer\r\n    metadata:\r\n      annotations:\r\n        metallb.universe.tf/loadBalancerIPs: 172.18.0.160\r\n\r\n  secondaryService:\r\n    type: LoadBalancer\r\n    metadata:\r\n      annotations:\r\n        metallb.universe.tf/loadBalancerIPs: 172.18.0.161\r\n\r\n  metrics:\r\n    enabled: true\r\n\r\n  podSecurityContext:\r\n    fsGroup: 0\r\n    runAsGroup: 0\r\n    runAsNonRoot: false\r\n    runAsUser: 0\r\n```\r\n\r\nI can confirm that `MariaDB` `Pods` run without any issue but the recovery `Pods` fail with the following error:\r\n```bash\r\nmariadbd: Please consult the Knowledge Base to find out how to run mysqld as root!\r\n2024-10-23 16:38:32 0 [ERROR] Aborting\r\n```\r\nAs the error suggest, we may need to add `user=root` on an exception basis like the documentation says:\r\n- https://mariadb.com/kb/en/running-mariadbd-as-root/\r\n\r\nContributions are welcome!", "Thanks for the confirmation. We can take a look into the potential fix", "This issue is stale because it has been open 60 days with no activity.", "This issue is stale because it has been open 60 days with no activity.", "This issue is stale because it has been open 60 days with no activity.", "This issue was closed because it has been stalled for 30 days with no activity." ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The MariaDB galera recovery job crashes due to missing user=root argument, causing the MariaDB to be unrecoverable after crash.",
      "validationOrRequirement" : "The MariaDB pods are able to run in the root mode successfully, but the recovery job pods are crashing due to the missing user=root argument.",
      "attemptedFixes" : "The recovery job pods are crashing due to the error message 'mariadbd: Please consult the Knowledge Base to find out how to run mysqld as root!', indicating that running as root is not directly supported by the official images.",
      "otherNotes" : "The issue is related to the MariaDB recovery job pods crashing due to missing user=root argument, causing the MariaDB to be unrecoverable after crash. The potential fix is to add --user=root when the recovery job has the podSecurityContext of run as root.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407655
  }, {
    "issueDTO" : {
      "id" : 3259646380,
      "title" : "Systemd scripts",
      "url" : "https://github.com/apache/airflow/issues/53706",
      "repositoryName" : "apache/airflow",
      "description" : "### Apache Airflow version\n\n3.0.3\n\n### If \"Other Airflow 2 version\" selected, which one?\n\n_No response_\n\n### What happened?\n\nDue to Airflow version update new scripts were created.\nOne of them (airflow-api.service) contains bug:\n\n`ExecStart=/bin/bash -c 'source /home/airflow/airflow_venv/bin/activate && airflow api'`\n\ninstead of \n\n`ExecStart=/bin/bash -c 'source /home/airflow/airflow_venv/bin/activate && airflow api-server'`\n\nAdditionally consistency was broken. New scripts contains Environment settings (variables directy specified in service script) instead of EnvironmentFile (which is better approach especially when some additional env are created by Admin), After clause is changed (currently services not waiting for base services like redis, rabbitmq or postgre).\n\n### What you think should happen instead?\n\n_No response_\n\n### How to reproduce\n\nTry to execute script airflow-api in systemd environment\n\n### Operating System\n\nUbuntu Linux\n\n### Versions of Apache Airflow Providers\n\n_No response_\n\n### Deployment\n\nVirtualenv installation\n\n### Deployment details\n\n_No response_\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [x] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)\n",
      "updatedAt" : 1753367307.000000000,
      "user" : "frodo2000",
      "userHtmlUrl" : "https://github.com/frodo2000",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12542245?v=4",
      "labels" : [ "kind:bug", "area:core", "area:API", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Nice issue for someone to pick up" ],
      "repository" : {
        "description" : "Apache Airflow - A platform to programmatically author, schedule, and monitor workflows",
        "homepage" : "https://airflow.apache.org/",
        "name" : "airflow",
        "fullName" : "apache/airflow",
        "htmlUrl" : "https://github.com/apache/airflow",
        "gitUrl" : "git://github.com/apache/airflow.git",
        "sshUrl" : "git@github.com:apache/airflow.git",
        "cloneUrl" : "https://github.com/apache/airflow.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15362,
        "stargazersCount" : 41230,
        "watchersCount" : 41230,
        "size" : 419309,
        "openIssuesCount" : 1522,
        "subscribersCount" : 763,
        "pushedAt" : "2025-07-24T23:09:06Z",
        "languages" : {
          "Java" : 1443,
          "Jinja" : 76192,
          "CSS" : 15733,
          "Go" : 63158,
          "HTML" : 43330,
          "Jupyter Notebook" : 7288,
          "TypeScript" : 2168833,
          "HCL" : 3786,
          "Dockerfile" : 119789,
          "Shell" : 232889,
          "JavaScript" : 329955,
          "Mako" : 2684,
          "Python" : 42616717
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Update systemd scripts to fix a bug and improve consistency after Apache Airflow version update.",
      "validationOrRequirement" : "Fix the bug in the airflow-api.service script, and restore consistency by using EnvironmentFile instead of directly specifying environment settings.",
      "attemptedFixes" : "None mentioned in the issue description or comments.",
      "otherNotes" : "Apache Airflow version update led to creation of new scripts, including one with a bug. Consistency was also broken, with environment settings specified directly in service scripts instead of using EnvironmentFile.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407658
  }, {
    "issueDTO" : {
      "id" : 2645235228,
      "title" : "\uD83D\uDE80 Feature: Add instruments support for httpx",
      "url" : "https://github.com/traceloop/openllmetry/issues/2283",
      "repositoryName" : "traceloop/openllmetry",
      "description" : "### Which component is this feature for?\n\nAll Packages\n\n### \uD83D\uDD16 Feature description\n\nToday the solution currently supports Instruments.REQUESTS and Instruments.URLLIB3.  Is there any plans to extend the instruments to support HTTPX?\n\n### \uD83C\uDFA4 Why is this feature needed ?\n\nMany libraries that require async support have migrated from requests to httpx.  Providing httpx support natively would extend the use of this library to a larger user base.\n\n### ?????? How do you aim to achieve this?\n\nIdeally, this feature would provide similar ease of configuration as is currently available for Requests.\n\n### \uD83D\uDD04??? Additional Information\n\n_No response_\n\n### \uD83D\uDC40 Have you spent some time to check if this feature request has been raised before?\n\n- [X] I checked and didn't find similar issue\n\n### Are you willing to submit PR?\n\nNone",
      "updatedAt" : 1753367247.000000000,
      "user" : "damianoneill",
      "userHtmlUrl" : "https://github.com/damianoneill",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/15426674?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Definitely @damianoneill! Do you think we should add it always by default?", "@nirga I think the best approach is to behave like REQUESTS since the userbase will likely use them similarly. ", "Hi @nirga,\r\nI'm new to open-source and would love to take this up.", "Sounds good @whoiskrtk2! Let me know if you have any questions. Should be fairly straightforward", "I plan to look into the instrumentation for `requests` and `urllib` and try to port that for `httpx`. It may need some work given that `httpx` supports asyncio and HTTP 2, but should be a good experience. I'll reach out if I get stuck anywhere. Thanks!", "Quick question: isn't it a bit bloated of your package to depend on every package under the sun?", "@haf wdym by \"every package under the sun\"? These are small-footprint packages. Even if we depended on all instrumentations (which we don't) it would have been still a much smaller footprint than a single `numpy` dependency. \nIt's similar to the otel auto-instrumentation package (which also depends on all instrumentations). \n\nDo you experience any issues with that?", "It's not about the LoC you depend on, it's the fact that your package has all these other dependencies which brings the headache. Isn't what you're doing here something for extras? https://stackoverflow.com/questions/52474931/what-is-extra-in-pypi-dependency\n\nEdit: to answer your question. I haven't explicitly experienced any dependency conflict issues with your package no because we only depend on openai and anthropic right now, but you did break our tracing when we installed you, and the API of your package isn't fully composable (it doesn't separate side effecting calls from pure functions)\n\nEdit 2: I would never in my life install an auto-instrumentation package from OT ??? the moment anything isn't working you're ****ed and have no idea where and what to investigate.", "Hi @nirga \nI would love to contribute to this, can I give it a shot?" ],
      "repository" : {
        "description" : "Open-source observability for your LLM application, based on OpenTelemetry",
        "homepage" : "https://www.traceloop.com/openllmetry",
        "name" : "openllmetry",
        "fullName" : "traceloop/openllmetry",
        "htmlUrl" : "https://github.com/traceloop/openllmetry",
        "gitUrl" : "git://github.com/traceloop/openllmetry.git",
        "sshUrl" : "git@github.com:traceloop/openllmetry.git",
        "cloneUrl" : "https://github.com/traceloop/openllmetry.git",
        "owner" : {
          "login" : "traceloop",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 763,
        "stargazersCount" : 6118,
        "watchersCount" : 6118,
        "size" : 36422,
        "openIssuesCount" : 247,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T13:13:04Z",
        "languages" : {
          "Shell" : 183,
          "Python" : 2283005
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add instruments support for httpx to extend the library's user base and provide similar ease of configuration as is currently available for Requests.",
      "validationOrRequirement" : "The author suggests that the feature should be similar to the existing support for Requests, and that the package should not depend on every package under the sun.",
      "attemptedFixes" : "The author suggests porting the instrumentation for requests and urllib to httpx, and mentions that it may require some work due to httpx's support for asyncio and HTTP 2.",
      "otherNotes" : "The issue is about adding support for HTTPX in the Instruments component, which would extend the library's user base. The author suggests it should be similar to the existing support for Requests. There are comments discussing the potential impact on the package's dependencies and the need for composable functions.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407664
  }, {
    "issueDTO" : {
      "id" : 2586350804,
      "title" : "[Bug] Compressed backups use unconventional file extensions",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/940",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\r\nBugs should be filed for issues encountered whilst operating mariadb-operator.\r\nPlease provide as much detail as possible. \r\n-->\r\n\r\n**Documentation**\r\n- [x] I acknowledge that I have read the relevant [documentation](https://github.com/mariadb-operator/mariadb-operator/tree/main/docs).\r\n\r\n**Describe the bug**\r\n<!--\r\nA clear and concise description of what the bug is. \r\nTip: you can use \r\n```\r\n<code here>\r\n```\r\nfor code blocks of your kubectl output or YAML files.\r\n-->\r\nGzip compressed backups have the file extensions in the wrong order. They are named:\r\n\r\n`backup.2024-10-13T02_00_00Z.gzip.sql`\r\n\r\nWhich means you cannot just decompress them, since gzip does not recognize the .sql extension:\r\n\r\n```\r\n$ gunzip backup.2024-10-13T02_00_00Z.gzip.sql      \r\ngzip: backup.2024-10-13T02_00_00Z.gzip.sql: unknown suffix -- ignored\r\n```\r\n\r\nIt would be better if the files are called `*.sql.gz` so they can be recognized by tools like gunzip by default.\r\n \r\n**Expected behaviour**\r\n<!--A concise description of what you expected to happen.-->\r\n\r\n**Steps to reproduce the bug**\r\n<!--Steps to reproduce the bug should be clear and easily reproducible to help people\r\ngain an understanding of the problem.-->\r\n\r\n1. Create a gzip compressed backup.\r\n2. Check the created filename.\r\n\r\n**Environment details**:\r\n- Kubernetes version: 1.30.5+k3s1\r\n- Kubernetes distribution: k3s\r\n- mariadb-operator version: 0.34.0\r\n- Galera data-plane version (init and agent): N/A\r\n- Install method: helm\r\n\r\n**Additional context**\r\n<!--Add any other context  here.-->\r\n",
      "updatedAt" : 1753367188.000000000,
      "user" : "pkerwien",
      "userHtmlUrl" : "https://github.com/pkerwien",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13525244?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @pkerwien ! Thanks for raising this.\r\n\r\nAlthough I agree, we should follow conventional extensions to leverage existing tooling, this change implies breaking changes, as there will be user who already have backups taken with previous versions of the operator. For this reason, we should also think about the migration path as part of this issue. I'm thinking about the following options:\r\n- Declare a breaking change in the release notes and provide a migration script.\r\n- Include a migration step for old backups as part of the operator's backup subcommand.\r\n", "This issue is stale because it has been open 60 days with no activity.", "> Hey @pkerwien ! Thanks for raising this.\r\n> \r\n> Although I agree, we should follow conventional extensions to leverage existing tooling, this change implies breaking changes, as there will be user who already have backups taken with previous versions of the operator. For this reason, we should also think about the migration path as part of this issue. I'm thinking about the following options:\r\n> \r\n> * Declare a breaking change in the release notes and provide a migration script.\r\n> * Include a migration step for old backups as part of the operator's backup subcommand.\r\n\r\n2 cents here. The unusual file naming (Remembering that file extensions are useless for most of tools since magic is used to detect file properties and GUI associations - so doesn't calling it \"extension\") may break some automations. gzip and bzip2 when uncompress a file named with extension, get this extension removed from target file. In this inverted file naming, gzip and bzip2 are unable to automatically detect file content and properly remove the suffix of target filename.\r\n\r\nThat said: If mariadb-operator backup/restore tools uses proper command line detection (Use magic to detect proper file format instead file naming) and use complete command line syntax for compressors (`bzip2 -z` for compression, `bzip2 -d` for decompression - as stated in manpage to explicit operation), the operator will be resilient about extension changes and keeping old behaviour for existent backups with old filename, since these way to handle the files does not depend anymore of file proper suffix.\r\n\r\nI know operator was wrote with Go, but using the shell tools is just to ilustrate my point in a SRE point of view as example.", "A side question regarding the backup pipeline: why are backups compressed on the upload step (main container) instead of during mariadb-dump in the init container? Currently, for a 20G database, I need to provide at least 30G of storage in the staging PVC. With piped compression during mariadb-dump, it would probably be enough to allocate 10G.", "> That said: If mariadb-operator backup/restore tools uses proper command line detection (Use magic to detect proper file format instead file naming) and use complete command line syntax for compressors (bzip2 -z for compression, bzip2 -d for decompression - as stated in manpage to explicit operation), the operator will be resilient about extension changes and keeping old behaviour for existent backups with old filename, since these way to handle the files does not depend anymore of file proper suffix.\n\n@leleobhz Thank you for you insights, very useful suggestion. Removing the suffix dependency and instead do a detection based on the file would be great, this way no migration would be needed as it will be backwards compatible. I think it was actually the first approach that @vixns took when raising the PR. It would need to be accomodated and tested in the current codebase:\n- https://github.com/vixns/mariadb-operator/blob/f7d96f79364b6985364ee70f59704c4c543eb818/cmd/backup/restore.go#L107\n- https://github.com/vixns/mariadb-operator/blob/f7d96f79364b6985364ee70f59704c4c543eb818/cmd/backup/restore.go#L118\n\nContributions are welcome here! I would suggest to move the detection logic to our [backup pkg](https://github.com/mariadb-operator/mariadb-operator/tree/main/pkg/backup) and add a generous amount of unit tests, as it would become a critical function.\n\n> A side question regarding the backup pipeline: why are backups compressed on the upload step (main container) instead of during mariadb-dump in the init container? Currently, for a 20G database, I need to provide at least 30G of storage in the staging PVC. With piped compression during mariadb-dump, it would probably be enough to allocate 10G.\n\n@SPodjasek good question! We cannot do the compression on the MariaDB container because it lacks the bzip2 dependency (it only has gzip), we want to minimize the dependencies to reduce the attack surface and CVEs. Another good reason to do it in the go sidecar is the ease of testing, you can have unit tests to validate the compression function, whereas doing it on the main container will require an integration test. ", "This issue is stale because it has been open 60 days with no activity.", "This issue is stale because it has been open 60 days with no activity." ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the file naming convention of compressed backups to make them more compatible with existing tooling.",
      "validationOrRequirement" : "The file naming convention of compressed backups should follow conventional extensions to leverage existing tooling. There should also be a migration path for existing backups.",
      "attemptedFixes" : "Some contributors have suggested using proper command line detection to handle file formats instead of relying on file naming conventions. There is also a discussion about why backups are compressed on the upload step instead of during mariadb-dump.",
      "otherNotes" : "The issue is about the file naming convention of compressed backups, which is currently unconventional and may break some automations. It also raises the question of migration path for existing backups. Some contributors have suggested using proper command line detection to handle file formats instead of relying on file naming conventions. There is also a discussion about why backups are compressed on the upload step instead of during mariadb-dump.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407670
  }, {
    "issueDTO" : {
      "id" : 2663441369,
      "title" : "\uD83D\uDE80 Feature: Support for Azure AI Search",
      "url" : "https://github.com/traceloop/openllmetry/issues/2303",
      "repositoryName" : "traceloop/openllmetry",
      "description" : "### Which component is this feature for?\n\nAll Packages\n\n### \uD83D\uDD16 Feature description\n\nThanks for the amazing work! \r\n\r\nWould be super cool to see support for Azure AI Search in future :)\n\n### \uD83C\uDFA4 Why is this feature needed ?\n\nPopulat choice for RAG applications\n\n### ?????? How do you aim to achieve this?\n\nAn autoinstrumentor just like the other ones\n\n### \uD83D\uDD04??? Additional Information\n\n_No response_\n\n### \uD83D\uDC40 Have you spent some time to check if this feature request has been raised before?\n\n- [X] I checked and didn't find similar issue\n\n### Are you willing to submit PR?\n\nNone",
      "updatedAt" : 1753367094.000000000,
      "user" : "baniasbaabe",
      "userHtmlUrl" : "https://github.com/baniasbaabe",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/72874670?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks @baniasbaabe, can you link to docs / write a small usage example to make it easier for contributors?", "Link to Documentation: https://learn.microsoft.com/en-us/python/api/overview/azure/search-documents-readme?view=azure-python", "Has the issue been fixed now? @baniasbaabe ", "No it hasn't @Afolabi-cyber ", "i want to see if i can work on this issue. I also wanted to see if you know where is issue is originating from @baniasbaabe .", "@Ali7425 this is not an issue - that's a new feature to support", "ok thanks. what do you think is a good way implement the code\r\n", "and would i be able to work on this\r\n", "Sure @Ali7425 - hop over [slack](https://www.traceloop.com/slack) if you need any assistance. I'd look at the API of Azure AI Search and see if you can build a small sample app and continue from there.", "Hello, I am interested to add contribute in this feature.", "I am currently working on it but feel free to try and contribute\n", "Hi, I am interested in contributing to this " ],
      "repository" : {
        "description" : "Open-source observability for your LLM application, based on OpenTelemetry",
        "homepage" : "https://www.traceloop.com/openllmetry",
        "name" : "openllmetry",
        "fullName" : "traceloop/openllmetry",
        "htmlUrl" : "https://github.com/traceloop/openllmetry",
        "gitUrl" : "git://github.com/traceloop/openllmetry.git",
        "sshUrl" : "git@github.com:traceloop/openllmetry.git",
        "cloneUrl" : "https://github.com/traceloop/openllmetry.git",
        "owner" : {
          "login" : "traceloop",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 763,
        "stargazersCount" : 6118,
        "watchersCount" : 6118,
        "size" : 36422,
        "openIssuesCount" : 247,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T13:13:04Z",
        "languages" : {
          "Shell" : 183,
          "Python" : 2283005
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to support Azure AI Search in the traceloop/openllmetry repository, which would be a valuable addition for RAG applications.",
      "validationOrRequirement" : "The author has not specified any specific requirements or validations, but the feature is considered a good first issue and is labeled as 'help wanted'.",
      "attemptedFixes" : "None mentioned, but contributors have shown interest in implementing the feature and have asked for guidance on how to proceed.",
      "otherNotes" : "Additional information is not provided, but the author and other contributors have engaged in discussions and offered help.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407674
  }, {
    "issueDTO" : {
      "id" : 2614465277,
      "title" : "Allow to create additionalLabels in serviceMonitor section",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/966",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\r\nBugs should be filed for issues encountered whilst operating mariadb-operator.\r\nPlease provide as much detail as possible. \r\n-->\r\n\r\n\r\n**Describe the bug**\r\nAfter trying different configurations, I am not able to add additionalLabels inside the serviceMonitor which could allow me to monitor specific mariadb instances. Checking the documentation [we only have ](https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/METRICS.md#servicemonitor) we only have the following possibilities\r\n```\r\n    serviceMonitor:\r\n      prometheusRelease: kube-prometheus-stack\r\n      jobLabel: mariadb-monitoring\r\n      interval: 10s\r\n      scrapeTimeout: 10s\r\n    username: monitoring\r\n    passwordSecretKeyRef:\r\n      name: mariadb\r\n      key: password\r\n```\r\nHowever it is not enough for me as I would like to add some other additionalLabels.\r\n**Expected behaviour**\r\n<!--A concise description of what you expected to happen.-->\r\nBeing able to code something like:\r\n\r\n```\r\n    serviceMonitor:\r\n      additionalLabels:\r\n        release: \"${values['global']['helmReleaseNamePrefix']}monitoring-platform\"\r\n      interval: 10s\r\n      scrapeTimeout: 10s\r\n    username: monitoring\r\n    passwordSecretKeyRef:\r\n      name: mariadb\r\n      key: password\r\n```\r\n**Steps to reproduce the bug**\r\n<!--Steps to reproduce the bug should be clear and easily reproducible to help people\r\ngain an understanding of the problem.-->\r\nadditionalLabels or selector matchLabels are not being taken into account\r\n\r\n**Debug information**\r\n- Related object events:\r\n```bash\r\nkubectl get events --field-selector involvedObject.name=<mariadb-resource-name>\r\nkubectl get events --field-selector involvedObject.name=<backup-resource-name>\r\nkubectl get events --field-selector involvedObject.name=<restore-resource-name>\r\n```\r\n- `mariadb-operator` logs. Set the `--log-level` to `debug` if needed.\r\n\r\n**Environment details**:\r\n- mariadb-operator version: 0.30.0\r\n- Install method: [helm]\r\n\r\n**Additional context**\r\n<!--Add any other context  here.-->\r\n",
      "updatedAt" : 1753366861.000000000,
      "user" : "jpicara",
      "userHtmlUrl" : "https://github.com/jpicara",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6992066?v=4",
      "labels" : [ "bug", "help wanted", "metrics", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi,\r\nI was able to fix the issue by using the label `prometheusRelease` to point into the Prometheus release just like\r\n```   \r\n        metrics:\r\n          enabled: true\r\n          serviceMonitor:\r\n            prometheusRelease: \"${values['global']['helmReleaseNamePrefix']}monitoring-platform\"\r\n```\r\n\r\nHowever in my view, I still consider we should have `additionalLabels` in case we want to add some specific label to the serviceMonitor automatically created.", "Adding a +1 here, as I am running in to something similar. Because $reasons we run multiple Prometheus instances in our cluster and we therefore have a need to specify which label to monitor on. Unfortunately using the `release` label doesn't work for us there since we already use that label for other purposes.\r\n\r\nI have worked around the issue by using `inheritMetadata.labels`, but ideally I'd not do that because it sets the label on _all_ the created resources.", "This issue is stale because it has been open 60 days with no activity.", "+1", "Thanks for bringing this up. We could extend our `serviceMonitor` definition to have a map of `additionalLabels` as you suggested:\n\n```yaml\nserviceMonitor:\n   additionalLabels:\n      environment: production\n      region: eu-west1\n``` \n\nWhich will result in the following `ServiceMonitor` getting reconciled:\n\n```yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nspec:\n  endpoints:\n  - port: metrics\n    relabelings:\n     - targetLabel: environment\n       replacement: production\n     - targetLabel: region\n       replacement: eu-west1\n``` \n\nSee `ServiceMonitor` reference for further detail:\n- https://prometheus-operator.dev/docs/api-reference/api/#monitoring.coreos.com/v1.ServiceMonitorSpec\n\nContributions are welcomed! ", "> Thanks for bringing this up. We could extend our `serviceMonitor` definition to have a map of `additionalLabels` as you suggested:\n> \n> serviceMonitor:\n>    additionalLabels:\n>       environment: production\n>       region: eu-west1\n> \n> Which will result in the following `ServiceMonitor` getting reconciled:\n> \n> apiVersion: monitoring.coreos.com/v1\n> kind: ServiceMonitor\n> spec:\n>   endpoints:\n>   - port: metrics\n>     relabelings:\n>      - targetLabel: environment\n>        replacement: production\n>      - targetLabel: region\n>        replacement: eu-west1\n> \n> See `ServiceMonitor` reference for further detail:\n> \n>     * https://prometheus-operator.dev/docs/api-reference/api/#monitoring.coreos.com/v1.ServiceMonitorSpec\n> \n> \n> Contributions are welcomed!\n\n@mmontes11 I am not sure if that is exactly what @jpicara requested. We are also missing the feature for `serviceMonitor.additionalLablels`, but we just need the result to end up in `metadata.labels` of `ServiceMonitor` object (e.g. to work similar as most of the bitnami charts `servicemonitor.labels`). \n\nExample:\n```\nserviceMonitor:\n   additionalLabels:\n      prometheus: prod\n```\n\n```\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    prometheus: prod\n```\n", "Actually, I think both requests are legit.\n\n```yaml\napiVersion: k8s.mariadb.com/v1alpha1\nkind: MariaDB\nmetadata:\n  name: mariadb\nspec:\n  metrics:\n    enabled: true\n    serviceMonitor:\n      metadata:\n        metadata:\n          labels:\n            prometheus: prod\n      relabelings:\n       - targetLabel: environment\n         replacement: production\n       - targetLabel: region\n         replacement: eu-west1\n```\n\n@jpicara You will be able to configure `relabelings` i.e. change Prometheus labels by specifying `spec.metrics.serviceMonitor.relabelings`. This will reconcile the following `ServiceMonitor`:\n\n```yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nspec:\n  endpoints:\n  - port: metrics\n    relabelings:\n     - targetLabel: environment\n       replacement: production\n     - targetLabel: region\n       replacement: eu-west1\n```\n\n@mhanc Indeed, we should be able to provide labels in the `ServiceMonitor` object metadata so it can be matched by the Prometheus instance:\nhttps://github.com/prometheus-community/helm-charts/blob/3d6314b7d552246c1c3e60c3f89b0efbef6270c0/charts/kube-prometheus-stack/values.yaml#L4063\n\nWe will be deprecating the `prometheusRelease` field, as the `release` label can be passed through the new `metadata` field. The resulting `ServiceMonitor` will be:\n\n```yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    prometheus: prod\n```\n\nContributions are welcome! Will try to make some room in the upcoming release if nobody raises a PR.", "This issue is stale because it has been open 60 days with no activity." ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to allow the user to add additionalLabels in serviceMonitor section, specifically release, environment, region, etc. to monitor specific mariadb instances.",
      "validationOrRequirement" : "The requirement is to be able to add additionalLabels in serviceMonitor section, specifically release, environment, region, etc. The user wants to be able to monitor specific mariadb instances by adding labels.",
      "attemptedFixes" : "The user has tried different configurations but couldn't add additionalLabels. The user has also mentioned that they have worked around the issue by using `inheritMetadata.labels` but ideally they would not do that because it sets the label on all the created resources.",
      "otherNotes" : "The issue is about adding additionalLabels in serviceMonitor section, the user wants to be able to monitor specific mariadb instances by adding labels. The user has tried different configurations but couldn't add additionalLabels. The expected behavior is to be able to add labels like release, environment, region, etc. The issue has been open for 60 days with no activity.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407681
  }, {
    "issueDTO" : {
      "id" : 3260069667,
      "title" : "Purpose of data available at https://download.qgis.org/qgisdata",
      "url" : "https://github.com/qgis/QGIS-Website/issues/694",
      "repositoryName" : "qgis/QGIS-Website",
      "description" : "### URL\n\nhttps://download.qgis.org/qgisdata\n\n### Type(s) of Problems\n\n_No response_\n\n### Summary\n\nThere's this page (https://download.qgis.org/qgisdata). The page contains old QGIS documentation. I can't tell how to access it from navigating the website but some of its pages can be returned by web searches, which is annoying since we should only expose latest versions (or less recent, but controlled through the documentation website).\nWhat is this docs store purpose? Any chance to remove the docs?",
      "updatedAt" : 1753366592.000000000,
      "user" : "DelazJ",
      "userHtmlUrl" : "https://github.com/DelazJ",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7983394?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Official Website for QGIS.org",
        "homepage" : "https://qgis.org",
        "name" : "QGIS-Website",
        "fullName" : "qgis/QGIS-Website",
        "htmlUrl" : "https://github.com/qgis/QGIS-Website",
        "gitUrl" : "git://github.com/qgis/QGIS-Website.git",
        "sshUrl" : "git@github.com:qgis/QGIS-Website.git",
        "cloneUrl" : "https://github.com/qgis/QGIS-Website.git",
        "owner" : {
          "login" : "qgis",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 68,
        "stargazersCount" : 35,
        "watchersCount" : 35,
        "size" : 1430550,
        "openIssuesCount" : 24,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-24T12:05:05Z",
        "languages" : {
          "TypeScript" : 44477,
          "Dockerfile" : 284,
          "Shell" : 21241,
          "CSS" : 15675,
          "Makefile" : 4783,
          "JavaScript" : 130229,
          "Sass" : 197602,
          "HTML" : 179412,
          "Nix" : 2525,
          "Python" : 60362
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To understand the purpose of the data available at https://download.qgis.org/qgisdata and potentially remove the outdated documentation.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The page contains old QGIS documentation, and some of its pages can be returned by web searches, which is annoying since we should only expose latest versions (or less recent, but controlled through the documentation website).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407685
  }, {
    "issueDTO" : {
      "id" : 3246073932,
      "title" : "Reload after \"delete asset\" does not use filters",
      "url" : "https://github.com/junobuild/juno/issues/1765",
      "repositoryName" : "junobuild/juno",
      "description" : "# Issue\n\nAfter a \"Delete asset\" in the Storage, the list of assets is reloaded. It works out BUT if the dev has selected some filters, those are not used to reload the list.\n\n# What to do\n\nOn reload after delete, use the filters.\n\n# Screenshots\n\nApply filter\n<img width=\"1536\" height=\"1031\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/7e8496c7-8fa7-421c-96f0-0adfe706c0b2\" />\n\nOk list is filtered\n<img width=\"1536\" height=\"1031\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ae7862e2-4742-4413-b2ce-ff2d6f58c5f2\" />\n\nDelete an asset\n<img width=\"1536\" height=\"1031\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4f961766-5bd1-4696-8ec1-a0f36edbb530\" />\n<img width=\"1536\" height=\"1031\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/3b0ae248-c2f6-4f41-ada8-bc3ae734c1a6\" />\n\nThe list is reloaded without observing the filters which are still active\n<img width=\"1536\" height=\"1031\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d942b0bd-7390-4ab0-a4b7-b06fabde1ad1\" />",
      "updatedAt" : 1753366578.000000000,
      "user" : "peterpeterparker",
      "userHtmlUrl" : "https://github.com/peterpeterparker",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16886711?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Can I take this issue ?\nETA 2 days", "Sure go for it @ritik4ever !\n\nIt's a good first issue, but also a tricky one given the components are quite abstracted.\n\nThe delete operation is initiated in `Asset.svelte` via the `deleteData` function. However, the actual deletion is performed in the `DataDelete.svelte` component (that is used by the former), within the `deleteSelectedData` function.\n\nWhen this function succeeds, it calls `listParamsStore.reset()`, which resets the parameters (e.g., filters). These parameters are observed in the `$effect` of the `Assets` component, which triggers a new list/load when the parameters change. ", "Hey could you please assign it to me." ],
      "repository" : {
        "description" : "A next-gen serverless platform that helps developers build and ship secure projects at scale.",
        "homepage" : "https://juno.build",
        "name" : "juno",
        "fullName" : "junobuild/juno",
        "htmlUrl" : "https://github.com/junobuild/juno",
        "gitUrl" : "git://github.com/junobuild/juno.git",
        "sshUrl" : "git@github.com:junobuild/juno.git",
        "cloneUrl" : "https://github.com/junobuild/juno.git",
        "owner" : {
          "login" : "junobuild",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 33,
        "stargazersCount" : 253,
        "watchersCount" : 253,
        "size" : 16104,
        "openIssuesCount" : 71,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-24T10:32:10Z",
        "languages" : {
          "TypeScript" : 1208867,
          "Dockerfile" : 6121,
          "Shell" : 27792,
          "Rust" : 1099954,
          "SCSS" : 38798,
          "JavaScript" : 374517,
          "HTML" : 40861,
          "Svelte" : 868313
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "After a 'Delete asset' in the Storage, the list of assets is reloaded, but if the dev has selected some filters, those are not used to reload the list. On reload after delete, use the filters.",
      "validationOrRequirement" : "filters should be observed after deletion",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "The delete operation is initiated in Asset.svelte via the deleteData function. The actual deletion is performed in DataDelete.svelte component within the deleteSelectedData function. The listParamsStore.reset() function is called after deletion, which resets the parameters (e.g., filters).",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407689
  }, {
    "issueDTO" : {
      "id" : 335379226,
      "title" : "Create corresponding CSS properties for originX and originY",
      "url" : "https://github.com/NativeScript/NativeScript/issues/5991",
      "repositoryName" : "NativeScript/NativeScript",
      "description" : "Create CSS properties for [`originX` and `originY`.](https://docs.nativescript.org/api-reference/classes/_ui_core_view_.view#originx)\r\n\r\nIn CSS specification the corresponding property is called [transform-origin](https://developer.mozilla.org/en-US/docs/Web/CSS/transform-origin).\r\n\r\nThe goal is to allow NativeScript views to be transformed via their origin properties in CSS animations. Currently, this is possible only [via code-behind as demonstrated here](https://github.com/NativeScript/nativescript-sdk-examples-js/tree/master/app/ns-ui-widgets-category/animations/origin-properties).\r\n\r\n<bountysource-plugin>\r\n\r\n---\r\nWant to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/60090794-create-corresponding-css-properties-for-originx-and-originy?utm_campaign=plugin&utm_content=tracker%2F12908224&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F12908224&utm_medium=issues&utm_source=github).\r\n</bountysource-plugin>",
      "updatedAt" : 1753366484.000000000,
      "user" : "NickIliev",
      "userHtmlUrl" : "https://github.com/NickIliev",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18008302?v=4",
      "labels" : [ "feature", "hacktoberfest", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@NickIliev I want to take this up. How can I proceed with it?", "@arshadkazmi42 Check Nativescript contribution guidelines [here](https://github.com/NativeScript/NativeScript/blob/master/CONTRIBUTING.md)", "@NickIliev How do you want this issue to be addressed? Do you want me to have separate classes with different origin values linked to corresponding views in JS/TS files, or something else?", "Is this issue still open? Can i get assigned to it?", "is this issue still open?\n" ],
      "repository" : {
        "description" : "??? Empowering JavaScript with native platform APIs. ??? Best of all worlds (TypeScript, Swift, Objective C, Kotlin, Java, Dart). Use what you love ?????? Angular, React, Solid, Svelte, Vue with: iOS (UIKit, SwiftUI), Android (View, Jetpack Compose), Dart (Flutter) and you name it compatible.",
        "homepage" : "https://nativescript.org",
        "name" : "NativeScript",
        "fullName" : "NativeScript/NativeScript",
        "htmlUrl" : "https://github.com/NativeScript/NativeScript",
        "gitUrl" : "git://github.com/NativeScript/NativeScript.git",
        "sshUrl" : "git@github.com:NativeScript/NativeScript.git",
        "cloneUrl" : "https://github.com/NativeScript/NativeScript.git",
        "owner" : {
          "login" : "NativeScript",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1668,
        "stargazersCount" : 24910,
        "watchersCount" : 24910,
        "size" : 179333,
        "openIssuesCount" : 912,
        "subscribersCount" : 653,
        "pushedAt" : "2025-07-23T20:26:03Z",
        "languages" : {
          "TypeScript" : 4361412,
          "Java" : 534313,
          "CSS" : 36823,
          "Shell" : 20443,
          "SCSS" : 65,
          "JavaScript" : 70789,
          "Objective-C" : 122990,
          "Swift" : 7303,
          "HTML" : 1303,
          "Ruby" : 293
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create corresponding CSS properties for originX and originY to allow NativeScript views to be transformed via their origin properties in CSS animations.",
      "validationOrRequirement" : "Follow Nativescript contribution guidelines [here](https://github.com/NativeScript/NativeScript/blob/master/CONTRIBUTING.md) and consider having separate classes with different origin values linked to corresponding views in JS/TS files, or something else.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The issue is related to NativeScript views being transformed via their origin properties in CSS animations, currently possible only via code-behind.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407694
  }, {
    "issueDTO" : {
      "id" : 3193271091,
      "title" : "[Feature Request] Show latency of connections",
      "url" : "https://github.com/GyulyVGC/sniffnet/issues/845",
      "repositoryName" : "GyulyVGC/sniffnet",
      "description" : "### Is there an existing issue for this?\n\n- [x] I have searched the existing issues.\n\n### Describe the solution you'd like\n\nIt'd be nice to see ping/latency of open connections to know if you're close to the target server.  Similar program with said feature would be Resource Monitor that would come with Windows.\n\n### Is your feature request related to a problem?\n\nI used this feature for online gaming, not every game shows what your ping/latency is.  With online games having multiple locations/providers it's nice to know you're using the optimal one.",
      "updatedAt" : 1753366418.000000000,
      "user" : "TheWyn",
      "userHtmlUrl" : "https://github.com/TheWyn",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/841141?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @TheWyn thanks for opening this issue.\n\nWhere would you expect to see the latency in Sniffnet? In the inspect page table? Cause in the overview page, and more specifically the network hosts section, more than one connection is agglomerated for each entry.\n\nI'm also starting to wonder which would be the best way to collect latencies for each connection, since pinging each of them doesn't feel optimal.", "> Hey [@TheWyn](https://github.com/TheWyn) thanks for opening this issue.\n> \n> Where would you expect to see the latency in Sniffnet? In the inspect page table? Cause in the overview page, and more specifically the network hosts section, more than one connection is agglomerated for each entry.\n> \n> I'm also starting to wonder which would be the best way to collect latencies for each connection, since pinging each of them doesn't feel optimal.\n\nI'd expect to see it in the inspect table or in the connection details, if it was possible to see connection details per program that would also be an option.", "I think the Inspect page table would be the best place to show latency since it focuses on individual connections, and latency really varies per connection. On the Overview page, especially in the Network Hosts section, multiple connections get grouped together, so it???s harder to show meaningful latency info for each host there.\n\nAbout how to collect latency data, pinging every connection one by one might be a bit too heavy and could cause extra traffic or slow things down. Maybe we could try other approaches like:\n\n1)Using passive measurements from traffic timestamps, like how long the TCP handshake takes, if that info is available\n2)Sending ICMP or TCP timestamp requests only when needed or just for some selected connections\n3)Caching latency values and updating them every now and then to keep overhead low\n", "Labeling this issue as https://github.com/GyulyVGC/sniffnet/labels/good%20first%20issue and https://github.com/GyulyVGC/sniffnet/labels/help%20wanted to gather additional feedback and help ", "I think the best approach would be to only ping the selected connections, as pinging other connections would only add to the network load and be of no value. These selected connections can then be cached and updated every nth second.\n\nOr we can inspect a single connection, and have a button which measures latency." ],
      "repository" : {
        "description" : "Comfortably monitor your Internet traffic \uD83D\uDD75????????????",
        "homepage" : "https://sniffnet.net",
        "name" : "sniffnet",
        "fullName" : "GyulyVGC/sniffnet",
        "htmlUrl" : "https://github.com/GyulyVGC/sniffnet",
        "gitUrl" : "git://github.com/GyulyVGC/sniffnet.git",
        "sshUrl" : "git@github.com:GyulyVGC/sniffnet.git",
        "cloneUrl" : "https://github.com/GyulyVGC/sniffnet.git",
        "owner" : {
          "login" : "GyulyVGC",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 974,
        "stargazersCount" : 29308,
        "watchersCount" : 29308,
        "size" : 290180,
        "openIssuesCount" : 54,
        "subscribersCount" : 117,
        "pushedAt" : "2025-07-24T10:49:56Z",
        "languages" : {
          "Dockerfile" : 767,
          "Shell" : 1370,
          "Rust" : 932512,
          "Rich Text Format" : 10415
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to show the latency of connections in Sniffnet, specifically in the inspect page table or connection details, to help users know which provider to use for online gaming.",
      "validationOrRequirement" : "The author suggests that pinging every connection one by one might be a bit too heavy and could cause extra traffic or slow things down. The best approach would be to only ping the selected connections, as pinging other connections would only add to the network load and be of no value.",
      "attemptedFixes" : "The author mentions pinging each connection doesn't feel optimal, and suggests using passive measurements from traffic timestamps, sending ICMP or TCP timestamp requests only when needed, or caching latency values and updating them every now and then to keep overhead low.",
      "otherNotes" : "The issue is related to online gaming, where latency is important to know which provider to use. The suggested places to show latency are the inspect page table or connection details. The author suggests using passive measurements, ICMP or TCP timestamp requests, or caching latency values to collect latency data. The issue is labeled as good first issue and help wanted to gather additional feedback and help.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407701
  }, {
    "issueDTO" : {
      "id" : 2633692681,
      "title" : "[Bug] MariaDB pods crash after set `rootEmptyPassword` to `true`",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/1021",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\r\nBugs should be filed for issues encountered whilst operating mariadb-operator.\r\nPlease provide as much detail as possible. \r\n-->\r\n\r\n**Documentation**\r\n- [x] I acknowledge that I have read the relevant [documentation](https://github.com/mariadb-operator/mariadb-operator/tree/main/docs).\r\n\r\n**Describe the bug**\r\n<!--\r\nA clear and concise description of what the bug is. \r\nTip: you can use \r\n```\r\n<code here>\r\n```\r\nfor code blocks of your kubectl output or YAML files.\r\n-->\r\nIn our test environment, we set the `rootEmptyPassword` to `true`. However, the MariaDB pods cannot be initialized correctly due to the error ```\"msg\":\"Error getting environment variables\",\"error\":\"MariadbRootPassword: missing required value: MARIADB_ROOT_PASSWORD\"``` \r\n\r\n**Expected behaviour**\r\n<!--A concise description of what you expected to happen.-->\r\nWe want to see the mariadb pods are initialized correctly and then running.\r\n\r\n**Steps to reproduce the bug**\r\n<!--Steps to reproduce the bug should be clear and easily reproducible to help people\r\ngain an understanding of the problem.-->\r\n\r\n1. Apply a CR with more than `1` replicas and `rootEmptyPassword` enabled, for example:\r\n```\r\napiVersion: k8s.mariadb.com/v1alpha1\r\nkind: MariaDB\r\nmetadata:\r\n  name: mariadb-min\r\nspec:\r\n  rootEmptyPassword: true\r\n  storage:\r\n    size: 1Gi\r\n    storageClassName: standard\r\n    resizeInUseVolumes: true\r\n    waitForVolumeResize: true\r\n  galera:\r\n    enabled: true\r\n  replicas: 3\r\n```\r\n\r\n**Debug information**\r\n- Related object events:\r\n```bash\r\nkubectl get events --field-selector involvedObject.name=<mariadb-resource-name>\r\nkubectl get events --field-selector involvedObject.name=<backup-resource-name>\r\nkubectl get events --field-selector involvedObject.name=<restore-resource-name>\r\n```\r\n13s         Normal    Created     pod/mariadb-min-1   Created container init\r\n12s         Normal    Started     pod/mariadb-min-1   Started container init\r\n12s         Warning   BackOff     pod/mariadb-min-1   Back-off restarting failed container init in pod mariadb-min-1_default(8b3c2a50-511d-4a5c-a41d-932629a5a26a)\r\n\r\n**Environment details**:\r\n- Kubernetes version: v1.29\r\n- Kubernetes distribution: KIND\r\n- mariadb-operator version: 0.35.1\r\n- Install method: [helm, OLM, or static manifests]: helm\r\n\r\n**Additional context**\r\n<!--Add any other context  here.-->\r\nI think the issue happens in the init containers of mariadb pods when there are more than `1` replicas.",
      "updatedAt" : 1753366413.000000000,
      "user" : "kos-team",
      "userHtmlUrl" : "https://github.com/kos-team",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/172315486?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This issue is stale because it has been open 60 days with no activity.", "This issue was closed because it has been stalled for 30 days with no activity.", "`rootEmptyPassword` is only intented to be used with the standalone topology. We could add extra validation rules to ensure this.", "This issue is stale because it has been open 60 days with no activity.", "This issue was closed because it has been stalled for 30 days with no activity." ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The MariaDB pods crash after setting `rootEmptyPassword` to `true` due to the error `\"msg\":\"Error getting environment variables\",\"error\":\"MariadbRootPassword: missing required value: MARIADB_ROOT_PASSWORD\"`.",
      "validationOrRequirement" : "The `rootEmptyPassword` should be used with the standalone topology, and extra validation rules could be added to ensure this.",
      "attemptedFixes" : "No specific attempted fixes mentioned in the issue description.",
      "otherNotes" : "The issue is related to the init containers of mariadb pods when there are more than 1 replicas, and the error is due to the missing required value MARIADB_ROOT_PASSWORD.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407706
  }, {
    "issueDTO" : {
      "id" : 3248481256,
      "title" : "Fix flaky test TestEthClient",
      "url" : "https://github.com/ethereum/go-ethereum/issues/32252",
      "repositoryName" : "ethereum/go-ethereum",
      "description" : "Flaky test `TestEthClient`\n\n`FAIL\tgithub.com/ethereum/go-ethereum/ethclient\t600.327s`\n\n```\npanic: test timed out after 10m0s\n\trunning tests:\n\t\tTestEthClient (10m0s)\n\t\tTestEthClient/AtFunctions (10m0s)\n```\n---\n\n```\n--- FAIL: TestTransactionRollbackBehavior (10.15s)\n    rollback_test.go:53: failed to send transaction: already known\nFAIL\n```",
      "updatedAt" : 1753366313.000000000,
      "user" : "rjl493456442",
      "userHtmlUrl" : "https://github.com/rjl493456442",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5959481?v=4",
      "labels" : [ "type:bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I would like to try this! thanks.", "hey @rjl493456442 actually am new to geth, and having a hard time trying to reproduce the flakiness of the above tests like running the tests multiple times or even in parallel are not helping...can you help me in this regard.", "@arnabnandikgp The [stress](https://pkg.go.dev/golang.org/x/tools/cmd/stress#pkg-overview) tool can help here." ],
      "repository" : {
        "description" : "Go implementation of the Ethereum protocol",
        "homepage" : "https://geth.ethereum.org",
        "name" : "go-ethereum",
        "fullName" : "ethereum/go-ethereum",
        "htmlUrl" : "https://github.com/ethereum/go-ethereum",
        "gitUrl" : "git://github.com/ethereum/go-ethereum.git",
        "sshUrl" : "git@github.com:ethereum/go-ethereum.git",
        "cloneUrl" : "https://github.com/ethereum/go-ethereum.git",
        "owner" : {
          "login" : "ethereum",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 21000,
        "stargazersCount" : 49365,
        "watchersCount" : 49365,
        "size" : 228166,
        "openIssuesCount" : 323,
        "subscribersCount" : 2208,
        "pushedAt" : "2025-07-24T08:43:04Z",
        "languages" : {
          "Smarty" : 32330,
          "C" : 1854460,
          "CMake" : 30065,
          "Makefile" : 13455,
          "M4" : 23683,
          "Go" : 12530823,
          "HTML" : 1121,
          "Sage" : 42344,
          "NSIS" : 23197,
          "Dockerfile" : 4988,
          "Shell" : 37829,
          "Solidity" : 14815,
          "JavaScript" : 436893,
          "Assembly" : 63615,
          "Python" : 33217
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the flaky test 'TestEthClient'.",
      "validationOrRequirement" : "Reproduce the flakiness of the tests, and fix the test 'TestEthClient'.",
      "attemptedFixes" : "The commenter @arnabnandikgp suggested using the stress tool to help reproduce the flakiness of the tests.",
      "otherNotes" : "The test timed out after 10m0s, and there was a panic error. Additionally, the test 'TestTransactionRollbackBehavior' failed due to a failed transaction.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407709
  }, {
    "issueDTO" : {
      "id" : 2811638956,
      "title" : "bug: Incorrect unicode render in the tweet component",
      "url" : "https://github.com/TheExGenesis/community-archive/issues/202",
      "repositoryName" : "TheExGenesis/community-archive",
      "description" : "Characters like ampersand and `<` `>` don't display correctly. \n\n<img width=\"400\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8dc606b2-9fda-4292-949d-e9a094c48f6e\" />\n\n<img width=\"300\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/61ca772e-d501-4d07-b58b-28e336784f39\" />\n\n<img width=\"300\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e07be06a-fd56-4563-b7ca-3f4843c4cb72\" />",
      "updatedAt" : 1753366275.000000000,
      "user" : "DefenderOfBasic",
      "userHtmlUrl" : "https://github.com/DefenderOfBasic",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/173721283?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "For reference this is how I handle it in my vanilla tweet component UI (it handles these specific cases as I found them, there might be a more general solution: https://github.com/DefenderOfBasic/twitter-semantic-search/blob/65684b0bf99eb3d4548a49cc0eeadc9b83861011/frontend/search.html#L200 )" ],
      "repository" : {
        "description" : "An open tweet database and API anyone can build on.",
        "homepage" : "https://www.community-archive.org",
        "name" : "community-archive",
        "fullName" : "TheExGenesis/community-archive",
        "htmlUrl" : "https://github.com/TheExGenesis/community-archive",
        "gitUrl" : "git://github.com/TheExGenesis/community-archive.git",
        "sshUrl" : "git@github.com:TheExGenesis/community-archive.git",
        "cloneUrl" : "https://github.com/TheExGenesis/community-archive.git",
        "owner" : {
          "login" : "TheExGenesis",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 17,
        "stargazersCount" : 93,
        "watchersCount" : 93,
        "size" : 2980,
        "openIssuesCount" : 46,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-17T18:08:55Z",
        "languages" : {
          "TypeScript" : 521838,
          "CSS" : 1710,
          "PLpgSQL" : 965755,
          "JavaScript" : 88000,
          "HTML" : 1432,
          "Python" : 24912
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Incorrect unicode render in the tweet component, specifically with characters like ampersand and < and >, which don't display correctly.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is accompanied by images and a reference to a solution implemented in a vanilla tweet component UI.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407712
  }, {
    "issueDTO" : {
      "id" : 2880910259,
      "title" : "Some feature and improvement suggestions",
      "url" : "https://github.com/AyuGram/AyuGramDesktop/issues/35",
      "repositoryName" : "AyuGram/AyuGramDesktop",
      "description" : "### Is your feature request related to a problem?\n\nNO\n\n### Describe the solution you'd like\n\n1. At the bottom of the channel page, it's better there are two side-by-side buttons, \"Enable/disable notifications\" and \"Discussions\".\n2. In groups with related channels, the upper right corner [...]button can jump to the related channel.\n3. Add the function of forwarding without quote.\n4. Add repeat function.\n\nThe above features are from 64Gram (no longer updated).\n\nIn Chinese:\n1.?????????????????????????????????????????????????????????????????????/?????????????????????????????????\n2.??????????????????????????????????????????[...]?????????????????????????????????\n3.???????????????????????????\n4.??????????????????\n\n??????????????????64Gram (???????????????)\n\n### Describe alternatives you've considered\n\n64Gram is a good client but discountinued. It has some good feature, hope Ayugram will add.\n\n### Additional context\n\nI just change from 64gram to ayugram, the lack of some features makes me not use to. I think ayugram can be better, these are the suggestions I have made and I hope they will be accepted. Thank you.\n\nps. Not good in English, the comment is translated by google translate or deepl. I'm sorry if I've offended you.",
      "updatedAt" : 1753366233.000000000,
      "user" : "LennoC",
      "userHtmlUrl" : "https://github.com/LennoC",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30518666?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks for suggestions.\n1. Probably no, I don't like how it looks (mute/unmute is the first item in three dots)\n2. Looks fine\n3. If you mean adding it as a context menu item, then I don't like it really, since you may remove quote by either clicking on Send button in \"Forward to...\" box or on the input field in chat\n4. Doesn't make sense to me\n\nTwo last suggestions are common asked (at least on Android), yet I still don't see why people desperately need it. Maybe you could tell more about use cases?", "Thanks for reply.\n\n1. Maybe it better to have a option: 1 button or 2 button(mute/discuss). I think it would be more convenient.\n2. Thank you. This is really helpful.\n3. No quote forward function is helpful, when there is a passage with some medias and comments. People can easily forward the complete passage includes multimedia without quote, sometimes maybe sender wants to hide, sometimes resend wants to hide (sender).\n\n> 3\\. since you may remove quote by either clicking on Send button in \"Forward to...\" box\n\nI didn't find this box or function. \n\n4. It is just OK, this is a function for fun. We like to repeat a funny comments in group chat, so it's convenient by 1-click repeat.\n\n\n", "The \"repeat\" button is used widely in some group chats, especially in groups mainly using Chinese. It is implemented in almost all Android clients forked by Chinese developers. This is also one of the original reasons that attracted me to use 64Gram, which was stopped developing a few months ago.\n\nIt is just for fun, but very convenient. So I would appreciate it if you added the button :)\n\nIn my view, the reason why people desperately need the two last functions is that many Android client has implemented them, so people are used to using them. It seems the forwarding function set (including no quote fwd, repeat, no quote repeat and so on) was firstly implemented by \"Neko\" series clients, and spread to Plus and other 3rd clients.\n\nAdditionally, the \"repeat\" button just did one simple thing: forward the message to current chat with quote, rather than copy the message content and send it again without quote.", "Regarding \"repeat\" - I don't really know how it should look & work. I saw it implemented in https://github.com/bl0-k/BlockGramDesktop\n\nIf anyone is really interested in the feature, please open an appropriate PR. The option to enable/disable it should be located in \"Context Menu\" section of AyuGram Preferences.", "> I didn't find this box or function.\n\n@LennoC \n\n<img width=\"596\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ed7ee163-1f2e-4afe-a3f7-f32bad9a50fc\" />\n\n<img width=\"424\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/1c61799a-a4dd-4798-9bcc-5156e2efb5e7\" />", "@ZavaruKitsu \nThank you very much. Maybe there's an improvement here, to make it faster and easier for us.\nNow I have to do 3 steps or more, I think we can:\nJust add a button or/and right-menu, then we can forward message without sender name very easily.\n\nBTW, new release function \"related channel from group\" is so exciting. Thank you for your efforts.", "Sorry for a late reply, but i can one up feature #3 as well. I use it literally everyday on Plus, on my phone. I like the way it is just adding a new line in the forwarding screen with 2 on/off switches. One for Quote and 1 for Captions. And it remembers what you chose last time, so i can send unquoted and uncapped fwds with only 1 click. And if i want captions and/or quote i can just turn it back on spot.\n\nThe easiest way would probably be simply saving checkbox state in send submenu. And adding \"Save forwarding options state\" in the Preferences.\n\nCompletely moving the whole submenu to the main fwd screen works too, since space real estate on PC usually is not a problem.", "any update for this  ?" ],
      "repository" : {
        "description" : "Desktop Telegram client with good customization and Ghost mode.",
        "homepage" : "https://t.me/ayugram",
        "name" : "AyuGramDesktop",
        "fullName" : "AyuGram/AyuGramDesktop",
        "htmlUrl" : "https://github.com/AyuGram/AyuGramDesktop",
        "gitUrl" : "git://github.com/AyuGram/AyuGramDesktop.git",
        "sshUrl" : "git@github.com:AyuGram/AyuGramDesktop.git",
        "cloneUrl" : "https://github.com/AyuGram/AyuGramDesktop.git",
        "owner" : {
          "login" : "AyuGram",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : true,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 212,
        "stargazersCount" : 2726,
        "watchersCount" : 2726,
        "size" : 267258,
        "openIssuesCount" : 38,
        "subscribersCount" : 31,
        "pushedAt" : "2025-07-23T16:41:03Z",
        "languages" : {
          "C++" : 23563133,
          "CSS" : 37230,
          "C" : 9950532,
          "Objective-C++" : 189841,
          "CMake" : 131177,
          "Inno Setup" : 6633,
          "Dockerfile" : 31262,
          "Shell" : 32173,
          "Batchfile" : 19610,
          "JavaScript" : 30301,
          "Objective-C" : 18226,
          "VBScript" : 752,
          "Python" : 100825
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to add feature and improvement suggestions from 64Gram to AyuGram, including two side-by-side buttons at the bottom of the channel page, jumping to related channels, forwarding without quote, and repeating a message.",
      "validationOrRequirement" : "The author is suggesting that the features should be implemented as they are commonly used in other clients, and that the state of the forwarding options should be saved.",
      "attemptedFixes" : "The comments suggest that the repeat function should be implemented as a context menu item, and the forwarding without quote function should be implemented as a new line in the forwarding screen with 2 on/off switches. One for Quote and 1 for Captions. The comments also suggest that the state of the forwarding options should be saved.",
      "otherNotes" : "The issue is about feature and improvement suggestions from 64Gram, a discontinued client. The author is suggesting two side-by-side buttons at the bottom of the channel page, jumping to related channels, forwarding without quote, and repeating a message. The author also mentioned that these features are commonly used in Android clients. The author is asking for these features to be added to AyuGram.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407720
  }, {
    "issueDTO" : {
      "id" : 2762034861,
      "title" : "[Bug] Backup CronJob is not updated when switching MariaDB replicas from >1 to none and hence keeps using non-existing `-primary` service",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/1100",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\r\nBugs should be filed for issues encountered whilst operating mariadb-operator.\r\nPlease provide as much detail as possible. \r\n-->\r\n\r\n**Documentation**\r\n- [x] I acknowledge that I have read the relevant [documentation](https://github.com/mariadb-operator/mariadb-operator/tree/main/docs).\r\n\r\n**Describe the bug**\r\n```\r\nmariadb \uD83D\uDCBE Exporting env\r\nmariadb \uD83D\uDCBE Writing target file: /backup/0-backup-target.txt\r\nmariadb \uD83D\uDCBE Setting target file permissions\r\nmariadb \uD83D\uDCBE Taking backup: /backup/backup.2024-12-28T22:13:47Z.sql\r\nmariadb mariadb-dump: Got error: 2005: \"Unknown server host 'mariadb-primary.home.svc.cluster.local' (-5)\" when trying to connect\r\n```\r\n\r\nWhen deploying a `MariaDB` \"server\" with the configuration below, it will only create the following two services\r\n- mariadb\r\n- mariadb-internal\r\n\r\n**However,  if the same `MariaDB` name was used before with `replicas`, a previously configured `CronJob` exists that wants to connect to `mariadb-primary` service.** This service is removed/non-existing when running without replication/Galera cluster.\r\n\r\n```yaml\r\napiVersion: k8s.mariadb.com/v1alpha1\r\nkind: MariaDB\r\nmetadata:\r\n  name: mariadb\r\n  labels:\r\n    app: mariadb\r\nspec:\r\n  rootPasswordSecretKeyRef:\r\n    name: mariadb\r\n    key: root-password\r\n    generate: true\r\n\r\n  storage:\r\n    volumeClaimTemplate:\r\n      resources:\r\n        requests:\r\n          storage: 10Gi\r\n      storageClassName: local-path\r\n      accessModes:\r\n        - ReadWriteOnce\r\n\r\n  metrics:\r\n    enabled: false\r\n```\r\n\r\n**Expected behaviour**\r\nI expect the CronJob to be updated whenever the underlying MariaDB instance is changed\r\n\r\n**Steps to reproduce the bug**\r\n<!--Steps to reproduce the bug should be clear and easily reproducible to help people\r\ngain an understanding of the problem.-->\r\n\r\n1. Create a single MariaDB instance WITH replication\r\n2. Create a backup CRD for this MariaDB instance\r\n3. Remove the replication from the MariaDB instance (CRD)\r\n4. \"Describe\" the CronJob and see the host is still set to `xxxx-primary....`\r\n\r\n**Debug information**\r\n- Related object events:\r\n```bash\r\nroot@kubernetes-1:~# kubectl get events --field-selector involvedObject.name=mariadb -n home\r\nLAST SEEN   TYPE     REASON             OBJECT                MESSAGE\r\n4h4m        Normal   SuccessfulCreate   statefulset/mariadb   create Pod mariadb-0 in StatefulSet mariadb successful\r\n25m         Normal   SuccessfulCreate   statefulset/mariadb   create Pod mariadb-0 in StatefulSet mariadb successful\r\n20m         Normal   SuccessfulCreate   statefulset/mariadb   create Claim storage-mariadb-0 Pod mariadb-0 in StatefulSet mariadb success\r\n20m         Normal   SuccessfulCreate   statefulset/mariadb   create Pod mariadb-0 in StatefulSet mariadb successful\r\n\r\nroot@kubernetes-1:~# kubectl get events --field-selector involvedObject.name=backup -n home\r\nLAST SEEN   TYPE      REASON             OBJECT           MESSAGE\r\n3h47m       Normal    SuccessfulCreate   cronjob/backup   Created job backup-28923540\r\n167m        Normal    JobAlreadyActive   cronjob/backup   Not starting job because prior execution is running and concurrency policy is Forbid\r\n147m        Normal    JobAlreadyActive   cronjob/backup   Not starting job because prior execution is running and concurrency policy is Forbid\r\n143m        Normal    JobAlreadyActive   cronjob/backup   Not starting job because prior execution is running and concurrency policy is Forbid\r\n107m        Normal    JobAlreadyActive   cronjob/backup   Not starting job because prior execution is running and concurrency policy is Forbid\r\n98m         Normal    JobAlreadyActive   cronjob/backup   Not starting job because prior execution is running and concurrency policy is Forbid\r\n47m         Normal    JobAlreadyActive   cronjob/backup   Not starting job because prior execution is running and concurrency policy is Forbid\r\n50m         Normal    SuccessfulDelete   cronjob/backup   Deleted job backup-28923480\r\n50m         Normal    SawCompletedJob    cronjob/backup   Saw completed job: backup-28923540, condition: Failed\r\n50m         Normal    SuccessfulCreate   cronjob/backup   Created job backup-28923660\r\n47m         Normal    SuccessfulDelete   cronjob/backup   Deleted job backup-28923540\r\n47m         Normal    SawCompletedJob    cronjob/backup   Saw completed job: backup-28923660, condition: Failed\r\n47m         Normal    SuccessfulCreate   cronjob/backup   Created job backup-28923720\r\n41m         Normal    SuccessfulDelete   cronjob/backup   Deleted job backup-28923660\r\n41m         Normal    SawCompletedJob    cronjob/backup   Saw completed job: backup-28923720, condition: Failed\r\n30m         Warning   UnexpectedJob      cronjob/backup   Saw a job that the controller did not create or forgot: backup-manual-qp5\r\n30m         Normal    SuccessfulDelete   cronjob/backup   Deleted job backup-28923720\r\n8m54s       Warning   UnexpectedJob      cronjob/backup   Saw a job that the controller did not create or forgot: backup-manual-m65\r\n8m54s       Normal    SuccessfulDelete   cronjob/backup   Deleted job backup-manual-qp5\r\n```\r\n\r\n**Environment details**:\r\n- Kubernetes version: v1.31.4\r\n- Kubernetes distribution: k3s\r\n- mariadb-operator version: 0.36.0\r\n- Galera data-plane version (init and agent): -\r\n- Install method: helm via flux (HelmRelease)\r\n\r\n**Additional context**\r\nCurrent workaround is to remove the `Backup` CRD and recreate it. ",
      "updatedAt" : 1753365766.000000000,
      "user" : "kevinvalk",
      "userHtmlUrl" : "https://github.com/kevinvalk",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3524694?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This issue is stale because it has been open 60 days with no activity.", "> However, if the same MariaDB name was used before with replicas, a previously configured CronJob exists that wants to connect to mariadb-primary service\n\nAltough possible, we are not aiming to support migrating from one topology to another just by updating the manifest. We could add immutability for enforcing this.\n\nFor this case, we can explore having the `*-primary` service created for the standalone topology as well, for consistency reasons.", "This issue is stale because it has been open 60 days with no activity.", "This issue was closed because it has been stalled for 30 days with no activity." ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The Backup CronJob is not updated when switching MariaDB replicas from >1 to none and hence keeps using non-existing -primary service",
      "validationOrRequirement" : "The CronJob should be updated whenever the underlying MariaDB instance is changed",
      "attemptedFixes" : "Not mentioned",
      "otherNotes" : "Current workaround is to remove the Backup CRD and recreate it, Although possible, we are not aiming to support migrating from one topology to another just by updating the manifest. We could add immutability for enforcing this. For this case, we can explore having the *-primary service created for the standalone topology as well, for consistency reasons.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407725
  }, {
    "issueDTO" : {
      "id" : 3246320585,
      "title" : "Misaligned venue titles",
      "url" : "https://github.com/nusmodifications/nusmods/issues/4114",
      "repositoryName" : "nusmodifications/nusmods",
      "description" : "### Describe the bug\n\nAKIMLA 4 is misaligned on the venu search page. This is likely because it's the first venue so the left button is disabled and is shorter:\n\n<img width=\"2520\" height=\"639\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5eadd4ca-e1d8-42d6-b5a0-a18acb50693b\" />\n\n<img width=\"2547\" height=\"733\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/410a6988-3d45-42ae-bcde-8016ac6ab38a\" />\n\nSame issue with the last venue:\n\n<img width=\"1753\" height=\"424\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2039c629-d7c7-49aa-9e9d-71c6483976f7\" />\n\n### Additional context\n\nIf you are interested in working on this, a good place to look is `VenueDetailsComponent`.",
      "updatedAt" : 1753365656.000000000,
      "user" : "leslieyip02",
      "userHtmlUrl" : "https://github.com/leslieyip02",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/90888680?v=4",
      "labels" : [ "bug", "taken", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "\uD83C\uDFEB Official course planning platform for National University of Singapore.",
        "homepage" : "https://nusmods.com",
        "name" : "nusmods",
        "fullName" : "nusmodifications/nusmods",
        "htmlUrl" : "https://github.com/nusmodifications/nusmods",
        "gitUrl" : "git://github.com/nusmodifications/nusmods.git",
        "sshUrl" : "git@github.com:nusmodifications/nusmods.git",
        "cloneUrl" : "https://github.com/nusmodifications/nusmods.git",
        "owner" : {
          "login" : "nusmodifications",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 340,
        "stargazersCount" : 626,
        "watchersCount" : 626,
        "size" : 50133,
        "openIssuesCount" : 193,
        "subscribersCount" : 23,
        "pushedAt" : "2025-07-24T14:01:44Z",
        "languages" : {
          "TypeScript" : 1467694,
          "CSS" : 14492,
          "Shell" : 5956,
          "Pug" : 946,
          "ANTLR" : 2895,
          "SCSS" : 139677,
          "JavaScript" : 83587,
          "Go" : 26565,
          "HTML" : 3760,
          "EJS" : 2514
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To fix the misaligned venue titles on the venue search page, likely due to the first and last venues having different layouts.",
      "validationOrRequirement" : "No specific validations or requirements are mentioned in the description or comments.",
      "attemptedFixes" : "No attempted fixes or blockers are mentioned in the description or comments.",
      "otherNotes" : "The issue is related to the VenueDetailsComponent and involves misaligned venue titles on the venue search page, with the left button being disabled for the first venue and the last venue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407728
  }, {
    "issueDTO" : {
      "id" : 3258757527,
      "title" : "No need to skip for float and long double in the basket test",
      "url" : "https://github.com/poncateam/ponca/issues/185",
      "repositoryName" : "poncateam/ponca",
      "description" : "Why is the skip for float and long double still present in the basket test, [at line 112](https://github.com/poncateam/ponca/blob/d9b2414879888a554f21a2b771a9a96dedb4421c/tests/src/basket.cpp#L110C1-L113C22) ? It should have been removed in the PR #162 which fix this approximation error by sorting the fit3.\nThese 4 lines shouldn't have been added back.",
      "updatedAt" : 1753365656.000000000,
      "user" : "Me-k-01",
      "userHtmlUrl" : "https://github.com/Me-k-01",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/57592360?v=4",
      "labels" : [ "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "It was added back by mistake during the PR #167." ],
      "repository" : {
        "description" : "Ponca (fomerly known as Patate) is a header only C++/CUDA library for point cloud analysis",
        "homepage" : "https://poncateam.github.io/ponca/",
        "name" : "ponca",
        "fullName" : "poncateam/ponca",
        "htmlUrl" : "https://github.com/poncateam/ponca",
        "gitUrl" : "git://github.com/poncateam/ponca.git",
        "sshUrl" : "git@github.com:poncateam/ponca.git",
        "cloneUrl" : "https://github.com/poncateam/ponca.git",
        "owner" : {
          "login" : "poncateam",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 23,
        "stargazersCount" : 35,
        "watchersCount" : 35,
        "size" : 56813,
        "openIssuesCount" : 34,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-23T12:48:15Z",
        "languages" : {
          "C++" : 482024,
          "C" : 4332,
          "CMake" : 21013
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Why is the skip for float and long double still present in the basket test, and it should have been removed in the PR #162 which fix this approximation error by sorting the fit3.",
      "validationOrRequirement" : "remove the skip for float and long double in the basket test",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "It was added back by mistake during the PR #167.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407731
  }, {
    "issueDTO" : {
      "id" : 2863944681,
      "title" : "Release branches have all required checks for QA run",
      "url" : "https://github.com/camunda/camunda/issues/28417",
      "repositoryName" : "camunda/camunda",
      "description" : "## Description\n\nAs a part of the [release process](https://github.com/camunda/camunda/wiki/Release-Process) in the BPMN model, one of the [QA steps is to ensure all important checks on the release branch are passing](https://github.com/camunda/zeebe-engineering-processes/blob/main/src/main/resources/release/forms/qa_build_check.form).\n\nCurrently, not all of these CI checks are run on the release branches and possibly, some checks that should be are not.\n\n## Goal\n\n- Agree with the QA team on what are the must-have CI checks that need to run on the release branches to suffice for the release process\n  - (if relevant) Document this decision\n- Ensure these checks are configured to run on the release branches\n",
      "updatedAt" : 1753365393.000000000,
      "user" : "maxdanilov",
      "userHtmlUrl" : "https://github.com/maxdanilov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/6655714?v=4",
      "labels" : [ "kind/bug", "area/project", "component/build-pipeline", "component/release", "blocker/stakeholder", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Details provided by @cmur2 :\n\nThere is [a form in the release process](https://github.com/camunda/zeebe-engineering-processes/blob/main/src/main/resources/release/forms/qa_build_check.form) (camunda_release.bpmn -> Start automated release QA process -> Check QA results) that required the monorepo release manager to check if certain CI workflows are green. That list is outdated and possibly incomplete and this ticket is about fixing that.\n\nTwo questions:\n1. is the list complete aka all CI checks that QA thinks are necessary for a release candidate (to judge whether the software is ok) also on the list?\n2. is the list outdated aka are there CI checks on the list which are actually not needed?\n\nOnce we have an answer for the above two questions, we can have a look at the triggers of CI checks and \na) remove triggers if those checks don't need to run on releases \nb) add triggers if CI checks should run.\n\n[Reference search (possible inaccurate due to GH Search) for CI checks that _currently_ run on release branches](https://github.com/search?q=repo%3Acamunda%2Fcamunda%20push%20branches%20release**&type=code).\n\nThose CI checks will be re-run for each commit pushed to a release branch. I think that is proper behavior since people might be pushing hotfixes to release branches and we want to have up2date info.\n\n```\n# Check CI build pipeline and QA build\n\nCheck the results of the following builds. Verify that the latest build for the release branch is successful. If there are any not-successful builds, ask the respective DRI to analyze them and understand if they can be ignored. For example, `ABORTED` builds (grey) can be ignored, but should be retried - these typically indicate the node running the build was restarted mid-way. Red builds should be analyzed, but at times there may be a known flaky tests which should not block the release. If in doubt, ask your tech lead for advice.\n\n#### Monorepo CI\n\n* [GitHub CI](https://github.com/camunda/camunda/actions/workflows/ci.yml?query=branch%3A{{ release_branch_name }})\n\n#### Zeebe CI/QA\n\n* [Slack #zeebe-ci](https://app.slack.com/client/T0PM0P1SA/C013MEVQ4M9/activity)\n* DRI: `@zeebe-medic`\n\n#### Tasklist CI github builds\n\n* URL:\n  * https://github.com/camunda/camunda/actions/workflows/tasklist-ci.yml?query=branch%3A{{ release_branch_name }}\n  * https://github.com/camunda/camunda/actions/workflows/tasklist-e2e-tests.yml?query=branch%3A{{ release_branch_name }}\n  * https://github.com/camunda/camunda/actions/workflows/tasklist-docker-tests.yml?query=branch%3A{{ release_branch_name }}\n* DRI: `@tasklist-release-manager`\n\n#### Operate CI github builds\n\n* URL:\n  * https://github.com/camunda/camunda/actions/workflows/operate-ci.yml?query=branch%3A{{ release_branch_name }}\n  * https://github.com/camunda/camunda/actions/workflows/operate-frontend.yml?query=branch%3A{{ release_branch_name }}\n  * https://github.com/camunda/camunda/actions/workflows/operate-e2e-tests.yml?query=branch%3A{{ release_branch_name }}\n* DRI: `@operate-release-manager`\n```", "@mschoe and @esraagamal6 kindly confirmed no updates are currently required for the CI checks:\n\n<img width=\"1204\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/97cdb8aa-eef6-4415-b50e-3fb4647d93b5\" />\n\n<img width=\"483\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/072ae7e9-159e-48c9-bb5e-e2a3c22e6e02\" />", "https://github.com/camunda/camunda/actions/workflows/tasklist-docker-tests.yml is now triggered from https://github.com/camunda/camunda/actions/workflows/ci.yml, so removing it from the form", "https://github.com/camunda/camunda/actions/workflows/operate-ci.yml in https://github.com/camunda/camunda/pull/31518 was split into those 3 workflows:\nhttps://github.com/camunda/camunda/actions/workflows/operate-ci-core-features.yml\nhttps://github.com/camunda/camunda/actions/workflows/operate-ci-data-layer.yml\nhttps://github.com/camunda/camunda/actions/workflows/operate-ci-identity.yml\n\nUpdating the form with those checks in https://github.com/camunda/zeebe-engineering-processes/pull/565", "Putting the ticket on hold until alpha6", "@oleksandr-kriuchenko-lohika could you please revisit this issue with the QA? (now that alpha6 has been released)" ],
      "repository" : {
        "description" : "Process Orchestration Framework",
        "homepage" : "https://camunda.com/platform/",
        "name" : "camunda",
        "fullName" : "camunda/camunda",
        "htmlUrl" : "https://github.com/camunda/camunda",
        "gitUrl" : "git://github.com/camunda/camunda.git",
        "sshUrl" : "git@github.com:camunda/camunda.git",
        "cloneUrl" : "https://github.com/camunda/camunda.git",
        "owner" : {
          "login" : "camunda",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 682,
        "stargazersCount" : 3738,
        "watchersCount" : 3738,
        "size" : 654460,
        "openIssuesCount" : 2401,
        "subscribersCount" : 114,
        "pushedAt" : "2025-07-25T00:56:57Z",
        "languages" : {
          "MDX" : 2383,
          "Smarty" : 230,
          "Java" : 53444072,
          "CSS" : 2925,
          "Makefile" : 20359,
          "Go" : 76584,
          "HTML" : 14083,
          "FreeMarker" : 94639,
          "TypeScript" : 6833929,
          "Dockerfile" : 23726,
          "Shell" : 45165,
          "Batchfile" : 3877,
          "SCSS" : 134945,
          "JavaScript" : 1534275
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Ensure all required CI checks are run on release branches as part of the release process and agree on the must-have CI checks with the QA team.",
      "validationOrRequirement" : "The issue requires the QA team to agree on the must-have CI checks and ensure they are configured to run on release branches. The CI checks should be reviewed and triggers removed or added as needed.",
      "attemptedFixes" : "The author mentions that @cmur2, @mschoe, and @esraagamal6 confirmed no updates are currently required for the CI checks. The issue has been put on hold until alpha6 and @oleksandr-kriuchenko-lohika has been asked to revisit the issue with the QA team.",
      "otherNotes" : "The issue is about ensuring all required CI checks are run on release branches as part of the release process. The QA team needs to agree on the must-have CI checks and ensure they are configured to run on release branches. The issue also involves reviewing the triggers of CI checks and removing or adding triggers as needed.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407738
  }, {
    "issueDTO" : {
      "id" : 3224961029,
      "title" : "About the automatic carriage return problem of pasting part",
      "url" : "https://github.com/google-gemini/gemini-cli/issues/3953",
      "repositoryName" : "google-gemini/gemini-cli",
      "description" : "### What would you like to be added?\n\nRemove the paste return to prevent the message from being automatically sent when pasting.\n\n### Why is this needed?\n\nAbout the automatic carriage return problem of pasting part\n\nDuring use, we often need to paste some errors, codes, etc. into cli for communication, but I found that now no matter in the web editor, carriage return will be attached when pasting. This will cause me to send the problem directly after pasting. But in fact, I didn't finish writing. But when I stopped by esc, I tried to retrieve the previous conversation, but it disappeared, and I could never complete the pasting operation.\n\nAnother way is to copy and paste it into an unformatted part first, such as WIN+R to run the input box before copying and pasting it into cli. I think this is a very big problem and seriously affects development efficiency.\n\nI wonder if the last space can be automatically cleaned when pasting to prevent sending messages before editing is completed.\n\nNow as long as it involves me entering some text, and then I try to combine errors in multiple locations to ask questions. It can't be completed at all. I tried \\ enter shift, but it didn't work.\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753365238.000000000,
      "user" : "ISensuiI",
      "userHtmlUrl" : "https://github.com/ISensuiI",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/13973830?v=4",
      "labels" : [ "area/ux", "kind/enhancement", "priority/p2", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Ubuntu and some bespoke Linux here. Miraculously in Gemini CLI's GUI the EOL marks in the pasted snippets so far have been rightly converted to some marks that do not trigger sending the command. (That is: I do not have this problem). \n(While e.g. Grok AI's GUI is awful in that respect indeed: every copied string from its own GUI appends  double EOLs, methinks) \n\n\nTwo tips for now: \nA. Just keep a scratchpad file open in the same folder so that Gemini can access it. Then you can paste there anything, without worrying. Gemini then shall read it via `read_file` when you tell her to do so. Just keep that TXT file open in another window: `gedit`, `notepad` etc. one.  \nB. Describe what to do, then add some \"code here:\" as an informal marker between intent and source, and the code as the source (that may indeed trigger execution then).  \n\n", "It is a method, I understand what you mean. Create a temp.txt file to handle pasting. But many times we don't need a large text, such as a small error message, which can also cause this problem. I understand that it is because of system reasons and some IDEs or webs have implicit line breaks, which I think should be automatically cleaned up. I can indeed use the method you gave for the time being. Thank you for your reply.", "Thanks for flagging this, @ISensuiI! Accidental sends on paste are annoying. A quick fix could be:\n\n1. **Trim trailing newlines on paste** before inserting text.  \n2. **Use Shift+Enter** for new lines; only plain Enter sends.  \n3. **Guard on send**???strip any leftover newline before submitting.\n\nI???d love to tackle this???could you please assign #3953 to me? I can draft a small PR with these handlers if you???re on board! \uD83D\uDE4F\uD83C\uDFFE\n", "Yes, thank you very much for helping me complete the PR. Is there anything I can do? Or can you just submit a PR and reference the current issue? I have never submitted a PR myself, so I don't know the correct process. How should I proceed?", "> Yes, thank you very much for helping me complete the PR. Is there anything I can do? Or can you just submit a PR and reference the current issue? I have never submitted a PR myself, so I don't know the correct process. How should I proceed?\n\nGemini-CLI can guide you in every step", "> Yes, thank you very much for helping me complete the PR. Is there anything I can do? Or can you just submit a PR and reference the current issue? I have never submitted a PR myself, so I don't know the correct process. How should I proceed?\n\nThanks for confirming! I???ll start working on this and will open a PR linked to this issue.\n\n", "Myself I thought about using MS PowerToys for this to do on fly replacement, but I was also thinking about another solution that is more advanced (to my level) that will do this automatically by detecting the Terminal window name and thus applying the replacement exclusively to that window without even having to remember anything (sort of set and forget). But I also thought about something like Windows Commander Palette plugin that will sort of type the text and by modifying to replace the new line chars by Ctrl+Enter (I think it can work but I need to test the idea, yet it can be slower than it should to do it this way and also cause all sort of UX undesirable situations.)\n\nTomorrow hopefully I will try to learn more about this and what would be the best options to have to circumvent this issue, but I hope that Gosling will come up with an elegant solution that will make all my tinkering obsolete. ", "Quick temporary fix that worked well for me : just **dumbly paste it into your navigator search** bar (Chrome/Firefox), this will remove all line carriage, ctrl+c again and you should be good to go ", "Yes, https://github.com/google-gemini/gemini-cli/issues/3953#issuecomment-3102402480 shall work, just do not press \"Enter\" ;) then.  \nFYI: https://textcleaner.net/ is a more elegant solution. Or `terminator` etc. as your terminal. ", "My current method is to use nodepad to input once to complete the editing and then press CTRL+A CTRL+V and there will be no problem.", "@Gosling-dude Are you working on it? If not, will try to write a PR for this since its an issue which is bugging me a lot,", "> [@Gosling-dude](https://github.com/Gosling-dude) Are you working on it? If not, will try to write a PR for this since its an issue which is bugging me a lot,\n\n@binarycache Thanks for the nudge! I???m just about to carve out some time to start on this today. Feel free to tackle it in parallel if you???d like???happy to collaborate on a joint PR or review your branch. Otherwise, I???ll aim to have a draft ready by end of day tomorrow and will link it here. Let me know what works best for you!", "I would like to add one more thing. I hope that when someone PRs, they can pay attention to the fact that ! will cause code truncation. For example, if I use\n\nXXXXXXXXXX return !anyhow(\"XXXXXXXXXX\")\n\nNo matter how long the conversation is, it will be truncated by ! . So even if I use the notepad combination, I have to manually replace ! again.\nIt becomes\n\nanyhow(\"XXXXXXXXXX\")", "> I would like to add one more thing. I hope that when someone PRs, they can pay attention to the fact that ! will cause code truncation. For example, if I use\n> \n> XXXXXXXXXX return !anyhow(\"XXXXXXXXXX\")\n> \n> No matter how long the conversation is, it will be truncated by ! . So even if I use the notepad combination, I have to manually replace ! again. It becomes\n> \n> anyhow(\"XXXXXXXXXX\")\n\n@ISensuiI Thanks for flagging this???good catch! The current approach naively strips any trailing characters, which unfortunately eats leading ! tokens. In the PR I???ll:\n\n- Limit trimming so it only drops \\n/\\r\\n at the end of the pasted block???no other characters will be removed.\n- Preserve leading/trailing ! by only targeting newline characters in the regex (e.g. text.replace(/[\\r\\n]+$/g, '')).\n- Add a test case specifically for a snippet like return !anyhow(\"XXX\") to ensure the ! survives intact.\n\nLet me know if there are any other edge-cases you???ve seen! I???ll include this in the upcoming draft.\n", "> > [@Gosling-dude](https://github.com/Gosling-dude) Are you working on it? If not, will try to write a PR for this since its an issue which is bugging me a lot,\n> \n> [@binarycache](https://github.com/binarycache) Thanks for the nudge! I???m just about to carve out some time to start on this today. Feel free to tackle it in parallel if you???d like???happy to collaborate on a joint PR or review your branch. Otherwise, I???ll aim to have a draft ready by end of day tomorrow and will link it here. Let me know what works best for you!\n\n@Gosling-dude No worries, I plan to take it up in the weekend. So please go ahead, if any help or review is needed do let me know." ],
      "repository" : {
        "description" : "An open-source AI agent that brings the power of Gemini directly into your terminal.",
        "homepage" : "",
        "name" : "gemini-cli",
        "fullName" : "google-gemini/gemini-cli",
        "htmlUrl" : "https://github.com/google-gemini/gemini-cli",
        "gitUrl" : "git://github.com/google-gemini/gemini-cli.git",
        "sshUrl" : "git@github.com:google-gemini/gemini-cli.git",
        "cloneUrl" : "https://github.com/google-gemini/gemini-cli.git",
        "owner" : {
          "login" : "google-gemini",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5999,
        "stargazersCount" : 63648,
        "watchersCount" : 63648,
        "size" : 18267,
        "openIssuesCount" : 1398,
        "subscribersCount" : 311,
        "pushedAt" : "2025-07-25T00:19:30Z",
        "languages" : {
          "TypeScript" : 2800004,
          "Dockerfile" : 1354,
          "Shell" : 1112,
          "Makefile" : 1336,
          "JavaScript" : 87062
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "the main goal of this issue is to resolve the automatic carriage return problem when pasting in the cli, which causes the message to be sent before editing is completed, and the solution should be able to automatically clean up the last space when pasting and preserve leading/trailing ! tokens.",
      "validationOrRequirement" : "the issue requires a solution that can automatically clean up the last space when pasting to prevent sending messages before editing is completed, and also preserve leading/trailing ! tokens, and the solution should be able to handle edge-cases such as snippets with ! tokens, and also consider the fact that ! will cause code truncation.",
      "attemptedFixes" : "the users have tried various workarounds such as using a scratchpad file, describing what to do and adding a code marker, and using a temp.txt file to handle pasting, but these solutions are not ideal and the issue is still present, and some users have also suggested more advanced solutions such as using MS PowerToys or Windows Commander Palette plugin to detect the terminal window name and apply the replacement exclusively to that window.",
      "otherNotes" : "the issue is about removing the automatic carriage return when pasting in the cli, which causes the message to be sent before editing is completed, and the suggested solutions include trimming trailing newlines on paste, using shift+enter for new lines, and guarding on send to strip leftover newline before submitting, and there are also some temporary workarounds mentioned.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407748
  }, {
    "issueDTO" : {
      "id" : 2876207344,
      "title" : "[Bug] Revoking privileges on a user with specific database and GRANT OPTION can produce invalid SQL statement",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/1176",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\nBugs should be filed for issues encountered whilst operating mariadb-operator.\nPlease provide as much detail as possible. \n-->\n\n**Documentation**\n- [x] I acknowledge that I have read the relevant [documentation](https://github.com/mariadb-operator/mariadb-operator/tree/main/docs).\n\n**Describe the bug**\n\nRevoking grants can produce an invalid SQL statement when attempting to revoke a user with both a specific database assignment and the user also has `GRANT OPTION`.\n\nThe SQL produced by revoke has a subtle problem which can be described in an old mysql bug report I found: https://bugs.mysql.com/bug.php?id=69313\n\nBasically, you can't issue a:\n```REVOKE ALL PRIVILEGES, GRANT OPTION ON `nova_cell0`.* FROM 'nova'@'%';``` as it produces an error:\n\n```\nMariaDB [(none)]> REVOKE ALL PRIVILEGES, GRANT OPTION ON `nova_cell0`.* FROM 'nova'@'%';\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'ON `nova_cell0`.* FROM 'nova'@'%'' at line 1\n```\n\n\nYou can only do `REVOKE all privileges, grant option FROM user` - it can't be combined with the specific database nova_cell0 with ```ON `nova_cell0`.*```\n\nMaybe there should be two separate REVOKEs - 1 for revoking on a specific database, and a second revoke for the grant options?\n\nMariaDB revoke reference docs showing the `REVOKE ... ON` versus `REVOKE GRANT OPTION FROM`: https://mariadb.com/kb/en/revoke/\n\n**Expected behaviour**\n\nExpecting revoke to work without error.\n\n**Steps to reproduce the bug**\n\nUsing manifest:\n\n```\n---\napiVersion: k8s.mariadb.com/v1alpha1\nkind: Grant\nmetadata:\n  name: nova-cell0-grant\n  namespace: openstack\nspec:\n  mariaDbRef:\n    name: mariadb\n    waitForIt: true\n  privileges:\n    - \"ALL\"\n  database: \"nova_cell0\"\n  table: \"*\"\n  username: nova\n  grantOption: true\n  host: \"%\"\n  retryInterval: 5s\n```\n\nThen issuing a revoke. We added logging to see the actual SQL statement being executed, which is invalid:\n\n```\nREVOKE ALL,GRANT OPTION ON `nova_cell0`.* FROM 'nova'@'%';\n```\n\n```\nMariaDB [(none)]> REVOKE ALL PRIVILEGES, GRANT OPTION ON `nova_cell0`.* FROM 'nova'@'%';\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'ON `nova_cell0`.* FROM 'nova'@'%'' at line 1\n```\n\nAnd this error in the operator logs:\n\n```\n{\"level\":\"error\",\"ts\":1740421634.2657945,\"msg\":\"Reconciler error\",\"controller\":\"grant\",\"controllerGroup\":\"k8s.mariadb.com\",\"controllerKind\":\"Grant\",\"Grant\":{\"name\":\"nova-cell0-grant\",\"namespace\":\"openstack\"},\"namespace\":\"openstack\",\"name\":\"nova-cell0-grant\",\"reconcileID\":\"a690ec22-3c8d-47f5-ba31-e8c51b3b414e\",\"error\":\"error reconciling in TemplateReconciler: error reconciling in TemplateFinalizer: error revoking grant in MariaDB: 1 error occurred:\\n\\t* Error 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'ON `nova_cell0`.* FROM 'nova'@'%'' at line 1\\n\\n\",\"stacktrace\":\"sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller[...]).reconcileHandler\\n\\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.19.0/pkg/internal/controller/controller.go:316\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller[...]).processNextWorkItem\\n\\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.19.0/pkg/internal/controller/controller.go:263\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller[...]).Start.func2.2\\n\\t/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.19.0/pkg/internal/controller/controller.go:224\"}\n```\n\n**Environment details**:\n- MariaDB Operator version: 0.31.0\n- MariaDB Server version: 11.0.3-MariaDB-1:11.0.3+maria~ubu2204\n- Install method: argocd + helm\n",
      "updatedAt" : 1753365159.000000000,
      "user" : "nicholaskuechler",
      "userHtmlUrl" : "https://github.com/nicholaskuechler",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1755790?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "hi, can i work on it?\n", "This issue is stale because it has been open 60 days with no activity.", "This issue was closed because it has been stalled for 30 days with no activity.", "Hey @IvanPiatnishin ! Yes, please, go ahead", "Please take into account the new changes that have been introduced here, which handles the `REVOKE` differently as stated in the issue:\nhttps://github.com/mariadb-operator/mariadb-operator/pull/1326" ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to resolve the bug where revoking privileges on a user with specific database and GRANT OPTION can produce an invalid SQL statement.",
      "validationOrRequirement" : "The issue is specific to the MariaDB Operator and the revoke functionality. It requires the MariaDB Server version to be 11.0.3-MariaDB-1:11.0.3+maria~ubu2204 and the MariaDB Operator version to be 0.31.0. The installation method is via argocd + helm.",
      "attemptedFixes" : "Two separate REVOKEs - 1 for revoking on a specific database, and a second revoke for the grant options, were suggested as a possible solution.",
      "otherNotes" : "The issue is related to the MariaDB Operator and the revoke functionality. The SQL statement produced by the revoke has a subtle problem which can be described in an old mysql bug report. The error is due to the combination of revoking privileges on a specific database and the user having GRANT OPTION. It is expected to work without error.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407755
  }, {
    "issueDTO" : {
      "id" : 3063366742,
      "title" : "Test Main Data Storage Functions for Sun Position",
      "url" : "https://github.com/UWOrbital/OBC-firmware/issues/408",
      "repositoryName" : "UWOrbital/OBC-firmware",
      "description" : "## Background\nThe main data storage functions for the sun position files where implemented but need to be tested.\n\n## Requirements\nWork off the branch: https://github.com/UWOrbital/OBC-firmware/tree/yarik%2Fsun-file under obc/modules/sun.\n \n- [ ] The code should be moved to obc/app/sys after updating the branch with main\n- [ ]  Create an example in obc/app/example with a stack size of 10kb\n- [ ]  Generate about 8kbs of data from the ephemeris.py script and store it as a variable in the stack\n- [ ]  Have that variable write all the data to the sun file\n- [ ]  Run the `ephemeris.py` to get 8kb of data: https://github.com/UWOrbital/OBC-firmware/blob/main/gs/backend/sun/README.md\n- [ ]  Test the ephemeris module\n\n## Important Information\nThe data storage file will be a regular file that fixed at the start of the mission\n\nFor reference, a data point???s coordinates are 12 bytes in the current implementation.\n\nThe file will be in the same format as the data file generated by the ephemeris.py script here: https://github.com/UWOrbital/OBC-firmware/blob/main/gs/backend/sun/README.md#contents-of-the-output-file\n\nIt will support the following operations:\n\n- Read a data point from a data point index from the file O(1)\n- Get smallest JD O(1)\n- Get largest JD O(1)\n- Check if a JD is within the range of the file O(1)\n- Get the number of data points in the file, this should be O(1)\n- Get the index of a JD in the file O(1)\n- Get the number of data points after an inputted JD (use previous 2 functions)\n- Additionally: Pack/unpack functions for doubles\n\nAsk @Yarik if you have any questions\n\nThese functions have already been implemented but they need to be tested on the obc\n\nBranch with code: https://github.com/UWOrbital/OBC-firmware/tree/yarik%2Fsun-file under obc/modules/sun. The code should probably be moved to sys and it still needs to be tested\n",
      "updatedAt" : 1753364821.000000000,
      "user" : "Yarik-Popov",
      "userHtmlUrl" : "https://github.com/Yarik-Popov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/89220488?v=4",
      "labels" : [ "project: firmware", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Process to get the required data:\n1. Run `ephemeris.py` with the required arguments to generate around 8kb of data, output it to a file\nNow in `main.c` of the example\n2. Copy this file into an array in c\n3. You will need to use a function to write this array from step 2 into a file (iirc the default is `sun_file.bin` but u will need to check the `sun_file.c` for the name)\n4. You will then initialize the sun module\n5. You will need to write some tests that use the data from the sun file from earlier\n6. Delete the file at the end if the tests fail or succeed (I would define a macro that would delete the sun data file if an non success error code is returned)", "The file name is in ephemeris.c. This file is the entry point to the sun module. All the other filed shouldnt be called directly by users and are public just for testing reasons. \n\nSince we can't get a file onto the SD card, we need to resort to writing the bytes of the file from the main.c example file.\n\nIt would be the other way around. You will need to manually copy the data from the file that is generated by ephemeris.py into an array in your main.c file than on the obc have this array be written to a file" ],
      "repository" : {
        "description" : "All code developed by the UW Orbital firmware team",
        "homepage" : "",
        "name" : "OBC-firmware",
        "fullName" : "UWOrbital/OBC-firmware",
        "htmlUrl" : "https://github.com/UWOrbital/OBC-firmware",
        "gitUrl" : "git://github.com/UWOrbital/OBC-firmware.git",
        "sshUrl" : "git@github.com:UWOrbital/OBC-firmware.git",
        "cloneUrl" : "https://github.com/UWOrbital/OBC-firmware.git",
        "owner" : {
          "login" : "UWOrbital",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 24,
        "stargazersCount" : 20,
        "watchersCount" : 20,
        "size" : 17425,
        "openIssuesCount" : 173,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-24T19:14:49Z",
        "languages" : {
          "C++" : 563057,
          "CSS" : 4685,
          "Jinja" : 4612,
          "C" : 9389472,
          "CMake" : 55375,
          "SWIG" : 1096,
          "QMake" : 2406,
          "Makefile" : 302,
          "HTML" : 794,
          "TypeScript" : 20520,
          "Shell" : 793,
          "Linker Script" : 22041,
          "Assembly" : 185204,
          "Python" : 193463
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Test the main data storage functions for the sun position files that were implemented but need to be tested.",
      "validationOrRequirement" : "The code should be moved to obc/app/sys after updating the branch with main, create an example in obc/app/example with a stack size of 10kb, generate about 8kbs of data from the ephemeris.py script and store it as a variable in the stack, have that variable write all the data to the sun file, run the ephemeris.py to get 8kb of data, test the ephemeris module.",
      "attemptedFixes" : "The code has already been implemented, but it needs to be tested on the obc. The code should be moved to obc/app/sys after updating the branch with main.",
      "otherNotes" : "The data storage file will be a regular file that is fixed at the start of the mission. The file will be in the same format as the data file generated by the ephemeris.py script. It will support various operations such as reading a data point, getting smallest JD, getting largest JD, checking if a JD is within the range of the file, getting the number of data points, getting the index of a JD, and getting the number of data points after an inputted JD. The pack/unpack functions for doubles are also supported.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407764
  }, {
    "issueDTO" : {
      "id" : 3132356429,
      "title" : "Add a downloaded option to the episode filter list on the podcast details page.",
      "url" : "https://github.com/amugofjava/anytime_podcast_player/issues/150",
      "repositoryName" : "amugofjava/anytime_podcast_player",
      "description" : "**Is your feature request related to a problem? Please describe.**\nThis is a request from a user received via email. It would be useful to be able to filter downloaded episodes within the podcast details page.\n\n**Describe the solution you'd like**\nAdd a 'Downloaded' option to the Filter episodes list.\n\n",
      "updatedAt" : 1753364811.000000000,
      "user" : "amugofjava",
      "userHtmlUrl" : "https://github.com/amugofjava",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5526902?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi!  I'd love to work on this issue. It looks like a great first issue to get started with. Is there anything i need to be aware of before starting on this issue please let me know...any approaches you would want me to follow?\n\nmy approach would be updating the ui by adding a downloaded button that would navigate user to the downloaded episodes for that podcast or overall downloads...\n\nCould you please assign it to me?\nI'll start working on it and open a pull request once assigned. Thanks! \uD83D\uDE4C", "Hi @sandy4242,\n\nYes, sure, I'm happy to assign this to you; however, the issue is more straightforward and wouldn't need an additional button.\n\nIf you go into the list of episodes for podcast you will see a filter button which allows you to filter episodes:\n\n<img width=\"288\" height=\"272\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/011e05a0-dde8-42ca-9d5f-7a3c971af6ac\" />\n\nWhat the user has requested is an additional option of 'Downloaded' in the list, so they can filter downloaded episodes for that podcast. If you would like to go ahead with implementing this, please let me know and I can assign it to you.\n\nOne thing to be aware of is that you will need to add a new string in the `L.dart` class file for the `Downloaded` option. Please see the [TRANSLATION.md](https://github.com/amugofjava/anytime_podcast_player/blob/master/TRANSLATION.md) file on how Anytime handles translations. For a single word, Google Translate/Bing Translator are useful for translating labels into the supported languages. If you don't feel comfortable handling the translations, don't worry, this can be done later.\n\nI do have a really busy couple of weeks coming up and I may be slow to respond to questions and PRs, so please bear with me. Thanks.", "i did fork the repo and looked it up and i am sure i could contribute to it...i will too try with the translation .\nThank you for the response..." ],
      "repository" : {
        "description" : "Simple, easy to use Podcast player app written in Flutter and Dart.",
        "homepage" : "",
        "name" : "anytime_podcast_player",
        "fullName" : "amugofjava/anytime_podcast_player",
        "htmlUrl" : "https://github.com/amugofjava/anytime_podcast_player",
        "gitUrl" : "git://github.com/amugofjava/anytime_podcast_player.git",
        "sshUrl" : "git@github.com:amugofjava/anytime_podcast_player.git",
        "cloneUrl" : "https://github.com/amugofjava/anytime_podcast_player.git",
        "owner" : {
          "login" : "amugofjava",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 112,
        "stargazersCount" : 521,
        "watchersCount" : 521,
        "size" : 15357,
        "openIssuesCount" : 24,
        "subscribersCount" : 18,
        "pushedAt" : "2025-07-22T19:19:35Z",
        "languages" : {
          "Objective-C" : 38,
          "Swift" : 725,
          "Ruby" : 2873,
          "Dart" : 977323,
          "Kotlin" : 144
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a 'Downloaded' option to the Filter episodes list in the podcast details page to allow users to filter downloaded episodes for a podcast.",
      "validationOrRequirement" : "Add a new string in the L.dart class file for the Downloaded option and handle translations.",
      "attemptedFixes" : "The user has already forked the repo and looked it up, and is willing to contribute to the project.",
      "otherNotes" : "The issue is related to a user request via email and the solution involves adding a 'Downloaded' option to the Filter episodes list in the podcast details page. The user can filter downloaded episodes for that podcast. The issue also requires adding a new string in the L.dart class file for the Downloaded option and handling translations.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407769
  }, {
    "issueDTO" : {
      "id" : 2601726166,
      "title" : "[FEATURE] Add support for `complex` types",
      "url" : "https://github.com/qBraid/pyqasm/issues/33",
      "repositoryName" : "qBraid/pyqasm",
      "description" : "### Feature Description\n\nAdd support for `complex` types being used inside openqasm3 programs. \r\nReference : [complex types in qasm3](https://openqasm.com/language/types.html#complex-numbers)\n\n### Implementation (Optional)\n\n_No response_",
      "updatedAt" : 1753364717.000000000,
      "user" : "TheGupta2012",
      "userHtmlUrl" : "https://github.com/TheGupta2012",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/57539040?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Python toolkit providing OpenQASM 3 semantic analyzer and utilities for program analysis and compilation.",
        "homepage" : "https://docs.qbraid.com/pyqasm",
        "name" : "pyqasm",
        "fullName" : "qBraid/pyqasm",
        "htmlUrl" : "https://github.com/qBraid/pyqasm",
        "gitUrl" : "git://github.com/qBraid/pyqasm.git",
        "sshUrl" : "git@github.com:qBraid/pyqasm.git",
        "cloneUrl" : "https://github.com/qBraid/pyqasm.git",
        "owner" : {
          "login" : "qBraid",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 18,
        "watchersCount" : 18,
        "size" : 792,
        "openIssuesCount" : 43,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-24T14:50:52Z",
        "languages" : {
          "OpenQASM" : 2686,
          "Shell" : 14037,
          "Cython" : 2597,
          "Python" : 624806
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for complex types being used inside openqasm3 programs",
      "validationOrRequirement" : "Add support for complex types in openqasm3 programs",
      "attemptedFixes" : "No attempts or blockers mentioned",
      "otherNotes" : "Reference to complex types in qasm3 provided, implementation details not provided",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407771
  }, {
    "issueDTO" : {
      "id" : 2937659119,
      "title" : "[Bug] Connection flags bash command quoting issue",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/1201",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\nBugs should be filed for issues encountered whilst operating mariadb-operator.\nPlease provide as much detail as possible. \n-->\n\n**Documentation**\n- [x] I acknowledge that I have read the relevant [documentation](https://github.com/mariadb-operator/mariadb-operator/tree/main/docs).\n\n**Describe the bug**\n\nResulting Job init-container args from Backup CR:\n\n```sh\nset -euo pipefail;echo \uD83D\uDCBE Exporting env;export BACKUP_FILE=/backup/backup.$(date -u +'%Y-%m-%dT%H:%M:%SZ').sql;echo \uD83D\uDCBE Writing target file: /backup/0-backup-target.txt;printf \"${BACKUP_FILE}\" > /backup/0-backup-target.txt;echo \uD83D\uDCBE Taking backup: $(cat '/backup/0-backup-target.txt');mariadb-dump --user=${MARIADB_OPERATOR_USER} --password=${MARIADB_OPERATOR_PASSWORD} --host=mariadb-galera.lab0.svc.cluster.local --port=3306 --single-transaction --events --routines --all-databases --skip-add-locks --ignore-table=mysql.global_priv --ssl --ssl-ca /etc/pki/ca.crt --ssl-cert /etc/pki/client.crt --ssl-key /etc/pki/client.key --ssl-verify-server-cert > $(cat '/backup/0-backup-target.txt')\n```\n\n**Expected behaviour**\n\nThe variables must be quoted in order to ensure correct behavior when whitespace or other special characters are included in the `MARIADB_OPERATOR_USER` or `MARIADB_OPERATOR_PASSWORD` variables. \n\n**Steps to reproduce the bug**\n<!--Steps to reproduce the bug should be clear and easily reproducible to help people\ngain an understanding of the problem.-->\n\n1. Create a minimal MariaDB CR deployment\n2. Create a valid Backup CR referring to the MariaDB instance\n3. Check the resulting Job's init-container's args\n\n**Debug information**\n\nThis seems to be the relevant flawed code:\npkg/command/command.go:\n```go\nfunc ConnectionFlags(co *CommandOpts, mariadb *mariadbv1alpha1.MariaDB) string {\n\tflags := fmt.Sprintf(\n\t\t\"--user=${%s} --password=${%s} --host=%s --port=%d\",\n\t\tco.UserEnv,\n\t\tco.PasswordEnv,\n\t\thost(mariadb),\n\t\tmariadb.Spec.Port,\n\t)\n\tif co.Database != nil {\n\t\tflags += fmt.Sprintf(\" --database=%s\", *co.Database)\n\t}\n\treturn flags\n}\n```\n\nPS:\nFor what it's worth, I would also quote all other substitutions such as\n```sh\nBACKUP_FILE=/backup/backup.$(date -u +'%Y-%m-%dT%H:%M:%SZ').sql\n```\nand\n```\n> $(cat '/backup/0-backup-target.txt')\n```\nwhich are not expected to contain whitespace, just to be sure.\n\nPPS:\nIMO, the whole bash script templating is a bit janky and ideally should be replaced with a proper go program that reads the environment or some configuration file.\nAlso there seems to be the [MYSQL_PWD environment variable](https://mariadb.com/kb/en/mariadb-environment-variables/).",
      "updatedAt" : 1753364668.000000000,
      "user" : "ClemaX",
      "userHtmlUrl" : "https://github.com/ClemaX",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9118612?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This issue is stale because it has been open 60 days with no activity.", "This issue was closed because it has been stalled for 30 days with no activity." ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to fix the connection flags bash command quoting issue in the mariadb-operator, specifically when variables contain whitespace or special characters.",
      "validationOrRequirement" : "The variables must be quoted in order to ensure correct behavior when whitespace or other special characters are included in the MARIADB_OPERATOR_USER or MARIADB_OPERATOR_PASSWORD variables.",
      "attemptedFixes" : "No specific fixes mentioned in the issue, but the author suggests quoting all substitutions and also mentions that the whole bash script templating is janky and ideally should be replaced with a proper Go program.",
      "otherNotes" : "The issue is related to bash command quoting and the author suggests quoting all substitutions to ensure correct behavior when whitespace or other special characters are included in the variables.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407776
  }, {
    "issueDTO" : {
      "id" : 3103555029,
      "title" : "Const integer casts",
      "url" : "https://github.com/rust-bitcoin/rust-bitcoin/issues/4581",
      "repositoryName" : "rust-bitcoin/rust-bitcoin",
      "description" : "Because we want to support `const` we've started using `as` casts instead of `into()` in the code. This makes the code harder to reason about. But we don't really need to do that. We can simply add a module `const_casts` in `internals` that will have functions like `u8_to_usize`, `u8_to_u32` etc, basically for all implementations of `From`. Similarly we can have feature-gated `u32_to_usize` and `usize_to_u64` for cases where we don't support 16-bit platforms.\n\nYes, this means that the code doing integer casts in `const` context will become longer but I think it's starting to be worth it since there are many casts and I already got confused by some code.\n\nThis issue is easy in principle but involves a bunch of changes.",
      "updatedAt" : 1753364600.000000000,
      "user" : "Kixunil",
      "userHtmlUrl" : "https://github.com/Kixunil",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1178779?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Yeah, great idea. Let's do it. The casts make me wince every time.", "hey, can please confirm if I get your idea correctly before I change all those files?\n\n1. New module\n\n<img width=\"1429\" height=\"856\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bf5d3cdb-7d26-4992-9107-f75a1ece436f\" />\n\n2. Replace all casting with `as` occurrences like this:\n\n<img width=\"1371\" height=\"581\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/89dc8da7-918b-46fd-9493-f5cfbc4dbfb3\" />\n\nEdit: not sure yet what to do with those unsafe situations, I am gonna put panic here, do you have a better suggestion?", "I appreciate the effort you made to draw all these screenshots but they're compressed and anyway I can't tell what they're supposed to mean. Could you just post a diff?\n\nAlso please do not add panics where none exist.", "ok, I thought the screenshots will be the quickest way to explain the changes I am making: left is before, right is after the change. What does it mean \"they're compressed\"? You can't see the screenshots? \n\nI don't know if you mean `git diff` in terminal, because at least for me this is much less readable:\n\n1. new module which will look like this:\n\n```diff\ndiff --git a/internals/src/const_casts.rs b/internals/src/const_casts.rs\nindex e01cb73aa498..15141926c75e 100644\n--- a/internals/src/const_casts.rs\n+++ b/internals/src/const_casts.rs\n@@ -1,24 +1,33 @@\n+//! Const-compatible integer casting functions.\n+//!\n+//! This module provides explicit, const-compatible functions for integer type conversions\n+//! that would normally be done using the [`Into`] trait. Since trait methods cannot be used\n+//! in `const` contexts, these functions serve as alternatives that make conversion intent\n+//! clear while maintaining compile-time evaluation capabilities.\n+//!\n+//! # Safety\n+//!\n+//! All functions in this module perform the same conversions as their corresponding\n+//! [`From`] implementations. Platform-specific functions are feature-gated to prevent\n+//! compilation on unsupported architectures.\n+\n+/// narrowing functions\n+\n pub const fn u8_to_usize(value: u8) -> usize {\n     value as usize\n }\n\n+const fn u64_to_usize(value: u64) -> usize {\n+    #[cfg(not(target_pointer_width = \"64\"))]\n+    {\n+        if value > usize::MAX as u64 {\n+            panic!(\"Value too large for usize on this platform\");\n+        }\n+    }\n+    value as usize\n+}\n+\n+/// widening functions (always safe)\n \n pub const fn usize_to_u64(value: usize) -> u64 {\n     value as u64\n```\n\n2. replacements of the casts in the code:\n\n```diff\ndiff --git a/fuzz/src/fuzz_utils.rs b/fuzz/src/fuzz_utils.rs\nindex 883729c3cd2e..401cbaab9b3f 100644\n--- a/fuzz/src/fuzz_utils.rs\n+++ b/fuzz/src/fuzz_utils.rs\n@@ -1,13 +1,14 @@\n // SPDX-License-Identifier: CC0-1.0\n-\n //! Helper functions for fuzzing.\n \n+use internals::{const_casts};\n+\n pub fn consume_random_bytes<'a>(data: &mut &'a [u8]) -> &'a [u8] {\n     if data.is_empty() {\n         return &[];\n     }\n \n-    let length = (data[0] as usize) % (data.len() + 1);\n+    let length = (const_casts::u8_to_usize(data[0])) % (data.len() + 1);\n     let (bytes, rest) = data.split_at(length);\n     *data = rest;\n```\n\n3. for the panic, I wanted to ask for your advice: what do you suggest to do in the case of risk of losing precision during casting", "I have edited your comment to use diff highlighting (type ```diff to do this). It is much more readable than screenshots now, thanks!", "And to answer your question, yes, concept ACK this approach. Interesting idea to gate the panics on `target_pointer_width`, although really we want the panic only when it's *less than* 64 rather than when it's *not equal to*. Maybe this is impossible to do. In that case I guess we can just special-case the specific values \"32\" and \"64\" which will be the overwhelmingly most common ones. Or not bother. This is just an optimization, and a compile-time one at that." ],
      "repository" : {
        "description" : "Rust Bitcoin library",
        "homepage" : null,
        "name" : "rust-bitcoin",
        "fullName" : "rust-bitcoin/rust-bitcoin",
        "htmlUrl" : "https://github.com/rust-bitcoin/rust-bitcoin",
        "gitUrl" : "git://github.com/rust-bitcoin/rust-bitcoin.git",
        "sshUrl" : "git@github.com:rust-bitcoin/rust-bitcoin.git",
        "cloneUrl" : "https://github.com/rust-bitcoin/rust-bitcoin.git",
        "owner" : {
          "login" : "rust-bitcoin",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 843,
        "stargazersCount" : 2409,
        "watchersCount" : 2409,
        "size" : 17328,
        "openIssuesCount" : 477,
        "subscribersCount" : 58,
        "pushedAt" : "2025-07-24T14:32:23Z",
        "languages" : {
          "Shell" : 39379,
          "Rust" : 2650506,
          "RPC" : 197,
          "Just" : 1673
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to support `const` and avoid using `as` casts by creating a new module `const_casts` with functions for all implementations of `From`.",
      "validationOrRequirement" : "The issue involves a bunch of changes, including creating a new module, replacing all casting with `as` occurrences, and handling unsafe situations. The author wants to support `const` and avoid using `as` casts.",
      "attemptedFixes" : "The author has attempted to explain the changes through screenshots, but they are compressed and not readable. The author also suggested using `git diff` in the terminal, but it's less readable. The author has also asked for advice on how to handle the risk of losing precision during casting.",
      "otherNotes" : "The author wants to support `const` and to avoid using `as` casts, they suggest creating a new module `const_casts` with functions for all implementations of `From`. The code will become longer but it's worth it since there are many casts. The issue involves a bunch of changes, including a new module, replacing all casting with `as` occurrences, and handling unsafe situations.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407784
  }, {
    "issueDTO" : {
      "id" : 2258584461,
      "title" : "Terminal Icon picker weird placement",
      "url" : "https://github.com/microsoft/vscode/issues/211083",
      "repositoryName" : "microsoft/vscode",
      "description" : "The terminal icon picker is positioned at the far top of the window. This looks a bit weird as the top border of the widget is not visible. I would have expected the widget to be placed bellow the command center.\r\n\r\n<img width=\"594\" alt=\"image\" src=\"https://github.com/microsoft/vscode/assets/44439583/996bc79b-40ab-4386-b485-72a4961f825a\">\r\n",
      "updatedAt" : 1753364444.000000000,
      "user" : "benibenj",
      "userHtmlUrl" : "https://github.com/benibenj",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/44439583?v=4",
      "labels" : [ "terminal-tabs", "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Code pointer: https://github.com/microsoft/vscode/blob/191a248afd908b018bbf05087be8898498e1eec6/src/vs/workbench/contrib/terminal/browser/terminalIconPicker.ts#L60", " hello! @Tyriar I'm sossost, a new contributor. I would like to solve this problem.\r\n\r\nWhich is the best solution\r\nmodifying the top border of the widget so that it is not cut off, or positioning the widget below the command center?", "@sossost ideally we would position it below the command center when it's triggered via the command palette, or near the terminal tab if it's triggered from there.", "Wow. ", "@Tyriar Like @abhijit-chikane has expressed his concern in the PR raised should we probably change the position of the terminal icon colour change tab as well if not it might look weird where one shows the position on bottom and the other on top . \r\n![image](https://github.com/microsoft/vscode/assets/44496526/bedae4a0-1be8-4357-94e9-a2443554ef1e)\r\n", "@Tyriar I'm working on this one if you don't mind. \nI took over the PR #212174 but I had to make some changes to it because the icon picker was still at the top when there was only one terminal instance.\n\nI'm also changing the color picker so we have it positioned like the icons picker", "I want to work on this issue as my first ever proper issue. Can I be assigned to this?\r\n", "How do I test this code?\r\n", "@benibenj FYI I don't think we should do the placement change for the command center as the quick pick puts itself over it. It does however hide the command center which we should do instead to remain consistent.\n\nThe icon hover attached to the tab should still happen though.", "/| Header | Header | Header | Header | Header |\n\nTesting", "The widget now has an arrow on the bottom of it:\n\n![Image](https://github.com/user-attachments/assets/29633b0b-6ec8-475a-a12d-5f1316e85e7c)", "Hello @benibenj, I see that the issue is still open and labeled as good first issue. I would like to contribute to this issue as my first open-source contribution. Could you please confirm if its still available?" ],
      "repository" : {
        "description" : "Visual Studio Code",
        "homepage" : "https://code.visualstudio.com",
        "name" : "vscode",
        "fullName" : "microsoft/vscode",
        "htmlUrl" : "https://github.com/microsoft/vscode",
        "gitUrl" : "git://github.com/microsoft/vscode.git",
        "sshUrl" : "git@github.com:microsoft/vscode.git",
        "cloneUrl" : "https://github.com/microsoft/vscode.git",
        "owner" : {
          "login" : "microsoft",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 33934,
        "stargazersCount" : 174935,
        "watchersCount" : 174935,
        "size" : 1047146,
        "openIssuesCount" : 11918,
        "subscribersCount" : 3362,
        "pushedAt" : "2025-07-25T00:57:11Z",
        "languages" : {
          "C#" : 864,
          "Scheme" : 2166,
          "C" : 818,
          "Makefile" : 2307,
          "Handlebars" : 1064,
          "ShaderLab" : 330,
          "Go" : 652,
          "Inno Setup" : 310191,
          "HTML" : 356219,
          "Groovy" : 3928,
          "Jupyter Notebook" : 929,
          "TypeScript" : 71959691,
          "Shell" : 102998,
          "R" : 362,
          "SCSS" : 6732,
          "JavaScript" : 841299,
          "Objective-C" : 1387,
          "PHP" : 998,
          "Lua" : 252,
          "Visual Basic .NET" : 893,
          "Ruby" : 1703,
          "Less" : 1029,
          "F#" : 634,
          "Python" : 2171,
          "Clojure" : 1206,
          "Raku" : 761,
          "PowerShell" : 17190,
          "Java" : 599,
          "CSS" : 1066501,
          "C++" : 2745,
          "Rust" : 501293,
          "Pug" : 654,
          "Hack" : 16,
          "Objective-C++" : 1387,
          "TeX" : 1602,
          "Tree-sitter Query" : 12094,
          "Perl" : 1922,
          "Cuda" : 3634,
          "Julia" : 940,
          "Dockerfile" : 960,
          "Scilab" : 202892,
          "CoffeeScript" : 590,
          "Batchfile" : 19037,
          "Swift" : 284,
          "Roff" : 351,
          "HLSL" : 184,
          "Dart" : 324
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to resolve the weird placement of the terminal icon picker at the top of the window and position it below the command center.",
      "validationOrRequirement" : "The issue should be resolved by positioning the terminal icon picker below the command center when triggered via the command palette, or near the terminal tab if triggered from there. The placement change for the command center should not be done as it hides the quick pick.",
      "attemptedFixes" : "The PR #212174 is being worked on to change the position of the terminal icon picker. The icon picker was still at the top when there was only one terminal instance. The color picker is also being changed to be positioned like the icon picker.",
      "otherNotes" : "The terminal icon picker is positioned at the top of the window, which looks weird. It should be placed below the command center. There is a PR #212174 being worked on to fix this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407790
  }, {
    "issueDTO" : {
      "id" : 3088392176,
      "title" : "Move Gate Decomposition Figures to Markdown Documentation",
      "url" : "https://github.com/qBraid/pyqasm/issues/190",
      "repositoryName" : "qBraid/pyqasm",
      "description" : "## **Description**\nRefactor the `gates.py` file by relocating all gate decomposition figures (currently included as ASCII diagrams or docstring illustrations) into a dedicated Markdown documentation file (e.g., `docs/gate_decompositions.md`). The `gates.py` file will then reference the Markdown file, rather than embedding decomposition figures directly in code or docstrings.\n\n## **Implementation**\n- **Extraction:** Identify and extract all gate decomposition figures, ASCII diagrams, and explanatory illustrations from `gates.py`.\n- **Documentation:** Create a new Markdown file (e.g., `docs/gate_decompositions.md`) and organize the decompositions by gate name/type, preserving all relevant explanations and diagrams.\n- **Reference Update:** In `gates.py`, replace each removed figure with a reference or link to the corresponding section in the Markdown file. For example:\n\n```python\n# See docs/gate_decompositions.md#crx-gate for decomposition details.\n```\n- README Update: Optionally, add a reference to the new documentation file in the project README and relevant configs.\n- Testing: Ensure that docstring removals do not affect code execution or automated documentation builds.",
      "updatedAt" : 1753364386.000000000,
      "user" : "TheGupta2012",
      "userHtmlUrl" : "https://github.com/TheGupta2012",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/57539040?v=4",
      "labels" : [ "no-qc-knowledge-reqd", "documentation", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Python toolkit providing OpenQASM 3 semantic analyzer and utilities for program analysis and compilation.",
        "homepage" : "https://docs.qbraid.com/pyqasm",
        "name" : "pyqasm",
        "fullName" : "qBraid/pyqasm",
        "htmlUrl" : "https://github.com/qBraid/pyqasm",
        "gitUrl" : "git://github.com/qBraid/pyqasm.git",
        "sshUrl" : "git@github.com:qBraid/pyqasm.git",
        "cloneUrl" : "https://github.com/qBraid/pyqasm.git",
        "owner" : {
          "login" : "qBraid",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 18,
        "watchersCount" : 18,
        "size" : 792,
        "openIssuesCount" : 43,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-24T14:50:52Z",
        "languages" : {
          "OpenQASM" : 2686,
          "Shell" : 14037,
          "Cython" : 2597,
          "Python" : 624806
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor the gates.py file by moving gate decomposition figures to a dedicated Markdown documentation file and updating references and README.",
      "validationOrRequirement" : "The implementation should ensure that docstring removals do not affect code execution or automated documentation builds.",
      "attemptedFixes" : "None mentioned in the description",
      "otherNotes" : "The issue involves refactoring the gates.py file by relocating gate decomposition figures into a dedicated Markdown documentation file, and updating references and README.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407793
  }, {
    "issueDTO" : {
      "id" : 3258788558,
      "title" : "Refactor tty_write arguments",
      "url" : "https://github.com/richardscollin/tmux-rs/issues/80",
      "repositoryName" : "richardscollin/tmux-rs",
      "description" : "Refactor tty_write in `src/tty_.rs` to accept a `cmdfn` that is not wrapped in a function and fix all the calls.\n\n```\npub unsafe fn tty_write(cmdfn: Option<unsafe fn(*mut tty, *const tty_ctx)>, ctx: *mut tty_ctx)\n```\n\nShould be changed to:\n\n```rust\npub unsafe fn tty_write(cmdfn: unsafe fn(*mut tty, *const tty_ctx), ctx: *mut tty_ctx)\n```\n\nall uses should then be changed to not wrap the parameter in `Some`.",
      "updatedAt" : 1753364358.000000000,
      "user" : "richardscollin",
      "userHtmlUrl" : "https://github.com/richardscollin",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5686133?v=4",
      "labels" : [ "refactoring", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Should that be \"not wrapped in an Option\" (you wrote \"function\")?" ],
      "repository" : {
        "description" : "A Rust port of tmux",
        "homepage" : "https://richardscollin.github.io/tmux-rs/",
        "name" : "tmux-rs",
        "fullName" : "richardscollin/tmux-rs",
        "htmlUrl" : "https://github.com/richardscollin/tmux-rs",
        "gitUrl" : "git://github.com/richardscollin/tmux-rs.git",
        "sshUrl" : "git@github.com:richardscollin/tmux-rs.git",
        "cloneUrl" : "https://github.com/richardscollin/tmux-rs.git",
        "owner" : {
          "login" : "richardscollin",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 21,
        "stargazersCount" : 721,
        "watchersCount" : 721,
        "size" : 21527,
        "openIssuesCount" : 17,
        "subscribersCount" : 5,
        "pushedAt" : "2025-07-23T12:26:40Z",
        "languages" : {
          "Shell" : 10,
          "Rust" : 3142142,
          "Nix" : 1900
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor the tty_write function in src/tty_.rs to accept a cmdfn that is not wrapped in an Option and fix all the calls.",
      "validationOrRequirement" : "The function signature should not wrap the parameter in an Option.",
      "attemptedFixes" : "The description mentions the required change in the function signature.",
      "otherNotes" : "The author suggested a correction in the description comment.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407796
  }, {
    "issueDTO" : {
      "id" : 3004088523,
      "title" : "[Bug] imagePullSecrets is inmutable",
      "url" : "https://github.com/mariadb-operator/mariadb-operator/issues/1254",
      "repositoryName" : "mariadb-operator/mariadb-operator",
      "description" : "<!--\nBugs should be filed for issues encountered whilst operating mariadb-operator.\nPlease provide as much detail as possible. \n-->\n\n**Documentation**\n- [X] I acknowledge that I have read the relevant [documentation](https://github.com/mariadb-operator/mariadb-operator/tree/main/docs).\n\n**Describe the bug**\nTried to add a credential for the images for my MariaDB resource, got `'spec.imagePullSecrets' field is inmutable`\n\n**Expected behaviour**\nOne should be able to add or change the pull credentials.\n\n**Environment details**:\n- Kubernetes version: 1.32.3\n- Kubernetes distribution: k3s\n- MariaDB Operator version: 0.38.1\n- MariaDB Server version: 11.5\n- Install method: Helm\n",
      "updatedAt" : 1753364317.000000000,
      "user" : "codestation",
      "userHtmlUrl" : "https://github.com/codestation",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/61178?v=4",
      "labels" : [ "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Thanks @codestation ! Indeed, this should be mutable. Contributions welcomed!", "This issue is stale because it has been open 60 days with no activity." ],
      "repository" : {
        "description" : "\uD83E\uDDAD Run and operate MariaDB in a cloud native way",
        "homepage" : "https://github.com/mariadb-operator/mariadb-operator/blob/main/docs/README.md",
        "name" : "mariadb-operator",
        "fullName" : "mariadb-operator/mariadb-operator",
        "htmlUrl" : "https://github.com/mariadb-operator/mariadb-operator",
        "gitUrl" : "git://github.com/mariadb-operator/mariadb-operator.git",
        "sshUrl" : "git@github.com:mariadb-operator/mariadb-operator.git",
        "cloneUrl" : "https://github.com/mariadb-operator/mariadb-operator.git",
        "owner" : {
          "login" : "mariadb-operator",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 138,
        "stargazersCount" : 692,
        "watchersCount" : 692,
        "size" : 17866,
        "openIssuesCount" : 118,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-22T15:00:48Z",
        "languages" : {
          "Smarty" : 8463,
          "Dockerfile" : 421,
          "Shell" : 172500,
          "Makefile" : 52315,
          "Go" : 2706795
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "allow adding or changing pull credentials for MariaDB resource",
      "validationOrRequirement" : "spec.imagePullSecrets field should be mutable",
      "attemptedFixes" : "none mentioned",
      "otherNotes" : "Bugs should be filed for issues encountered whilst operating mariadb-operator. Acknowledgment of relevant documentation provided.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407798
  }, {
    "issueDTO" : {
      "id" : 2344647678,
      "title" : "[Bug]: `BrandImage` resizes itself in dark theme when resizing sidebar",
      "url" : "https://github.com/storybookjs/storybook/issues/28192",
      "repositoryName" : "storybookjs/storybook",
      "description" : "### Describe the bug\n\nWhen switching to the Storybook dark theme, the `BrandImage` resizes itself when changing the width of the sidebar. The same problem seems to have been addressed for the light theme in this issue: https://github.com/storybookjs/storybook/issues/24702. \r\n\r\nDepending on the width of the sidebar, the logos might be different sizes when switching between themes. \r\n\r\nI think the dark theme should behave like the light theme.\r\n\r\nhttps://github.com/storybookjs/storybook/assets/69268452/b32aaac0-f50c-4ea8-a367-547a5a280530\r\n\r\n\n\n### Reproduction link\n\nN/A\n\n### Reproduction steps\n\n_No response_\n\n### System\n\n```bash\nStorybook Environment Info:\r\n\r\n  System:\r\n    OS: macOS 14.5\r\n    CPU: (10) arm64 Apple M1 Pro\r\n    Shell: 5.9 - /bin/zsh\r\n  Binaries:\r\n    Node: 18.7.0 - ~/.nvm/versions/node/v18.7.0/bin/node\r\n    Yarn: 1.22.19 - ~/.nvm/versions/node/v18.7.0/bin/yarn\r\n    npm: 8.15.0 - ~/.nvm/versions/node/v18.7.0/bin/npm\r\n    pnpm: 8.3.1 - ~/.nvm/versions/node/v18.7.0/bin/pnpm <----- active\r\n  Browsers:\r\n    Chrome: 125.0.6422.142\r\n    Edge: 125.0.2535.92\r\n    Safari: 17.5\r\n  npmPackages:\r\n    @storybook/addon-a11y: 8.0.9 => 8.0.9 \r\n    @storybook/addon-actions: 8.0.9 => 8.0.9 \r\n    @storybook/addon-essentials: 8.0.9 => 8.0.9 \r\n    @storybook/blocks: 8.0.9 => 8.0.9 \r\n    @storybook/theming: 8.0.9 => 8.0.9 \r\n    @storybook/web-components: 8.0.9 => 8.0.9 \r\n    @storybook/web-components-vite: 8.0.9 => 8.0.9 \r\n    chromatic: 5.8.3 => 5.8.3 \r\n    storybook: 8.0.9 => 8.0.9 \r\n    storybook-dark-mode: 4.0.1 => 4.0.1\n```\n\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753364224.000000000,
      "user" : "mayabuserde",
      "userHtmlUrl" : "https://github.com/mayabuserde",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/69268452?v=4",
      "labels" : [ "ui", "bug", "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello @vanessayuenn and @mayabuserde,\r\nI'm new to open source contribution and would like to get started. Can you please give me any tips and processes that I need to follow to contribute to this issue?\r\nThanks.", "Hey,\r\nI can fix it, Assign it to me.\r\nThank you", "Hi @mayabuserde  - thank you for sharing video and details. I would like to contribute into this project, can you please assign this to me ? Thank you so much! :) ", "Hi @vanessayuenn, can you help with assigning the issue to someone or provide some guidance on how to start working on it? \r\nThank you!", "@mayabuserde hii is this issue fixed because i am tried reproducing it but it is working normally for me\r\n[Screencast from 04-09-24 08:13:56 PM IST.webm](https://github.com/user-attachments/assets/c58cf59c-ab6d-438b-a57c-3748b2d9a275)\r\n", "@ShreySinha02 Nope still happening.. it only affects the width of the logo. In your case the width is fixed that's why it doesn't resize.", "hii @mayabuserde please look #29129 ", "Hi! I'd like to help with this. Can I take it?" ],
      "repository" : {
        "description" : "Storybook is the industry standard workshop for building, documenting, and testing UI components in isolation",
        "homepage" : "https://storybook.js.org",
        "name" : "storybook",
        "fullName" : "storybookjs/storybook",
        "htmlUrl" : "https://github.com/storybookjs/storybook",
        "gitUrl" : "git://github.com/storybookjs/storybook.git",
        "sshUrl" : "git@github.com:storybookjs/storybook.git",
        "cloneUrl" : "https://github.com/storybookjs/storybook.git",
        "owner" : {
          "login" : "storybookjs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 9623,
        "stargazersCount" : 87309,
        "watchersCount" : 87309,
        "size" : 1039456,
        "openIssuesCount" : 2157,
        "subscribersCount" : 926,
        "pushedAt" : "2025-07-24T16:51:23Z",
        "languages" : {
          "TypeScript" : 8515715,
          "MDX" : 87407,
          "CSS" : 22373,
          "Shell" : 1051,
          "Pug" : 3991,
          "Handlebars" : 1711,
          "SCSS" : 125,
          "JavaScript" : 2479536,
          "Vue" : 36081,
          "HTML" : 24251,
          "Svelte" : 71472,
          "EJS" : 6046
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The `BrandImage` resizes itself in dark theme when resizing sidebar.",
      "validationOrRequirement" : "The dark theme should behave like the light theme, with the logos being the same size when switching between themes.",
      "attemptedFixes" : "Assigning the issue to someone, requesting tips and processes for contribution, and offering to fix the issue.",
      "otherNotes" : "The issue is specific to the dark theme and the logo resizing when changing the width of the sidebar. The same problem was addressed for the light theme in a different issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407802
  }, {
    "issueDTO" : {
      "id" : 3244383393,
      "title" : "Convert Images into Meshery Design [ Kubernetes Workshop]",
      "url" : "https://github.com/layer5io/exoscale-academy/issues/45",
      "repositoryName" : "layer5io/exoscale-academy",
      "description" : "Hey Everyone,\nGood First Issue Alert! \uD83C\uDF89\nWe???re converting the images in the learning paths to Meshery designs.\nHere???s what you need to do:\nA few issues have already been created, each with an image attached.\nYour task is to redesign the image into a Meshery design.\nOnce done, share your design as a comment under the respective issue.\nFor reference:\nImage:\n\n<img width=\"2792\" height=\"1334\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ff8fe676-35ee-4c7a-8f5c-0430a9a1c299\" />\n\nDesign:\n\n<img width=\"720\" height=\"504\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f6a23159-c088-4c1c-8991-cf697bfd5f7a\" />\n\n\nSome notes for making meshery designs from images :\n1. If there is text in the image, using a text box for it won't work while embedding, try to use the image box and assign it a name so that it's visible in embedded design.\n2. Whenever there is an exoscale image, try to use https://meshery.io/assets/modelsFiles/exoscale-icons.tar  in the meshery model import from url and the make designs with it.\nWhenever it mentions the use of or supported tools in clustering etc, also mention meshery as a tool too. ( this is for academy )\n3. Comment the url for the design prepared in the respective issue .\n4. For making your first design you get awarded with \"Design Pioneer\" Badge  : https://badges.layer5.io/ and is a good-first-issue to get started with\n5. If they wanted just a static image, then they don???t need to embed a design\n\n",
      "updatedAt" : 1753363797.000000000,
      "user" : "Namanv0509",
      "userHtmlUrl" : "https://github.com/Namanv0509",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/149177973?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Academy for Exoscale",
        "homepage" : "https://exoscale.layer5.io/academy",
        "name" : "exoscale-academy",
        "fullName" : "layer5io/exoscale-academy",
        "htmlUrl" : "https://github.com/layer5io/exoscale-academy",
        "gitUrl" : "git://github.com/layer5io/exoscale-academy.git",
        "sshUrl" : "git@github.com:layer5io/exoscale-academy.git",
        "cloneUrl" : "https://github.com/layer5io/exoscale-academy.git",
        "owner" : {
          "login" : "layer5io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 20,
        "stargazersCount" : 23,
        "watchersCount" : 23,
        "size" : 191827,
        "openIssuesCount" : 16,
        "subscribersCount" : 1,
        "pushedAt" : "2025-07-25T00:53:09Z",
        "languages" : {
          "Makefile" : 1652,
          "JavaScript" : 103,
          "HTML" : 118,
          "Nix" : 1138
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Convert Images into Meshery Design for the Kubernetes Workshop",
      "validationOrRequirement" : "Redesign the image into a Meshery design. Share the design as a comment under the respective issue.",
      "attemptedFixes" : "None",
      "otherNotes" : "Some notes for making meshery designs from images : 1. If there is text in the image, using a text box for it won't work while embedding, try to use the image box and assign it a name so that it's visible in embedded design. 2. Whenever there is an exoscale image, try to use https://meshery.io/assets/modelsFiles/exoscale-icons.tar in the meshery model import from url and the make designs with it. Whenever it mentions the use of or supported tools in clustering etc, also mention meshery as a tool too. ( this is for academy ) 3. Comment the url for the design prepared in the respective issue . 4. For making your first design you get awarded with \"Design Pioneer\" Badge : https://badges.layer5.io/ and is a good-first-issue to get started with 5. If they wanted just a static image, then they don???t need to embed a design",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407810
  }, {
    "issueDTO" : {
      "id" : 3146145101,
      "title" : "Make tabs responsive for Mobile View UI of Resource Page",
      "url" : "https://github.com/ohcnetwork/care_fe/issues/12615",
      "repositoryName" : "ohcnetwork/care_fe",
      "description" : "**Describe the bug**\nOutgoing | Incoming and Active | Completed tabs are inconsistent and not responsive.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See error\n\n**Expected behavior**\nWe can improve the UI and make it like this: \n\n![Image](https://github.com/user-attachments/assets/89697649-b019-4802-aacb-352f3fc10569)\n\n**Screenshots**\n\n![Image](https://github.com/user-attachments/assets/d29a24b1-82f6-43ca-b3ba-62f9cb1d6124)\n\n**Desktop (please complete the following information):**\n\n- OS: [e.g. iOS]\n- Browser [e.g. chrome, safari]\n- Version [e.g. 22]\n\n**Smartphone (please complete the following information):**\n\n- Device: [e.g. iPhone6]\n- OS: [e.g. iOS8.1]\n- Browser [e.g. stock browser, safari]\n- Version [e.g. 22]\n\n**Additional context**\nAdd any other context about the problem here.\n\n---\n\n### \uD83D\uDEA8 DO NOT EDIT BELOW THIS LINE \uD83D\uDEA8\n\n### Instructions for Requesting Assignment:\n\nTo request assignment, please clearly outline your solution and timeline by commenting on the issue using the format below:\n\n**Describe your solution clearly:**\nProvide a detailed explanation of your proposed solution, including your approach, key implementation steps, and relevant examples or references. Mention any dependencies, assumptions, or risks you foresee that might affect your timeline or implementation.\n\n**Expected Timeline:**\n- End date: [Expected submission date of a completed Pull Request]\n\n**Additional Context:**\nInclude any other relevant context, links, screenshots, or resources that support your proposed solution.\n\n> \uD83D\uDEA8 Your assignment may be unassigned if there is no activity or progress within the stated timeline unless communicated clearly and agreed upon.\n",
      "updatedAt" : 1753363783.000000000,
      "user" : "Tanuj1718",
      "userHtmlUrl" : "https://github.com/Tanuj1718",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/125687187?v=4",
      "labels" : [ "stale", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi! \uD83D\uDC4B I???d like to work on this issue. I???m new here and also new to this codebase, so I may need a bit of extra time to get familiar with everything. My estimated time to complete this is about 2-3 days. Please let me know if that works, or if there???s anything specific I should keep in mind as I get started. Thanks!", "I???ve completed the changes for this issue and have attached screenshots of the updated UI for your review. I noticed the issue hasn???t been assigned to me yet, but I wanted to share my progress.\n\nAlso, could you please let me know if I should maintain the previous green color for the tabs, or if any color updates are required?\n\nThank you! Looking forward to your feedback.\n\n![Image](https://github.com/user-attachments/assets/d1ae7893-d313-4e8e-9e67-8069814d86c9)\n\n![Image](https://github.com/user-attachments/assets/e8400d87-4659-4a4c-adab-830c5747114b)", "I would like to work on this issue as part of the GDC AI Internship.", "@rithviknishad @Jacobjeevan guys??\n", "@sudosuanjal Let's not do that, stick with the current design, modify it to look better for smaller screens \uD83D\uDC4D ", "<img width=\"1912\" height=\"987\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e1e098ea-4c6c-42ff-be69-ffd08aaa20d3\" />\n\n<img width=\"588\" height=\"853\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ee6b1c0e-c1b6-43d1-b56b-2177869a3f55\" />\n\nHi @rithviknishad,\nApologies for the delay in completing the task, I had to step away for a while due to some personal reasons. I've now implemented the required changes.\nPlease feel free to reassign the issue to me so I can go ahead and raise the pull request.\nThanks for your patience \uD83D\uDE4F", "Hey team, if this is still valid ,I???d like to work on this. I???ll implement the toggle buttons using Tailwind classes with dynamic styling based on active state and state management in React.\n\nETA-26/07/2025" ],
      "repository" : {
        "description" : "Care is a Digital Public Good enabling TeleICU & Decentralised Administration of Healthcare Capacity across States.",
        "homepage" : "https://care.ohc.network",
        "name" : "care_fe",
        "fullName" : "ohcnetwork/care_fe",
        "htmlUrl" : "https://github.com/ohcnetwork/care_fe",
        "gitUrl" : "git://github.com/ohcnetwork/care_fe.git",
        "sshUrl" : "git@github.com:ohcnetwork/care_fe.git",
        "cloneUrl" : "https://github.com/ohcnetwork/care_fe.git",
        "owner" : {
          "login" : "ohcnetwork",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 841,
        "stargazersCount" : 539,
        "watchersCount" : 539,
        "size" : 56104,
        "openIssuesCount" : 197,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-24T18:43:38Z",
        "languages" : {
          "TypeScript" : 5000391,
          "Dockerfile" : 560,
          "CSS" : 7532,
          "JavaScript" : 11073,
          "HTML" : 3683
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Make tabs responsive for mobile view UI of Resource Page, with inconsistent and non-responsive outgoing, incoming and active, and completed tabs.",
      "validationOrRequirement" : "The UI should be improved and made responsive like the provided screenshot, and the current design should be modified to look better for smaller screens.",
      "attemptedFixes" : "The issue has been attempted to be fixed by some contributors, including implementing toggle buttons using Tailwind classes with dynamic styling based on active state and state management in React.",
      "otherNotes" : "The issue is about making tabs responsive for mobile view UI of Resource Page, with inconsistent and non-responsive outgoing, incoming and active, and completed tabs.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407815
  }, {
    "issueDTO" : {
      "id" : 3215367543,
      "title" : "[Typography] Defining typography values does not update CSS variables",
      "url" : "https://github.com/mui/material-ui/issues/46498",
      "repositoryName" : "mui/material-ui",
      "description" : "### Steps to reproduce\n\nI created the theme by following the example described here https://mui.com/material-ui/customization/typography/#responsive-font-sizes. The only difference is that I want CSS variables to be generated so I added the appropriate options for `cssVariables`.\n```js\nconst theme = createTheme({\n  cssVariables: {\n    colorSchemeSelector: 'class',\n  },\n});\n\ntheme.typography.h3 = {\n  fontSize: '1.2rem',\n  '@media (min-width:600px)': {\n    fontSize: '1.5rem',\n  },\n  [theme.breakpoints.up('md')]: {\n    fontSize: '2.4rem',\n  },\n};\n```\n\n### Current behavior\n\nThe CSS variable `--mui-font-h3` has a default value all the time, instead of the value defined from theme. \n```\n--mui-font-h3: 400 3rem / 1.167 \"Roboto\", \"Helvetica\", \"Arial\", sans-serif;\n```\nhttps://stackblitz.com/edit/github-emurbz-94uwqfdk?file=src%2Fcomponents%2FProTip.tsx\n\n### Expected behavior\n\nThe CSS variable should reflect the values set in the theme.\n```\n--mui-font-h3: 400 1.2rem / 1.167 \"Roboto\", \"Helvetica\", \"Arial\", sans-serif;\n```\n\n### Context\n\n_No response_\n\n### Your environment\n\n<details>\n  <summary><code>npx @mui/envinfo</code></summary>\n\n```\nSystem:\n    OS: macOS 15.3.2\n  Binaries:\n    Node: 22.14.0 - ~/.nvm/versions/node/v22.14.0/bin/node\n    npm: 10.9.2 - ~/.nvm/versions/node/v22.14.0/bin/npm\n    pnpm: Not Found\n  Browsers:\n    Chrome: 138.0.7204.51\n    Edge: Not Found\n    Safari: 18.3.1\n  npmPackages:\n    @emotion/react: ^11.14.0 => 11.14.0 \n    @emotion/styled: ^11.14.1 => 11.14.1 \n    @mui/core-downloads-tracker:  7.2.0 \n    @mui/icons-material: ^7.2.0 => 7.2.0 \n    @mui/material: ^7.2.0 => 7.2.0 \n    @mui/material-nextjs: ^7.2.0 => 7.2.0 \n    @mui/private-theming:  7.2.0 \n    @mui/styled-engine:  7.2.0 \n    @mui/system:  7.2.0 \n    @mui/types:  7.4.4 \n    @mui/utils:  7.2.0 \n    @types/react: ^19 => 19.1.8 \n    react: ^19.0.0 => 19.1.0 \n    react-dom: ^19.0.0 => 19.1.0 \n    typescript: ^5 => 5.8.3\n```\n</details>\n\n\n**Search keywords**: css variables, create theme",
      "updatedAt" : 1753363589.000000000,
      "user" : "zacol",
      "userHtmlUrl" : "https://github.com/zacol",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/565560?v=4",
      "labels" : [ "customization: css", "docs", "ready to take", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "For CSS variables to work, the `typography` must be defined within the same call because the `theme.vars` is calculated once:\n\n\n```js\nconst baseTheme = createTheme();\n\nconst theme = createTheme({\n  cssVariables: {\n    colorSchemeSelector: 'class',\n  },\n  typography: {\n    h3: {\n       fontSize: '1.2rem',\n      '@media (min-width:600px)': {\n        fontSize: '1.5rem',\n      },\n      [baseTheme.breakpoints.up('md')]: {\n        fontSize: '2.4rem',\n      },\n    }\n  }\n});\n```\n\nI think we could improve the [docs on this](https://mui.com/material-ui/customization/typography/#responsive-font-sizes) to be:\n\n```diff\nconst baseTheme = createTheme();\n\nconst theme = createTheme({\n  typography: {\n    h3: {\n       fontSize: '1.2rem',\n      '@media (min-width:600px)': {\n        fontSize: '1.5rem',\n      },\n      [baseTheme.breakpoints.up('md')]: {\n        fontSize: '2.4rem',\n      },\n    }\n  }\n});\n```", "@siriwatknp  Hi, I want to work on this? Could I take this up?", "> @siriwatknp  Hi, I want to work on this? Could I take this up?\n\nThank you, feel free to tag me when you have the PR ready.", "Hi @siriwatknp  @ZeeshanTamboli , I was wondering if we should also update the existing description:\n???The theme.typography.* [variant](https://mui.com/material-ui/customization/typography/#variants) properties map directly to the generated CSS. You can use [media queries](https://mui.com/material-ui/customization/breakpoints/#api) inside them.???\nto better align with the changes made in the demo.\n\nI???d be happy to make that update if needed ??? just let me know what you think!\n\nI???ve also connected a PR for this ??? whenever you get a chance, could you please take a look and review it?", "Hi, I???d like to work on this,please assign it to me.", "@NandanaAnukumar There's a already a PR up for it: #46558 " ],
      "repository" : {
        "description" : "Material UI: Comprehensive React component library that implements Google's Material Design. Free forever.",
        "homepage" : "https://mui.com/material-ui/",
        "name" : "material-ui",
        "fullName" : "mui/material-ui",
        "htmlUrl" : "https://github.com/mui/material-ui",
        "gitUrl" : "git://github.com/mui/material-ui.git",
        "sshUrl" : "git@github.com:mui/material-ui.git",
        "cloneUrl" : "https://github.com/mui/material-ui.git",
        "owner" : {
          "login" : "mui",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 32597,
        "stargazersCount" : 96214,
        "watchersCount" : 96214,
        "size" : 691803,
        "openIssuesCount" : 1761,
        "subscribersCount" : 1333,
        "pushedAt" : "2025-07-24T10:50:25Z",
        "languages" : {
          "TypeScript" : 4745515,
          "CSS" : 25010,
          "JavaScript" : 4451242,
          "HTML" : 1631
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the problem where the CSS variable does not update correctly when defining typography values in the theme.",
      "validationOrRequirement" : "The issue requires the usage of CSS variables and the creation of a theme with typography values. The author wants the CSS variable to reflect the values set in the theme.",
      "attemptedFixes" : "The author mentions that they tried defining the typography within the same call as the theme creation, and also mentions that the issue might be related to the documentation.",
      "otherNotes" : "The issue is related to the usage of CSS variables and the creation of a theme with typography values. The author wants the CSS variable to reflect the values set in the theme, but it's not updating correctly. The issue is marked as good first issue and has a PR already up for it.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407820
  }, {
    "issueDTO" : {
      "id" : 3258780269,
      "title" : "Slow CI runs `lint/tidy_flake8_macos` and `lint/tidy_flake8_ubuntu`",
      "url" : "https://github.com/solvcon/modmesh/issues/554",
      "repositoryName" : "solvcon/modmesh",
      "description" : "We have `lint / tidy_flake8_macos` and `lint / tidy_flake8_ubuntu` CI to check the format in Python. But it need 10~25 mins to check format.\n\n`lint / tidy_flake8_ubuntu`:\n - Cost 11m36s. See the [job](https://github.com/solvcon/modmesh/actions/runs/16489770954/job/46621648379).\n - Cost 12m30s. See the [job](https://github.com/solvcon/modmesh/actions/runs/15698590151/job/44228470406).\n\n`lint / tidy_flake8_macos`:\n - Cost 24m18s. See the [job](https://github.com/solvcon/modmesh/actions/runs/16489628194/job/46621236910).\n - Cost 25m37s. See the [job](https://github.com/solvcon/modmesh/actions/runs/15698590151/job/44228470405).\n\nCompare clang-checker (40s), it need 18.75x~38.425x time cost, which is strange.\nI think it should skip pilot build stage to reduce the time cost. Only run flake8 format checker on Python script.",
      "updatedAt" : 1753363488.000000000,
      "user" : "c1ydehhx",
      "userHtmlUrl" : "https://github.com/c1ydehhx",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/69747731?v=4",
      "labels" : [ "build", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "clang-tidy is necessary for C++.  A proposal to speed it up is welcome.  We should not skip the basic static check.\n\nRunning it with debug build makes it slower, but also find more issues than release build.  The behaviors between Linux and macos slightly differ sometimes so we need the runs on the two platforms." ],
      "repository" : {
        "description" : "Toolkit for solving partial differential equations",
        "homepage" : "",
        "name" : "modmesh",
        "fullName" : "solvcon/modmesh",
        "htmlUrl" : "https://github.com/solvcon/modmesh",
        "gitUrl" : "git://github.com/solvcon/modmesh.git",
        "sshUrl" : "git@github.com:solvcon/modmesh.git",
        "cloneUrl" : "https://github.com/solvcon/modmesh.git",
        "owner" : {
          "login" : "solvcon",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 49,
        "stargazersCount" : 50,
        "watchersCount" : 50,
        "size" : 1904,
        "openIssuesCount" : 72,
        "subscribersCount" : 13,
        "pushedAt" : "2025-07-24T02:31:53Z",
        "languages" : {
          "C++" : 956213,
          "Shell" : 3908,
          "CMake" : 36688,
          "Makefile" : 8518,
          "Python" : 557267,
          "GLSL" : 571
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Improve the performance of CI runs `lint/tidy_flake8_macos` and `lint/tidy_flake8_ubuntu` by optimizing the build process and reducing the time taken",
      "validationOrRequirement" : "reduce time cost, 18.75x~38.425x time cost compared to clang-checker",
      "attemptedFixes" : "skip pilot build stage to reduce the time cost. Only run flake8 format checker on Python script",
      "otherNotes" : "clang-tidy is necessary for C++. A proposal to speed it up is welcome. We should not skip the basic static check. Running it with debug build makes it slower, but also find more issues than release build. The behaviors between Linux and macos slightly differ sometimes so we need the runs on the two platforms.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407825
  }, {
    "issueDTO" : {
      "id" : 3217385115,
      "title" : "Fix error handling in the binary xds validator method",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11634",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "See the https://github.com/kgateway-dev/kgateway/blob/3305e7830fb8eef00046066ea37e3ecb22256c9e/pkg/validator/validator.go#L51. The error wrapping in that LOC is wrong and will hide errors. Likely needs to be `return fmt.Errorf(\"%v: %w\", ErrInvalidXDS, err)`.",
      "updatedAt" : 1753363435.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "Temporarily unassigning myself. I'm seeing this pop up more and more though, so i might take a stab at it at some point in the near future.", "@devc007 low hanging fruit in case you're interested.", "yeah @timflannagan will raise PR soon, thank you!" ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 543,
        "stargazersCount" : 4653,
        "watchersCount" : 4653,
        "size" : 211827,
        "openIssuesCount" : 562,
        "subscribersCount" : 100,
        "pushedAt" : "2025-07-24T19:33:09Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16895,
          "Rust" : 20712,
          "Makefile" : 32755,
          "JavaScript" : 435,
          "Go" : 4121797,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix error handling in the binary xds validator method",
      "validationOrRequirement" : "Error wrapping in the specified LOC should be done using `return fmt.Errorf(\"%v: %w\", ErrInvalidXDS, err)\"",
      "attemptedFixes" : "None mentioned in the description or comments",
      "otherNotes" : "Temporarily unassigning myself. I'm seeing this pop up more and more though, so i might take a stab at it at some point in the near future., @devc007 low hanging fruit in case you're interested., yeah @timflannagan will raise PR soon, thank you!",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407830
  }, {
    "issueDTO" : {
      "id" : 3183170473,
      "title" : "Job Board: Easy Fix: Host Bootstrap.js locally instead of using jsdelivr",
      "url" : "https://github.com/opensourcedesign/opensourcedesign.github.io/issues/492",
      "repositoryName" : "opensourcedesign/opensourcedesign.github.io",
      "description" : "Description: We host the other used [javascript libraries locally](https://github.com/opensourcedesign/jobs/blob/e04c6ff80ff96d2bc72d5a033d10c750e105a8a9/_includes/footer.html#L66). A [recent commit](https://github.com/opensourcedesign/jobs/pull/960/commits/7e43f2d16c85bc5eca760af1737fd550e24de058) introduced a needed js library, but links to it at jsdelivr instead of using a locally hosted version. \n\nPossible Solution: Check in the minified library locally and link to it instead of to the version hosted at jsdelivr.",
      "updatedAt" : 1753363331.000000000,
      "user" : "jdittrich",
      "userHtmlUrl" : "https://github.com/jdittrich",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3416487?v=4",
      "labels" : [ "bug", "Jobs", "JS", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I created a PR numbered #962 that fixes this.", "pr link - https://github.com/opensourcedesign/jobs/pull/962", "Hi! \uD83D\uDC4B I???d like to contribute to this issue. I???ll work on replacing the external jsdelivr link with a locally hosted version of the required JS library. Let me know if someone is already working on it or if there's anything I should keep in mind before raising a PR. Thanks!\n", "@jdittrich did this get completed?", "> Hi! \uD83D\uDC4B I???d like to contribute to this issue. I???ll work on replacing the external jsdelivr link with a locally hosted version of the required JS library. Let me know if someone is already working on it or if there's anything I should keep in mind before raising a PR. Thanks!\n\nhttps://github.com/opensourcedesign/opensourcedesign.github.io/issues/493 <<<< this is the new issue i think this issue got completed!" ],
      "repository" : {
        "description" : "\uD83C\uDFA8\uD83D\uDCBB Source code of our website",
        "homepage" : "https://opensourcedesign.net",
        "name" : "opensourcedesign.github.io",
        "fullName" : "opensourcedesign/opensourcedesign.github.io",
        "htmlUrl" : "https://github.com/opensourcedesign/opensourcedesign.github.io",
        "gitUrl" : "git://github.com/opensourcedesign/opensourcedesign.github.io.git",
        "sshUrl" : "git@github.com:opensourcedesign/opensourcedesign.github.io.git",
        "cloneUrl" : "https://github.com/opensourcedesign/opensourcedesign.github.io.git",
        "owner" : {
          "login" : "opensourcedesign",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 200,
        "stargazersCount" : 367,
        "watchersCount" : 367,
        "size" : 140893,
        "openIssuesCount" : 53,
        "subscribersCount" : 147,
        "pushedAt" : "2025-06-09T06:51:43Z",
        "languages" : {
          "CSS" : 4516,
          "SCSS" : 20286,
          "JavaScript" : 2736,
          "HTML" : 39093,
          "Ruby" : 719
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal is to replace the external jsdelivr link with a locally hosted version of the required JS library.",
      "validationOrRequirement" : "The requirement is to host the Bootstrap.js library locally instead of using jsdelivr.",
      "attemptedFixes" : "A PR was created to fix this issue (#962).",
      "otherNotes" : "The issue was reported to host Bootstrap.js locally instead of using jsdelivr, and a PR was created to fix this.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407833
  }, {
    "issueDTO" : {
      "id" : 3257564839,
      "title" : "Generic \"exit status 1\" errors in API validation suite",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11751",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "When an API validation test case that expect to be successfully applied (i.e. wantError is unspecified or set explicitly to empty string), and the apiserver ends up rejects the configuration, then `exit status 1` is logged, making it difficult to debug the test case further. See https://github.com/kgateway-dev/kgateway/blob/352400f278f80b6da7aa45620535d601df44f873/test/kubernetes/e2e/tests/api_validation_test.go#L338-L340 for the relevant LOC.\n\nInstead, we should log the `out.String()` when wantErr == \"\" and err != nil.",
      "updatedAt" : 1753363274.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi, I'd like to work on this issue. Could you please assign it to me?\n@timflannagan " ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 543,
        "stargazersCount" : 4653,
        "watchersCount" : 4653,
        "size" : 211827,
        "openIssuesCount" : 562,
        "subscribersCount" : 100,
        "pushedAt" : "2025-07-24T19:33:09Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16895,
          "Rust" : 20712,
          "Makefile" : 32755,
          "JavaScript" : 435,
          "Go" : 4121797,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To log the out.String() instead of exit status 1 when an API validation test case fails and wantErr is unspecified or set to an empty string",
      "validationOrRequirement" : "The requirement is to log the out.String() when wantErr is an empty string and err is not nil",
      "attemptedFixes" : "None mentioned in the issue description",
      "otherNotes" : "The issue is related to API validation suite, specifically with exit status 1 errors, and there's a link to the relevant LOC in the test file.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407837
  }, {
    "issueDTO" : {
      "id" : 3257797281,
      "title" : "Rename the regression-tests.yaml GHA workflow",
      "url" : "https://github.com/kgateway-dev/kgateway/issues/11753",
      "repositoryName" : "kgateway-dev/kgateway",
      "description" : "This workflow is currently scoped to running the conformance related suites. Additionally, the current naming conflicts with the https://github.com/kgateway-dev/kgateway/blob/main/.github/workflows/pr-kubernetes-tests.yaml which also handles our regression/presubmit testing. We should rename the former's filename to be conformance.yaml or some invariant of that.",
      "updatedAt" : 1753363243.000000000,
      "user" : "timflannagan",
      "userHtmlUrl" : "https://github.com/timflannagan",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/9899409?v=4",
      "labels" : [ "Good First Issue" ],
      "state" : "OPEN",
      "comments" : [ "/assign \nplease assign me???thank you" ],
      "repository" : {
        "description" : "The Cloud-Native API Gateway and AI Gateway",
        "homepage" : "https://kgateway.dev",
        "name" : "kgateway",
        "fullName" : "kgateway-dev/kgateway",
        "htmlUrl" : "https://github.com/kgateway-dev/kgateway",
        "gitUrl" : "git://github.com/kgateway-dev/kgateway.git",
        "sshUrl" : "git@github.com:kgateway-dev/kgateway.git",
        "cloneUrl" : "https://github.com/kgateway-dev/kgateway.git",
        "owner" : {
          "login" : "kgateway-dev",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 543,
        "stargazersCount" : 4653,
        "watchersCount" : 4653,
        "size" : 211827,
        "openIssuesCount" : 562,
        "subscribersCount" : 100,
        "pushedAt" : "2025-07-24T19:33:09Z",
        "languages" : {
          "Smarty" : 4225,
          "Dockerfile" : 3622,
          "Shell" : 16895,
          "Rust" : 20712,
          "Makefile" : 32755,
          "JavaScript" : 435,
          "Go" : 4121797,
          "Python" : 1003786
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rename the regression-tests.yaml GitHub Actions workflow to a more descriptive and unique name.",
      "validationOrRequirement" : "Rename the workflow filename to avoid conflicts and ensure it's descriptive.",
      "attemptedFixes" : "None mentioned",
      "otherNotes" : "The issue is related to renaming a GitHub Actions workflow to avoid naming conflicts with another workflow.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407839
  }, {
    "issueDTO" : {
      "id" : 3246700645,
      "title" : "add a `screenshots` attribute in the `torrents` table",
      "url" : "https://github.com/Arcadia-Solutions/arcadia/issues/284",
      "repositoryName" : "Arcadia-Solutions/arcadia",
      "description" : "an array of string that will contain direct links to images",
      "updatedAt" : 1753363171.000000000,
      "user" : "FrenchGithubUser",
      "userHtmlUrl" : "https://github.com/FrenchGithubUser",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/71668459?v=4",
      "labels" : [ "backend", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "there should also be changes in the related structs and on the torrent upload process" ],
      "repository" : {
        "description" : "Content-agnostic torrent site & tracker framework",
        "homepage" : "https://arcadia-solutions.github.io/arcadia/",
        "name" : "arcadia",
        "fullName" : "Arcadia-Solutions/arcadia",
        "htmlUrl" : "https://github.com/Arcadia-Solutions/arcadia",
        "gitUrl" : "git://github.com/Arcadia-Solutions/arcadia.git",
        "sshUrl" : "git@github.com:Arcadia-Solutions/arcadia.git",
        "cloneUrl" : "https://github.com/Arcadia-Solutions/arcadia.git",
        "owner" : {
          "login" : "Arcadia-Solutions",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 22,
        "stargazersCount" : 150,
        "watchersCount" : 150,
        "size" : 21747,
        "openIssuesCount" : 88,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-23T20:17:42Z",
        "languages" : {
          "TypeScript" : 55796,
          "Dockerfile" : 3323,
          "Shell" : 9946,
          "CSS" : 4241,
          "Rust" : 432662,
          "PLpgSQL" : 36967,
          "Vue" : 227252,
          "HTML" : 310
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "add a `screenshots` attribute in the `torrents` table",
      "validationOrRequirement" : "an array of string that will contain direct links to images",
      "attemptedFixes" : "",
      "otherNotes" : "there should also be changes in the related structs and on the torrent upload process",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407841
  }, {
    "issueDTO" : {
      "id" : 2398890994,
      "title" : "Feature Request: Parent/Child \"Nested\" Tag Relationships",
      "url" : "https://github.com/sysadminsmedia/homebox/issues/112",
      "repositoryName" : "sysadminsmedia/homebox",
      "description" : "### What is the problem you are trying to solve with this feature?\n\nToday, items must be tagged manually, with each applicable tag. This can lead to a somewhat disorganized sprawl of tags, some of which are always 'paired' with each other anyway.\n\n### What is the solution you are proposing?\n\nI think it would be valuable to be able to designate a tag as a 'parent' tag & add 'child' tags to the parent, so if an item is tagged with the child tag, it also shows up in reports/search results for the parent tag as well.\n\n### What alternatives have you considered?\n\nManual tagging of such 'child/parent' tags individually\n\n### Additional context\n\nExample:\r\n\r\n- Parent Tag: Electronics & Accessories\r\n  - Hard Drives\r\n    - Backup Hard Drive\r\n    - Production Hard Drive\r\n    - Spare Hard Drive\r\n  - Computers\r\n    - Laptops\r\n    - Servers\n\n### Contributions\n\n- [X] I have searched through existing issues and feature requests to see if my idea has already been proposed.\n- [ ] If this feature is accepted, I would be willing to help implement and maintain this feature.\n- [X] If this feature is accepted, I'm willing to sponsor the development of this feature.",
      "updatedAt" : 1753363144.000000000,
      "user" : "a2brew",
      "userHtmlUrl" : "https://github.com/a2brew",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/88284052?v=4",
      "labels" : [ "\uD83D\uDC77????????? help wanted", "hacktoberfest", "?????? enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "This actually makes perfect sense to be honest, maybe even having a button with something simple like ???inherit parent tags??? so that the user can decide whether to or not..!", "I don't think that it ever makes sense for it to not inherit the parents tag.  Essentially we're talking about creating a taxonomy using tags.  I'll look into doing this as a first effort.", "Just curious if this has been looked at yet. Nested locations and nested items are great and make good use of the DB relative to a spreadsheet. Nested tags would be icing on the cake!" ],
      "repository" : {
        "description" : "A continuation of HomeBox the inventory and organization system built for the Home User",
        "homepage" : "https://homebox.software",
        "name" : "homebox",
        "fullName" : "sysadminsmedia/homebox",
        "htmlUrl" : "https://github.com/sysadminsmedia/homebox",
        "gitUrl" : "git://github.com/sysadminsmedia/homebox.git",
        "sshUrl" : "git@github.com:sysadminsmedia/homebox.git",
        "cloneUrl" : "https://github.com/sysadminsmedia/homebox.git",
        "owner" : {
          "login" : "sysadminsmedia",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 187,
        "stargazersCount" : 3335,
        "watchersCount" : 3335,
        "size" : 50307,
        "openIssuesCount" : 54,
        "subscribersCount" : 16,
        "pushedAt" : "2025-07-24T15:00:45Z",
        "languages" : {
          "TypeScript" : 144705,
          "Dockerfile" : 3796,
          "CSS" : 30417,
          "Vue" : 442531,
          "JavaScript" : 5937,
          "Go" : 555375,
          "HTML" : 14508,
          "Python" : 2398
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a feature that allows users to create a 'parent/child' tag relationship, enabling more organized and structured tagging.",
      "validationOrRequirement" : "The feature requires the ability to designate a tag as a 'parent' and add 'child' tags to it, and also to display child tags in reports/search results for the parent tag.",
      "attemptedFixes" : "Manual tagging of 'child/parent' tags individually has been considered as an alternative solution.",
      "otherNotes" : "This feature request proposes creating a 'parent/child' tag relationship, allowing users to designate a tag as a 'parent' and add 'child' tags to it, which would also show up in reports/search results for the parent tag.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407846
  }, {
    "issueDTO" : {
      "id" : 3259878753,
      "title" : "expanding mediainfo stretches the torrents table",
      "url" : "https://github.com/Arcadia-Solutions/arcadia/issues/289",
      "repositoryName" : "Arcadia-Solutions/arcadia",
      "description" : "for example, with the fixtures: http://localhost:5173/title-group/2",
      "updatedAt" : 1753363045.000000000,
      "user" : "FrenchGithubUser",
      "userHtmlUrl" : "https://github.com/FrenchGithubUser",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/71668459?v=4",
      "labels" : [ "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Content-agnostic torrent site & tracker framework",
        "homepage" : "https://arcadia-solutions.github.io/arcadia/",
        "name" : "arcadia",
        "fullName" : "Arcadia-Solutions/arcadia",
        "htmlUrl" : "https://github.com/Arcadia-Solutions/arcadia",
        "gitUrl" : "git://github.com/Arcadia-Solutions/arcadia.git",
        "sshUrl" : "git@github.com:Arcadia-Solutions/arcadia.git",
        "cloneUrl" : "https://github.com/Arcadia-Solutions/arcadia.git",
        "owner" : {
          "login" : "Arcadia-Solutions",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 22,
        "stargazersCount" : 150,
        "watchersCount" : 150,
        "size" : 21747,
        "openIssuesCount" : 88,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-23T20:17:42Z",
        "languages" : {
          "TypeScript" : 55796,
          "Dockerfile" : 3323,
          "Shell" : 9946,
          "CSS" : 4241,
          "Rust" : 432662,
          "PLpgSQL" : 36967,
          "Vue" : 227252,
          "HTML" : 310
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to resolve the problem of the mediainfo feature stretching the torrents table.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the issue description.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the issue description.",
      "otherNotes" : "The issue is related to the mediainfo feature and its impact on the torrents table, specifically when expanding it.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407849
  }, {
    "issueDTO" : {
      "id" : 2486460953,
      "title" : "Adding suppport for reverse iteration",
      "url" : "https://github.com/tonbo-io/tonbo/issues/109",
      "repositoryName" : "tonbo-io/tonbo",
      "description" : "In current, `Transaction::scan` and `DB::scan` only supports ascending order, it should be better to support reverse order iteration. This includes two steps tasks:\r\n- [ ] API design\r\n- [ ] the reverse iteration implentation",
      "updatedAt" : 1753363024.000000000,
      "user" : "ethe",
      "userHtmlUrl" : "https://github.com/ethe",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12211036?v=4",
      "labels" : [ "enhancement", "good first issue", "M - Medium" ],
      "state" : "OPEN",
      "comments" : [ "Taking this up", "This is what I am thinkging, please let me know if this is okay or feel free to mention changes.\r\n\r\nApi design - \r\n\r\n```\r\nenum ScanOrder {\r\n    Ascending,\r\n    Descending,\r\n```\r\n\r\nThis can be passed to `DB::Scan`\r\n```\r\npub async fn scan<'scan, T: 'scan>(\r\n        &'scan self,\r\n        range: (Bound<&'scan R::Key>, Bound<&'scan R::Key>),\r\n        mut f: impl FnMut(TransactionEntry<'_, R>) -> T + 'scan,\r\n        order: ScanOrder\r\n    ) -> impl Stream<Item = Result<T, CommitError<R>>> + 'scan\r\n```\r\n    \r\n and \r\n \r\n Also to `Transaction::Scan`\r\n ```\r\n pub async fn scan<'scan>(\r\n        &'scan self,\r\n        range: (Bound<&'scan R::Key>, Bound<&'scan R::Key>),\r\n        order: ScanOrder\r\n    ) -> Scan<'scan, R, FP> {\r\n        let streams = vec![TransactionScan {\r\n            inner: self.local.range(range), // match here to wrt to scanorder to do ascending(default) or descending\r\n            ts: self.ts,\r\n        }\r\n        .into()];\r\n        Scan::new(&self.share, range, self.ts, &self.version, streams)\r\n    }\r\n```", "Is it better to have a builder pattern here? Because I think iteration is much more common than reverse iteration, we could keep:\r\n```rust\r\npub async fn scan<'scan>(\r\n       &'scan self,\r\n       range: (Bound<&'scan R::Key>, Bound<&'scan R::Key>),\r\n   ) -> Scan<'scan, R, FP>\r\n```\r\n\r\nthen we add `reverse` method on `Scan`, users are able to use it like\r\n```rust\r\n            let mut scan = txn\r\n                .scan((Bound::Included(&name), Bound::Excluded(&upper)))\r\n                .await\r\n                .reverse()\r\n                .take()\r\n                .await\r\n                .unwrap();\r\n```\r\n\r\nIn this way, if users do not explicitly declare reverse iterating, Tonbo could use iterating as default.", "Aligned.", "`MergeScan` consists of multiple iterators\r\n- MutableScan\r\n- ImmutableScan\r\n- LevelStream\r\n- SsTableScan\r\n  - ParquetRecordBatchStream\r\n\r\nThese should all implement reverse", "Can I give this a try @ethe ?", "@hp77-creator sure, I'd love to!", "Hi, I have another take on this https://github.com/mysuperai/superai-flows/pull/366 @ethe " ],
      "repository" : {
        "description" : "A portable embedded database using Arrow.",
        "homepage" : "https://tonbo.io",
        "name" : "tonbo",
        "fullName" : "tonbo-io/tonbo",
        "htmlUrl" : "https://github.com/tonbo-io/tonbo",
        "gitUrl" : "git://github.com/tonbo-io/tonbo.git",
        "sshUrl" : "git@github.com:tonbo-io/tonbo.git",
        "cloneUrl" : "https://github.com/tonbo-io/tonbo.git",
        "owner" : {
          "login" : "tonbo-io",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 75,
        "stargazersCount" : 1114,
        "watchersCount" : 1114,
        "size" : 2743,
        "openIssuesCount" : 38,
        "subscribersCount" : 17,
        "pushedAt" : "2025-07-24T11:57:07Z",
        "languages" : {
          "RenderScript" : 1,
          "Rust" : 739857,
          "JavaScript" : 1732,
          "Python" : 38266
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for reverse iteration in Transaction::scan and DB::scan, including API design and implementation of reverse iteration.",
      "validationOrRequirement" : "The API design should include passing ScanOrder as an enum to the scan function. The implementation should involve creating a builder pattern for the scan function and adding a reverse method. The reverse iteration should be implemented for all iterators: MutableScan, ImmutableScan, LevelStream, SsTableScan, and ParquetRecordBatchStream.",
      "attemptedFixes" : "The issue mentions the implementation of the reverse iteration and the possibility of using a builder pattern. The comment section discusses the implementation and the possibility of using a default ascending order if the user does not explicitly declare reverse iteration.",
      "otherNotes" : "The issue is about adding support for reverse iteration in Transaction::scan and DB::scan. The current implementation only supports ascending order. The solution involves two steps: API design and implementation of reverse iteration. The API design includes passing ScanOrder as an enum to the scan function. The implementation involves creating a builder pattern for the scan function and adding a reverse method. The comment section discusses the implementation and the possibility of using a default ascending order if the user does not explicitly declare reverse iteration.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407857
  }, {
    "issueDTO" : {
      "id" : 2995718367,
      "title" : "Refactor cluster_info module to reduce complexity of the code",
      "url" : "https://github.com/anza-xyz/agave/issues/5824",
      "repositoryName" : "anza-xyz/agave",
      "description" : "#### Problem\n\n`cluster_info` module has the following problems:\n* too much code in one module -- for example, maybe move `Node` to it's own file?\n* `Node` has several constructors which have some differences but I'm sure there is a space for consolidation\n* `Sockets` structure is flat, so it spits sockets by names. For example, `tpu_` and later these fields are used to construct structure `TpuSockets`. Extract structures with proper construction encapsulation.\n* in `new_localhost_with_pubkey_and_quic_endpoints` we sometime bind to 0.0.0.0 and sometimes to localhost.\n* Encapsulation -- remove `pub` from fields:\n```rust\npub struct Node {\n    pub info: ContactInfo,\n    pub sockets: Sockets,\n}\n```\n\n",
      "updatedAt" : 1753362871.000000000,
      "user" : "KirillLykov",
      "userHtmlUrl" : "https://github.com/KirillLykov",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/687962?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@alexpyattaev Created an issue while looking into it. Might be a good starting issue for a new comer.", "struct Sockets is definitely on their way towards net-utils so we can have all socket binding related code in more or less one place.  It can be neatly split off from Node initialization. [PR for that](https://github.com/anza-xyz/agave/pull/5832)", "@KirillLykov @alexpyattaev Is this issue up for grabs?", "go for it! I forgot about it completely", "Is it still up?\n", "> Is it still up?\n\nYes, but you can also look at any other file that looks particularly nasty, such as issues in blockstore.rs https://github.com/anza-xyz/agave/issues/5923 \n\nJust make sure that you do not change the signatures that are part of the public API. ", "@KirillLykov???@alexpyattaev??Hi! I see PR???#6668 is stalled with merge conflicts.  \nI???d be happy to rebase it on current???`master`, add the requested `pub use Node`.  \nIs it OK if I take this over (either by pushing to the existing branch or opening a fresh PR that supersedes it)? Thanks!\n" ],
      "repository" : {
        "description" : "Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.",
        "homepage" : "https://www.anza.xyz/",
        "name" : "agave",
        "fullName" : "anza-xyz/agave",
        "htmlUrl" : "https://github.com/anza-xyz/agave",
        "gitUrl" : "git://github.com/anza-xyz/agave.git",
        "sshUrl" : "git@github.com:anza-xyz/agave.git",
        "cloneUrl" : "https://github.com/anza-xyz/agave.git",
        "owner" : {
          "login" : "anza-xyz",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : true,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 614,
        "stargazersCount" : 1222,
        "watchersCount" : 1222,
        "size" : 456811,
        "openIssuesCount" : 676,
        "subscribersCount" : 37,
        "pushedAt" : "2025-07-24T23:30:12Z",
        "languages" : {
          "Dockerfile" : 5772,
          "Shell" : 455456,
          "C++" : 18125,
          "Rust" : 22450203,
          "C" : 138899,
          "Linker Script" : 452,
          "Makefile" : 10490,
          "TeX" : 835,
          "Python" : 20303
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Refactor cluster_info module to reduce complexity of the code by moving Node to its own file, consolidating constructors, and extracting structures with proper construction encapsulation",
      "validationOrRequirement" : "Do not change public API signatures, refactor code to reduce complexity, encapsulate structures",
      "attemptedFixes" : "PR #5832 for extracting sockets structure, PR #6668 for rebase and pub use Node",
      "otherNotes" : "Issue is up for grabs, but can also be looked into other files like blockstore.rs. PR #6668 is stalled with merge conflicts and needs rebase.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407861
  }, {
    "issueDTO" : {
      "id" : 3227750703,
      "title" : "Logger strips filenames weirdly when repo is not named \"lakefs\"",
      "url" : "https://github.com/treeverse/lakeFS/issues/9296",
      "repositoryName" : "treeverse/lakeFS",
      "description" : "This affects:\n- Any build in a directory with a strange name.\n- Any re-use of the lakeFS logging infrastructure in other projects.\n- The lakeFS enterprise server.  Many logs are emitted from files named \"-Enterprise/...\", which is oddly confusing.\n\nWe probably need to improve function logCallTrimmer.  For instance, ProjectDirectoryName might be injected differently from other projects, it might be a var (set during some init), perhaps a var holding a regexp for the part to keep, or something else.",
      "updatedAt" : 1753362797.000000000,
      "user" : "arielshaqed",
      "userHtmlUrl" : "https://github.com/arielshaqed",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7802932?v=4",
      "labels" : [ "go", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hello, I'm interested in this question. Can I do this question here? @arielshaqed ", "Hey @VH992098059 - all yours. Let us know if you need any assistance", "OK! thank you @itaiad200  \n", "Hello, I want to run this project locally, but I need a treeverse/lakefs-enterprise mirroring license. Am I going to apply for this??? @itaiad200 " ],
      "repository" : {
        "description" : "lakeFS - Data version control for your data lake | Git for data",
        "homepage" : "https://docs.lakefs.io",
        "name" : "lakeFS",
        "fullName" : "treeverse/lakeFS",
        "htmlUrl" : "https://github.com/treeverse/lakeFS",
        "gitUrl" : "git://github.com/treeverse/lakeFS.git",
        "sshUrl" : "git@github.com:treeverse/lakeFS.git",
        "cloneUrl" : "https://github.com/treeverse/lakeFS.git",
        "owner" : {
          "login" : "treeverse",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 382,
        "stargazersCount" : 4785,
        "watchersCount" : 4785,
        "size" : 159414,
        "openIssuesCount" : 417,
        "subscribersCount" : 41,
        "pushedAt" : "2025-07-24T14:07:38Z",
        "languages" : {
          "Java" : 249032,
          "CSS" : 55932,
          "C++" : 8023,
          "Scala" : 208930,
          "Makefile" : 16205,
          "Go" : 4209725,
          "Mustache" : 4548,
          "HTML" : 389,
          "TypeScript" : 130743,
          "Dockerfile" : 4911,
          "Shell" : 12862,
          "Batchfile" : 800,
          "JavaScript" : 461577,
          "Lua" : 34308,
          "Ruby" : 146,
          "Python" : 241357
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Logger strips filenames weirdly when repo is not named 'lakefs'.",
      "validationOrRequirement" : "Improve function logCallTrimmer, possibly by injecting ProjectDirectoryName differently.",
      "attemptedFixes" : "None mentioned in the issue description or comments.",
      "otherNotes" : "This issue affects builds in directories with strange names, re-use of lakeFS logging infrastructure in other projects, and the lakeFS enterprise server.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407864
  }, {
    "issueDTO" : {
      "id" : 2895038222,
      "title" : "list of things that need sprites made",
      "url" : "https://github.com/DeltaV-Station/Delta-v/issues/3115",
      "repositoryName" : "DeltaV-Station/Delta-v",
      "description" : "## Description\nthe follow things have placeholder sprites and need someone good to draw new ones:\n- autodoc (its literally using a cdda sprite) - needs icon and ideally an animated one for when its active\n- deltav guns have no wield sprites, e.g. adjutant\n- ~~syndie fultons - just needs an evil looking icon~~\n- secborg module icons - theres a lot of them\n- syndiborg module icon - also a lot\n- practice disabler inhands, probably just recolor\n\nthese sprites are probably bad codersprites:\n- lathe upgrade kit",
      "updatedAt" : 1753362773.000000000,
      "user" : "deltanedas",
      "userHtmlUrl" : "https://github.com/deltanedas",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/39013340?v=4",
      "labels" : [ "Good First Issue", "Changes: Sprite", "Feature Request" ],
      "state" : "OPEN",
      "comments" : [ "I can do the practice disabler sprites", "Telegnosis too", "Don't forget the wield sprites for something like half our ballistic long-arms.\n\nVulcan, Tenebra, both types of Mark 1 (which need to be wieldable in general), Adjutant, Enforcer, and Jackdaw all need them last I checked.", "i'm working on the animated techfabs :3", "i've finished the borg ID chips, and have been working on fixing up the autodoc. I'll also work on the syndi borg logos and the upgrade kits", "i've finished the wizard pda and now am working on salvage doors", "the syndie fulton is outdated here no? its not being used anymore" ],
      "repository" : {
        "description" : "A fork of Space Station 14, embracing a mixture of classic SS13 chaos and experimentation only possible with the new engine",
        "homepage" : "https://deltav.gay",
        "name" : "Delta-v",
        "fullName" : "DeltaV-Station/Delta-v",
        "htmlUrl" : "https://github.com/DeltaV-Station/Delta-v",
        "gitUrl" : "git://github.com/DeltaV-Station/Delta-v.git",
        "sshUrl" : "git@github.com:DeltaV-Station/Delta-v.git",
        "cloneUrl" : "https://github.com/DeltaV-Station/Delta-v.git",
        "owner" : {
          "login" : "DeltaV-Station",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 525,
        "stargazersCount" : 107,
        "watchersCount" : 107,
        "size" : 985802,
        "openIssuesCount" : 233,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-24T20:45:26Z",
        "languages" : {
          "C#" : 22939952,
          "PowerShell" : 8968,
          "CSS" : 8911,
          "Fluent" : 1971788,
          "Go" : 5293,
          "XSLT" : 1873,
          "MATLAB" : 4971,
          "FreeMarker" : 1947,
          "Shell" : 1733,
          "Batchfile" : 724,
          "JavaScript" : 5224,
          "Lua" : 7782,
          "Nix" : 1633,
          "Python" : 67725
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create new sprites for various items in the DeltaV-Station/Delta-v repository",
      "validationOrRequirement" : "Good First Issue, Changes: Sprite, Feature Request",
      "attemptedFixes" : "The author has been working on the animated techfabs, borg ID chips, autodoc, syndi borg logos, and upgrade kits, and has finished the wizard pda and salvage doors.",
      "otherNotes" : "The issue is about creating new sprites for various items in the DeltaV-Station/Delta-v repository, including autodoc, deltav guns, syndie fultons, secborg module icons, syndiborg module icon, practice disabler inhands, and lathe upgrade kit. The comments mention specific items that need wield sprites, such as Vulcan, Tenebra, Mark 1, Adjutant, Enforcer, and Jackdaw.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407870
  }, {
    "issueDTO" : {
      "id" : 2287833073,
      "title" : "[Feature Request]  Create a `DivModable` trait",
      "url" : "https://github.com/modular/modular/issues/2598",
      "repositoryName" : "modular/modular",
      "description" : "### Review Mojo's priorities\r\n\r\n- [X] I have read the [roadmap and priorities](https://docs.modular.com/mojo/roadmap.html#overall-priorities) and I believe this request falls within the priorities.\r\n\r\n### What is your request?\r\n\r\nCreate a trait for the `__divmod__` method. In its simplest form, it would look like this in a struct:\r\n\r\n`fn __divmod__(self: Self, other: Self) -> Tuple[Self, Self]`\r\n\r\n\r\n### What is your motivation for this change?\r\n\r\nEach dunder method has its own trait. We should do it for `__divmod__` too. \r\n\r\nSee https://github.com/modularml/mojo/pull/2097#discussion_r1591144433\r\n\r\n\r\n### Any other details?\r\n\r\nWhile trying to implement it, I encountered a blocking error. See the issue https://github.com/modularml/mojo/issues/2597 . It might be a compiler bug, or I might misuse traits.",
      "updatedAt" : 1753362386.000000000,
      "user" : "gabrieldemarmiesse",
      "userHtmlUrl" : "https://github.com/gabrieldemarmiesse",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/12891691?v=4",
      "labels" : [ "mojo", "enhancement", "mojo-repo", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "@rparolin \r\n\r\nhello, I have an interest for this issue.\r\n\r\nI'm new comer of mojo repo, so I would like to know the reference.\r\nAre there any similar PRs or code that could help me resolve this issue?", "As @christoph-schlumpf mentioned [here](https://github.com/modular/modular/issues/2597#issuecomment-3096572922), this should be possible now.  This would be a great first issue still to allow the following code to work:\n\n```\n\n@fieldwise_init\nstruct Foo(DivModable):\n   var val : Int\n\n   fn __divmod__(self, other: Self) -> (Self, Self):\n      return 1, 1\n\nvar f0 = Foo(0)\nvar f1 = Foo(1)\nvar v0 = divmod(f0, f1)\n```\n\nCurrently `divmod` just works on `Int` and `UInt` if I recall correctly.", "Hi @kyoto7250,\n\nDo you still want to do that? Otherwise, I can do it.", "I'd like to give it a try \uD83D\uDC4D\uD83C\uDFFD " ],
      "repository" : {
        "description" : "The Modular Platform (includes MAX & Mojo)",
        "homepage" : "https://docs.modular.com/",
        "name" : "modular",
        "fullName" : "modular/modular",
        "htmlUrl" : "https://github.com/modular/modular",
        "gitUrl" : "git://github.com/modular/modular.git",
        "sshUrl" : "git@github.com:modular/modular.git",
        "cloneUrl" : "https://github.com/modular/modular.git",
        "owner" : {
          "login" : "modular",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2670,
        "stargazersCount" : 24548,
        "watchersCount" : 24548,
        "size" : 89312,
        "openIssuesCount" : 783,
        "subscribersCount" : 260,
        "pushedAt" : "2025-07-24T18:43:37Z",
        "languages" : {
          "MDX" : 653993,
          "Shell" : 16976,
          "Jinja" : 78,
          "Mojo" : 14782952,
          "Starlark" : 1102264,
          "HTML" : 885097,
          "Python" : 3975806,
          "Cuda" : 7324
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a trait for the __divmod__ method. In its simplest form, it would look like this in a struct: fn __divmod__(self: Self, other: Self) -> Tuple[Self, Self]",
      "validationOrRequirement" : "Each dunder method has its own trait. We should do it for __divmod__ too.",
      "attemptedFixes" : "While trying to implement it, I encountered a blocking error. See the issue https://github.com/modularml/mojo/issues/2597 . It might be a compiler bug, or I might misuse traits.",
      "otherNotes" : "The author is a new comer of mojo repo, so I would like to know the reference. Are there any similar PRs or code that could help me resolve this issue?, This would be a great first issue still to allow the following code to work: @fieldwise_init struct Foo(DivModable): var val : Int fn __divmod__(self, other: Self) -> (Self, Self): return 1, 1 var f0 = Foo(0) var f1 = Foo(1) var v0 = divmod(f0, f1) Currently divmod just works on Int and UInt if I recall correctly.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407878
  }, {
    "issueDTO" : {
      "id" : 2582785065,
      "title" : "Dependency Dashboard",
      "url" : "https://github.com/tuono-labs/tuono/issues/34",
      "repositoryName" : "tuono-labs/tuono",
      "description" : "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/tuono-labs/tuono).\n\n## Awaiting Schedule\n\nThe following updates are awaiting their schedule. To get an update now, click on a checkbox below.\n\n - [ ] <!-- unschedule-branch=renovate/babel-monorepo -->fix(deps): update dependency @babel/types to v7.28.2\n - [ ] <!-- unschedule-branch=renovate/oxlint-monorepo -->chore(deps): update dependency oxc-transform to v0.78.0\n - [ ] <!-- unschedule-branch=renovate/prettier-3.x -->chore(deps): update dependency prettier to v3.6.2\n - [ ] <!-- unschedule-branch=renovate/rust-1.x -->chore(deps): update rust docker tag to v1.88\n - [ ] <!-- unschedule-branch=renovate/vitejs-plugin-react-swc-3.x-lockfile -->fix(deps): update dependency @vitejs/plugin-react-swc to v3.11.0\n - [ ] <!-- unschedule-branch=renovate/prettier-3.x-lockfile -->fix(deps): update dependency prettier to v3.6.2\n\n## Open\n\nThe following updates have all been created. To force a retry/rebase of any, click on a checkbox below.\n\n - [ ] <!-- rebase-branch=renovate/vitest-eslint-plugin-1.x -->[chore(deps): update dependency @vitest/eslint-plugin to v1.3.4](../pull/801)\n - [ ] <!-- rebase-branch=renovate/devdependencies-(eslint) -->[chore(deps): update devdependencies (eslint)](../pull/807) (`@eslint/js`, `eslint`, `eslint-import-resolver-typescript`, `eslint-plugin-import`, `typescript-eslint`)\n - [ ] <!-- rebase-branch=renovate/vite-7.x -->[fix(deps): update dependency vite to v7](../pull/818)\n - [ ] <!-- rebase-all-open-prs -->**Click on this checkbox to rebase all open PRs at once**\n\n## Ignored or Blocked\n\nThe following updates are blocked by an existing closed PR. To recreate the PR, click on a checkbox below.\n\n - [ ] <!-- recreate-branch=renovate/unplugin-isolated-decl-0.x -->[chore(deps): update dependency unplugin-isolated-decl to v0.14.5](../pull/804)\n - [ ] <!-- recreate-branch=renovate/web-streams-polyfill-4.x-lockfile -->[fix(deps): update dependency web-streams-polyfill to v4.1.0](../pull/322)\n - [ ] <!-- recreate-branch=renovate/watchexec-8.x -->[fix(deps): update rust crate watchexec to v8](../pull/820)\n - [ ] <!-- recreate-branch=renovate/watchexec-events-6.x -->[fix(deps): update rust crate watchexec-events to v6](../pull/821)\n - [ ] <!-- recreate-branch=renovate/watchexec-signals-5.x -->[fix(deps): update rust crate watchexec-signals to v5](../pull/822)\n - [ ] <!-- recreate-branch=renovate/watchexec-supervisor-5.x -->[fix(deps): update rust crate watchexec-supervisor to v5](../pull/823)\n\n## Detected dependencies\n\n<details><summary>cargo</summary>\n<blockquote>\n\n<details><summary>crates/tuono_internal/Cargo.toml</summary>\n\n - `serde 1.0`\n - `serde_json 1.0.137`\n - `fs_extra 1.3.0`\n - `tempfile 3.14.0`\n - `assert_cmd 2.0.16`\n - `serial_test 3.0.0`\n\n</details>\n\n<details><summary>crates/tuono_lib_macros/Cargo.toml</summary>\n\n - `syn 2.0.0`\n - `quote 1.0`\n\n</details>\n\n<details><summary>crates/tuono_lib/Cargo.toml</summary>\n\n - `ssr_rs 0.8.3`\n - `axum 0.8.1`\n - `axum-extra 0.10.0`\n - `tokio 1.37.0`\n - `serde 1.0.202`\n - `erased-serde 0.4.5`\n - `serde_json 1.0`\n - `serde_urlencoded 0.7.1`\n - `reqwest 0.12.4`\n - `once_cell 1.19.0`\n - `regex 1.10.5`\n - `either 1.13.0`\n - `tower-http 0.6.0`\n - `colored 3.0.0`\n - `tokio-tungstenite 0.27.0`\n - `futures-util 0.3`\n - `tungstenite 0.27.0`\n - `http 1.1.0`\n - `pin-project 1.1.7`\n - `tower 0.5.1`\n - `fs_extra 1.3.0`\n - `tempfile 3.14.0`\n - `serial_test 3.0.0`\n\n</details>\n\n<details><summary>crates/tuono/Cargo.toml</summary>\n\n - `clap 4.5.4`\n - `syn 2.0.100`\n - `tracing 0.1.41`\n - `tracing-subscriber 0.3.19`\n - `miette 7.2.0`\n - `colored 3.0.0`\n - `once_cell 1.19.0`\n - `watchexec 5.0.0`\n - `watchexec-signals 4.0.0`\n - `watchexec-events 4.0.0`\n - `watchexec-supervisor 3.0.0`\n - `tokio 1`\n - `serde 1.0.202`\n - `glob 0.3.1`\n - `regex 1.10.4`\n - `reqwest 0.12.4`\n - `serde_json 1.0`\n - `fs_extra 1.3.0`\n - `http 1.1.0`\n - `spinners 4.1.1`\n - `console 0.16.0`\n - `convert_case 0.8.0`\n - `wiremock 0.6.2`\n - `tempfile 3.14.0`\n - `assert_cmd 2.0.16`\n - `serial_test 3.0.0`\n\n</details>\n\n<details><summary>e2e/fixtures/base/Cargo.toml</summary>\n\n - `serde 1.0.202`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>docker-compose</summary>\n<blockquote>\n\n<details><summary>docker/compose.yml</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>dockerfile</summary>\n<blockquote>\n\n<details><summary>docker/Dockerfile</summary>\n\n - `rust 1.83-bookworm`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>github-actions</summary>\n<blockquote>\n\n<details><summary>.github/actions/install-node-dependencies/action.yml</summary>\n\n - `pnpm/action-setup v4`\n - `actions/setup-node v4`\n - `actions/setup-node v4`\n\n</details>\n\n<details><summary>.github/workflows/docker-ci.yml</summary>\n\n - `actions/checkout v4`\n\n</details>\n\n<details><summary>.github/workflows/e2e-ci.yml</summary>\n\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n\n</details>\n\n<details><summary>.github/workflows/examples-ci.yml</summary>\n\n - `actions/checkout v4`\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n\n</details>\n\n<details><summary>.github/workflows/pr-labeler.yml</summary>\n\n - `actions/checkout v4`\n - `actions/labeler v5`\n\n</details>\n\n<details><summary>.github/workflows/pr-title-checker.yml</summary>\n\n\n</details>\n\n<details><summary>.github/workflows/release.yml</summary>\n\n - `actions/checkout v4`\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n - `katyo/publish-crates v2`\n - `actions/checkout v4`\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n - `katyo/publish-crates v2`\n\n</details>\n\n<details><summary>.github/workflows/repo-root-ci.yml</summary>\n\n - `actions/checkout v4`\n\n</details>\n\n<details><summary>.github/workflows/rust-ci.yml</summary>\n\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n - `actions/checkout v4`\n - `actions-rust-lang/setup-rust-toolchain v1`\n\n</details>\n\n<details><summary>.github/workflows/spell-checking.yml</summary>\n\n - `actions/checkout v4`\n - `reviewdog/action-languagetool v1`\n\n</details>\n\n<details><summary>.github/workflows/typescript-ci.yml</summary>\n\n - `actions/checkout v4`\n - `actions/checkout v4`\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>npm</summary>\n<blockquote>\n\n<details><summary>devtools/vite-config/package.json</summary>\n\n - `oxc-transform 0.77.3`\n - `rollup-plugin-preserve-directives 0.4.0`\n - `unplugin-isolated-decl 0.13.6`\n - `vite 6.1.3`\n - `vite-plugin-externalize-deps 0.9.0`\n\n</details>\n\n<details><summary>e2e/fixtures/base/package.json</summary>\n\n - `react ^19.0.0`\n - `react-dom ^19.0.0`\n - `@types/react ^19.0.2`\n - `@types/react-dom ^19.0.2`\n - `typescript ^5.6.3`\n\n</details>\n\n<details><summary>package.json</summary>\n\n - `@eslint/js 9.24.0`\n - `@playwright/test 1.54.1`\n - `@types/node 22.16.5`\n - `@vitest/eslint-plugin 1.2.1`\n - `eslint 9.24.0`\n - `eslint-import-resolver-typescript 4.3.2`\n - `eslint-plugin-import 2.31.0`\n - `eslint-plugin-react 7.37.5`\n - `eslint-plugin-react-hooks 5.2.0`\n - `prettier 3.5.3`\n - `turbo 2.5.5`\n - `typescript 5.8.3`\n - `typescript-eslint 8.29.1`\n - `pnpm 10.13.1+sha512.37ebf1a5c7a30d5fabe0c5df44ee8da4c965ca0c5af3dbab28c3a1681b70a256218d05c81c9c0dcf767ef6b8551eb5b960042b9ed4300c59242336377e01cfad`\n\n</details>\n\n<details><summary>packages/tuono-react-vite-plugin/package.json</summary>\n\n - `@babel/core ^7.24.4`\n - `@babel/types ^7.24.0`\n - `prettier ^3.2.4`\n - `vite ^6.1.1`\n - `@types/babel__core 7.20.5`\n - `vitest 3.2.4`\n\n</details>\n\n<details><summary>packages/tuono-router/package.json</summary>\n\n - `react-intersection-observer ^9.13.0`\n - `@testing-library/react 16.3.0`\n - `@types/react 19.1.8`\n - `@vitejs/plugin-react-swc 3.11.0`\n - `happy-dom 18.0.1`\n - `react 19.1.0`\n - `vite 6.1.3`\n - `vitest 3.2.4`\n - `react >=19.0.0`\n\n</details>\n\n<details><summary>packages/tuono/package.json</summary>\n\n - `@babel/core ^7.24.4`\n - `@babel/plugin-syntax-jsx ^7.24.1`\n - `@babel/plugin-syntax-typescript ^7.24.1`\n - `@rollup/plugin-inject ^5.0.5`\n - `@vitejs/plugin-react-swc ^3.8.0`\n - `fast-text-encoding ^1.0.6`\n - `url-search-params-polyfill ^8.2.5`\n - `vite ^6.1.1`\n - `web-streams-polyfill ^4.0.0`\n - `@types/babel__core 7.20.5`\n - `@types/babel__traverse 7.20.7`\n - `@types/node 22.16.5`\n - `@types/react 19.1.8`\n - `@types/react-dom 19.1.6`\n - `react 19.1.0`\n - `react-dom 19.1.0`\n - `vitest 3.2.4`\n - `react >=19.0.0`\n - `react-dom >=19.0.0`\n\n</details>\n\n<details><summary>pnpm-workspace.yaml</summary>\n\n\n</details>\n\n</blockquote>\n</details>\n\n<details><summary>nvm</summary>\n<blockquote>\n\n<details><summary>.nvmrc</summary>\n\n - `node 22.17.1`\n\n</details>\n\n</blockquote>\n</details>\n\n---\n\n- [ ] <!-- manual job -->Check this box to trigger a request for Renovate to run again on this repository\n\n",
      "updatedAt" : 1753362295.000000000,
      "user" : "renovate[bot]",
      "userHtmlUrl" : "https://github.com/apps/renovate",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/in/2740?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "??? Modern fullstack web framework based on Rust and React",
        "homepage" : "https://tuono.dev",
        "name" : "tuono",
        "fullName" : "tuono-labs/tuono",
        "htmlUrl" : "https://github.com/tuono-labs/tuono",
        "gitUrl" : "git://github.com/tuono-labs/tuono.git",
        "sshUrl" : "git@github.com:tuono-labs/tuono.git",
        "cloneUrl" : "https://github.com/tuono-labs/tuono.git",
        "owner" : {
          "login" : "tuono-labs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 49,
        "stargazersCount" : 890,
        "watchersCount" : 890,
        "size" : 3054,
        "openIssuesCount" : 33,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-24T13:04:57Z",
        "languages" : {
          "TypeScript" : 132475,
          "Dockerfile" : 1436,
          "Rust" : 199814
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to update the dependencies in the tuono-labs/tuono repository, including Renovate updates and detected dependencies.",
      "validationOrRequirement" : "The issue does not specify any specific validations or requirements, but it does provide information about the detected dependencies and the pending updates.",
      "attemptedFixes" : "The issue includes a list of attempted fixes, which are updates that have been created but not yet applied. These updates are awaiting their schedule or have been blocked by an existing closed PR.",
      "otherNotes" : "This issue is related to updating dependencies in the tuono-labs/tuono repository. It includes a list of pending updates, open updates, and blocked updates. The issue also provides information about the detected dependencies, GitHub Actions, npm packages, and other relevant context.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407884
  }, {
    "issueDTO" : {
      "id" : 3243111997,
      "title" : "Correction r??gle 3.3 (1)",
      "url" : "https://github.com/SocialGouv/code-du-travail-numerique/issues/6692",
      "repositoryName" : "SocialGouv/code-du-travail-numerique",
      "description" : "- [ ] 8.2. Contrastes des ??l??ments graphiques (https://racomach.fr/cdtn/rapport.html#bookmark25)\n\n## Probl??me\n\n - 3.3 - majeur : pr??sence d?????l??ments graphiques ayant un contraste insuffisant avec leur arri??re-plan\nSur la page P08 - Page information :\n\nSur la page P08 - Page information :\n- Lors du survol des actions de la lightbox, les actions ne sont plus suffisamment contrast??es\n\n## Solution\n\n~~- Augmenter le contraste de ces ??l??ments jusqu????? au moins 3:1 par rapport aux\ncouleurs adjacentes~~\n\nPour la lightbox : \n- on retire la lightbox \n- et on ajoute le lien sur la photo \"texte ?? d??finir\" @a11y-Marie une id??e ? \n\n\nDocuments de r??f??rences :\n- Grille RGAA : https://docs.google.com/spreadsheets/d/1U15Gqbw617V2CSSrOjhlH2Twqwef3Chh/edit?usp=sharing&ouid=115350906005572784675&rtpof=true&sd=true\n- Rapport RGAA : https://docs.google.com/document/d/1i3tdpziz2Hi7r0T6C-Jh2yl98f7J84Imm2EUDGPbYZA/edit?usp=sharing",
      "updatedAt" : 1753362259.000000000,
      "user" : "m-maillot",
      "userHtmlUrl" : "https://github.com/m-maillot",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/992514?v=4",
      "labels" : [ "RGAA", "lightbox", "Prio moyenne", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Code du Travail Num??rique",
        "homepage" : "https://code.travail.gouv.fr",
        "name" : "code-du-travail-numerique",
        "fullName" : "SocialGouv/code-du-travail-numerique",
        "htmlUrl" : "https://github.com/SocialGouv/code-du-travail-numerique",
        "gitUrl" : "git://github.com/SocialGouv/code-du-travail-numerique.git",
        "sshUrl" : "git@github.com:SocialGouv/code-du-travail-numerique.git",
        "cloneUrl" : "https://github.com/SocialGouv/code-du-travail-numerique.git",
        "owner" : {
          "login" : "SocialGouv",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 23,
        "stargazersCount" : 114,
        "watchersCount" : 114,
        "size" : 206658,
        "openIssuesCount" : 205,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-24T12:43:32Z",
        "languages" : {
          "TypeScript" : 6698340,
          "Dockerfile" : 4573,
          "CSS" : 6060,
          "JavaScript" : 187439,
          "HTML" : 183
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Correct rule 3.3 regarding insufficient contrast between graphic elements and their background",
      "validationOrRequirement" : "Increase the contrast of graphic elements to at least 3:1, remove the lightbox and add a link on the photo 'text to be defined'",
      "attemptedFixes" : "Augmenter le contraste de ces ??l??ments jusqu????? au moins 3:1 par rapport aux couleurs adjacentes (removed) and remove the lightbox and add a link on the photo 'text to be defined'",
      "otherNotes" : "The issue is about correcting rule 3.3, specifically about insufficient contrast between graphic elements and their background. The problem is observed on the P08 - Page information page, where actions in the lightbox are not sufficiently contrasted. The suggested solution is to increase the contrast of these elements to at least 3:1, but it seems to have been removed. Instead, it's proposed to remove the lightbox and add a link on the photo 'text to be defined' @a11y-Marie has an idea.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407891
  }, {
    "issueDTO" : {
      "id" : 2999884937,
      "title" : "Add a mapping in SemConv of GitHub concepts to SemConv",
      "url" : "https://github.com/open-telemetry/semantic-conventions/issues/2124",
      "repositoryName" : "open-telemetry/semantic-conventions",
      "description" : "### Area(s)\n\n_No response_\n\n### What's missing?\n\nIt's hard for a new user of the GitHub receiver to understand what GitHub concepts map to CICD semantic conventions.\n\n### Describe the solution you'd like\n\nSimilar to the way [database semconv](https://opentelemetry.io/docs/specs/semconv/database/) works, we should add a `github.md` file to show the mapping of GitHub concepts to Semantic Conventions. ",
      "updatedAt" : 1753362241.000000000,
      "user" : "adrielp",
      "userHtmlUrl" : "https://github.com/adrielp",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/25961386?v=4",
      "labels" : [ "cicd:phase-2", "help wanted", "area:cicd", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Defines standards for generating consistent, accessible telemetry across a variety of domains",
        "homepage" : "",
        "name" : "semantic-conventions",
        "fullName" : "open-telemetry/semantic-conventions",
        "htmlUrl" : "https://github.com/open-telemetry/semantic-conventions",
        "gitUrl" : "git://github.com/open-telemetry/semantic-conventions.git",
        "sshUrl" : "git@github.com:open-telemetry/semantic-conventions.git",
        "cloneUrl" : "https://github.com/open-telemetry/semantic-conventions.git",
        "owner" : {
          "login" : "open-telemetry",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 252,
        "stargazersCount" : 404,
        "watchersCount" : 404,
        "size" : 7887,
        "openIssuesCount" : 695,
        "subscribersCount" : 43,
        "pushedAt" : "2025-07-24T04:08:27Z",
        "languages" : {
          "Dockerfile" : 683,
          "Jinja" : 24790,
          "Shell" : 7579,
          "Open Policy Agent" : 92695,
          "Makefile" : 12740,
          "Go" : 1047,
          "Roff" : 12686,
          "Ruby" : 12
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add a mapping in SemConv of GitHub concepts to SemConv to make it easier for new users of the GitHub receiver to understand the mapping.",
      "validationOrRequirement" : "The GitHub receiver should be able to understand the mapping of GitHub concepts to CICD semantic conventions, and a `github.md` file should be created.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about adding a mapping of GitHub concepts to Semantic Conventions, with a suggested solution of creating a github.md file similar to database semconv.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407895
  }, {
    "issueDTO" : {
      "id" : 3259776049,
      "title" : "[fix]: ???????????? ?????? ?????? ?????? ????????? ?????? ????????? ??????",
      "url" : "https://github.com/githru/githru-vscode-ext/issues/807",
      "repositoryName" : "githru/githru-vscode-ext",
      "description" : "### ?????? ??????\n\n_No response_\n\n### ?????? ??????\n\nTemporalFilter?????? `commitMap`??? `clocMap` ???????????? ???????????? ???????????? ????????????. ??????????????? CLOC ????????? ?????? ??????, ?????? ????????? CLOC ???????????? ???????????????.\n\n????????? ?????? ???????????? ?????????.\n\n```typescript\n// ?????? ???\ncommitMap.set(formattedDate, clocMapItem ? clocMapItem + 1 : 1);\nclocMap.set(formattedDate, commitMapItem ? commitMapItem + clocValue : clocValue);\n\n// ?????? ???\ncommitMap.set(formattedDate, commitMapItem ? commitMapItem + 1 : 1);\nclocMap.set(formattedDate, clocMapItem ? clocMapItem + clocValue : clocValue);\n```\n\n> [!NOTE]\n> ?????? ?????? ??????\n> https://github.com/githru/githru-vscode-ext/blob/e37f94d5b7aa0602899ad9a45a8b07c5ce533b1e/packages/view/src/components/TemporalFilter/TemporalFilter.tsx#L57 \n> https://github.com/githru/githru-vscode-ext/blob/e37f94d5b7aa0602899ad9a45a8b07c5ce533b1e/packages/view/src/components/TemporalFilter/TemporalFilter.tsx#L58\n\n### ??????\n\n_No response_",
      "updatedAt" : 1753362069.000000000,
      "user" : "Jxxunnn",
      "userHtmlUrl" : "https://github.com/Jxxunnn",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/86228307?v=4",
      "labels" : [ "fix", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Lightweight but robust Githru for VSCode Extension",
        "homepage" : null,
        "name" : "githru-vscode-ext",
        "fullName" : "githru/githru-vscode-ext",
        "htmlUrl" : "https://github.com/githru/githru-vscode-ext",
        "gitUrl" : "git://github.com/githru/githru-vscode-ext.git",
        "sshUrl" : "git@github.com:githru/githru-vscode-ext.git",
        "cloneUrl" : "https://github.com/githru/githru-vscode-ext.git",
        "owner" : {
          "login" : "githru",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 91,
        "stargazersCount" : 55,
        "watchersCount" : 55,
        "size" : 89609,
        "openIssuesCount" : 82,
        "subscribersCount" : 4,
        "pushedAt" : "2025-07-25T00:38:38Z",
        "languages" : {
          "TypeScript" : 229193,
          "SCSS" : 16232,
          "JavaScript" : 5844,
          "HTML" : 344
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix the issue where the 'commitMap' and 'clocMap' variables are swapped in the TemporalFilter, causing incorrect data display in the charts",
      "validationOrRequirement" : "Fix temporal filter to correctly display commit count and code change quantity chart data",
      "attemptedFixes" : "No attempted fixes or blockers mentioned",
      "otherNotes" : "Related code location: https://github.com/githru/githru-vscode-ext/blob/e37f94d5b7aa0602899ad9a45a8b07c5ce533b1e/packages/view/src/components/TemporalFilter/TemporalFilter.tsx#L57, https://github.com/githru/githru-vscode-ext/blob/e37f94d5b7aa0602899ad9a45a8b07c5ce533b1e/packages/view/src/components/TemporalFilter/TemporalFilter.tsx#L58",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407901
  }, {
    "issueDTO" : {
      "id" : 2763078751,
      "title" : "Implement pg_auth_members",
      "url" : "https://github.com/crate/crate/issues/17179",
      "repositoryName" : "crate/crate",
      "description" : "### Problem Statement\n\nA number of tools (see Labels) run queries looking for this system view.\n\n### Possible Solutions\n\nImplement as per the spec at https://www.postgresql.org/docs/14/catalog-pg-auth-members.html\n\n### Considered Alternatives\n\n```sql\nCREATE FUNCTION first_quarter_of_md5_to_bigint(TEXT) \nRETURNS BIGINT\nLANGUAGE JAVASCRIPT\nAS \n$$\n\tfunction first_quarter_of_md5_to_bigint(md5Hash) {\n\t\tif (md5Hash.length !== 32 || !/^[a-f0-9]{32}$/i.test(md5Hash)) {\n\t\t\tthrow new Error('Invalid MD5 hash');\n\t\t}\t\t\t\t\n\t\tconst hashPart = md5Hash.substring(0, 8);\t\t\t\t\n\t\tconst intHash = parseInt(hashPart, 16);\t\t\n\t\treturn intHash;\n\t}\n$$;\n\nCREATE VIEW pg_auth_members AS\n(\n\tSELECT first_quarter_of_md5_to_bigint(\n\t\t\tmd5(CONCAT (a.granted_role ['role'],a.rolname))) AS oid\n\t\t,(\n\t\t\tSELECT lookup.oid\n\t\t\tFROM pg_roles lookup\n\t\t\tWHERE lookup.rolname = a.granted_role ['role']\n\t\t\t) AS roleid /* ID of a role that has a member */\n\t\t,a.oid AS member /* ID of a role that is a member of roleid */\n\t\t,(\n\t\t\tSELECT lookup2.oid\n\t\t\tFROM pg_roles lookup2\n\t\t\tWHERE lookup2.rolname = a.granted_role ['grantor']\n\t\t\t) AS grantor /* ID of the role that granted this membership */\n\t\t,rolsuper AS admin_option /* True if member can grant membership in roleid to others */\n\t\t,true AS inherit_option /* True if the member automatically inherits the privileges of the granted role */\n\t\t,false AS set_option /* True if the member can SET ROLE to the granted role */\n\tFROM (\n\t\tSELECT oid\n\t\t\t,rolname\n\t\t\t,rolsuper\n\t\t\t,unnest(granted_roles) AS granted_role\n\t\tFROM pg_roles\n\t\tJOIN sys.users ON pg_roles.rolname = users.name\n\t\t) a\n);\n```",
      "updatedAt" : 1753361638.000000000,
      "user" : "hlcianfagna",
      "userHtmlUrl" : "https://github.com/hlcianfagna",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/110453267?v=4",
      "labels" : [ "tool: DataGrip", "tool: Theobald", "contributions welcome", "feature: pgsql", "complexity: 1-3", "good first issue", "tool: DBeaver", "tool: pg-ldap-sync" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "CrateDB is a distributed and scalable SQL database for storing and analyzing massive amounts of data in near real-time, even with complex queries. It is PostgreSQL-compatible, and based on Lucene.",
        "homepage" : "https://cratedb.com/database",
        "name" : "crate",
        "fullName" : "crate/crate",
        "htmlUrl" : "https://github.com/crate/crate",
        "gitUrl" : "git://github.com/crate/crate.git",
        "sshUrl" : "git@github.com:crate/crate.git",
        "cloneUrl" : "https://github.com/crate/crate.git",
        "owner" : {
          "login" : "crate",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 581,
        "stargazersCount" : 4271,
        "watchersCount" : 4271,
        "size" : 165735,
        "openIssuesCount" : 320,
        "subscribersCount" : 173,
        "pushedAt" : "2025-07-24T13:51:24Z",
        "languages" : {
          "Java" : 33351488,
          "Shell" : 8641,
          "ANTLR" : 50682,
          "Python" : 72902
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement the pg_auth_members system view as per the PostgreSQL documentation.",
      "validationOrRequirement" : "The implementation should be done as per the PostgreSQL documentation and the system view should be created as per the specification.",
      "attemptedFixes" : "The considered alternatives section includes a SQL function and view implementation.",
      "otherNotes" : "The issue description includes a problem statement, possible solutions, and considered alternatives. The possible solution involves implementing the pg_auth_members system view as per the PostgreSQL documentation.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407904
  }, {
    "issueDTO" : {
      "id" : 1902641876,
      "title" : "docs: update publish plugin pages with instructions for alternative package managers",
      "url" : "https://github.com/grafana/plugin-tools/issues/410",
      "repositoryName" : "grafana/plugin-tools",
      "description" : "Should list npm, pnpm and yarn \r\n\r\n- [ ] package a plugin only references yarn currently\r\n- [ ] sign a plugin only references npx\r\n\r\nCan use `getting-started` as an example for how this can be achieved",
      "updatedAt" : 1753361625.000000000,
      "user" : "sympatheticmoose",
      "userHtmlUrl" : "https://github.com/sympatheticmoose",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19860021?v=4",
      "labels" : [ "no stalebot", "type/docs", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Note: Maybe leave sign a plugin to npx / pnpm only as there is no alternative in yarn 1", "package a plugin - we can probably do with linking to the general build plugin step as it's actually more about creating the zip file properly of a built plugin. Something like https://grafana.com/developers/plugin-tools/create-a-plugin/develop-a-plugin/work-with-frontend#synccommand-cmdrun-build-", "hi @sympatheticmoose is this open to external contributors? if not, are there issues open to external contributors? was learning and using grafana at my uni, thought why not contribute, but sadly everything is too cluttered for me to find a issue:)" ],
      "repository" : {
        "description" : "Create Grafana plugins with ease.",
        "homepage" : "https://grafana.com/developers/plugin-tools/",
        "name" : "plugin-tools",
        "fullName" : "grafana/plugin-tools",
        "htmlUrl" : "https://github.com/grafana/plugin-tools",
        "gitUrl" : "git://github.com/grafana/plugin-tools.git",
        "sshUrl" : "git@github.com:grafana/plugin-tools.git",
        "cloneUrl" : "https://github.com/grafana/plugin-tools.git",
        "owner" : {
          "login" : "grafana",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 31,
        "stargazersCount" : 76,
        "watchersCount" : 76,
        "size" : 154178,
        "openIssuesCount" : 54,
        "subscribersCount" : 144,
        "pushedAt" : "2025-07-24T17:00:51Z",
        "languages" : {
          "TypeScript" : 506780,
          "MDX" : 32604,
          "Dockerfile" : 2521,
          "CSS" : 16949,
          "Shell" : 1856,
          "JavaScript" : 12677,
          "Go" : 13296,
          "HTML" : 53
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "update publish plugin pages with instructions for alternative package managers",
      "validationOrRequirement" : "list npm, pnpm and yarn, use getting-started as an example for how this can be achieved",
      "attemptedFixes" : "package a plugin only references yarn currently, sign a plugin only references npx",
      "otherNotes" : "Note: Maybe leave sign a plugin to npx / pnpm only as there is no alternative in yarn 1, package a plugin - we can probably do with linking to the general build plugin step as it's actually more about creating the zip file properly of a built plugin. Something like https://grafana.com/developers/plugin-tools/create-a-plugin/develop-a-plugin/work-with-frontend#synccommand-cmdrun-build-",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407909
  }, {
    "issueDTO" : {
      "id" : 3233491885,
      "title" : "Extend GET all accounts endpoint by search query filter",
      "url" : "https://github.com/ghostfolio/ghostfolio/issues/5171",
      "repositoryName" : "ghostfolio/ghostfolio",
      "description" : "The goal of this issue is to support `@Query('query') filterBySearchQuery?: string` in the `GET account` [endpoint](https://github.com/ghostfolio/ghostfolio/blob/main/apps/api/src/app/account/account.controller.ts#L89). Respect the filter in the [getAccountsWithAggregations()](https://github.com/ghostfolio/ghostfolio/blob/main/apps/api/src/app/portfolio/portfolio.service.ts#L212) function by using [Fuse.js](https://www.fusejs.io) similar to [getHoldings()](https://github.com/ghostfolio/ghostfolio/pull/5062/files#diff-b76b6c44c1bfd51ef638e858cc1226d3f730918ed2ffd4bf6890f3f97313cbdeR296) for the following `keys`: `name` and `platform.name`.",
      "updatedAt" : 1753361598.000000000,
      "user" : "dtslvr",
      "userHtmlUrl" : "https://github.com/dtslvr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/4159106?v=4",
      "labels" : [ "help wanted", "enhancement", "good first issue", "NestJS" ],
      "state" : "OPEN",
      "comments" : [ "hey can i work on this", "Hi @aqsaaqeel,\n\nAny progress on the issue? Let me know if you need support.", "> Hi [@aqsaaqeel](https://github.com/aqsaaqeel),\n> \n> Any progress on the issue? Let me know if you need support.\n\nI've been having issues setting up the project. It's okay if someone else works on it now. I will need some time", "@dtslvr, I'll take a look!" ],
      "repository" : {
        "description" : "Open Source Wealth Management Software. Angular + NestJS + Prisma + Nx + TypeScript \uD83E\uDD0D",
        "homepage" : "https://Ghostfol.io",
        "name" : "ghostfolio",
        "fullName" : "ghostfolio/ghostfolio",
        "htmlUrl" : "https://github.com/ghostfolio/ghostfolio",
        "gitUrl" : "git://github.com/ghostfolio/ghostfolio.git",
        "sshUrl" : "git@github.com:ghostfolio/ghostfolio.git",
        "cloneUrl" : "https://github.com/ghostfolio/ghostfolio.git",
        "owner" : {
          "login" : "ghostfolio",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 690,
        "stargazersCount" : 6176,
        "watchersCount" : 6176,
        "size" : 57878,
        "openIssuesCount" : 150,
        "subscribersCount" : 25,
        "pushedAt" : "2025-07-24T19:10:30Z",
        "languages" : {
          "TypeScript" : 1943098,
          "Dockerfile" : 2101,
          "CSS" : 6426,
          "Shell" : 172,
          "SCSS" : 54859,
          "PLpgSQL" : 1591,
          "JavaScript" : 17598,
          "HTML" : 680109
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Extend the `GET all accounts` endpoint by adding a search query filter.",
      "validationOrRequirement" : "Implement `@Query('query') filterBySearchQuery?: string` in the `GET account` endpoint, respect the filter in the `getAccountsWithAggregations()` function using Fuse.js for the keys `name` and `platform.name`.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "Commenter needs support to set up the project, willing to take a look later. Commenter was also asked if they need support with the issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407913
  }, {
    "issueDTO" : {
      "id" : 3038793992,
      "title" : "\uD83D\uDC05 Epic: GPU Support for the Ersilia Model Hub",
      "url" : "https://github.com/ersilia-os/ersilia/issues/1640",
      "repositoryName" : "ersilia-os/ersilia",
      "description" : "# GPU Support for the Ersilia Model Hub\n\n## Background\n\nCurrently, the Ersilia Model Hub does not support GPU acceleration, which limits the performance of some models ??? and makes others completely unusable. Models are currently packaged as CPU-only Docker images. The goal of this project is to evaluate and implement GPU support using Docker.\n\n## Goals\n\n- Demonstrate that a model can run inside a Docker container with GPU access.\n- Build the foundation to support GPU in the Ersilia infrastructure (template, CLI, metadata, CI/CD).\n- Benchmark performance between CPU and GPU runs.\n\n## Step 1: Manual GPU Docker Test (Top-Down)\n\nWe will first verify that models can run in a GPU-enabled Docker container, without relying on Ersilia's internal infrastructure (e.g., CLI or model template).\n\n- [ ] Select two test models:\n  - [ ] One **GPU-only** model (TBD).\n  - [ ] One **GPU/CPU-compatible** model (suggested: FAISS-based).\n- [ ] Set up the new GPU workstation.\n- [ ] Choose and test an appropriate CUDA base image (e.g., `nvidia/cuda:...`).\n- [ ] Ensure image size is acceptable (<~4GB ideally).\n- [ ] Run tests on:\n  - [ ] At least two local GPU workstations.\n  - [ ] One cloud instance (e.g., AWS GPU instance).\n\n## Step 2: Integrate GPU Support into Ersilia Infrastructure\n\n### \uD83E\uDDF1 At the [Ersilia Template](https://github.com/ersilia-os/eos-template) level\n\n- [ ] How should `install.yml` indicate GPU requirements?\n- [ ] If model code differs between CPU/GPU, how should this be reflected in the `framework/`?\n\n### ?????? At the [Ersilia CLI](https://github.com/ersilia-os/ersilia) level\n\n- [ ] Add support for `--gpu` or `--cpu` flags in the `ersilia serve` command.\n- [ ] Decide whether GPU/CPU mode should be:\n  - Explicit (user-defined via flag), or\n  - Automatic (detect from hardware?)\n- [ ] Assess: Can one image support both CPU and GPU, or do we need separate ones?\n\n### \uD83D\uDCE6 At the [Ersilia Metadata](https://github.com/ersilia-os/eos5axz/blob/main/metadata.json) level\n\n- [ ] Add `runtime: GPU` / `CPU` or similar field.\n- [ ] Consider `requirements` or `compatibility` sections if needed.\n\n### \uD83D\uDC33 On [DockerHub](https://hub.docker.com/u/ersiliaos)\n\n- [ ] Should GPU-compatible images use a separate tag (e.g., `model:gpu`) or separate repo?\n- [ ] Define tagging convention early.\n\n## Step 3: GitHub Actions & CI Integration\n\nIn the [Ersilia Model Workflows](https://github.com/ersilia-os/ersilia-model-workflows):\n\n- [ ] Detect whether a model supports GPU.\n- [ ] Build and push a GPU-compatible Docker image (using `nvidia-docker`).\n- [ ] Ensure existing workflows are not broken.\n\nIn the [Ersilia CLI CI/CD](https://github.com/ersilia-os/ersilia):\n\n- [ ] Add at least one unit test to check GPU execution (on GitHub-hosted runners or self-hosted runner with GPU).\n\n## Step 4: Benchmarking & Validation\n\n- [ ] Run performance benchmarks:\n  - CPU vs GPU execution time.\n  - Memory consumption and constraints.\n- [ ] Record any limitations or environment-specific requirements.",
      "updatedAt" : 1753361477.000000000,
      "user" : "miquelduranfrigola",
      "userHtmlUrl" : "https://github.com/miquelduranfrigola",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/19725330?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Note that I have created a [folder in Google Drive](https://drive.google.com/drive/folders/1sNwmeeNtbQUup0Qj66o1ykrwlkPe9Bl_?usp=drive_link) for project-related documentation.", "Two minor comments @miquelduranfrigola :\n- [x] Support multiple GPUs. There might be more than one GPU in a device and either we have to select one device or sharding tasks accross all available GPUs\n- [x] not only nvidia binary but also other accelerators.", "- [x] Set up the new GPU workstation.\n\n- [ ] Select two test models:\n\n   - [ ] One GPU-only model \n\n   - [x] One GPU/CPU-compatible model (suggested: FAISS-based).\n\n- [x] Choose and test an appropriate CUDA base image (e.g., nvidia/cuda:...).\n\n\n## CUDA Base Image: \n\nNvidia has 3 \"flavours\" images `base`, `runtime` and `devel`. `runtime` seems to be the most appropriate for our use case, necessary runtime and Mathematics Libraries, NCCL and optionally cudNN. For example : \n\n```nvidia/cuda:12.9.0-runtime-ubuntu24.04```\n\nThis comes to ~ 2 GB/3 GB depending on the exact CUDA and Ubuntu Version being used. \n\nIdeally run automated tests/builds for different combinations of Ubuntu (or other distributions?) and CUDA  versions. \n\n## CPU vs GPU preliminary testing\n\nA very simple test on TabPFN using a [Sci-Kit Learn Breast Cancer Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) showed approximately 3x-4x speed ups when GPU access to the process was enabled, compared to CPU only runs (on the Norrsken GPU Workstation).\n\nMore detailed tests using a [Dataset of approximately 2 Million Compounds](https://github.com/ersilia-os/sars-cov-2-chemspace/blob/main/data/reference_library_inchikeys.csv) showed overwhelming speed-ups with GPU Accelerated similarity searches using [FAISS](https://github.com/facebookresearch/faiss), the difference between search times of GPU and CPU implementations scaled/diverged with the Index size. **It is clearly worth trying to accelerate models using GPU Acceleration.**\n\nWe built indices out of Count Fingerprints of the compounds (converted the SMILES to 2048 Vectors). Cosine Similarity was used as a metric. \n\nFAISS does not support cosine by default, so we use  an `Inner Product` index and perform L2 (Euclidean) Normalisation on the vectors before adding to them to the index (or before searching), which is the equivalent of using Cosine similarity.\n\nTests were ran with index sizes of `10,000`, `100,000`, `500,000` and `1,000,000`. Nearest 100 Neighbours. \n\n### Index size 100,000:\n| Number of Searches | CPU (s) | GPU (s) |\n|--------------------|---------|---------|\n| 100                | 1       | 0.01    |\n| 1,000              | 7.08    | 0.04    |\n| 10,000             | 67.49   | 0.11    |\n| 100,000            | >350    | 1.30    |\n| 500,000            | -       | 5.50    |\n\n### Index size 1,000,000\n\n| Number of Searches | CPU (s) | GPU (s) |\n|--------------------|---------|---------|\n| 100                | 9.42    | 0.02    |\n| 1,000              | 71      | 0.10    |\n| 10,000             | 711     | 1.03    |\n| 100,000            | -       | 10.45   |\n| 500,000            | -       | 52.50   |\n\n\n\n### \n\n<img width=\"765\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e39adae0-7c06-43ba-ba5f-3da89037da02\" />\n\n_NOTE: GPUs are typically higher latency but have higher parallel throughput and memory bandwidth than CPUs. It is best to use batch queries with the CPU or GPU as this amortises the touching of index memory across all of the queries and this is when GPU speed ups are convenient. We will most likely not see any improvements in GPU search times with single queries (if anything it might be slower because of GPU overhead)._\n\n\nThe examples of inference time comparisons and a 3D plot (inference time against index and query sizes), clearly demonstrate **GPUs provide absolutely non-trivial speed ups for the right tasks.**\n\n\n\n\n\n\n", "# Very Heavy Index (FAISS Flat)\n\nFlat (IP and L2 for example) indices are extremely large (because FAISS only supports Float32 vectors, hence each Fingerprint vector is 32 * 2048 = 65,536 Bits or 4 * 2048=8,192  Bytes), scaling up to millions of vectors means we are dealing with indices that are 10s of GBs.\n\nTried FPSim2 but there are no benefits to GPU accelerating since it does not support batch queries (could be worth looking into CUDA Programming and tuning it to support batch queries, as it supports Sparse Vectors and Tanimoto Search on GPU)\n\n## Promising alternative to Flat FAISS Index: **Approximate Nearest Neighbour (ANN) search**\n\nMost methods for ANN require index training and parameter tuning which makes building the index more complex. We also need to ensure that the training sample is diverse. \n\nPlease note the difference between training and adding to Indices. And index cannot be trained incrementally but can be incrementally added to.\n\nMemory bottlenecks are also an issue so I first train the index and then add vectors to it incrementally in batches. (Although, it is suggested, If possible at all,  add more compute at index build time. (Especially if the index does not change a lot over time))\n\nThe following ANN methods are explored and suggested (compared to ~16 GB with a flat index of around 1.99 million Vectors)\n\n### **_IVFPQ (Inverted File Index with Product Quantisation):_** \n\n#### **_I am yet to do Accuracy tests on IVFPQ but with computational performance (inference time), models seem to enjoy GPU Acceleration speed ups similar to those mentioned above for FAISS Flat indices._**\n\nThis creates very light indices: `~93 MB for an index of around 1.99 Million Vectors`, but there might be a non-trivial loss of accuracy. \n\nNote: For some reason after the index is trained and incrementally built, FAISS takes a lot of time to write it to disk which makes it look like the process is frozen but isn't actually frozen - it goes into an \"uninterruptible sleep\" because of Disk IO, as indicated by the \"D\" state in htop. \n\n### **_HNSWSQ (Hierarchical Navigable Small World Index with Scalar Quantisation)_**\n\nTraining is reasonably fast (with GPU) but adding vectors is computationally intensive and needs to batched appropriately.\n\n#### **_I am yet to do Accuracy tests on HNSWSQ but with computational performance , HNSW seem to enjoy GPU Acceleration only with at Training time as indices are pretty compact and are VERY FAST with CPU and FAISS does not have a GPU search for this yet._**\n\nWhen choosing the strength of quantisation, there is a trade off between memory and accuracy:\n\nIndex of **1.99 million Vectors**:\n\n```\n4.63 GB (~2KB Per Vector + overhead) with a  8-Bit Quantiser while maintaining around 95-98% Accuracy^\n\n\n\n2.59 GB (~1.15KB Per Vector + overhead) with a 4-Bit Quantiser  while maintaining around 90-95% Accuracy^\n```\n\n\nAdding vectors to this kind of index is slow.\n\n_^accuracy according to official documentation and third party tests_\n", "# Metric Learning - Embedding Model\n\nAnother alternative to using vanilla flat indices with 2048 dimensional fingerprints we explore is the use of a metric learning model to create embeddings that are lower dimensions. We use these embeddings to create flat FAISS indices that are much lighter than the standard fingerprint indices (512, 256, 128, 100 dimensional embeddings vs 2048 dimensional fingerprints). We uses torch's GPU version and enjoy non-trivial speed-ups at training time, while creating embeddings and inference time (FAISS Search using a GPU index).\n\nNote: The searches are performed on a flat index, hence are exact searches, but the using of the embedding model means there is an approximation.", "We are aiming to create compound similarity search models with 4 compound libraries:\n\n- ChemDiv (100k)\n- A representative of Enamine  (~9 million)\n- DrugBank (~11k)\n- COCONUT (should be between 500k and 1 Million)\n\nWe also create a _Metric Learning Embedding Model_ out of a [reference library of 2 million compounds.](https://github.com/ersilia-os/sars-cov-2-chemspace/blob/main/data/reference_library_inchikeys.csv).\n\nFor each of the above libraries the aim is to have 3 variants of indices:\n\n- _A flat IP index with L2 Normalisation_\n    - This is going to be very large for libraries with 500k+ compounds)\n\n- _A compressed IVFPQ IP index  with L2 normalisation (FAISS compression)_\n   - This creates very light indices but as mentioned above there is a loss of search accuracy\n\n- _A flat index created with embeddings from the above mentioned model._\n   - This is lets us create indices that are lighter than vanilla flat indices and also lets us have control and confidence over the accuracy of the search (given that we are confident in the embedding model, which is arguably simpler to benchmark).\n \n", "Implemented a metric learning pipeline that creates learned embeddings from existing flat FAISS index. \n\n### Transforms 2048-dimensional fingerprints ??? _256/128/100-dimensional learned embeddings_ with cosine similarity\n\n### Triplet sampling: Uses existing 2M compound FAISS index for mining hard positives/negatives\n\nEvaluations: ROC-AUC, AP, distance distributions, t-SNE visualizations\n\nThe pipeline maintains L2 normalization throughout for FlatIP cosine similarity and includes model checkpointing + SMILES mapping for deployment.\n\nCreated with PyTorch + FAISS GPU. ", "@dhrvrc to close the internship please update this issue with a summary of where the developed resources can be found as well as the documentation associated to them. \n\nFor example: the conclusion of this project has resulted in two model incorporations (add summary of why they are related to the GPU incorporation)\n\n- https://github.com/ersilia-os/ersilia/issues/1699\n- https://github.com/ersilia-os/ersilia/issues/1697\n\nand \n...", "Hi everyone, thanks for the detailed breakdown, this is super insightful!\n\nI just had a small thought while reading through the benchmarking and index optimizations. Since you're already exploring multiple types of FAISS indices and embedding strategies (like IVFPQ, HNSWSQ, and metric learning), would it be worth considering adding a metadata field in the model hub that reflects the index type and embedding strategy used (e.g., flat, IVFPQ, embedding model version)?\n\nThis might make it easier down the line for users (and maintainers) to:\n\n* Quickly assess what kind of GPU support or performance to expect\n\n* Compare models or indices in similar domains\n\n* Reproduce or build upon existing pipelines with more transparency\n\nAlso, happy to help brainstorm or prototype how this metadata could be structured if it???s of interest. Let me know!", "Hi @Darshithaj we really appreciate your useful insight on the issue you mentioned. But currently we are not actively working this project as it requires careful thought and design to support GPU models in the Ersilia model hub level. But will let you know when we do this tho." ],
      "repository" : {
        "description" : "The Ersilia Model Hub, a repository of AI/ML models for infectious and neglected disease research.",
        "homepage" : "https://ersilia.io",
        "name" : "ersilia",
        "fullName" : "ersilia-os/ersilia",
        "htmlUrl" : "https://github.com/ersilia-os/ersilia",
        "gitUrl" : "git://github.com/ersilia-os/ersilia.git",
        "sshUrl" : "git@github.com:ersilia-os/ersilia.git",
        "cloneUrl" : "https://github.com/ersilia-os/ersilia.git",
        "owner" : {
          "login" : "ersilia-os",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 162,
        "stargazersCount" : 265,
        "watchersCount" : 265,
        "size" : 62894,
        "openIssuesCount" : 36,
        "subscribersCount" : 19,
        "pushedAt" : "2025-07-22T20:33:37Z",
        "languages" : {
          "Dockerfile" : 7980,
          "Shell" : 5118,
          "Jupyter Notebook" : 43547,
          "Python" : 1321677
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to implement GPU support for the Ersilia Model Hub, which currently does not support GPU acceleration. The goal is to evaluate and implement GPU support using Docker.",
      "validationOrRequirement" : "The issue requires several validations and requirements, including selecting two test models, setting up the new GPU workstation, choosing and testing an appropriate CUDA base image, and running automated tests/builds for different combinations of Ubuntu and CUDA versions. The issue also requires detecting whether a model supports GPU, building and pushing a GPU-compatible Docker image, and ensuring existing workflows are not broken.",
      "attemptedFixes" : "The issue mentions several attempted fixes, including setting up a new GPU workstation, choosing and testing an appropriate CUDA base image, and running automated tests/builds for different combinations of Ubuntu and CUDA versions. The issue also mentions the need to detect whether a model supports GPU, build and push a GPU-compatible Docker image, and ensure existing workflows are not broken.",
      "otherNotes" : "The issue aims to implement GPU support for the Ersilia Model Hub, which currently does not support GPU acceleration. The goal is to evaluate and implement GPU support using Docker. The project involves several steps: manual GPU Docker test, integrating GPU support into Ersilia infrastructure, benchmarking and validation. The issue also explores alternative index methods such as IVFPQ and HNSWSQ, and uses metric learning embedding models. The project requires careful thought and design to support GPU models in the Ersilia model hub level.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407923
  }, {
    "issueDTO" : {
      "id" : 3257230906,
      "title" : "Missing target origin argument of window.postMessage taint operations",
      "url" : "https://github.com/SAP/project-foxhound/issues/322",
      "repositoryName" : "SAP/project-foxhound",
      "description" : "It would be convenient to add the target origin to the arguments of window.postMessage taint operations.\n\n**Example**\n\n```js\nw.postMessage(location.href, \"http://example.com\");\n```\n\nAfter executing the above snippet, the following taint operation should be observed in the taint of the reported string:\n\n```\n{\n  \"arguments\": [\"http://example.com\"],\n  \"builtin\": true,\n  \"location\": { ... },\n  \"operation\": \"window.postMessage\",\n  \"source\": false\n}\n```\n\nHowever, the actual taint operation is the following:\n\n```\n{\n  \"arguments\": [\"null\"],\n  \"builtin\": true,\n  \"location\": { ... },\n  \"operation\": \"window.postMessage\",\n  \"source\": false\n}\n```\n",
      "updatedAt" : 1753361410.000000000,
      "user" : "eleumasc",
      "userHtmlUrl" : "https://github.com/eleumasc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29689340?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Agreed, that looks like a useful improvement!\n\nIn general, the arguments per operation we provide is not quite standardized/not always complete, but that is a ton of work to go through all of them and think of the right behavior.." ],
      "repository" : {
        "description" : "A web browser with dynamic data-flow tracking enabled in the Javascript engine and DOM, based on Mozilla Firefox (https://github.com/mozilla-firefox/firefox). It can be used to identify insecure data flows or data privacy leaks in client-side web applications.",
        "homepage" : "",
        "name" : "project-foxhound",
        "fullName" : "SAP/project-foxhound",
        "htmlUrl" : "https://github.com/SAP/project-foxhound",
        "gitUrl" : "git://github.com/SAP/project-foxhound.git",
        "sshUrl" : "git@github.com:SAP/project-foxhound.git",
        "cloneUrl" : "https://github.com/SAP/project-foxhound.git",
        "owner" : {
          "login" : "SAP",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 114,
        "watchersCount" : 114,
        "size" : 5157791,
        "openIssuesCount" : 57,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-21T13:18:44Z",
        "languages" : {
          "GDB" : 5718,
          "CMake" : 85368,
          "M4" : 519370,
          "Go" : 14155,
          "HTML" : 229539639,
          "NSIS" : 566437,
          "Groovy" : 8995,
          "Pawn" : 5519,
          "IDL" : 2619752,
          "Befunge" : 6280,
          "SCSS" : 301761,
          "Gnuplot" : 710,
          "Pascal" : 6780,
          "Assembly" : 7039249,
          "Python" : 29383122,
          "PowerShell" : 5881,
          "Yacc" : 2517,
          "Jinja" : 875,
          "Rust" : 14705845,
          "Objective-C++" : 637989,
          "SWIG" : 3312,
          "Fluent" : 970694,
          "Perl" : 541372,
          "Ragel" : 35253,
          "AIDL" : 12985,
          "RenderScript" : 3698,
          "Scilab" : 99,
          "Starlark" : 66196,
          "Batchfile" : 30560,
          "Meson" : 85483,
          "Swift" : 16097,
          "Mako" : 1006,
          "C#" : 126138,
          "C" : 113377273,
          "Makefile" : 2777879,
          "DIGITAL Command Language" : 64988,
          "Stylus" : 82,
          "TypeScript" : 8879646,
          "Shell" : 2738408,
          "R" : 1064,
          "sed" : 1562,
          "Awk" : 6178,
          "JavaScript" : 286815659,
          "Objective-C" : 388870,
          "PHP" : 35367,
          "Ruby" : 9501,
          "GLSL" : 1318425,
          "Raku" : 21544,
          "Java" : 5088231,
          "C++" : 294388241,
          "CSS" : 3204220,
          "TeX" : 382211,
          "NASL" : 133375,
          "XSLT" : 18509,
          "Kotlin" : 23472035,
          "WebIDL" : 151333,
          "Dockerfile" : 67288,
          "CoffeeScript" : 623,
          "Euphoria" : 1960,
          "Linker Script" : 97,
          "Roff" : 539948,
          "HLSL" : 26023,
          "Lex" : 11373
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add the target origin to the arguments of window.postMessage taint operations.",
      "validationOrRequirement" : "The target origin should be included in the arguments of window.postMessage taint operations.",
      "attemptedFixes" : "No attempted fixes mentioned in the issue description or comments.",
      "otherNotes" : "The arguments per operation provided are not standardized/not always complete, but it's a lot of work to go through all of them and think of the right behavior.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407926
  }, {
    "issueDTO" : {
      "id" : 2439545622,
      "title" : "Contacts on Windows",
      "url" : "https://github.com/dotnet/maui/issues/23940",
      "repositoryName" : "dotnet/maui",
      "description" : "### Description\r\n\r\nWe are currently testing a WinUI version of our app.\r\nWhen running the iOS build our users often use [Contacts ](https://learn.microsoft.com/en-us/dotnet/maui/platform-integration/communication/contacts?view=net-maui-8.0) to pick mail addresses from the device's contacts (which are synced with Azure/Exchange). For Windows this is not working as \"Picking a contact is unsupported on Windows.\"\r\n\r\n### Public API Changes\r\n\r\n(API should be the same as it is and for example invoke Outlook's contacts)\r\n\r\n### Intended Use-Case\r\n\r\nAccess contact information on Windows, so you don't have to copy and paste raw text data from other sources for example mail drafts or spreadsheets.",
      "updatedAt" : 1753361326.000000000,
      "user" : "formerlymisterhenson",
      "userHtmlUrl" : "https://github.com/formerlymisterhenson",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/99845854?v=4",
      "labels" : [ "proposal/open", "t/enhancement ??????", "good first issue", "platform/windows", "area-essentials" ],
      "state" : "OPEN",
      "comments" : [ "Currently the ContactsPicker is broken on WinAppSDK (https://github.com/microsoft/WindowsAppSDK/issues/1157). Here is also a related issue on MAUI docs repo: https://github.com/dotnet/docs-maui/issues/1191. If you need to invoke the Outlook's contacts, I recommend checking out the guides on working with [Microsoft Graph APIs](https://learn.microsoft.com/en-us/windows/apps/windows-dotnet-maui/tutorial-graph-api) with MAUI. " ],
      "repository" : {
        "description" : ".NET MAUI is the .NET Multi-platform App UI, a framework for building native device applications spanning mobile, tablet, and desktop.",
        "homepage" : "https://dot.net/maui",
        "name" : "maui",
        "fullName" : "dotnet/maui",
        "htmlUrl" : "https://github.com/dotnet/maui",
        "gitUrl" : "git://github.com/dotnet/maui.git",
        "sshUrl" : "git@github.com:dotnet/maui.git",
        "cloneUrl" : "https://github.com/dotnet/maui.git",
        "owner" : {
          "login" : "dotnet",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1863,
        "stargazersCount" : 22812,
        "watchersCount" : 22812,
        "size" : 597044,
        "openIssuesCount" : 4487,
        "subscribersCount" : 632,
        "pushedAt" : "2025-07-25T00:48:33Z",
        "languages" : {
          "C#" : 26255362,
          "PowerShell" : 210014,
          "TypeScript" : 8999,
          "Java" : 72778,
          "Shell" : 140920,
          "CSS" : 20541,
          "Batchfile" : 1400,
          "CMake" : 15373,
          "JavaScript" : 8603,
          "HTML" : 43621
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Access contact information on Windows, so you don't have to copy and paste raw text data from other sources for example mail drafts or spreadsheets.",
      "validationOrRequirement" : "The API should be the same as it is and for example invoke Outlook's contacts.",
      "attemptedFixes" : "Checking out the guides on working with Microsoft Graph APIs with MAUI is recommended for invoking Outlook's contacts.",
      "otherNotes" : "Currently the ContactsPicker is broken on WinAppSDK (https://github.com/microsoft/WindowsAppSDK/issues/1157) and there is a related issue on MAUI docs repo: https://github.com/dotnet/docs-maui/issues/1191.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407931
  }, {
    "issueDTO" : {
      "id" : 3257254685,
      "title" : "Missing sources: HashChangeEvent.oldURL and HashChangeEvent.newURL",
      "url" : "https://github.com/SAP/project-foxhound/issues/323",
      "repositoryName" : "SAP/project-foxhound",
      "description" : "On the `hashchange` event listener, the `oldURL` and `newURL` attributes of the `HashChangeEvent` object should be tainted, as a consequence of potentially setting a tainted value to `location.hash`, `location.href`, or others.",
      "updatedAt" : 1753361303.000000000,
      "user" : "eleumasc",
      "userHtmlUrl" : "https://github.com/eleumasc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/29689340?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hmmm, could you post some sample code on how this is used for an attack/privacy leak? I'm not quite sure I follow the issue here.\n\nOr is the problem that oldURL (pointed to location hash which used to be tainted) and newURL (points to location.hash which is tainted) are generally untainted?\n\nCould you provide a small test program? I'm unaware of said event, so a simple program highlighting its usage would be welcome. Even better would be a [mochitest](https://github.com/SAP/project-foxhound/tree/main/taint/test/mochitest) that showcases where we are losing taints as a PR ;) but an example would be required to look into it to better figure out what goes wrong here and what's the expected behavior." ],
      "repository" : {
        "description" : "A web browser with dynamic data-flow tracking enabled in the Javascript engine and DOM, based on Mozilla Firefox (https://github.com/mozilla-firefox/firefox). It can be used to identify insecure data flows or data privacy leaks in client-side web applications.",
        "homepage" : "",
        "name" : "project-foxhound",
        "fullName" : "SAP/project-foxhound",
        "htmlUrl" : "https://github.com/SAP/project-foxhound",
        "gitUrl" : "git://github.com/SAP/project-foxhound.git",
        "sshUrl" : "git@github.com:SAP/project-foxhound.git",
        "cloneUrl" : "https://github.com/SAP/project-foxhound.git",
        "owner" : {
          "login" : "SAP",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 16,
        "stargazersCount" : 114,
        "watchersCount" : 114,
        "size" : 5157791,
        "openIssuesCount" : 57,
        "subscribersCount" : 8,
        "pushedAt" : "2025-07-21T13:18:44Z",
        "languages" : {
          "GDB" : 5718,
          "CMake" : 85368,
          "M4" : 519370,
          "Go" : 14155,
          "HTML" : 229539639,
          "NSIS" : 566437,
          "Groovy" : 8995,
          "Pawn" : 5519,
          "IDL" : 2619752,
          "Befunge" : 6280,
          "SCSS" : 301761,
          "Gnuplot" : 710,
          "Pascal" : 6780,
          "Assembly" : 7039249,
          "Python" : 29383122,
          "PowerShell" : 5881,
          "Yacc" : 2517,
          "Jinja" : 875,
          "Rust" : 14705845,
          "Objective-C++" : 637989,
          "SWIG" : 3312,
          "Fluent" : 970694,
          "Perl" : 541372,
          "Ragel" : 35253,
          "AIDL" : 12985,
          "RenderScript" : 3698,
          "Scilab" : 99,
          "Starlark" : 66196,
          "Batchfile" : 30560,
          "Meson" : 85483,
          "Swift" : 16097,
          "Mako" : 1006,
          "C#" : 126138,
          "C" : 113377273,
          "Makefile" : 2777879,
          "DIGITAL Command Language" : 64988,
          "Stylus" : 82,
          "TypeScript" : 8879646,
          "Shell" : 2738408,
          "R" : 1064,
          "sed" : 1562,
          "Awk" : 6178,
          "JavaScript" : 286815659,
          "Objective-C" : 388870,
          "PHP" : 35367,
          "Ruby" : 9501,
          "GLSL" : 1318425,
          "Raku" : 21544,
          "Java" : 5088231,
          "C++" : 294388241,
          "CSS" : 3204220,
          "TeX" : 382211,
          "NASL" : 133375,
          "XSLT" : 18509,
          "Kotlin" : 23472035,
          "WebIDL" : 151333,
          "Dockerfile" : 67288,
          "CoffeeScript" : 623,
          "Euphoria" : 1960,
          "Linker Script" : 97,
          "Roff" : 539948,
          "HLSL" : 26023,
          "Lex" : 11373
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to ensure that the `oldURL` and `newURL` attributes of the `HashChangeEvent` object are tainted when setting a tainted value to `location.hash`, `location.href`, or others.",
      "validationOrRequirement" : "The issue is related to taint tracking and the expected behavior of the `oldURL` and `newURL` attributes.",
      "attemptedFixes" : "None mentioned in the comments.",
      "otherNotes" : "The issue is related to the `hashchange` event listener and the `HashChangeEvent` object, specifically the `oldURL` and `newURL` attributes. The author is unsure about the issue and is asking for sample code, test program, or a mochitest to better understand the problem.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407936
  }, {
    "issueDTO" : {
      "id" : 3253639961,
      "title" : "Activity History Page",
      "url" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game/issues/581",
      "repositoryName" : "DistinctCodes/NFT-Scavenger-Hunt-Game",
      "description" : "**Description:**\nCreate an activity history page that shows user???s puzzle attempts, login history, NFT mints, etc.\n\n**Components to Build:**\n\n* Activity timeline\n* Filter by type/date\n* Pagination",
      "updatedAt" : 1753360963.000000000,
      "user" : "yusuftomilola",
      "userHtmlUrl" : "https://github.com/yusuftomilola",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/52901501?v=4",
      "labels" : [ "NEXTJS", "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ "Hey @yusuftomilola,\nI'm Wheval ??? a frontend developer experienced in building responsive UIs. I???m interested in this task.\n\nI???d approach this by building a pagination component for the activity page, and ensuring the layout is responsive across devices. I???ll also handle loading states properly. Would love to contribute to this!", "Hi, As a returning contributior, can I work on this? \n\nRecommended by [OnlyDust](https://onlydust.com/) for high-quality and dependable contributions." ],
      "repository" : {
        "description" : "A gamified blockchain application built on the StarkNet ecosystem that combines educational puzzles with NFT rewards. Players can solve riddles and blockchain-related challenges to earn unique NFTs while learning about the StarkNet ecosystem.",
        "homepage" : "",
        "name" : "NFT-Scavenger-Hunt-Game",
        "fullName" : "DistinctCodes/NFT-Scavenger-Hunt-Game",
        "htmlUrl" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game",
        "gitUrl" : "git://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "sshUrl" : "git@github.com:DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "cloneUrl" : "https://github.com/DistinctCodes/NFT-Scavenger-Hunt-Game.git",
        "owner" : {
          "login" : "DistinctCodes",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 124,
        "stargazersCount" : 32,
        "watchersCount" : 32,
        "size" : 6874,
        "openIssuesCount" : 15,
        "subscribersCount" : 0,
        "pushedAt" : "2025-07-22T17:39:19Z",
        "languages" : {
          "TypeScript" : 873552,
          "CSS" : 235,
          "Cairo" : 73927,
          "JavaScript" : 106288
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create an activity history page that shows user???s puzzle attempts, login history, NFT mints, etc.",
      "validationOrRequirement" : "NEXTJS, frontend",
      "attemptedFixes" : "Building a pagination component for the activity page, ensuring responsive layout, handling loading states",
      "otherNotes" : "Contributors can work on this issue, good first issue, recommended by OnlyDust, frontend task",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407939
  }, {
    "issueDTO" : {
      "id" : 3258025907,
      "title" : "Wrapper script for macOS: use a relative path to the executable instead of an absolute path",
      "url" : "https://github.com/GyulyVGC/sniffnet/issues/898",
      "repositoryName" : "GyulyVGC/sniffnet",
      "description" : "When installing Sniffnet with the provided Disk Image, it requires the app to be placed in the Applications folder in order to work.\n\nThis is because on macOS Sniffnet is launched via a [wrapper script](https://github.com/GyulyVGC/sniffnet/blob/main/resources/packaging/macos/wrapper.sh) that references the executable absolute path.\nThis issue proposes to launch it with a relative path instead so that we can avoid issues like #888.\n\nProblems in fixing this issue:\n- we cannot use `$PWD` since it contains the directory where the script is launched, not the script directory\n- I almost got it working using `DIR=$(cd \"$(dirname \"$0\")\"; pwd -P)`, but then for some reason `$DIR` is not correctly expanded in the osascript \"do shell script\"",
      "updatedAt" : 1753360655.000000000,
      "user" : "GyulyVGC",
      "userHtmlUrl" : "https://github.com/GyulyVGC",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/100347457?v=4",
      "labels" : [ "help wanted", "packaging", "enhancement", "good first issue", "macOS" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Comfortably monitor your Internet traffic \uD83D\uDD75????????????",
        "homepage" : "https://sniffnet.net",
        "name" : "sniffnet",
        "fullName" : "GyulyVGC/sniffnet",
        "htmlUrl" : "https://github.com/GyulyVGC/sniffnet",
        "gitUrl" : "git://github.com/GyulyVGC/sniffnet.git",
        "sshUrl" : "git@github.com:GyulyVGC/sniffnet.git",
        "cloneUrl" : "https://github.com/GyulyVGC/sniffnet.git",
        "owner" : {
          "login" : "GyulyVGC",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 974,
        "stargazersCount" : 29308,
        "watchersCount" : 29308,
        "size" : 290180,
        "openIssuesCount" : 54,
        "subscribersCount" : 117,
        "pushedAt" : "2025-07-24T10:49:56Z",
        "languages" : {
          "Dockerfile" : 767,
          "Shell" : 1370,
          "Rust" : 932512,
          "Rich Text Format" : 10415
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a wrapper script for macOS that uses a relative path to the executable instead of an absolute path",
      "validationOrRequirement" : "The wrapper script must use a relative path to the executable instead of an absolute path",
      "attemptedFixes" : "The author tried to use DIR=$(cd \"$(dirname \"$0\")\"; pwd -P) but it didn't work correctly in the osascript \"do shell script\"",
      "otherNotes" : "The issue requires the app to be placed in the Applications folder to work due to a wrapper script referencing the executable absolute path. The issue proposes to launch it with a relative path to avoid issues like #888.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407943
  }, {
    "issueDTO" : {
      "id" : 3259747875,
      "title" : "Unnecessary `help?` boolean in the frontend `TheoryMeta` type",
      "url" : "https://github.com/ToposInstitute/CatColab/issues/612",
      "repositoryName" : "ToposInstitute/CatColab",
      "description" : "For arcane reasons (https://github.com/ToposInstitute/CatColab/pull/553), the `TheoryMeta` type has a `help?: boolean` field. This is currently used to determine whether or not a help page is automatically generated for the corresponding theory at `/help/logics/${TheoryMeta.id}`. Since this page should always be generated (see footnote below), this should be removed.\n\nhttps://github.com/ToposInstitute/CatColab/blob/c8ca5c359eb677117b5f03c63061cf25aced239a/packages/frontend/src/stdlib/types.ts#L27\n\nFootnote: If there is no corresponding help file `/packages/frontend/src/help/logics/${TheoryMeta.id}.mdx` then the help page is still populated with the types and analyses from `theoryTypes`and `theoryAnalyses` (respectively), and a warning is rendered below (sourced from `/packages/frontend/src/help/logics/logic-help-not-found.mdx`) saying that the documentation is currently incomplete.",
      "updatedAt" : 1753360494.000000000,
      "user" : "tim-at-topos",
      "userHtmlUrl" : "https://github.com/tim-at-topos",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/101851908?v=4",
      "labels" : [ "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A collaborative environment for formal, interoperable, conceptual modeling",
        "homepage" : "https://catcolab.org",
        "name" : "CatColab",
        "fullName" : "ToposInstitute/CatColab",
        "htmlUrl" : "https://github.com/ToposInstitute/CatColab",
        "gitUrl" : "git://github.com/ToposInstitute/CatColab.git",
        "sshUrl" : "git@github.com:ToposInstitute/CatColab.git",
        "cloneUrl" : "https://github.com/ToposInstitute/CatColab.git",
        "owner" : {
          "login" : "ToposInstitute",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 98,
        "watchersCount" : 98,
        "size" : 5353,
        "openIssuesCount" : 138,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-25T00:28:26Z",
        "languages" : {
          "TypeScript" : 440142,
          "Julia" : 40045,
          "MDX" : 30282,
          "Dockerfile" : 1018,
          "CSS" : 40672,
          "Shell" : 13508,
          "Rust" : 589447,
          "JavaScript" : 2753,
          "XSLT" : 20981,
          "HTML" : 367,
          "Nix" : 587358
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "remove the unnecessary help? boolean in the frontend TheoryMeta type",
      "validationOrRequirement" : "remove the help?: boolean field since this page should always be generated",
      "attemptedFixes" : "",
      "otherNotes" : "For arcane reasons, the TheoryMeta type has a help?: boolean field. If there is no corresponding help file, the help page is still populated with types and analyses from theoryTypes and theoryAnalyses, and a warning is rendered saying that the documentation is currently incomplete.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407947
  }, {
    "issueDTO" : {
      "id" : 3259730454,
      "title" : "`TheoryHelpButton` uses `Theory` and `TheoryMeta`",
      "url" : "https://github.com/ToposInstitute/CatColab/issues/611",
      "repositoryName" : "ToposInstitute/CatColab",
      "description" : "Currently `TheoryHelpButton` takes either optional props of type `Theory` *and* type `TheoryMeta`. This is a hack arising from moving the help button from the main toolbar at the top of the page to next to the logic name in the logic selector. I don't think that the help button needs access to the actual `Theory`, so just rewriting this to only accept a `TheoryMeta` should suffice. As part of this, it might be sensible to write a function `theoryFromMeta: TheoryMeta -> Theory`.\n\nhttps://github.com/ToposInstitute/CatColab/blob/c8ca5c359eb677117b5f03c63061cf25aced239a/packages/frontend/src/page/toolbar.tsx#L54",
      "updatedAt" : 1753360149.000000000,
      "user" : "tim-at-topos",
      "userHtmlUrl" : "https://github.com/tim-at-topos",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/101851908?v=4",
      "labels" : [ "good first issue", "frontend" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A collaborative environment for formal, interoperable, conceptual modeling",
        "homepage" : "https://catcolab.org",
        "name" : "CatColab",
        "fullName" : "ToposInstitute/CatColab",
        "htmlUrl" : "https://github.com/ToposInstitute/CatColab",
        "gitUrl" : "git://github.com/ToposInstitute/CatColab.git",
        "sshUrl" : "git@github.com:ToposInstitute/CatColab.git",
        "cloneUrl" : "https://github.com/ToposInstitute/CatColab.git",
        "owner" : {
          "login" : "ToposInstitute",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 25,
        "stargazersCount" : 98,
        "watchersCount" : 98,
        "size" : 5353,
        "openIssuesCount" : 138,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-25T00:28:26Z",
        "languages" : {
          "TypeScript" : 440142,
          "Julia" : 40045,
          "MDX" : 30282,
          "Dockerfile" : 1018,
          "CSS" : 40672,
          "Shell" : 13508,
          "Rust" : 589447,
          "JavaScript" : 2753,
          "XSLT" : 20981,
          "HTML" : 367,
          "Nix" : 587358
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Rewriting the help button to only accept a TheoryMeta and potentially creating a function theoryFromMeta: TheoryMeta -> Theory.",
      "validationOrRequirement" : "Rewriting the help button to only accept a TheoryMeta should suffice.",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "The issue arises from moving the help button from the main toolbar to next to the logic name in the logic selector.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407949
  }, {
    "issueDTO" : {
      "id" : 3252572417,
      "title" : "Add ABOUT in Navbar",
      "url" : "https://github.com/opensource-society/CodeClip/issues/50",
      "repositoryName" : "opensource-society/CodeClip",
      "description" : "The current navbar does not include an About section, which can help users quickly understand the purpose and features of the website. I propose adding an About link to the navbar that redirects to a dedicated \"About\" page or section. This will improve navigation, user experience, and provide clear context about the website.\n\nCurrent :\n\n<img width=\"1600\" height=\"87\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6136b82c-ac49-4104-8e02-af2cc77fb76e\" />\n\nProposed :\n\n<img width=\"1600\" height=\"91\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ee43bf9d-63ce-4809-9b5f-e5ff1c290e19\" />\n\nPlease assign me this issue with gssoc2025 label and appropriate level.",
      "updatedAt" : 1753360099.000000000,
      "user" : "Shalini22-ui",
      "userHtmlUrl" : "https://github.com/Shalini22-ui",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/183373949?v=4",
      "labels" : [ "enhancement", "gssoc2025", "good first issue", "level 1" ],
      "state" : "OPEN",
      "comments" : [ "@adityai0 i would like to work on this assignment ,please assign this to me.\n\n## \uD83D\uDCC4 Feature: About Page\n\n### Description\nI would like to add a dedicated **About Page** (`about.html`) . \n\n\n### What I will implement\n- Create `about.html` with project description, features list, and GitHub links.\n- Update navigation in `index.html` to include a link to the About Page.\n- Maintain consistent styling with the existing theme.\n- Ensure mobile responsiveness.\n\n\n### Request\nI would like to be assigned this issue so I can work on it .\n\n---\n\n", "go ahead @pranavpatil005 ", "@Shalini22-ui you also can collaborate with @pranavpatil005 ", "> @Shalini22-ui you also can collaborate with @pranavpatil005 \n\nYes would love to thanks,please add level to the issue", "## \uD83D\uDC1E Issue: CSS Not Applied to About Page + Enhancement Proposal\n\n### Description:\n\nCurrently, the CSS styles are not applied to the **About** page, resulting in inconsistent appearance compared to the rest of the website. This affects the overall user experience and visual coherence of the application.\n\n---\n\n### \uD83D\uDEE0??? Proposed Enhancements:\n\n1. **Fix the styling issue on the About page**  \n   Ensure that the page uses the global design variables (colors, fonts, layout) and supports both light and dark themes.\n\n2. **Add a Login and Signup page**  \n   Introduce authentication pages to improve user onboarding experience.\n   \n\n---\n\n### ??? Expected Outcome:\n\n- A visually consistent and responsive **About** page.\n- Fully functional, clean, and mobile-friendly **Login** and **Signup** pages with theme support.\n- Enhanced professionalism and future scalability of the website.\n\n---\n\n## Request \nI would like to work on this please assign this to me @adityai0 \n", "@nikitatri  @pranavpatil005 is already working on this. ask him if he needs any help", "i would love to collaborate with this issue @adityai0 " ],
      "repository" : {
        "description" : "CodeClip is a comprehensive coding challenge platform built with HTML, CSS, and JavaScript, designed specifically for GSSoC contributors and the broader coding community.",
        "homepage" : "https://opensource-society.github.io/CodeClip/",
        "name" : "CodeClip",
        "fullName" : "opensource-society/CodeClip",
        "htmlUrl" : "https://github.com/opensource-society/CodeClip",
        "gitUrl" : "git://github.com/opensource-society/CodeClip.git",
        "sshUrl" : "git@github.com:opensource-society/CodeClip.git",
        "cloneUrl" : "https://github.com/opensource-society/CodeClip.git",
        "owner" : {
          "login" : "opensource-society",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 90,
        "stargazersCount" : 27,
        "watchersCount" : 27,
        "size" : 1475,
        "openIssuesCount" : 75,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-24T17:15:19Z",
        "languages" : {
          "CSS" : 40699,
          "JavaScript" : 18676,
          "HTML" : 146258
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to improve navigation, user experience, and provide clear context about the website by adding an About section to the navbar and creating a dedicated About page.",
      "validationOrRequirement" : "The requirement is to create a dedicated About page with project description, features list, and GitHub links, and to update navigation in index.html to include a link to the About Page, with consistent styling and mobile responsiveness.",
      "attemptedFixes" : "The issue is not yet attempted, but there are proposals for enhancements and a request to assign the issue to a contributor.",
      "otherNotes" : "The issue is about adding an About section to the navbar and creating a dedicated About page, and also enhancing the styling of the About page and adding a login and signup page.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407955
  }, {
    "issueDTO" : {
      "id" : 3253843743,
      "title" : "[Bug] < Footer links are not connected to URLs>",
      "url" : "https://github.com/opensource-society/CodeClip/issues/79",
      "repositoryName" : "opensource-society/CodeClip",
      "description" : "## Description\nThe footer section of the website contains links such as **Home**, **About**, **Contact**, etc.  \nHowever, these links are **not connected to any URLs** ??? clicking on them does nothing.\n\n## Steps to Reproduce\n- Assign proper URLs to each link\n- If actual pages do not exist, use placeholder links like `\"#\"` or `\"/contact\"` (if planned)\n\n\n\n",
      "updatedAt" : 1753360044.000000000,
      "user" : "RaunakOP90",
      "userHtmlUrl" : "https://github.com/RaunakOP90",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/179382180?v=4",
      "labels" : [ "bug", "gssoc2025", "good first issue", "level 1" ],
      "state" : "OPEN",
      "comments" : [ "please assign this issue to me @adityai0 ", "Hi \uD83D\uDC4B, @adityai0 \n\nI noticed the footer links currently don???t redirect anywhere, and I can update them to point to the correct URLs with semantic accessibility in mind. I???ve already contributed to this project and am familiar with its structure. Kindly assign this to me so I can start working on it right away. \uD83D\uDE80\n\nThank you! \uD83D\uDE0A\n\n", "please assign this issue to me @adityai0 ", "please assign this issue to me @adityai0", "@adityai0 Hi! I am part of GSSOC and would like to work on this. Could you please assign it to me? Thanks!", "Please assign this issue to me @adityai0 ", "@adityai0 Hi! I am part of GSSOC 25 and would like to work on this. Could you please assign it to me? Thanks!\n\n", "hey, could you assign me this issue? " ],
      "repository" : {
        "description" : "CodeClip is a comprehensive coding challenge platform built with HTML, CSS, and JavaScript, designed specifically for GSSoC contributors and the broader coding community.",
        "homepage" : "https://opensource-society.github.io/CodeClip/",
        "name" : "CodeClip",
        "fullName" : "opensource-society/CodeClip",
        "htmlUrl" : "https://github.com/opensource-society/CodeClip",
        "gitUrl" : "git://github.com/opensource-society/CodeClip.git",
        "sshUrl" : "git@github.com:opensource-society/CodeClip.git",
        "cloneUrl" : "https://github.com/opensource-society/CodeClip.git",
        "owner" : {
          "login" : "opensource-society",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 90,
        "stargazersCount" : 27,
        "watchersCount" : 27,
        "size" : 1475,
        "openIssuesCount" : 75,
        "subscribersCount" : 3,
        "pushedAt" : "2025-07-24T17:15:19Z",
        "languages" : {
          "CSS" : 40699,
          "JavaScript" : 18676,
          "HTML" : 146258
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The footer section of the website contains links that are not connected to any URLs, and need to be updated to point to the correct URLs with semantic accessibility in mind.",
      "validationOrRequirement" : "Assign proper URLs to each link, if actual pages do not exist, use placeholder links like \"#\" or \"/contact\"",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "Assignee is requested multiple times in the comments, mentioning familiarity with the project structure and willingness to work on it with semantic accessibility in mind.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407958
  }, {
    "issueDTO" : {
      "id" : 3124296203,
      "title" : "Support Arrow Flight SQL",
      "url" : "https://github.com/lakehq/sail/issues/520",
      "repositoryName" : "lakehq/sail",
      "description" : "We would like to support Arrow Flight SQL as an alternative protocol to Spark Connect. This would allow integration with SQL clients (e.g. BI tools) outside of PySpark. The user would be able to start the server via something like `sail flight server` in the command line.\n\nUsing the [Arrow Flight SQL JDBC Driver](https://arrow.apache.org/docs/java/flight_sql_jdbc_driver.html), Java applications can connect to Sail via `jdbc:arrow-flight-sql://`. This is similar to how the [Spark Thrift Server](https://www.russellspitzer.com/2017/05/19/Spark-Sql-Thriftserver/) allows connection via `jdbc:hive2://`.\n\n(As far as I can tell, the Spark Thrift Server uses the JDBC protocol, and do not use Apache Thrift.)\n\nBallista used to support Arrow Flight SQL (~1,000 LoC) but the functionality has been removed (<https://github.com/apache/datafusion-ballista/pull/1228>). I expect the effort would be similar in Sail. The design should be straightforward and not too much knowledge of Sail internals is required.",
      "updatedAt" : 1753360027.000000000,
      "user" : "linhr",
      "userHtmlUrl" : "https://github.com/linhr",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/5601366?v=4",
      "labels" : [ "help wanted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I've worked quite a bit with raw arrow tables so I'd like to take a crack at this if possible?\n\nI mainly use Go but I've built small things in rust.", "> I've worked quite a bit with raw arrow tables so I'd like to take a crack at this if possible?\n> \n> I mainly use Go but I've built small things in rust.\n\n@DeliveranceTechSolutions Thank you for your interest in this issue! Your expertise with Arrow tables sounds like a great fit.\n\nPlease feel free to take a crack at this issue. If you have any questions about the codebase or need any help getting started, do not hesitate to ask. We are happy to help along the way!", "@DeliveranceTechSolutions How are things going? Let us know if you need help with anything!", "@shehabgamin hey Shehab, some things came up on a project I'm on, I've been looking over crates and I have the arrow flight part implemented; however, I'm looking into how it'll interface with you guys.  Rust hard lol", "@DeliveranceTechSolutions Rust is indeed hard! You'll get the hang of it quickly.\n\nFeel free to open up a draft PR if you'd like. @linhr, @lonless9, and I are happy to give pointers and lend a hand.\n\nAlso, if communicating over Slack would be easier/better for you, feel free to join our Community Slack:\nhttps://lakesail.com/slack", "Hey @shehabgamin @linhr @lonless9 I have the server up here [sail-flight](https://github.com/DeliveranceTechSolutions/sail-flight)  I'm obviously using training wheels to get started so please forgive me.  I haven't really started a true piece of rust software but I do understand everything that is going on.  I've used grpc since 2021 so I would be good to implement a client, stub, and anything else we'd need.\n\nI appreciate the feedback, rust is a language I'd really like to hard switch to.", "This is nice progress so far! Here are a few pointers that you may look at.\n\n* **gRPC server code generation**. Here is an example of using `build.rs` script to generate server stub from `.proto` files and include the generated code in the project (without checking in them to Git).\n  * <https://github.com/lakehq/sail/blob/main/crates/sail-spark-connect/build.rs>\n  * <https://github.com/lakehq/sail/blob/main/crates/sail-spark-connect/src/lib.rs>\n* **Session management**. You can refer to the `create_session_context` implementation in the `sail-spark-connect` crate. (In the future we can extract related functions to another crate since they will be used for both the Spark Connect server and the Arrow Flight SQL server.)\n* **Query execution**. You can see how `resolve_and_execute_plan` is used in the `sail-spark-connect` crate.\n* **Overall architecture**. The Ballista implementation (removed in <https://github.com/apache/datafusion-ballista/pull/1228> but is still useful for us) is a relevant example for how the server would look like in Sail.", "Awesome, yea I saw ballista briefly and will look more into their implementation.  I also saw I pushed the Protos but I'll keep that clean.  I'm essentially at the pause point of connecting to sail so I appreciate your help with the entry fn.  If this looks good then I'll try to have an iteration up this week.", "Sounds good! Feel free to continue the implementation and I'd be happy to answer any questions you may have!", "Hey @linhr I have an update and a test for the jdbc connector [sail-flight](https://github.com/DeliveranceTechSolutions/sail-flight)", "Nice progress!\n\nI skimmed through the code and it seems it currently uses DataFusion `SessionContext` and `.sql()` method for query execution. I guess a next step to consider could be switching to Sail's query execution methods.\n\nLet me also think about how to refactor the session constructor so that you don't have to depend on the `sail-spark-connect` crate.", "Will the SessionContext still be stemming from DataFusion or is there something I'm not seeing?\n\nDo I need to instantiate the SqlCommand proto struct if that is the case?", "The Sail `SessionContext` is still DataFusion session context but we have special construction logic. The \"**Session management**\" note in my earlier comment has pointers to related code.\n\n`SqlCommand` is part of the Spark Connect protocol and is unrelated to the Arrow Flight server.\n\nYou can (1) call `parse_one_statement` to parse the SQL string, (2) call `from_ast_statement` to convert SQL AST to the Sail spec, and (3) call `resolve_and_execute_plan` to execute the plan using the session context. You can search for usage of these functions to get an idea how they are used in practice.", "Oh apologies, I think I understand what needs to be done now.  I'll take a look tomorrow, thanks.", "I pushed some more changes @linhr I believe this is closer to the goal?", "Yeah I think it captures the idea! Feel free to continue your exploration in other operations for the Flight server!", "Is there any way we can get a pr state of some kind @linhr @shehabgamin?\n\nI'm jobless and somewhat desperate so I really need some resume boosters because mine is trash.\n\nIt may not help me get a rust role but it'll help me survive and feed my family hopefully.", "Absolutely! You are welcomed to open a PR and contribute to Sail, and I believe the work you've been doing would be valuable for your resume. And best wishes for your job search!\n\nTo begin with, I'd recommend preparing smaller PR that contains only Rust code (i.e. without the README etc. or Java test scripts in your current repo). The code will be in the `sail-flight-sql` crate with `build.rs` and the Arrow Flight SQL server implementation you currently have.\n\nDo not copy existing functions from the `sail-spark-connect` crate. If you need a method from there, feel free to make the function `pub`.\n\nI'd be happy to review and merge the PR. Let me know if you have questions!", "@DeliveranceTechSolutions Feel free to email me your resume if you???d like. My email is my first name at LakeSail. Thank you so much for this contribution. We???ll definitely get it merged, and we???re here to help in any way we can.", "@linhr @shehabgamin thanks, I really appreciate the help and support.\n\nI genuinely believe this is a good project and will be back.  If it weren't for open source and other devs like Linus then I don't know if I would be a programmer today.\n\nI'll organize the pr and get it in as soon as I can." ],
      "repository" : {
        "description" : "LakeSail's computation framework with a mission to unify batch processing, stream processing, and compute-intensive AI workloads.",
        "homepage" : "https://lakesail.com",
        "name" : "sail",
        "fullName" : "lakehq/sail",
        "htmlUrl" : "https://github.com/lakehq/sail",
        "gitUrl" : "git://github.com/lakehq/sail.git",
        "sshUrl" : "git@github.com:lakehq/sail.git",
        "cloneUrl" : "https://github.com/lakehq/sail.git",
        "owner" : {
          "login" : "lakehq",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 44,
        "stargazersCount" : 856,
        "watchersCount" : 856,
        "size" : 5026,
        "openIssuesCount" : 98,
        "subscribersCount" : 11,
        "pushedAt" : "2025-07-24T14:15:09Z",
        "languages" : {
          "Dockerfile" : 4887,
          "Shell" : 16821,
          "Rust" : 2644836,
          "jq" : 3545,
          "JavaScript" : 749,
          "Python" : 137741
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Support Arrow Flight SQL as an alternative protocol to Spark Connect, allowing integration with SQL clients (e.g. BI tools) outside of PySpark.",
      "validationOrRequirement" : "The user should not copy existing functions from the `sail-spark-connect` crate. If needed, make the function `pub`. The code should be in the `sail-flight-sql` crate with `build.rs` and the Arrow Flight SQL server implementation.",
      "attemptedFixes" : "The user has implemented the Arrow Flight SQL server using Rust, and has made progress on connecting to Sail. The code currently uses DataFusion `SessionContext` and `.sql()` method for query execution. The next step is to consider switching to Sail's query execution methods.",
      "otherNotes" : "The user would be able to start the server via something like `sail flight server` in the command line. Java applications can connect to Sail via `jdbc:arrow-flight-sql://`. The design should be straightforward and not too much knowledge of Sail internals is required. The Ballista implementation is a relevant example for how the server would look like in Sail.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407966
  }, {
    "issueDTO" : {
      "id" : 3259725125,
      "title" : "Explorer UI",
      "url" : "https://github.com/paritytech/revive/issues/366",
      "repositoryName" : "paritytech/revive",
      "description" : "The revive [explorer ](https://github.com/paritytech/revive/tree/main/crates/explorer) utility provides us with insights about the code generation. But it lacks a user interface. A UI will make it more convenient to find sub-optimal aspects of the codegen and improve debug information.\n\nI envision a 2 pane WebUI with the YUL and the corresponding RISC-V code. Akin to the [compiler explorer.](https://godbolt.org/).\n- Clicking on a YUL location should jump the RISCV pane to the right place\n- Color-highlighting of the currently selected line\n- The WebUI in the first version doesn't need to have a compiler backend. \n  - The explorer currently uses the dwarfdump utility. It only extracts the locations. But we'd also want to see the instructions. I suggest:\n  - On startup, it analyzes the shared object with dwarfdump and objdump\n  - Once done, the webUI starts and just displays information (processing does not need to happen in the UI - can be added later)\n",
      "updatedAt" : 1753359990.000000000,
      "user" : "xermicus",
      "userHtmlUrl" : "https://github.com/xermicus",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/8707171?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Solidity compiler for Polkadot, targetting PolkaVM in pallet-revive",
        "homepage" : "",
        "name" : "revive",
        "fullName" : "paritytech/revive",
        "htmlUrl" : "https://github.com/paritytech/revive",
        "gitUrl" : "git://github.com/paritytech/revive.git",
        "sshUrl" : "git@github.com:paritytech/revive.git",
        "cloneUrl" : "https://github.com/paritytech/revive.git",
        "owner" : {
          "login" : "paritytech",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 18,
        "stargazersCount" : 84,
        "watchersCount" : 84,
        "size" : 25164,
        "openIssuesCount" : 46,
        "subscribersCount" : 6,
        "pushedAt" : "2025-07-22T16:45:59Z",
        "languages" : {
          "TypeScript" : 28962,
          "Yul" : 4927,
          "Dockerfile" : 985,
          "C++" : 679,
          "Rust" : 896015,
          "C" : 9943,
          "Solidity" : 59443,
          "LLVM" : 8189,
          "Makefile" : 2357,
          "JavaScript" : 26790,
          "HTML" : 1340
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a user interface for the revive utility to make it more convenient to find sub-optimal aspects of the codegen and improve debug information, envisioning a 2 pane WebUI with YUL and RISC-V code, with features like jumping to RISC-V pane, color-highlighting of selected line and displaying information without processing in the UI.",
      "validationOrRequirement" : "good first issue",
      "attemptedFixes" : "",
      "otherNotes" : "The explorer utility currently uses dwarfdump utility and only extracts locations, but wants to see instructions, suggests analyzing shared object with dwarfdump and objdump on startup.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407970
  }, {
    "issueDTO" : {
      "id" : 3258145035,
      "title" : "[Feature] add DashScope coder support",
      "url" : "https://github.com/alibaba/spring-ai-alibaba/issues/1780",
      "repositoryName" : "alibaba/spring-ai-alibaba",
      "description" : "### Feature Request\n\n??????qwen3-coder???????????????????????????????????????????????????\nRefer: https://help.aliyun.com/zh/model-studio/qwen-coder#fdf195bf372ae\n\n### Is your feature request related to a problem? Please describe\n\n_No response_\n\n### Describe the solution you'd like\n\n_No response_\n\n### Describe alternatives you've considered\n\n_No response_\n\n### Additional context\n\n_No response_",
      "updatedAt" : 1753359978.000000000,
      "user" : "HunterPorter",
      "userHtmlUrl" : "https://github.com/HunterPorter",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7405333?v=4",
      "labels" : [ "area/core", "needs-triage", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "good idea " ],
      "repository" : {
        "description" : "Agentic AI Framework for Java Developers",
        "homepage" : "https://java2ai.com",
        "name" : "spring-ai-alibaba",
        "fullName" : "alibaba/spring-ai-alibaba",
        "htmlUrl" : "https://github.com/alibaba/spring-ai-alibaba",
        "gitUrl" : "git://github.com/alibaba/spring-ai-alibaba.git",
        "sshUrl" : "git@github.com:alibaba/spring-ai-alibaba.git",
        "cloneUrl" : "https://github.com/alibaba/spring-ai-alibaba.git",
        "owner" : {
          "login" : "alibaba",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 998,
        "stargazersCount" : 5006,
        "watchersCount" : 5006,
        "size" : 147621,
        "openIssuesCount" : 286,
        "subscribersCount" : 66,
        "pushedAt" : "2025-07-24T23:14:32Z",
        "languages" : {
          "Java" : 6218355,
          "CSS" : 26756,
          "Makefile" : 7848,
          "TeX" : 4902,
          "Vue" : 496814,
          "Mustache" : 4656,
          "HTML" : 119089,
          "TypeScript" : 536249,
          "Dockerfile" : 2057,
          "Shell" : 42951,
          "Smalltalk" : 11271,
          "Batchfile" : 3003,
          "JavaScript" : 34104,
          "Less" : 6998,
          "Python" : 3892
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add support for DashScope coder model in the feature.",
      "validationOrRequirement" : "No specific validations or requirements mentioned.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is related to adding support for DashScope coder model, which is currently trending.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407972
  }, {
    "issueDTO" : {
      "id" : 3259708252,
      "title" : "[Arm] Size-test: Run the binary on CI",
      "url" : "https://github.com/pytorch/executorch/issues/12812",
      "repositoryName" : "pytorch/executorch",
      "description" : "### \uD83D\uDE80 The feature, motivation and pitch\n\nToday we just build and test for size, but we also want to run it to make sure the build is viable.\n\n\n### Alternatives\n\n_No response_\n\n### Additional context\n\n* CI job - https://github.com/pytorch/executorch/blob/8da2ea6ea98062d73ff5c8da1d9b1ce99ca11a18/.github/workflows/trunk.yml#L220\n* We may run into size_test.cpp using FileDataLoader which may not be supported on the baremetal platforms. See arm_executor_runner.cpp for BufferDataLoader use.\n\n### RFC (Optional)\n\n_No response_",
      "updatedAt" : 1753359648.000000000,
      "user" : "digantdesai",
      "userHtmlUrl" : "https://github.com/digantdesai",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/368720?v=4",
      "labels" : [ "actionable", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "On-device AI across mobile, embedded and edge for PyTorch",
        "homepage" : "https://pytorch.org/executorch/",
        "name" : "executorch",
        "fullName" : "pytorch/executorch",
        "htmlUrl" : "https://github.com/pytorch/executorch",
        "gitUrl" : "git://github.com/pytorch/executorch.git",
        "sshUrl" : "git@github.com:pytorch/executorch.git",
        "cloneUrl" : "https://github.com/pytorch/executorch.git",
        "owner" : {
          "login" : "pytorch",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 627,
        "stargazersCount" : 3054,
        "watchersCount" : 3054,
        "size" : 242669,
        "openIssuesCount" : 1273,
        "subscribersCount" : 69,
        "pushedAt" : "2025-07-25T00:57:59Z",
        "languages" : {
          "Java" : 91516,
          "C++" : 7679686,
          "Jinja" : 11160,
          "C" : 92780,
          "Objective-C++" : 585916,
          "CMake" : 258695,
          "Kotlin" : 47365,
          "Dockerfile" : 2846,
          "Shell" : 249480,
          "Starlark" : 490914,
          "Batchfile" : 339,
          "Objective-C" : 192676,
          "Swift" : 92248,
          "Python" : 9717219,
          "GLSL" : 337891
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to run the binary on CI to ensure the build is viable.",
      "validationOrRequirement" : "No specific validations or requirements mentioned.",
      "attemptedFixes" : "No attempted fixes mentioned in the description or comments.",
      "otherNotes" : "The issue aims to run the binary on CI, mentioning that today we just build and test for size, but also want to run it to ensure the build is viable. Additional context includes a CI job link and a potential issue with FileDataLoader on baremetal platforms.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407976
  }, {
    "issueDTO" : {
      "id" : 3111728514,
      "title" : "Feature Request: Table-only insights with time-based breakdowns",
      "url" : "https://github.com/PostHog/posthog/issues/33025",
      "repositoryName" : "PostHog/posthog",
      "description" : "### Feature request\n\n## Is your feature request related to a problem?\n\nCurrently, when converting trend insights to table format, the time breakdown is lost and only shows aggregated sums. For dashboards where we only need tabular data, there's no way to display time-series data in a table format without also showing the graph visualization.\n\n## Describe the solution you'd like\n\nAdd the ability to create table-only insights that maintain time-based breakdowns (daily, weekly, monthly, etc.) without requiring a graph component. This would allow users to:\n\n- Create pure table visualizations with time series data\n- Share cleaner dashboards focused on tabular data\n- Maintain the detailed time breakdown that's currently only available in graph format under detailed results\n\n## Describe alternatives you've considered\n- Using SQL insights for custom tables (but this requires more technical knowledge)\n- Hiding graph elements via CSS (not a sustainable solution)\n\n## Additional context\nFrom: https://posthoghelp.zendesk.com/agent/tickets/31269\n\n### Debug info\n\n```shell\nKind: bug\n\nTarget area: analytics\n\nReport event: http://go/ticketByUUID/cc34299c-4d75-4c48-9e07-c57f2cb91e85\n\nSession: https://us.posthog.com/project/sTMFPsFhdP1Ssg/replay/0196f860-9b0f-7a71-b797-fc903a5a9ece?t=256\n\nExceptions: https://us.posthog.com/project/2/error_tracking?filterGroup=%7B%22type%22%3A%22AND%22%2C%22values%22%3A%5B%7B%22type%22%3A%22AND%22%2C%22values%22%3A%5B%7B%22key%22%3A%22%24session_id%22%2C%22value%22%3A%5B%220196f860-9b0f-7a71-b797-fc903a5a9ece%22%5D%2C%22operator%22%3A%22exact%22%2C%22type%22%3A%22event%22%7D%5D%7D%5D%7D\n\nLocation: https://eu.posthog.com/project/7005/dashboard/73635\n\nPersons-on-events mode for project: person_id_no_override_properties_on_events\n```",
      "updatedAt" : 1753359548.000000000,
      "user" : "benHPostHog",
      "userHtmlUrl" : "https://github.com/benHPostHog",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/181385999?v=4",
      "labels" : [ "enhancement", "feature/insights", "good first issue", "team/product-analytics" ],
      "state" : "OPEN",
      "comments" : [ "+1 https://posthog.com/questions/enable-detailed-table-below-the-chart", "@benHPostHog I would like to contribute to this issue.", "Hey @benHPostHog, can you share some instructions on how can I reproduce this behaviour locally? I can see an insights page from the dummy data but where is the options to go \"table only\" view?" ],
      "repository" : {
        "description" : "\uD83E\uDD94 PostHog provides open-source web & product analytics, session recording, feature flagging and A/B testing that you can self-host. Get started - free.",
        "homepage" : "https://posthog.com",
        "name" : "posthog",
        "fullName" : "PostHog/posthog",
        "htmlUrl" : "https://github.com/PostHog/posthog",
        "gitUrl" : "git://github.com/PostHog/posthog.git",
        "sshUrl" : "git@github.com:PostHog/posthog.git",
        "cloneUrl" : "https://github.com/PostHog/posthog.git",
        "owner" : {
          "login" : "PostHog",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1806,
        "stargazersCount" : 27948,
        "watchersCount" : 27948,
        "size" : 2937930,
        "openIssuesCount" : 2227,
        "subscribersCount" : 115,
        "pushedAt" : "2025-07-25T00:50:48Z",
        "languages" : {
          "MDX" : 33492,
          "Smarty" : 1517,
          "C++" : 697800,
          "CSS" : 1407,
          "Rust" : 2787334,
          "C" : 285,
          "PLpgSQL" : 9521,
          "Go" : 45701,
          "HTML" : 162461,
          "Perl" : 35898,
          "EJS" : 4831,
          "TypeScript" : 24567059,
          "Dockerfile" : 16676,
          "Shell" : 100449,
          "ANTLR" : 29394,
          "SCSS" : 351753,
          "JavaScript" : 453210,
          "Python" : 28584686
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to add the ability to create table-only insights that maintain time-based breakdowns, allowing users to create pure table visualizations with time series data, share cleaner dashboards focused on tabular data, and maintain the detailed time breakdown that's currently only available in graph format under detailed results.",
      "validationOrRequirement" : "The user wants to create table-only insights that maintain time-based breakdowns without requiring a graph component, and the table should be able to display daily, weekly, monthly, etc. time series data.",
      "attemptedFixes" : "The user has considered using SQL insights for custom tables, but this requires more technical knowledge, and hiding graph elements via CSS, but this is not a sustainable solution.",
      "otherNotes" : "The issue is related to a problem where the time breakdown is lost when converting trend insights to table format, and the user wants to display time-series data in a table format without showing the graph visualization.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407982
  }, {
    "issueDTO" : {
      "id" : 2836832801,
      "title" : "\uD83D\uDCCE Port `arrow-body-style` from eslint",
      "url" : "https://github.com/biomejs/biome/issues/5050",
      "repositoryName" : "biomejs/biome",
      "description" : "### Description\n\nPort the [`arrow-body-style`](https://eslint.org/docs/latest/rules/arrow-body-style) rule from eslint. \n\nSuggested names:\n- `useConsistentArrowReturn`\n\nThe eslint rule has options, but we don't usually implement options on the first iteration of a rule. For this task, implement the functionality that is equivalent to the default option (which would be `as-needed`).\n\nSource: https://eslint.org/docs/latest/rules/arrow-body-style\n\n**Want to contribute?** Lets you know you are interested! We will assign you to the issue to prevent several people to work on the same issue. Don't worry, we can unassign you later if you are no longer interested in the issue! Read our [contributing guide](https://github.com/biomejs/biome/blob/main/CONTRIBUTING.md) and [analyzer contributing guide](https://github.com/biomejs/biome/blob/main/crates/biome_analyze/CONTRIBUTING.md).",
      "updatedAt" : 1753359377.000000000,
      "user" : "dyc3",
      "userHtmlUrl" : "https://github.com/dyc3",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1808807?v=4",
      "labels" : [ "L-JavaScript", "A-Linter", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hey @dyc3 I would like to take this issue! \uD83D\uDE00", "Is there another task for the \"always\" eslint setting (i.e., requiring you to add explicit block and return statement)? If not, it would be nice if the title of this were revised to: Port `arrow-body-style: as-needed` from eslint.", "We could use a name such as `useConsistentArrowReturn`. I think that name works even if we add the option.", "> We could use a name such as `useConsistentArrowReturn`. I think that name works even if we add the option.\n\nI like that, and it seems to align with other rules that let you pick a potentially controversial style and enforce it, e.g., `useConsistentArrayType`", "Any updates?", "@isjavierdiaz it's been 5 months. I assume you don't have time." ],
      "repository" : {
        "description" : "A toolchain for web projects, aimed to provide functionalities to maintain them. Biome offers formatter and linter, usable via CLI and LSP.",
        "homepage" : "https://biomejs.dev",
        "name" : "biome",
        "fullName" : "biomejs/biome",
        "htmlUrl" : "https://github.com/biomejs/biome",
        "gitUrl" : "git://github.com/biomejs/biome.git",
        "sshUrl" : "git@github.com:biomejs/biome.git",
        "cloneUrl" : "https://github.com/biomejs/biome.git",
        "owner" : {
          "login" : "biomejs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : false,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 649,
        "stargazersCount" : 20251,
        "watchersCount" : 20251,
        "size" : 222326,
        "openIssuesCount" : 311,
        "subscribersCount" : 59,
        "pushedAt" : "2025-07-24T20:00:00Z",
        "languages" : {
          "TypeScript" : 701668,
          "Dockerfile" : 562,
          "CSS" : 322448,
          "Shell" : 3221,
          "RenderScript" : 2,
          "Rust" : 15898792,
          "Astro" : 262,
          "JavaScript" : 1422065,
          "Vue" : 1827,
          "HTML" : 63966,
          "Svelte" : 852,
          "Just" : 5314
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Port the `arrow-body-style` rule from eslint and implement the functionality equivalent to the default option (`as-needed`).",
      "validationOrRequirement" : "The requirement is to port the `arrow-body-style` rule from eslint and implement the functionality equivalent to the default option (`as-needed`).",
      "attemptedFixes" : "The issue has comments discussing potential names for the rule, including `useConsistentArrowReturn`, and the possibility of adding an option for the `always` eslint setting.",
      "otherNotes" : "The issue is part of the biomejs/biome repository and has labels L-JavaScript, A-Linter, and good first issue. The author is dyc3 and the issue is about porting the `arrow-body-style` rule from eslint. The suggested name for the rule is `useConsistentArrowReturn`. There is a mention of implementing the functionality equivalent to the default option (`as-needed`) and the possibility of adding an option in the future.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407989
  }, {
    "issueDTO" : {
      "id" : 2613354849,
      "title" : "Feature: add isnan, isinf scalar functions",
      "url" : "https://github.com/databendlabs/databend/issues/16690",
      "repositoryName" : "databendlabs/databend",
      "description" : "**Summary**\r\n\r\nDescription for this feature.\r\n\r\nAdd `isnan`, `isinf ` functions for float types(f32, f64).",
      "updatedAt" : 1753359318.000000000,
      "user" : "sundy-li",
      "userHtmlUrl" : "https://github.com/sundy-li",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/3325189?v=4",
      "labels" : [ "C-feature", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "take", "Can I take this issue? It looks like it's been a while since there was any activity." ],
      "repository" : {
        "description" : "\uD835\uDDD7\uD835\uDDEE\uD835\uDE01\uD835\uDDEE, \uD835\uDDD4\uD835\uDDFB\uD835\uDDEE\uD835\uDDF9\uD835\uDE06\uD835\uDE01\uD835\uDDF6\uD835\uDDF0\uD835\uDE00 & \uD835\uDDD4\uD835\uDDDC. Modern alternative to Snowflake. Cost-effective and simple for massive-scale analytics. https://databend.com",
        "homepage" : "https://docs.databend.com",
        "name" : "databend",
        "fullName" : "databendlabs/databend",
        "htmlUrl" : "https://github.com/databendlabs/databend",
        "gitUrl" : "git://github.com/databendlabs/databend.git",
        "sshUrl" : "git@github.com:databendlabs/databend.git",
        "cloneUrl" : "https://github.com/databendlabs/databend.git",
        "owner" : {
          "login" : "databendlabs",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 795,
        "stargazersCount" : 8675,
        "watchersCount" : 8675,
        "size" : 315088,
        "openIssuesCount" : 595,
        "subscribersCount" : 95,
        "pushedAt" : "2025-07-25T00:02:55Z",
        "languages" : {
          "Dockerfile" : 9628,
          "Java" : 6896,
          "Shell" : 519736,
          "Jinja" : 33036,
          "RenderScript" : 1,
          "Rust" : 24461365,
          "Makefile" : 4015,
          "JavaScript" : 231,
          "HTML" : 2216,
          "Python" : 215057
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add isnan, isinf scalar functions for float types(f32, f64)",
      "validationOrRequirement" : "Add functions for float types f32 and f64",
      "attemptedFixes" : "None",
      "otherNotes" : "Feature request for adding isnan and isinf scalar functions for float types f32 and f64",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407991
  }, {
    "issueDTO" : {
      "id" : 3259633673,
      "title" : "[ENH] `mapie 1.X` compatibility",
      "url" : "https://github.com/sktime/skpro/issues/563",
      "repositoryName" : "sktime/skpro",
      "description" : "The `MapieRegressor` is no longer compatible with `mapie` since version 1. The upstream regressor has been split into four classes.\n\nWe should:\n\n* add the `mapie<1.0` dependency to the `MapieRegressor`\n* add four classes interfacing the four `mapie` regression classes",
      "updatedAt" : 1753359186.000000000,
      "user" : "fkiraly",
      "userHtmlUrl" : "https://github.com/fkiraly",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/7985502?v=4",
      "labels" : [ "module:regression", "feature request", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "A unified framework for tabular probabilistic regression, time-to-event prediction, and probability distributions in python",
        "homepage" : "https://skpro.readthedocs.io/en/latest",
        "name" : "skpro",
        "fullName" : "sktime/skpro",
        "htmlUrl" : "https://github.com/sktime/skpro",
        "gitUrl" : "git://github.com/sktime/skpro.git",
        "sshUrl" : "git@github.com:sktime/skpro.git",
        "cloneUrl" : "https://github.com/sktime/skpro.git",
        "owner" : {
          "login" : "sktime",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 59,
        "stargazersCount" : 272,
        "watchersCount" : 272,
        "size" : 12280,
        "openIssuesCount" : 81,
        "subscribersCount" : 9,
        "pushedAt" : "2025-07-24T14:47:46Z",
        "languages" : {
          "Dockerfile" : 660,
          "Shell" : 624,
          "Makefile" : 1835,
          "Python" : 1352774
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Make the MapieRegressor compatible with mapie versions less than 1.0 by adding the necessary dependencies and classes.",
      "validationOrRequirement" : "Add the mapie<1.0 dependency to the MapieRegressor and add four classes interfacing the four mapie regression classes.",
      "attemptedFixes" : "No attempted fixes or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about making the MapieRegressor compatible with mapie versions less than 1.0. This is a feature request and is labeled as a good first issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753407995
  }, {
    "issueDTO" : {
      "id" : 3110489740,
      "title" : "Airflow v3 user creation command fails",
      "url" : "https://github.com/apache/airflow/issues/51304",
      "repositoryName" : "apache/airflow",
      "description" : "### Apache Airflow version\n\n3.0.1\n\n### If \"Other Airflow 2 version\" selected, which one?\n\n_No response_\n\n### What happened?\n\nUnsure if this is my mistake, but the createUserJob fails on Kubernetes using the Helm chart.\n\nHere's the output of the `airflow users` command that displays the same error as the createUserJob.\n```\nairflow@airflow-api-server-6865b4769f-cvl2c:/opt/airflow$ airflow users\nUsage: airflow [-h] GROUP_OR_COMMAND ...\n\nPositional Arguments:\n  GROUP_OR_COMMAND\n\n    Groups\n      assets            Manage assets\n      backfill          Manage backfills\n      config            View configuration\n      connections       Manage connections\n      dags              Manage DAGs\n      db                Database operations\n      jobs              Manage jobs\n      kubernetes        Tools to help run the KubernetesExecutor\n      pools             Manage pools\n      providers         Display providers\n      tasks             Manage tasks\n      variables         Manage variables\n\n    Commands:\n      api-server        Start an Airflow API server instance\n      cheat-sheet       Display cheat sheet\n      dag-processor     Start a dag processor instance\n      info              Show information about current Airflow and environment\n      kerberos          Start a kerberos ticket renewer\n      plugins           Dump information about loaded plugins\n      rotate-fernet-key\n                        Rotate encrypted connection credentials and variables\n      scheduler         Start a scheduler instance\n      standalone        Run an all-in-one copy of Airflow\n      triggerer         Start a triggerer instance\n      version           Show the version\n\nOptions:\n  -h, --help            show this help message and exit\n\nairflow command error: argument GROUP_OR_COMMAND: invalid choice: 'users' (choose from api-server, assets, backfill, cheat-sheet, config, connections, dag-processor, dags, db, info, jobs, kerberos, kubernetes, plugins, p\nools, providers, rotate-fernet-key, scheduler, standalone, tasks, triggerer, variables, version), see help above.\n```\n\n### What you think should happen instead?\n\n_No response_\n\n### How to reproduce\n\nRun `airflow users -h` on v3.0.1 Airflow Docker image.\n\n### Operating System\n\nKubernetes\n\n### Versions of Apache Airflow Providers\n\n_No response_\n\n### Deployment\n\nOfficial Apache Airflow Helm Chart\n\n### Deployment details\n\nDeployment on GKE using ArgoCD.\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit PR?\n\n- [ ] Yes I am willing to submit a PR!\n\n### Code of Conduct\n\n- [x] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)\n",
      "updatedAt" : 1753359109.000000000,
      "user" : "markhc",
      "userHtmlUrl" : "https://github.com/markhc",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/11592227?v=4",
      "labels" : [ "kind:bug", "area:core", "area:CLI", "needs-triage", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Do you have Airflow fab provider installed?\n\nhttps://airflow.apache.org/docs/apache-airflow-providers-fab/stable/cli-ref.html\n\nhttps://github.com/apache/airflow/blob/main/providers/fab/src/airflow/providers/fab/auth_manager/cli_commands/user_command.py", "This is a standard deploy using the provided helm chart. I have not modified any settings related to providers, so if it doesn't come pre-installed I do not have it. \n\nMy point is that, in my opinion, a standard installation should work out of the box. As it stands I cannot login to the deployed Airflow instance as no default user has been created.", "Also, even after installing `apache-airflow-providers-fab` the error persists\n\n```\nairflow@airflow-api-server-6865b4769f-cvl2c:/opt/airflow$ pip freeze | grep fab\napache-airflow-providers-fab==2.0.2\n```\n```\nairflow@airflow-api-server-6865b4769f-cvl2c:/opt/airflow$ airflow users create\nUsage: airflow [-h] GROUP_OR_COMMAND ...\n\nPositional Arguments:\n  GROUP_OR_COMMAND\n\n[...] omitted for brevity\n\nOptions:\n  -h, --help            show this help message and exit\n\nairflow command error: argument GROUP_OR_COMMAND: invalid choice: 'users' (choose from api-server, assets, backfill, cheat-sheet, config, connections, dag-processor, dags, db, info, jobs, kerberos, kubernetes, plugins, p\nools, providers, rotate-fernet-key, scheduler, standalone, tasks, triggerer, variables, version), see help above.\n```", "You need to have `FabAuthManager` conifgured. The `users` command is part of the Fab Auth Manaager https://airflow.apache.org/docs/apache-airflow-providers-fab/stable/cli-ref.html.\n\n\"Standard\" installation now uses SimpleAuthManeager https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/auth-manager/simple/index.html\n\n", "> You need to have `FabAuthManager` conifgured. The `users` command is part of the Fab Auth Manaager https://airflow.apache.org/docs/apache-airflow-providers-fab/stable/cli-ref.html.\n> \n> \"Standard\" installation now uses SimpleAuthManeager https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/auth-manager/simple/index.html\n\nDo you have an example on how to configure it then? Because I have the package installed and I've set `auth_manager = airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager` in the `[core]` section of the config file but both `airflow users create` and `flask fab create-user` still fail.", "> > You need to have `FabAuthManager` conifgured. The `users` command is part of the Fab Auth Manaager https://airflow.apache.org/docs/apache-airflow-providers-fab/stable/cli-ref.html.\n> > \"Standard\" installation now uses SimpleAuthManeager https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/auth-manager/simple/index.html\n> \n> Do you have an example on how to configure it then? Because I have the package installed and I've set `auth_manager = airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager` in the `[core]` section of the config file but both `airflow users create` and `flask fab create-user` still fail.\n\nNo idea - works for me when I just set it - i guess some settings on your side are not applied in the container:\n\n![Image](https://github.com/user-attachments/assets/da3f95df-1524-4ee5-a568-0d9c46e500d3)", "Somehow reinstalling fixed it. Really not sure what was wrong in my first install. The only thing I changed was setting FAB as the auth manager in the Helm chart from the beginning (my first install was using SimpleAuth at first). \n\nThanks!", "It also failed for me when using the helm chart, in fact, it does not show up in airflow subcommands but fab is installed and used for Oauth against Azure. Very weird.", "> It also failed for me when using the helm chart, in fact, it does not show up in airflow subcommands but fab is installed and used for Oauth against Azure. Very weird.\n\nI think it depends on how you are running the `airflow` command and whether the container you are running it in has the FAB provider installed and FAB Auth manager configured. Can you check it ?\n", "First of all, and as always thank you so much for Apache Airflow :), I've depended on it for years for many projects.\n\nAnd yes, as far as I can tell we do have it installed. Some \"evidence\" that may help, short of showing the running system.\n\n1. I'm using a custom docker image (but based on apache/airflow:3.0.0-python3.12) that includes this in its requirements: **apache-airflow-providers-fab==2.0.1**. This is a gist with its definition and related files: https://gist.github.com/mrbungie/ab8e2a2104e56c7d6dc8872d01d44f9a\n2. I'm setting the following relevant values in my helm chart: https://gist.github.com/mrbungie/eaae9aed11d04b04d960376788d3e91e (here im showing it with webserver.defaultUser = false, but when I set it to true, the createUser fails)\n3. We implemented a webserver_config.py (shown in [1] gist integrated with EntraID). And it works, so FAB is working.\n\nWhen I get into most containers, they do have the users subcommand:\n<img width=\"1260\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ee48e1aa-ec4a-49be-be7c-37fa666eddfa\" />\n\nBut when checking the create-user container (after setting createUser to true), it fails.\n\n<img width=\"727\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5a486456-24c5-4d5e-a2b9-e918ea0416e3\" />\n<img width=\"1271\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/79d1a1f3-dd36-44a3-9306-f9dd40cab6ed\" />\n\nI'm pretty sure it has to do with the fact that the env vars overriding Auth are not reaching the createUser container.\ncreate-user envvars:\n\n<img width=\"730\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/abb8def2-b78c-464c-9ecd-f0317f421901\" />\n\nMeanwhile other containers (like api-server)\n\n<img width=\"731\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/ea1437bb-c9c1-470c-9df1-f5f74ba42b6a\" />\n\nI guess that means that that setting (i.e. airflow.core.auth_manager / AIRFLOW__CORE__AUTH_MANAGER) **should be set exclusively via airflow.cfg**, but I think docs should be clearer about that.\n\nIf that's not the hoped behaviour, I would guess AIRFLOW__CORE__AUTH_MANAGER, if set, should be propagated down into the create-user container (after all, if its going to run create-user in Airflow 3, it should have that set to FAB or it is always going to fail). Maybe the create-user container should check if FAB is on (via env var + airflow.cfg), and if not, it should just continue gracefully and maybe logging that so users are advised to set createUser = false if they are just using Simple Auth. \n\nIf anything I'm saying makes sense, I can make a PR fixing this in some direction you propose.\n\nMore info:\nHelm chart commit SHA256: https://github.com/apache/airflow/commit/3bd9746d5c30d47fec1e50cc95a3b83add1ee3e8\n \n<img width=\"1460\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/24d3c3b4-bbbe-4b24-8d50-d2bc194cbaa2\" />", "OK. So it means that createUserJob template needs to be fixed. I marked it for next chart version and as good first issue. Anyone is invited to fix it.", "> If anything I'm saying makes sense, I can make a PR fixing this in some direction you propose.\n\nMakes absolutely sense. Thanks for all those invstigations @mrbungie ! and Fix would be really nice!", "From version>=3.0.0, no subcommand 'users'.\n\nYou would have to use airflow standalone, which also gets an error", "@mrbungie may I ask how you added the `AIRFLOW__CORE__AUTH_MANAGER` env variable? Did you add it through the `extraEnv:`/`extraEnvFrom`, or through the `config.core:` section (or any other way)?", "I'm looking into this issue and would like to contribute if it's still unresolved." ],
      "repository" : {
        "description" : "Apache Airflow - A platform to programmatically author, schedule, and monitor workflows",
        "homepage" : "https://airflow.apache.org/",
        "name" : "airflow",
        "fullName" : "apache/airflow",
        "htmlUrl" : "https://github.com/apache/airflow",
        "gitUrl" : "git://github.com/apache/airflow.git",
        "sshUrl" : "git@github.com:apache/airflow.git",
        "cloneUrl" : "https://github.com/apache/airflow.git",
        "owner" : {
          "login" : "apache",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 15362,
        "stargazersCount" : 41230,
        "watchersCount" : 41230,
        "size" : 419309,
        "openIssuesCount" : 1522,
        "subscribersCount" : 763,
        "pushedAt" : "2025-07-24T23:09:06Z",
        "languages" : {
          "Java" : 1443,
          "Jinja" : 76192,
          "CSS" : 15733,
          "Go" : 63158,
          "HTML" : 43330,
          "Jupyter Notebook" : 7288,
          "TypeScript" : 2168833,
          "HCL" : 3786,
          "Dockerfile" : 119789,
          "Shell" : 232889,
          "JavaScript" : 329955,
          "Mako" : 2684,
          "Python" : 42616717
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to create a user in Airflow v3 on Kubernetes using the Helm chart, but the `airflow users create` command fails with an error.",
      "validationOrRequirement" : "The user creation command is part of the Fab Auth Manager, and the `users` command is not available by default in Airflow v3. The user needs to have `FabAuthManager` configured.",
      "attemptedFixes" : "The user has tried installing the `apache-airflow-providers-fab` package, setting `auth_manager = airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager` in the `[core]` section of the config file, and reinstalling. The user has also tried setting FAB as the auth manager in the Helm chart.",
      "otherNotes" : "The issue is related to the Airflow v3 user creation command failing on Kubernetes using the Helm chart. The user has tried installing the `apache-airflow-providers-fab` package and setting `auth_manager = airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager` in the `[core]` section of the config file, but still encounters the error. The issue seems to be related to the container not having the FAB provider installed and FAB Auth manager configured. The user has also tried reinstalling and setting FAB as the auth manager in the Helm chart, but the issue persists.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408005
  }, {
    "issueDTO" : {
      "id" : 3204609385,
      "title" : "Mode-aware consistency check",
      "url" : "https://github.com/JabRef/jabref/issues/13467",
      "repositoryName" : "JabRef/jabref",
      "description" : "We have a library consistency check for checking whether fields in a set of entries are set/unset consistently. Currently, this is NOT aware of the difference of BibTeX and BibLaTeX.\n\n??? This is a good excercise to learn test-driven development and using a data model. This issue cannot be solved with an AI. You really have to think though BibTeX and BibLaTeX for yourself! Take this issue only if you are willing to invest significant time. ???\n\nExample: \n\n```bibtex\n@online{withDate,\n  date = {2025},\n  urldate = {2025-07-05}\n}\n\n@online{withoutDate,\n  urldate = {2025-07-05}\n}\n```\n\nIn BibTeX: Only `withDate`, field: `date` should be reported, because both entries take `urldate`.\n\nIn BibLaTeX: Only `withoutDate`, field: `date` (missing) should be reported, because required field `date` is missing.\n\n## Task\n\n- Modify `org.jabref.logic.quality.consistency.BibliographyConsistencyCheck` to use a complete `BibDatabaseContext` instead of a list of entries\n- Modify `org.jabref.logic.quality.consistency.BibliographyConsistencyCheck#check` to adhere the mode\n\n## Hints\n\n- Required fields of BibLaTeX `@online`: `org.jabref.model.entry.types.BiblatexEntryTypeDefinitions#ONLINE`\n- Get used to `org.jabref.model.entry.types.BibtexEntryTypeDefinitions` and `org.jabref.model.entry.types.BiblatexEntryTypeDefinitions`\n- One can get the required fields using `org.jabref.model.entry.BibEntryType#getRequiredFields`\n- Do test-driven development. Start with enabling `org.jabref.logic.quality.consistency.BibliographyConsistencyCheckTest#unsetFieldsReported` again.\n- Do not get confused with \"library\" and \"database\". User-facing we talk about \"library\", inside the code, we use \"database\", but mean \"library\".\n",
      "updatedAt" : 1753358793.000000000,
      "user" : "koppor",
      "userHtmlUrl" : "https://github.com/koppor",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/1366654?v=4",
      "labels" : [ "\uD83D\uDCCC Pinned", "component: consistency-check", "good first issue", "\uD83D\uDCCD Assigned" ],
      "state" : "OPEN",
      "comments" : [ "hello i'd like to take on this issue.", "Hi my friend, I'd like to take this task if possible.", "\uD83D\uDC4B Hey, looks like you???re eager to work on this issue???great! \uD83C\uDF89 It also looks like you skipped reading our [CONTRIBUTING.md](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md), which explains exactly how to participate. No worries, it happens to the best of us. Give it a read, and you???ll discover the ancient wisdom of assigning issues to yourself. Trust me, it???s worth it. \uD83D\uDE80\n<!-- thollander/actions-comment-pull-request \"wisdom\" -->", "/assign-me", "\uD83D\uDC4B Hey @dcarpentiero, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80", "/assign-me", "\uD83D\uDC4B Hey @dcarpentiero, thank you for your interest in this issue! \uD83C\uDF89\n\nWe're excited to have you on board. Start by exploring our [Contributing](https://github.com/JabRef/jabref/blob/main/CONTRIBUTING.md) guidelines, and don't forget to check out our [workspace setup guidelines](https://devdocs.jabref.org/getting-into-the-code/guidelines-for-setting-up-a-local-workspace) to get started smoothly.\n\nFor questions on JabRef functionality and the code base, you can consult the [JabRef Guru](https://gurubase.io/g/jabref) or ask on our Gitter chat.\n\nIn case you encounter failing tests during development, please check our [developer FAQs](https://devdocs.jabref.org/code-howtos/faq.html)!\n\nHaving any questions or issues? Feel free to ask here on GitHub. Need help setting up your local workspace? Join the conversation on [JabRef's Gitter chat](https://gitter.im/JabRef/jabref). And don't hesitate to open a (draft) pull request early on to show the direction it is heading towards. This way, you will receive valuable feedback.\n\nHappy coding! \uD83D\uDE80" ],
      "repository" : {
        "description" : "Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases",
        "homepage" : "https://www.jabref.org",
        "name" : "jabref",
        "fullName" : "JabRef/jabref",
        "htmlUrl" : "https://github.com/JabRef/jabref",
        "gitUrl" : "git://github.com/JabRef/jabref.git",
        "sshUrl" : "git@github.com:JabRef/jabref.git",
        "cloneUrl" : "https://github.com/JabRef/jabref.git",
        "owner" : {
          "login" : "JabRef",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 2881,
        "stargazersCount" : 3953,
        "watchersCount" : 3953,
        "size" : 249443,
        "openIssuesCount" : 578,
        "subscribersCount" : 112,
        "pushedAt" : "2025-07-24T20:20:03Z",
        "languages" : {
          "PowerShell" : 2037,
          "Java" : 11269860,
          "CSS" : 74176,
          "TeX" : 758587,
          "AppleScript" : 1721,
          "XSLT" : 151843,
          "Just" : 1194,
          "Shell" : 9305,
          "Batchfile" : 637,
          "ANTLR" : 9176,
          "BibTeX Style" : 78034,
          "Ruby" : 507,
          "Python" : 22282
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Modify org.jabref.logic.quality.consistency.BibliographyConsistencyCheck to use a complete BibDatabaseContext instead of a list of entries and modify org.jabref.logic.quality.consistency.BibliographyConsistencyCheck#check to adhere to the mode",
      "validationOrRequirement" : "Required fields of BibLaTeX @online: org.jabref.model.entry.types.BiblatexEntryTypeDefinitions#ONLINE, get used to org.jabref.model.entry.types.BibtexEntryTypeDefinitions and org.jabref.model.entry.types.BiblatexEntryTypeDefinitions, one can get the required fields using org.jabref.model.entry.BibEntryType#getRequiredFields",
      "attemptedFixes" : "None mentioned in the description or comments.",
      "otherNotes" : "This issue is a good exercise to learn test-driven development and using a data model. It requires significant time investment and understanding of BibTeX and BibLaTeX. The issue includes hints and guidance for contributors.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408011
  }, {
    "issueDTO" : {
      "id" : 3006339908,
      "title" : "Track of Runnable Examples",
      "url" : "https://github.com/kubeedge/ianvs/issues/194",
      "repositoryName" : "kubeedge/ianvs",
      "description" : "This issue serves to track the runnable examples in the latest release of Ianvs.\n\nIanvs includes a wide range of examples showcasing its benchmarking capabilities.\nSo far, I have verified the following examples as runnable and also updated their quick-start documentation guide for easy setup with no errors:\n\n- [ ] MOT17/multiedge_inference_bench  \n- [ ] aoa/single_task_bench  \n- [ ] bdd/lifelong_learning_bench  \n- [ ] cifar100/fci_ssl  \n- [ ] cifar100/federated_class_incremental_learning  \n- [ ] cifar100/federated_learning  \n- [ ] cifar100/sedna_federated_learning  \n- [ ] cityscapes/lifelong_learning_bench  \n- [ ] cityscapes/singletask_learning_bench  \n- [ ] cityscapes-synthia/lifelong_learning_bench  \n- [ ] cityscapes-synthia/scene-based-unknown-task-recognition  \n- [x] cloud-edge-collaborative-inference-for-llm\n- [ ] government/singletask_learning_bench  \n- [ ] imagenet/multiedge_inference_bench  \n- [ ] llm-agent/singletask_learning_bench  \n- [ ] llm-edge-benchmark-suite/single_task_bench  \n- [ ] llm-edge-benchmark-suite/single_task_bench_with_compression  \n- [ ] llm_simple_qa\n- [ ] pcb-aoi/incremental_learning_bench  \n- [x] pcb-aoi/singletask_learning_bench  \n- [ ] robot/lifelong_learning_bench  \n- [ ] robot-cityscapes-synthia/lifelong_learning_bench  \n- [ ] smart_coding/smart_coding_learning_bench  \n- [ ] yaoba/singletask_learning_boost  \n- [ ] yaoba/singletask_learning_yolox_tta\n\n\nI'll continue updating this list as I verify that the other examples work correctly and update their quick-start documentation as needed.",
      "updatedAt" : 1753358303.000000000,
      "user" : "AryanNanda17",
      "userHtmlUrl" : "https://github.com/AryanNanda17",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/125150482?v=4",
      "labels" : [ "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "I have updated the documentation and verified the installation process for [PCB-AOI Single-Task Learning example](https://github.com/kubeedge/ianvs/tree/main/examples/pcb-aoi). The PRs [#174](https://github.com/kubeedge/ianvs/pull/174), [#182](https://github.com/kubeedge/ianvs/pull/182), [#171](https://github.com/kubeedge/ianvs/pull/171) resolve the path errors and dependency conflicts for this example. ", "I have updated the quick-start guide of [cloud-edge-collaborative-inference-for-llm](https://github.com/kubeedge/ianvs/tree/main/examples/cloud-edge-collaborative-inference-for-llm) example in PR #188. \nAlso, the PR #191, replaces the `PCB-AOI` related content with `cloud-edge-collaborative-inference-for-LLM` example. ", "@MooreZheng\n\nHi there,\nThanks for all the updates! Could you help me figure out which benchmark examples are still left to verify? I want to work on the ones that haven???t been tested or documented yet.", "> [@MooreZheng](https://github.com/MooreZheng)\n> \n> Hi there, Thanks for all the updates! Could you help me figure out which benchmark examples are still left to verify? I want to work on the ones that haven???t been tested or documented yet.\n\nAs far as I am concerned, the list at the top is already the latest one. If there is any news from our members, please let us know @AryanNanda17 @FuryMartin ", "@MooreZheng \n\nI???ve done a review of the repo and noticed there are still several documentation and example-related tasks left to complete, including:\n\n- Writing quick-start READMEs for new or untouched example folders (e.g., benchmark_ci_pipeline/, keink_simulation/, kepler_power_bench/, mscoco/lifelong_learning_bench/, t4rec_mllib/, widerface/edge_detection_bench)\n\n- Ensuring ianvs -f testenv.yaml works smoothly on CPU-only hosts for each example, and listing all required datasets/model weights with updated mirror links\n\n- Adding how-to-build-dataset guides for new datasets and troubleshooting FAQs, especially for simulation environments\n\n- Improving environment setup scripts to cover ROCm/CPU-only, adding a matrix of tested OS/Python/CUDA setups, and documenting offline installation for air-gapped nodes\n\n- Creating missing hyper-parameter sweep templates and documentation (examples/_template/hpo)\n\n- Providing clear CI integration steps (e.g., guidelines for adding examples to GitHub Actions workflows)\n\n- Explaining the leaderboard result schema and reporting process in the docs\n\n- Documenting edge-device resource profiling for recent LLM-related demos and including sample power traces\n\n- Adding demo clips or screenshots to video-based example READMEs to clarify expected results\n\n- Translating documentation that's only available in Chinese into English, especially for smart_coding and yaoba/*\n\n- Updating dataset mirrors to avoid timeouts and including backup links or procedures\n\n- Adding version-tag information to clarify which release each example was first verified in\n\nWould it be helpful if I start working on these areas? Please let me know if I should begin tackling any specific tasks from this list, or if there are priorities I should focus on first.\n\nThanks!", "> [@MooreZheng](https://github.com/MooreZheng)\n> \n> I???ve done a review of the repo and noticed there are still several documentation and example-related tasks left to complete, including:\n> \n> * Writing quick-start READMEs for new or untouched example folders (e.g., benchmark_ci_pipeline/, keink_simulation/, kepler_power_bench/, mscoco/lifelong_learning_bench/, t4rec_mllib/, widerface/edge_detection_bench)\n> * Ensuring ianvs -f testenv.yaml works smoothly on CPU-only hosts for each example, and lists all required datasets/model weights with updated mirror links\n> * Adding how-to-build-dataset guides for new datasets and troubleshooting FAQs, especially for simulation environments\n> * Improving environment setup scripts to cover ROCm/CPU-only, adding a matrix of tested OS/Python/CUDA setups, and documenting offline installation for air-gapped nodes\n> * Creating missing hyper-parameter sweep templates and documentation (examples/_template/hpo)\n> * Providing clear CI integration steps (e.g., guidelines for adding examples to GitHub Actions workflows)\n> * Explaining the leaderboard result schema and reporting process in the docs\n> * Documenting edge-device resource profiling for recent LLM-related demos and including sample power traces\n> * Adding demo clips or screenshots to video-based example READMEs to clarify expected results\n> * Translating documentation that's only available in Chinese into English, especially for smart_coding and yaoba/*\n> * Updating dataset mirrors to avoid timeouts and including backup links or procedures\n> * Adding version-tag information to clarify which release each example was first verified in\n> \n> Would it be helpful if I start working on these areas? Please let me know if I should begin tackling any specific tasks from this list, or if there are priorities I should focus on first.\n> \n> Thanks!\n\nGood to learn about your progress. My suggestion would be to focus on examples one by one and fix the issue when executing the example. Higher priority should be given to those bugs that would affect the example execution, and make sure examples are runnable.  ", "@MooreZheng \n\nI will work on the following examples first\n\n- MOT17/multiedge_inference_bench\n\n- aoa/single_task_bench\n\n- bdd/lifelong_learning_bench\n\nDO tell me if I need to have somethig in my mind before I start working on them \n", "@MooreZheng I just wanted to ask whether I just have to add documentation for the features I have listed above, do I have to implement them too?\n" ],
      "repository" : {
        "description" : "Distributed Synergy AI Benchmarking",
        "homepage" : "https://ianvs.readthedocs.io",
        "name" : "ianvs",
        "fullName" : "kubeedge/ianvs",
        "htmlUrl" : "https://github.com/kubeedge/ianvs",
        "gitUrl" : "git://github.com/kubeedge/ianvs.git",
        "sshUrl" : "git@github.com:kubeedge/ianvs.git",
        "cloneUrl" : "https://github.com/kubeedge/ianvs.git",
        "owner" : {
          "login" : "kubeedge",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 68,
        "stargazersCount" : 142,
        "watchersCount" : 142,
        "size" : 133816,
        "openIssuesCount" : 46,
        "subscribersCount" : 7,
        "pushedAt" : "2025-07-22T13:02:57Z",
        "languages" : {
          "Python" : 198074
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to track and document the runnable examples in the latest release of Ianvs, and to ensure that they are correctly verified and documented.",
      "validationOrRequirement" : "The issue requires verifying and documenting the examples, ensuring that they are runnable and have correct quick-start documentation. The author suggests focusing on examples one by one and fixing the issue when executing the example, with higher priority given to those bugs that would affect the example execution.",
      "attemptedFixes" : "The author has already verified and updated the quick-start documentation guide for some examples, and the PRs #174, #182, #171 resolve the path errors and dependency conflicts for the PCB-AOI Single-Task Learning example. The author has also updated the quick-start guide of the cloud-edge-collaborative-inference-for-llm example in PR #188, and replaced the PCB-AOI related content with the cloud-edge-collaborative-inference-for-LLM example in PR #191.",
      "otherNotes" : "The issue is about tracking runnable examples in the latest release of Ianvs, with a focus on verifying and documenting the examples. There are still several documentation and example-related tasks left to complete, including writing quick-start READMEs, ensuring testenv.yaml works smoothly, adding how-to-build-dataset guides, and more.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408020
  }, {
    "issueDTO" : {
      "id" : 3239062046,
      "title" : "Cannot upload a firmware for ESP32-C3 with a flash memory 16MB",
      "url" : "https://github.com/nanoframework/Home/issues/1656",
      "repositoryName" : "nanoframework/Home",
      "description" : "### Tool\n\nnanoff\n\n### Description\n\nWhen I tried to flash a firmware for either the **ESP32_C3_REV3** or **XIAO_ESP32C3** target, the process has been ended with an error E4003:\n\n```\nPS C:\\WINDOWS\\system32> nanoff --target ESP32_C3_REV3 --serialport COM17 --update --masserase\n.NET nanoFramework Firmware Flasher v2.5.126+716b21797a\nCopyright (C) 2019 .NET Foundation and nanoFramework project contributors\n\nReading details from chip...OK                                                                                    \n                        \nConnected to:\nESP32-C3 (ESP32-C3 (QFN32) (revision v0.4))\nFeatures WiFi, BLE\nFlash size 16MB W25Q128_V from WINBOND_NEX (manufacturer 0x239 device 0x16408)\nPSRAM: not available\nCrystal 40MHz\nMAC 24:EC:4A:E6:56:04\n\nExtracting ESP32_C3_REV3-1.12.4.289.zip...OK\n\nUpdating to 1.12.4.289\n\nErasing flash...OK                                                                                                \n            \nFlashing firmware...\nError E4003: Failed to write new firmware to ESP32. (\n...\nesptool write_flash: error: argument <address> <filename>: [Errno 2] No such file or directory: 'C:\\\\Users\\\\rkiss\\\n\\.nanoFramework\\\\fw_cache\\\\ESP32_C3_REV3\\\\partitions_16mb.bin'\n)\n```\n\nIt looks like, the firmware package **ESP32_C3_REV3-1.12.4.289.zip** included only images for 2MB and 4MB, so there are missing the images for 8MB and 16MB.\n\n### How to reproduce\n\n_No response_\n\n### Expected behaviour\n\n_No response_\n\n### Screenshots\n\n_No response_\n\n### Aditional context\n\n_No response_",
      "updatedAt" : 1753358185.000000000,
      "user" : "romankiss",
      "userHtmlUrl" : "https://github.com/romankiss",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/30365471?v=4",
      "labels" : [ "trivial", "Area: Targets-ESP32", "good first issue", "up-for-grabs", "Area: Config-and-Build" ],
      "state" : "OPEN",
      "comments" : [ "@AdrianSoundy  please could you look at into this issue? It looks like only the ESP32-C3 targets has this issue:\n\n **ESP32_C3_REV3-1.12.4.372.zip** included the following files:\n\n<img width=\"325\" height=\"293\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/021d7f67-8c58-4119-b19b-4e7d58429e53\" />\n\n\nbut the others targets, for instance, **ESP32_S3-1.12.4.372.zip:** \n\n<img width=\"346\" height=\"422\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/d633aa35-678a-4309-8b80-07729a7763e3\" />\n\nWhy the ESP32-C3 flash memory is limited for 4MB size?\n \nThanks" ],
      "repository" : {
        "description" : ":house: The landing page for .NET nanoFramework repositories.",
        "homepage" : "https://www.nanoframework.net",
        "name" : "Home",
        "fullName" : "nanoframework/Home",
        "htmlUrl" : "https://github.com/nanoframework/Home",
        "gitUrl" : "git://github.com/nanoframework/Home.git",
        "sshUrl" : "git@github.com:nanoframework/Home.git",
        "cloneUrl" : "https://github.com/nanoframework/Home.git",
        "owner" : {
          "login" : "nanoframework",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 84,
        "stargazersCount" : 898,
        "watchersCount" : 898,
        "size" : 201660,
        "openIssuesCount" : 84,
        "subscribersCount" : 50,
        "pushedAt" : "2025-07-07T12:52:49Z",
        "languages" : { },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to be able to upload a firmware for ESP32-C3 with a 16MB flash memory.",
      "validationOrRequirement" : "The issue is related to the ESP32-C3 target with 16MB flash memory, and the firmware package not including images for this size.",
      "attemptedFixes" : "No attempts or blockers mentioned in the issue description or comments.",
      "otherNotes" : "The issue seems to be related to the firmware package not including images for 16MB flash memory, which is only available for ESP32_C3 targets.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408024
  }, {
    "issueDTO" : {
      "id" : 3209215377,
      "title" : "Color all stars before the star the user is hovering on when rating agent performance",
      "url" : "https://github.com/All-Hands-AI/OpenHands/issues/9584",
      "repositoryName" : "All-Hands-AI/OpenHands",
      "description" : "**What problem or use case are you trying to solve?**\nWhen rating the agent???s performance, we only color the star we are hovering on. It is more standard to color the star the user is hovering on as well as the stars before it.\n\n\n**Describe the UX or technical implementation you have in mind**\n\n**Additional context**\n\n\n### If you find this feature request or enhancement useful, make sure to add a \uD83D\uDC4D to the issue\n",
      "updatedAt" : 1753358106.000000000,
      "user" : "amanape",
      "userHtmlUrl" : "https://github.com/amanape",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/83104063?v=4",
      "labels" : [ "enhancement", "good first issue", "OH UI/UX" ],
      "state" : "OPEN",
      "comments" : [ "@amanape As I am a newbie - could you point me to how to rate an agent's performance? I searched the docs but couldn't find any reference to this.", "Hi @michaldorsett when running OpenHands locally, there are  \uD83D\uDC4D and \uD83D\uDC4E buttons that allow you to rate it that way.\nOn OpenHands Cloud, after the agent performs a task, a 5 star rating system appears that you can rate it that way." ],
      "repository" : {
        "description" : "\uD83D\uDE4C OpenHands: Code Less, Make More",
        "homepage" : "https://all-hands.dev",
        "name" : "OpenHands",
        "fullName" : "All-Hands-AI/OpenHands",
        "htmlUrl" : "https://github.com/All-Hands-AI/OpenHands",
        "gitUrl" : "git://github.com/All-Hands-AI/OpenHands.git",
        "sshUrl" : "git@github.com:All-Hands-AI/OpenHands.git",
        "cloneUrl" : "https://github.com/All-Hands-AI/OpenHands.git",
        "owner" : {
          "login" : "All-Hands-AI",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 7213,
        "stargazersCount" : 61105,
        "watchersCount" : 61105,
        "size" : 218181,
        "openIssuesCount" : 397,
        "subscribersCount" : 420,
        "pushedAt" : "2025-07-24T22:47:02Z",
        "languages" : {
          "TypeScript" : 1472971,
          "Dockerfile" : 8120,
          "Shell" : 116789,
          "Jinja" : 80292,
          "CSS" : 8337,
          "Makefile" : 15534,
          "JavaScript" : 34600,
          "HTML" : 1849,
          "Python" : 5163132
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to enhance the user experience by coloring all stars before the star the user is hovering on when rating agent performance.",
      "validationOrRequirement" : "The requirement is to color the star the user is hovering on as well as the stars before it, which is considered a standard practice.",
      "attemptedFixes" : "No specific fixes are mentioned in the comments, but the author suggests that the issue might be related to the documentation, and the commenter provides information on how to rate an agent's performance in OpenHands.",
      "otherNotes" : "The issue is related to the UX/UI of the rating system, with a focus on coloring stars before the hovered one when rating agent performance.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408029
  }, {
    "issueDTO" : {
      "id" : 3144702355,
      "title" : "Clean up circular dependencies around the kubelet's admitHandlers and the container runtime",
      "url" : "https://github.com/kubernetes/kubernetes/issues/132298",
      "repositoryName" : "kubernetes/kubernetes",
      "description" : "Basically, this TODO:\n\nhttps://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/allocation/allocation_manager.go#L71\n\nThe reason that we have `AddPodAdmitHandlers` as a separate method for the allocation manager as opposed to just passing in the admit handers into the constructor is because of some circular dependencies:\n\n### shutdown manager and probe manager\n- Construction of the [container runtime](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L750) depends on the [allocation manager](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L779).\n- One of the [allocation manager's handlers](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L1041) depends on the shutdown manager.\n- The shutdown manager depends on the [probe manager](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L1024).\n- The probe manager depends on the [container runtime](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L913).\n\npotential resolution: it doesn't look like the shutdown manager uses the probe manager for anything, so that dependency in the shutdown manager can be removed, thus removing the dependency cycle.\n\n### shutdown manager and volume manager\n- Construction of the container runtime depends on the allocation manager.\n- One of the allocation manager's handlers depends on the [shutdown manager].\n- The shutdown manager depends on the [volume manager](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L1025).\n- The volume manager depends on the [container runtime](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L954).\n\npotential resolution: it doesn't look like the volume manager uses the container runtime for anything, so that dependency in the volume manager can likewise be removed, removing the dependency cycle. \n\n### eviction manager and image manager\n- Construction of the [image manager](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L874) depends on the container runtime.\n- Construction of the container runtime depends on the allocation manager. \n- One of the [allocation manager's handlers] depends on the [eviction manager](https://github.com/kubernetes/kubernetes/blob/77bd3f89fbc389d5dfebbed880e08a1e4949312c/pkg/kubelet/kubelet.go#L969). \n- The eviction manager depends on the image manager.\n\npotential resolution: ??? \n\nThis isn't a huge issue, but in general this a symptom of the kubelet code being filled with bloated and circular dependencies. It makes the code hard to work with. There are probably more that I haven't listed here, but didn't fully dive into it.\n\n(Also noting that me saying \"x is not used for anything\" is just based on a quick search so I could be wrong - a more thorough search is needed.)\n\n/sig node\n/kind cleanup\n/triage accepted\n/priority important-longterm\n",
      "updatedAt" : 1753357990.000000000,
      "user" : "natasha41575",
      "userHtmlUrl" : "https://github.com/natasha41575",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/16629434?v=4",
      "labels" : [ "sig/node", "priority/important-longterm", "kind/cleanup", "help wanted", "triage/accepted", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "/help\n/good first issue", "@natasha41575: \n\tThis request has been marked as needing help from a contributor.\n\n### Guidelines\nPlease ensure that the issue body includes answers to the following questions:\n- Why are we solving this issue?\n- To address this issue, are there any code changes? If there are code changes, what needs to be done in the code and what places can the assignee treat as reference points?\n- How can the assignee reach out to you for help?\n\n\nFor more details on the requirements of such an issue, please see [here](https://www.kubernetes.dev/docs/guide/help-wanted/) and ensure that they are met.\n\nIf this request no longer meets these requirements, the label can be removed\nby commenting with the `/remove-help` command.\n\n\n<details>\n\nIn response to [this](https://github.com/kubernetes/kubernetes/issues/132298):\n\n>/help\n>/good first issue\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes-sigs/prow](https://github.com/kubernetes-sigs/prow/issues/new?title=Prow%20issue:) repository.\n</details>", "/good-first-issue", "@natasha41575: \n\tThis request has been marked as suitable for new contributors.\n\n### Guidelines\nPlease ensure that the issue body includes answers to the following questions:\n- Why are we solving this issue?\n- To address this issue, are there any code changes? If there are code changes, what needs to be done in the code and what places can the assignee treat as reference points?\n- How can the assignee reach out to you for help?\n\n\nFor more details on the requirements of such an issue, please see [here](https://www.kubernetes.dev/docs/guide/help-wanted/#good-first-issue) and ensure that they are met.\n\nIf this request no longer meets these requirements, the label can be removed\nby commenting with the `/remove-good-first-issue` command.\n\n\n<details>\n\nIn response to [this](https://github.com/kubernetes/kubernetes/issues/132298):\n\n>/good-first-issue\n\n\nInstructions for interacting with me using PR comments are available [here](https://git.k8s.io/community/contributors/guide/pull-requests.md).  If you have questions or suggestions related to my behavior, please file an issue against the [kubernetes-sigs/prow](https://github.com/kubernetes-sigs/prow/issues/new?title=Prow%20issue:) repository.\n</details>", "/assign", "/cc", "I agree with the issue, thanks for filing it up! Refactoring and cleaning up is likely to require some back and forth with community/reviewers to figure out a good way forward", "> Refactoring and cleaning up is likely to require some back and forth with community/reviewers to figure out a good way forward\n\n+1, cleaning up everything will definitely require a lot of discussion. But I think there is some low hanging fruit with the particular TODO I mentioned in this issue (just removing unused dependencies) that can be done quickly and easily.\n\nTo external contributors: feel free to submit PRs that only address the smaller things.", "> feel free to submit PRs that only address the smaller things.\n\n@natasha41575 I noticed that there is still no related PR for this. Could I take this on and work on it?", "/assign", "/assign", "/assign", "@natasha41575 \nHi, I've noticed that there are two PRs fixed the first two circular dependencies mentioned. I am a newcomer who want to contribute to the community. Is there any hints for the thirds circular dependencies(**eviction manager and image manager**)?\nThanks!", "Hello @natasha41575 , I have investigated the third circular depedency and had a rough solution idea wanna some discussion: \n- Remove `Admit` function from evictionManager (The inspiration is that 'evition' should happen after a pod is created, so evictionManager should not use `Admit` to prevent a pod from creating)\n- Write a new admissionManager-like class using the previous removed `Admit` function\n- Put the newly added admissionManager in the place previously using `evictionManager` when initializing kubelet.\n\nIn your opinion, is my implementation plan reasonable? ", "/assign", "/unassign", "/assign\n", "Hi @natasha41575 and everyone,\n\nI'm new to the Kubernetes project and would love to contribute to this cleanup effort.\n\nI saw the third circular dependency between the `evictionManager` and `imageManager` is still under discussion, and I???d be happy to explore and help out there. Is it still open for contribution?\n\nAlso, @ylink-lfs???s proposed idea of separating `Admit` into a new component sounds promising. I???d love to understand the current direction and whether I can help with code, refactoring, or testing.\n\nPlease let me know how I can best contribute here ??? excited to get involved!\n", "Hi @natasha41575 and team,\n\nI???m a new contributor to Kubernetes and interested in tackling the circular dependency between the eviction manager and image manager. I???ve reviewed @ylink-lfs???s proposed solution and would like to contribute to it or explore other approaches. Is this still open for contribution? Any specific guidance or references for getting started would be appreciated!\n" ],
      "repository" : {
        "description" : "Production-Grade Container Scheduling and Management",
        "homepage" : "https://kubernetes.io",
        "name" : "kubernetes",
        "fullName" : "kubernetes/kubernetes",
        "htmlUrl" : "https://github.com/kubernetes/kubernetes",
        "gitUrl" : "git://github.com/kubernetes/kubernetes.git",
        "sshUrl" : "git@github.com:kubernetes/kubernetes.git",
        "cloneUrl" : "https://github.com/kubernetes/kubernetes.git",
        "owner" : {
          "login" : "kubernetes",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 41013,
        "stargazersCount" : 116497,
        "watchersCount" : 116497,
        "size" : 1388910,
        "openIssuesCount" : 2502,
        "subscribersCount" : 3212,
        "pushedAt" : "2025-07-25T00:59:14Z",
        "languages" : {
          "PowerShell" : 147503,
          "Dockerfile" : 45190,
          "Shell" : 1972289,
          "C" : 4205,
          "sed" : 1262,
          "Batchfile" : 833,
          "Makefile" : 64132,
          "Go" : 80356579,
          "HTML" : 106,
          "Python" : 18353
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to clean up circular dependencies in the kubelet code, specifically around the admitHandlers and the container runtime, to make the code easier to work with and reduce complexity.",
      "validationOrRequirement" : "The issue requires code changes and refactoring, and the assignee should ensure that the issue body includes answers to the following questions: Why are we solving this issue? To address this issue, are there any code changes? If there are code changes, what needs to be done in the code and what places can the assignee treat as reference points? How can the assignee reach out to the author for help?",
      "attemptedFixes" : "The first two circular dependencies were fixed with PRs, but the third one is still open for contribution. @ylink-lfs proposed an idea of separating the Admit function into a new component, and new contributors are welcome to explore and help out.",
      "otherNotes" : "This issue is about cleaning up circular dependencies in the kubelet code, specifically around the admitHandlers and the container runtime. The issue is marked as needing help from a contributor and is suitable for new contributors. There are potential resolutions for the first two circular dependencies, but the third one is still under discussion.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408037
  }, {
    "issueDTO" : {
      "id" : 1758410712,
      "title" : "Prefer the usage of Duplicate instead of Copy in all the modules",
      "url" : "https://github.com/decidim/decidim/issues/11043",
      "repositoryName" : "decidim/decidim",
      "description" : "### Describe the bug\n\nWhen I go to duplicate a Conference as an admin, I see that we're using the \"copy\" terminology or the \"duplicate\" term indistinctly. \r\n\n\n### To Reproduce\n\n1. Sign in as admin\r\n2. Go to the Conferences page in the admin panel\r\n3. Click on the \"Duplicate\" button on any conference\r\n4. See the error\n\n### Expected behavior\n\nTo always use the same term. We agreed that \"Duplicate\" is clearer. This would mean that we also need to change the code, at least:\r\n\r\n* decidim-conferences/app/commands/decidim/conferences/admin/copy_conference.rb\r\n* decidim-conferences/app/forms/decidim/conferences/admin/conference_copy_form.rb\r\n* decidim-conferences/spec/commands/copy_conference_spec.rb\r\n* decidim-conferences/spec/shared/copy_conferences_examples.rb\r\n* decidim-templates/app/commands/decidim/templates/admin/copy_questionnaire_template.rb\r\n\n\n### Screenshots\n\n\r\n![Screenshot of the \"Duplicate conference\" page](https://github.com/decidim/decidim/assets/717367/7e8398ca-f4cd-4eaf-ad45-f97a0d297157)\r\n\n\n### Stacktrace\n\n_No response_\n\n### Extra data\n\n\r\n- Decidim Version: 0.28.0.dev\r\n- Decidim installation: Nightly\r\n\n\n### Additional context\n\n\r\nAlso I'm talking about Conferences but this also applies to other spaces (like Processes at least). We should change it in all of these in Spaces and also in the Components/Features that have this same pattern/form/etc. This is what I've come up with a quick search:\r\n\r\n* decidim-assemblies/app/commands/decidim/assemblies/admin/copy_assembly.rb\r\n* decidim-assemblies/app/forms/decidim/assemblies/admin/assembly_copy_form.rb\r\n* decidim-conferences/app/commands/decidim/conferences/admin/copy_conference.rb\r\n* decidim-conferences/app/forms/decidim/conferences/admin/conference_copy_form.rb\r\n* decidim-meetings/app/commands/decidim/meetings/admin/copy_meeting.rb\r\n* decidim-pages/app/commands/decidim/pages/copy_page.rb\r\n* decidim-participatory_processes/app/commands/decidim/participatory_processes/admin/copy_participatory_process.rb\r\n* decidim-participatory_processes/app/forms/decidim/participatory_processes/admin/participatory_process_copy_form.rb\r\n* ",
      "updatedAt" : 1753357936.000000000,
      "user" : "andreslucena",
      "userHtmlUrl" : "https://github.com/andreslucena",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/717367?v=4",
      "labels" : [ "type: bug", "module: assemblies", "module: conferences", "module: participatory processes", "module: pages", "good first issue", "module: meetings" ],
      "state" : "OPEN",
      "comments" : [ "A quick tip, for doing this kind of refactors is always good to use `git mv` so it can respect the git file history ", "Hello ! I would like to contribute to this project, and I think that this issue is a good starting point. Is it still an active issue?", "> Hello ! I would like to contribute to this project, and I think that this issue is a good starting point. Is it still an active issue?\n\nIf you want to give it a crack @blastoncrush feel free to create a PR!", "@andreslucena this is completed as per #14993. I would recommend with PR's which require renaming and replacing the code base in the case of Decidim, is completing them module by module (PR 14XXXX proposals etc)\n\nOtherwise you'll be reviewing PR's sometimes as we've in the maintainers team seen in the past, with 100+ pages to review which can cause time constraints and confusion. ", "@greenwoodt I'm reopening this one because I'm just too lazy to open a new one \uD83D\uDE05 \n\nCan you do the renaming in the other modules \uD83D\uDE4F\uD83C\uDFFD ? If you want you can do a PR for module. Thanks!!" ],
      "repository" : {
        "description" : "The participatory democracy framework. A generator and multiple gems made with Ruby on Rails",
        "homepage" : "https://decidim.org/",
        "name" : "decidim",
        "fullName" : "decidim/decidim",
        "htmlUrl" : "https://github.com/decidim/decidim",
        "gitUrl" : "git://github.com/decidim/decidim.git",
        "sshUrl" : "git@github.com:decidim/decidim.git",
        "cloneUrl" : "https://github.com/decidim/decidim.git",
        "owner" : {
          "login" : "decidim",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 430,
        "stargazersCount" : 1602,
        "watchersCount" : 1602,
        "size" : 295144,
        "openIssuesCount" : 447,
        "subscribersCount" : 57,
        "pushedAt" : "2025-07-24T19:04:26Z",
        "languages" : {
          "Dockerfile" : 205,
          "Shell" : 49,
          "SCSS" : 270197,
          "JavaScript" : 822192,
          "HTML" : 1848390,
          "Ruby" : 13265719
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Prefer the usage of Duplicate instead of Copy in all the modules, to ensure consistency and clarity.",
      "validationOrRequirement" : "Use the term 'Duplicate' consistently instead of 'Copy' in all modules, and rename and replace code accordingly.",
      "attemptedFixes" : "No specific fixes mentioned in the issue description, but a comment suggests renaming and replacing code in the Decidim project, possibly in modules.",
      "otherNotes" : "The issue applies to multiple modules: assemblies, conferences, meetings, pages, and participatory processes. A contributor has expressed interest in contributing to this issue.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408041
  }, {
    "issueDTO" : {
      "id" : 3151872238,
      "title" : "2025 Spring AI Alibaba ????????????/????????????",
      "url" : "https://github.com/alibaba/spring-ai-alibaba/issues/1251",
      "repositoryName" : "alibaba/spring-ai-alibaba",
      "description" : "### Description\n\n??????????????????????????????Spring AI Alibaba???Jmanus?????????<font style=\"color:rgb(31, 35, 40);\">????????????????????????????????????Spring AI Alibaba/Jmanus?????????????????????????????????????????????????????????Spring AI Alibaba/Jmanus?????????????????????????????????????????????????????????</font>\n\n## ????????????:\n1.???????????????????????????????????????????????????????????????CSDN?????????????????????B?????????????????????????????????\n2.???**????????????**?????????/???????????????????????? issue ?????????????????????????????????????????????7?????????????????????7?????????????????????????????????????????????????????????????????????\n3.???????????????????????????[????????????????????????](https://survey.aliyun.com/apps/zhiliao/aX4Z_BS8a)\n\n\n## ????????????\n1. ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????T????????????\n2. ??????????????????2???????????????????????????????????????????????????????????????????????????????????????????????????????????????/???????????????????????????????????????????????????2?????????????????????????????????????????????????????????\n\n\n## <font style=\"color:rgb(31, 35, 40);\">??????????????????</font>\n+ <font style=\"color:rgb(31, 35, 40);\">??????????????????????????????????????????????????????</font>\n+ <font style=\"color:rgb(31, 35, 40);\">????????????????????????????????????</font>\n+ <font style=\"color:rgb(31, 35, 40);\">??????????????????????????????????????????????????????</font>\n\n",
      "updatedAt" : 1753357749.000000000,
      "user" : "chickenlj",
      "userHtmlUrl" : "https://github.com/chickenlj",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18097545?v=4",
      "labels" : [ "area/community", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Spring ai alibaba????????????????????????https://github.com/GTyingzi/spring-ai-tutorial\nSpring ai alibaba????????????????????????https://mp.weixin.qq.com/s/sKBum3MHMd24cMlW8z9NCA\nSpring ai alibaba??????????????????https://www.bilibili.com/video/BV17NMsziEqp?spm_id_from=333.788.videopod.sections&vd_source=8393ba8b4463e2acda959f2ff2c792f6", "Spring ai alibaba???????????????????????????https://github.com/lzb240082240/spring-ai-hospital-appointment-clientele-services", "?????????????????????T???\uD83D\uDE1D\n??????spring-ai-alibaba???????????????RAG???????????????https://blog.csdn.net/weixin_49244783/article/details/148747645", "??????Spring-AI-Alibaba???OpenDeepWiki????????? https://github.com/D1nvan/JDeepWiki", "??????Spring-AI-Alibaba????????????????????????https://github.com/zxuexingzhijie/spring-ai-alibaba-examples/tree/main/spring-ai-alibaba-translate-example", "5?????????????????????McpTool??????????????????????????????https://mp.weixin.qq.com/s/Ax-pr3rgHbL8KSu8RAHCLQ", "Spring AI Alibaba Graph ?????? https://blog.csdn.net/qq_52397471/article/details/148660511 ", " spring AI Alibaba ?????????????????? ChatBot  [https://blog.csdn.net/weixin_50309827/article/details/148734113](https://blog.csdn.net/weixin_50309827/article/details/148734113)", ".SpringAIAlibaba+qwen????????????????????????????????????:\n?????????https://www.yuque.com/geren-t8lyq/ncgl94/yv5dnl8ohd7791n1?singleDoc# ???Spring AI Alibaba ???????????????????????????\n?????????https://www.bilibili.com/video/BV1C5UxYuEc2/\n\nJmanus??????\nhttps://www.bilibili.com/video/BV1vjKzziEC1", "??????????????????Spring AI Alibaba????????????????????????????????????RAG+Function Calling+MCP??????+????????????????????????\n????????????: https://www.processon.com/view/link/6810800f83d6ee240f5796b0?cid=67ff3b399346680abca00ff9\nB??????????????????\nhttps://www.bilibili.com/video/BV1aWE4z4Eow/?spm_id_from=333.1387.upload.video_card.click", "SpringBoot+Spring AI Alibaba??????RAG????????????: https://mp.weixin.qq.com/s/MO59zPv5OFtB01htIcIwwg", "Spring AI Alibaba + Nacos ?????? MCP Server ???????????????https://mp.weixin.qq.com/s/5dUY1lfACZnm5Ql-fiqnAQ", "???????????? Spring AI Alibaba ???NL2SQL????????????\n- https://datamining.blog.csdn.net/article/details/148768445\n- https://mp.weixin.qq.com/s/XBJ0JmJ4SMq5jbynqLYrMQ", "??????Spring AI Alibaba ???RAG??????????????????\n\n- https://github.com/luxiaobai007/springAIAlibabaRagQA\n- https://blog.csdn.net/weixin_45268711/article/details/148783089\n", "Spring AI Alibaba ????????????????????????????????????https://blog.csdn.net/sufu1065/article/details/148696485", "Spring AI ?????? PostgreSQL ???????????????RAG ????????????\nhttps://github.com/lsqlister/spring-ai-alibaba-rag-pgvector-jdbc-postgres", "Spring Ai Alibaba Graph???????????????????????????\n\n- https://blog.csdn.net/renpeng301/article/details/148877785\n- https://mp.weixin.qq.com/s/TdO8NUEKPculhVwimBbvdw\n- ?????????https://github.com/renpengben/effective-agent-spring-alibaba-graph\n", "Spring AI Alibaba JManus ???????????????????????????????????????[https://mp.weixin.qq.com/s/jArKpQjYz4gupEhf8LvQYA](https://mp.weixin.qq.com/s/jArKpQjYz4gupEhf8LvQYA)", "??????Spring AI Alibaba????????????????????????https://juejin.cn/spost/7520183736127635490", "Agent ?????????https://blog.csdn.net/sunyingboaini/article/details/148838902?spm=1001.2014.3001.5501\nRAG?????????https://blog.csdn.net/sunyingboaini/article/details/148282572?spm=1001.2014.3001.5501\nSpringAl?????????https://blog.csdn.net/sunyingboaini/article/details/147832050?spm=1001.2014.3001.5501", "?????????????????????T???\uD83D\uDE1D\n?????? Spring AI Alibaba ??????????????????????????? RAG ????????????????????????https://blog.csdn.net/2301_79969279/article/details/148951185", "Spring AI Alibaba JManus?????????https://juejin.cn/post/7520248971865112622", "Spring AI Alibaba Graph ?????? ???https://blog.csdn.net/a_ittle_pan/article/details/148951415", "??????????????????spring AI Alibaba ??????RAG????????????????????????????????????https://juejin.cn/spost/7520169104713662503\n????????????t?????????????????????", "Spring AI Alibaba??????AI Code Review?????????https://blog.csdn.net/qq_39911747/article/details/148952124", "Spring AI Alibaba Graph???????????????\nhttps://mp.weixin.qq.com/s/aIga0-YGoUrLRCLYe0u9fQ", "Spring AI Alibaba ??????????????????????????????????????????https://juejin.cn/post/7520328716082331682", "???Spring AI Alibaba ??? Jmanus???Java ???????????? AI ?????????????????????https://blog.csdn.net/qq_21267357/article/details/148954959?sharetype=blogdetail&sharerId=148954959&sharerefer=PC&sharesource=qq_21267357&spm=1011.2480.3001.8118", "??????Spring AI Alibaba NL2SQL????????????????????????: https://github.com/kaori-seasons/spring-ai-alibaba-nl2sql-examples\n\nSpring AI Alibaba??????????????????NL2SQL ---- ??????????????????????????????????????????: https://juejin.cn/post/7520448236315115558\n\nps:??????T???", "spring ai alibaba mcp?????? + ant design x????????????: https://juejin.cn/post/7520379793889067008", "???????????????ChatClient????????????https://blog.csdn.net/csynsgh/article/details/148955236", "??????spring-ai-alibaba????????????????????????????????????????????????https://blog.csdn.net/benbuben8/article/details/148955813?sharetype=blogdetail&sharerId=148955813&sharerefer=PC&sharesource=benbuben8&spm=1011.2480.3001.8118", "?????????????????????Spring AI Alibaba???????????????????????????????????????????????? https://blog.csdn.net/VLSMB/article/details/148956485?sharetype=blogdetail&sharerId=148956485&sharerefer=PC&sharesource=VLSMB&spm=1011.2480.3001.8118", "????????????????????????????????????", "???????????? Spring Cloud Alibaba AI ????????????: https://blog.csdn.net/qq_52397471/article/details/138356672", "SpringCloud Alibaba AI??????DeepSeek??????AI???????????????https://developer.aliyun.com/article/1653771", "SpringAI??????????????????json???????????????https://blog.csdn.net/qq_51864596/article/details/148975367?spm=1011.2415.3001.5331", "Spring-AI-Alibaba??????????????????Streamable-http MCP Server): \nhttps://blog.csdn.net/linguiben/article/details/148975309?spm=1018.2226.3001.4187", "??????Spring AI Alibaba???https://blog.csdn.net/weixin_63945098/article/details/148973543", "??????Spring-AI-Alibaba?????????AI?????????https://github.com/zhaoxi7109/aihelper\nhttps://blog.csdn.net/qq_51106567/article/details/148983414?spm=1011.2415.3001.5331", "???????????????https://blog.csdn.net/MuShan_bit/article/details/148984139", "Spring AI Alibaba Model Context Protocol ???????????????????????????AI??????\nhttps://github.com/javaeege/spring-ai-alibaba-ollama-mcp-weather-webflux", "Spring AI Alibaba Nacos ???????????? : https://blog.csdn.net/weixin_44754533/article/details/148996636?spm=1011.2415.3001.10575&sharefrom=mp_manage_link", "Spring AI Alibaba Graph???????????????https://blog.csdn.net/weixin_46246673/article/details/149000117?spm=1001.2014.3001.5501", "9.41 ????????????????????????????????????AI????????????spring ai alibaba openman... https://v.douyin.com/9fxbBzqM8FQ/ NJI:/ L@j.Cu 11/20 ", "spring AI Alibaba Graph ???????????? https://blog.csdn.net/m0_63798859/article/details/149065264?sharetype=blogdetail&sharerId=149065264&sharerefer=PC&sharesource=m0_63798859&spm=1011.2480.3001.8118", "?????? https://[mp.weixin.qq.com/s/XpsWl36lDCZDR2-Z2mMOlw](https://mp.weixin.qq.com/s/XpsWl36lDCZDR2-Z2mMOlw)", "Observation???????????????????????????Spring AI Alibaba??????LangFuse??????????????? https://blog.csdn.net/m0_63798859/article/details/149094224?sharetype=blogdetail&sharerId=149094224&sharerefer=PC&sharesource=m0_63798859&spm=1011.2480.3001.8118", "??????Spring AI Alibaba???????????????RAG??????\n??????Spring AI Alibaba workflow???graph???????????????????????????????????????????????????\nhttps://blog.csdn.net/qq_41508508/article/details/149117494", "spring-ai-alibaba ?????????????????????7????????????????????????\n1.??????  https://blog.csdn.net/u011648768/article/details/148961160?spm=1001.2014.3001.5502\n2.jar????????? https://blog.csdn.net/u011648768/article/details/148995370?spm=1001.2014.3001.5502\n3. ?????? https://blog.csdn.net/u011648768/article/details/149000393?spm=1001.2014.3001.5502\n4. ??????????????????????????????????????? https://blog.csdn.net/u011648768/article/details/149015829?spm=1001.2014.3001.5502\n5. ?????????????????? https://blog.csdn.net/u011648768/article/details/149023515?spm=1001.2014.3001.5502\n6. DocumentReader???DocumentParser https://blog.csdn.net/u011648768/article/details/149062263?spm=1001.2014.3001.5502\n7. ????????? https://blog.csdn.net/u011648768/article/details/149098175?spm=1001.2014.3001.5502\n8. ???????????? https://blog.csdn.net/u011648768/article/details/149101108?spm=1001.2014.3001.5502\n9. ????????? https://blog.csdn.net/u011648768/article/details/149119606?spm=1001.2014.3001.5502\n10. ???????????????????????? https://blog.csdn.net/u011648768/article/details/149124366?spm=1001.2014.3001.5502\n11. ??????????????????????????? https://blog.csdn.net/u011648768/article/details/149134346?spm=1001.2014.3001.5502\n12. ??????????????????????????? https://blog.csdn.net/u011648768/article/details/149143363?spm=1001.2014.3001.5502\n13. ????????????????????? https://blog.csdn.net/u011648768/article/details/149144466?spm=1001.2014.3001.5502\n14. ????????????????????? https://blog.csdn.net/u011648768/article/details/149152910?spm=1001.2014.3001.5502\n15. ??????????????????sql https://blog.csdn.net/u011648768/article/details/149156206?spm=1001.2014.3001.5502\n16. ??????????????????????????? https://blog.csdn.net/u011648768/article/details/149288497?spm=1001.2014.3001.5502\n17. ????????? https://blog.csdn.net/u011648768/article/details/149316567?spm=1001.2014.3001.5502\n18. ??????tushare https://blog.csdn.net/u011648768/article/details/149329647?spm=1001.2014.3001.5502\n19. ?????????????????? https://blog.csdn.net/u011648768/article/details/149332082?spm=1001.2014.3001.5502\n20. ?????????????????? https://blog.csdn.net/u011648768/article/details/149368346?spm=1001.2014.3001.5502\n21. ?????????nl2sql https://blog.csdn.net/u011648768/article/details/149401537?spm=1001.2014.3001.5502\n22. ?????????????????????https://blog.csdn.net/u011648768/article/details/149439029?spm=1001.2014.3001.5502\n23. ????????????????????? https://blog.csdn.net/u011648768/article/details/149487058?spm=1001.2014.3001.5502", "????????????SpringAI??????Alibaba SpringAI\n[https://blog.csdn.net/qq_52295073/article/details/149301970?sharetype=blogdetail&sharerId=149301970&sharerefer=PC&sharesource=qq_52295073&spm=1011.2480.3001.8118](url)", "??????Spring AI Alibaba??????????????????AI????????????????????????????????????,?????????????????????:**mysql** / **neo4j** / **milvus**?????????????????????rag?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????webmagic?????????????????????????????????????????????rag???\n7???24?????????????????????????????????????????????????????????????????????\n???????????????http://ai.grabteacher.ltd/\n???????????????https://github.com/TouHouQing/chatAiDemo/tree/alibaba\ncsdn???????????????https://blog.csdn.net/2301_80155689/article/details/149354391?fromshare=blogdetail&sharetype=blogdetail&sharerId=149354391&sharerefer=PC&sharesource=2301_80155689&sharefrom=from_link", "JManus ?????????????????????????????????AI Agent???????????? \nhttps://mp.weixin.qq.com/s/JXkwpLFyDh9zhrMK0YR6eA", "??????Spring AI Alibaba???RAG ?????????????????????\n1???github?????????https://github.com/Matthew-Miao/mxy-rag-server\n2???csdn?????????https://blog.csdn.net/qq_29434541/article/details/149406325", "???????????????AI????????????Spring AI Alibaba + JManus??????)  :  https://cloud.tencent.com/developer/article/2540706", "https://blog.csdn.net/hhhoy/article/details/149465432?spm=1001.2014.3001.5501\n???????????????", "CP ??? SSE ?????????Client ?????? Server ???????????????????????????????????????????????? Server ?????????????????????Client ????????????????????? SSE ???????????????????????????????????????????????????\n\nSSE?????????????????????https://mp.weixin.qq.com/s/ljdQdkDPVzPbTcnmLf2E3g\nSSE????????????????????????https://github.com/alibaba/spring-ai-alibaba/tree/main/spring-ai-alibaba-mcp/spring-ai-alibaba-mcp-recovery\nSSE???????????????https://github.com/springaialibaba/spring-ai-alibaba-examples/tree/main/spring-ai-alibaba-mcp-example/spring-ai-alibaba-mcp-starter-example/client/mcp-recovery-client", "???????????? Spring AI Alibaba?????????????????? AI ?????? : https://blog.csdn.net/weixin_40716986/article/details/149490504?spm=1011.2124.3001.6209", "????????????Spring AI Alibaba Graph ???????????????AI??????????????????????????????\nhttps://mp.weixin.qq.com/s/C2AGIJocODXw8nuPMZ_YMg", "Spring AI Alibaba + Nacos api-key?????????????????? https://blog.csdn.net/m0_51474122/article/details/149464986", "Spring AI Alibaba Graph??????????????????????????????????????????????????????????????????????????????????????????CSDN???????????????https://blog.csdn.net/qq_45778701/article/details/149528223?fromshare=blogdetail&sharetype=blogdetail&sharerId=149528223&sharerefer=PC&sharesource=qq_45778701&sharefrom=from_link", "??????????????????\nDeepResearch???Agent??????????????????\nhttps://juejin.cn/post/7529496810265198626", "??????????????????\nSpring AI Alibaba + JManus???????????????????????????????????????????????????https://blog.csdn.net/2301_81028896/article/details/149542170?fromshare=blogdetail&sharetype=blogdetail&sharerId=149542170&sharerefer=PC&sharesource=2301_81028896&sharefrom=from_link\n?????????????????????T???\uD83D\uDE1D", "https://blog.csdn.net/qq_66848092/article/details/149542422?spm=1001.2014.3001.5501", "Spring AI Alibaba?????????????????????????????????????????????: https://blog.csdn.net/2301_80783457/article/details/149542616?spm=1001.2014.3001.5502", "?????? ????????????????????? & Spring AI Alibaba Playground ?????????????????????\nhttps://blog.csdn.net/z18206/article/details/149569781?sharetype=blogdetail&sharerId=149569781&sharerefer=PC&sharesource=z18206&spm=1011.2480.3001.8118", "Spring AI Alibaba????????????\n\n[https://blog.csdn.net/brownxd/article/details/149098619](https://blog.csdn.net/brownxd/article/details/149098619)", "?????????????????????T???\uD83D\uDE1D\nSpring Cloud Alibaba AI????????????https://blog.csdn.net/qq_45563887/article/details/149607101", "7 ???????????????\n????????????Spring AI Alibaba???????????????????????????https://blog.csdn.net/Ecard9085/article/details/149607987", "Spring AI Alibaba ???????????????????????????????????????:https://blog.csdn.net/qq_21267357/article/details/149608929", "JManus ??????????????????????????? https://blog.csdn.net/qq_44560143/article/details/149606607?spm=1011.2415.3001.5331", "??????AI??????????????????Graph??????????????????????????????????????????\nhttps://www.yuque.com/disaster-4qc4i/xhs01z/qrh6lv7m3sexgvr4?singleDoc# \nhttps://blog.csdn.net/a_ittle_pan/article/details/149610125?sharetype=blogdetail&sharerId=149610125&sharerefer=PC&sharesource=a_ittle_pan&spm=1011.2480.3001.8118", "https://blog.csdn.net/qq_51663610/article/details/149610454?sharetype=blogdetail&sharerId=149610454&sharerefer=PC&sharesource=qq_51663610&spm=1011.2480.3001.8118", "![Image](https://github.com/user-attachments/assets/f0cfba4a-cfd5-460d-82de-8ecbb0dd3c5c)", "saa mcp ???????????????????????????????????????\nhttps://www.yuque.com/zaijiansunwukong-bam2v/zrb9b1/ost2cuh4g69usshg", "saa mcp router ??????????????? https://www.yuque.com/zaijiansunwukong-bam2v/zrb9b1/tgsk7nwkn82038gp\n" ],
      "repository" : {
        "description" : "Agentic AI Framework for Java Developers",
        "homepage" : "https://java2ai.com",
        "name" : "spring-ai-alibaba",
        "fullName" : "alibaba/spring-ai-alibaba",
        "htmlUrl" : "https://github.com/alibaba/spring-ai-alibaba",
        "gitUrl" : "git://github.com/alibaba/spring-ai-alibaba.git",
        "sshUrl" : "git@github.com:alibaba/spring-ai-alibaba.git",
        "cloneUrl" : "https://github.com/alibaba/spring-ai-alibaba.git",
        "owner" : {
          "login" : "alibaba",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 998,
        "stargazersCount" : 5006,
        "watchersCount" : 5006,
        "size" : 147621,
        "openIssuesCount" : 286,
        "subscribersCount" : 66,
        "pushedAt" : "2025-07-24T23:14:32Z",
        "languages" : {
          "Java" : 6218355,
          "CSS" : 26756,
          "Makefile" : 7848,
          "TeX" : 4902,
          "Vue" : 496814,
          "Mustache" : 4656,
          "HTML" : 119089,
          "TypeScript" : 536249,
          "Dockerfile" : 2057,
          "Shell" : 42951,
          "Smalltalk" : 11271,
          "Batchfile" : 3003,
          "JavaScript" : 34104,
          "Less" : 6998,
          "Python" : 3892
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of the issue is to collect and share Spring AI Alibaba-related works, including tutorials, articles, and videos, and to encourage the community to contribute to the project. The issue is seeking contributions from the community, and the organizers are offering prizes for the best submissions.",
      "validationOrRequirement" : "The issue does not have specific validation or requirement, but rather a set of guidelines for contributors to follow. The guidelines include a list of topics and formats that the organizers are interested in, as well as a set of rules for submitting contributions.",
      "attemptedFixes" : "The issue is not a traditional bug fix, but rather a call to action for the community to contribute to the project. The organizers are seeking contributions in the form of blog posts, videos, and code examples that showcase the capabilities of Spring AI Alibaba. The issue includes a list of existing works and resources related to Spring AI Alibaba, as well as a roadmap for the project's future development.",
      "otherNotes" : "The issue is about the 2025 Spring AI Alibaba technology blog/video collection. It's a community-driven project that aims to collect and share Spring AI Alibaba-related works, including tutorials, articles, and videos. The issue is seeking contributions from the community, and the organizers are offering prizes for the best submissions. The issue also includes a list of existing works and resources related to Spring AI Alibaba, as well as a roadmap for the project's future development.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408051
  }, {
    "issueDTO" : {
      "id" : 2759930185,
      "title" : "Fix broken & inaccurate detector unit tests",
      "url" : "https://github.com/trufflesecurity/trufflehog/issues/3817",
      "repositoryName" : "trufflesecurity/trufflehog",
      "description" : "The detector unit tests were created by \"reverse engineering\" the patterns, thus they do not provide any real value or confirm how accurate the detectors are.\r\n\r\nAdditionally, the structure of the tests are (in my opinion) not maintainable as they are difficult to understand and do not reflect any realistic scenarios. \r\n\r\nhttps://github.com/trufflesecurity/trufflehog/blob/def734a783b2d4542f2b353d326130d618f3c421/pkg/detectors/netsuite/netsuite_test.go#L14-L44\r\n\r\n## Examples\r\n\r\nThere are dozens, if not hundreds, of problematic test files. These are illustrative.\r\n\r\n### BombBomb\r\n\r\nThe \"valid\" tests for BombBomb do not match the detector's pattern.\r\n\r\nhttps://github.com/trufflesecurity/trufflehog/blob/def734a783b2d4542f2b353d326130d618f3c421/pkg/detectors/bombbomb/bombbomb.go#L24\r\n\r\nhttps://github.com/trufflesecurity/trufflehog/blob/def734a783b2d4542f2b353d326130d618f3c421/pkg/detectors/bombbomb/bombbomb_test.go#L15\r\n\r\n### Kraken\r\n\r\nThe \"valid\" pattern is nonsensical and [not correct base64 encoding](https://base64.guru/learn/base64-characters). The detector should not match this, that is a defect.\r\n\r\nhttps://github.com/trufflesecurity/trufflehog/blob/def734a783b2d4542f2b353d326130d618f3c421/pkg/detectors/kraken/kraken_test.go#L16\r\n\r\n![image](https://github.com/user-attachments/assets/2faa811b-fc31-41c9-b836-eff1d36762fd)\r\nhttps://support.kraken.com/hc/en-us/articles/360000919966-How-to-create-an-API-key\r\n\r\n### viewneo\r\n\r\nA few hundred detectors contain tests tightly coupled to the current implementation of [`PrefixRegex`](https://github.com/trufflesecurity/trufflehog/blob/bcd89e63f88be1126959c20210f134a81b3d252a/pkg/detectors/detectors.go#L229-L233\r\n). Any changes to the prefix pattern will break the detector tests, which seems inadvisable.\r\n\r\nhttps://github.com/trufflesecurity/trufflehog/blob/def734a783b2d4542f2b353d326130d618f3c421/pkg/detectors/viewneo/viewneo_test.go#L38-L42\r\n\r\n\r\n",
      "updatedAt" : 1753357645.000000000,
      "user" : "rgmz",
      "userHtmlUrl" : "https://github.com/rgmz",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/32133502?v=4",
      "labels" : [ "pkg/detectors", "bug", "good first issue", "contributions welcomed" ],
      "state" : "OPEN",
      "comments" : [ "The `bombbomb` pattern test case was functioning correctly when I wrote it. However, the failure was introduced by this [pull request](https://github.com/trufflesecurity/trufflehog/pull/3462), which modified the pattern without updating the corresponding test cases. Moving forward, we should ensure that any changes to a pattern are accompanied by updates to the relevant test cases.\r\n\r\nAdditionally, I???d appreciate your input on some test cases I wrote to simulate real-world scenarios for various detectors. For example, take a look at the [bombbomb detector complex pattern test](https://github.com/trufflesecurity/trufflehog/blob/main/pkg/detectors/bombbomb/bombbomb_test.go#L16). If this approach looks good, we can work on updating the remaining test cases to follow a similar strategy.", "> If this approach looks good, we can work on updating the remaining test cases to follow a similar strategy.\r\n\r\nAgreed, and this may also involve updating detectors where the existing regex could potentially match incorrect patterns.", "> The `bombbomb` pattern test case was functioning correctly when I wrote it. However, the failure was introduced by this [pull request](https://github.com/trufflesecurity/trufflehog/pull/3462), which modified the pattern without updating the corresponding test cases.\r\n\r\nSmall mistakes like that should be detected once #3773 is merged.\r\n\r\n> Additionally, I???d appreciate your input on some test cases I wrote to simulate real-world scenarios for various detectors. For example, take a look at the [bombbomb detector complex pattern test](https://github.com/trufflesecurity/trufflehog/blob/main/pkg/detectors/bombbomb/bombbomb_test.go#L16).\r\n\r\nThat's a better approach, although you only really need 1/2 lines of surrounding context. I'd also suggest moving the inputs inline with the test cases (input: \\`...`) instead of sprintf'ing them.\r\n```diff\r\n\tcomplexPattern = `\r\n\t\t\r\n\t\tbombbombToken := \"HUmGL.17uQMEShYp2RVMR8vypd1iqj6FZcKkQ4SazuMkbEKhzRFKuvOiwYmNWPSvkE4wiLOv-zWTkK1WkVTScRb9_io0_kvhYX31tpwR3lAJUh27RJzf1BehaJTQDXhJB6aT2gQ2LMT7dda-b3vhmEuZHzPV9AMLV6cOrcqOTkK60vMcB0PTLRQ3c_kY.a.9.hRvgogdlI8mQJrzD0myPBY7lMpjpkcskQDpOgz2I37kNDYhf7IxT6sG-a7rI1LdpJ6HhJacktlNJSswST9jbt4A0ropfJJTHGny2aId4WyPpAnQubM98F1BUnyhfkDzenaUuuQ_ZoPn9mAOsdLQUlAyp4I9oLJ_v8yQ0Q4M.Yujscho9G4ZbVTInC2mP8taCPZdRK5qt-UfAF0CX9B4E0F9NItMUbRdbm3xIkl8C6iPUcgY5OTQDBSJRLKBJgIaEyyXe10pPw.qOUhLKNPcg5qPs1xhgBsZKfW2hNTff2dCL5h6E.940ojPuT0Iw90Q8kpQ2UzeUJrhXH9_GUANKA.pjD0-YcGpnlVEDouyXaXowUoh8pLqD-BtBQfteqyFqz7THGDvQKikMy7wiBuJAo0HttMG3jw1zKtA3gM6_VIXo_K4WN6yz8Ow4n5f6Unn5zn4j2haKA4WWI5-1c8-mm7SF5VqYJVz42wBmRqB6MWXegJ7yLt_EoG1tJHftnHZ\"\r\n\t\treq.Header.Set(\"Authorization\", bombbombToken)\r\n\t`\r\n```\r\n\r\nI tend to base test cases on results found from GitHub or [SourceGraph](https://sourcegraph.com/search) search.\r\ne.g., https://github.com/trufflesecurity/trufflehog/pull/3784/files#diff-8d1772a0a428fddbb34136f1096bc2461293e55d4faffcfe9a100070e11411e1\r\n", "I can fix the `bombbomb` pattern test case as of now" ],
      "repository" : {
        "description" : "Find, verify, and analyze leaked credentials",
        "homepage" : "https://trufflesecurity.com",
        "name" : "trufflehog",
        "fullName" : "trufflesecurity/trufflehog",
        "htmlUrl" : "https://github.com/trufflesecurity/trufflehog",
        "gitUrl" : "git://github.com/trufflesecurity/trufflehog.git",
        "sshUrl" : "git@github.com:trufflesecurity/trufflehog.git",
        "cloneUrl" : "https://github.com/trufflesecurity/trufflehog.git",
        "owner" : {
          "login" : "trufflesecurity",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 1922,
        "stargazersCount" : 19970,
        "watchersCount" : 19970,
        "size" : 44784,
        "openIssuesCount" : 275,
        "subscribersCount" : 191,
        "pushedAt" : "2025-07-24T15:56:28Z",
        "languages" : {
          "Dockerfile" : 621,
          "Shell" : 15060,
          "Makefile" : 1956,
          "Go" : 10114965,
          "Gnuplot" : 264
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fix broken and inaccurate detector unit tests by creating tests that simulate real-world scenarios and are maintainable, and ensure that any changes to the pattern are accompanied by updates to the relevant test cases.",
      "validationOrRequirement" : "The detector tests should be maintainable, easy to understand, and reflect realistic scenarios. Any changes to the pattern should be accompanied by updates to the relevant test cases.",
      "attemptedFixes" : "The author has attempted to fix the 'bombbomb' pattern test case, but it was introduced by a pull request and needs to be updated. Additionally, the author has written test cases to simulate real-world scenarios for various detectors.",
      "otherNotes" : "The detector unit tests were created by reverse engineering the patterns, thus they do not provide any real value or confirm how accurate the detectors are. The tests are difficult to understand and do not reflect any realistic scenarios.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408058
  }, {
    "issueDTO" : {
      "id" : 189708015,
      "title" : "Rota mobile interface",
      "url" : "https://github.com/sheltermanager/asm3/issues/68",
      "repositoryName" : "sheltermanager/asm3",
      "description" : "Option to show \"My Rota\" in the mobile interface if the user is tied to a person record and it has a rota.",
      "updatedAt" : 1753357347.000000000,
      "user" : "bobintetley",
      "userHtmlUrl" : "https://github.com/bobintetley",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18594812?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Animal Shelter Manager",
        "homepage" : null,
        "name" : "asm3",
        "fullName" : "sheltermanager/asm3",
        "htmlUrl" : "https://github.com/sheltermanager/asm3",
        "gitUrl" : "git://github.com/sheltermanager/asm3.git",
        "sshUrl" : "git@github.com:sheltermanager/asm3.git",
        "cloneUrl" : "https://github.com/sheltermanager/asm3.git",
        "owner" : {
          "login" : "sheltermanager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 127648,
        "openIssuesCount" : 123,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T11:16:27Z",
        "languages" : {
          "Dockerfile" : 613,
          "CSS" : 337410,
          "Shell" : 10839,
          "Makefile" : 6349,
          "JavaScript" : 13547254,
          "PHP" : 6255,
          "HTML" : 2896442,
          "Less" : 9472,
          "Python" : 10945810
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Add 'My Rota' option to mobile interface if user is tied to a person record and has a rota",
      "validationOrRequirement" : "Option to show 'My Rota' in the mobile interface if the user is tied to a person record and it has a rota",
      "attemptedFixes" : "",
      "otherNotes" : "Repository: sheltermanager/asm3, Author: bobintetley, Labels: enhancement, good first issue",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408061
  }, {
    "issueDTO" : {
      "id" : 3215353886,
      "title" : "[DAG] Fold trunc(abdu(x,y)) and trunc(abds(x,y)) if they have sufficient leading zero/sign bits",
      "url" : "https://github.com/llvm/llvm-project/issues/147683",
      "repositoryName" : "llvm/llvm-project",
      "description" : "https://zig.godbolt.org/z/f3ac4Moxr\n\n```\nSelectionDAG has 12 nodes:\n  t0: ch,glue = EntryToken\n          t2: v4i16,ch = CopyFromReg t0, Register:v4i16 %0\n        t5: v4i32 = zero_extend t2\n          t4: v4i16,ch = CopyFromReg t0, Register:v4i16 %1\n        t6: v4i32 = zero_extend t4\n      t13: v4i32 = abdu t5, t6\n    t9: v4i16 = truncate t13\n  t11: ch,glue = CopyToReg t0, Register:v4i16 $d0, t9\n  t12: ch = AArch64ISD::RET_GLUE t11, Register:v4i16 $d0, t11:1\n```\n\nIf a ABD node has sufficient leading zero/sign bits then it should still work in a truncated type - it doesn't have to be from a zext/sext node specifically so computeKnownBits/ComputeNumSignBits should probably be used.\n\n- [x] Create alive2 links to prove when abd patterns can be safely truncated\n- [ ] Add test coverage (using aarch64 intrinsics is probably easiest as that will always start from ISD::ABDU/S nodes)\n- [ ] Add suitable folds in DAGCombiner::visitTRUNCATE - including legality checks",
      "updatedAt" : 1753357267.000000000,
      "user" : "RKSimon",
      "userHtmlUrl" : "https://github.com/RKSimon",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/2175834?v=4",
      "labels" : [ "llvm:SelectionDAG", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "CC @woruyu - not sure if this is of interest?", "\nHi!\n\nThis issue may be a good introductory issue for people new to working on LLVM. If you would like to work on this issue, your first steps are:\n\n1. Check that no other contributor is working on this issue. If someone is assigned to the issue or claimed to be working on it, ping the person. After one week without a response, the assignee may be changed.\n1. Leave a comment indicating that you are working on the issue, or just create a [pull request](https://github.com/llvm/llvm-project/pulls) after following the steps below. [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n1. Fix the issue locally.\n1. [Run the test suite](https://llvm.org/docs/TestingGuide.html#unit-and-regression-tests) locally. Remember that the subdirectories under `test/` create fine-grained testing targets, so you can e.g. use `make check-clang-ast` to only run Clang's AST tests.\n1. Create a Git commit.\n1. Run [`git clang-format HEAD~1`](https://clang.llvm.org/docs/ClangFormat.html#git-integration) to format your changes.\n1. Open a [pull request](https://github.com/llvm/llvm-project/pulls) to the [upstream repository](https://github.com/llvm/llvm-project) on GitHub. Detailed instructions can be found [in GitHub's documentation](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request). [Mention](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue) this issue in the description of the pull request.\n\nIf you have any further questions about this issue, don't hesitate to ask via a comment in the thread below.\n\n", "\n@llvm/issue-subscribers-good-first-issue\n\nAuthor: Simon Pilgrim (RKSimon)\n\n<details>\nhttps://zig.godbolt.org/z/f3ac4Moxr\n\n```\nSelectionDAG has 12 nodes:\n  t0: ch,glue = EntryToken\n          t2: v4i16,ch = CopyFromReg t0, Register:v4i16 %0\n        t5: v4i32 = zero_extend t2\n          t4: v4i16,ch = CopyFromReg t0, Register:v4i16 %1\n        t6: v4i32 = zero_extend t4\n      t13: v4i32 = abdu t5, t6\n    t9: v4i16 = truncate t13\n  t11: ch,glue = CopyToReg t0, Register:v4i16 $d0, t9\n  t12: ch = AArch64ISD::RET_GLUE t11, Register:v4i16 $d0, t11:1\n```\n\nIf a ABD node has sufficient leading zero/sign bits then it should still work in a truncated type - it doesn't have to be from a zext/sext_extend node specifically so computeKnownBits/ComputeNumSignBits should probably be used.\n\n- [ ] Create alive2 links to prove when abd patterns can be safely truncated\n- [ ] Add test coverage (using aarch64 intrinsics is probably easiest as that will always start from ISD::ABDU/S nodes)\n- [ ] Add suitable folds in DAGCombiner::visitTRUNCATE - including legality checks\n</details>\n", "Hi! I'd like to work on this issue. Can you assign it to me?\n ", "alive2 abdu pattern: https://alive2.llvm.org/ce/z/d59BCq\n```ll\ndefine i4 @src_abdu(i16 %a0, i16 %a1) {\n#0:\n  %lz0 = ctlz i16 %a0, 0\n  %lz1 = ctlz i16 %a1, 0\n  %zz0 = icmp uge i16 %lz0, 12\n  %zz1 = icmp uge i16 %lz1, 12\n  assume i1 %zz0\n  assume i1 %zz1\n  %max = umax i16 %a0, %a1\n  %min = umin i16 %a0, %a1\n  %diff = sub i16 %max, %min\n  %res = trunc i16 %diff to i4\n  ret i4 %res\n}\n=>\ndefine i4 @tgt_abdu(i16 %a0, i16 %a1) {\n#0:\n  %x0 = trunc i16 %a0 to i4\n  %x1 = trunc i16 %a1 to i4\n  %max = umax i4 %x0, %x1\n  %min = umin i4 %x0, %x1\n  %diff = sub i4 %max, %min\n  ret i4 %diff\n}\nTransformation seems to be correct!\n```", "alive2 abds pattern\n```ll\ndefine i4 @src_abds(i16 %a0, i16 %a1) {\n  ; representable as i4\n  %t0 = trunc i16 %a0 to i4\n  %t1 = trunc i16 %a1 to i4\n  %x0 = sext i4 %t0 to i16\n  %x1 = sext i4 %t1 to i16\n  %eq0 = icmp eq i16 %x0, %a0\n  %eq1 = icmp eq i16 %x1, %a1\n  call void @llvm.assume(i1 %eq0)\n  call void @llvm.assume(i1 %eq1)\n\n  %max = call i16 @llvm.smax.i16(i16 %a0, i16 %a1)\n  %min = call i16 @llvm.smin.i16(i16 %a0, i16 %a1)\n  %diff = sub i16 %max, %min\n  %res = trunc i16 %diff to i4\n  ret i4 %res\n}\n\ndefine i4 @tgt_abds(i16 %a0, i16 %a1) {\n  %x0 = trunc i16 %a0 to i4\n  %x1 = trunc i16 %a1 to i4\n  %max = call i4 @llvm.smax.i4(i4 %x0, i4 %x1)\n  %min = call i4 @llvm.smin.i4(i4 %x0, i4 %x1)\n  %diff = sub i4 %max, %min\n  ret i4 %diff\n}\n```", "@toprakmurat ping - have you been able to look at this?", "This is beyond my current skill level. Please feel free to reassign it if needed.", "I would like to fix this???Thank you!" ],
      "repository" : {
        "description" : "The LLVM Project is a collection of modular and reusable compiler and toolchain technologies.",
        "homepage" : "http://llvm.org",
        "name" : "llvm-project",
        "fullName" : "llvm/llvm-project",
        "htmlUrl" : "https://github.com/llvm/llvm-project",
        "gitUrl" : "git://github.com/llvm/llvm-project.git",
        "sshUrl" : "git@github.com:llvm/llvm-project.git",
        "cloneUrl" : "https://github.com/llvm/llvm-project.git",
        "owner" : {
          "login" : "llvm",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 14563,
        "stargazersCount" : 33645,
        "watchersCount" : 33645,
        "size" : 2568475,
        "openIssuesCount" : 31089,
        "subscribersCount" : 580,
        "pushedAt" : "2025-07-25T00:59:09Z",
        "languages" : {
          "GDB" : 8473,
          "CMake" : 4108206,
          "Mustache" : 17219,
          "HTML" : 1956247,
          "Pawn" : 20078,
          "MATLAB" : 4946,
          "Fortran" : 11668142,
          "LLVM" : 634320209,
          "OCaml" : 335815,
          "Assembly" : 154980494,
          "Python" : 12978634,
          "Rust" : 4903,
          "Objective-C++" : 1178815,
          "SWIG" : 288374,
          "Tree-sitter Query" : 6195,
          "Perl" : 183797,
          "MLIR" : 21384848,
          "Cuda" : 1243277,
          "Scilab" : 160404,
          "Starlark" : 1194175,
          "Batchfile" : 52122,
          "AMPL" : 1662,
          "Swift" : 271,
          "DTrace" : 334,
          "C" : 202468383,
          "RPC" : 28,
          "Makefile" : 114950,
          "Cool" : 5401,
          "Jupyter Notebook" : 72939,
          "M" : 9785,
          "TypeScript" : 69121,
          "Shell" : 264842,
          "Awk" : 127345,
          "JavaScript" : 161607,
          "Mathematica" : 1118,
          "Objective-C" : 4302574,
          "Lua" : 12033,
          "PHP" : 64,
          "Limbo" : 303,
          "POV-Ray SDL" : 861,
          "Emacs Lisp" : 69003,
          "C++" : 490174634,
          "CSS" : 63859,
          "FIRRTL" : 4349198,
          "TeX" : 2141,
          "AppleScript" : 1429,
          "NASL" : 35217,
          "HIP" : 857866,
          "Julia" : 49676,
          "Dockerfile" : 23110,
          "Linker Script" : 903,
          "Roff" : 61624,
          "HLSL" : 1512603,
          "Mercury" : 14,
          "Vim Script" : 29186
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Fold trunc(abdu(x,y)) and trunc(abds(x,y)) if they have sufficient leading zero/sign bits.",
      "validationOrRequirement" : "The issue requires creating alive2 links to prove when abd patterns can be safely truncated, adding test coverage using aarch64 intrinsics, and adding suitable folds in DAGCombiner::visitTRUNCATE - including legality checks.",
      "attemptedFixes" : "alive2 abdu pattern and alive2 abds pattern are provided, but it seems that the issue is beyond the current skill level of the person who commented.",
      "otherNotes" : "The issue is about folding trunc(abdu(x,y)) and trunc(abds(x,y)) if they have sufficient leading zero/sign bits. It involves creating alive2 links to prove when abd patterns can be safely truncated, adding test coverage using aarch64 intrinsics, and adding suitable folds in DAGCombiner::visitTRUNCATE - including legality checks.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408067
  }, {
    "issueDTO" : {
      "id" : 189709340,
      "title" : "Store comments in the log when they change",
      "url" : "https://github.com/sheltermanager/asm3/issues/71",
      "repositoryName" : "sheltermanager/asm3",
      "description" : "Just as we do with weight and location, have an option to store comments and hidden animal comments in the log as they change. This keeps old versions of bios and anything else.",
      "updatedAt" : 1753357249.000000000,
      "user" : "bobintetley",
      "userHtmlUrl" : "https://github.com/bobintetley",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18594812?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Animal Shelter Manager",
        "homepage" : null,
        "name" : "asm3",
        "fullName" : "sheltermanager/asm3",
        "htmlUrl" : "https://github.com/sheltermanager/asm3",
        "gitUrl" : "git://github.com/sheltermanager/asm3.git",
        "sshUrl" : "git@github.com:sheltermanager/asm3.git",
        "cloneUrl" : "https://github.com/sheltermanager/asm3.git",
        "owner" : {
          "login" : "sheltermanager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 127648,
        "openIssuesCount" : 123,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T11:16:27Z",
        "languages" : {
          "Dockerfile" : 613,
          "CSS" : 337410,
          "Shell" : 10839,
          "Makefile" : 6349,
          "JavaScript" : 13547254,
          "PHP" : 6255,
          "HTML" : 2896442,
          "Less" : 9472,
          "Python" : 10945810
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Store comments in the log when they change",
      "validationOrRequirement" : "Have an option to store comments and hidden animal comments in the log as they change.",
      "attemptedFixes" : "",
      "otherNotes" : "The issue aims to store comments and hidden animal comments in the log as they change, keeping old versions of bios and other information.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408070
  }, {
    "issueDTO" : {
      "id" : 189710568,
      "title" : "Autocomplete additional field type",
      "url" : "https://github.com/sheltermanager/asm3/issues/79",
      "repositoryName" : "sheltermanager/asm3",
      "description" : "It'd be nice to offer autocomplete as an additional field type (a textbox with lookup values).",
      "updatedAt" : 1753357150.000000000,
      "user" : "bobintetley",
      "userHtmlUrl" : "https://github.com/bobintetley",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18594812?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Animal Shelter Manager",
        "homepage" : null,
        "name" : "asm3",
        "fullName" : "sheltermanager/asm3",
        "htmlUrl" : "https://github.com/sheltermanager/asm3",
        "gitUrl" : "git://github.com/sheltermanager/asm3.git",
        "sshUrl" : "git@github.com:sheltermanager/asm3.git",
        "cloneUrl" : "https://github.com/sheltermanager/asm3.git",
        "owner" : {
          "login" : "sheltermanager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 127648,
        "openIssuesCount" : 123,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T11:16:27Z",
        "languages" : {
          "Dockerfile" : 613,
          "CSS" : 337410,
          "Shell" : 10839,
          "Makefile" : 6349,
          "JavaScript" : 13547254,
          "PHP" : 6255,
          "HTML" : 2896442,
          "Less" : 9472,
          "Python" : 10945810
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "To offer autocomplete as an additional field type in a textbox with lookup values.",
      "validationOrRequirement" : "No specific validations or requirements mentioned in the description or comments.",
      "attemptedFixes" : "No attempts or blockers mentioned in the description or comments.",
      "otherNotes" : "The issue is about adding autocomplete as an additional field type in a textbox with lookup values.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408072
  }, {
    "issueDTO" : {
      "id" : 189710685,
      "title" : "Contextual reports",
      "url" : "https://github.com/sheltermanager/asm3/issues/80",
      "repositoryName" : "sheltermanager/asm3",
      "description" : "User suggestion, on the animal and person details screens have a \"Reports\" dropdown next to Documents.\n\nThe new dropdown should filter/show all reports with a single $ASK ANIMAL$ or $ASK PERSON$ tag in their source (new get_reports query).\n\nThe target link for each one is the normal link for the report with the extra parameters &mode=exec&ASK1=[ID]\n\nThis allows reports for the currently viewed record to be run without being asked for one.",
      "updatedAt" : 1753357121.000000000,
      "user" : "bobintetley",
      "userHtmlUrl" : "https://github.com/bobintetley",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18594812?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Animal Shelter Manager",
        "homepage" : null,
        "name" : "asm3",
        "fullName" : "sheltermanager/asm3",
        "htmlUrl" : "https://github.com/sheltermanager/asm3",
        "gitUrl" : "git://github.com/sheltermanager/asm3.git",
        "sshUrl" : "git@github.com:sheltermanager/asm3.git",
        "cloneUrl" : "https://github.com/sheltermanager/asm3.git",
        "owner" : {
          "login" : "sheltermanager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 127648,
        "openIssuesCount" : 123,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T11:16:27Z",
        "languages" : {
          "Dockerfile" : 613,
          "CSS" : 337410,
          "Shell" : 10839,
          "Makefile" : 6349,
          "JavaScript" : 13547254,
          "PHP" : 6255,
          "HTML" : 2896442,
          "Less" : 9472,
          "Python" : 10945810
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a 'Reports' dropdown next to Documents on animal and person details screens, allowing users to run reports for the currently viewed record without being asked for one.",
      "validationOrRequirement" : "The new dropdown should filter/show all reports with a single $ASK ANIMAL$ or $ASK PERSON$ tag in their source (new get_reports query).",
      "attemptedFixes" : "",
      "otherNotes" : "The issue is related to adding a dropdown for reports on animal and person details screens with filtering and linking options.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408076
  }, {
    "issueDTO" : {
      "id" : 3254668158,
      "title" : "[ACTION] unable to create image and text posts",
      "url" : "https://github.com/PipedreamHQ/pipedream/issues/17752",
      "repositoryName" : "PipedreamHQ/pipedream",
      "description" : "**Describe the bug**\nI am unable to post images to LinkedIn via the Pipedream MCP server. I receive an authorization error (403 Forbidden) indicating that the authenticated user ID is missing or invalid.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n\n1.  Connect your LinkedIn account to the MCP server using Pipedream.\n2.  Attempt to create a LinkedIn post through the Pipedream MCP server.\n3.  Observe the authorization error: \"The authenticated user ID is missing or invalid, resulting in an authorization error (403 Forbidden) from LinkedIn.\"\n4.  See the reproduction on Pipedream chat at: `https://chat.pipedream.com/chat/9498e4ca-e957-430a-97ff-9bef8c74ab38`\n\n**Expected behavior**\nI expect to be able to successfully post to LinkedIn through the Pipedream MCP server after authenticating my LinkedIn account. The image post should be created without any authorization errors.\n\n**Additional context**\nThe error suggests a problem with authentication or authorization when trying to post on my behalf, despite a successful connection of the LinkedIn account to the MCP server. Possible reasons include:\n*   **Token Scope or Expiry:** The access token from Pipedream/MCP might lack correct permissions for image posting or may have expired.\n*   **MCP Server Integration:** The MCP server might not be correctly passing the LinkedIn user ID or access token to the LinkedIn API, or there might be a mismatch between the Pipedream authenticated session and the IDE context.\n*   **User Context:** The integration might require explicit user context (user ID/profile) to be passed with each request, which might be missing.\n*   **Pipedream vs. IDE Context:** The authentication from Pipedream may not be valid in the IDE or MCP server context if tokens are not shared or valid for both environments.",
      "updatedAt" : 1753356821.000000000,
      "user" : "prasad169-ch",
      "userHtmlUrl" : "https://github.com/prasad169-ch",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/175522295?v=4",
      "labels" : [ "triaged", "tracked internally", "help wanted", "action", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "related to https://github.com/PipedreamHQ/pipedream/issues/17723", "still facing the issues my problem won't solve\n", "i would like to work on it" ],
      "repository" : {
        "description" : "Connect APIs, remarkably fast.  Free for developers.",
        "homepage" : "https://pipedream.com",
        "name" : "pipedream",
        "fullName" : "PipedreamHQ/pipedream",
        "htmlUrl" : "https://github.com/PipedreamHQ/pipedream",
        "gitUrl" : "git://github.com/PipedreamHQ/pipedream.git",
        "sshUrl" : "git@github.com:PipedreamHQ/pipedream.git",
        "cloneUrl" : "https://github.com/PipedreamHQ/pipedream.git",
        "owner" : {
          "login" : "PipedreamHQ",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5419,
        "stargazersCount" : 10247,
        "watchersCount" : 10247,
        "size" : 608233,
        "openIssuesCount" : 4153,
        "subscribersCount" : 276,
        "pushedAt" : "2025-07-25T00:33:00Z",
        "languages" : {
          "TypeScript" : 1313176,
          "MDX" : 1185411,
          "Dockerfile" : 295,
          "CSS" : 4596,
          "Shell" : 2688,
          "Makefile" : 270,
          "JavaScript" : 25500208,
          "HTML" : 568,
          "Jupyter Notebook" : 22765
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create image and text posts to LinkedIn via the Pipedream MCP server without receiving an authorization error (403 Forbidden) indicating that the authenticated user ID is missing or invalid.",
      "validationOrRequirement" : "The authenticated user ID is missing or invalid, resulting in an authorization error (403 Forbidden) from LinkedIn.",
      "attemptedFixes" : "The issue is still facing and not solved by the related issue #17723.",
      "otherNotes" : "Possible reasons for the issue include Token Scope or Expiry, MCP Server Integration, User Context, and Pipedream vs. IDE Context.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408080
  }, {
    "issueDTO" : {
      "id" : 290259990,
      "title" : "Create waiting list from animal",
      "url" : "https://github.com/sheltermanager/asm3/issues/338",
      "repositoryName" : "sheltermanager/asm3",
      "description" : "Similar to how an animal record can be created from a waiting list entry with a toolbar button, there should be an option to do the reverse from an animal record.\r\n\r\nThis scenario comes up when an adopter wants to return their animal but the shelter does not have room. Have a button on the animal toolbar which is only active when an animal has an open adoption, transfer or reclaim movement.\r\n\r\nIt creates a waiting list entry, uses the person from the last exit movement as the contact and puts an animal summary in the description (including its code, name, species, gender, breed and age).",
      "updatedAt" : 1753356556.000000000,
      "user" : "bobintetley",
      "userHtmlUrl" : "https://github.com/bobintetley",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18594812?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ ],
      "repository" : {
        "description" : "Animal Shelter Manager",
        "homepage" : null,
        "name" : "asm3",
        "fullName" : "sheltermanager/asm3",
        "htmlUrl" : "https://github.com/sheltermanager/asm3",
        "gitUrl" : "git://github.com/sheltermanager/asm3.git",
        "sshUrl" : "git@github.com:sheltermanager/asm3.git",
        "cloneUrl" : "https://github.com/sheltermanager/asm3.git",
        "owner" : {
          "login" : "sheltermanager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 127648,
        "openIssuesCount" : 123,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T11:16:27Z",
        "languages" : {
          "Dockerfile" : 613,
          "CSS" : 337410,
          "Shell" : 10839,
          "Makefile" : 6349,
          "JavaScript" : 13547254,
          "PHP" : 6255,
          "HTML" : 2896442,
          "Less" : 9472,
          "Python" : 10945810
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a waiting list entry from an animal record",
      "validationOrRequirement" : "Create a button on the animal toolbar which is only active when an animal has an open adoption, transfer or reclaim movement.",
      "attemptedFixes" : "",
      "otherNotes" : "This scenario comes up when an adopter wants to return their animal but the shelter does not have room.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408083
  }, {
    "issueDTO" : {
      "id" : 342398215,
      "title" : "Suggestions for Transport Book",
      "url" : "https://github.com/sheltermanager/asm3/issues/464",
      "repositoryName" : "sheltermanager/asm3",
      "description" : "1. Is it possible to have a total of the number of animals displayed on the transport screen? And to update that number if a filter is applied. i.e. typing a date in the **at** column?\r\n\r\n2. Is it possible to have a **Select all**, to select all the animals to complete the status in bulk?",
      "updatedAt" : 1753356398.000000000,
      "user" : "1gkwc6",
      "userHtmlUrl" : "https://github.com/1gkwc6",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/34856767?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Select all was added for all tables quite a while ago, but the table widget should be updated to output the number of visible records in it (ie. deduct ones hidden by the built in filters)" ],
      "repository" : {
        "description" : "Animal Shelter Manager",
        "homepage" : null,
        "name" : "asm3",
        "fullName" : "sheltermanager/asm3",
        "htmlUrl" : "https://github.com/sheltermanager/asm3",
        "gitUrl" : "git://github.com/sheltermanager/asm3.git",
        "sshUrl" : "git@github.com:sheltermanager/asm3.git",
        "cloneUrl" : "https://github.com/sheltermanager/asm3.git",
        "owner" : {
          "login" : "sheltermanager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 127648,
        "openIssuesCount" : 123,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T11:16:27Z",
        "languages" : {
          "Dockerfile" : 613,
          "CSS" : 337410,
          "Shell" : 10839,
          "Makefile" : 6349,
          "JavaScript" : 13547254,
          "PHP" : 6255,
          "HTML" : 2896442,
          "Less" : 9472,
          "Python" : 10945810
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement suggestions for Transport Book: display total number of animals on transport screen and add 'Select all' feature",
      "validationOrRequirement" : "update table widget to output the number of visible records, deduct ones hidden by built in filters",
      "attemptedFixes" : "Select all was already added for all tables",
      "otherNotes" : "Select all was added for all tables quite a while ago, but the table widget should be updated to output the number of visible records in it (ie. deduct ones hidden by the built in filters)",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408086
  }, {
    "issueDTO" : {
      "id" : 388924384,
      "title" : "Online form: Create equipment loan",
      "url" : "https://github.com/sheltermanager/asm3/issues/530",
      "repositoryName" : "sheltermanager/asm3",
      "description" : "Some customers would like to be able to create equipment loan records from completed online form info. The form should require person info like lost/found/waiting list.",
      "updatedAt" : 1753356203.000000000,
      "user" : "bobintetley",
      "userHtmlUrl" : "https://github.com/bobintetley",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18594812?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Create equipment loan as per #775" ],
      "repository" : {
        "description" : "Animal Shelter Manager",
        "homepage" : null,
        "name" : "asm3",
        "fullName" : "sheltermanager/asm3",
        "htmlUrl" : "https://github.com/sheltermanager/asm3",
        "gitUrl" : "git://github.com/sheltermanager/asm3.git",
        "sshUrl" : "git@github.com:sheltermanager/asm3.git",
        "cloneUrl" : "https://github.com/sheltermanager/asm3.git",
        "owner" : {
          "login" : "sheltermanager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 127648,
        "openIssuesCount" : 123,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T11:16:27Z",
        "languages" : {
          "Dockerfile" : 613,
          "CSS" : 337410,
          "Shell" : 10839,
          "Makefile" : 6349,
          "JavaScript" : 13547254,
          "PHP" : 6255,
          "HTML" : 2896442,
          "Less" : 9472,
          "Python" : 10945810
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create online form to create equipment loan records from completed form info",
      "validationOrRequirement" : "Create equipment loan records, require person info like lost/found/waiting list, as per #775",
      "attemptedFixes" : "No attempts or blockers mentioned",
      "otherNotes" : "Create equipment loan records from completed online form info, requiring person info like lost/found/waiting list, as per #775",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408089
  }, {
    "issueDTO" : {
      "id" : 3253440214,
      "title" : "[TRIGGER]",
      "url" : "https://github.com/PipedreamHQ/pipedream/issues/17741",
      "repositoryName" : "PipedreamHQ/pipedream",
      "description" : "**Describe the event source. What app is this for, and what event does the trigger correspond to?**\nCreate a discord role\n**Please provide a link to the relevant API docs for the specific service / operation this trigger is tied to.**\nhttps://discord.com/developers/docs/reference",
      "updatedAt" : 1753356200.000000000,
      "user" : "RAFAELESPADA",
      "userHtmlUrl" : "https://github.com/RAFAELESPADA",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/34714331?v=4",
      "labels" : [ "triaged", "question", "trigger / source", "help wanted", "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Hi @RAFAELESPADA, should is be an action or a source? Is this the API you're requesting? https://discord.com/developers/docs/resources/guild#create-guild-role", "> Hi @RAFAELESPADA, should is be an action or a source? Is this the API you're requesting? https://discord.com/developers/docs/resources/guild#create-guild-role\n\nAction. Yes this is the api" ],
      "repository" : {
        "description" : "Connect APIs, remarkably fast.  Free for developers.",
        "homepage" : "https://pipedream.com",
        "name" : "pipedream",
        "fullName" : "PipedreamHQ/pipedream",
        "htmlUrl" : "https://github.com/PipedreamHQ/pipedream",
        "gitUrl" : "git://github.com/PipedreamHQ/pipedream.git",
        "sshUrl" : "git@github.com:PipedreamHQ/pipedream.git",
        "cloneUrl" : "https://github.com/PipedreamHQ/pipedream.git",
        "owner" : {
          "login" : "PipedreamHQ",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 5419,
        "stargazersCount" : 10247,
        "watchersCount" : 10247,
        "size" : 608233,
        "openIssuesCount" : 4153,
        "subscribersCount" : 276,
        "pushedAt" : "2025-07-25T00:33:00Z",
        "languages" : {
          "TypeScript" : 1313176,
          "MDX" : 1185411,
          "Dockerfile" : 295,
          "CSS" : 4596,
          "Shell" : 2688,
          "Makefile" : 270,
          "JavaScript" : 25500208,
          "HTML" : 568,
          "Jupyter Notebook" : 22765
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Create a discord role using the Discord API",
      "validationOrRequirement" : "The API requires a specific service/operation and a link to the relevant API docs is needed.",
      "attemptedFixes" : "The author (@RAFAELESPADA) confirmed that the API is correct (https://discord.com/developers/docs/resources/guild#create-guild-role)",
      "otherNotes" : "The issue is related to creating a discord role and requires a link to the relevant API docs for the specific service/operation this trigger is tied to.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408093
  }, {
    "issueDTO" : {
      "id" : 2792850075,
      "title" : "CF Conventions compliance review",
      "url" : "https://github.com/icenet-ai/icenet/issues/308",
      "repositoryName" : "icenet-ai/icenet",
      "description" : "Check netCDF forecast output compliance with [CF Conventions](https://cfconventions.org/).\n\nAs an example, currently, the forecast initialisation time is output as `time` variable, but in the convention, it seems to typically be called `forecast_reference_time`. And, also, the forecast lead time is output as `leadtime` variable currently, I haven't delved deep into this yet, but I think this should be called either `time` with `standard_name=forecast_period` (Ref [here](https://cfconventions.org/Data/cf-standard-names/77/build/cf-standard-name-table.html)).\n\nReferencing this section: https://cfconventions.org/Data/cf-conventions/cf-conventions-1.12/cf-conventions.html#scalar-coordinate-variables\n",
      "updatedAt" : 1753356185.000000000,
      "user" : "bnubald",
      "userHtmlUrl" : "https://github.com/bnubald",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/55503826?v=4",
      "labels" : [ "help wanted", "on hold", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Agree wholeheartedly with this @bnubald. The mechanism for defining the data should not be taken from the reference files (as demonstrated with #336) because this differs across the SIC ground truths. This is a blocker for v0.4, given `icenet_output` also is being redesigned to define metadata more explicitly where possible. Currently that's WIP, but this is a good issue to hang off! " ],
      "repository" : {
        "description" : "The icenet library is a pip installable python package containing the commands and code you need to produce forecasts",
        "homepage" : "",
        "name" : "icenet",
        "fullName" : "icenet-ai/icenet",
        "htmlUrl" : "https://github.com/icenet-ai/icenet",
        "gitUrl" : "git://github.com/icenet-ai/icenet.git",
        "sshUrl" : "git@github.com:icenet-ai/icenet.git",
        "cloneUrl" : "https://github.com/icenet-ai/icenet.git",
        "owner" : {
          "login" : "icenet-ai",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 12,
        "stargazersCount" : 27,
        "watchersCount" : 27,
        "size" : 1805,
        "openIssuesCount" : 91,
        "subscribersCount" : 4,
        "pushedAt" : "2025-06-26T16:03:12Z",
        "languages" : {
          "Makefile" : 2636,
          "Python" : 481508
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "CF Conventions compliance review",
      "validationOrRequirement" : "Check netCDF forecast output compliance with [CF Conventions](https://cfconventions.org/).",
      "attemptedFixes" : "Currently, the forecast initialisation time is output as `time` variable, but it seems to typically be called `forecast_reference_time` according to the convention. The forecast lead time is output as `leadtime` variable currently, which should be called either `time` with `standard_name=forecast_period`.",
      "otherNotes" : "The mechanism for defining the data should not be taken from the reference files as it differs across the SIC ground truths. This is a blocker for v0.4, given icenet_output also is being redesigned to define metadata more explicitly where possible.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408098
  }, {
    "issueDTO" : {
      "id" : 3226558117,
      "title" : "[p5.js 2.0 Bug Report]: p5 reference error for p5.MediaElement",
      "url" : "https://github.com/processing/p5.js/issues/7968",
      "repositoryName" : "processing/p5.js",
      "description" : "### Most appropriate sub-area of p5.js?\n\n- [ ] Accessibility\n- [ ] Color\n- [ ] Core/Environment/Rendering\n- [ ] Data\n- [x] DOM\n- [ ] Events\n- [ ] Image\n- [ ] IO\n- [ ] Math\n- [ ] Typography\n- [ ] Utilities\n- [ ] WebGL\n- [ ] Build process\n- [ ] Unit testing\n- [ ] Internationalization\n- [ ] Friendly errors\n- [ ] Other (specify if possible)\n\n### p5.js version\n\nv2.0.3\n\n### Web browser and version\n\nFirefox 140.0.4\n\n### Operating system\n\nMacOS (Sequioa 15.5)\n\n### Steps to reproduce this\n\n### Steps:\n1. Install p5.js from npm \n2. Create the sketch.js file show in the [snippet section](#Snippet)\n3. Run Vite in dev mode to view the page.\n\n### Snippet:\n\n```js\nimport P5 from \"p5\";\n\n/**\n * @type {P5.MediaElement}\n */\nlet videoFeed;\n\nwindow.setup = async function setup() {\n    noCanvas();\n    videoFeed = createCapture(VIDEO);\n    videoFeed.size(90, 90);\n};\n\nwindow.draw = function draw() {\n    videoFeed.loadPixels();\n};\n```\n\n### Errors\n\n```\nfes_core.js:166:9\n\uD83C\uDF38 p5.js says: \n[p5.js?v=8fb9faf4, line 47924] Cannot read property of undefined. Check the line number in error and make sure the variable which is being operated is not undefined.\n\n + More info: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Cant_access_property#what_went_wrong\n```\n```\nfes_core.js:566:22\nUncaught TypeError: can't access property \"functionName\", stacktrace2[(friendlyStack[0].frameIndex - 2)] is undefined\n    processStack fes_core.js:566\n    fesErrorMonitor fes_core.js:662\n    fesCore fes_core.js:946\n    registerAddon main-BKN5yFoS.js:1258\n    friendlyErrors index.js:16\n    <anonymous> app.js:108\n[Learn More]\n    processStack fes_core.js:566\n    fesErrorMonitor fes_core.js:662\n    (Async: EventListener.handleEvent)\n    fesCore fes_core.js:946\n    registerAddon main-BKN5yFoS.js:1258\n    friendlyErrors index.js:16\n    <anonymous> app.js:108\n```\n```\np5.MediaElement.js:796:5\nUncaught (in promise) ReferenceError: p5 is not defined\n    loadPixels p5.MediaElement.js:796\n    setup sketch.js:11\n    #_setup main-BKN5yFoS.js:1303\n    #_start main-BKN5yFoS.js:1277\n    _p5 main-BKN5yFoS.js:1241\n    _globalInit init.js:82\n    promise callback* app.js:118\n[Learn More]\n    #_start main-BKN5yFoS.js:1277\n    AsyncFunctionThrow self-hosted:804\n    (Async: async)\n    _p5 main-BKN5yFoS.js:1241\n    _globalInit init.js:82\n    (Async: promise callback)\n    <anonymous> app.js:118\n```\n\n\n### Additional Notes\n\n`loadPixels()` is working on variables with the `p5.Image` type but does not work for the `p5.MediaElement`. Something to note is that the language server correctly picks up on most `p5` types. For instance when an image is loaded with `loadImage()` and stored into a variable, it implicitly has a type of `p5.Image`. However `createCapture()` is given an implicit type of `any`, so the `videoFeed` variable above is also of type `any`. Additionally when I hover over the import line: `import P5 from \"p5\";` I get the following message:\n```\nCould not find a declaration file for module 'p5'. '/Users/lukejans/Code/testing/p5-issue/node_modules/.pnpm/p5@2.0.3/node_modules/p5/dist/app.js' implicitly has an 'any' type.\nThere are types at '/Users/lukejans/Code/testing/p5-issue/node_modules/p5/types/p5.d.ts', but this result could not be resolved when respecting package.json \"exports\". The 'p5' library may need to update its package.json or typings. (ts 7016)\n```\nSo when I explicitly set the type in a JSDoc comment I get a language server hint that `P5.MediaElement` cannot be resolved.\n\n### Potentially Related Code\n\nhttps://github.com/processing/p5.js/blob/746a481a059152a7755423589a7860f4f1e0dcdc/src/dom/p5.MediaElement.js#L787-L790",
      "updatedAt" : 1753356161.000000000,
      "user" : "lukejans",
      "userHtmlUrl" : "https://github.com/lukejans",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/91230392?v=4",
      "labels" : [ "Good First Issue", "p5.js 2.0", "Help Wanted", "Area:DOM" ],
      "state" : "OPEN",
      "comments" : [ "looks like `p5` is not imported in this file where it's used https://github.com/processing/p5.js/blob/dev-2.0/src%2Fdom%2Fp5.MediaElement.js#L789", "hii, i am interested in this issue. can you please assign me?\n", "Thanks @pratham-radadiya! ", "@davepagurek if its still not solved, I would be happy to solve it dave!" ],
      "repository" : {
        "description" : "p5.js is a client-side JS platform that empowers artists, designers, students, and anyone to learn to code and express themselves creatively on the web. It is based on the core principles of Processing. http://twitter.com/p5xjs ???",
        "homepage" : "http://p5js.org/",
        "name" : "p5.js",
        "fullName" : "processing/p5.js",
        "htmlUrl" : "https://github.com/processing/p5.js",
        "gitUrl" : "git://github.com/processing/p5.js.git",
        "sshUrl" : "git@github.com:processing/p5.js.git",
        "cloneUrl" : "https://github.com/processing/p5.js.git",
        "owner" : {
          "login" : "processing",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 3531,
        "stargazersCount" : 22798,
        "watchersCount" : 22798,
        "size" : 111402,
        "openIssuesCount" : 397,
        "subscribersCount" : 498,
        "pushedAt" : "2025-07-22T10:29:40Z",
        "languages" : {
          "CSS" : 5236,
          "JavaScript" : 3813537,
          "HTML" : 89943,
          "Markdown" : 1609857,
          "GLSL" : 53388
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "The main goal of this issue is to fix the p5 reference error for p5.MediaElement, and to make sure that p5.MediaElement is properly imported in the file where it's used.",
      "validationOrRequirement" : "The issue is related to the DOM area of p5.js, and the requirement is to properly import p5.MediaElement in the file where it's used.",
      "attemptedFixes" : "The issue has been tried to be fixed by creating a sketch.js file and running Vite in dev mode to view the page. The error is occurring in the loadPixels() function.",
      "otherNotes" : "The issue is about p5 reference error for p5.MediaElement, and it seems that p5.MediaElement is not properly imported in the file where it's used. The error is occurring in the loadPixels() function. The language server correctly picks up on most p5 types, but not p5.MediaElement. The issue is related to the DOM area of p5.js.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408105
  }, {
    "issueDTO" : {
      "id" : 3257788439,
      "title" : "MangaPanda not recognised",
      "url" : "https://github.com/elboletaire/manga-downloader/issues/68",
      "repositoryName" : "elboletaire/manga-downloader",
      "description" : "When entering a Link from MangaPanda.in it says 'site not recognised'",
      "updatedAt" : 1753355814.000000000,
      "user" : "Cyjo44",
      "userHtmlUrl" : "https://github.com/Cyjo44",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/222511170?v=4",
      "labels" : [ "site-support", "bug", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "They probably changed something in the layout and it's not properly detecting it anymore." ],
      "repository" : {
        "description" : "\uD83D\uDCDA Download manga (and comics) from online reading websites",
        "homepage" : "",
        "name" : "manga-downloader",
        "fullName" : "elboletaire/manga-downloader",
        "htmlUrl" : "https://github.com/elboletaire/manga-downloader",
        "gitUrl" : "git://github.com/elboletaire/manga-downloader.git",
        "sshUrl" : "git@github.com:elboletaire/manga-downloader.git",
        "cloneUrl" : "https://github.com/elboletaire/manga-downloader.git",
        "owner" : {
          "login" : "elboletaire",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 26,
        "stargazersCount" : 156,
        "watchersCount" : 156,
        "size" : 4201,
        "openIssuesCount" : 17,
        "subscribersCount" : 2,
        "pushedAt" : "2025-07-11T11:01:21Z",
        "languages" : {
          "Dockerfile" : 694,
          "Shell" : 291,
          "Makefile" : 1956,
          "Go" : 49804
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "MangaPanda not recognized when entering a link",
      "validationOrRequirement" : "Site layout has changed",
      "attemptedFixes" : "",
      "otherNotes" : "They probably changed something in the layout and it's not properly detecting it anymore.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408107
  }, {
    "issueDTO" : {
      "id" : 874342502,
      "title" : "New lookup dropdown with descriptions",
      "url" : "https://github.com/sheltermanager/asm3/issues/1002",
      "repositoryName" : "sheltermanager/asm3",
      "description" : "The lookup data description fields for items like vaccinations, locations, etc are never actually displayed anywhere.\r\n\r\nBack in ASM 1, we used to show them in the dropdown at the side of the item being selected. It would require a new dropdown widget, but could we replicate the old behaviour? \r\n\r\nOne option might be to subclass the JQuery autocomplete box and have the dropdown fire on focus, like we do in a few other areas. Another alternative is to fully implement the selectbox widget instead of hanging it off the select tag.",
      "updatedAt" : 1753355786.000000000,
      "user" : "bobintetley",
      "userHtmlUrl" : "https://github.com/bobintetley",
      "userAvatarUrl" : "https://avatars.githubusercontent.com/u/18594812?v=4",
      "labels" : [ "enhancement", "good first issue" ],
      "state" : "OPEN",
      "comments" : [ "Replacing the use of select is probably not a good idea as it will work horribly on mobile. I think the way to go is have an option to include the description in the dropdown list with the main item - eg: Item [Description] \r\n\r\nPeople can then turn it on if they want, but the default behaviour should be as it is now without descriptions since most people don't use them (although this could because they are of such limited use)." ],
      "repository" : {
        "description" : "Animal Shelter Manager",
        "homepage" : null,
        "name" : "asm3",
        "fullName" : "sheltermanager/asm3",
        "htmlUrl" : "https://github.com/sheltermanager/asm3",
        "gitUrl" : "git://github.com/sheltermanager/asm3.git",
        "sshUrl" : "git@github.com:sheltermanager/asm3.git",
        "cloneUrl" : "https://github.com/sheltermanager/asm3.git",
        "owner" : {
          "login" : "sheltermanager",
          "avatarUrl" : null,
          "htmlUrl" : null
        },
        "hasIssues" : true,
        "fork" : false,
        "hasDownloads" : true,
        "archived" : false,
        "disabled" : false,
        "forksCount" : 71,
        "stargazersCount" : 121,
        "watchersCount" : 121,
        "size" : 127648,
        "openIssuesCount" : 123,
        "subscribersCount" : 15,
        "pushedAt" : "2025-07-24T11:16:27Z",
        "languages" : {
          "Dockerfile" : 613,
          "CSS" : 337410,
          "Shell" : 10839,
          "Makefile" : 6349,
          "JavaScript" : 13547254,
          "PHP" : 6255,
          "HTML" : 2896442,
          "Less" : 9472,
          "Python" : 10945810
        },
        "private" : false
      }
    },
    "summary" : {
      "main" : "Implement a new lookup dropdown with descriptions, similar to the old behavior in ASM 1, to display lookup data description fields for items like vaccinations, locations, etc.",
      "validationOrRequirement" : "The description fields for items like vaccinations, locations, etc are never actually displayed anywhere, and the dropdown should be implemented in a way that works well on mobile devices.",
      "attemptedFixes" : "One option is to subclass the JQuery autocomplete box and have the dropdown fire on focus, another alternative is to fully implement the selectbox widget instead of hanging it off the select tag.",
      "otherNotes" : "The issue is about replicating the old behavior of displaying lookup data description fields in a dropdown at the side of the item being selected, possibly by subclassing the JQuery autocomplete box or fully implementing the selectbox widget.",
      "summaryText" : "",
      "validJson" : true
    },
    "updatedAt" : 1753408112
  } ]
}